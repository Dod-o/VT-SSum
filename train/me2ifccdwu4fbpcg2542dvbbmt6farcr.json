{
    "id": "me2ifccdwu4fbpcg2542dvbbmt6farcr",
    "title": "Statistical Modeling of Relational Data",
    "info": {
        "author": [
            "Pedro Domingos, Dept. of Computer Science & Engineering, University of Washington"
        ],
        "published": "Aug. 12, 2007",
        "recorded": "August 2007",
        "category": [
            "Top->Computer Science->Machine Learning->Inductive Logic Programming",
            "Top->Computer Science->Machine Learning->Statistical Learning"
        ]
    },
    "url": "http://videolectures.net/kdd07_domingos_smord/",
    "segmentation": [
        [
            "This is a tutorial on statistical modeling of relational data, and I'm Peter Domingus from the universe."
        ],
        [
            "Washington, so here's what I'm going to do.",
            "I will begin with a little bit of motivation, and then I will spend some time covering the foundational areas of modeling relational data, namely probabilistic inference, statistical learning, logical inference, and inductive logic programming.",
            "Of course, I will only do the very briefest overview of each of these, and then I will talk about how we can put the pieces together and finally spend some time on how we can use of these, how we can use the result for."
        ],
        [
            "Lots of interesting and challenging applications, so here's in one slide.",
            "The basic motivation for this tutorial in this whole area of KDD.",
            "Most traditional data mining really thinks about a single relation.",
            "But the data that we mine is almost never in a single relation.",
            "Usually it's in multiple relations, and often they have very complicated interactions between them and we would like to model these directly, not have to 1st shoehorn them into this form at great expense and effort, and maybe even get results that are not so good.",
            "So that's one basic motivation.",
            "There's a number of a number of other ones that are closely related.",
            "One of them is the following.",
            "Statistical modeling.",
            "Usually assumes that the objects that you're modeling are all independent of each other.",
            "the ID in the, in the jargon, meaning independent and identically distributed, but again in the real world, objects are interdependent.",
            "Your data is non IID, people influence each other.",
            "Web pages point to each other.",
            "You know, things interact, so you can't look at each one of them in isolation.",
            "We would like to look at all of them together.",
            "Another one is that we almost always assume that you know the type of data that you're mining is only you know is 1.",
            "There's only one type of data that you're mining at any given time.",
            "Most of the time, however, that's not the case.",
            "We have multiple types of objects.",
            "We may have even whole hierarchies of classes, and we have multiple types of data, and you know things like text, images, databases, HTML spreadsheets, and often the things that we want to mine are spread across sources of these different types, not just one.",
            "And we again, we would like to be able to handle all of those together.",
            "A very closely related issue is that typically in KDD, people assume that the preprocessing has already been done.",
            "And you know, practice has shown that this is almost always where actually most of the costs of data mining is.",
            "Because we have to do the preprocessing and that's nontrivial, we have to take all those sources of data we have to extract the information we have to integrate it.",
            "We have to clean it up.",
            "And we need to focus on doing these things better because that's actually where the bottleneck is these days.",
            "And finally, most of data mining today is what you might call knowledge poor.",
            "We have an algorithm with some very weak ideas embedded in it, and this algorithm runs on some data and hopefully produces some results, but there's a big distance between this and what we would really like to get out of a data mining system, which is the actions that you need to take.",
            "In order to go from data to actions, we actually need knowledge about the problem, how certain things cause certain things, how certain religions that are maybe not present in data, but necessary for your inference isn't for deciding what actions to take, how these things interact.",
            "So the way to handle all of these things are at least one way.",
            "One good way to handle these things is to look directly at modeling multi relational data as multi relational data, and that's what we're going to try to do here."
        ],
        [
            "Here's some examples of areas where these issues are important.",
            "Web search, of course, is a very famous one.",
            "You get better results when you take into account links between pages, information extraction.",
            "Very important area in different extractions interact.",
            "You want to extract entities of different types.",
            "More generally, natural language processing and perception.",
            "Here's another nice example.",
            "Medical diagnosis.",
            "People do a lot of work on medical diagnosis datasets.",
            "They always assume that your patients are independent, but we know that this isn't true when there's an epidemic of something you know.",
            "If somebody has one particular illness, somebody else is actually more likely to have it, and if there's a family, members are the coworkers or you have been in contact with them, they're even more likely, so this is a good example of non eyedness computational biology.",
            "Another important area where you know every single one of these issues that I mentioned, this present social networks and other very obvious one, and you know very important one these days because computing and so on you know the examples go on and pretty much I think every area.",
            "Where we do data mining.",
            "If you look at it carefully you will see that the issues that I listed."
        ],
        [
            "There are present.",
            "So of course trying to mine multiple relations directly instead of, you know, one simplified data set where there's only one relation has benefits, and it also has cost, so let's keep that in mind.",
            "Let's see what those benefits and costs are.",
            "So one obvious benefit is that you potentially get better predictive accuracy.",
            "When I model objects independently, I'm losing information I don't take into font into account, for example, that the buying preferences of somebody I talked to influence mine, and so I'm less able to predict my buying preferences.",
            "This is one another one so predictive accuracy in general is one of the big gains of modeling interdependencies between objects and so forth.",
            "Another one is that we potentially get a better understanding of what's going on when we actually look at the multiple types of entities and relations among them.",
            "If we force things into this mode of 1 table.",
            "If we over simplify things, that will necessarily limit the insights that we can get from mining.",
            "And more generally, I think looking at these issues is the growth path for KDD.",
            "If we look at where we are or we have been in the past and we would like to be in the future, I think going the way of looking at multiple relations is really one sort of like nice way to grow.",
            "What are the costs?",
            "Well, for one learning is going to be much harder now.",
            "If I have multiple relations, multiple types of objects, interactions among them, I have many more things to model.",
            "I have many more parameters just going to be harder.",
            "In fact, this is the main reason why people in the past have made this idea.",
            "Assumption is that it makes life easy for them.",
            "And the other another one other related one is this.",
            "When we do simple things like, say, classification, clustering, Association rule mining, we pretty much can ignore this issue of inference.",
            "So you classify it, you give it an object, you produce a class label very simple.",
            "Once we start taking interactions of things into account, inference can no longer be ignored, because now the problem of how you propagate information from one node in this network to another.",
            "How you actually change these interactions together becomes crucial.",
            "So now we can no longer ignore the issue of inference, and in fact a good chunk of the time that we're going to be spending here is going to be on this issue.",
            "And finally, and perhaps most important, there's a price for the user.",
            "There's a price for the data miner.",
            "It's harder, it's more complex to actually build models and know what you're doing when you're dealing with this very rich complicated universe with different types, different relations, interactions and whatnot, then it is to deal with a single table.",
            "So these are the benefits.",
            "These are the costs that there's been a lot of research in this area, and in recent times, and of course the idea is to try to maximize the benefit."
        ],
        [
            "It's while minimizing the costs so we could state the goal in one sentence, perhaps as follows.",
            "At the end of the day, we actually like to be able to learn from multiple relations.",
            "Is easily as today we learn from a single one.",
            "We want to make the learning and the inference and the user interaction is easy or nearly as easy as nearly so as we can make it as mining from a single relation.",
            "Now this seems like a very ambitious goal and it is.",
            "But the good news is there's been a lot of progress in recent years.",
            "There's you know, there's a whole growing research area known as multi relational data mining, statistical relational learning, structured prediction.",
            "It goes by a bunch of different names, and I think I would claim that today we're actually close enough to this goal.",
            "And we have software that's easy to use that's open source, so everybody can use it.",
            "And you know, this software embodies algorithms and techniques that I think are mature enough to be used even by people who aren't the researchers developing it, and so really the goal of this tutorial is to sort of, like, you know, give people this these.",
            "At least a survey of these ideas, and then these techniques, and another point to bear in mind, though if you're on the research side as opposed to more, the application side is that first of all all the old research questions and Katie are still present here, plus a lot of interesting new ones.",
            "So as a field of opportunities for research, this is."
        ],
        [
            "Really quite wonderful, so here's the plan.",
            "Here's what we're going to do.",
            "This tutorial we have the elements that we need to solve this larger, more general Kitty problem, namely those elements are the following.",
            "We have probability for handling the uncertainty.",
            "That of course is present in all large datasets and in learning.",
            "We're all familiar with using probability and statistics in data mining.",
            "Now we also have logic for doing the richer modeling that we want to do here.",
            "We want to model multiple types.",
            "We want to model relations who model complex dependencies among objects.",
            "Logic is a language you know that has existed for a long time and that people in computer science always used to do these kinds of things, and so we can.",
            "We can.",
            "We can certainly draw on it here.",
            "Of course, the problem is going to be to learn to deal with this one.",
            "We're learning it.",
            "Then when you know when there's noise and whatnot, which logic per second do.",
            "And then we have learning and inference algorithms for each of these we have statistical learning algorithms, probabilistic inference algorithms, logical inference, inductive logic, programming, and so we have the pieces from which we can build the solution that we need.",
            "We actually don't have to start from scratch, and So what we're going to do is.",
            "First of all, we're going over these pieces and then we're going to figure out how to put them together.",
            "And perhaps surprisingly, it turns out to not be that hard to put them together in a way that actually works and is not too complex.",
            "And in fact, you know of the three parts of that role.",
            "This is actually going to be the shortest.",
            "And then once we've, you know invested our effort into getting up to speed on this and figuring out how to do this.",
            "Then we get the payoff.",
            "The proof is that on a wide range of applications that people care about, we're going to get huge leverage from actually not being able to do things at this more powerful level.",
            "And so the last part of the tutorial, naturally, the largest one, is going to be sort of like very practically minded, you know, look at how we can.",
            "Do, you know, a bunch of different applications.",
            "And of course, again, I'm only going to cover a small.",
            "Say."
        ],
        [
            "Ample of what can be done, but hopefully that will give people the general idea.",
            "So before we get into the meat of things, let me start with a couple of disclaimers.",
            "First of all, what I'm going to do here is not a complete survey of multi relational data mining.",
            "I will not mention many things that maybe deserve to be mentioned, but time is short.",
            "It's also of course, not a complete survey of the foundational areas.",
            "I really only have time to touch on a few essentials.",
            "In each one of them, but the satisfying thing is that even with just those few essentials, that's actually going to be enough for our purposes.",
            "The focus of this is mainly practical, not theoretical.",
            "There's a lot of theories you know, backing up a lot of of what I'm going to do here, but I'm actually not going to delve into that.",
            "I'm going to focus more on the applications.",
            "Because I think these days it's really more what we need.",
            "I'm going to assume some basic background knowledge in logic, probability and statistics etc.",
            "Not much, but certainly more than nothing.",
            "Please ask questions if at anytime there's something that's not clear.",
            "Do ask questions and finally this tutorial.",
            "All the examples that I'm going to show here.",
            "The code, the datasets, a text version of the tutorial.",
            "These are all available at this website alchemy.cs.washington.edu and I will put up this URL again more towards the."
        ],
        [
            "OK, so let's get started.",
            "Let's look at the founder."
        ],
        [
            "Larry's first of all, let's look at probabilistic inference, and most people have probably heard of vision networks.",
            "I'm actually going to focus on something slightly different, which is Markov networks, which probably people are not as familiar with, But actually turns out to be as important or even more so for multi relational data mining vision networks.",
            "So what is a Markov network?",
            "A Markov network like a vision network is a model like graphical model of the joint distribution of a set of variables.",
            "So here's an example smoking cancer, asthma cough.",
            "I'm going to assume that all Boolean.",
            "And it's a graphical model, so one part of the model is a graph.",
            "But unlike Envision Networks, it's an undirected graph, meaning there are no errors on the edges.",
            "And what this graph means is that a variable is independent of the rest of the network given its immediate neighbors.",
            "So for example, cough is independent of smoking given cancer and asthma.",
            "OK, so the graph tells us what the independent structure of the domain is, and this is actually simpler than Bayes Nets, because in business breathing off independence is kind of complicated.",
            "Here it's very simple if when I take out a bunch of variables to others become disconnected, then they're independently conditionally independent.",
            "Given the ones that I removed.",
            "So graph separation is all that's needed here, so this gives us the structure of the model.",
            "The parameters are given by what's called potential functions.",
            "Potential functions are defined over the clicks of the graph, so here, for example, there's a potential functions for the smoking cancer click click being a completely connected sub graph, and there's a potential function for the cancer asthma, cough click and potential functions can have arbitrary non negative real values.",
            "For example, here's for the Smoking Cancer click.",
            "There's two Boolean variables, so there's four States and I've assigned the value of the potential function to each one of them and intuitive meaning of a potential function.",
            "Is that higher values.",
            "Of the potential function correspond to states of the world that the world prefers that are more likely.",
            "So for example.",
            "This state is more likely than this state.",
            "And what this is capturing is that smoking causes cancer.",
            "So smoking causes cancer.",
            "You're less, you know.",
            "If it's less likely that your smoke that you smoke and don't have cancer, then it is that you smoke and have cancer or don't smoke at all, OK?",
            "Now to compute the probability of a state.",
            "All that I have to do is is go to each, go to each click, read off the value of its potential function corresponding to the state that it's in, and multiply them altogether.",
            "And that gives me my probability up to normalization constant.",
            "Which I have to divide by in order to make sure that these things all add up to one and that normalization constant is simply the sum of the of this product for all possible states.",
            "So this is very nice because it's very flexible.",
            "You can model just about anything.",
            "In this way you can put any knowledge that you want into this, but there's a very big problem lurking here, which is that it doesn't scale.",
            "The reason this doesn't scale is that if I need the value of the potential function for each state of the clique, I can only have small cliques.",
            "A click of size two or three is fine, but a clique of size 10 is going to have too many states.",
            "It's going to be impossible to store.",
            "It's going to be hard to reason with.",
            "It's going to be very hard to learn."
        ],
        [
            "Parameters Fortunately, we have another alternative, which is what's called a log linear form or log linear model.",
            "In a log linear model, instead of representing my probability as a product of factors, I'm going to represent it as an exponentiated sum of weighted features, and you can always convert 1 to the other.",
            "I take a product, I take it's log and I have and I have a son in the exponent and that's what I have here.",
            "So so.",
            "In the simplest case, I can just take the potential function and convert each of each states into a feature.",
            "So for example, one feature would be smoking is false and cancer is false, and then I and then its weight is the log of the corresponding value of the potential function, right?",
            "So I can always go from one to the other, but where I've gained something is that I don't necessarily need to have one feature for every possible state of the click.",
            "I could have a click with a very large number of states if I know that there's only 10 important, say 10 important features of that click, I can just compute those, assign weights to them, and now what I've done is that now I have a very compact representation.",
            "For example, here's a very simple feature of smoking and cancer.",
            "It's one if you don't smoke or have cancer, and it's 0 otherwise.",
            "And if I assign it a weight of 1.5, this actually implements this potential function that I had here before.",
            "OK, of course in this case it's not very impressive because the table was small to start with, but if I have a large click and we're going to want to model things with potentially very large clicks, this can make all the difference, and we're going to be leveraging it."
        ],
        [
            "Pensively as you'll see.",
            "So how do Markov networks compare with vision networks?",
            "Here's a very quick summary.",
            "So the form of both of them is a product of potentials.",
            "So Markov networks and vision that was actually very similar in many ways.",
            "Mathematically, they have almost the same form.",
            "The big difference is that in Markov networks the potentials can be arbitrary in the Bayes Nets the potentials have to be conditional probabilities.",
            "In Markov networks we can have cycles, not a problem.",
            "This is going to be very very useful for us in vision.",
            "Network cycles are forbidden if you have a vision network with direct excited that you actually doesn't represent anything, so you have to worry about not creating them when you learn from data.",
            "In Markov networks, the partition function, meaning that normalization constant that I saw before is arbitrary envision networks, very conveniently it's equal to 1, so we never have to worry about it, and this is a significant advantage of vision networks.",
            "In fact, if we say let's take a product of potentials representation and impose that the potential function is to be one.",
            "Essentially what you get out is a vision network.",
            "OK, so this is one advantage of vision networks.",
            "Now, how do we check independency Markov networks?",
            "It's just graph separation as I mentioned in Bayes Nets.",
            "It's this much more complicated.",
            "And called this separation.",
            "So in terms of an interface for the user based networks are actually kind of harder to deal with than Markov networks are.",
            "Now, one thing that it's important to realize is that if you look at the graphs of vision networks and Markov networks.",
            "There are some things that you can some independence relations that you can represent compact cleaner Markov network, but not in a vision network, and vice versa, so neither one dominates in that respect.",
            "But the important thing to bear in mind is that the log linear form applies to both, so if something is a compact base net, it'll it'll be a compact log linear form and something for a Markov network.",
            "So as long as we're using this log linear form in terms of compactness were always OK. How do we do inference in Markov networks?",
            "We can use as we shall see shortly.",
            "Algorithms like Markov chain, Monte Carlo, belief propagation and so on.",
            "Envision networks.",
            "What we usually do for inference is first we convert them to Markov networks and then we do the inference on Markov networks.",
            "So in some sense, Markov networks are the more fundamental notion."
        ],
        [
            "So how do we do inference in Markov networks?",
            "Well, typically what we so the Markov network is a model of the full joint distribution of a set of variables, and then typically the questions that we want to answer are things like what is the conditional probability of some variable given some others?",
            "What is the marginal distribution of some subset of the variables?",
            "And here's the expression that we want to do this over.",
            "Unfortunately, doing doing this inference exactly is a very hard problem.",
            "It's sharply complete, which means it's even worse than NP hard.",
            "OK.",
            "However, there's something that's actually very easy, which is the condition, or it's called the Markov blanket of a variable.",
            "The Markov blanket of a variable in the Markov network is just its neighbors in the graph, and it's easy to see that the distribution of a variable given its neighbors in the graph is actually can be computed directly.",
            "It's a simple expression.",
            "All the clicks that don't involve that variable disappear, things cancel out, and so this can be done quite efficiently, and So what we're going to see is an algorithm for inference that exploits this.",
            "The algorithm is called Gibbs sampling.",
            "It's probably one of the most widely used algorithms in the universe.",
            "There was a survey of like that, I think by IEEE computer a few years ago.",
            "Of what the most important you know algorithms were, and this actually came out on top 'cause it's used throughout science and technologies to do inference on complicated probabilistic."
        ],
        [
            "And it's more general Markov chain Monte Carlo, of which Gibbs sampling is an example an it's a joyfully simple algorithm for what its power.",
            "So it's well worth knowing.",
            "So how does Gibbs sampling work?",
            "It works like this.",
            "I start out by assigning random truth values to all my variables.",
            "I'm focusing on the Boolean case here.",
            "And then I do the following.",
            "I repeatedly go to a variable and re sample its value given its neighbors.",
            "Right, so I have it's conditional distribution given its neighbors, and I've taken you sample of its value.",
            "I have a new state and I just do this for a long time.",
            "Some maximal cycles or until some convergence criterion is met, and then I just estimate my probabilities of interest as the fraction of states in which the event that I'm asking about health.",
            "Like you know, what is the probability that this person has?",
            "You know disease X?",
            "Well, I sample a whole bunch of States and if you know if in those states 80% of them the person has this is X, then I said that probably is .8 and this is really a Gibbs sampling.",
            "It's a very simple algorithm, but."
        ],
        [
            "It's also very general.",
            "There are other inference methods that are worth knowing about.",
            "Gibbs sampling in truth is actually probably overused.",
            "It's used even when it's not probably the best thing to have.",
            "So there are many, many variations of Markov chain Monte Carlo, so Gibbs sampling is just the best non representative this class.",
            "But there are many others.",
            "There's also a newer class of algorithms called belief propagation that is becoming quite popular, in particular for this type of problem we use what's called the sum product version of belief propagation, because what we're actually doing is we're doing sums of products to compute probabilities.",
            "There's also variational approximations, and there's also a very large literature on exact methods.",
            "Gibbs sampling on all these other methods are approximate, right?",
            "They give an approximate answer with more time.",
            "They will give you a better answer.",
            "There's also exact methods.",
            "However, exact methods did not work on the large problems that we're interested in here, so we're not going to focus on that much, but there's certain."
        ],
        [
            "A lot of you know there's a big literature on that, so the other main type of inference that we often want to want to do is what's called MA P for maximum posteriori or MPE.",
            "For most probable explanation inference.",
            "And the goal here is, given some evidence X.",
            "So these are the values of some variables.",
            "I want to find the most likely state of the world.",
            "I I have some other variables why the query?",
            "And I want to find the values of the query variables that are most likely given the evidence for those who.",
            "Are you familiar with things like hidden Markov models?",
            "This is what the Viterbi algorithm is doing, so we're looking for the most likely joint set of the variables.",
            "In some ways this is simpler than computing probabilities, but in some way it's actually alot alot.",
            "Alot more subtle because now what we're doing is we want to find the jointly most likely state which is not necessarily just the most likely state of each of the variables in isolation.",
            "So for this."
        ],
        [
            "Of inference.",
            "What kind of algorithms do we have?",
            "The Classical one is called iterated conditional modes and it's very simple.",
            "It's just greedy search.",
            "You go to each variable in turn and you set it to the most likely value of that variable given its neighbors.",
            "It's conditional mode and you just keep doing that until you bump into local minimum.",
            "It's a little bit like the MLP inference analog of Gibbs sampling.",
            "The advantage of this is that it's fast.",
            "The disadvantage of course is that it will get stuck in local Optima.",
            "To avoid that, we can use simulated annealing, where sometimes it takes some random.",
            "Down steps instead of up steps and simulated annealing if you give it enough time and you do right will actually give you the global optimum, but it could take a very long time.",
            "Similar the new link is very widely used, but it's also very slow.",
            "OK, so that's the good and the bad of it.",
            "More recently there's this class of algorithms that are based on converting the inference problem to problem of finding a min cut in a graph.",
            "They don't always aren't always applicable when they are, they can actually be really good.",
            "And then there's also belief propagation.",
            "Belief propagation is pretty much the same algorithm that we saw before, except that instead of some product now we do Max product because what we're doing is we're taking maximums of products OK."
        ],
        [
            "These are some of the other MLP inference algorithms that are available.",
            "Let us now look at how we can learn these kinds of models from data."
        ],
        [
            "K. So we're going to look at two things.",
            "As usual, learning parameters, meaning the weights and learning structure, meaning the features.",
            "And we're going to look at how parameters could be learned generatively or discriminatively, and in this tutorial I'm going to assume that we have complete data.",
            "IE, there's no data.",
            "There are no missing values in general.",
            "Of course we could have missing values, in which case we need to use M versions of the algorithms that I'm going to describe here, and they're available in the software that will mention later, But here for brevity I'm going."
        ],
        [
            "I'm going to ignore that issue, so how can we learn weights well?",
            "The standard Classical way is generative learning, where or just maximum likelihood or Bayesian learning.",
            "So what we do in maximum likelihood learning is we try to find the values of the weights that make the data that we've seen as likely as possible, and unfortunately for Markov networks there is no closed form for the weights.",
            "You actually have to do the numerical optimization.",
            "The good news is that there are no local maximum.",
            "It's a convex problem.",
            "So there's a single global optimum, and you're guaranteed to find it.",
            "You know you don't have to worry about getting stuck in local Optima and to do the numerical optimization there are many.",
            "You know there's of course gradient descent, and then there's also many more sophisticated, faster methods that use 2nd order information that use the Hessian matrix of a second order derivatives.",
            "And so how do we do this?",
            "We we take the expression for the probability that we saw before we take it's log.",
            "We differentiated with respect to each weight and that gives us the gradient and the great and tell us which is actually we should go in an.",
            "This derivative actually has a very intuitive form.",
            "Which, like you know easy.",
            "It's helpful for understanding what goes on, so here's what it is.",
            "The derivative of the log likelihood with respect to the weight of some feature.",
            "If you do, the math just turns out to be the following.",
            "It's the difference between the number of times that the feature is true in the data and the number of times that the model predicts that the feature is true.",
            "OK, so if the model is predicting the future is true less often than it really is, it's weight needs to go up.",
            "You know, in the opposite case it needs to go down, and when the predictive and true and true counts lineup for all the features you know, we've reached their optimum and we're done learning.",
            "We've matched the data perfectly.",
            "OK, so that's the idea.",
            "There's there's there's a snag here though.",
            "The snag is that to compute this term, we need to do inference.",
            "This is computing an expectation over Markov network, so this could again this gets us back to that Sharpie hard problem.",
            "And now when we do this.",
            "Repeatedly, at each step of our gradient descent or or other optimization procedures, things could get very very slow.",
            "OK, so we need something more efficient."
        ],
        [
            "What can we do?",
            "Well, a fairly old idea that is still very popular is pseudo likelihood.",
            "And now you see the likelihood is the following is if optimizing likelihood is too hard.",
            "Let's optimize something easier instead and hope that it still gives good results.",
            "And the idea is actually fiendishly clever.",
            "Pseudo likelihood is just the product overall variables of the probability of the variable given the state of its neighbors in the data.",
            "OK, so this is easy to compute for the same reason that Gibbs sampling have easy time computing the conditional probabilities right?",
            "This is it's just a simple expression, no inference is required.",
            "And there is one important property which the likelihood has, which is that it's a consistent estimator.",
            "So, given you know, given enough data it will converge to the true values of, it'll produce the model that gives you the true values of all these conditional probabilities.",
            "And you know when you combine, combine this with with a fast optimization method.",
            "You actually get learning that there is quite scalable.",
            "It's widely used in, feels like vision, special statistics, natural language processing, social network modeling, etc.",
            "The important thing to keep in mind though is this is that sometimes it works and sometimes it doesn't went through the likelihood works, it's great when it, when it fails it can fail pretty badly.",
            "When and why the pseudo likelihood fail.",
            "Well, the problem with pseudo likelihood is that it's focused on optimizing short range interactions.",
            "That's how it knows about.",
            "So if your inference time, you're going to look at long chains of inference pseudo likelihood.",
            "You know really didn't optimize your model for that and you could get terrible results, so the likelihood this conditioning on the known states of your neighbors, so it tends to be too confident of them.",
            "It tends to overweight the nearby information at the expense of you know your neighbors that, for example, the information that you know about your object itself.",
            "So likelihood is good in some ways, but it's prob."
        ],
        [
            "Matic, in others.",
            "So what else can we do?",
            "We can do discriminative learning.",
            "Discriminative learning is actually often a very good idea in its own right, and you know, I mean these days people pretty much almost always do discriminative instead of generative learning.",
            "Just because it gives better results.",
            "And the reason it gives better results is that it's actually trying to optimize the right thing most of the time.",
            "So what is the right thing?",
            "What we do in discriminative learning is that instead of maximizing the joint distribution of all the variables, what I'm going to do is I'm going to maximize the conditional likelihood of the query variables given the evidence variables.",
            "Of course, this requires knowing at learning time who's going to be Korean, who's going to be evidence, but most of the time we do know that, so we can you know.",
            "So in some sense, it would be silly not to use that information and then by optimizing this right, we're actually not going to waste any modeling effort trying to model model interactions between variables that we actually don't care about.",
            "And that could actually make us do the wrong thing, because you know, I could make a change.",
            "That improves the modeling of the things that I don't care, but at the expense of making you know, the modeling of Y given X worse.",
            "So This is why this tends to give better results, and you know the expression that we get is pretty much the same, except that now what we have is PY given X instead of just the joint distribution of all the variables, and I can ignore all the clicks that only involve variables in X because at inference time I'm going to know those, but the difference is that now I have another way to deal with this problematic term here, which is the following.",
            "Instead of computing this expectation over all possible sets of Y given X, what I can do is I can just look for the single most likely state of Y given X, do the counts in those and let them be an approximation for the Council for everybody.",
            "The reason this works is that these distributions can have all sorts of peaks all over the place, but as I condition on more and more information on the Exide most of those peaks will disappear and in the limit that should have all of my mass concentrated in one peak.",
            "So if I just use that peak as my approximation, in many cases, that's actually a good enough approximation.",
            "And remember, we're just learning here from noisy data, so it's not like I really care about getting exactly the right thing.",
            "So this is a very simple idea, but it can actually.",
            "I mean it can make life way easier for us because now instead of computing an exponential, assume with an exponential number of terms.",
            "I'm just doing a maximization which can be a lot faster."
        ],
        [
            "So there's a couple of other approaches to it.",
            "Learning that are worth knowing about the classical approach for learning, which in this model is something called iterative scaling.",
            "It's not used a lot these days because it's quite slow.",
            "A very recent method is Max margin approach is maximized and approaches are the extension to Markov networks of the ideas of support vector machines and so far they've only been used for restrictive types of structures, but it's a method with with a lot of."
        ],
        [
            "Promise.",
            "So what about structure learning?",
            "Suppose I don't just want to learn the weights, I actually want to lend a structure of the model, i.e.",
            "In a log linear model, I want to figure out what the features are, not just what the weights should be.",
            "Well, we can think of doing sort of like a greedy search approach to this right?",
            "I start with atomic features, meaning the variables themselves.",
            "And then I Gridley try conjoining each feature with each Atom an I evaluate them according to likelihood or posterior or something.",
            "I pick the best ones and I keep going.",
            "So this this is a reasonable method to use, there is a problem with it, though the problem is that when I try a new candidate feature.",
            "In order to evaluate it, I now need to potentially recompute all the weights because the features interact with each other.",
            "So for each candidate I need to do a weight optimization.",
            "Optimal weight optimization takes some time, even if it takes a few minutes.",
            "If I'm going to try millions of combinations, that's going to be infeasible.",
            "So we need something some way to overcome this problem.",
            "What people have typically done and you know, it's a reasonable thing to do, is to assume that when I create a new feature, the weights of the previous features stay constant.",
            "So now the only thing I have to compute is the weight for this new feature.",
            "And that can be done fast.",
            "In some cases it can be done in closed form and then maybe once I've selected the feature.",
            "Now I can do the optimization for everybody again, so again this is an approximation.",
            "Sometimes it's OK, sometimes it doesn't give such good results, but it's what people have done OK."
        ],
        [
            "Alright, so let's talk a little bit about logical inference."
        ],
        [
            "So first order logic is a very rich language that pretty much allows us to say all the kinds of things that we're going to want to say here.",
            "Formulas in first order logic, I will tap out of four types of symbols, constants representing objects in the domain, like Anna variables like X, that range over the objects in the domain, functions that take a tuple of objects as input and produce an object as output, like say mother of X and predicates that represent properties of objects.",
            "Or relations between objects, like for example friends XY represents whether X&Y are friends or not.",
            "OK, and I'm going to call a literal a predicate or its negation.",
            "So for example, friends are not friends and a clause is a disjunction of literals.",
            "For example, mother of X are not friends XY.",
            "And I need to call a grounding of a predicate or formula.",
            "What we obtain when we replace all the variables by constants.",
            "For example, if one of the predicates in my domain is friends XY and two of the constants are N and Bob.",
            "One possible grounding is friend Cinnabon.",
            "OK and friends and above is just a Boolean variable that is true if N and Bob are friends and false otherwise, and I'm going to call a world also known as model or interpretation and assignment of truth values to all the ground predicates.",
            "OK.",
            "So at the end of the day I forum all groundings of all predicates with all constants.",
            "I have a very large Boolean vector and this is the state of my world.",
            "And the thing that we're going to be worried about here is probability distributions over such states of the world."
        ],
        [
            "OK.",
            "So how do we do inference in first or logical?",
            "Traditionally this was done by theorem proving.",
            "That's for example, what Prolog does in more in recent years.",
            "However, people have found that perhaps surprisingly, it's often a lot more efficient to do propositional isation, which is you ground out the whole knowledge base, followed by model checking.",
            "Are you running a satisfiability solver?",
            "And there's two main approaches to satisfiability.",
            "One of them is backtracking, exemplified by the deep algorithm.",
            "I'm not going to cover that here due to time limitations.",
            "The other one is stochastic local search exemplified by walk set, which I will cover here."
        ],
        [
            "So, so what's the basic?",
            "Let me let me lay out the problem of satisfiability.",
            "So this is what we're going to use to do inference.",
            "We have an input that's a set of clauses.",
            "And remember, we can always convert the knowledge base to a set of clauses, IE to conjunctive normal form or CNF.",
            "And the output is either the truth assignment that satisfies all the clauses or failure.",
            "So we want to get one of those two things out.",
            "Satisfiability, of course is the paradigmatic NP complete problem.",
            "You can reduce all of this to it.",
            "Since of course this is intractable and less equals NP, the solution is to do some kind of search.",
            "The key point to realize that is something that you know during the first several decades of this problem, which of course people in many years of computer science look at didn't realize is that even though in the worst case, satisfiability is hard, in most cases it's actually easy, and this is going to bias, you know, no end of efficiencies.",
            "The reason most at most satisfiability problems are actually easy is that there's only a narrow region of problem space where they're hard.",
            "And the intuition is this.",
            "Think of the clauses constraints on the variables.",
            "If I have a lot of variables and very few clauses, the problem is underconstrained, then it's easy to find the solution rapidly.",
            "On the other side, if I have a lot of clauses on a few variables, then the problem is over constrained and it's easy to realize quickly that there's going to be no solution.",
            "The only hard region is going to be in a narrow range of the ratio of clauses to variables where you really have to look at the details to make to figure out whether you can solve the problem or not."
        ],
        [
            "So how does the Catholic local search work?",
            "It's quite simple.",
            "You start with a random state that's at each.",
            "It's a search process, and at each point in the search process I have a complete assignment of values to the variables and then what I'm going to do is.",
            "I'm going to flip variables in unsatisfied clauses to try to satisfy them and I will use the heuristic for Hill climbing on those like for example, trying to minimize the number of unsatisfied clauses.",
            "Of course, if I just did this, I would fall into local minima in order to avoid that, I'm going to do some amount of random flips, and I'm also going to restart the whole problem, multiple the whole process multiple times."
        ],
        [
            "OK, so here's the Walksat algorithm, very famous algorithm, surprisingly simple given how powerful it is.",
            "In fact, it's powerful because it's simple because it's simple.",
            "You can do these search steps.",
            "You know gazillions of times in very little, very little CPU time.",
            "So I'm just going to do this for one to Max tries.",
            "I start out with a random truth assignment as a solution, and then I go through some maximum number of flips where first of all I check if in the current state of the clauses are satisfied.",
            "If they are, then I return that solution because you know, I've succeeded.",
            "Otherwise.",
            "I pick a random unsatisfied clause with some probability P, where this is an input parameter.",
            "I flip a random variable in that clause, which guarantees that the clause is satisfied.",
            "Otherwise, I flip a variable that maximizes the number of satisfied clauses.",
            "OK, so this is the greedy step.",
            "And if I'm lucky at some point in this process, I will have a solution.",
            "If I'm unlucky, I won't have a solution, and the disadvantage of these types of methods is that I never know.",
            "If there really is no solution either, I just didn't find one in the time that I have available.",
            "So if you really want that answer, if you want a negative answer, you need to use the backtracking types of methods.",
            "The disadvantage of these methods are that they tend to be a lot faster.",
            "OK, so to scale to really large problems, which is what we want here, works at tends to be very."
        ],
        [
            "OK, so finally let's look at inductive logic programming.",
            "So the question now is like how do we learn knowledge bases in first order logic from data?"
        ],
        [
            "OK, and probably the best way to introduce this is to start by looking at propositional rule induction.",
            "So rule induction over a single table.",
            "So we have a set of positive and negative examples of some concept, let's say spam.",
            "You know spam emails and non spam emails.",
            "Each example is is the concept or class Y. I'm going to assume here that it's a Boolean and a set of attributes.",
            "Again, I'm going to hear this Boolean, so why would we spam non spam and X1 to XN would be the presence of different words like the word free?",
            "For example, is probably a very good indication of that something is spam.",
            "Are you still hearing?",
            "So the goal in Rule induction is to induce a set of rules that cover all the positive examples, but none of the negative ones OK. And the rule is just a body implies ahead, otherwise known as a horn clause.",
            "So the body is a conjunction of tests.",
            "Which can be literals.",
            "Meaning you know these values or their negations and the head is the class and I'm going to say that a rule covers an example.",
            "If the example satisfies the body of our.",
            "OK, and in order to do the learning I'm going to need some evaluation measure for a rule like you know, it's accuracy, information gain, coverage, support.",
            "You can use different things."
        ],
        [
            "So the way the way rules you know, there are many algorithms for this.",
            "But so, like the most widely used one, works like this.",
            "I'm going to learn a single rule, one antecedent at a time, and I'm going to learn a rule set by learning one rule at a time.",
            "So how do I learn a single rule?",
            "I start out with the head being the class and then antibody, meaning that everything matches the rule and then what I do is I look at every literal I try adding it to the rule.",
            "I evaluate the result, and then I add the literal that gives me the best results.",
            "OK, so now I have added a little to the rule and I can repeat that another little to the rule until no literal improves the evaluation.",
            "And then I returned the rule that I found OK."
        ],
        [
            "This not plugged into the larger algorithm, often known as separating conquer, which goes like this.",
            "I start with an empty ruleset.",
            "And with my set S, which is all that all the examples.",
            "And I repeat the following.",
            "I learn a single rule the way that I just described.",
            "I add that rule to the rule set and then I delete from the set as the positive examples that I just covered, I separate them out because those are accounted for now and then I'm going to try to learn another rule to cover the remainder of the positive examples.",
            "And I keep on doing this until hopefully actually this.",
            "It's not until this set is empty.",
            "It's until a set of until there are no positive examples left to cover.",
            "OK, yeah.",
            "Part of the algorithm is lens in setting where even more in certain way.",
            "The same idea that boosting ordering has, which is emphasizing or with the you know well classified, that's actually so the question here is like how does this really?",
            "Isn't this similar to boosting?",
            "This is actually a lot older than boosting right decades older, but there's an interesting relationship between.",
            "In fact you can use boosting to learn rule sets by taking a single rule as the model that you're boosting, and that can give good results.",
            "So in boosting, in a certain sense, what happens is that.",
            "I don't completely take out examples, I just done with them.",
            "So yes, there is an interesting relation between the two.",
            "As I said, this is only the most basic algorithm.",
            "It's not the most suface."
        ],
        [
            "So now how do we do first order rule induction?",
            "Right now instead of justice Boolean attributes, I have arbitrary predicates with arguments and things now look very complicated.",
            "The good news is that we can actually take the algorithm that we just saw and transfer it to this more powerful language with only a couple of changes.",
            "So now why index IR predicates with arguments?",
            "Say why isn't sesser XY?",
            "Let's say we want to learn the rules that predict ancestor XY from things like, you know parents XY, OK.",
            "So now what's going to happen is that when I grow a rule, what I'm trying on is not attributes, its literals, and again I can try adding all literals in the language with one caveat, which is.",
            "I should make the restriction that I can only add literals that share at least one variable with the literals that already in the rule, because if they don't, then basically the new little says nothing about the things that I'm that I'm interested in, so I think this is a reasonable restriction to make.",
            "And then the other thing that we need to worry about is that adding a little actually changes the number of groundings of the rule.",
            "In propositional learning, the space of examples that I was learning rules over was always the same.",
            "It was the set of objects that I have in my domain.",
            "Here it's a little more subtle.",
            "Notice suppose that I'm building a rule for ancestor XY, right?",
            "What is the set of groundings of this rule?",
            "It's the set of pairs of people, right?",
            "Such that one could be the ancestor of the other.",
            "But if I now add this little parents ZY and notice I'm obeying that rule here because it has wine common with this guy now the set of ground possible groundings of this rule.",
            "Is the set of triples XYZ?",
            "So now I've just suddenly greatly expanded my space of possibilities so it be easy to fool myself that I'm doing very well because I'm just creating a lot of positive groundings, but that doesn't actually mean anything.",
            "So what I need to do is I need to change my evaluation function to take this effect into account.",
            "And again, there's many ways to do this, but one simple heuristic, one that works fairly well is I just take eval and I multiplied by the number of positive groundings of the original rule that are still covered.",
            "After adding little Arrow.",
            "And the idea behind this statistic is that, well, that's what I care about.",
            "OK, if the total number of groundings has gone up but the number of positive groundings has gone down, actually you know I'm more interested in the letter, so I can use this to compensate, and this this is just one algorithm, But this is very, you know, variations of this algorithm are very widely used in inductive logic programming and are surprisingly power."
        ],
        [
            "OK, so now let's look at putting the pieces together, and now that we've covered the main pieces of background that we're going to need to do multiple multi relational data mining.",
            "Let's see how we can actually you know."
        ],
        [
            "Turn this into albums that we're interested in, and of course, because this is an area of active research, there's a whole slew of approaches.",
            "Here are some of them.",
            "All this one is called knowledge based model construction.",
            "There's also something called stochastic logic programs, probabilistic relational models, relational Markov networks, vision logic, Markov logic and many others.",
            "And people are still proposing more of these."
        ],
        [
            "The key thing to remember though, is that there's a number of dimensions along which this algorithm is different.",
            "So what you don't understand is what does dimensions are, and then when a new algorithm comes along, you will know where to place it.",
            "And instead of having to, you know, remember, and understand an exponentially growing number of algorithms.",
            "You just have to remember understand this, you know, linear number of dimensions.",
            "So what are those dimensions?",
            "Well, one dimension is just the logical language that the representation uses.",
            "So the logical language could be full blown 1st order logic.",
            "Or more often it's a subset.",
            "It's something like horn clauses or frame systems.",
            "On the other side, there's the probabilistic language that the representation uses.",
            "It could be vision, networks, Markov networks.",
            "It could be something like probabilistic context free grammars.",
            "Or it could be even more restricted languages.",
            "Then there's the type of learning that you can do.",
            "Generative versus discriminative structure and parameters versus perimeters only.",
            "Knowledge risk rich or knowledge poor.",
            "And finally there's the type of inference that you can do, like MIT and marginal, and whether you fully ground out your network to the inference or you only partially grounded, or you do lifted inference where you reason at the level of all sets of objects at once.",
            "So what I'm going to do next is I'm going to give you a whirlwind tour of some of these approaches, just to give you a flavor.",
            "Of what's available.",
            "Keeping these relevant dimensions in my."
        ],
        [
            "So knowledge based model construction works as follows.",
            "The logical language is horn clauses and the probabilistic languages Bayes Nets.",
            "And the idea knowledge based model construction is that you have a set of horn clauses that specify how to build a vision network.",
            "And the way they specified is as follows.",
            "A ground Atom in the in the every ground Atom in your logical knowledge base becomes a node in the vision network, like for example friends Anna Bob would become a node in the vision network.",
            "The head of a clause.",
            "Is going to be a child node and the body of the clause are going to be the parent nodes.",
            "OK, so this is how you do this correspondence between horn clauses in the structure of the vision network.",
            "Now of course, the problem is that I could have more than one clause with the same hit.",
            "Right, in which case now I need some way to combine.",
            "The influence of the multiple classes on this one child.",
            "For that I need the combining function atypical combiner function that we use this noisy or.",
            "So I will say that this this child variable is true whenever any of the sets of the parents, any of the antecedents in any of the rules is true, except it's a noisy process.",
            "So probabilistically they could fail to make the child true.",
            "And then to learn these models to learn the structure, you can use any LP algorithm to learn parameters, you can use the EM algorithm.",
            "And to do inference typically what happens is you do partial ground and this is.",
            "This is why this is called knowledge based model construction, because what you do when you have a query is you construct the network that you need to answer the query.",
            "You don't build a full model 'cause you know that could be very bad, you just build the part that you need to answer the question and then over that ground network.",
            "Now you can use any probabilistic inference method.",
            "Typically people have used belief propagation, but you could also use the MCM."
        ],
        [
            "See another algorithms stochastic logic programs.",
            "The logical languages, again, horn clauses, but not the probabilistic languages.",
            "Probabilistic context free grammars.",
            "SLP's are a first order generalization of PCF cheese.",
            "Where instead of production rules do not have horn clauses.",
            "And the way we do this is we're going to attach it probability to each clause.",
            "And then the sums of the probabilities of the clauses with the same head has to be one.",
            "So the semantics for this is that I have a probability distribution over the ways in which that.",
            "Head could be produced as a body or could be proved using the body OK, and So what I have at the end of the days I have a probability distribution over possible proofs and if I send those out for any particular AT and I'm interested in, I get the probability of that Atom.",
            "OK, so again learning could be done using any IOP algorithm and now parameters can be learned using M except I have to do what's called failure adjusted Ian because some proofs fail.",
            "Which means that you know the probability mass of the valid proofs is going to be less than one, so I need to.",
            "I'm going to need to renormalize.",
            "And to do inference, what happens is that you know I can do inference using a prologue engine, but the way it works is that instead of just producing 1 proof as in Prolog, I need to produce all possible proofs and then I need to keep updating the probabilities by multiplying things down the proof tree and adding over alternative subtrees.",
            "And this is how you doing."
        ],
        [
            "In SLP's probabilistic relational models, the logical languages frame systems, meaning what we're going to have is, we're going to have a set of classes of objects, and each class of objects is going to have attributes and relations to other objects, with the important restriction, which is what frame systems make that their relations can only be binary.",
            "So relation is always from the current object to some other object.",
            "And then what?",
            "What PRMS have is for each class I have a template of a vision network that I'm going to construct for objects of that class.",
            "So for objects of the class, I'm going to have a vision network that says how the properties of the object depend on each other and on properties of related objects.",
            "OK, so this is your basic language.",
            "Notice we're not allowing dependencies of relations on relations here.",
            "To learn it's very nice because we can learn the parameters in closed form.",
            "It's a vision network.",
            "If there's missing data which most of the time there is, then you have to use them.",
            "But again, that's fairly standard.",
            "The way structure is learned is by generalizing algorithms for learning vision network structure.",
            "What's going to happen is that I'm going to try adding, removing, reversing links, but I'm going to do this in a tiered way.",
            "First, I try to see predict properties of an object given properties of the object itself, and then using properties of objects that are directly related, and then objects that are two links away and so on until nothing gives me an improvement, because if I try to do it over everybody all at once, it would be too costly and I would probably overfit massively.",
            "Inferencing PRMS is done by fully grounding the network, although you know.",
            "I don't see any reason why it couldn't be done using partial grounding, and typically people have used belief propagation, but again, you could use MCMC or something else."
        ],
        [
            "So relational Markov networks is now something that's somewhat different from these approaches that we've seen so far in relational Markov logic network.",
            "In relation Markov networks, the logical languages, SQL queries of the simplest type conjunctive queries.",
            "And the probabilistic languages Markov networks.",
            "And the way our immense work is as follows.",
            "What the query specifies is what the clicks are.",
            "I run a query on a database and it gives me.",
            "It gives out a bunch of tuples.",
            "These each of these tuples is a click.",
            "OK, and now associated with each click.",
            "I'm going to have a potential function.",
            "So I have a query to define the click and I have the potential function over the click OK. Notice arms do not allow uncertainty of relations.",
            "At least this is currently defined.",
            "I can use the relations in the query to produce my clicks, but then the probability distribution is just over the atoms in the click which are properties of objects learning to date.",
            "People have only then weight learning and discriminative learning in particular.",
            "Inference again is done by full grounding and then running."
        ],
        [
            "Belief propagation.",
            "So vision logic.",
            "Vision Logic is a fairly complicated language with its own syntax, but essentially it's at the level of 1st order logic.",
            "The probabilistic languages, again vision, networks and the way this works is that there's this programming language called blog.",
            "Very unfortunate name.",
            "You'll never find it on the web for vision Logic and what a block program specifies is how to generate the relational world.",
            "It's sort of like the idea of a generative model, taken to the limit.",
            "It says, well, do this with certain probability, generate some number of objects and then.",
            "Generate these properties of these objects and then given that generate some properties of related objects and so forth.",
            "The block program actually only specifies the structure of the model, the parameters the distributions have to be specified somewhere else in Java code or some library distributions or whatever.",
            "The nice thing about Vision Logic is that, unlike the languages that we saw before, it actually allows for there to be unknown objects in your domain, meaning objects that exist and affect what goes on.",
            "But you don't observe directly.",
            "Think for example, of blips on the radar.",
            "These loops are generated by aircraft.",
            "Blog actually allows it to model the existence of aircraft, whereas in these other languages you were only doing distributions over the things that you could observe.",
            "A very big problem with with blog.",
            "It was already present in the other models, but it becomes even more seriously is that it could a block program could easily create a vision network with directed cycles.",
            "In which case your inference will never finish running.",
            "Unfortunately, checking a block program to make sure that it doesn't create networks with cycles is an intractable problem, and so you know people basically just don't do it and they and they hope for the best.",
            "To date, no learning algorithms for blockers in proposed inference is done by Markov chain Monte Carlo.",
            "With the proposal distribution that you have to supply.",
            "Again, this is not so great because most people have no even people with PhD in machine learning.",
            "Often you know have a lot of trouble figuring out how to define a proposal distribution.",
            "A nice thing about inferencing blog is that it does just use partial grounding.",
            "So if the relevant part of the model is simple as it can, BMC things can be fairly efficient."
        ],
        [
            "Finally, and most recently, Markov logic is a language in which the logical language is full first order logic.",
            "The probabilistic languages, Markov networks.",
            "And the syntax is very simple.",
            "The syntax is just first order logic as before, except we're going to attach weights to the formulas and other semantics.",
            "Is that a formula with the weight is a template for constructing features of a Markov network and now learning the parameters can be then generatively or discriminatively structure can be then by LP and learning Arbitrary clause is not just horn clauses and some kind of MVP score inference to do MVP inference, we can use a weighted satisfiability solver.",
            "As we shall see later, to do marginal inference efficiently, we can use MCMC.",
            "But with the moves proposed by a SAT solver, which is a lot faster than using something like Gibbs and again we can do partial grounding and we can actually do something else which is lazy inference, which is we actually even among the relevant variables were actually going to only ground some of them because most of them can be left implicit."
        ],
        [
            "And of the various approaches, Markov logic is the most developed one to date in terms of, you know, having all the necessary algorithms and their scalability and so forth and their availability in the open source software and so forth.",
            "It also has the nice feature that we can look at many other approaches as special cases of Markov logic.",
            "Because Markov logic uses the most general probabilistic and logical language, we can actually see how each one of these other languages is a special case of Markov logic and understand what the structure of the of the domain is, and So what I'm going to focus on for the rest of this tutorial is Markov logic.",
            "Many of the algorithms that we will see from Markov logic are applicable to the other representations, and certainly many of the issues are present across representations, but you know we have to pick one to forge ahead.",
            "And and for that I'm going to use Markov logic OK.",
            "So it's at 10:00 AM.",
            "We now have 1/2 hour break and we will start again at 10:30."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is a tutorial on statistical modeling of relational data, and I'm Peter Domingus from the universe.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Washington, so here's what I'm going to do.",
                    "label": 0
                },
                {
                    "sent": "I will begin with a little bit of motivation, and then I will spend some time covering the foundational areas of modeling relational data, namely probabilistic inference, statistical learning, logical inference, and inductive logic programming.",
                    "label": 1
                },
                {
                    "sent": "Of course, I will only do the very briefest overview of each of these, and then I will talk about how we can put the pieces together and finally spend some time on how we can use of these, how we can use the result for.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Lots of interesting and challenging applications, so here's in one slide.",
                    "label": 0
                },
                {
                    "sent": "The basic motivation for this tutorial in this whole area of KDD.",
                    "label": 0
                },
                {
                    "sent": "Most traditional data mining really thinks about a single relation.",
                    "label": 1
                },
                {
                    "sent": "But the data that we mine is almost never in a single relation.",
                    "label": 0
                },
                {
                    "sent": "Usually it's in multiple relations, and often they have very complicated interactions between them and we would like to model these directly, not have to 1st shoehorn them into this form at great expense and effort, and maybe even get results that are not so good.",
                    "label": 0
                },
                {
                    "sent": "So that's one basic motivation.",
                    "label": 0
                },
                {
                    "sent": "There's a number of a number of other ones that are closely related.",
                    "label": 0
                },
                {
                    "sent": "One of them is the following.",
                    "label": 0
                },
                {
                    "sent": "Statistical modeling.",
                    "label": 0
                },
                {
                    "sent": "Usually assumes that the objects that you're modeling are all independent of each other.",
                    "label": 0
                },
                {
                    "sent": "the ID in the, in the jargon, meaning independent and identically distributed, but again in the real world, objects are interdependent.",
                    "label": 0
                },
                {
                    "sent": "Your data is non IID, people influence each other.",
                    "label": 0
                },
                {
                    "sent": "Web pages point to each other.",
                    "label": 0
                },
                {
                    "sent": "You know, things interact, so you can't look at each one of them in isolation.",
                    "label": 0
                },
                {
                    "sent": "We would like to look at all of them together.",
                    "label": 0
                },
                {
                    "sent": "Another one is that we almost always assume that you know the type of data that you're mining is only you know is 1.",
                    "label": 0
                },
                {
                    "sent": "There's only one type of data that you're mining at any given time.",
                    "label": 1
                },
                {
                    "sent": "Most of the time, however, that's not the case.",
                    "label": 1
                },
                {
                    "sent": "We have multiple types of objects.",
                    "label": 0
                },
                {
                    "sent": "We may have even whole hierarchies of classes, and we have multiple types of data, and you know things like text, images, databases, HTML spreadsheets, and often the things that we want to mine are spread across sources of these different types, not just one.",
                    "label": 0
                },
                {
                    "sent": "And we again, we would like to be able to handle all of those together.",
                    "label": 0
                },
                {
                    "sent": "A very closely related issue is that typically in KDD, people assume that the preprocessing has already been done.",
                    "label": 0
                },
                {
                    "sent": "And you know, practice has shown that this is almost always where actually most of the costs of data mining is.",
                    "label": 0
                },
                {
                    "sent": "Because we have to do the preprocessing and that's nontrivial, we have to take all those sources of data we have to extract the information we have to integrate it.",
                    "label": 0
                },
                {
                    "sent": "We have to clean it up.",
                    "label": 0
                },
                {
                    "sent": "And we need to focus on doing these things better because that's actually where the bottleneck is these days.",
                    "label": 0
                },
                {
                    "sent": "And finally, most of data mining today is what you might call knowledge poor.",
                    "label": 0
                },
                {
                    "sent": "We have an algorithm with some very weak ideas embedded in it, and this algorithm runs on some data and hopefully produces some results, but there's a big distance between this and what we would really like to get out of a data mining system, which is the actions that you need to take.",
                    "label": 0
                },
                {
                    "sent": "In order to go from data to actions, we actually need knowledge about the problem, how certain things cause certain things, how certain religions that are maybe not present in data, but necessary for your inference isn't for deciding what actions to take, how these things interact.",
                    "label": 0
                },
                {
                    "sent": "So the way to handle all of these things are at least one way.",
                    "label": 0
                },
                {
                    "sent": "One good way to handle these things is to look directly at modeling multi relational data as multi relational data, and that's what we're going to try to do here.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here's some examples of areas where these issues are important.",
                    "label": 0
                },
                {
                    "sent": "Web search, of course, is a very famous one.",
                    "label": 1
                },
                {
                    "sent": "You get better results when you take into account links between pages, information extraction.",
                    "label": 0
                },
                {
                    "sent": "Very important area in different extractions interact.",
                    "label": 0
                },
                {
                    "sent": "You want to extract entities of different types.",
                    "label": 0
                },
                {
                    "sent": "More generally, natural language processing and perception.",
                    "label": 1
                },
                {
                    "sent": "Here's another nice example.",
                    "label": 0
                },
                {
                    "sent": "Medical diagnosis.",
                    "label": 0
                },
                {
                    "sent": "People do a lot of work on medical diagnosis datasets.",
                    "label": 0
                },
                {
                    "sent": "They always assume that your patients are independent, but we know that this isn't true when there's an epidemic of something you know.",
                    "label": 0
                },
                {
                    "sent": "If somebody has one particular illness, somebody else is actually more likely to have it, and if there's a family, members are the coworkers or you have been in contact with them, they're even more likely, so this is a good example of non eyedness computational biology.",
                    "label": 0
                },
                {
                    "sent": "Another important area where you know every single one of these issues that I mentioned, this present social networks and other very obvious one, and you know very important one these days because computing and so on you know the examples go on and pretty much I think every area.",
                    "label": 0
                },
                {
                    "sent": "Where we do data mining.",
                    "label": 0
                },
                {
                    "sent": "If you look at it carefully you will see that the issues that I listed.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There are present.",
                    "label": 0
                },
                {
                    "sent": "So of course trying to mine multiple relations directly instead of, you know, one simplified data set where there's only one relation has benefits, and it also has cost, so let's keep that in mind.",
                    "label": 0
                },
                {
                    "sent": "Let's see what those benefits and costs are.",
                    "label": 0
                },
                {
                    "sent": "So one obvious benefit is that you potentially get better predictive accuracy.",
                    "label": 1
                },
                {
                    "sent": "When I model objects independently, I'm losing information I don't take into font into account, for example, that the buying preferences of somebody I talked to influence mine, and so I'm less able to predict my buying preferences.",
                    "label": 0
                },
                {
                    "sent": "This is one another one so predictive accuracy in general is one of the big gains of modeling interdependencies between objects and so forth.",
                    "label": 0
                },
                {
                    "sent": "Another one is that we potentially get a better understanding of what's going on when we actually look at the multiple types of entities and relations among them.",
                    "label": 0
                },
                {
                    "sent": "If we force things into this mode of 1 table.",
                    "label": 0
                },
                {
                    "sent": "If we over simplify things, that will necessarily limit the insights that we can get from mining.",
                    "label": 0
                },
                {
                    "sent": "And more generally, I think looking at these issues is the growth path for KDD.",
                    "label": 1
                },
                {
                    "sent": "If we look at where we are or we have been in the past and we would like to be in the future, I think going the way of looking at multiple relations is really one sort of like nice way to grow.",
                    "label": 0
                },
                {
                    "sent": "What are the costs?",
                    "label": 1
                },
                {
                    "sent": "Well, for one learning is going to be much harder now.",
                    "label": 0
                },
                {
                    "sent": "If I have multiple relations, multiple types of objects, interactions among them, I have many more things to model.",
                    "label": 0
                },
                {
                    "sent": "I have many more parameters just going to be harder.",
                    "label": 0
                },
                {
                    "sent": "In fact, this is the main reason why people in the past have made this idea.",
                    "label": 0
                },
                {
                    "sent": "Assumption is that it makes life easy for them.",
                    "label": 0
                },
                {
                    "sent": "And the other another one other related one is this.",
                    "label": 0
                },
                {
                    "sent": "When we do simple things like, say, classification, clustering, Association rule mining, we pretty much can ignore this issue of inference.",
                    "label": 0
                },
                {
                    "sent": "So you classify it, you give it an object, you produce a class label very simple.",
                    "label": 0
                },
                {
                    "sent": "Once we start taking interactions of things into account, inference can no longer be ignored, because now the problem of how you propagate information from one node in this network to another.",
                    "label": 0
                },
                {
                    "sent": "How you actually change these interactions together becomes crucial.",
                    "label": 0
                },
                {
                    "sent": "So now we can no longer ignore the issue of inference, and in fact a good chunk of the time that we're going to be spending here is going to be on this issue.",
                    "label": 0
                },
                {
                    "sent": "And finally, and perhaps most important, there's a price for the user.",
                    "label": 0
                },
                {
                    "sent": "There's a price for the data miner.",
                    "label": 0
                },
                {
                    "sent": "It's harder, it's more complex to actually build models and know what you're doing when you're dealing with this very rich complicated universe with different types, different relations, interactions and whatnot, then it is to deal with a single table.",
                    "label": 0
                },
                {
                    "sent": "So these are the benefits.",
                    "label": 0
                },
                {
                    "sent": "These are the costs that there's been a lot of research in this area, and in recent times, and of course the idea is to try to maximize the benefit.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It's while minimizing the costs so we could state the goal in one sentence, perhaps as follows.",
                    "label": 0
                },
                {
                    "sent": "At the end of the day, we actually like to be able to learn from multiple relations.",
                    "label": 1
                },
                {
                    "sent": "Is easily as today we learn from a single one.",
                    "label": 1
                },
                {
                    "sent": "We want to make the learning and the inference and the user interaction is easy or nearly as easy as nearly so as we can make it as mining from a single relation.",
                    "label": 0
                },
                {
                    "sent": "Now this seems like a very ambitious goal and it is.",
                    "label": 0
                },
                {
                    "sent": "But the good news is there's been a lot of progress in recent years.",
                    "label": 0
                },
                {
                    "sent": "There's you know, there's a whole growing research area known as multi relational data mining, statistical relational learning, structured prediction.",
                    "label": 0
                },
                {
                    "sent": "It goes by a bunch of different names, and I think I would claim that today we're actually close enough to this goal.",
                    "label": 0
                },
                {
                    "sent": "And we have software that's easy to use that's open source, so everybody can use it.",
                    "label": 0
                },
                {
                    "sent": "And you know, this software embodies algorithms and techniques that I think are mature enough to be used even by people who aren't the researchers developing it, and so really the goal of this tutorial is to sort of, like, you know, give people this these.",
                    "label": 0
                },
                {
                    "sent": "At least a survey of these ideas, and then these techniques, and another point to bear in mind, though if you're on the research side as opposed to more, the application side is that first of all all the old research questions and Katie are still present here, plus a lot of interesting new ones.",
                    "label": 0
                },
                {
                    "sent": "So as a field of opportunities for research, this is.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Really quite wonderful, so here's the plan.",
                    "label": 0
                },
                {
                    "sent": "Here's what we're going to do.",
                    "label": 0
                },
                {
                    "sent": "This tutorial we have the elements that we need to solve this larger, more general Kitty problem, namely those elements are the following.",
                    "label": 0
                },
                {
                    "sent": "We have probability for handling the uncertainty.",
                    "label": 1
                },
                {
                    "sent": "That of course is present in all large datasets and in learning.",
                    "label": 0
                },
                {
                    "sent": "We're all familiar with using probability and statistics in data mining.",
                    "label": 0
                },
                {
                    "sent": "Now we also have logic for doing the richer modeling that we want to do here.",
                    "label": 0
                },
                {
                    "sent": "We want to model multiple types.",
                    "label": 0
                },
                {
                    "sent": "We want to model relations who model complex dependencies among objects.",
                    "label": 0
                },
                {
                    "sent": "Logic is a language you know that has existed for a long time and that people in computer science always used to do these kinds of things, and so we can.",
                    "label": 0
                },
                {
                    "sent": "We can.",
                    "label": 0
                },
                {
                    "sent": "We can certainly draw on it here.",
                    "label": 0
                },
                {
                    "sent": "Of course, the problem is going to be to learn to deal with this one.",
                    "label": 0
                },
                {
                    "sent": "We're learning it.",
                    "label": 0
                },
                {
                    "sent": "Then when you know when there's noise and whatnot, which logic per second do.",
                    "label": 1
                },
                {
                    "sent": "And then we have learning and inference algorithms for each of these we have statistical learning algorithms, probabilistic inference algorithms, logical inference, inductive logic, programming, and so we have the pieces from which we can build the solution that we need.",
                    "label": 0
                },
                {
                    "sent": "We actually don't have to start from scratch, and So what we're going to do is.",
                    "label": 0
                },
                {
                    "sent": "First of all, we're going over these pieces and then we're going to figure out how to put them together.",
                    "label": 1
                },
                {
                    "sent": "And perhaps surprisingly, it turns out to not be that hard to put them together in a way that actually works and is not too complex.",
                    "label": 0
                },
                {
                    "sent": "And in fact, you know of the three parts of that role.",
                    "label": 0
                },
                {
                    "sent": "This is actually going to be the shortest.",
                    "label": 1
                },
                {
                    "sent": "And then once we've, you know invested our effort into getting up to speed on this and figuring out how to do this.",
                    "label": 0
                },
                {
                    "sent": "Then we get the payoff.",
                    "label": 0
                },
                {
                    "sent": "The proof is that on a wide range of applications that people care about, we're going to get huge leverage from actually not being able to do things at this more powerful level.",
                    "label": 0
                },
                {
                    "sent": "And so the last part of the tutorial, naturally, the largest one, is going to be sort of like very practically minded, you know, look at how we can.",
                    "label": 0
                },
                {
                    "sent": "Do, you know, a bunch of different applications.",
                    "label": 0
                },
                {
                    "sent": "And of course, again, I'm only going to cover a small.",
                    "label": 0
                },
                {
                    "sent": "Say.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Ample of what can be done, but hopefully that will give people the general idea.",
                    "label": 0
                },
                {
                    "sent": "So before we get into the meat of things, let me start with a couple of disclaimers.",
                    "label": 0
                },
                {
                    "sent": "First of all, what I'm going to do here is not a complete survey of multi relational data mining.",
                    "label": 0
                },
                {
                    "sent": "I will not mention many things that maybe deserve to be mentioned, but time is short.",
                    "label": 0
                },
                {
                    "sent": "It's also of course, not a complete survey of the foundational areas.",
                    "label": 1
                },
                {
                    "sent": "I really only have time to touch on a few essentials.",
                    "label": 0
                },
                {
                    "sent": "In each one of them, but the satisfying thing is that even with just those few essentials, that's actually going to be enough for our purposes.",
                    "label": 1
                },
                {
                    "sent": "The focus of this is mainly practical, not theoretical.",
                    "label": 0
                },
                {
                    "sent": "There's a lot of theories you know, backing up a lot of of what I'm going to do here, but I'm actually not going to delve into that.",
                    "label": 0
                },
                {
                    "sent": "I'm going to focus more on the applications.",
                    "label": 0
                },
                {
                    "sent": "Because I think these days it's really more what we need.",
                    "label": 0
                },
                {
                    "sent": "I'm going to assume some basic background knowledge in logic, probability and statistics etc.",
                    "label": 1
                },
                {
                    "sent": "Not much, but certainly more than nothing.",
                    "label": 0
                },
                {
                    "sent": "Please ask questions if at anytime there's something that's not clear.",
                    "label": 0
                },
                {
                    "sent": "Do ask questions and finally this tutorial.",
                    "label": 0
                },
                {
                    "sent": "All the examples that I'm going to show here.",
                    "label": 0
                },
                {
                    "sent": "The code, the datasets, a text version of the tutorial.",
                    "label": 0
                },
                {
                    "sent": "These are all available at this website alchemy.cs.washington.edu and I will put up this URL again more towards the.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so let's get started.",
                    "label": 0
                },
                {
                    "sent": "Let's look at the founder.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Larry's first of all, let's look at probabilistic inference, and most people have probably heard of vision networks.",
                    "label": 0
                },
                {
                    "sent": "I'm actually going to focus on something slightly different, which is Markov networks, which probably people are not as familiar with, But actually turns out to be as important or even more so for multi relational data mining vision networks.",
                    "label": 0
                },
                {
                    "sent": "So what is a Markov network?",
                    "label": 0
                },
                {
                    "sent": "A Markov network like a vision network is a model like graphical model of the joint distribution of a set of variables.",
                    "label": 0
                },
                {
                    "sent": "So here's an example smoking cancer, asthma cough.",
                    "label": 0
                },
                {
                    "sent": "I'm going to assume that all Boolean.",
                    "label": 0
                },
                {
                    "sent": "And it's a graphical model, so one part of the model is a graph.",
                    "label": 0
                },
                {
                    "sent": "But unlike Envision Networks, it's an undirected graph, meaning there are no errors on the edges.",
                    "label": 0
                },
                {
                    "sent": "And what this graph means is that a variable is independent of the rest of the network given its immediate neighbors.",
                    "label": 0
                },
                {
                    "sent": "So for example, cough is independent of smoking given cancer and asthma.",
                    "label": 0
                },
                {
                    "sent": "OK, so the graph tells us what the independent structure of the domain is, and this is actually simpler than Bayes Nets, because in business breathing off independence is kind of complicated.",
                    "label": 0
                },
                {
                    "sent": "Here it's very simple if when I take out a bunch of variables to others become disconnected, then they're independently conditionally independent.",
                    "label": 0
                },
                {
                    "sent": "Given the ones that I removed.",
                    "label": 0
                },
                {
                    "sent": "So graph separation is all that's needed here, so this gives us the structure of the model.",
                    "label": 0
                },
                {
                    "sent": "The parameters are given by what's called potential functions.",
                    "label": 0
                },
                {
                    "sent": "Potential functions are defined over the clicks of the graph, so here, for example, there's a potential functions for the smoking cancer click click being a completely connected sub graph, and there's a potential function for the cancer asthma, cough click and potential functions can have arbitrary non negative real values.",
                    "label": 1
                },
                {
                    "sent": "For example, here's for the Smoking Cancer click.",
                    "label": 0
                },
                {
                    "sent": "There's two Boolean variables, so there's four States and I've assigned the value of the potential function to each one of them and intuitive meaning of a potential function.",
                    "label": 0
                },
                {
                    "sent": "Is that higher values.",
                    "label": 0
                },
                {
                    "sent": "Of the potential function correspond to states of the world that the world prefers that are more likely.",
                    "label": 0
                },
                {
                    "sent": "So for example.",
                    "label": 0
                },
                {
                    "sent": "This state is more likely than this state.",
                    "label": 0
                },
                {
                    "sent": "And what this is capturing is that smoking causes cancer.",
                    "label": 0
                },
                {
                    "sent": "So smoking causes cancer.",
                    "label": 0
                },
                {
                    "sent": "You're less, you know.",
                    "label": 0
                },
                {
                    "sent": "If it's less likely that your smoke that you smoke and don't have cancer, then it is that you smoke and have cancer or don't smoke at all, OK?",
                    "label": 0
                },
                {
                    "sent": "Now to compute the probability of a state.",
                    "label": 0
                },
                {
                    "sent": "All that I have to do is is go to each, go to each click, read off the value of its potential function corresponding to the state that it's in, and multiply them altogether.",
                    "label": 0
                },
                {
                    "sent": "And that gives me my probability up to normalization constant.",
                    "label": 0
                },
                {
                    "sent": "Which I have to divide by in order to make sure that these things all add up to one and that normalization constant is simply the sum of the of this product for all possible states.",
                    "label": 0
                },
                {
                    "sent": "So this is very nice because it's very flexible.",
                    "label": 0
                },
                {
                    "sent": "You can model just about anything.",
                    "label": 0
                },
                {
                    "sent": "In this way you can put any knowledge that you want into this, but there's a very big problem lurking here, which is that it doesn't scale.",
                    "label": 0
                },
                {
                    "sent": "The reason this doesn't scale is that if I need the value of the potential function for each state of the clique, I can only have small cliques.",
                    "label": 0
                },
                {
                    "sent": "A click of size two or three is fine, but a clique of size 10 is going to have too many states.",
                    "label": 0
                },
                {
                    "sent": "It's going to be impossible to store.",
                    "label": 0
                },
                {
                    "sent": "It's going to be hard to reason with.",
                    "label": 0
                },
                {
                    "sent": "It's going to be very hard to learn.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Parameters Fortunately, we have another alternative, which is what's called a log linear form or log linear model.",
                    "label": 0
                },
                {
                    "sent": "In a log linear model, instead of representing my probability as a product of factors, I'm going to represent it as an exponentiated sum of weighted features, and you can always convert 1 to the other.",
                    "label": 0
                },
                {
                    "sent": "I take a product, I take it's log and I have and I have a son in the exponent and that's what I have here.",
                    "label": 0
                },
                {
                    "sent": "So so.",
                    "label": 0
                },
                {
                    "sent": "In the simplest case, I can just take the potential function and convert each of each states into a feature.",
                    "label": 0
                },
                {
                    "sent": "So for example, one feature would be smoking is false and cancer is false, and then I and then its weight is the log of the corresponding value of the potential function, right?",
                    "label": 0
                },
                {
                    "sent": "So I can always go from one to the other, but where I've gained something is that I don't necessarily need to have one feature for every possible state of the click.",
                    "label": 0
                },
                {
                    "sent": "I could have a click with a very large number of states if I know that there's only 10 important, say 10 important features of that click, I can just compute those, assign weights to them, and now what I've done is that now I have a very compact representation.",
                    "label": 0
                },
                {
                    "sent": "For example, here's a very simple feature of smoking and cancer.",
                    "label": 0
                },
                {
                    "sent": "It's one if you don't smoke or have cancer, and it's 0 otherwise.",
                    "label": 0
                },
                {
                    "sent": "And if I assign it a weight of 1.5, this actually implements this potential function that I had here before.",
                    "label": 0
                },
                {
                    "sent": "OK, of course in this case it's not very impressive because the table was small to start with, but if I have a large click and we're going to want to model things with potentially very large clicks, this can make all the difference, and we're going to be leveraging it.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Pensively as you'll see.",
                    "label": 0
                },
                {
                    "sent": "So how do Markov networks compare with vision networks?",
                    "label": 0
                },
                {
                    "sent": "Here's a very quick summary.",
                    "label": 0
                },
                {
                    "sent": "So the form of both of them is a product of potentials.",
                    "label": 0
                },
                {
                    "sent": "So Markov networks and vision that was actually very similar in many ways.",
                    "label": 0
                },
                {
                    "sent": "Mathematically, they have almost the same form.",
                    "label": 0
                },
                {
                    "sent": "The big difference is that in Markov networks the potentials can be arbitrary in the Bayes Nets the potentials have to be conditional probabilities.",
                    "label": 0
                },
                {
                    "sent": "In Markov networks we can have cycles, not a problem.",
                    "label": 0
                },
                {
                    "sent": "This is going to be very very useful for us in vision.",
                    "label": 0
                },
                {
                    "sent": "Network cycles are forbidden if you have a vision network with direct excited that you actually doesn't represent anything, so you have to worry about not creating them when you learn from data.",
                    "label": 0
                },
                {
                    "sent": "In Markov networks, the partition function, meaning that normalization constant that I saw before is arbitrary envision networks, very conveniently it's equal to 1, so we never have to worry about it, and this is a significant advantage of vision networks.",
                    "label": 0
                },
                {
                    "sent": "In fact, if we say let's take a product of potentials representation and impose that the potential function is to be one.",
                    "label": 0
                },
                {
                    "sent": "Essentially what you get out is a vision network.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is one advantage of vision networks.",
                    "label": 0
                },
                {
                    "sent": "Now, how do we check independency Markov networks?",
                    "label": 0
                },
                {
                    "sent": "It's just graph separation as I mentioned in Bayes Nets.",
                    "label": 1
                },
                {
                    "sent": "It's this much more complicated.",
                    "label": 0
                },
                {
                    "sent": "And called this separation.",
                    "label": 0
                },
                {
                    "sent": "So in terms of an interface for the user based networks are actually kind of harder to deal with than Markov networks are.",
                    "label": 0
                },
                {
                    "sent": "Now, one thing that it's important to realize is that if you look at the graphs of vision networks and Markov networks.",
                    "label": 0
                },
                {
                    "sent": "There are some things that you can some independence relations that you can represent compact cleaner Markov network, but not in a vision network, and vice versa, so neither one dominates in that respect.",
                    "label": 0
                },
                {
                    "sent": "But the important thing to bear in mind is that the log linear form applies to both, so if something is a compact base net, it'll it'll be a compact log linear form and something for a Markov network.",
                    "label": 0
                },
                {
                    "sent": "So as long as we're using this log linear form in terms of compactness were always OK. How do we do inference in Markov networks?",
                    "label": 0
                },
                {
                    "sent": "We can use as we shall see shortly.",
                    "label": 0
                },
                {
                    "sent": "Algorithms like Markov chain, Monte Carlo, belief propagation and so on.",
                    "label": 0
                },
                {
                    "sent": "Envision networks.",
                    "label": 0
                },
                {
                    "sent": "What we usually do for inference is first we convert them to Markov networks and then we do the inference on Markov networks.",
                    "label": 0
                },
                {
                    "sent": "So in some sense, Markov networks are the more fundamental notion.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how do we do inference in Markov networks?",
                    "label": 1
                },
                {
                    "sent": "Well, typically what we so the Markov network is a model of the full joint distribution of a set of variables, and then typically the questions that we want to answer are things like what is the conditional probability of some variable given some others?",
                    "label": 0
                },
                {
                    "sent": "What is the marginal distribution of some subset of the variables?",
                    "label": 0
                },
                {
                    "sent": "And here's the expression that we want to do this over.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately, doing doing this inference exactly is a very hard problem.",
                    "label": 0
                },
                {
                    "sent": "It's sharply complete, which means it's even worse than NP hard.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "However, there's something that's actually very easy, which is the condition, or it's called the Markov blanket of a variable.",
                    "label": 0
                },
                {
                    "sent": "The Markov blanket of a variable in the Markov network is just its neighbors in the graph, and it's easy to see that the distribution of a variable given its neighbors in the graph is actually can be computed directly.",
                    "label": 0
                },
                {
                    "sent": "It's a simple expression.",
                    "label": 0
                },
                {
                    "sent": "All the clicks that don't involve that variable disappear, things cancel out, and so this can be done quite efficiently, and So what we're going to see is an algorithm for inference that exploits this.",
                    "label": 0
                },
                {
                    "sent": "The algorithm is called Gibbs sampling.",
                    "label": 0
                },
                {
                    "sent": "It's probably one of the most widely used algorithms in the universe.",
                    "label": 0
                },
                {
                    "sent": "There was a survey of like that, I think by IEEE computer a few years ago.",
                    "label": 0
                },
                {
                    "sent": "Of what the most important you know algorithms were, and this actually came out on top 'cause it's used throughout science and technologies to do inference on complicated probabilistic.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And it's more general Markov chain Monte Carlo, of which Gibbs sampling is an example an it's a joyfully simple algorithm for what its power.",
                    "label": 0
                },
                {
                    "sent": "So it's well worth knowing.",
                    "label": 0
                },
                {
                    "sent": "So how does Gibbs sampling work?",
                    "label": 1
                },
                {
                    "sent": "It works like this.",
                    "label": 0
                },
                {
                    "sent": "I start out by assigning random truth values to all my variables.",
                    "label": 0
                },
                {
                    "sent": "I'm focusing on the Boolean case here.",
                    "label": 0
                },
                {
                    "sent": "And then I do the following.",
                    "label": 0
                },
                {
                    "sent": "I repeatedly go to a variable and re sample its value given its neighbors.",
                    "label": 0
                },
                {
                    "sent": "Right, so I have it's conditional distribution given its neighbors, and I've taken you sample of its value.",
                    "label": 0
                },
                {
                    "sent": "I have a new state and I just do this for a long time.",
                    "label": 0
                },
                {
                    "sent": "Some maximal cycles or until some convergence criterion is met, and then I just estimate my probabilities of interest as the fraction of states in which the event that I'm asking about health.",
                    "label": 1
                },
                {
                    "sent": "Like you know, what is the probability that this person has?",
                    "label": 0
                },
                {
                    "sent": "You know disease X?",
                    "label": 0
                },
                {
                    "sent": "Well, I sample a whole bunch of States and if you know if in those states 80% of them the person has this is X, then I said that probably is .8 and this is really a Gibbs sampling.",
                    "label": 0
                },
                {
                    "sent": "It's a very simple algorithm, but.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It's also very general.",
                    "label": 0
                },
                {
                    "sent": "There are other inference methods that are worth knowing about.",
                    "label": 1
                },
                {
                    "sent": "Gibbs sampling in truth is actually probably overused.",
                    "label": 0
                },
                {
                    "sent": "It's used even when it's not probably the best thing to have.",
                    "label": 1
                },
                {
                    "sent": "So there are many, many variations of Markov chain Monte Carlo, so Gibbs sampling is just the best non representative this class.",
                    "label": 0
                },
                {
                    "sent": "But there are many others.",
                    "label": 0
                },
                {
                    "sent": "There's also a newer class of algorithms called belief propagation that is becoming quite popular, in particular for this type of problem we use what's called the sum product version of belief propagation, because what we're actually doing is we're doing sums of products to compute probabilities.",
                    "label": 0
                },
                {
                    "sent": "There's also variational approximations, and there's also a very large literature on exact methods.",
                    "label": 0
                },
                {
                    "sent": "Gibbs sampling on all these other methods are approximate, right?",
                    "label": 0
                },
                {
                    "sent": "They give an approximate answer with more time.",
                    "label": 0
                },
                {
                    "sent": "They will give you a better answer.",
                    "label": 0
                },
                {
                    "sent": "There's also exact methods.",
                    "label": 0
                },
                {
                    "sent": "However, exact methods did not work on the large problems that we're interested in here, so we're not going to focus on that much, but there's certain.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A lot of you know there's a big literature on that, so the other main type of inference that we often want to want to do is what's called MA P for maximum posteriori or MPE.",
                    "label": 0
                },
                {
                    "sent": "For most probable explanation inference.",
                    "label": 0
                },
                {
                    "sent": "And the goal here is, given some evidence X.",
                    "label": 0
                },
                {
                    "sent": "So these are the values of some variables.",
                    "label": 0
                },
                {
                    "sent": "I want to find the most likely state of the world.",
                    "label": 1
                },
                {
                    "sent": "I I have some other variables why the query?",
                    "label": 0
                },
                {
                    "sent": "And I want to find the values of the query variables that are most likely given the evidence for those who.",
                    "label": 0
                },
                {
                    "sent": "Are you familiar with things like hidden Markov models?",
                    "label": 0
                },
                {
                    "sent": "This is what the Viterbi algorithm is doing, so we're looking for the most likely joint set of the variables.",
                    "label": 0
                },
                {
                    "sent": "In some ways this is simpler than computing probabilities, but in some way it's actually alot alot.",
                    "label": 0
                },
                {
                    "sent": "Alot more subtle because now what we're doing is we want to find the jointly most likely state which is not necessarily just the most likely state of each of the variables in isolation.",
                    "label": 0
                },
                {
                    "sent": "So for this.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Of inference.",
                    "label": 0
                },
                {
                    "sent": "What kind of algorithms do we have?",
                    "label": 0
                },
                {
                    "sent": "The Classical one is called iterated conditional modes and it's very simple.",
                    "label": 1
                },
                {
                    "sent": "It's just greedy search.",
                    "label": 0
                },
                {
                    "sent": "You go to each variable in turn and you set it to the most likely value of that variable given its neighbors.",
                    "label": 0
                },
                {
                    "sent": "It's conditional mode and you just keep doing that until you bump into local minimum.",
                    "label": 0
                },
                {
                    "sent": "It's a little bit like the MLP inference analog of Gibbs sampling.",
                    "label": 0
                },
                {
                    "sent": "The advantage of this is that it's fast.",
                    "label": 0
                },
                {
                    "sent": "The disadvantage of course is that it will get stuck in local Optima.",
                    "label": 0
                },
                {
                    "sent": "To avoid that, we can use simulated annealing, where sometimes it takes some random.",
                    "label": 0
                },
                {
                    "sent": "Down steps instead of up steps and simulated annealing if you give it enough time and you do right will actually give you the global optimum, but it could take a very long time.",
                    "label": 0
                },
                {
                    "sent": "Similar the new link is very widely used, but it's also very slow.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's the good and the bad of it.",
                    "label": 0
                },
                {
                    "sent": "More recently there's this class of algorithms that are based on converting the inference problem to problem of finding a min cut in a graph.",
                    "label": 0
                },
                {
                    "sent": "They don't always aren't always applicable when they are, they can actually be really good.",
                    "label": 1
                },
                {
                    "sent": "And then there's also belief propagation.",
                    "label": 0
                },
                {
                    "sent": "Belief propagation is pretty much the same algorithm that we saw before, except that instead of some product now we do Max product because what we're doing is we're taking maximums of products OK.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "These are some of the other MLP inference algorithms that are available.",
                    "label": 0
                },
                {
                    "sent": "Let us now look at how we can learn these kinds of models from data.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "K. So we're going to look at two things.",
                    "label": 0
                },
                {
                    "sent": "As usual, learning parameters, meaning the weights and learning structure, meaning the features.",
                    "label": 1
                },
                {
                    "sent": "And we're going to look at how parameters could be learned generatively or discriminatively, and in this tutorial I'm going to assume that we have complete data.",
                    "label": 1
                },
                {
                    "sent": "IE, there's no data.",
                    "label": 0
                },
                {
                    "sent": "There are no missing values in general.",
                    "label": 0
                },
                {
                    "sent": "Of course we could have missing values, in which case we need to use M versions of the algorithms that I'm going to describe here, and they're available in the software that will mention later, But here for brevity I'm going.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm going to ignore that issue, so how can we learn weights well?",
                    "label": 0
                },
                {
                    "sent": "The standard Classical way is generative learning, where or just maximum likelihood or Bayesian learning.",
                    "label": 1
                },
                {
                    "sent": "So what we do in maximum likelihood learning is we try to find the values of the weights that make the data that we've seen as likely as possible, and unfortunately for Markov networks there is no closed form for the weights.",
                    "label": 0
                },
                {
                    "sent": "You actually have to do the numerical optimization.",
                    "label": 1
                },
                {
                    "sent": "The good news is that there are no local maximum.",
                    "label": 0
                },
                {
                    "sent": "It's a convex problem.",
                    "label": 0
                },
                {
                    "sent": "So there's a single global optimum, and you're guaranteed to find it.",
                    "label": 0
                },
                {
                    "sent": "You know you don't have to worry about getting stuck in local Optima and to do the numerical optimization there are many.",
                    "label": 0
                },
                {
                    "sent": "You know there's of course gradient descent, and then there's also many more sophisticated, faster methods that use 2nd order information that use the Hessian matrix of a second order derivatives.",
                    "label": 0
                },
                {
                    "sent": "And so how do we do this?",
                    "label": 0
                },
                {
                    "sent": "We we take the expression for the probability that we saw before we take it's log.",
                    "label": 0
                },
                {
                    "sent": "We differentiated with respect to each weight and that gives us the gradient and the great and tell us which is actually we should go in an.",
                    "label": 0
                },
                {
                    "sent": "This derivative actually has a very intuitive form.",
                    "label": 0
                },
                {
                    "sent": "Which, like you know easy.",
                    "label": 0
                },
                {
                    "sent": "It's helpful for understanding what goes on, so here's what it is.",
                    "label": 0
                },
                {
                    "sent": "The derivative of the log likelihood with respect to the weight of some feature.",
                    "label": 0
                },
                {
                    "sent": "If you do, the math just turns out to be the following.",
                    "label": 0
                },
                {
                    "sent": "It's the difference between the number of times that the feature is true in the data and the number of times that the model predicts that the feature is true.",
                    "label": 1
                },
                {
                    "sent": "OK, so if the model is predicting the future is true less often than it really is, it's weight needs to go up.",
                    "label": 0
                },
                {
                    "sent": "You know, in the opposite case it needs to go down, and when the predictive and true and true counts lineup for all the features you know, we've reached their optimum and we're done learning.",
                    "label": 0
                },
                {
                    "sent": "We've matched the data perfectly.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's the idea.",
                    "label": 0
                },
                {
                    "sent": "There's there's there's a snag here though.",
                    "label": 0
                },
                {
                    "sent": "The snag is that to compute this term, we need to do inference.",
                    "label": 0
                },
                {
                    "sent": "This is computing an expectation over Markov network, so this could again this gets us back to that Sharpie hard problem.",
                    "label": 0
                },
                {
                    "sent": "And now when we do this.",
                    "label": 1
                },
                {
                    "sent": "Repeatedly, at each step of our gradient descent or or other optimization procedures, things could get very very slow.",
                    "label": 0
                },
                {
                    "sent": "OK, so we need something more efficient.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What can we do?",
                    "label": 0
                },
                {
                    "sent": "Well, a fairly old idea that is still very popular is pseudo likelihood.",
                    "label": 0
                },
                {
                    "sent": "And now you see the likelihood is the following is if optimizing likelihood is too hard.",
                    "label": 0
                },
                {
                    "sent": "Let's optimize something easier instead and hope that it still gives good results.",
                    "label": 0
                },
                {
                    "sent": "And the idea is actually fiendishly clever.",
                    "label": 0
                },
                {
                    "sent": "Pseudo likelihood is just the product overall variables of the probability of the variable given the state of its neighbors in the data.",
                    "label": 1
                },
                {
                    "sent": "OK, so this is easy to compute for the same reason that Gibbs sampling have easy time computing the conditional probabilities right?",
                    "label": 0
                },
                {
                    "sent": "This is it's just a simple expression, no inference is required.",
                    "label": 0
                },
                {
                    "sent": "And there is one important property which the likelihood has, which is that it's a consistent estimator.",
                    "label": 0
                },
                {
                    "sent": "So, given you know, given enough data it will converge to the true values of, it'll produce the model that gives you the true values of all these conditional probabilities.",
                    "label": 0
                },
                {
                    "sent": "And you know when you combine, combine this with with a fast optimization method.",
                    "label": 0
                },
                {
                    "sent": "You actually get learning that there is quite scalable.",
                    "label": 1
                },
                {
                    "sent": "It's widely used in, feels like vision, special statistics, natural language processing, social network modeling, etc.",
                    "label": 0
                },
                {
                    "sent": "The important thing to keep in mind though is this is that sometimes it works and sometimes it doesn't went through the likelihood works, it's great when it, when it fails it can fail pretty badly.",
                    "label": 0
                },
                {
                    "sent": "When and why the pseudo likelihood fail.",
                    "label": 0
                },
                {
                    "sent": "Well, the problem with pseudo likelihood is that it's focused on optimizing short range interactions.",
                    "label": 0
                },
                {
                    "sent": "That's how it knows about.",
                    "label": 0
                },
                {
                    "sent": "So if your inference time, you're going to look at long chains of inference pseudo likelihood.",
                    "label": 0
                },
                {
                    "sent": "You know really didn't optimize your model for that and you could get terrible results, so the likelihood this conditioning on the known states of your neighbors, so it tends to be too confident of them.",
                    "label": 0
                },
                {
                    "sent": "It tends to overweight the nearby information at the expense of you know your neighbors that, for example, the information that you know about your object itself.",
                    "label": 0
                },
                {
                    "sent": "So likelihood is good in some ways, but it's prob.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Matic, in others.",
                    "label": 0
                },
                {
                    "sent": "So what else can we do?",
                    "label": 0
                },
                {
                    "sent": "We can do discriminative learning.",
                    "label": 0
                },
                {
                    "sent": "Discriminative learning is actually often a very good idea in its own right, and you know, I mean these days people pretty much almost always do discriminative instead of generative learning.",
                    "label": 0
                },
                {
                    "sent": "Just because it gives better results.",
                    "label": 0
                },
                {
                    "sent": "And the reason it gives better results is that it's actually trying to optimize the right thing most of the time.",
                    "label": 0
                },
                {
                    "sent": "So what is the right thing?",
                    "label": 0
                },
                {
                    "sent": "What we do in discriminative learning is that instead of maximizing the joint distribution of all the variables, what I'm going to do is I'm going to maximize the conditional likelihood of the query variables given the evidence variables.",
                    "label": 0
                },
                {
                    "sent": "Of course, this requires knowing at learning time who's going to be Korean, who's going to be evidence, but most of the time we do know that, so we can you know.",
                    "label": 0
                },
                {
                    "sent": "So in some sense, it would be silly not to use that information and then by optimizing this right, we're actually not going to waste any modeling effort trying to model model interactions between variables that we actually don't care about.",
                    "label": 0
                },
                {
                    "sent": "And that could actually make us do the wrong thing, because you know, I could make a change.",
                    "label": 0
                },
                {
                    "sent": "That improves the modeling of the things that I don't care, but at the expense of making you know, the modeling of Y given X worse.",
                    "label": 0
                },
                {
                    "sent": "So This is why this tends to give better results, and you know the expression that we get is pretty much the same, except that now what we have is PY given X instead of just the joint distribution of all the variables, and I can ignore all the clicks that only involve variables in X because at inference time I'm going to know those, but the difference is that now I have another way to deal with this problematic term here, which is the following.",
                    "label": 0
                },
                {
                    "sent": "Instead of computing this expectation over all possible sets of Y given X, what I can do is I can just look for the single most likely state of Y given X, do the counts in those and let them be an approximation for the Council for everybody.",
                    "label": 1
                },
                {
                    "sent": "The reason this works is that these distributions can have all sorts of peaks all over the place, but as I condition on more and more information on the Exide most of those peaks will disappear and in the limit that should have all of my mass concentrated in one peak.",
                    "label": 0
                },
                {
                    "sent": "So if I just use that peak as my approximation, in many cases, that's actually a good enough approximation.",
                    "label": 0
                },
                {
                    "sent": "And remember, we're just learning here from noisy data, so it's not like I really care about getting exactly the right thing.",
                    "label": 0
                },
                {
                    "sent": "So this is a very simple idea, but it can actually.",
                    "label": 0
                },
                {
                    "sent": "I mean it can make life way easier for us because now instead of computing an exponential, assume with an exponential number of terms.",
                    "label": 0
                },
                {
                    "sent": "I'm just doing a maximization which can be a lot faster.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So there's a couple of other approaches to it.",
                    "label": 0
                },
                {
                    "sent": "Learning that are worth knowing about the classical approach for learning, which in this model is something called iterative scaling.",
                    "label": 1
                },
                {
                    "sent": "It's not used a lot these days because it's quite slow.",
                    "label": 0
                },
                {
                    "sent": "A very recent method is Max margin approach is maximized and approaches are the extension to Markov networks of the ideas of support vector machines and so far they've only been used for restrictive types of structures, but it's a method with with a lot of.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Promise.",
                    "label": 0
                },
                {
                    "sent": "So what about structure learning?",
                    "label": 1
                },
                {
                    "sent": "Suppose I don't just want to learn the weights, I actually want to lend a structure of the model, i.e.",
                    "label": 0
                },
                {
                    "sent": "In a log linear model, I want to figure out what the features are, not just what the weights should be.",
                    "label": 0
                },
                {
                    "sent": "Well, we can think of doing sort of like a greedy search approach to this right?",
                    "label": 0
                },
                {
                    "sent": "I start with atomic features, meaning the variables themselves.",
                    "label": 1
                },
                {
                    "sent": "And then I Gridley try conjoining each feature with each Atom an I evaluate them according to likelihood or posterior or something.",
                    "label": 0
                },
                {
                    "sent": "I pick the best ones and I keep going.",
                    "label": 0
                },
                {
                    "sent": "So this this is a reasonable method to use, there is a problem with it, though the problem is that when I try a new candidate feature.",
                    "label": 0
                },
                {
                    "sent": "In order to evaluate it, I now need to potentially recompute all the weights because the features interact with each other.",
                    "label": 1
                },
                {
                    "sent": "So for each candidate I need to do a weight optimization.",
                    "label": 0
                },
                {
                    "sent": "Optimal weight optimization takes some time, even if it takes a few minutes.",
                    "label": 0
                },
                {
                    "sent": "If I'm going to try millions of combinations, that's going to be infeasible.",
                    "label": 0
                },
                {
                    "sent": "So we need something some way to overcome this problem.",
                    "label": 0
                },
                {
                    "sent": "What people have typically done and you know, it's a reasonable thing to do, is to assume that when I create a new feature, the weights of the previous features stay constant.",
                    "label": 0
                },
                {
                    "sent": "So now the only thing I have to compute is the weight for this new feature.",
                    "label": 0
                },
                {
                    "sent": "And that can be done fast.",
                    "label": 0
                },
                {
                    "sent": "In some cases it can be done in closed form and then maybe once I've selected the feature.",
                    "label": 0
                },
                {
                    "sent": "Now I can do the optimization for everybody again, so again this is an approximation.",
                    "label": 0
                },
                {
                    "sent": "Sometimes it's OK, sometimes it doesn't give such good results, but it's what people have done OK.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so let's talk a little bit about logical inference.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So first order logic is a very rich language that pretty much allows us to say all the kinds of things that we're going to want to say here.",
                    "label": 0
                },
                {
                    "sent": "Formulas in first order logic, I will tap out of four types of symbols, constants representing objects in the domain, like Anna variables like X, that range over the objects in the domain, functions that take a tuple of objects as input and produce an object as output, like say mother of X and predicates that represent properties of objects.",
                    "label": 0
                },
                {
                    "sent": "Or relations between objects, like for example friends XY represents whether X&Y are friends or not.",
                    "label": 0
                },
                {
                    "sent": "OK, and I'm going to call a literal a predicate or its negation.",
                    "label": 1
                },
                {
                    "sent": "So for example, friends are not friends and a clause is a disjunction of literals.",
                    "label": 0
                },
                {
                    "sent": "For example, mother of X are not friends XY.",
                    "label": 0
                },
                {
                    "sent": "And I need to call a grounding of a predicate or formula.",
                    "label": 0
                },
                {
                    "sent": "What we obtain when we replace all the variables by constants.",
                    "label": 1
                },
                {
                    "sent": "For example, if one of the predicates in my domain is friends XY and two of the constants are N and Bob.",
                    "label": 0
                },
                {
                    "sent": "One possible grounding is friend Cinnabon.",
                    "label": 0
                },
                {
                    "sent": "OK and friends and above is just a Boolean variable that is true if N and Bob are friends and false otherwise, and I'm going to call a world also known as model or interpretation and assignment of truth values to all the ground predicates.",
                    "label": 1
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So at the end of the day I forum all groundings of all predicates with all constants.",
                    "label": 0
                },
                {
                    "sent": "I have a very large Boolean vector and this is the state of my world.",
                    "label": 0
                },
                {
                    "sent": "And the thing that we're going to be worried about here is probability distributions over such states of the world.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So how do we do inference in first or logical?",
                    "label": 0
                },
                {
                    "sent": "Traditionally this was done by theorem proving.",
                    "label": 1
                },
                {
                    "sent": "That's for example, what Prolog does in more in recent years.",
                    "label": 0
                },
                {
                    "sent": "However, people have found that perhaps surprisingly, it's often a lot more efficient to do propositional isation, which is you ground out the whole knowledge base, followed by model checking.",
                    "label": 1
                },
                {
                    "sent": "Are you running a satisfiability solver?",
                    "label": 0
                },
                {
                    "sent": "And there's two main approaches to satisfiability.",
                    "label": 1
                },
                {
                    "sent": "One of them is backtracking, exemplified by the deep algorithm.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to cover that here due to time limitations.",
                    "label": 0
                },
                {
                    "sent": "The other one is stochastic local search exemplified by walk set, which I will cover here.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, so what's the basic?",
                    "label": 0
                },
                {
                    "sent": "Let me let me lay out the problem of satisfiability.",
                    "label": 0
                },
                {
                    "sent": "So this is what we're going to use to do inference.",
                    "label": 0
                },
                {
                    "sent": "We have an input that's a set of clauses.",
                    "label": 0
                },
                {
                    "sent": "And remember, we can always convert the knowledge base to a set of clauses, IE to conjunctive normal form or CNF.",
                    "label": 1
                },
                {
                    "sent": "And the output is either the truth assignment that satisfies all the clauses or failure.",
                    "label": 1
                },
                {
                    "sent": "So we want to get one of those two things out.",
                    "label": 0
                },
                {
                    "sent": "Satisfiability, of course is the paradigmatic NP complete problem.",
                    "label": 0
                },
                {
                    "sent": "You can reduce all of this to it.",
                    "label": 0
                },
                {
                    "sent": "Since of course this is intractable and less equals NP, the solution is to do some kind of search.",
                    "label": 0
                },
                {
                    "sent": "The key point to realize that is something that you know during the first several decades of this problem, which of course people in many years of computer science look at didn't realize is that even though in the worst case, satisfiability is hard, in most cases it's actually easy, and this is going to bias, you know, no end of efficiencies.",
                    "label": 0
                },
                {
                    "sent": "The reason most at most satisfiability problems are actually easy is that there's only a narrow region of problem space where they're hard.",
                    "label": 0
                },
                {
                    "sent": "And the intuition is this.",
                    "label": 0
                },
                {
                    "sent": "Think of the clauses constraints on the variables.",
                    "label": 0
                },
                {
                    "sent": "If I have a lot of variables and very few clauses, the problem is underconstrained, then it's easy to find the solution rapidly.",
                    "label": 0
                },
                {
                    "sent": "On the other side, if I have a lot of clauses on a few variables, then the problem is over constrained and it's easy to realize quickly that there's going to be no solution.",
                    "label": 0
                },
                {
                    "sent": "The only hard region is going to be in a narrow range of the ratio of clauses to variables where you really have to look at the details to make to figure out whether you can solve the problem or not.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how does the Catholic local search work?",
                    "label": 1
                },
                {
                    "sent": "It's quite simple.",
                    "label": 0
                },
                {
                    "sent": "You start with a random state that's at each.",
                    "label": 1
                },
                {
                    "sent": "It's a search process, and at each point in the search process I have a complete assignment of values to the variables and then what I'm going to do is.",
                    "label": 0
                },
                {
                    "sent": "I'm going to flip variables in unsatisfied clauses to try to satisfy them and I will use the heuristic for Hill climbing on those like for example, trying to minimize the number of unsatisfied clauses.",
                    "label": 1
                },
                {
                    "sent": "Of course, if I just did this, I would fall into local minima in order to avoid that, I'm going to do some amount of random flips, and I'm also going to restart the whole problem, multiple the whole process multiple times.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so here's the Walksat algorithm, very famous algorithm, surprisingly simple given how powerful it is.",
                    "label": 0
                },
                {
                    "sent": "In fact, it's powerful because it's simple because it's simple.",
                    "label": 0
                },
                {
                    "sent": "You can do these search steps.",
                    "label": 0
                },
                {
                    "sent": "You know gazillions of times in very little, very little CPU time.",
                    "label": 0
                },
                {
                    "sent": "So I'm just going to do this for one to Max tries.",
                    "label": 0
                },
                {
                    "sent": "I start out with a random truth assignment as a solution, and then I go through some maximum number of flips where first of all I check if in the current state of the clauses are satisfied.",
                    "label": 0
                },
                {
                    "sent": "If they are, then I return that solution because you know, I've succeeded.",
                    "label": 0
                },
                {
                    "sent": "Otherwise.",
                    "label": 0
                },
                {
                    "sent": "I pick a random unsatisfied clause with some probability P, where this is an input parameter.",
                    "label": 1
                },
                {
                    "sent": "I flip a random variable in that clause, which guarantees that the clause is satisfied.",
                    "label": 0
                },
                {
                    "sent": "Otherwise, I flip a variable that maximizes the number of satisfied clauses.",
                    "label": 1
                },
                {
                    "sent": "OK, so this is the greedy step.",
                    "label": 0
                },
                {
                    "sent": "And if I'm lucky at some point in this process, I will have a solution.",
                    "label": 0
                },
                {
                    "sent": "If I'm unlucky, I won't have a solution, and the disadvantage of these types of methods is that I never know.",
                    "label": 0
                },
                {
                    "sent": "If there really is no solution either, I just didn't find one in the time that I have available.",
                    "label": 0
                },
                {
                    "sent": "So if you really want that answer, if you want a negative answer, you need to use the backtracking types of methods.",
                    "label": 0
                },
                {
                    "sent": "The disadvantage of these methods are that they tend to be a lot faster.",
                    "label": 0
                },
                {
                    "sent": "OK, so to scale to really large problems, which is what we want here, works at tends to be very.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so finally let's look at inductive logic programming.",
                    "label": 0
                },
                {
                    "sent": "So the question now is like how do we learn knowledge bases in first order logic from data?",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, and probably the best way to introduce this is to start by looking at propositional rule induction.",
                    "label": 0
                },
                {
                    "sent": "So rule induction over a single table.",
                    "label": 0
                },
                {
                    "sent": "So we have a set of positive and negative examples of some concept, let's say spam.",
                    "label": 1
                },
                {
                    "sent": "You know spam emails and non spam emails.",
                    "label": 0
                },
                {
                    "sent": "Each example is is the concept or class Y. I'm going to assume here that it's a Boolean and a set of attributes.",
                    "label": 0
                },
                {
                    "sent": "Again, I'm going to hear this Boolean, so why would we spam non spam and X1 to XN would be the presence of different words like the word free?",
                    "label": 0
                },
                {
                    "sent": "For example, is probably a very good indication of that something is spam.",
                    "label": 0
                },
                {
                    "sent": "Are you still hearing?",
                    "label": 1
                },
                {
                    "sent": "So the goal in Rule induction is to induce a set of rules that cover all the positive examples, but none of the negative ones OK. And the rule is just a body implies ahead, otherwise known as a horn clause.",
                    "label": 0
                },
                {
                    "sent": "So the body is a conjunction of tests.",
                    "label": 0
                },
                {
                    "sent": "Which can be literals.",
                    "label": 0
                },
                {
                    "sent": "Meaning you know these values or their negations and the head is the class and I'm going to say that a rule covers an example.",
                    "label": 0
                },
                {
                    "sent": "If the example satisfies the body of our.",
                    "label": 0
                },
                {
                    "sent": "OK, and in order to do the learning I'm going to need some evaluation measure for a rule like you know, it's accuracy, information gain, coverage, support.",
                    "label": 0
                },
                {
                    "sent": "You can use different things.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the way the way rules you know, there are many algorithms for this.",
                    "label": 0
                },
                {
                    "sent": "But so, like the most widely used one, works like this.",
                    "label": 0
                },
                {
                    "sent": "I'm going to learn a single rule, one antecedent at a time, and I'm going to learn a rule set by learning one rule at a time.",
                    "label": 0
                },
                {
                    "sent": "So how do I learn a single rule?",
                    "label": 1
                },
                {
                    "sent": "I start out with the head being the class and then antibody, meaning that everything matches the rule and then what I do is I look at every literal I try adding it to the rule.",
                    "label": 0
                },
                {
                    "sent": "I evaluate the result, and then I add the literal that gives me the best results.",
                    "label": 0
                },
                {
                    "sent": "OK, so now I have added a little to the rule and I can repeat that another little to the rule until no literal improves the evaluation.",
                    "label": 0
                },
                {
                    "sent": "And then I returned the rule that I found OK.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This not plugged into the larger algorithm, often known as separating conquer, which goes like this.",
                    "label": 0
                },
                {
                    "sent": "I start with an empty ruleset.",
                    "label": 0
                },
                {
                    "sent": "And with my set S, which is all that all the examples.",
                    "label": 0
                },
                {
                    "sent": "And I repeat the following.",
                    "label": 0
                },
                {
                    "sent": "I learn a single rule the way that I just described.",
                    "label": 1
                },
                {
                    "sent": "I add that rule to the rule set and then I delete from the set as the positive examples that I just covered, I separate them out because those are accounted for now and then I'm going to try to learn another rule to cover the remainder of the positive examples.",
                    "label": 0
                },
                {
                    "sent": "And I keep on doing this until hopefully actually this.",
                    "label": 0
                },
                {
                    "sent": "It's not until this set is empty.",
                    "label": 1
                },
                {
                    "sent": "It's until a set of until there are no positive examples left to cover.",
                    "label": 0
                },
                {
                    "sent": "OK, yeah.",
                    "label": 0
                },
                {
                    "sent": "Part of the algorithm is lens in setting where even more in certain way.",
                    "label": 0
                },
                {
                    "sent": "The same idea that boosting ordering has, which is emphasizing or with the you know well classified, that's actually so the question here is like how does this really?",
                    "label": 0
                },
                {
                    "sent": "Isn't this similar to boosting?",
                    "label": 0
                },
                {
                    "sent": "This is actually a lot older than boosting right decades older, but there's an interesting relationship between.",
                    "label": 0
                },
                {
                    "sent": "In fact you can use boosting to learn rule sets by taking a single rule as the model that you're boosting, and that can give good results.",
                    "label": 0
                },
                {
                    "sent": "So in boosting, in a certain sense, what happens is that.",
                    "label": 0
                },
                {
                    "sent": "I don't completely take out examples, I just done with them.",
                    "label": 0
                },
                {
                    "sent": "So yes, there is an interesting relation between the two.",
                    "label": 0
                },
                {
                    "sent": "As I said, this is only the most basic algorithm.",
                    "label": 0
                },
                {
                    "sent": "It's not the most suface.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now how do we do first order rule induction?",
                    "label": 1
                },
                {
                    "sent": "Right now instead of justice Boolean attributes, I have arbitrary predicates with arguments and things now look very complicated.",
                    "label": 0
                },
                {
                    "sent": "The good news is that we can actually take the algorithm that we just saw and transfer it to this more powerful language with only a couple of changes.",
                    "label": 0
                },
                {
                    "sent": "So now why index IR predicates with arguments?",
                    "label": 1
                },
                {
                    "sent": "Say why isn't sesser XY?",
                    "label": 0
                },
                {
                    "sent": "Let's say we want to learn the rules that predict ancestor XY from things like, you know parents XY, OK.",
                    "label": 0
                },
                {
                    "sent": "So now what's going to happen is that when I grow a rule, what I'm trying on is not attributes, its literals, and again I can try adding all literals in the language with one caveat, which is.",
                    "label": 0
                },
                {
                    "sent": "I should make the restriction that I can only add literals that share at least one variable with the literals that already in the rule, because if they don't, then basically the new little says nothing about the things that I'm that I'm interested in, so I think this is a reasonable restriction to make.",
                    "label": 1
                },
                {
                    "sent": "And then the other thing that we need to worry about is that adding a little actually changes the number of groundings of the rule.",
                    "label": 0
                },
                {
                    "sent": "In propositional learning, the space of examples that I was learning rules over was always the same.",
                    "label": 0
                },
                {
                    "sent": "It was the set of objects that I have in my domain.",
                    "label": 0
                },
                {
                    "sent": "Here it's a little more subtle.",
                    "label": 0
                },
                {
                    "sent": "Notice suppose that I'm building a rule for ancestor XY, right?",
                    "label": 0
                },
                {
                    "sent": "What is the set of groundings of this rule?",
                    "label": 0
                },
                {
                    "sent": "It's the set of pairs of people, right?",
                    "label": 0
                },
                {
                    "sent": "Such that one could be the ancestor of the other.",
                    "label": 0
                },
                {
                    "sent": "But if I now add this little parents ZY and notice I'm obeying that rule here because it has wine common with this guy now the set of ground possible groundings of this rule.",
                    "label": 0
                },
                {
                    "sent": "Is the set of triples XYZ?",
                    "label": 0
                },
                {
                    "sent": "So now I've just suddenly greatly expanded my space of possibilities so it be easy to fool myself that I'm doing very well because I'm just creating a lot of positive groundings, but that doesn't actually mean anything.",
                    "label": 1
                },
                {
                    "sent": "So what I need to do is I need to change my evaluation function to take this effect into account.",
                    "label": 0
                },
                {
                    "sent": "And again, there's many ways to do this, but one simple heuristic, one that works fairly well is I just take eval and I multiplied by the number of positive groundings of the original rule that are still covered.",
                    "label": 1
                },
                {
                    "sent": "After adding little Arrow.",
                    "label": 0
                },
                {
                    "sent": "And the idea behind this statistic is that, well, that's what I care about.",
                    "label": 0
                },
                {
                    "sent": "OK, if the total number of groundings has gone up but the number of positive groundings has gone down, actually you know I'm more interested in the letter, so I can use this to compensate, and this this is just one algorithm, But this is very, you know, variations of this algorithm are very widely used in inductive logic programming and are surprisingly power.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so now let's look at putting the pieces together, and now that we've covered the main pieces of background that we're going to need to do multiple multi relational data mining.",
                    "label": 0
                },
                {
                    "sent": "Let's see how we can actually you know.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Turn this into albums that we're interested in, and of course, because this is an area of active research, there's a whole slew of approaches.",
                    "label": 0
                },
                {
                    "sent": "Here are some of them.",
                    "label": 0
                },
                {
                    "sent": "All this one is called knowledge based model construction.",
                    "label": 0
                },
                {
                    "sent": "There's also something called stochastic logic programs, probabilistic relational models, relational Markov networks, vision logic, Markov logic and many others.",
                    "label": 1
                },
                {
                    "sent": "And people are still proposing more of these.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The key thing to remember though, is that there's a number of dimensions along which this algorithm is different.",
                    "label": 0
                },
                {
                    "sent": "So what you don't understand is what does dimensions are, and then when a new algorithm comes along, you will know where to place it.",
                    "label": 0
                },
                {
                    "sent": "And instead of having to, you know, remember, and understand an exponentially growing number of algorithms.",
                    "label": 0
                },
                {
                    "sent": "You just have to remember understand this, you know, linear number of dimensions.",
                    "label": 0
                },
                {
                    "sent": "So what are those dimensions?",
                    "label": 0
                },
                {
                    "sent": "Well, one dimension is just the logical language that the representation uses.",
                    "label": 0
                },
                {
                    "sent": "So the logical language could be full blown 1st order logic.",
                    "label": 1
                },
                {
                    "sent": "Or more often it's a subset.",
                    "label": 1
                },
                {
                    "sent": "It's something like horn clauses or frame systems.",
                    "label": 1
                },
                {
                    "sent": "On the other side, there's the probabilistic language that the representation uses.",
                    "label": 0
                },
                {
                    "sent": "It could be vision, networks, Markov networks.",
                    "label": 0
                },
                {
                    "sent": "It could be something like probabilistic context free grammars.",
                    "label": 0
                },
                {
                    "sent": "Or it could be even more restricted languages.",
                    "label": 1
                },
                {
                    "sent": "Then there's the type of learning that you can do.",
                    "label": 0
                },
                {
                    "sent": "Generative versus discriminative structure and parameters versus perimeters only.",
                    "label": 0
                },
                {
                    "sent": "Knowledge risk rich or knowledge poor.",
                    "label": 0
                },
                {
                    "sent": "And finally there's the type of inference that you can do, like MIT and marginal, and whether you fully ground out your network to the inference or you only partially grounded, or you do lifted inference where you reason at the level of all sets of objects at once.",
                    "label": 0
                },
                {
                    "sent": "So what I'm going to do next is I'm going to give you a whirlwind tour of some of these approaches, just to give you a flavor.",
                    "label": 0
                },
                {
                    "sent": "Of what's available.",
                    "label": 0
                },
                {
                    "sent": "Keeping these relevant dimensions in my.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So knowledge based model construction works as follows.",
                    "label": 1
                },
                {
                    "sent": "The logical language is horn clauses and the probabilistic languages Bayes Nets.",
                    "label": 1
                },
                {
                    "sent": "And the idea knowledge based model construction is that you have a set of horn clauses that specify how to build a vision network.",
                    "label": 0
                },
                {
                    "sent": "And the way they specified is as follows.",
                    "label": 0
                },
                {
                    "sent": "A ground Atom in the in the every ground Atom in your logical knowledge base becomes a node in the vision network, like for example friends Anna Bob would become a node in the vision network.",
                    "label": 1
                },
                {
                    "sent": "The head of a clause.",
                    "label": 1
                },
                {
                    "sent": "Is going to be a child node and the body of the clause are going to be the parent nodes.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is how you do this correspondence between horn clauses in the structure of the vision network.",
                    "label": 0
                },
                {
                    "sent": "Now of course, the problem is that I could have more than one clause with the same hit.",
                    "label": 0
                },
                {
                    "sent": "Right, in which case now I need some way to combine.",
                    "label": 0
                },
                {
                    "sent": "The influence of the multiple classes on this one child.",
                    "label": 0
                },
                {
                    "sent": "For that I need the combining function atypical combiner function that we use this noisy or.",
                    "label": 0
                },
                {
                    "sent": "So I will say that this this child variable is true whenever any of the sets of the parents, any of the antecedents in any of the rules is true, except it's a noisy process.",
                    "label": 0
                },
                {
                    "sent": "So probabilistically they could fail to make the child true.",
                    "label": 0
                },
                {
                    "sent": "And then to learn these models to learn the structure, you can use any LP algorithm to learn parameters, you can use the EM algorithm.",
                    "label": 0
                },
                {
                    "sent": "And to do inference typically what happens is you do partial ground and this is.",
                    "label": 0
                },
                {
                    "sent": "This is why this is called knowledge based model construction, because what you do when you have a query is you construct the network that you need to answer the query.",
                    "label": 0
                },
                {
                    "sent": "You don't build a full model 'cause you know that could be very bad, you just build the part that you need to answer the question and then over that ground network.",
                    "label": 0
                },
                {
                    "sent": "Now you can use any probabilistic inference method.",
                    "label": 0
                },
                {
                    "sent": "Typically people have used belief propagation, but you could also use the MCM.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "See another algorithms stochastic logic programs.",
                    "label": 1
                },
                {
                    "sent": "The logical languages, again, horn clauses, but not the probabilistic languages.",
                    "label": 0
                },
                {
                    "sent": "Probabilistic context free grammars.",
                    "label": 0
                },
                {
                    "sent": "SLP's are a first order generalization of PCF cheese.",
                    "label": 1
                },
                {
                    "sent": "Where instead of production rules do not have horn clauses.",
                    "label": 0
                },
                {
                    "sent": "And the way we do this is we're going to attach it probability to each clause.",
                    "label": 0
                },
                {
                    "sent": "And then the sums of the probabilities of the clauses with the same head has to be one.",
                    "label": 0
                },
                {
                    "sent": "So the semantics for this is that I have a probability distribution over the ways in which that.",
                    "label": 0
                },
                {
                    "sent": "Head could be produced as a body or could be proved using the body OK, and So what I have at the end of the days I have a probability distribution over possible proofs and if I send those out for any particular AT and I'm interested in, I get the probability of that Atom.",
                    "label": 0
                },
                {
                    "sent": "OK, so again learning could be done using any IOP algorithm and now parameters can be learned using M except I have to do what's called failure adjusted Ian because some proofs fail.",
                    "label": 0
                },
                {
                    "sent": "Which means that you know the probability mass of the valid proofs is going to be less than one, so I need to.",
                    "label": 0
                },
                {
                    "sent": "I'm going to need to renormalize.",
                    "label": 0
                },
                {
                    "sent": "And to do inference, what happens is that you know I can do inference using a prologue engine, but the way it works is that instead of just producing 1 proof as in Prolog, I need to produce all possible proofs and then I need to keep updating the probabilities by multiplying things down the proof tree and adding over alternative subtrees.",
                    "label": 0
                },
                {
                    "sent": "And this is how you doing.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In SLP's probabilistic relational models, the logical languages frame systems, meaning what we're going to have is, we're going to have a set of classes of objects, and each class of objects is going to have attributes and relations to other objects, with the important restriction, which is what frame systems make that their relations can only be binary.",
                    "label": 1
                },
                {
                    "sent": "So relation is always from the current object to some other object.",
                    "label": 0
                },
                {
                    "sent": "And then what?",
                    "label": 0
                },
                {
                    "sent": "What PRMS have is for each class I have a template of a vision network that I'm going to construct for objects of that class.",
                    "label": 0
                },
                {
                    "sent": "So for objects of the class, I'm going to have a vision network that says how the properties of the object depend on each other and on properties of related objects.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is your basic language.",
                    "label": 0
                },
                {
                    "sent": "Notice we're not allowing dependencies of relations on relations here.",
                    "label": 1
                },
                {
                    "sent": "To learn it's very nice because we can learn the parameters in closed form.",
                    "label": 0
                },
                {
                    "sent": "It's a vision network.",
                    "label": 0
                },
                {
                    "sent": "If there's missing data which most of the time there is, then you have to use them.",
                    "label": 0
                },
                {
                    "sent": "But again, that's fairly standard.",
                    "label": 0
                },
                {
                    "sent": "The way structure is learned is by generalizing algorithms for learning vision network structure.",
                    "label": 0
                },
                {
                    "sent": "What's going to happen is that I'm going to try adding, removing, reversing links, but I'm going to do this in a tiered way.",
                    "label": 0
                },
                {
                    "sent": "First, I try to see predict properties of an object given properties of the object itself, and then using properties of objects that are directly related, and then objects that are two links away and so on until nothing gives me an improvement, because if I try to do it over everybody all at once, it would be too costly and I would probably overfit massively.",
                    "label": 0
                },
                {
                    "sent": "Inferencing PRMS is done by fully grounding the network, although you know.",
                    "label": 0
                },
                {
                    "sent": "I don't see any reason why it couldn't be done using partial grounding, and typically people have used belief propagation, but again, you could use MCMC or something else.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So relational Markov networks is now something that's somewhat different from these approaches that we've seen so far in relational Markov logic network.",
                    "label": 0
                },
                {
                    "sent": "In relation Markov networks, the logical languages, SQL queries of the simplest type conjunctive queries.",
                    "label": 1
                },
                {
                    "sent": "And the probabilistic languages Markov networks.",
                    "label": 0
                },
                {
                    "sent": "And the way our immense work is as follows.",
                    "label": 0
                },
                {
                    "sent": "What the query specifies is what the clicks are.",
                    "label": 0
                },
                {
                    "sent": "I run a query on a database and it gives me.",
                    "label": 0
                },
                {
                    "sent": "It gives out a bunch of tuples.",
                    "label": 0
                },
                {
                    "sent": "These each of these tuples is a click.",
                    "label": 0
                },
                {
                    "sent": "OK, and now associated with each click.",
                    "label": 0
                },
                {
                    "sent": "I'm going to have a potential function.",
                    "label": 0
                },
                {
                    "sent": "So I have a query to define the click and I have the potential function over the click OK. Notice arms do not allow uncertainty of relations.",
                    "label": 0
                },
                {
                    "sent": "At least this is currently defined.",
                    "label": 0
                },
                {
                    "sent": "I can use the relations in the query to produce my clicks, but then the probability distribution is just over the atoms in the click which are properties of objects learning to date.",
                    "label": 0
                },
                {
                    "sent": "People have only then weight learning and discriminative learning in particular.",
                    "label": 0
                },
                {
                    "sent": "Inference again is done by full grounding and then running.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Belief propagation.",
                    "label": 0
                },
                {
                    "sent": "So vision logic.",
                    "label": 0
                },
                {
                    "sent": "Vision Logic is a fairly complicated language with its own syntax, but essentially it's at the level of 1st order logic.",
                    "label": 0
                },
                {
                    "sent": "The probabilistic languages, again vision, networks and the way this works is that there's this programming language called blog.",
                    "label": 0
                },
                {
                    "sent": "Very unfortunate name.",
                    "label": 0
                },
                {
                    "sent": "You'll never find it on the web for vision Logic and what a block program specifies is how to generate the relational world.",
                    "label": 1
                },
                {
                    "sent": "It's sort of like the idea of a generative model, taken to the limit.",
                    "label": 0
                },
                {
                    "sent": "It says, well, do this with certain probability, generate some number of objects and then.",
                    "label": 0
                },
                {
                    "sent": "Generate these properties of these objects and then given that generate some properties of related objects and so forth.",
                    "label": 0
                },
                {
                    "sent": "The block program actually only specifies the structure of the model, the parameters the distributions have to be specified somewhere else in Java code or some library distributions or whatever.",
                    "label": 0
                },
                {
                    "sent": "The nice thing about Vision Logic is that, unlike the languages that we saw before, it actually allows for there to be unknown objects in your domain, meaning objects that exist and affect what goes on.",
                    "label": 0
                },
                {
                    "sent": "But you don't observe directly.",
                    "label": 0
                },
                {
                    "sent": "Think for example, of blips on the radar.",
                    "label": 0
                },
                {
                    "sent": "These loops are generated by aircraft.",
                    "label": 0
                },
                {
                    "sent": "Blog actually allows it to model the existence of aircraft, whereas in these other languages you were only doing distributions over the things that you could observe.",
                    "label": 0
                },
                {
                    "sent": "A very big problem with with blog.",
                    "label": 1
                },
                {
                    "sent": "It was already present in the other models, but it becomes even more seriously is that it could a block program could easily create a vision network with directed cycles.",
                    "label": 0
                },
                {
                    "sent": "In which case your inference will never finish running.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately, checking a block program to make sure that it doesn't create networks with cycles is an intractable problem, and so you know people basically just don't do it and they and they hope for the best.",
                    "label": 0
                },
                {
                    "sent": "To date, no learning algorithms for blockers in proposed inference is done by Markov chain Monte Carlo.",
                    "label": 1
                },
                {
                    "sent": "With the proposal distribution that you have to supply.",
                    "label": 0
                },
                {
                    "sent": "Again, this is not so great because most people have no even people with PhD in machine learning.",
                    "label": 1
                },
                {
                    "sent": "Often you know have a lot of trouble figuring out how to define a proposal distribution.",
                    "label": 0
                },
                {
                    "sent": "A nice thing about inferencing blog is that it does just use partial grounding.",
                    "label": 0
                },
                {
                    "sent": "So if the relevant part of the model is simple as it can, BMC things can be fairly efficient.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Finally, and most recently, Markov logic is a language in which the logical language is full first order logic.",
                    "label": 1
                },
                {
                    "sent": "The probabilistic languages, Markov networks.",
                    "label": 0
                },
                {
                    "sent": "And the syntax is very simple.",
                    "label": 0
                },
                {
                    "sent": "The syntax is just first order logic as before, except we're going to attach weights to the formulas and other semantics.",
                    "label": 0
                },
                {
                    "sent": "Is that a formula with the weight is a template for constructing features of a Markov network and now learning the parameters can be then generatively or discriminatively structure can be then by LP and learning Arbitrary clause is not just horn clauses and some kind of MVP score inference to do MVP inference, we can use a weighted satisfiability solver.",
                    "label": 0
                },
                {
                    "sent": "As we shall see later, to do marginal inference efficiently, we can use MCMC.",
                    "label": 0
                },
                {
                    "sent": "But with the moves proposed by a SAT solver, which is a lot faster than using something like Gibbs and again we can do partial grounding and we can actually do something else which is lazy inference, which is we actually even among the relevant variables were actually going to only ground some of them because most of them can be left implicit.",
                    "label": 1
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And of the various approaches, Markov logic is the most developed one to date in terms of, you know, having all the necessary algorithms and their scalability and so forth and their availability in the open source software and so forth.",
                    "label": 0
                },
                {
                    "sent": "It also has the nice feature that we can look at many other approaches as special cases of Markov logic.",
                    "label": 1
                },
                {
                    "sent": "Because Markov logic uses the most general probabilistic and logical language, we can actually see how each one of these other languages is a special case of Markov logic and understand what the structure of the of the domain is, and So what I'm going to focus on for the rest of this tutorial is Markov logic.",
                    "label": 0
                },
                {
                    "sent": "Many of the algorithms that we will see from Markov logic are applicable to the other representations, and certainly many of the issues are present across representations, but you know we have to pick one to forge ahead.",
                    "label": 0
                },
                {
                    "sent": "And and for that I'm going to use Markov logic OK.",
                    "label": 0
                },
                {
                    "sent": "So it's at 10:00 AM.",
                    "label": 0
                },
                {
                    "sent": "We now have 1/2 hour break and we will start again at 10:30.",
                    "label": 0
                }
            ]
        }
    }
}