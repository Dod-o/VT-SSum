{
    "id": "2pjrypu7nvqibgf7gqtb7nrfgmeqi37x",
    "title": "Result Enrichment in Commerce Search using Browse Trails",
    "info": {
        "author": [
            "Debmalya Panigrahi, Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology, MIT"
        ],
        "published": "Aug. 9, 2011",
        "recorded": "February 2011",
        "category": [
            "Top->Computer Science->Web Search"
        ]
    },
    "url": "http://videolectures.net/wsdm2011_panigrahi_rec/",
    "segmentation": [
        [
            "So what I would be talking about is how you can leverage information about user behavior that you learn from browse trails to enrich the set of results.",
            "For that, a common search engine returns in response to a product query and this is joint work with Srinivas Gollapudi from Microsoft Research and I did this work when I was an intern there."
        ],
        [
            "Alright, so what's the basic question we want to address?",
            "Take your favorite common search engine.",
            "He reviews Bing shopping as an example, not without reason I guess.",
            "And let's say the user is searching for digital cameras.",
            "An enters the following search query purple Pentax Optio, so presumably the user wants a purple camera and would like to see Pentax optio cameras in the set of results that the search engine returns.",
            "Now often what happens is the catalog that search engine has does not contain an exact match to what the user is looking for.",
            "For example, here the catalog might not contain.",
            "A purple Pentax Cam, up to camera or might contain very few of them, so to enrich the set of results returned to the user, the search engine needs to return a set.",
            "Some results where we have a partial match with what the user searched for.",
            "So I have 3 examples here, so the search the catalog might contain a purple Canon camera instead of a Pentax camera.",
            "Or it might contain Pentax cameras, but in different colors.",
            "So for example a red Pentax camera or a blue one, and the basic question we want to address is which of these several options that the search engine has is likely to satisfy the user more right?",
            "So which of these all of which have a partial match, should the search engine return?"
        ],
        [
            "So let us try to deconstruct this query a little further.",
            "So here the query contains of three different attributes, purple, Pentax, and Optio.",
            "Let's focus on the first 2.",
            "So purple obviously is a color attribute, and Pentax is the manufacturer attribute.",
            "So the first question we can ask is which of these two attribute values is more important.",
            "So when we're replacing one of them, when we are searching for partial matches which should match of these two, should we replace purple or should be replacement tax effect tax is more important, which is likely to happen for digital cameras.",
            "Then we would like to retain Pentax and replace purple for this is extremely context sensitive right?",
            "So for example, if the user were searching for dresses, color would be a very important attribute.",
            "But possibly not for digital cameras.",
            "OK, so this is the first question we use.",
            "How important is an attribute value?",
            "And once we've decided that we want to replace purple rather than printer?",
            "Sorry Pentax, we might have several options.",
            "So what do we replace it with?",
            "For example, in the previous slide, you saw that there was a red Pentax camera and a blue one.",
            "So which of these two is better?",
            "So which of blue or red is the more replaceable option, given purple, given purple was what the user was?",
            "Originally looking for so these are the two questions we will address in this talk."
        ],
        [
            "So let's try to formalize them a little more.",
            "Let's first look at similarity or replace ability.",
            "So what's the similarity of Pentax and Canon?",
            "It's essentially the fraction of users who searched for a Pentax camera, but ended up buying a Canon camera, or at least browsed web pages which contain information about Canon cameras, right?",
            "So that's precisely the definition for similarity of Pentax and Kanell.",
            "Now.",
            "One thing to note, and this is extremely important.",
            "That these the similarity parameters that we have defined our highly asymmetric.",
            "In fact, the general trend is that people who search for lesser known brands or less popular brands tend to be happier with more popular brands, but not vice versa.",
            "So someone searching for a vivitar camera would be reasonably happy if sure, if shown a Canon camera, but someone searching for a Canon camera really wants a Canon camera itself, not something else, so this asymmetry is extremely important.",
            "So this is the.",
            "This is one of the two parameters we are interested in.",
            "Sorry."
        ],
        [
            "The other parameter is the non replaceability or importance of an attribute value.",
            "So how important is it to match the attribute value exactly in the set of products that I return?",
            "And this is simply the relative frequency of queries containing that value which actually land up in web pages that contain data relevant to that value.",
            "So how many people searching for Canon cameras actually go to web pages containing information about Canon cameras themselves?",
            "So notice that the two definitions are some uniformity in the definition.",
            "In fact, we can.",
            "In fact, the importance of often attribute.",
            "Let's say Pentax is simply the similarity of context itself, right?",
            "So we will treat this uniformly.",
            "Now.",
            "Again, there's the general trend is that for very popular attribute values, for example, if you assume that Kanaan is more popular than Pentax, which is more popular than visitor, then the importance of Canon would typically be higher than the importance of Frontex, which would again be higher than the importance of it are right?",
            "So people who.",
            "Originally, search for Vivitar are likely to migrate towards the more popular brands, but not vice versa.",
            "So these are the two quantities we want to estimate.",
            "Now obviously the challenge here is how do we annotate each web domain or webpage with what information it contains, right so?",
            "We don't appear if we don't know whether a webpage is good for is relevant for Canon or relevant for Pentax or what, and this is the key question that we don't need to answer.",
            "Once we have answered this question, it's easy to compute these parameters, so this is the question I will focus on for the rest of the talk."
        ],
        [
            "So what are the various techniques that one can use so one of the obvious techniques is to use something like web crawling so we can actually look at the content of these web pages and try to figure out what that page is about, right?",
            "The problem with web crawling obviously is that it's extremely resource intensive, so we ruled that out.",
            "So a very popular method is our suite of methods that are very popular or what are known as click based methods.",
            "So here user clicks.",
            "Are used to click through.",
            "Rates are used to identify associations between users and web pages.",
            "Now there are several problems with click based methods.",
            "For example, there are a lot of spurious clicks since we're just taking the first click off and use of a user after issuing the query.",
            "There are a lot of spurious clicks and there's no way to distinguish between a spurious click and a genuine one.",
            "Also, the data is extremely sparse because it's only a small part of the web that tends to figure in.",
            "Search query results, which means that we have only information about that part of the web.",
            "We don't get to know about a very heavy tail, so because of these, so sometimes to make the data dense, denser people use things like similarity estimates and so on.",
            "But then the question is how do you?",
            "How do you make these estimates?",
            "So you need some more data to do that."
        ],
        [
            "So what we propose here is to go beyond single clicks and use entire browse trail data.",
            "So if it so, we did an empirical study and it turns out that most browse trails by their brows trail is a query followed by the sequence of URLs that the user visits.",
            "So the user issues or queries, let's say Q1 and then it's showing a set of results.",
            "She clicks on one of them.",
            "Let's say you for here that's a URL.",
            "Now she clicks on a hyper link on that page and goes to you 6 and so on.",
            "So this entire sequence of URLs constitutes of Rose Trail.",
            "So as as the table shows a very large fraction, in fact something like 60% of browse trails don't terminate in the first click, which means that subsequent clicks do contain significant information about user data, so it's a larger corpus that we're dealing with here.",
            "Another important feature is that this is much more robust to noisy clicks, because typically these spurious clicks tend to be very short, typically just one click.",
            "So once we take these long trails into account as well.",
            "The noisy clicks tend to become statistically less relevant, so that's one advantage of using browse trails and this is data that we can collect easily from tool world logs, so that's what we in fact do.",
            "We collect this data from IE toolbar logs.",
            "So this is not the first name that browse trails are being used.",
            "It has been previously used for various things, for example Bill and Cohen.",
            "White used it to find relevant search results and white at all used it to find popular destinations on the web and guide users to those destinations.",
            "But we are the first ones to use this for this particular particular purpose, which is to annotate web domains or web pages with relevant information."
        ],
        [
            "OK. OK, so let let me let me say a few more words about the data that we're using.",
            "So what's important to note is that we're not mining the content of any of these web pages.",
            "In fact, we're not even parsing the URLs.",
            "So these web pages, for all we know are all identical and empty and have some URL which we can represent by just a number.",
            "So all we are using is just the sequence of these URLs and the query that was initially issued by the user in response to which this browse trail came about.",
            "So that's all we're using.",
            "So one obvious question is why aren't we using a richer set of data?",
            "For example, why not crawl the pages, which as I said?",
            "Incurs a huge overhead, whereas the data that we are using can come simply for the browser and is much lighter.",
            "One other option which is slightly lighter than crawling the entire page is to actually parse the URL itself.",
            "Often URLs contains some information about what they contain, I mean the info about their content and therefore parsing the URL itself might be an option, but what we found is that Benny pages that actually come up in these browse trails are non English language pages or and therefore the URLs do not contain any information about their content or even for English language pages most URLs.",
            "Tend to be very difficult to parse to extract information about the content.",
            "Also, we must keep in mind that we have a humongous amount of data to consider, so these as we will show we actually work with almost half a billion browse trails.",
            "So any additional computation on these browse trails is going to add a huge overhead and we want to avoid that."
        ],
        [
            "So before I give you an algorithm for annotating the web based on browse trail data, let me give you let's step back and look at some of the salient features of what we're trying to do.",
            "So firstly, as I said, the importance and similarity of attribute values is heavily dependent on the category of products that the user is looking for.",
            "For example, dresses and digital cameras will have very different importance values for an attribute like color, so we're restricting ourselves to a single attribute each time.",
            "For example, we restrict ourselves to either digital cameras or dresses or kitchen appliances and so on, so that the queries are homogeneous set of queries the user is searching for this for various strings, but for the same kind of product.",
            "We also assume that the query comes annotated with the values of the attributes.",
            "So for example, a perfect purple Pentax optio query can be parsed into purple and Pentax optio, where purple is the attribute.",
            "Purple is the value of of the color attribute, and Pentax off Theo is the value of the manufacturer attribute.",
            "This is this this parser has been developed in search labs itself and we use this parser in our work.",
            "The final point to note is that we treat each attribute separately, so when we're computing similarity scores, we compute score scores between two values for let's say the color attribute or the manufacturer attributes at a time.",
            "We're fixing a category and fixing an attribute.",
            "OK."
        ],
        [
            "OK, so in the rest of the talk what I will do is give you a very brief and high level overview of the algorithm that we used to annotate web domains based on browse trails.",
            "I won't give all the details of the algorithm because it's slightly hairy, but what I will do is I'll give you an analytical framework which we use to develop the algorithm and I'll give some analytical results and this framework will involve a set of assumptions, so we will experimentally verify.",
            "Firstly, we will verify these assumptions.",
            "And then we will verify the output of the algorithm.",
            "So first we will see that whether the assumptions are true, and Secondly we will see whether the algorithm produces the right similarity measures."
        ],
        [
            "Let's start with the algorithm."
        ],
        [
            "The idea is extremely simple simple, so the idea is the following.",
            "If a lot of Canon queries, for example visitor page, then that page must be relevant to Canon.",
            "So this is a very simple idea, so we use simple frequency counts to annotate webpages.",
            "Now obviously this just using frequency counts is not sufficient because some of these very popular attribute values like for example, let's say can and will simply swamp everything else.",
            "So we have to be very careful about how we use the counts.",
            "But all we need are frequency counts in the algorithm.",
            "And the final goal is to come up with tables of the following kind.",
            "So for example, canon.com is likely to be very relevant for Canon queries, but less so for all other brands.",
            "So can and should have a very high weight in the list of annotations for canon.com for Amazon.com, on the other hand, all popular manufacturers should have a high weight, whereas less popular ones should have lesser smaller weight.",
            "So these are the kinds of tables we want to construct at the end."
        ],
        [
            "So let's get to the analytical framework which will help us in designing the algorithm.",
            "So suppose and this is a simplifying assumption.",
            "Suppose that each domain has a single unknown relevant attribute value.",
            "OK, this is an assumption we don't need in the algorithm, but for the purpose of this talk, I'll make this assumption to make things simpler, and we did not.",
            "For domain D, we did not.",
            "The actual attribute value SKU of D. This is what we want to figure out.",
            "This is something we don't know.",
            "Now if sub QD represents the frequent frequency of browse trails for queries containing attribute value Q that visit domain D, so Q for example, could be can on here.",
            "Then we can quantify the definitions of similarity unimportance that I described earlier.",
            "So similarities simply is the relative frequency of queries containing attribute value Q that visit domains for which the correct annotation is Q prime.",
            "So that's the similarity of Q&Q prime.",
            "The importance of Q is the relative frequency of queries that have attribute value Q that actually land upon pages.",
            "Who's correct annotation is Q itself?",
            "OK, so these are the two quantities that we want to estimate.",
            "So the overall input is are these frequency counts, which we get from browse trails.",
            "So how do we process this frequency counts to get the following output?",
            "So we want the similarity unimportance of similarity of every pair of attribute values and the importance of all attribute values, and we want to do it by via the identification of K of D for all the domains.",
            "Once we do that, it's very simple, we can just use this formula to do the calculations.",
            "So as such it so it's fairly easy to show that we don't have sufficient information in the system.",
            "It's information theoretically impossible to do this annotation, so let's try to make our model A little richer when introducing some assumptions."
        ],
        [
            "So for the first assumption, we introduce the notation.",
            "Let D sub QB domains, which should actually be annotated with Q. OK, who's correct annotation is Q.",
            "So these are a set of domains that we represent by D. Subq.",
            "The positive bias assumption roughly says that if a query has contains a keyword Q, let's say a query contains Kanaan, then it is more likely to go to a Canon webpage than to any other web page.",
            "OK, so.",
            "That's what I have written in notation there, but essentially the frequencies of Canon query is going to Canon webpages is higher than the frequency of Canon queries going to say Pentax web pages, so that's our first assumption.",
            "So for the second assumption again, we need some notation let N, sub, QQ prime be the set of queries that contain Q, But actually end up on web pages is correct annotation is Q prime.",
            "An insert Q are all queries that contain Q, the total frequency.",
            "So what the uniformity assumption says is that if you fix a keyword Q and look at only queries containing Q and then fix the, then consider the set of web pages.",
            "The who's correct annotation is Q prime, then the.",
            "Then the query visit patterns of these queries over this set of web pages is more or less uniform, and again that's what I have written in notation.",
            "There, we introduce we make this parameterized using Alpha and Delta, so that it's somewhat robust.",
            "Our final assumption is what we call proportionality.",
            "This roughly says that keywords that are popular in queries are also popular in domains.",
            "So if Canon is a popular query term, then the web would contain more pages with correct annotation.",
            "Is Canon and again we make this robust by making it parameterized, introducing parameters, beaten, So for the rest of.",
            "So for what I'll say later, think of Alpha, Delta, beta and Gamma as as numbers fairly close to 1."
        ],
        [
            "Sermon analytical result is the following theorem.",
            "We give an algorithm that annotates each domain with a list of attribute values and we denote it by L sub D such that it satisfies the following properties.",
            "The first property is what we call completeness, so if the correct annotation of a domain is Q.",
            "And Q is an important attribute.",
            "Then the list must contain Q.",
            "It doesn't miss any important attribute.",
            "The second is soundness, which says that if the correct annotation of a domain is Q.",
            "But some other keyword Q prime is contained in its list.",
            "Then the similarity of Q2 Q prime must be high, roughly Theta square.",
            "Healthy dubbing apparel parameter for completeness.",
            "So the first one says that we don't miss an important attribute.",
            "The second one says that we don't introduce attributes that are very dissimilar in the list.",
            "And the final assumption is is largely for efficiency purposes, so we don't want these lists list to be extremely large, so we show that the average length of each list is roughly one over Theta.",
            "So read that as one over Theta, because all these quantities are close to theater.",
            "In fact, this is information theoretically tight, you cannot do anything better than this.",
            "So I won't give a proof of the theorem.",
            "I won't give the description of the algorithm itself, but.",
            "But this is the main analytical result that we prove in the paper, and the paper contains all details."
        ],
        [
            "So in the rest of the talk, instead of giving a proof, let me try to show you how we experimentally validated our technique."
        ],
        [
            "So before we go to the experiments, one immediate issue is the scalability of our ideas.",
            "So there are a lot of domains and each domain has a lot of different queries for various different attribute values.",
            "Visiting it.",
            "So do we actually maintain tables for all of these?",
            "Well, we don't because it's too much, too much data.",
            "All we do is we maintain tables only for very frequently visited domains and also for a particular domain.",
            "We only consider frequent.",
            "Attributes, and this is fairly simple to do, even if the browse trails are not in memory.",
            "If they come in a stream using standard techniques like heavy hitters or reservoir sampling.",
            "So in fact, in fact we run our algorithms on almost half a billion browse trails and it runs in less than an hour, so it's fairly efficient and scalable."
        ],
        [
            "So the first set of experiments were to validate our assumptions.",
            "Remember that we had three assumptions in our analytical model to validate these assumptions.",
            "We used browse trails on Amazon.com.",
            "Now the advantage with using pages on Amazon.com is that the URL contains sufficient information about the product that's on the page and therefore we know the correct annotation from just by parsing the URL we compare it with what the algorithm does and we found that for positive for validating positive bias, which.",
            "We have looked at the distribution of queries containing a particular keyword Q visiting all kinds of various web various web pages on on Amazon.com and found that they mostly visited domains which are also which also contain products relevant to Q.",
            "For uniformity, we fixed Q&Q prime.",
            "That's that's what the assumption says.",
            "And then we looked at the distribution of queries containing Q on web pages annotated with Q prime, and this distribution had high entropy, which means that it was roughly uniform.",
            "And finally for proportionality, we looked at the relative frequency of an attribute value in both queries and product pages on Amazon.com, and these were very highly correlated or close to proportional.",
            "So these were the first set of experiments we."
        ],
        [
            "Then the second set of experiments were to test how good our algorithm was in computing similarity scores.",
            "And here we use the data set from IE8, browse trails for six months, which contains roughly half a billion browse trails.",
            "In fact, a 63% of these trails had length more than one, so that validates our assumption that browse trails which are long, contain useful information or browse fields in general, contain more useful information than single clicks.",
            "Now the categories we used were were some of these were the.",
            "These are some of the examples of categories we use, digital cameras, laptops, kitchen appliances and so on.",
            "And some of the attributes that we looked at were manufacturer, product line etc.",
            "So these are these are quite standard ones."
        ],
        [
            "So how did we verify your similarity or evaluate our similarity values?",
            "First, we ran our algorithm and computer similarity values.",
            "Then we used human judges through Amazon's Mechanical Turk to compute similarity rankings.",
            "What does the similarity ranking mean?",
            "Well, we fixed.",
            "Fix the keyboard and then looked at and ask the human judges to rank all other keywords by similarity to that keyword.",
            "And we compared these two lists, the one that the algorithm computes and the human and one computed by a human judge, and it turns out that these lists were very close.",
            "In fact, their deviation was roughly 4 to 5% of what the maximum deviation could be.",
            "So I'll skip some anecdotal examples of similarity and importance values because I don't have time."
        ],
        [
            "And go to some other applications of our techniques.",
            "Firstly, we can use these lists to indicate which domains are good for what kind of product.",
            "For example, Best Buy might be better for plain text and Canon cameras.",
            "We can also use this for product diversification.",
            "Note that importances and similarity have a very close relation to relevance and novelty, which is used in product."
        ],
        [
            "Versification.",
            "And in future work we would like to study more carefully what the dependencies between different attributes are.",
            "Not that what we did work for single attributes, but often attributes are very dependent.",
            "And how do we handle them in these techniques?",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what I would be talking about is how you can leverage information about user behavior that you learn from browse trails to enrich the set of results.",
                    "label": 0
                },
                {
                    "sent": "For that, a common search engine returns in response to a product query and this is joint work with Srinivas Gollapudi from Microsoft Research and I did this work when I was an intern there.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so what's the basic question we want to address?",
                    "label": 0
                },
                {
                    "sent": "Take your favorite common search engine.",
                    "label": 0
                },
                {
                    "sent": "He reviews Bing shopping as an example, not without reason I guess.",
                    "label": 0
                },
                {
                    "sent": "And let's say the user is searching for digital cameras.",
                    "label": 0
                },
                {
                    "sent": "An enters the following search query purple Pentax Optio, so presumably the user wants a purple camera and would like to see Pentax optio cameras in the set of results that the search engine returns.",
                    "label": 0
                },
                {
                    "sent": "Now often what happens is the catalog that search engine has does not contain an exact match to what the user is looking for.",
                    "label": 0
                },
                {
                    "sent": "For example, here the catalog might not contain.",
                    "label": 0
                },
                {
                    "sent": "A purple Pentax Cam, up to camera or might contain very few of them, so to enrich the set of results returned to the user, the search engine needs to return a set.",
                    "label": 0
                },
                {
                    "sent": "Some results where we have a partial match with what the user searched for.",
                    "label": 0
                },
                {
                    "sent": "So I have 3 examples here, so the search the catalog might contain a purple Canon camera instead of a Pentax camera.",
                    "label": 0
                },
                {
                    "sent": "Or it might contain Pentax cameras, but in different colors.",
                    "label": 0
                },
                {
                    "sent": "So for example a red Pentax camera or a blue one, and the basic question we want to address is which of these several options that the search engine has is likely to satisfy the user more right?",
                    "label": 0
                },
                {
                    "sent": "So which of these all of which have a partial match, should the search engine return?",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let us try to deconstruct this query a little further.",
                    "label": 0
                },
                {
                    "sent": "So here the query contains of three different attributes, purple, Pentax, and Optio.",
                    "label": 0
                },
                {
                    "sent": "Let's focus on the first 2.",
                    "label": 0
                },
                {
                    "sent": "So purple obviously is a color attribute, and Pentax is the manufacturer attribute.",
                    "label": 1
                },
                {
                    "sent": "So the first question we can ask is which of these two attribute values is more important.",
                    "label": 0
                },
                {
                    "sent": "So when we're replacing one of them, when we are searching for partial matches which should match of these two, should we replace purple or should be replacement tax effect tax is more important, which is likely to happen for digital cameras.",
                    "label": 0
                },
                {
                    "sent": "Then we would like to retain Pentax and replace purple for this is extremely context sensitive right?",
                    "label": 0
                },
                {
                    "sent": "So for example, if the user were searching for dresses, color would be a very important attribute.",
                    "label": 0
                },
                {
                    "sent": "But possibly not for digital cameras.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is the first question we use.",
                    "label": 0
                },
                {
                    "sent": "How important is an attribute value?",
                    "label": 1
                },
                {
                    "sent": "And once we've decided that we want to replace purple rather than printer?",
                    "label": 0
                },
                {
                    "sent": "Sorry Pentax, we might have several options.",
                    "label": 1
                },
                {
                    "sent": "So what do we replace it with?",
                    "label": 0
                },
                {
                    "sent": "For example, in the previous slide, you saw that there was a red Pentax camera and a blue one.",
                    "label": 0
                },
                {
                    "sent": "So which of these two is better?",
                    "label": 0
                },
                {
                    "sent": "So which of blue or red is the more replaceable option, given purple, given purple was what the user was?",
                    "label": 0
                },
                {
                    "sent": "Originally looking for so these are the two questions we will address in this talk.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's try to formalize them a little more.",
                    "label": 0
                },
                {
                    "sent": "Let's first look at similarity or replace ability.",
                    "label": 0
                },
                {
                    "sent": "So what's the similarity of Pentax and Canon?",
                    "label": 1
                },
                {
                    "sent": "It's essentially the fraction of users who searched for a Pentax camera, but ended up buying a Canon camera, or at least browsed web pages which contain information about Canon cameras, right?",
                    "label": 0
                },
                {
                    "sent": "So that's precisely the definition for similarity of Pentax and Kanell.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "One thing to note, and this is extremely important.",
                    "label": 0
                },
                {
                    "sent": "That these the similarity parameters that we have defined our highly asymmetric.",
                    "label": 0
                },
                {
                    "sent": "In fact, the general trend is that people who search for lesser known brands or less popular brands tend to be happier with more popular brands, but not vice versa.",
                    "label": 0
                },
                {
                    "sent": "So someone searching for a vivitar camera would be reasonably happy if sure, if shown a Canon camera, but someone searching for a Canon camera really wants a Canon camera itself, not something else, so this asymmetry is extremely important.",
                    "label": 0
                },
                {
                    "sent": "So this is the.",
                    "label": 0
                },
                {
                    "sent": "This is one of the two parameters we are interested in.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The other parameter is the non replaceability or importance of an attribute value.",
                    "label": 0
                },
                {
                    "sent": "So how important is it to match the attribute value exactly in the set of products that I return?",
                    "label": 0
                },
                {
                    "sent": "And this is simply the relative frequency of queries containing that value which actually land up in web pages that contain data relevant to that value.",
                    "label": 1
                },
                {
                    "sent": "So how many people searching for Canon cameras actually go to web pages containing information about Canon cameras themselves?",
                    "label": 0
                },
                {
                    "sent": "So notice that the two definitions are some uniformity in the definition.",
                    "label": 0
                },
                {
                    "sent": "In fact, we can.",
                    "label": 0
                },
                {
                    "sent": "In fact, the importance of often attribute.",
                    "label": 0
                },
                {
                    "sent": "Let's say Pentax is simply the similarity of context itself, right?",
                    "label": 0
                },
                {
                    "sent": "So we will treat this uniformly.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "Again, there's the general trend is that for very popular attribute values, for example, if you assume that Kanaan is more popular than Pentax, which is more popular than visitor, then the importance of Canon would typically be higher than the importance of Frontex, which would again be higher than the importance of it are right?",
                    "label": 0
                },
                {
                    "sent": "So people who.",
                    "label": 0
                },
                {
                    "sent": "Originally, search for Vivitar are likely to migrate towards the more popular brands, but not vice versa.",
                    "label": 1
                },
                {
                    "sent": "So these are the two quantities we want to estimate.",
                    "label": 0
                },
                {
                    "sent": "Now obviously the challenge here is how do we annotate each web domain or webpage with what information it contains, right so?",
                    "label": 0
                },
                {
                    "sent": "We don't appear if we don't know whether a webpage is good for is relevant for Canon or relevant for Pentax or what, and this is the key question that we don't need to answer.",
                    "label": 0
                },
                {
                    "sent": "Once we have answered this question, it's easy to compute these parameters, so this is the question I will focus on for the rest of the talk.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what are the various techniques that one can use so one of the obvious techniques is to use something like web crawling so we can actually look at the content of these web pages and try to figure out what that page is about, right?",
                    "label": 0
                },
                {
                    "sent": "The problem with web crawling obviously is that it's extremely resource intensive, so we ruled that out.",
                    "label": 1
                },
                {
                    "sent": "So a very popular method is our suite of methods that are very popular or what are known as click based methods.",
                    "label": 0
                },
                {
                    "sent": "So here user clicks.",
                    "label": 0
                },
                {
                    "sent": "Are used to click through.",
                    "label": 0
                },
                {
                    "sent": "Rates are used to identify associations between users and web pages.",
                    "label": 0
                },
                {
                    "sent": "Now there are several problems with click based methods.",
                    "label": 0
                },
                {
                    "sent": "For example, there are a lot of spurious clicks since we're just taking the first click off and use of a user after issuing the query.",
                    "label": 1
                },
                {
                    "sent": "There are a lot of spurious clicks and there's no way to distinguish between a spurious click and a genuine one.",
                    "label": 0
                },
                {
                    "sent": "Also, the data is extremely sparse because it's only a small part of the web that tends to figure in.",
                    "label": 0
                },
                {
                    "sent": "Search query results, which means that we have only information about that part of the web.",
                    "label": 0
                },
                {
                    "sent": "We don't get to know about a very heavy tail, so because of these, so sometimes to make the data dense, denser people use things like similarity estimates and so on.",
                    "label": 0
                },
                {
                    "sent": "But then the question is how do you?",
                    "label": 0
                },
                {
                    "sent": "How do you make these estimates?",
                    "label": 0
                },
                {
                    "sent": "So you need some more data to do that.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what we propose here is to go beyond single clicks and use entire browse trail data.",
                    "label": 1
                },
                {
                    "sent": "So if it so, we did an empirical study and it turns out that most browse trails by their brows trail is a query followed by the sequence of URLs that the user visits.",
                    "label": 0
                },
                {
                    "sent": "So the user issues or queries, let's say Q1 and then it's showing a set of results.",
                    "label": 0
                },
                {
                    "sent": "She clicks on one of them.",
                    "label": 0
                },
                {
                    "sent": "Let's say you for here that's a URL.",
                    "label": 0
                },
                {
                    "sent": "Now she clicks on a hyper link on that page and goes to you 6 and so on.",
                    "label": 0
                },
                {
                    "sent": "So this entire sequence of URLs constitutes of Rose Trail.",
                    "label": 0
                },
                {
                    "sent": "So as as the table shows a very large fraction, in fact something like 60% of browse trails don't terminate in the first click, which means that subsequent clicks do contain significant information about user data, so it's a larger corpus that we're dealing with here.",
                    "label": 0
                },
                {
                    "sent": "Another important feature is that this is much more robust to noisy clicks, because typically these spurious clicks tend to be very short, typically just one click.",
                    "label": 1
                },
                {
                    "sent": "So once we take these long trails into account as well.",
                    "label": 0
                },
                {
                    "sent": "The noisy clicks tend to become statistically less relevant, so that's one advantage of using browse trails and this is data that we can collect easily from tool world logs, so that's what we in fact do.",
                    "label": 0
                },
                {
                    "sent": "We collect this data from IE toolbar logs.",
                    "label": 1
                },
                {
                    "sent": "So this is not the first name that browse trails are being used.",
                    "label": 0
                },
                {
                    "sent": "It has been previously used for various things, for example Bill and Cohen.",
                    "label": 1
                },
                {
                    "sent": "White used it to find relevant search results and white at all used it to find popular destinations on the web and guide users to those destinations.",
                    "label": 0
                },
                {
                    "sent": "But we are the first ones to use this for this particular particular purpose, which is to annotate web domains or web pages with relevant information.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK. OK, so let let me let me say a few more words about the data that we're using.",
                    "label": 0
                },
                {
                    "sent": "So what's important to note is that we're not mining the content of any of these web pages.",
                    "label": 0
                },
                {
                    "sent": "In fact, we're not even parsing the URLs.",
                    "label": 0
                },
                {
                    "sent": "So these web pages, for all we know are all identical and empty and have some URL which we can represent by just a number.",
                    "label": 0
                },
                {
                    "sent": "So all we are using is just the sequence of these URLs and the query that was initially issued by the user in response to which this browse trail came about.",
                    "label": 0
                },
                {
                    "sent": "So that's all we're using.",
                    "label": 0
                },
                {
                    "sent": "So one obvious question is why aren't we using a richer set of data?",
                    "label": 0
                },
                {
                    "sent": "For example, why not crawl the pages, which as I said?",
                    "label": 1
                },
                {
                    "sent": "Incurs a huge overhead, whereas the data that we are using can come simply for the browser and is much lighter.",
                    "label": 0
                },
                {
                    "sent": "One other option which is slightly lighter than crawling the entire page is to actually parse the URL itself.",
                    "label": 0
                },
                {
                    "sent": "Often URLs contains some information about what they contain, I mean the info about their content and therefore parsing the URL itself might be an option, but what we found is that Benny pages that actually come up in these browse trails are non English language pages or and therefore the URLs do not contain any information about their content or even for English language pages most URLs.",
                    "label": 1
                },
                {
                    "sent": "Tend to be very difficult to parse to extract information about the content.",
                    "label": 0
                },
                {
                    "sent": "Also, we must keep in mind that we have a humongous amount of data to consider, so these as we will show we actually work with almost half a billion browse trails.",
                    "label": 1
                },
                {
                    "sent": "So any additional computation on these browse trails is going to add a huge overhead and we want to avoid that.",
                    "label": 1
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So before I give you an algorithm for annotating the web based on browse trail data, let me give you let's step back and look at some of the salient features of what we're trying to do.",
                    "label": 0
                },
                {
                    "sent": "So firstly, as I said, the importance and similarity of attribute values is heavily dependent on the category of products that the user is looking for.",
                    "label": 0
                },
                {
                    "sent": "For example, dresses and digital cameras will have very different importance values for an attribute like color, so we're restricting ourselves to a single attribute each time.",
                    "label": 0
                },
                {
                    "sent": "For example, we restrict ourselves to either digital cameras or dresses or kitchen appliances and so on, so that the queries are homogeneous set of queries the user is searching for this for various strings, but for the same kind of product.",
                    "label": 0
                },
                {
                    "sent": "We also assume that the query comes annotated with the values of the attributes.",
                    "label": 1
                },
                {
                    "sent": "So for example, a perfect purple Pentax optio query can be parsed into purple and Pentax optio, where purple is the attribute.",
                    "label": 0
                },
                {
                    "sent": "Purple is the value of of the color attribute, and Pentax off Theo is the value of the manufacturer attribute.",
                    "label": 0
                },
                {
                    "sent": "This is this this parser has been developed in search labs itself and we use this parser in our work.",
                    "label": 0
                },
                {
                    "sent": "The final point to note is that we treat each attribute separately, so when we're computing similarity scores, we compute score scores between two values for let's say the color attribute or the manufacturer attributes at a time.",
                    "label": 0
                },
                {
                    "sent": "We're fixing a category and fixing an attribute.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so in the rest of the talk what I will do is give you a very brief and high level overview of the algorithm that we used to annotate web domains based on browse trails.",
                    "label": 1
                },
                {
                    "sent": "I won't give all the details of the algorithm because it's slightly hairy, but what I will do is I'll give you an analytical framework which we use to develop the algorithm and I'll give some analytical results and this framework will involve a set of assumptions, so we will experimentally verify.",
                    "label": 0
                },
                {
                    "sent": "Firstly, we will verify these assumptions.",
                    "label": 0
                },
                {
                    "sent": "And then we will verify the output of the algorithm.",
                    "label": 0
                },
                {
                    "sent": "So first we will see that whether the assumptions are true, and Secondly we will see whether the algorithm produces the right similarity measures.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's start with the algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The idea is extremely simple simple, so the idea is the following.",
                    "label": 0
                },
                {
                    "sent": "If a lot of Canon queries, for example visitor page, then that page must be relevant to Canon.",
                    "label": 1
                },
                {
                    "sent": "So this is a very simple idea, so we use simple frequency counts to annotate webpages.",
                    "label": 0
                },
                {
                    "sent": "Now obviously this just using frequency counts is not sufficient because some of these very popular attribute values like for example, let's say can and will simply swamp everything else.",
                    "label": 1
                },
                {
                    "sent": "So we have to be very careful about how we use the counts.",
                    "label": 0
                },
                {
                    "sent": "But all we need are frequency counts in the algorithm.",
                    "label": 1
                },
                {
                    "sent": "And the final goal is to come up with tables of the following kind.",
                    "label": 0
                },
                {
                    "sent": "So for example, canon.com is likely to be very relevant for Canon queries, but less so for all other brands.",
                    "label": 0
                },
                {
                    "sent": "So can and should have a very high weight in the list of annotations for canon.com for Amazon.com, on the other hand, all popular manufacturers should have a high weight, whereas less popular ones should have lesser smaller weight.",
                    "label": 0
                },
                {
                    "sent": "So these are the kinds of tables we want to construct at the end.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's get to the analytical framework which will help us in designing the algorithm.",
                    "label": 0
                },
                {
                    "sent": "So suppose and this is a simplifying assumption.",
                    "label": 0
                },
                {
                    "sent": "Suppose that each domain has a single unknown relevant attribute value.",
                    "label": 1
                },
                {
                    "sent": "OK, this is an assumption we don't need in the algorithm, but for the purpose of this talk, I'll make this assumption to make things simpler, and we did not.",
                    "label": 1
                },
                {
                    "sent": "For domain D, we did not.",
                    "label": 0
                },
                {
                    "sent": "The actual attribute value SKU of D. This is what we want to figure out.",
                    "label": 0
                },
                {
                    "sent": "This is something we don't know.",
                    "label": 0
                },
                {
                    "sent": "Now if sub QD represents the frequent frequency of browse trails for queries containing attribute value Q that visit domain D, so Q for example, could be can on here.",
                    "label": 1
                },
                {
                    "sent": "Then we can quantify the definitions of similarity unimportance that I described earlier.",
                    "label": 0
                },
                {
                    "sent": "So similarities simply is the relative frequency of queries containing attribute value Q that visit domains for which the correct annotation is Q prime.",
                    "label": 0
                },
                {
                    "sent": "So that's the similarity of Q&Q prime.",
                    "label": 0
                },
                {
                    "sent": "The importance of Q is the relative frequency of queries that have attribute value Q that actually land upon pages.",
                    "label": 0
                },
                {
                    "sent": "Who's correct annotation is Q itself?",
                    "label": 0
                },
                {
                    "sent": "OK, so these are the two quantities that we want to estimate.",
                    "label": 0
                },
                {
                    "sent": "So the overall input is are these frequency counts, which we get from browse trails.",
                    "label": 0
                },
                {
                    "sent": "So how do we process this frequency counts to get the following output?",
                    "label": 0
                },
                {
                    "sent": "So we want the similarity unimportance of similarity of every pair of attribute values and the importance of all attribute values, and we want to do it by via the identification of K of D for all the domains.",
                    "label": 0
                },
                {
                    "sent": "Once we do that, it's very simple, we can just use this formula to do the calculations.",
                    "label": 0
                },
                {
                    "sent": "So as such it so it's fairly easy to show that we don't have sufficient information in the system.",
                    "label": 0
                },
                {
                    "sent": "It's information theoretically impossible to do this annotation, so let's try to make our model A little richer when introducing some assumptions.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for the first assumption, we introduce the notation.",
                    "label": 0
                },
                {
                    "sent": "Let D sub QB domains, which should actually be annotated with Q. OK, who's correct annotation is Q.",
                    "label": 0
                },
                {
                    "sent": "So these are a set of domains that we represent by D. Subq.",
                    "label": 0
                },
                {
                    "sent": "The positive bias assumption roughly says that if a query has contains a keyword Q, let's say a query contains Kanaan, then it is more likely to go to a Canon webpage than to any other web page.",
                    "label": 1
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "That's what I have written in notation there, but essentially the frequencies of Canon query is going to Canon webpages is higher than the frequency of Canon queries going to say Pentax web pages, so that's our first assumption.",
                    "label": 0
                },
                {
                    "sent": "So for the second assumption again, we need some notation let N, sub, QQ prime be the set of queries that contain Q, But actually end up on web pages is correct annotation is Q prime.",
                    "label": 0
                },
                {
                    "sent": "An insert Q are all queries that contain Q, the total frequency.",
                    "label": 0
                },
                {
                    "sent": "So what the uniformity assumption says is that if you fix a keyword Q and look at only queries containing Q and then fix the, then consider the set of web pages.",
                    "label": 0
                },
                {
                    "sent": "The who's correct annotation is Q prime, then the.",
                    "label": 0
                },
                {
                    "sent": "Then the query visit patterns of these queries over this set of web pages is more or less uniform, and again that's what I have written in notation.",
                    "label": 1
                },
                {
                    "sent": "There, we introduce we make this parameterized using Alpha and Delta, so that it's somewhat robust.",
                    "label": 1
                },
                {
                    "sent": "Our final assumption is what we call proportionality.",
                    "label": 1
                },
                {
                    "sent": "This roughly says that keywords that are popular in queries are also popular in domains.",
                    "label": 0
                },
                {
                    "sent": "So if Canon is a popular query term, then the web would contain more pages with correct annotation.",
                    "label": 0
                },
                {
                    "sent": "Is Canon and again we make this robust by making it parameterized, introducing parameters, beaten, So for the rest of.",
                    "label": 0
                },
                {
                    "sent": "So for what I'll say later, think of Alpha, Delta, beta and Gamma as as numbers fairly close to 1.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sermon analytical result is the following theorem.",
                    "label": 0
                },
                {
                    "sent": "We give an algorithm that annotates each domain with a list of attribute values and we denote it by L sub D such that it satisfies the following properties.",
                    "label": 1
                },
                {
                    "sent": "The first property is what we call completeness, so if the correct annotation of a domain is Q.",
                    "label": 1
                },
                {
                    "sent": "And Q is an important attribute.",
                    "label": 0
                },
                {
                    "sent": "Then the list must contain Q.",
                    "label": 0
                },
                {
                    "sent": "It doesn't miss any important attribute.",
                    "label": 0
                },
                {
                    "sent": "The second is soundness, which says that if the correct annotation of a domain is Q.",
                    "label": 0
                },
                {
                    "sent": "But some other keyword Q prime is contained in its list.",
                    "label": 0
                },
                {
                    "sent": "Then the similarity of Q2 Q prime must be high, roughly Theta square.",
                    "label": 0
                },
                {
                    "sent": "Healthy dubbing apparel parameter for completeness.",
                    "label": 0
                },
                {
                    "sent": "So the first one says that we don't miss an important attribute.",
                    "label": 0
                },
                {
                    "sent": "The second one says that we don't introduce attributes that are very dissimilar in the list.",
                    "label": 0
                },
                {
                    "sent": "And the final assumption is is largely for efficiency purposes, so we don't want these lists list to be extremely large, so we show that the average length of each list is roughly one over Theta.",
                    "label": 0
                },
                {
                    "sent": "So read that as one over Theta, because all these quantities are close to theater.",
                    "label": 0
                },
                {
                    "sent": "In fact, this is information theoretically tight, you cannot do anything better than this.",
                    "label": 0
                },
                {
                    "sent": "So I won't give a proof of the theorem.",
                    "label": 0
                },
                {
                    "sent": "I won't give the description of the algorithm itself, but.",
                    "label": 0
                },
                {
                    "sent": "But this is the main analytical result that we prove in the paper, and the paper contains all details.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in the rest of the talk, instead of giving a proof, let me try to show you how we experimentally validated our technique.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So before we go to the experiments, one immediate issue is the scalability of our ideas.",
                    "label": 0
                },
                {
                    "sent": "So there are a lot of domains and each domain has a lot of different queries for various different attribute values.",
                    "label": 0
                },
                {
                    "sent": "Visiting it.",
                    "label": 0
                },
                {
                    "sent": "So do we actually maintain tables for all of these?",
                    "label": 0
                },
                {
                    "sent": "Well, we don't because it's too much, too much data.",
                    "label": 0
                },
                {
                    "sent": "All we do is we maintain tables only for very frequently visited domains and also for a particular domain.",
                    "label": 1
                },
                {
                    "sent": "We only consider frequent.",
                    "label": 0
                },
                {
                    "sent": "Attributes, and this is fairly simple to do, even if the browse trails are not in memory.",
                    "label": 0
                },
                {
                    "sent": "If they come in a stream using standard techniques like heavy hitters or reservoir sampling.",
                    "label": 1
                },
                {
                    "sent": "So in fact, in fact we run our algorithms on almost half a billion browse trails and it runs in less than an hour, so it's fairly efficient and scalable.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the first set of experiments were to validate our assumptions.",
                    "label": 0
                },
                {
                    "sent": "Remember that we had three assumptions in our analytical model to validate these assumptions.",
                    "label": 0
                },
                {
                    "sent": "We used browse trails on Amazon.com.",
                    "label": 1
                },
                {
                    "sent": "Now the advantage with using pages on Amazon.com is that the URL contains sufficient information about the product that's on the page and therefore we know the correct annotation from just by parsing the URL we compare it with what the algorithm does and we found that for positive for validating positive bias, which.",
                    "label": 0
                },
                {
                    "sent": "We have looked at the distribution of queries containing a particular keyword Q visiting all kinds of various web various web pages on on Amazon.com and found that they mostly visited domains which are also which also contain products relevant to Q.",
                    "label": 0
                },
                {
                    "sent": "For uniformity, we fixed Q&Q prime.",
                    "label": 0
                },
                {
                    "sent": "That's that's what the assumption says.",
                    "label": 0
                },
                {
                    "sent": "And then we looked at the distribution of queries containing Q on web pages annotated with Q prime, and this distribution had high entropy, which means that it was roughly uniform.",
                    "label": 1
                },
                {
                    "sent": "And finally for proportionality, we looked at the relative frequency of an attribute value in both queries and product pages on Amazon.com, and these were very highly correlated or close to proportional.",
                    "label": 1
                },
                {
                    "sent": "So these were the first set of experiments we.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then the second set of experiments were to test how good our algorithm was in computing similarity scores.",
                    "label": 0
                },
                {
                    "sent": "And here we use the data set from IE8, browse trails for six months, which contains roughly half a billion browse trails.",
                    "label": 1
                },
                {
                    "sent": "In fact, a 63% of these trails had length more than one, so that validates our assumption that browse trails which are long, contain useful information or browse fields in general, contain more useful information than single clicks.",
                    "label": 0
                },
                {
                    "sent": "Now the categories we used were were some of these were the.",
                    "label": 0
                },
                {
                    "sent": "These are some of the examples of categories we use, digital cameras, laptops, kitchen appliances and so on.",
                    "label": 1
                },
                {
                    "sent": "And some of the attributes that we looked at were manufacturer, product line etc.",
                    "label": 0
                },
                {
                    "sent": "So these are these are quite standard ones.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how did we verify your similarity or evaluate our similarity values?",
                    "label": 0
                },
                {
                    "sent": "First, we ran our algorithm and computer similarity values.",
                    "label": 0
                },
                {
                    "sent": "Then we used human judges through Amazon's Mechanical Turk to compute similarity rankings.",
                    "label": 1
                },
                {
                    "sent": "What does the similarity ranking mean?",
                    "label": 0
                },
                {
                    "sent": "Well, we fixed.",
                    "label": 0
                },
                {
                    "sent": "Fix the keyboard and then looked at and ask the human judges to rank all other keywords by similarity to that keyword.",
                    "label": 0
                },
                {
                    "sent": "And we compared these two lists, the one that the algorithm computes and the human and one computed by a human judge, and it turns out that these lists were very close.",
                    "label": 0
                },
                {
                    "sent": "In fact, their deviation was roughly 4 to 5% of what the maximum deviation could be.",
                    "label": 0
                },
                {
                    "sent": "So I'll skip some anecdotal examples of similarity and importance values because I don't have time.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And go to some other applications of our techniques.",
                    "label": 1
                },
                {
                    "sent": "Firstly, we can use these lists to indicate which domains are good for what kind of product.",
                    "label": 1
                },
                {
                    "sent": "For example, Best Buy might be better for plain text and Canon cameras.",
                    "label": 1
                },
                {
                    "sent": "We can also use this for product diversification.",
                    "label": 0
                },
                {
                    "sent": "Note that importances and similarity have a very close relation to relevance and novelty, which is used in product.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Versification.",
                    "label": 0
                },
                {
                    "sent": "And in future work we would like to study more carefully what the dependencies between different attributes are.",
                    "label": 1
                },
                {
                    "sent": "Not that what we did work for single attributes, but often attributes are very dependent.",
                    "label": 1
                },
                {
                    "sent": "And how do we handle them in these techniques?",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}