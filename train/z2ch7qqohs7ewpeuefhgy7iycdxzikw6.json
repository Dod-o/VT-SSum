{
    "id": "z2ch7qqohs7ewpeuefhgy7iycdxzikw6",
    "title": "Salience Assignment for Multiple-Instance Regression",
    "info": {
        "author": [
            "Terran Lane, Department of Computer Science, University of New Mexico"
        ],
        "published": "June 24, 2007",
        "recorded": "June 2007",
        "category": [
            "Top->Computer Science->Machine Learning->Regression"
        ]
    },
    "url": "http://videolectures.net/icml07_lane_safm/",
    "segmentation": [
        [
            "OK, so thanks to the workshop organizers for getting this all together and inviting us to do this.",
            "And thanks for all of you for hanging on all the way through the conference and to the very last last day for the workshop.",
            "So this is some work that I did with my colleague Karey Wigwag stuff at JPL.",
            "On multiple instance regression, or specifically on salience assessment.",
            "And we'll talk about what that means in a second here."
        ],
        [
            "So Carey found this really nice problem that motivated this work.",
            "Which is the US Department of Agriculture is interested in knowing crop yield on a per County basis across the US.",
            "Specifically, they actually record this data.",
            "They measure crop yield on a per County basis, but they want to be able to predict it early in the year.",
            "So like in February, they want to predict what the harvest is going to look like in June or so so that they can target agricultural efforts and so early prediction is nice.",
            "So this is a map of Kansas in I think the captions are gonna think this is actually 2004 and the each one of these little squares is accounting in Kansas and the scale here is the crop yield.",
            "This is for corn in, measured in bushels per acre.",
            "And we can see that most of the corn production is concentrated down here in the Southwest corner of the state."
        ],
        [
            "But if we look at wheat production, it's concentrated over here, so there's this geographic dispersion of where these things are produced."
        ],
        [
            "The data that we have to work with to do this task is remote sensing data from the MODIS ground sensing satellite.",
            "It's multi spectral data.",
            "I think it senses 7 bands, of which we're using to the red in the near infrared bands in the pixels it reads are are squares, 250 meters on a side.",
            "So clearly this is much smaller than the size of a County.",
            "Satellite flies stripes around the earth and so it images these bands and every pixel gets imaged every eight days.",
            "So you get about 46 readings per pixel per year."
        ],
        [
            "OK, so so what's the challenge here?",
            "Where is the hard part?",
            "So the big problem?",
            "The core problem really that makes us a multiple instance thing is that every County is made up of multiple pixels in a variable number depending on the size of the County.",
            "And yet we only have a single regression targ."
        ],
        [
            "Fridge County right.",
            "So it's bag data, so here's an example.",
            "This is Cheyenne County in Kansas.",
            "In what you're seeing is a pseudocolor image of a normalized vegetation index, pixel by pixel across the entire County, and I think in this County there's somewhere in the vicinity of 40,000 pixels in some California counties there are upwards of 300,000 pixels, so you get this bag of pixel data that's associated with a single real value label, and there's clearly some spatial structure in here.",
            "There's this sort of diagonal here, which will see again in a little bit.",
            "We see that there's a lot of vegetation down here, very little vegetation up here.",
            "This is imaged at April 16th, which is turns out to be corn planting date, so the corn hasn't begun to grow yet.",
            "So the green stuff you see here is not corn."
        ],
        [
            "If we look forward a little bit, this is in June, which is at the wheat harvest date, right?",
            "And so now we've lost all this vegetation up here.",
            "We can infer that might be wheat.",
            "This diagonal remains that turns out to be a River, right?",
            "There's a lot of structure still down here, but if we look down in this quadrant, we can see that there's sort of a consistent flip flop from green to blue, right?",
            "So overtime, we've gone from the fields being almost empty to the fields being completely full.",
            "Um?"
        ],
        [
            "So there's a lot of structure in the data, But the problem is that we don't really understand what the relationship between individual pixels and the regression target.",
            "It's.",
            "I mean, if we knew which pixels we pixels in which pixels or pixels would have the problem solved essentially.",
            "But that information isn't given to us, so that's what we have to infer.",
            "So what we're interested in in this work is pixel salience, or how relevant is each pixel to the regression target that we're working on at the moment, and it boils down to weed is grown in different places and corn, and there are a bunch of things that are neither wheat nor corn, so you know there's rivers, their cities, right there, soybeans?",
            "So we have to in some way tease that apart.",
            "So just as an example here, time traces of three pixels drawn not entirely at random.",
            "Out of Kansas in 2001, so this is the time course, so we watch the evolution over the year and this is again the vegetation index and we see that we get very different characteristic curves for the three different pixels, right?",
            "So this one down here is almost flat.",
            "That's probably something that's not vegetative at all, like water or city, right?",
            "But these reflect very different types of plant matter, right?",
            "That peak at different times in the year.",
            "Possibly Wheaton corn, but possibly something else."
        ],
        [
            "OK, so the problem that we would really like to be able to solve is the full on multiple instance regression problem, which is, you know, given a set of bags that have counties made up of some set, you know some data items or pixels.",
            "We'd like to be able to predict real valued labels or yields for each County.",
            "This turns out to solve in its full glory.",
            "This turns out to be trickier than it looks.",
            "So what in this paper we concentrate on a sub task.",
            "The salience assignment task which is given a set of bags.",
            "Made up of data items and the labels, so that's part of the training data.",
            "We want to find the salience of each data item.",
            "Two predicting the data label within the training data, right?",
            "So we're not doing generalization to new bags were just trying to understand is which pixels go with the label that we're working on this.",
            "This makes it essentially an unsupervised learning problem, right?",
            "We don't have.",
            "We don't have that data.",
            "It's not.",
            "We don't have ground truth on these things."
        ],
        [
            "Um?",
            "OK, so of course people have looked at this variations on the multiple instance learning problem a lot previously.",
            "Starting with, you know the classic multiple instance learning paper and the core assumption here is that if there's one or more positive items in a bag, then it's a positive bag.",
            "If there are no positive items in a bag, that's a negative peg.",
            "And the focus here is really on classification.",
            "So doing positive negative tags.",
            "A relevant recent extension is the Miles algorithm, which extends it from thinking about single items to thinking about sets.",
            "So if there's a small set of items that relate to the label, we can call a big positive, but again, this is classification only.",
            "The work that's most closely related to us as the primary instance.",
            "Regression work by rampage.",
            "Here the assumption is that there's a single data item in the bag that can be used to predict the label.",
            "And and their job is really to find this exemplar point, and then once they found the exemplar points, they can make the regression estimate.",
            "The trick is that it turns out that they don't have a good way to find exemplars for new bags, right?",
            "So this is essentially the reason that extending to the full generalization regression problem is hard, and it's the same problem we face.",
            "Alright, so our extension is going to be to relax this and you know to beat our heads against this without success at the moment."
        ],
        [
            "OK, so to to understand the optimization function that we come up with.",
            "Let's begin by looking at the sort of geometry of a bag.",
            "So we have some some feature space here.",
            "A bag is a set of points."
        ],
        [
            "In this feature space and when you consider the regression target, write this."
        ],
        [
            "Is an orthogonal axis in our bag of data can?"
        ],
        [
            "Be thought of as a set of points in a plane.",
            "You know at the level of the regression target for the bag.",
            "And so a second bag is now."
        ],
        [
            "Second set of points at a different regression level and our goal is to find hyper."
        ],
        [
            "Plane or some other surface that in some sense fits well through.",
            "You know these different bag data OK."
        ],
        [
            "So the question becomes, which points should we use for the to base that regression on?",
            "And there's a lot of possibilities, right?",
            "So one sort of obvious thing one can do is simply take the mean or centroid of all the data, right?",
            "Just average everything together, but that doesn't really make a lot of sense in this case, because now you're averaging corn pixels with wheat pixels with city and soybeans and water and everything like that.",
            "So you'd like to do something more intelligent.",
            "So what Pier does is, you know, work to pick a best data item to pick this exemplar point.",
            "What we're going to do is pick a weighted mean point, right?",
            "And the reason we want to do this is because we really are interested in how relevant each point is.",
            "Each pixel is to the final classification, and we can interpret the weights of the of the data items as being those salience values, right?",
            "So things with an almost zero contribution to the exemplar.",
            "Can be thought of as having no contribution to the to the class label or to the regression label."
        ],
        [
            "OK, so so the key problem then becomes picking this exemplar and figuring out the weighted combination.",
            "So let's look at a single bag of data, which I'm going to denote capital BF B, with the superscript K. Just saying this is the case.",
            "Bag out of some arbitrary set of eggs.",
            "Let's think a little bit about what we'd like of the exemplar point.",
            "What we don't want is for the exemplar point to be way out here, right?",
            "If you allow an arbitrary.",
            "Linear combination of the of these pixels.",
            "Then you could end up with a point way out here, in which case the bag essentially has no influence on the label whatsoever, right?",
            "So what we really want is for the point to be somewhere within the bounds of the bag, so we're going to impose a simplex constraint or a convex Hull constraint, which we convert a simplex constraint.",
            "So we're going to enforce that the exemplar point falls somewhere within the convex Hull of our bag.",
            "So this leaves us with the problem.",
            "Find a vector of weights.",
            "So this is going to be our salience weights such that the exemplar formed by the weights in the data falls within the convex Hull of the bag and that the exemplar is good in a regression sense with respect to modeling the target.",
            "And then this vector Alpha K is going to be our salience factor.",
            "This is going to tell us tell us how relevant each point is to predict in the bag label and note that this is Alpha to the case.",
            "So there's one.",
            "There's one of these vectors for every bag, right?",
            "So we get a unique salience assignment out for each bag in our data set.",
            "Um?",
            "OK, so this leads us to formulating the following objective.",
            "Oh sure.",
            "Thanks.",
            "Images right?",
            "Yeah, they are.",
            "There's a huge amount of spatial information here that we could take advantage of, and we haven't yet.",
            "We've treated them as sort of undifferentiated piles.",
            "Piles of things right with, you know, the fact that their pixels, you know we should take advantage of but haven't yet, but we expect.",
            "Not necessarily.",
            "I mean, we'd expect him to be the same within a single year, but it turns out that across years it's going to change because they rotate crops.",
            "So a field that's a wheat crop this year is going to be a corn crop next year and going to follow another year, right?",
            "And if we knew which ones were which, we, you know, we could get a lot of advantage out of that.",
            "But then we would essentially have the salience is right.",
            "Question.",
            "So at the beginning you said the element objective is to predict the average yield of particular crops for particular counties, right?",
            "Seems that.",
            "The straightforward way it is when I'm straight forward would be to try and predict the average yield per pixel and then average over the pixels in accounting to get the average year for the County.",
            "You don't actually have a target.",
            "You don't actually have a target label for each pixel, but you do have a target label County, and so you can do some sharing of targets over the pixels and also use a structured supervised learning approach to make the predictions for neighboring pixels be similar.",
            "But This is why people use, for example, if we want to predict, say, health prices, so you build a regression predicted value of each house.",
            "Sharing between neighboring houses because everything else.",
            "Right, yeah?",
            "OK, so that approach makes sense, but it seems like you know, you know, have sort of the converse problem.",
            "So what we're trying to do is share relevance among pixels, and in your approach, I think what you have to do is share yield among pixels, and so you still have to solve this problem of how much yield do I assign to every pixel?",
            "The smoothing across local pixels is a good idea, but there's a lot of structure here that might complicate that.",
            "For example, neighboring fields aren't constrained to both be the same crop.",
            "Right, they can.",
            "They can be different crops, so you can have these sharp discontinuity's.",
            "But I mean your approach makes sense and it's a thing that we should consider.",
            "If you are sharing yield, at least yield is a well defined concept, like I can't say that I understand what the definition of salience is in this case.",
            "Right?",
            "Well when we go through the objective function will become a little bit clearer, but essentially it's.",
            "You know what?",
            "What fraction of each data point?",
            "Can be what fraction of each pixel should we use to predict the regressor for the entire County?",
            "Any other questions over here?",
            "OK."
        ],
        [
            "Right, so this is the objective that we're going to work with, so we're going to minimize this F. So W is our weight vector.",
            "Whatever parameters for regression model at the moment, we're just using a linear regressor, which is known to be only.",
            "So.",
            "So for this data.",
            "But you know, it's easy.",
            "I think it's this is extendible without too much trouble to more sophisticated regressors, right?",
            "And this is the set of our our vectors that we want.",
            "These are ultimately the targets that we care about getting out.",
            "So I."
        ],
        [
            "So this is our objective function.",
            "It doesn't look too bad.",
            "It's very least squares looking.",
            "Here's our label for Bag K, right?",
            "So everybody gets a single label.",
            "There's are bad data for K right?",
            "In this product.",
            "BK Alpha K is the exemplar for bad K. It's the weighted mean of the data in bag K where the weights are given by the salient factor.",
            "So this is what the salience really means, right?",
            "It's this weighted combination.",
            "And so every point contributes a sort of Alpha fraction to this exemplar.",
            "And then altogether we have our error.",
            "It's a simple squared error function, so this is the error in curd if you used.",
            "This exemplar with these weights to estimate this value."
        ],
        [
            "And in order to get the convex Hull constraint we have this simplex constraint, which says that you know boils down to the point must fall somewhere within the convex hole and every so the sum of all alphas has to be one the office has to be greater than zero, so you could interpret this as being sort of the fraction of each pixel it contributes to the exemplar or the probability of each pixel contributing the example or something."
        ],
        [
            "OK, so it turns out that while it's a nice, fairly clean form, solving it directly is not easy if you try to solve with respect to both Alpha and W simultaneously, it's really a mess.",
            "And it boils down to the objective function is indefinite in a combination of W and Alpha simultaneously right there for exact minimization of this thing is NP hard, which is a result that was consistent with Ray and pages finding on their formulation.",
            "Darn, but you know, being good machine learning hacker's a little thing like NP.",
            "Hardness doesn't stop us."
        ],
        [
            "Um?",
            "So you know the obvious observation, when you sit down and look at this for a little bit is that you know this is very least squares ish, right?",
            "You know so it should have a nice solution in some sense.",
            "And in fact if you freeze Alpha K then the solution is just the standard least squares solution that's in all the textbooks.",
            "And Conversely, if you freeze W you can solve for a single Alpha K, which is again least squares ish.",
            "But you have these simplex constraints so that forces it to be a quadratic program.",
            "But you know, there's a MATLAB subroutine for that, so that shouldn't trouble."
        ],
        [
            "So that leads to the following iterative algorithm.",
            "The APC salience algorithm.",
            "So you take his input, your bag data in your bag, labels an as output.",
            "You're going to turn your regression model, and your salient factors for alfaques.",
            "So we're going to begin by picking random W. This is because of the NP hardness, so you can do random restarts if you like, and then you enter the following iteration.",
            "So first you go over all the bags for each bag you solve the resulting quadratic program using the fixed W that you started with here right?",
            "And you find the best Alpha K. So this is the Alpha K that under that assumption of regression model, this is the weight vector that best allows you to predict.",
            "The output or produces the best exemplar with respect to that model, right?",
            "And then having fixed the alphas, you can solve the remaining objective function using least squares closed form to find the best regression model under the assumption that those are the correct salience assignments, and you keep doing this until you converge."
        ],
        [
            "So the question is, should this converge?",
            "Well, it feels very M like, but we haven't talked about any sort of generative model.",
            "There's no obvious expectation in here.",
            "It turns out that you can think about this one way of thinking about this anyways.",
            "In terms of something called an alternating projections algorithm, which is very familiar in the optimization community, but I haven't seen floating around machine learning so much, so I thought I'd introduce it a little bit.",
            "It's a solution to a convex feasibility problem.",
            "That is, find me a feasible point for point in the intersection of a bunch of convex sets.",
            "These things have a history that goes back to Von Neumann, but you know, I only ran into him last year.",
            "This is a nice survey paper on the stuff right there.",
            "They're sort of very similar in flavor to M and I think that there's probably a deep connection that I haven't fully explored, but they're really motivated by geometric considerations rather than by stochastic ones, so you don't have to have a generative model.",
            "There doesn't have to be a probability, assumption or expectation.",
            "All you really need or convex sets and projection operations.",
            "So in this case."
        ],
        [
            "Is the point that we want to find the critical point of our objective right so it works like this?",
            "So suppose I give you in this case 3 arbitrary convex sets in some space, and our goal is to find a point in the intersection so point in that little area down there we begin by choosing an arbitrary point and taking an orthogonal projection onto one set right from there, taking orthogonal projection onto another set right, and so on, right?",
            "And you just keep doing this, and eventually you end up down there.",
            "You're guaranteed end up, down there in the intersection.",
            "OK, so given this."
        ],
        [
            "Look back at the algorithm, the iterative algorithm and and try to understand it in this context.",
            "So this is the core loop section.",
            "It turns out that this step you can think of as being a projection onto the zeros of the partial derivative of F of our objective with respect to Alpha K right?",
            "In this step, down here is a projection onto the zeros with respect to the derivative with respect to W, right?",
            "So what we're finding is a point that's simultaneously a critical point with respect to Alpha and with respect to W. Which is a critical point of the complete objective.",
            "Now all I'm guaranteeing is that we found is 0 right?",
            "I'm not guaranteeing that we found, you know.",
            "On optimum right or else we would have proved that P equals NP.",
            "So we found some critical point.",
            "You could do a second derivative test at this point to determine whether your Max men saddle point or something like that.",
            "But the nice thing is that we've got a guarantee of convergence to some sort of reasonable point."
        ],
        [
            "OK, so that's all very nice, but does it actually work?",
            "So we looked at this on four years of this ground sensing data from drawn from California in Kansas, California is considerably fewer counties reporting yields for corn and wheat.",
            "These counties are really big.",
            "Like I said, some of them have 300,000 pixels and our algorithm you know you have to solve multiple QPS per iteration, so it's a wee bit slow, so we randomly sample 100 pixels from each County and then we compare it to the pier method.",
            "The rain page method they recommended random restarts for their methods.",
            "We did 10 random restarts for them.",
            "For our method we only chose the one initial random W vector and only ran it once.",
            "Now we."
        ],
        [
            "Call that this is essentially an unsupervised learning problem, so evaluation is going to look very unsupervised ISH, and I can't give you, you know, in our MSE plot.",
            "So here's a plot of one of the counties.",
            "This is Jewell County, Kansas in 2001.",
            "Latitude lanja tude.",
            "Each of these circles is one of our hundred pixels that we drew in the color scale.",
            "Is the salience that we assign right so darker pixels here are things that we consider to be more salient or receive higher weight lighter pixels of things that receive little or no wait.",
            "And the Red Cross is the exemplar point picked by the pier algorithm in the first interesting thing first.",
            "Useful thing to note is that there's a distinct clustering into this corner of the salient things, and that it coincides with the pixel that rampage picked.",
            "If we look at the wheat, if we look at the same same County, same pixels.",
            "Now trying to predict wheat, we're trying to model.",
            "Wait, we find a very different distribution.",
            "Now we get most of the clustering down here in the lower left corner an rampages pixel pops out in a very different place than this.",
            "One.",
            "Nice thing about this is that we get we do get spatial clustering which one might expect right?",
            "The second thing about this is that you get very different distributions for the two regression targets.",
            "That tells you that you are finding something about.",
            "The regression target.",
            "And that and that, the salience vectors that pop out do depend on on the goal target here.",
            "So a second way of evaluating this, right?"
        ],
        [
            "Is to look at stability estimate overtime.",
            "So the notion here is that while crop fields may change and rotate from year to year within a single year, a single pixel is only going to be corn or wheat, right?",
            "And it's not going to change its membership within a year.",
            "So if we look across a year right and we build a model on the first time point, then the first two time points in the first three time points and so on, we should expect those models to be consistent with each other and have roughly the same shape.",
            "And So what we did is measure.",
            "How much the model changes over the course of a year, right?",
            "And there's a stability measurement based on an entropy measure on because so we measured it both for the peer algorithm for ours, because peer only picks a single exemplar point.",
            "We to be fair, we only picked an example or point out of our model.",
            "We picked the maximally salient point that was produced by our algorithm, and So what we plot here is our means.",
            "Stability measure overall counties in Kansas and up is good.",
            "Up is more stable and so we see that in this case, the AP salience algorithm.",
            "The yellow one has a significantly more stable model over the course of a year then peer does.",
            "What this tells us is that the model that's picking tends to remain stable over the course of the year.",
            "We tend to be getting the same thing back over the year."
        ],
        [
            "When we look across California and corn, three out of the four times the story remains true in only in this case down here, California corn does peer consistently come out with a more stable model that also turns out to be the case with the fewest yield.",
            "Reporting counties, right?",
            "So there's some sense much less data here than there is up over here.",
            "OK, so um, so it's a fairly nice story, but where are we going with the next?",
            "Well, what we ultimately want to do is tackle regression problem, but there's a sort of chicken and egg problem here, which is that we can't get these salient factors without having label, and we don't have the label for under previously unseen bags, so we have no way to get the salience is so we can't build the model and so on, right?",
            "So the approaches that we'd like to take to.",
            "Tackless, we're currently working on the first thing is to generalize the salience is that is, if we can find the pixels in our new bag that are very similar to pixels in existing bags right, then maybe we can transfer salience is from existing bags to new bags.",
            "And the second thing that we're looking at is to take a set kernels approach and sort of abandoned.",
            "The salience is altogether.",
            "Salience is are very nice because they tell us things about the structure of the data in an unsupervised way and they can, you know, sort of tell you where corn is going on where we just going and so on.",
            "But if we really want to do is regres maybe all we want to do is construct a kernel.",
            "It can take 2 bags right and return to Colonel inner product between the two bags and then plug that into your favorite support vector regression method and out pops an answer hopefully so far.",
            "You know our early efforts on this haven't been successful, but we're still following, so that's the story.",
            "Thank."
        ],
        [
            "Well, very much for listening and I'll take any questions.",
            "I can understand why it's not.",
            "OK, well those would be good good things to try, but.",
            "Yeah, so I guess in this case what we're really looking for is sort of how much we're really looking for this model over the pixels, so I guess you could interpret the feature selector.",
            "You know the output of the feature selector is giving you that.",
            "But what we don't want is sort of dimensionality reduction of it, because then you get this sort of weird mixture of the pixels we want to be able to say for each pixel.",
            "This ones a cornfield in this ones Wheatfield, right?",
            "And so on.",
            "Soft weight on everything.",
            "Yeah, software on every pixel rather than mix rather than a mixture of the pixels.",
            "Yeah so.",
            "I'm sorry, can't quite hear you.",
            "You have a lot of his outlook papers, yeah?",
            "Right?",
            "So it seems like you could look at me Maps of the counties.",
            "Rap songs field.",
            "Right, yeah, Ann, you're right that there are a lot of spatial and geometric constraints that we could take advantage of.",
            "What we were fairly happy about in this case was that.",
            "Without putting any of that information and you still get you know something like a spatial clustering out, right?",
            "So it feels like we're, you know, there's something that's being pulled out purely out of the pure layout of the objective task, right?",
            "Without having to go in and add these spatial constraints.",
            "So right, so?",
            "I.",
            "You know, this feels like it's a little bit more knowledge free and you could apply it to other problems than just ground sensing problems.",
            "But you're right.",
            "I mean, you know ultimately this is preliminary work, right?",
            "So ultimately you know to to tackle this more thoroughly.",
            "Would we like to get in some of the spatial distribution stuff?",
            "Right, so each pixel we have two bands of spectral imaging data.",
            "We have a red bandana near infrared band, right?",
            "So each pixel is 2 dimensional and then what we have here are time series.",
            "Another thing we'd like to do is get a real temporal model end, so get some of the Markov.",
            "Transition dynamics of pixels overtime, but for the moment what we're doing is just concatenating time points together.",
            "So, for example, this is training data from January 1st to February 18th.",
            "So for each pixel we took its two values at each of the time points and concatenated together.",
            "I think this is like seven or eight time points.",
            "This is like you know, 14 or 16 dimensional vector.",
            "Any other questions?",
            "OK, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so thanks to the workshop organizers for getting this all together and inviting us to do this.",
                    "label": 0
                },
                {
                    "sent": "And thanks for all of you for hanging on all the way through the conference and to the very last last day for the workshop.",
                    "label": 0
                },
                {
                    "sent": "So this is some work that I did with my colleague Karey Wigwag stuff at JPL.",
                    "label": 0
                },
                {
                    "sent": "On multiple instance regression, or specifically on salience assessment.",
                    "label": 0
                },
                {
                    "sent": "And we'll talk about what that means in a second here.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So Carey found this really nice problem that motivated this work.",
                    "label": 0
                },
                {
                    "sent": "Which is the US Department of Agriculture is interested in knowing crop yield on a per County basis across the US.",
                    "label": 1
                },
                {
                    "sent": "Specifically, they actually record this data.",
                    "label": 0
                },
                {
                    "sent": "They measure crop yield on a per County basis, but they want to be able to predict it early in the year.",
                    "label": 0
                },
                {
                    "sent": "So like in February, they want to predict what the harvest is going to look like in June or so so that they can target agricultural efforts and so early prediction is nice.",
                    "label": 1
                },
                {
                    "sent": "So this is a map of Kansas in I think the captions are gonna think this is actually 2004 and the each one of these little squares is accounting in Kansas and the scale here is the crop yield.",
                    "label": 0
                },
                {
                    "sent": "This is for corn in, measured in bushels per acre.",
                    "label": 0
                },
                {
                    "sent": "And we can see that most of the corn production is concentrated down here in the Southwest corner of the state.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But if we look at wheat production, it's concentrated over here, so there's this geographic dispersion of where these things are produced.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The data that we have to work with to do this task is remote sensing data from the MODIS ground sensing satellite.",
                    "label": 1
                },
                {
                    "sent": "It's multi spectral data.",
                    "label": 0
                },
                {
                    "sent": "I think it senses 7 bands, of which we're using to the red in the near infrared bands in the pixels it reads are are squares, 250 meters on a side.",
                    "label": 0
                },
                {
                    "sent": "So clearly this is much smaller than the size of a County.",
                    "label": 0
                },
                {
                    "sent": "Satellite flies stripes around the earth and so it images these bands and every pixel gets imaged every eight days.",
                    "label": 0
                },
                {
                    "sent": "So you get about 46 readings per pixel per year.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so so what's the challenge here?",
                    "label": 0
                },
                {
                    "sent": "Where is the hard part?",
                    "label": 0
                },
                {
                    "sent": "So the big problem?",
                    "label": 0
                },
                {
                    "sent": "The core problem really that makes us a multiple instance thing is that every County is made up of multiple pixels in a variable number depending on the size of the County.",
                    "label": 1
                },
                {
                    "sent": "And yet we only have a single regression targ.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Fridge County right.",
                    "label": 0
                },
                {
                    "sent": "So it's bag data, so here's an example.",
                    "label": 0
                },
                {
                    "sent": "This is Cheyenne County in Kansas.",
                    "label": 1
                },
                {
                    "sent": "In what you're seeing is a pseudocolor image of a normalized vegetation index, pixel by pixel across the entire County, and I think in this County there's somewhere in the vicinity of 40,000 pixels in some California counties there are upwards of 300,000 pixels, so you get this bag of pixel data that's associated with a single real value label, and there's clearly some spatial structure in here.",
                    "label": 0
                },
                {
                    "sent": "There's this sort of diagonal here, which will see again in a little bit.",
                    "label": 0
                },
                {
                    "sent": "We see that there's a lot of vegetation down here, very little vegetation up here.",
                    "label": 0
                },
                {
                    "sent": "This is imaged at April 16th, which is turns out to be corn planting date, so the corn hasn't begun to grow yet.",
                    "label": 0
                },
                {
                    "sent": "So the green stuff you see here is not corn.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If we look forward a little bit, this is in June, which is at the wheat harvest date, right?",
                    "label": 0
                },
                {
                    "sent": "And so now we've lost all this vegetation up here.",
                    "label": 0
                },
                {
                    "sent": "We can infer that might be wheat.",
                    "label": 0
                },
                {
                    "sent": "This diagonal remains that turns out to be a River, right?",
                    "label": 0
                },
                {
                    "sent": "There's a lot of structure still down here, but if we look down in this quadrant, we can see that there's sort of a consistent flip flop from green to blue, right?",
                    "label": 0
                },
                {
                    "sent": "So overtime, we've gone from the fields being almost empty to the fields being completely full.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So there's a lot of structure in the data, But the problem is that we don't really understand what the relationship between individual pixels and the regression target.",
                    "label": 1
                },
                {
                    "sent": "It's.",
                    "label": 0
                },
                {
                    "sent": "I mean, if we knew which pixels we pixels in which pixels or pixels would have the problem solved essentially.",
                    "label": 0
                },
                {
                    "sent": "But that information isn't given to us, so that's what we have to infer.",
                    "label": 0
                },
                {
                    "sent": "So what we're interested in in this work is pixel salience, or how relevant is each pixel to the regression target that we're working on at the moment, and it boils down to weed is grown in different places and corn, and there are a bunch of things that are neither wheat nor corn, so you know there's rivers, their cities, right there, soybeans?",
                    "label": 1
                },
                {
                    "sent": "So we have to in some way tease that apart.",
                    "label": 0
                },
                {
                    "sent": "So just as an example here, time traces of three pixels drawn not entirely at random.",
                    "label": 0
                },
                {
                    "sent": "Out of Kansas in 2001, so this is the time course, so we watch the evolution over the year and this is again the vegetation index and we see that we get very different characteristic curves for the three different pixels, right?",
                    "label": 0
                },
                {
                    "sent": "So this one down here is almost flat.",
                    "label": 0
                },
                {
                    "sent": "That's probably something that's not vegetative at all, like water or city, right?",
                    "label": 0
                },
                {
                    "sent": "But these reflect very different types of plant matter, right?",
                    "label": 0
                },
                {
                    "sent": "That peak at different times in the year.",
                    "label": 0
                },
                {
                    "sent": "Possibly Wheaton corn, but possibly something else.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so the problem that we would really like to be able to solve is the full on multiple instance regression problem, which is, you know, given a set of bags that have counties made up of some set, you know some data items or pixels.",
                    "label": 1
                },
                {
                    "sent": "We'd like to be able to predict real valued labels or yields for each County.",
                    "label": 0
                },
                {
                    "sent": "This turns out to solve in its full glory.",
                    "label": 0
                },
                {
                    "sent": "This turns out to be trickier than it looks.",
                    "label": 0
                },
                {
                    "sent": "So what in this paper we concentrate on a sub task.",
                    "label": 1
                },
                {
                    "sent": "The salience assignment task which is given a set of bags.",
                    "label": 1
                },
                {
                    "sent": "Made up of data items and the labels, so that's part of the training data.",
                    "label": 1
                },
                {
                    "sent": "We want to find the salience of each data item.",
                    "label": 0
                },
                {
                    "sent": "Two predicting the data label within the training data, right?",
                    "label": 0
                },
                {
                    "sent": "So we're not doing generalization to new bags were just trying to understand is which pixels go with the label that we're working on this.",
                    "label": 0
                },
                {
                    "sent": "This makes it essentially an unsupervised learning problem, right?",
                    "label": 0
                },
                {
                    "sent": "We don't have.",
                    "label": 0
                },
                {
                    "sent": "We don't have that data.",
                    "label": 0
                },
                {
                    "sent": "It's not.",
                    "label": 0
                },
                {
                    "sent": "We don't have ground truth on these things.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "OK, so of course people have looked at this variations on the multiple instance learning problem a lot previously.",
                    "label": 1
                },
                {
                    "sent": "Starting with, you know the classic multiple instance learning paper and the core assumption here is that if there's one or more positive items in a bag, then it's a positive bag.",
                    "label": 0
                },
                {
                    "sent": "If there are no positive items in a bag, that's a negative peg.",
                    "label": 0
                },
                {
                    "sent": "And the focus here is really on classification.",
                    "label": 1
                },
                {
                    "sent": "So doing positive negative tags.",
                    "label": 0
                },
                {
                    "sent": "A relevant recent extension is the Miles algorithm, which extends it from thinking about single items to thinking about sets.",
                    "label": 0
                },
                {
                    "sent": "So if there's a small set of items that relate to the label, we can call a big positive, but again, this is classification only.",
                    "label": 1
                },
                {
                    "sent": "The work that's most closely related to us as the primary instance.",
                    "label": 0
                },
                {
                    "sent": "Regression work by rampage.",
                    "label": 0
                },
                {
                    "sent": "Here the assumption is that there's a single data item in the bag that can be used to predict the label.",
                    "label": 0
                },
                {
                    "sent": "And and their job is really to find this exemplar point, and then once they found the exemplar points, they can make the regression estimate.",
                    "label": 0
                },
                {
                    "sent": "The trick is that it turns out that they don't have a good way to find exemplars for new bags, right?",
                    "label": 1
                },
                {
                    "sent": "So this is essentially the reason that extending to the full generalization regression problem is hard, and it's the same problem we face.",
                    "label": 0
                },
                {
                    "sent": "Alright, so our extension is going to be to relax this and you know to beat our heads against this without success at the moment.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so to to understand the optimization function that we come up with.",
                    "label": 0
                },
                {
                    "sent": "Let's begin by looking at the sort of geometry of a bag.",
                    "label": 1
                },
                {
                    "sent": "So we have some some feature space here.",
                    "label": 0
                },
                {
                    "sent": "A bag is a set of points.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In this feature space and when you consider the regression target, write this.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is an orthogonal axis in our bag of data can?",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Be thought of as a set of points in a plane.",
                    "label": 0
                },
                {
                    "sent": "You know at the level of the regression target for the bag.",
                    "label": 0
                },
                {
                    "sent": "And so a second bag is now.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Second set of points at a different regression level and our goal is to find hyper.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Plane or some other surface that in some sense fits well through.",
                    "label": 0
                },
                {
                    "sent": "You know these different bag data OK.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the question becomes, which points should we use for the to base that regression on?",
                    "label": 1
                },
                {
                    "sent": "And there's a lot of possibilities, right?",
                    "label": 0
                },
                {
                    "sent": "So one sort of obvious thing one can do is simply take the mean or centroid of all the data, right?",
                    "label": 0
                },
                {
                    "sent": "Just average everything together, but that doesn't really make a lot of sense in this case, because now you're averaging corn pixels with wheat pixels with city and soybeans and water and everything like that.",
                    "label": 0
                },
                {
                    "sent": "So you'd like to do something more intelligent.",
                    "label": 0
                },
                {
                    "sent": "So what Pier does is, you know, work to pick a best data item to pick this exemplar point.",
                    "label": 0
                },
                {
                    "sent": "What we're going to do is pick a weighted mean point, right?",
                    "label": 0
                },
                {
                    "sent": "And the reason we want to do this is because we really are interested in how relevant each point is.",
                    "label": 0
                },
                {
                    "sent": "Each pixel is to the final classification, and we can interpret the weights of the of the data items as being those salience values, right?",
                    "label": 0
                },
                {
                    "sent": "So things with an almost zero contribution to the exemplar.",
                    "label": 0
                },
                {
                    "sent": "Can be thought of as having no contribution to the to the class label or to the regression label.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so so the key problem then becomes picking this exemplar and figuring out the weighted combination.",
                    "label": 0
                },
                {
                    "sent": "So let's look at a single bag of data, which I'm going to denote capital BF B, with the superscript K. Just saying this is the case.",
                    "label": 0
                },
                {
                    "sent": "Bag out of some arbitrary set of eggs.",
                    "label": 0
                },
                {
                    "sent": "Let's think a little bit about what we'd like of the exemplar point.",
                    "label": 0
                },
                {
                    "sent": "What we don't want is for the exemplar point to be way out here, right?",
                    "label": 0
                },
                {
                    "sent": "If you allow an arbitrary.",
                    "label": 0
                },
                {
                    "sent": "Linear combination of the of these pixels.",
                    "label": 0
                },
                {
                    "sent": "Then you could end up with a point way out here, in which case the bag essentially has no influence on the label whatsoever, right?",
                    "label": 0
                },
                {
                    "sent": "So what we really want is for the point to be somewhere within the bounds of the bag, so we're going to impose a simplex constraint or a convex Hull constraint, which we convert a simplex constraint.",
                    "label": 0
                },
                {
                    "sent": "So we're going to enforce that the exemplar point falls somewhere within the convex Hull of our bag.",
                    "label": 0
                },
                {
                    "sent": "So this leaves us with the problem.",
                    "label": 0
                },
                {
                    "sent": "Find a vector of weights.",
                    "label": 1
                },
                {
                    "sent": "So this is going to be our salience weights such that the exemplar formed by the weights in the data falls within the convex Hull of the bag and that the exemplar is good in a regression sense with respect to modeling the target.",
                    "label": 0
                },
                {
                    "sent": "And then this vector Alpha K is going to be our salience factor.",
                    "label": 0
                },
                {
                    "sent": "This is going to tell us tell us how relevant each point is to predict in the bag label and note that this is Alpha to the case.",
                    "label": 1
                },
                {
                    "sent": "So there's one.",
                    "label": 0
                },
                {
                    "sent": "There's one of these vectors for every bag, right?",
                    "label": 0
                },
                {
                    "sent": "So we get a unique salience assignment out for each bag in our data set.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "OK, so this leads us to formulating the following objective.",
                    "label": 0
                },
                {
                    "sent": "Oh sure.",
                    "label": 0
                },
                {
                    "sent": "Thanks.",
                    "label": 0
                },
                {
                    "sent": "Images right?",
                    "label": 0
                },
                {
                    "sent": "Yeah, they are.",
                    "label": 0
                },
                {
                    "sent": "There's a huge amount of spatial information here that we could take advantage of, and we haven't yet.",
                    "label": 0
                },
                {
                    "sent": "We've treated them as sort of undifferentiated piles.",
                    "label": 0
                },
                {
                    "sent": "Piles of things right with, you know, the fact that their pixels, you know we should take advantage of but haven't yet, but we expect.",
                    "label": 0
                },
                {
                    "sent": "Not necessarily.",
                    "label": 0
                },
                {
                    "sent": "I mean, we'd expect him to be the same within a single year, but it turns out that across years it's going to change because they rotate crops.",
                    "label": 0
                },
                {
                    "sent": "So a field that's a wheat crop this year is going to be a corn crop next year and going to follow another year, right?",
                    "label": 0
                },
                {
                    "sent": "And if we knew which ones were which, we, you know, we could get a lot of advantage out of that.",
                    "label": 0
                },
                {
                    "sent": "But then we would essentially have the salience is right.",
                    "label": 0
                },
                {
                    "sent": "Question.",
                    "label": 0
                },
                {
                    "sent": "So at the beginning you said the element objective is to predict the average yield of particular crops for particular counties, right?",
                    "label": 0
                },
                {
                    "sent": "Seems that.",
                    "label": 0
                },
                {
                    "sent": "The straightforward way it is when I'm straight forward would be to try and predict the average yield per pixel and then average over the pixels in accounting to get the average year for the County.",
                    "label": 0
                },
                {
                    "sent": "You don't actually have a target.",
                    "label": 0
                },
                {
                    "sent": "You don't actually have a target label for each pixel, but you do have a target label County, and so you can do some sharing of targets over the pixels and also use a structured supervised learning approach to make the predictions for neighboring pixels be similar.",
                    "label": 0
                },
                {
                    "sent": "But This is why people use, for example, if we want to predict, say, health prices, so you build a regression predicted value of each house.",
                    "label": 0
                },
                {
                    "sent": "Sharing between neighboring houses because everything else.",
                    "label": 0
                },
                {
                    "sent": "Right, yeah?",
                    "label": 0
                },
                {
                    "sent": "OK, so that approach makes sense, but it seems like you know, you know, have sort of the converse problem.",
                    "label": 0
                },
                {
                    "sent": "So what we're trying to do is share relevance among pixels, and in your approach, I think what you have to do is share yield among pixels, and so you still have to solve this problem of how much yield do I assign to every pixel?",
                    "label": 0
                },
                {
                    "sent": "The smoothing across local pixels is a good idea, but there's a lot of structure here that might complicate that.",
                    "label": 0
                },
                {
                    "sent": "For example, neighboring fields aren't constrained to both be the same crop.",
                    "label": 0
                },
                {
                    "sent": "Right, they can.",
                    "label": 0
                },
                {
                    "sent": "They can be different crops, so you can have these sharp discontinuity's.",
                    "label": 0
                },
                {
                    "sent": "But I mean your approach makes sense and it's a thing that we should consider.",
                    "label": 0
                },
                {
                    "sent": "If you are sharing yield, at least yield is a well defined concept, like I can't say that I understand what the definition of salience is in this case.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "Well when we go through the objective function will become a little bit clearer, but essentially it's.",
                    "label": 0
                },
                {
                    "sent": "You know what?",
                    "label": 0
                },
                {
                    "sent": "What fraction of each data point?",
                    "label": 0
                },
                {
                    "sent": "Can be what fraction of each pixel should we use to predict the regressor for the entire County?",
                    "label": 0
                },
                {
                    "sent": "Any other questions over here?",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right, so this is the objective that we're going to work with, so we're going to minimize this F. So W is our weight vector.",
                    "label": 1
                },
                {
                    "sent": "Whatever parameters for regression model at the moment, we're just using a linear regressor, which is known to be only.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So for this data.",
                    "label": 0
                },
                {
                    "sent": "But you know, it's easy.",
                    "label": 0
                },
                {
                    "sent": "I think it's this is extendible without too much trouble to more sophisticated regressors, right?",
                    "label": 0
                },
                {
                    "sent": "And this is the set of our our vectors that we want.",
                    "label": 0
                },
                {
                    "sent": "These are ultimately the targets that we care about getting out.",
                    "label": 0
                },
                {
                    "sent": "So I.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is our objective function.",
                    "label": 0
                },
                {
                    "sent": "It doesn't look too bad.",
                    "label": 0
                },
                {
                    "sent": "It's very least squares looking.",
                    "label": 0
                },
                {
                    "sent": "Here's our label for Bag K, right?",
                    "label": 1
                },
                {
                    "sent": "So everybody gets a single label.",
                    "label": 0
                },
                {
                    "sent": "There's are bad data for K right?",
                    "label": 0
                },
                {
                    "sent": "In this product.",
                    "label": 0
                },
                {
                    "sent": "BK Alpha K is the exemplar for bad K. It's the weighted mean of the data in bag K where the weights are given by the salient factor.",
                    "label": 1
                },
                {
                    "sent": "So this is what the salience really means, right?",
                    "label": 0
                },
                {
                    "sent": "It's this weighted combination.",
                    "label": 0
                },
                {
                    "sent": "And so every point contributes a sort of Alpha fraction to this exemplar.",
                    "label": 0
                },
                {
                    "sent": "And then altogether we have our error.",
                    "label": 0
                },
                {
                    "sent": "It's a simple squared error function, so this is the error in curd if you used.",
                    "label": 0
                },
                {
                    "sent": "This exemplar with these weights to estimate this value.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in order to get the convex Hull constraint we have this simplex constraint, which says that you know boils down to the point must fall somewhere within the convex hole and every so the sum of all alphas has to be one the office has to be greater than zero, so you could interpret this as being sort of the fraction of each pixel it contributes to the exemplar or the probability of each pixel contributing the example or something.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so it turns out that while it's a nice, fairly clean form, solving it directly is not easy if you try to solve with respect to both Alpha and W simultaneously, it's really a mess.",
                    "label": 0
                },
                {
                    "sent": "And it boils down to the objective function is indefinite in a combination of W and Alpha simultaneously right there for exact minimization of this thing is NP hard, which is a result that was consistent with Ray and pages finding on their formulation.",
                    "label": 1
                },
                {
                    "sent": "Darn, but you know, being good machine learning hacker's a little thing like NP.",
                    "label": 0
                },
                {
                    "sent": "Hardness doesn't stop us.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So you know the obvious observation, when you sit down and look at this for a little bit is that you know this is very least squares ish, right?",
                    "label": 0
                },
                {
                    "sent": "You know so it should have a nice solution in some sense.",
                    "label": 0
                },
                {
                    "sent": "And in fact if you freeze Alpha K then the solution is just the standard least squares solution that's in all the textbooks.",
                    "label": 0
                },
                {
                    "sent": "And Conversely, if you freeze W you can solve for a single Alpha K, which is again least squares ish.",
                    "label": 0
                },
                {
                    "sent": "But you have these simplex constraints so that forces it to be a quadratic program.",
                    "label": 0
                },
                {
                    "sent": "But you know, there's a MATLAB subroutine for that, so that shouldn't trouble.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that leads to the following iterative algorithm.",
                    "label": 0
                },
                {
                    "sent": "The APC salience algorithm.",
                    "label": 0
                },
                {
                    "sent": "So you take his input, your bag data in your bag, labels an as output.",
                    "label": 0
                },
                {
                    "sent": "You're going to turn your regression model, and your salient factors for alfaques.",
                    "label": 0
                },
                {
                    "sent": "So we're going to begin by picking random W. This is because of the NP hardness, so you can do random restarts if you like, and then you enter the following iteration.",
                    "label": 0
                },
                {
                    "sent": "So first you go over all the bags for each bag you solve the resulting quadratic program using the fixed W that you started with here right?",
                    "label": 1
                },
                {
                    "sent": "And you find the best Alpha K. So this is the Alpha K that under that assumption of regression model, this is the weight vector that best allows you to predict.",
                    "label": 0
                },
                {
                    "sent": "The output or produces the best exemplar with respect to that model, right?",
                    "label": 0
                },
                {
                    "sent": "And then having fixed the alphas, you can solve the remaining objective function using least squares closed form to find the best regression model under the assumption that those are the correct salience assignments, and you keep doing this until you converge.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the question is, should this converge?",
                    "label": 0
                },
                {
                    "sent": "Well, it feels very M like, but we haven't talked about any sort of generative model.",
                    "label": 0
                },
                {
                    "sent": "There's no obvious expectation in here.",
                    "label": 0
                },
                {
                    "sent": "It turns out that you can think about this one way of thinking about this anyways.",
                    "label": 0
                },
                {
                    "sent": "In terms of something called an alternating projections algorithm, which is very familiar in the optimization community, but I haven't seen floating around machine learning so much, so I thought I'd introduce it a little bit.",
                    "label": 0
                },
                {
                    "sent": "It's a solution to a convex feasibility problem.",
                    "label": 1
                },
                {
                    "sent": "That is, find me a feasible point for point in the intersection of a bunch of convex sets.",
                    "label": 0
                },
                {
                    "sent": "These things have a history that goes back to Von Neumann, but you know, I only ran into him last year.",
                    "label": 0
                },
                {
                    "sent": "This is a nice survey paper on the stuff right there.",
                    "label": 0
                },
                {
                    "sent": "They're sort of very similar in flavor to M and I think that there's probably a deep connection that I haven't fully explored, but they're really motivated by geometric considerations rather than by stochastic ones, so you don't have to have a generative model.",
                    "label": 0
                },
                {
                    "sent": "There doesn't have to be a probability, assumption or expectation.",
                    "label": 0
                },
                {
                    "sent": "All you really need or convex sets and projection operations.",
                    "label": 0
                },
                {
                    "sent": "So in this case.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is the point that we want to find the critical point of our objective right so it works like this?",
                    "label": 0
                },
                {
                    "sent": "So suppose I give you in this case 3 arbitrary convex sets in some space, and our goal is to find a point in the intersection so point in that little area down there we begin by choosing an arbitrary point and taking an orthogonal projection onto one set right from there, taking orthogonal projection onto another set right, and so on, right?",
                    "label": 0
                },
                {
                    "sent": "And you just keep doing this, and eventually you end up down there.",
                    "label": 0
                },
                {
                    "sent": "You're guaranteed end up, down there in the intersection.",
                    "label": 0
                },
                {
                    "sent": "OK, so given this.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Look back at the algorithm, the iterative algorithm and and try to understand it in this context.",
                    "label": 0
                },
                {
                    "sent": "So this is the core loop section.",
                    "label": 0
                },
                {
                    "sent": "It turns out that this step you can think of as being a projection onto the zeros of the partial derivative of F of our objective with respect to Alpha K right?",
                    "label": 1
                },
                {
                    "sent": "In this step, down here is a projection onto the zeros with respect to the derivative with respect to W, right?",
                    "label": 0
                },
                {
                    "sent": "So what we're finding is a point that's simultaneously a critical point with respect to Alpha and with respect to W. Which is a critical point of the complete objective.",
                    "label": 0
                },
                {
                    "sent": "Now all I'm guaranteeing is that we found is 0 right?",
                    "label": 0
                },
                {
                    "sent": "I'm not guaranteeing that we found, you know.",
                    "label": 0
                },
                {
                    "sent": "On optimum right or else we would have proved that P equals NP.",
                    "label": 0
                },
                {
                    "sent": "So we found some critical point.",
                    "label": 0
                },
                {
                    "sent": "You could do a second derivative test at this point to determine whether your Max men saddle point or something like that.",
                    "label": 0
                },
                {
                    "sent": "But the nice thing is that we've got a guarantee of convergence to some sort of reasonable point.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so that's all very nice, but does it actually work?",
                    "label": 1
                },
                {
                    "sent": "So we looked at this on four years of this ground sensing data from drawn from California in Kansas, California is considerably fewer counties reporting yields for corn and wheat.",
                    "label": 0
                },
                {
                    "sent": "These counties are really big.",
                    "label": 0
                },
                {
                    "sent": "Like I said, some of them have 300,000 pixels and our algorithm you know you have to solve multiple QPS per iteration, so it's a wee bit slow, so we randomly sample 100 pixels from each County and then we compare it to the pier method.",
                    "label": 1
                },
                {
                    "sent": "The rain page method they recommended random restarts for their methods.",
                    "label": 1
                },
                {
                    "sent": "We did 10 random restarts for them.",
                    "label": 0
                },
                {
                    "sent": "For our method we only chose the one initial random W vector and only ran it once.",
                    "label": 0
                },
                {
                    "sent": "Now we.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Call that this is essentially an unsupervised learning problem, so evaluation is going to look very unsupervised ISH, and I can't give you, you know, in our MSE plot.",
                    "label": 0
                },
                {
                    "sent": "So here's a plot of one of the counties.",
                    "label": 0
                },
                {
                    "sent": "This is Jewell County, Kansas in 2001.",
                    "label": 0
                },
                {
                    "sent": "Latitude lanja tude.",
                    "label": 0
                },
                {
                    "sent": "Each of these circles is one of our hundred pixels that we drew in the color scale.",
                    "label": 0
                },
                {
                    "sent": "Is the salience that we assign right so darker pixels here are things that we consider to be more salient or receive higher weight lighter pixels of things that receive little or no wait.",
                    "label": 0
                },
                {
                    "sent": "And the Red Cross is the exemplar point picked by the pier algorithm in the first interesting thing first.",
                    "label": 0
                },
                {
                    "sent": "Useful thing to note is that there's a distinct clustering into this corner of the salient things, and that it coincides with the pixel that rampage picked.",
                    "label": 0
                },
                {
                    "sent": "If we look at the wheat, if we look at the same same County, same pixels.",
                    "label": 0
                },
                {
                    "sent": "Now trying to predict wheat, we're trying to model.",
                    "label": 0
                },
                {
                    "sent": "Wait, we find a very different distribution.",
                    "label": 0
                },
                {
                    "sent": "Now we get most of the clustering down here in the lower left corner an rampages pixel pops out in a very different place than this.",
                    "label": 0
                },
                {
                    "sent": "One.",
                    "label": 0
                },
                {
                    "sent": "Nice thing about this is that we get we do get spatial clustering which one might expect right?",
                    "label": 0
                },
                {
                    "sent": "The second thing about this is that you get very different distributions for the two regression targets.",
                    "label": 0
                },
                {
                    "sent": "That tells you that you are finding something about.",
                    "label": 0
                },
                {
                    "sent": "The regression target.",
                    "label": 0
                },
                {
                    "sent": "And that and that, the salience vectors that pop out do depend on on the goal target here.",
                    "label": 0
                },
                {
                    "sent": "So a second way of evaluating this, right?",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is to look at stability estimate overtime.",
                    "label": 0
                },
                {
                    "sent": "So the notion here is that while crop fields may change and rotate from year to year within a single year, a single pixel is only going to be corn or wheat, right?",
                    "label": 0
                },
                {
                    "sent": "And it's not going to change its membership within a year.",
                    "label": 0
                },
                {
                    "sent": "So if we look across a year right and we build a model on the first time point, then the first two time points in the first three time points and so on, we should expect those models to be consistent with each other and have roughly the same shape.",
                    "label": 0
                },
                {
                    "sent": "And So what we did is measure.",
                    "label": 0
                },
                {
                    "sent": "How much the model changes over the course of a year, right?",
                    "label": 0
                },
                {
                    "sent": "And there's a stability measurement based on an entropy measure on because so we measured it both for the peer algorithm for ours, because peer only picks a single exemplar point.",
                    "label": 0
                },
                {
                    "sent": "We to be fair, we only picked an example or point out of our model.",
                    "label": 0
                },
                {
                    "sent": "We picked the maximally salient point that was produced by our algorithm, and So what we plot here is our means.",
                    "label": 0
                },
                {
                    "sent": "Stability measure overall counties in Kansas and up is good.",
                    "label": 0
                },
                {
                    "sent": "Up is more stable and so we see that in this case, the AP salience algorithm.",
                    "label": 0
                },
                {
                    "sent": "The yellow one has a significantly more stable model over the course of a year then peer does.",
                    "label": 0
                },
                {
                    "sent": "What this tells us is that the model that's picking tends to remain stable over the course of the year.",
                    "label": 0
                },
                {
                    "sent": "We tend to be getting the same thing back over the year.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "When we look across California and corn, three out of the four times the story remains true in only in this case down here, California corn does peer consistently come out with a more stable model that also turns out to be the case with the fewest yield.",
                    "label": 0
                },
                {
                    "sent": "Reporting counties, right?",
                    "label": 0
                },
                {
                    "sent": "So there's some sense much less data here than there is up over here.",
                    "label": 0
                },
                {
                    "sent": "OK, so um, so it's a fairly nice story, but where are we going with the next?",
                    "label": 0
                },
                {
                    "sent": "Well, what we ultimately want to do is tackle regression problem, but there's a sort of chicken and egg problem here, which is that we can't get these salient factors without having label, and we don't have the label for under previously unseen bags, so we have no way to get the salience is so we can't build the model and so on, right?",
                    "label": 1
                },
                {
                    "sent": "So the approaches that we'd like to take to.",
                    "label": 0
                },
                {
                    "sent": "Tackless, we're currently working on the first thing is to generalize the salience is that is, if we can find the pixels in our new bag that are very similar to pixels in existing bags right, then maybe we can transfer salience is from existing bags to new bags.",
                    "label": 0
                },
                {
                    "sent": "And the second thing that we're looking at is to take a set kernels approach and sort of abandoned.",
                    "label": 0
                },
                {
                    "sent": "The salience is altogether.",
                    "label": 0
                },
                {
                    "sent": "Salience is are very nice because they tell us things about the structure of the data in an unsupervised way and they can, you know, sort of tell you where corn is going on where we just going and so on.",
                    "label": 0
                },
                {
                    "sent": "But if we really want to do is regres maybe all we want to do is construct a kernel.",
                    "label": 0
                },
                {
                    "sent": "It can take 2 bags right and return to Colonel inner product between the two bags and then plug that into your favorite support vector regression method and out pops an answer hopefully so far.",
                    "label": 0
                },
                {
                    "sent": "You know our early efforts on this haven't been successful, but we're still following, so that's the story.",
                    "label": 0
                },
                {
                    "sent": "Thank.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, very much for listening and I'll take any questions.",
                    "label": 0
                },
                {
                    "sent": "I can understand why it's not.",
                    "label": 0
                },
                {
                    "sent": "OK, well those would be good good things to try, but.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so I guess in this case what we're really looking for is sort of how much we're really looking for this model over the pixels, so I guess you could interpret the feature selector.",
                    "label": 0
                },
                {
                    "sent": "You know the output of the feature selector is giving you that.",
                    "label": 0
                },
                {
                    "sent": "But what we don't want is sort of dimensionality reduction of it, because then you get this sort of weird mixture of the pixels we want to be able to say for each pixel.",
                    "label": 0
                },
                {
                    "sent": "This ones a cornfield in this ones Wheatfield, right?",
                    "label": 0
                },
                {
                    "sent": "And so on.",
                    "label": 0
                },
                {
                    "sent": "Soft weight on everything.",
                    "label": 0
                },
                {
                    "sent": "Yeah, software on every pixel rather than mix rather than a mixture of the pixels.",
                    "label": 0
                },
                {
                    "sent": "Yeah so.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry, can't quite hear you.",
                    "label": 0
                },
                {
                    "sent": "You have a lot of his outlook papers, yeah?",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "So it seems like you could look at me Maps of the counties.",
                    "label": 0
                },
                {
                    "sent": "Rap songs field.",
                    "label": 0
                },
                {
                    "sent": "Right, yeah, Ann, you're right that there are a lot of spatial and geometric constraints that we could take advantage of.",
                    "label": 0
                },
                {
                    "sent": "What we were fairly happy about in this case was that.",
                    "label": 0
                },
                {
                    "sent": "Without putting any of that information and you still get you know something like a spatial clustering out, right?",
                    "label": 0
                },
                {
                    "sent": "So it feels like we're, you know, there's something that's being pulled out purely out of the pure layout of the objective task, right?",
                    "label": 0
                },
                {
                    "sent": "Without having to go in and add these spatial constraints.",
                    "label": 0
                },
                {
                    "sent": "So right, so?",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                },
                {
                    "sent": "You know, this feels like it's a little bit more knowledge free and you could apply it to other problems than just ground sensing problems.",
                    "label": 0
                },
                {
                    "sent": "But you're right.",
                    "label": 0
                },
                {
                    "sent": "I mean, you know ultimately this is preliminary work, right?",
                    "label": 0
                },
                {
                    "sent": "So ultimately you know to to tackle this more thoroughly.",
                    "label": 0
                },
                {
                    "sent": "Would we like to get in some of the spatial distribution stuff?",
                    "label": 0
                },
                {
                    "sent": "Right, so each pixel we have two bands of spectral imaging data.",
                    "label": 0
                },
                {
                    "sent": "We have a red bandana near infrared band, right?",
                    "label": 0
                },
                {
                    "sent": "So each pixel is 2 dimensional and then what we have here are time series.",
                    "label": 0
                },
                {
                    "sent": "Another thing we'd like to do is get a real temporal model end, so get some of the Markov.",
                    "label": 0
                },
                {
                    "sent": "Transition dynamics of pixels overtime, but for the moment what we're doing is just concatenating time points together.",
                    "label": 0
                },
                {
                    "sent": "So, for example, this is training data from January 1st to February 18th.",
                    "label": 0
                },
                {
                    "sent": "So for each pixel we took its two values at each of the time points and concatenated together.",
                    "label": 0
                },
                {
                    "sent": "I think this is like seven or eight time points.",
                    "label": 0
                },
                {
                    "sent": "This is like you know, 14 or 16 dimensional vector.",
                    "label": 0
                },
                {
                    "sent": "Any other questions?",
                    "label": 0
                },
                {
                    "sent": "OK, thank you.",
                    "label": 0
                }
            ]
        }
    }
}