{
    "id": "cjkak2mdb2vyd6bjqripkuzazebrtdm7",
    "title": "The Gaussian Variational Approximation of Stochastic Differential Equations",
    "info": {
        "author": [
            "Manfred Opper, Department of Artificial Intelligence, TU Berlin"
        ],
        "published": "Feb. 25, 2007",
        "recorded": "December 2006",
        "category": [
            "Top->Computer Science->Machine Learning->Gaussian Processes"
        ]
    },
    "url": "http://videolectures.net/dsb06_opper_gvasd/",
    "segmentation": [
        [
            "This this talk is actually the joint of an effort of the workshop organizers, together with then confort and sort of our problem was we try to come up with a variational Gaussian approximation to stochastic differential equations.",
            "And this is very much related to the second talk this morning, but it's probably going to be a bit more theoretical and less practical because we were just after finding out what is the best Gaussian approximation in the variational sense, and there will be the question if we can make something practical out of it.",
            "So the outline of the talk would be I will speak about the Gaussian variational method for is just.",
            "Remind you of the finite dimensional case, then move on."
        ],
        [
            "The infinite dimensional case, meaning the application to stochastic differential equations because we have infinite time and that means the infinite dimensionality.",
            "This whole variational method will end up with a LaGrange function and you try to set up Lagrangian equations for them and try to solve them.",
            "For simple model problems.",
            "And it turns out for certain systems there might be a different funny interpretation in terms of a Hamiltonian, and in this case I don't really know if this will have any applications, but I found this quite neat, so I'm going to present it anyhow.",
            "And so just let me start right away with the variational method that we know in the machine learning community.",
            "So the variational method in Bayesian modeling is simply."
        ],
        [
            "You have a posterior.",
            "So this is the variable X, that's the hidden variable that we don't know why our observations say might be a parameter that we try to optimize later.",
            "So we approximate the intractable posterior by something that lives in a tractable family and tractable is of course means related to what we actually can do with our computers.",
            "So it might depend on.",
            "Yeah, our power.",
            "So in most applications and there's huge number of applications you find in lost in the last couple of years in NIPS, so you choose F to be factorizing distributions which factorize in all the variables or in groups of variables.",
            "So in this hasn't actually an advantage.",
            "We can show what is the form of the optimal Q in such a family.",
            "There's a free form optimization possible and then we can do a sequential.",
            "Method for optimizing these approximating probabilities Q there's of course another wonderful family of distributions that we know and we can handle.",
            "Usually very, very well, and that's the family of Gaussian distributions.",
            "It seems like that this family has not found so many friends in the machine learning community when it deals.",
            "When we deal with the variational method.",
            "And, well, I'm probably not probably a complete list, but I I remember only a couple of cases.",
            "For instance, David, Barber, Ann, and Chris Bishop, who dealt with Bayesian neural networks.",
            "There was a paper of Matthias Egger and very recently by organizing the workshop we learned the paper and about the paper of Honkala in Valpo Law.",
            "Of course, and one of the arguments that people often bring forward and have brought forward is probably, well, if you have a variational Gaussian approximation.",
            "You have to optimize the mean and the covariance matrix.",
            "Of course, a covariance matrix is a big object.",
            "You have a matrix of in, well, you have a thing of N squared parameters.",
            "Well, have it you because it's symmetric and so probably it's something that has too many parameters to be optimized.",
            "And then you might think of suboptimal solutions and things like that, so it's not probably such a nice thing.",
            "Well, there are other other problems as well.",
            "You cannot.",
            "You cannot approximate discrete random variables, yes?",
            "Please, sorry.",
            "Of.",
            "Practice at least what we do is playing the combining these two so it's Gaussian right, right, right, right.",
            "Some rank one.",
            "Yes.",
            "Yes.",
            "Number.",
            "For instance, we have.",
            "Gas and where?",
            "We have this other random field with which connects the consecutive.",
            "States.",
            "But this is classified with restricted Gaussian, yes.",
            "Yes, so there's a question you can come up with restricted classes of Gaussians, but it turns out there's also something that, well, some people know.",
            "It's some people with whom I talk to seem to well are aware of that fact in some cases, actually the true, the best.",
            "Gaussian has also a very simple well rather simple representation, and that's what I'm going to show you first in the discrete and discrete case, and then for the stochastic differential equations.",
            "So we were going for the optimum and see.",
            "That it can be represented in a search."
        ],
        [
            "Anyway, so this would be the finite dimensional case.",
            "So again here is Bayes Theorem P of X.",
            "Given the data in a parameter, is this an one way of writing the variational method?",
            "So remember the variational method.",
            "We tried to minimize the kullback Leiber divergance between Q, which is the variational.",
            "Approximation and P, which is the untractable true posterior, so it's the unsymmetric one where we have Q on the light on the left hand side and we can compute this KL so another formulation is we minimize a so-called variational free energy.",
            "Which is mine.",
            "Is the entropy and the average logarithm of the probability and of course for Gaussians we know that the entropy only depends on the covariance matrix.",
            "So if we look at this for Gaussians."
        ],
        [
            "For Gaussian families, then, the variational entropy with the entropy would only depend on the logarithm of the determinant, and if you just set the gradient of the free energy equal to 0, then you get 2 equations.",
            "First of all, the one for the mean, which says well on average the log probability of the model should be 0 and the other one gives you the inverse covariance matrixes.",
            "Essentially equal to the gradient of log P with respect to Sigma.",
            "There's a funny thing.",
            "A funny property of Gaussian averages.",
            "You can also replace that the first derivative with respect to the.",
            "Covariance matrix by a second derivative with respect to X is so it's in some sense an average Laplace approximation.",
            "So this says Laplace means you have to find a point where the derivative, the gradient of log P is 0, and then you have to estimate the covariance matrix by the 2nd derivative at that point and the Gaussian variational method does the same but on average.",
            "So this is a funny reformulation of that.",
            "And this would be a simple plot, so the red one is the true."
        ],
        [
            "Function you try to approximate the green one would be the Laplace approximation centered here with the same curvature and the Gaussian variational method is not local.",
            "In that sense.",
            "It not only concentrates at this point or its infinitesimal neighborhood, it just looks, it just looks at the global thing and then approximates this thing by something which is which takes more into account the full.",
            "Shape, at least there is more mass on this direction, and it's a fairly reasonable estimate of the mean.",
            "The variance, of course is not perfect, but OK, so it does a better job than the plus approximation that simple case.",
            "And if you now look at a class of posteriors that have the form that we know very well in."
        ],
        [
            "Gaussian process approximations where we have a part that is already Gaussian coming from the prior and this K is the kernel matrix and we have something which is which is usually the data part.",
            "So that depends.",
            "So this would factorize in the variables in the latent variables X and then you'll see that the covariance the inverse covariance is just the inverse kernel plus a diagonal thing at the optimum, so essentially.",
            "The covariance matrix can be parameterized by a diagonal matrix, at least the inverse one, so you have in fact for these types of models only two N parameters to optimize the mean and these diagonal matrix.",
            "Yeah, the diagonal matrix.",
            "So in fact the covariance matrix is something more.",
            "Complicated, but the inverse is just the old inverse plus a diagonal matrix.",
            "Well, some people know that already, and but I wasn't sure if everybody knows it, because some people argued Oh no, it's not OK.",
            "So just anyhow, I thought somebody has to do it and say it and then maybe publish it.",
            "So this is just an example, if you run."
        ],
        [
            "This on the on on on this very simple regression problem, but this time with Laplace noise.",
            "So you have a bunch of outliers here because of the more heavy tails of the noise and so the red curve is, well, you ignore the Laplacian, do just the regular fitting of Gaussian processes and the blue one.",
            "Well, it tells you well.",
            "OK, no, the other way round, the blue is of course the one that is sort of less robust in the red one is the.",
            "The Laplace and so this one optimizes the hyperparameters and you can do a. Quasi Newton updates and it works.",
            "It works OK so now, but this just to to tell you that in some cases the Gaussian approximation doesn't have so many parameters.",
            "I want to move on to the infinite dimensional case and now we're back at the stochastic differential equations stochastic trend."
        ],
        [
            "Differential equations, so our problem setting is the following.",
            "We have a time evolution of a state function X.",
            "With a general nonlinear function, FX driven by wienner process and for instance I just for simplicity, I just say all these variances are the same and replace it by a simple Sigma here.",
            "And then we have noisy observations of the hidden process at certain times and certain discrete times Tien.",
            "And that's the problem.",
            "We try to compute, make inference about the function X50 conditioned on the on the observations based on the prior knowledge that we have from this process.",
            "So the prior knowledge is, well this process, but it's a non Gaussian process.",
            "Of course if F of X.",
            "Is a nonlinear function, so we are dealing with a regression problem where the prior is non Gaussian and we can't really easily handle it and so this is kind of an implicit type of observation that we have.",
            "Information, sorry.",
            "Right, So what we wanted to do is, yeah, that's sort of the goal.",
            "We tried to predict the latent path."
        ],
        [
            "So that would in this case be the unknown function.",
            "I think it's it's yours, and here are some noisy observations and well, that would be probably not so good prediction of the unknown latent path, and we also like to get maybe an error bar.",
            "And we claim maybe we can do better.",
            "So what did we hear?",
            "So we completely ignored?",
            "The prior information or the nonlinearity and said, OK, let's use a vanilla Gaussian process regression problem where we have a radial basis function kernel and we optimize the kernel parameters, but we ignore that this is actually something.",
            "Well, it comes from a bistable problem, so it's a it's a potential that has two minima and it can flip between two things.",
            "But this simple application of a Gaussian process regression doesn't know about this thing, so it interprets the data is sorry.",
            "A little bit in a wrong way so it doesn't see that.",
            "Here is a sudden transition and so on.",
            "OK, so just simply to demonstrate, it might be useful to do more than just what we then just an ordinary Gaussian process regression.",
            "So first when we do Bayesian analysis, we have to talk about priors, so the prior induced by the state."
        ],
        [
            "Differential equation I presented here in a discretized form in order to avoid problems with the more more fancy things like Ito Anstrom knowledge that was explained.",
            "Well, probably no.",
            "There was no Stratonovich this morning in Chris Williams.",
            "Is talk well was there.",
            "I don't remember.",
            "OK so.",
            "For the, for simplicity we work.",
            "We work with the discrete time process to avoid any problems, so it means the change in the variable XK is given by.",
            "Well, this forest times Delta T. And of course there is this stochastic element that scales with the square root of Delta T. As explained this morning by Chris Williams and Delta T is the time increment and epsilon case IID Gaussian noise.",
            "Now we can write down the probability density for such a discrete path.",
            "And well, since these noises are Gaussian, we get a product over all these conditional things here.",
            "So we know that the difference between escape between Delta XC and this must be a Gaussian random variable.",
            "So this is the proper joint probability for all the X case.",
            "The discretized XK.",
            "So this is well defined.",
            "We're not going immediately to the Continuum, so this is prior.",
            "And the prior is of course non Gaussian.",
            "Let me see, Oh yes, I said there might.",
            "There's a possibility to this to do right is a bit more fancy.",
            "Yes, please."
        ],
        [
            "Station is fixed in fixed intervals.",
            "Yes, yes yes I did yes.",
            "Of course, one might argue, isn't it possible to represent like a measure over continue over over the the?",
            "Continuous time paths and you can do that with some with some if you were carefully and use a bit of.",
            "Well, the way I understand stochastic calculus, I mean not an expert, but in some sense you can sort of show that the measure where the force is zero in some sense converges to the something that's called the venar measure and the measure given by the stochastic differential equation relative to the Wiener measure can be.",
            "Are written in such a way.",
            "Well, you argue there are some things that have to be into that have to be replaced by integrals, but you have to be careful in the meaning of such integrals.",
            "These are, as Chris Williams this morning explained, so called Ito integrals, and you have to give him a proper meaning.",
            "You can also expresses in terms of Stratonovich integrals.",
            "Then they look a bit different.",
            "So the only thing is if you try to work from the start with the continuous time formulation.",
            "It's possible, but you have to be careful.",
            "What what these integrals mean?",
            "So that would be a Stratonovich integral, and that means for me.",
            "I can do things with this integral like doing integration by parts so the things people love to do with these things, but for our purpose we just work with a discrete time thing and only when it comes to expectations.",
            "We set Delta T to zero at the end and find out that we get a nice nice result when it comes to expectations.",
            "All the the non differentiability of the paths at the end vanish is.",
            "The expectation seems to be very nice.",
            "Functions, so we had the prior.",
            "The prior was yes, just to remind the prior was this.",
            "And the posterior is simply we have to multiply."
        ],
        [
            "Prior with the likelihood of the observation, so go at.",
            "This happens only at discrete times and said would be the whole normalization.",
            "We have to do at the end to have this probability.",
            "Normalized so this is the sequence of the observations and the partition function is the probability of the entire observed sequence, and this is always a discrete observed sequence and we have for simplicity assumed that the likelihood is now a Gaussian one, so this would be an option.",
            "Slightly more complicated if it was non Gaussian, but we concentrated on the non gaussianity of the prior.",
            "So now comes the variational approx."
        ],
        [
            "Imation, so in machine learning this variational approximation again is formed by minimizing the KL divergent between certain measures Q that we can handle end the posterior measure that we can't handle easily.",
            "So how should this Q look like?",
            "So the first argument is well conditioned on the data.",
            "The posterior process is still a Markov process, so let's look for Markov queues.",
            "Then, well, we should reverse this slightly.",
            "We want to work with Gaussian approximation.",
            "So if it's a Gaussian.",
            "Stochastic.",
            "Markov process?",
            "Well, maybe we should model this well, the only way of getting a Gaussian process is to work with a linear stochastic differential equation that represents that posterior Markov process.",
            "So there must be a linear one.",
            "That means we say the posterior is sort of generated approximately by a stochastic differential of such equation of such a form where this FL is a.",
            "Linear term and that means we have two parameters essentially that we can play with.",
            "It's the yeah this plus.",
            "Plus a bias term be.",
            "And it turns out you can show in the limit the noise variance, the optimal noise variance.",
            "Well, there should be a Sigma.",
            "Here has to be the same as the original 1, otherwise your KL divergences between the two processes must be becomes infinite.",
            "So immediately this is already given by Sigma, so there's no yes please.",
            "Yes afts.",
            "Find me."
        ],
        [
            "No, no, we don't.",
            "We don't replace it by a constant.",
            "This is actually a very important thing.",
            "It has to depend on the time, because when it sees an observation, it has to do something.",
            "So anytime there is some.",
            "No, that was wrong.",
            "We have two parameter functions.",
            "And that's that's, yeah, that's an important point point.",
            "A&B are parameter functions to be optimized.",
            "They're essentially parametrization of the conditional density, and yeah, so the noise variance.",
            "It's easy, we know it has to be the same one, and that is now the family of our variational functions.",
            "And we claim that this is this is the class the optimum has to be in that class.",
            "Right, so this is an example of a Markovian posterior which you can actually solve by hand and easily.",
            "So let's say I have a process starts at 0 and it would be avenar process an I have a single noise free observation at time one or time T, and then I find out that the prior, well, the prior force was zero.",
            "It's avenar process, there's no drift, but then you can compute a posterior drift which depends on time.",
            "And that essentially is yeah, that gives you precisely that behavior.",
            "You start at zero.",
            "Yeah, you diffuse a bit and at the end at the end point you have to come back to zero.",
            "And this is this process is known as the Brownian Bridge and it has this drift term.",
            "You can play the same game also for the Ornstein Uhlenbeck process which Chris has introduced this morning.",
            "So the prior would be minus gamma X the prior drift and the posterior one.",
            "Also depends on time and you see anytime you you reach the point where the observation is and it's a fixed observation, there's no noise.",
            "So really you have to clamp the point X2 two it's too it's value.",
            "This drift becomes infinite.",
            "That's the only way of clamping the point and preventing it from diffusing away.",
            "So this is this is a bed maybe yeah, so at least this.",
            "This is what we get if you have a real, annoys free observation.",
            "Then your linear drift term has to go to infinite to to achieve Infinity.",
            "To achieve that.",
            "In these cases these posterior FS, these linear ones are not approximations because the processes the prior processes that we started with were Gaussian already and the posterior ones are then also Gaussian because the observation was a trivial Gaussian with zero variance.",
            "Right, yeah, So what can we do about the kullback, Leiber, divergent?",
            "So we had set out with the problem of minimizing KL divergences."
        ],
        [
            "That family of densities and it turns out you work with the discrete time formula formulation.",
            "You calculate the KL divergent for the fixed for this fixed discretization and and you do your do your expectations and at the end you get a big sum and there's some scales nicely with Delta T, so you replace it by an integral and there's no square root of Delta T things left.",
            "After doing the expectation, you end up with something nice and this something nice is is this thing?",
            "So if you have two diffusion processes P1 and P2, and it turns out these sums become an integral, so it's an integral from zero to T, that's our time over which we want to approximate the process, and it's given by the difference between the two drifts.",
            "The norm of the differences averaged over the at the same time and averaged over.",
            "The the distribution P1.",
            "So if we knew what the marginal distributions of our approximating process are at each time marginals at each time, then we could easily well at least we could formally calculate that object and that's what we need to do.",
            "So yeah, so it's a.",
            "It's a fairly simple surprisingly simple expression and you could get the same result if you work with these type of yeah, ITO integrals fit OK so I felt a bit more on the safe side if I do it like that, yes, please.",
            "Yes, I had fixed the initial condition but I am not sure if this plays a role here.",
            "I don't know.",
            "I fixed the initial condition actually.",
            "Yes.",
            "Right, so this is the thing to be optimized.",
            "So the only thing we need.",
            "Remember, we have we need the marginals, but we also have an approximation for the conditional, so we need consistency between the marginals and the conditionals, like in a graphical model like in, for instance beta free energy.",
            "So.",
            "Right, so this is the slightly."
        ],
        [
            "Inflated picture if you do this so you have your Q, you have your posterior and there is a Lagrangian there.",
            "A bit stuff that depend on the on the noise.",
            "Well sorry they should could be a simple Sigma observation squared and so this is a part coming from the prior and there's a part coming from the observations.",
            "So that that is the slight change by adding the observations you get a bunch of Delta functions at.",
            "If you want to write everything under a time integral, you get some Delta functions.",
            "So how do we do this in practice?"
        ],
        [
            "Well, we need to establish the consistency between the marginals.",
            "We know that in our approximating posterior Gaussian process we have a drift and if we know the marginal here and we know what the drift.",
            "If it is, we know we can find out what the marginal at the next point is, so everything has to be consistent and a similar equation has already appeared this morning, so there is a differential equation for the mean for the marginal mean in the marginal covariance, which is given by this and that.",
            "So this is our exact equations for Gaussian diffusions where A&B were essentially these two parameters that we had.",
            "In the model, so remember A&B came from.",
            "Came from here, so our assumption was we have a linear drift which is linear in X and it was parameterized by A&B and these A&B's.",
            "They tell you how you go from one marginal distribution at some time T to the next time T plus Delta T. And so these equations have to be put in as constraint into the Lagrangian into the KL divergent that we want to optimize.",
            "So the idea was.",
            "Well, skip that.",
            "So the idea was just write down a Lagrangian function, so this is the thing that we want to minimum."
        ],
        [
            "Lies.",
            "But we have also a bunch of constraints to fulfill between the the marginal covariance and the marginal means and the variational parameters A&B, so we put them into such a LaGrange function.",
            "I don't know if it's a very naive thing, but this is what we came up with and so treat this problem and do an independent variation with respect to a B the marginal covariance of the marginal mean.",
            "And say this is now the optimum that we get.",
            "So.",
            "What do we get?",
            "Well, it's interesting you can actually, if you forget about the Gaussian variational method and look for the truth, what is the true posterior prediction you can deal with that in a similar way?",
            "Now you say OK, I don't have only a mean and a variance, but I have a whole probability density to propagate and I put it also under a Lagrangian function.",
            "Now the lagrangian."
        ],
        [
            "Multiplier is a function of X and time, and the Fokker Planck operator tells you how you go from the marginal density at time T to the marginal density at time T plus Delta T, but it's no longer a Gaussian approximation, it's the full thing, and then you can actually see what you would have to do in order to compute the posterior process.",
            "The posterior process will have a drift G which is equal to the old.",
            "Um, drift to the prior drift plus something which is a solution to the backward equation and there is a bunch of jump conditions, and so it's a it's a way.",
            "So just wanted to see if this formulism gives us what we know.",
            "So this is sort of the thing.",
            "If you didn't want to do a Gaussian approximation but solve the true thing.",
            "Right, so this is probably a bit boring.",
            "You just do with."
        ],
        [
            "Relational equations and they help you to eliminate some of the some of the parameters and at some point you end up.",
            "Um, being able to do analytical stuff and you have to do some numerics so the next step is now."
        ],
        [
            "Come up with an algorithm that computes the stationary paths of this Lagrangian function.",
            "So our suggestion was the following start somewhere.",
            "And actually, the starting point was the solution to to an ordinary Gaussian process regression.",
            "So it's not a dumb estimate, but it's a kind of a guest guest estimate.",
            "Then you say, well, I have to propagate forward the moment equations for the marginals forward in time.",
            "I also have to solve then backwards, so if I have a forward sweep I have to do a backward sweep with given marginals I have to determine the LaGrange parameters of my problem and you have to solve these backwards and anytime you see and observe."
        ],
        [
            "They shun it.",
            "Turns out if you look at the mathematics, anytime you see an observation so you come from backwards.",
            "I don't know from backwards from you, probably from here.",
            "So you come from there and you see an observation.",
            "Then your LaGrange parameters do something they jump, and then you solve between the observations.",
            "Again, the.",
            "Nonlinear differential equations.",
            "And that's what you hope to get convergence.",
            "So, just to summarize, what have we achieved?",
            "We have replaced all the zigzagging thing by ordinary nice differential equations, hopefully for some nice functions.",
            "And let's see.",
            "So you applied again because you hope this makes sense to something that you know exactly because you know the Ornstein Uhlenbeck process is again."
        ],
        [
            "See and process.",
            "So if you use your formulism you should recover the exact result, so that's what we did.",
            "So this is the orange diamondback process.",
            "He had a couple of.",
            "So this is a realization, and so I think the red points.",
            "No, yeah, the green the green line is just connecting the slightly noisy observations and the green.",
            "No, the red is is just our prediction for the path.",
            "The optimal prediction, say a well optimal come on.",
            "This is fluctuating, but this is this is the Bayes optimal prediction for for this process.",
            "And so you see is this is.",
            "This is something that this LaGrange parameter does, so it really is a bit of a nasty object, it's it's it's anytime it sees an observation it jumps and then it relaxes again and then it's kicked again anytime it sees.",
            "And observation, so we solve that using this backward forward forward backward algorithm and it converged fine.",
            "Um?",
            "The next thing is of course it's getting interesting when you have a bistable system and that's what people are."
        ],
        [
            "More interested in so you have a system which is driven by.",
            "Yes, you have a.",
            "Is this the prior information about your system?",
            "It's something that that lives in this double well potential.",
            "It doesn't over damped motion, so you can read this as an overdamped motion in such a.",
            "Potential where the where the force is the gradient of such a thing, so it can just jump from here to there.",
            "So we generate prior paths for this thing and for awhile nothing happens.",
            "The particle just moves in here, so we discard all those and then we wait until we get this jump.",
            "And then we say can we do inference in this window?",
            "Yes, so let's see.",
            "Yeah, so we try to see what what, what other people.",
            "Well other methods do so."
        ],
        [
            "So this is again a picture I've shown you before, and that is probably not so good.",
            "We just ignore it.",
            "All these spy stability and just said we do a vanilla Gaussian process regression and so this misses a bit.",
            "Yeah, the severity of the jump and here this is don't know exactly how it works.",
            "It's an ensemble Kalman smoother.",
            "It sees that there is a there is a jump at it, sort of.",
            "It doesn't locate it at the right position, and I think there's also something you have in in your paper."
        ],
        [
            "And yeah, so these are the ODS we would we have.",
            "We had to solve and."
        ],
        [
            "Yes, so this is what we got.",
            "Um?",
            "So we say, OK, this is reasonable, so this is the red thing is our prediction and there is an error bar.",
            "So you also see there are these little cusps and they are real because we have this, there's a stochastic differential equation.",
            "These cusps are really there.",
            "We say if we had a smooth noise process they weren't there.",
            "But this is not an artifact of the method.",
            "That is something that comes out, you know, because of the jumps of the LaGrange multipliers and that is a comparison with.",
            "Well, we have to see I mean this is more recent stuff with a Markov chain Monte Carlo who's actually using one of your methods and I hope we all do the right thing is there's always a bit of a problem to exchange.",
            "You see there's slight differences.",
            "I mean, well, we just.",
            "Yeah, so so yeah you see, here is.",
            "Yeah, there's a slight difference and important differences at the end, so the system moves on.",
            "This was the last observation because of the Gaussian approximation.",
            "Somehow you end up in in this minimum, and so you're getting stuck there.",
            "But what the Monte Carlo approach seems to do is the following thing.",
            "You don't know anymore where you are after awhile, and then you diffuse, but now you diffuse in the full double well.",
            "And you get a much bigger uncertainty and also the mean moves again to the true mean.",
            "But unfortunately in our case the Gaussian because you have this bistable thing, the Gaussian is stuck in one of the minimum, so that already gives gives us a bit of a problem, and this is probably a point to be discussed.",
            "So the Gaussian thing is sort of a bit limited.",
            "It doesn't see the other doesn't see the other potential well.",
            "When you don't have any observations, so it's getting stuck there, but in between it's smooth.",
            "This I thought fairly well right, but we have to say there's a few.",
            "A few little problems in getting this actually to converge.",
            "It turns out that the backward forward I mean correct me if I'm saying anything wrong that the backward forward is not so.",
            "Is not so stable as we hoped it would be, so some of the LaGrange functions turn out to be.",
            "They would love to run away to minus Infinity and you have to prevent them from doing this and solving solving a constrained problem and seeing that the final result is not sensitive to how you clamp this.",
            "So we see at the end that with good accuracy all our variational equations are fulfilled and we're happy, but it's not not yet a nice method.",
            "But I think I'm approaching the end of my talk slightly, do I?",
            "Yes, Sir.",
            "You just tell me how many minutes I got.",
            "Yeah, so just wanted to mention I and then we played a little bit with an attempt of getting rid of the Lagrangian parameters.",
            "Five OK?"
        ],
        [
            "And five I can do a lot so.",
            "So I thought maybe it's like I have always this problems in understanding LaGrange parameters.",
            "Maybe this is my personal problem, so I tried to get rid of them and and replace them by by something by the observables.",
            "Essentially by the means and the marginal means, and the variance is of the Gaussian process.",
            "So you can play a little bit with this Lagrangian function that we had that we wanted to minimize.",
            "And Ascentia Lee wanted to use these two equations in order to.",
            "Just get rid of the variational parameters A&B and replace them instead by M and it's time derivatives and S and it's time derivative so that you might end up with a nice LaGrange function that depends on on means and variances in their time derivatives.",
            "And this you can do essentially in the case where you force field is a gradient of a potential energy, funny enough, and so if you play with this.",
            "At least you get a nice expressions in dimension 1."
        ],
        [
            "So it turns out dimension one.",
            "You can get this action which you have to make stationary, which is essentially.",
            "This has the sorry there should be an S. There's the standard deviation, so it's an action that depends on the marginal mean.",
            "The marginal standard deviation, and it's time derivative and an effective potential.",
            "That depends only on mean and variance, so it's a funny object, so which looks very much like in mechanics.",
            "The only thing I did was staring at it and hoping that it reveals some of his secrets.",
            "So at least it would be nice to have a function I don't have anymore LaGrange parameters, but I can do sort of ordinary LaGrange mechanics with it.",
            "So I get Hamilton's equations, for instance, for this type of thing.",
            "There's of course data."
        ],
        [
            "And the data turns essentially tell you you have to solve these things in anytime you have an observation, then your momentous at the momenta corresponding to the means and the corresponding the momenta corresponding to the variances.",
            "They jump.",
            "Anytime you see an observation and you have to solve that, we didn't yet.",
            "So the only thing is if you stare a little bit."
        ],
        [
            "At this, for the Ornstein Uhlenbeck process it seems to make sense and here is this effective potential for the on standalone back process which actually separates in the mean.",
            "Well that should be a mean of course the mean and the variance is so let's see you having a simple example.",
            "This is the potential for the means.",
            "Well it doesn't look like a nice one but it's the right one.",
            "Let's say I start from here and I have an observation here.",
            "Then it means the particle just travels from here to there.",
            "And is accelerat, so it goes from zero and has an observation at at at time five at X = 3, so it just runs away and that would be the way the mean goes with time.",
            "What does the variance do?",
            "A variance?",
            "So if I start from zero, so the variance the potential for the variance it starts from."
        ],
        [
            "Zero, it bounces to its maximal variance and comes back, so you're at zero.",
            "You get a maximal uncertainty, but since you make a measurement, a perfect measurement at the end, you get a variance 0 again.",
            "So you can stare at these potentials and say OK, seems to make sense.",
            "Now what happens if you go to your nice double well potential?"
        ],
        [
            "Yeah, yeah, so I don't know maybe."
        ],
        [
            "At some point in a discussion, you have two dimensional things and you get 3 dimensional plots and I'm very bad at those things and so to summarize, this last part of it.",
            "Well, the first part is summarize the first part first.",
            "We have a LaGrange formulation with LaGrange multipliers.",
            "We have backward forward algorithm but not a guarantee for convergence and probably there are some communities that they know about these things and maybe it can be cured.",
            "There's an alternative that seems to make sense for the case where we have a force field with a potential energy so you can write down something that looks very much like Hamilton mechanics, which I found simply neat and I don't know if it leads to anything practical, but when I find something theoretically need I do it.",
            "Anyhow, so I'm.",
            "Got 10 years so I can do that right?",
            "So so this is it and just to end with a final with a list of things that we would love to do and actually it was at the end here but I got some more ideas."
        ],
        [
            "Well, the first thing I already mentioned right?",
            "Get something to make this converge.",
            "Then of course in practice for practical purposes there might be we have to make some optimal unset.",
            "See restrict our Gaussian processes to something that is that is easier to parameterized.",
            "Maybe something where some parameters are constant between two observations and things like that.",
            "Well, we haven't talked about multiplicative noise, I guess in many practical applications we have not a constant diffusion, but also a state dependent diffusion.",
            "Multiplicative noise, can we do that?",
            "Don't know.",
            "Well of course other processes.",
            "At the moment we driving of course with Wiener processes, but there might be interesting problems.",
            "Neil is going to talk about this this afternoon where you have priors over functions that are smooth.",
            "Well could we do such a thing for other smooth processes?",
            "And it's funny enough?",
            "This is a sort of a religious problem now.",
            "I mean you could do PAC Bayesian bounds like Matthias Egger did for Bayesian things.",
            "Some people might say.",
            "We don't want to do that, so OK other site.",
            "Well, some of our some of the people in the in the committee and in the consortium are sort of non bayesians.",
            "They're happy with that.",
            "Something probably that's not going to work because everybody tells me it's not going to work, but I want to be convinced.",
            "Important sampling we have now a prior something to sample from and people say the variational Gauss, the factorizing one.",
            "That's not a good idea to do important sampling.",
            "I'm not sure if it's the same argument.",
            "Apply immediately to this.",
            "The final nice thing with Gaussians is, well, at least in physics.",
            "We know we can sort of improve that step by step.",
            "Not really improved, but we may get a divergent perturbation series which we can re somewhere.",
            "Do other tricks with at least it has a principled way of improving step by step on that result using perturbation theory and this is well established.",
            "We know we can write down corrections using Feynman, Feynman, Feynman, Feynman, graphs and things like that, so this is probably also something to look at, and I think this is enough.",
            "Thank you very much.",
            "So I think it's very, very nice work.",
            "Thank you, Beth.",
            "This goes back to your slide way.",
            "It is cumulation of minus signs.",
            "Accumulation of minus signs.",
            "In this last part, the potentially the - before yes here this one.",
            "One more day.",
            "Yes.",
            "Yes.",
            "Yes.",
            "Yes, just.",
            "Is that if you have a normal Hamiltonian system, yes, some potential energy minus.",
            "The kinetic energy.",
            "Yes, that's kinetic minus potential and I write it in such a way, yes.",
            "There.",
            "Added beings so whereas in a normal system you say I have a fixed energy, you can divide it over extreme ocean or storing potential energy and it is a you know it has some tool constant actually controls different because there is potential is something you want to avoid is it is the area of high costs.",
            "And so it means that in the places of high costs you gotta speed up very fast.",
            "You want to get through those so HD you have there in a control issue.",
            "You have the difference of potential energy.",
            "And kinetic energy is constant.",
            "And it seems that this is also happening here.",
            "Yeah, I can't, I well, I don't really know the connection to to control yet.",
            "That's something we have to.",
            "We have to explore.",
            "The normal timing system, yet that the sum of his energies, yes.",
            "The difference is that the trajectory is chosen such that no, but you still have an energy conservation in this case, so between between two observations, the system conserves energy in such when the energy is now defined by kinetic plus V. So this is order.",
            "This Is Us.",
            "This is really ordinary classical mechanics.",
            "Yes, right?",
            "Yeah yeah, but I wanted to write it in such a way that resembles a LaGrange function.",
            "Yeah, well, maybe this is just a.",
            "So we didn't, yeah.",
            "Alright.",
            "Effective may be reminiscent of the minus in education control.",
            "OK, good.",
            "Yes, I don't know who was first.",
            "OK for the non gas in case I didn't quite understand your slide on that, but would it be related to taking the a capital A's that you find as optimal Ann and asking that that those be approximating the derivative?",
            "So on the near F those points in states so so you mean a should approximate the gradient of F somehow?",
            "Yeah it does, but they are not equal so they actually they are the differences is proportional to one of the LaGrange.",
            "From meters and so now if F isn't if if F is not linear and not known, yes, could you use that personality to try to constrain?",
            "OK, the problem is I have to say we at the moment we assume we know F Annina next step we would say we we we, we we we play with parametric X and then use the free energy in order to select the best parameters.",
            "So this we haven't yet done.",
            "I mean this goes on top.",
            "We have an expression for the free energy and we can use it.",
            "We hope to use it using a result.",
            "Not sure.",
            "I'm not sure if that's true.",
            "No, no no.",
            "I have to see.",
            "Yes, yes Sir, sorry.",
            "You have perfect measurements, yes, no no, but that was just for illustration.",
            "In general, I assume that there is some measurement noise.",
            "Like this?",
            "So.",
            "Space.",
            "So in the in the Lagrangian formulation, this is the observation noise that the variance of the observation noise and it shows you you your LaGrange parameter jump by such an amount.",
            "Yes.",
            "I guess you guys are being way too hypercritical of your solution on bistable case, but so if a Gaussian works, why not a couple of 'em?",
            "So why not have basically parametrization of basic a combination of Gaussians?",
            "Yeah, the problem.",
            "The problem is in the variational world.",
            "This doesn't seem to be a simple thing.",
            "I mean, people have tried mixtures of Gaussians rather than Gaussians in.",
            "Yeah, many years ago and it turned out it's not so simple and it would mean we would have to do a mixture of Gaussian processes.",
            "Probably then they could be nasty.",
            "It means it's coupled with forwarding.",
            "The backwards becomes couple, that's yeah.",
            "Miracle solution difficult.",
            "It would have to do that.",
            "I mean, it seems like because if we're not only interested in smoothing, but in making forecasts, then we'd rather be able to to avoid these problems where we don't have any data.",
            "Schedule questions."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This this talk is actually the joint of an effort of the workshop organizers, together with then confort and sort of our problem was we try to come up with a variational Gaussian approximation to stochastic differential equations.",
                    "label": 1
                },
                {
                    "sent": "And this is very much related to the second talk this morning, but it's probably going to be a bit more theoretical and less practical because we were just after finding out what is the best Gaussian approximation in the variational sense, and there will be the question if we can make something practical out of it.",
                    "label": 0
                },
                {
                    "sent": "So the outline of the talk would be I will speak about the Gaussian variational method for is just.",
                    "label": 0
                },
                {
                    "sent": "Remind you of the finite dimensional case, then move on.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The infinite dimensional case, meaning the application to stochastic differential equations because we have infinite time and that means the infinite dimensionality.",
                    "label": 1
                },
                {
                    "sent": "This whole variational method will end up with a LaGrange function and you try to set up Lagrangian equations for them and try to solve them.",
                    "label": 0
                },
                {
                    "sent": "For simple model problems.",
                    "label": 0
                },
                {
                    "sent": "And it turns out for certain systems there might be a different funny interpretation in terms of a Hamiltonian, and in this case I don't really know if this will have any applications, but I found this quite neat, so I'm going to present it anyhow.",
                    "label": 0
                },
                {
                    "sent": "And so just let me start right away with the variational method that we know in the machine learning community.",
                    "label": 1
                },
                {
                    "sent": "So the variational method in Bayesian modeling is simply.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You have a posterior.",
                    "label": 0
                },
                {
                    "sent": "So this is the variable X, that's the hidden variable that we don't know why our observations say might be a parameter that we try to optimize later.",
                    "label": 0
                },
                {
                    "sent": "So we approximate the intractable posterior by something that lives in a tractable family and tractable is of course means related to what we actually can do with our computers.",
                    "label": 0
                },
                {
                    "sent": "So it might depend on.",
                    "label": 0
                },
                {
                    "sent": "Yeah, our power.",
                    "label": 0
                },
                {
                    "sent": "So in most applications and there's huge number of applications you find in lost in the last couple of years in NIPS, so you choose F to be factorizing distributions which factorize in all the variables or in groups of variables.",
                    "label": 0
                },
                {
                    "sent": "So in this hasn't actually an advantage.",
                    "label": 0
                },
                {
                    "sent": "We can show what is the form of the optimal Q in such a family.",
                    "label": 0
                },
                {
                    "sent": "There's a free form optimization possible and then we can do a sequential.",
                    "label": 0
                },
                {
                    "sent": "Method for optimizing these approximating probabilities Q there's of course another wonderful family of distributions that we know and we can handle.",
                    "label": 0
                },
                {
                    "sent": "Usually very, very well, and that's the family of Gaussian distributions.",
                    "label": 1
                },
                {
                    "sent": "It seems like that this family has not found so many friends in the machine learning community when it deals.",
                    "label": 0
                },
                {
                    "sent": "When we deal with the variational method.",
                    "label": 1
                },
                {
                    "sent": "And, well, I'm probably not probably a complete list, but I I remember only a couple of cases.",
                    "label": 0
                },
                {
                    "sent": "For instance, David, Barber, Ann, and Chris Bishop, who dealt with Bayesian neural networks.",
                    "label": 0
                },
                {
                    "sent": "There was a paper of Matthias Egger and very recently by organizing the workshop we learned the paper and about the paper of Honkala in Valpo Law.",
                    "label": 0
                },
                {
                    "sent": "Of course, and one of the arguments that people often bring forward and have brought forward is probably, well, if you have a variational Gaussian approximation.",
                    "label": 0
                },
                {
                    "sent": "You have to optimize the mean and the covariance matrix.",
                    "label": 0
                },
                {
                    "sent": "Of course, a covariance matrix is a big object.",
                    "label": 0
                },
                {
                    "sent": "You have a matrix of in, well, you have a thing of N squared parameters.",
                    "label": 0
                },
                {
                    "sent": "Well, have it you because it's symmetric and so probably it's something that has too many parameters to be optimized.",
                    "label": 0
                },
                {
                    "sent": "And then you might think of suboptimal solutions and things like that, so it's not probably such a nice thing.",
                    "label": 0
                },
                {
                    "sent": "Well, there are other other problems as well.",
                    "label": 0
                },
                {
                    "sent": "You cannot.",
                    "label": 0
                },
                {
                    "sent": "You cannot approximate discrete random variables, yes?",
                    "label": 0
                },
                {
                    "sent": "Please, sorry.",
                    "label": 0
                },
                {
                    "sent": "Of.",
                    "label": 0
                },
                {
                    "sent": "Practice at least what we do is playing the combining these two so it's Gaussian right, right, right, right.",
                    "label": 0
                },
                {
                    "sent": "Some rank one.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Number.",
                    "label": 0
                },
                {
                    "sent": "For instance, we have.",
                    "label": 0
                },
                {
                    "sent": "Gas and where?",
                    "label": 0
                },
                {
                    "sent": "We have this other random field with which connects the consecutive.",
                    "label": 0
                },
                {
                    "sent": "States.",
                    "label": 0
                },
                {
                    "sent": "But this is classified with restricted Gaussian, yes.",
                    "label": 0
                },
                {
                    "sent": "Yes, so there's a question you can come up with restricted classes of Gaussians, but it turns out there's also something that, well, some people know.",
                    "label": 0
                },
                {
                    "sent": "It's some people with whom I talk to seem to well are aware of that fact in some cases, actually the true, the best.",
                    "label": 0
                },
                {
                    "sent": "Gaussian has also a very simple well rather simple representation, and that's what I'm going to show you first in the discrete and discrete case, and then for the stochastic differential equations.",
                    "label": 0
                },
                {
                    "sent": "So we were going for the optimum and see.",
                    "label": 0
                },
                {
                    "sent": "That it can be represented in a search.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Anyway, so this would be the finite dimensional case.",
                    "label": 1
                },
                {
                    "sent": "So again here is Bayes Theorem P of X.",
                    "label": 0
                },
                {
                    "sent": "Given the data in a parameter, is this an one way of writing the variational method?",
                    "label": 1
                },
                {
                    "sent": "So remember the variational method.",
                    "label": 1
                },
                {
                    "sent": "We tried to minimize the kullback Leiber divergance between Q, which is the variational.",
                    "label": 0
                },
                {
                    "sent": "Approximation and P, which is the untractable true posterior, so it's the unsymmetric one where we have Q on the light on the left hand side and we can compute this KL so another formulation is we minimize a so-called variational free energy.",
                    "label": 1
                },
                {
                    "sent": "Which is mine.",
                    "label": 0
                },
                {
                    "sent": "Is the entropy and the average logarithm of the probability and of course for Gaussians we know that the entropy only depends on the covariance matrix.",
                    "label": 0
                },
                {
                    "sent": "So if we look at this for Gaussians.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For Gaussian families, then, the variational entropy with the entropy would only depend on the logarithm of the determinant, and if you just set the gradient of the free energy equal to 0, then you get 2 equations.",
                    "label": 0
                },
                {
                    "sent": "First of all, the one for the mean, which says well on average the log probability of the model should be 0 and the other one gives you the inverse covariance matrixes.",
                    "label": 0
                },
                {
                    "sent": "Essentially equal to the gradient of log P with respect to Sigma.",
                    "label": 0
                },
                {
                    "sent": "There's a funny thing.",
                    "label": 0
                },
                {
                    "sent": "A funny property of Gaussian averages.",
                    "label": 0
                },
                {
                    "sent": "You can also replace that the first derivative with respect to the.",
                    "label": 0
                },
                {
                    "sent": "Covariance matrix by a second derivative with respect to X is so it's in some sense an average Laplace approximation.",
                    "label": 0
                },
                {
                    "sent": "So this says Laplace means you have to find a point where the derivative, the gradient of log P is 0, and then you have to estimate the covariance matrix by the 2nd derivative at that point and the Gaussian variational method does the same but on average.",
                    "label": 0
                },
                {
                    "sent": "So this is a funny reformulation of that.",
                    "label": 0
                },
                {
                    "sent": "And this would be a simple plot, so the red one is the true.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Function you try to approximate the green one would be the Laplace approximation centered here with the same curvature and the Gaussian variational method is not local.",
                    "label": 0
                },
                {
                    "sent": "In that sense.",
                    "label": 0
                },
                {
                    "sent": "It not only concentrates at this point or its infinitesimal neighborhood, it just looks, it just looks at the global thing and then approximates this thing by something which is which takes more into account the full.",
                    "label": 0
                },
                {
                    "sent": "Shape, at least there is more mass on this direction, and it's a fairly reasonable estimate of the mean.",
                    "label": 0
                },
                {
                    "sent": "The variance, of course is not perfect, but OK, so it does a better job than the plus approximation that simple case.",
                    "label": 0
                },
                {
                    "sent": "And if you now look at a class of posteriors that have the form that we know very well in.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Gaussian process approximations where we have a part that is already Gaussian coming from the prior and this K is the kernel matrix and we have something which is which is usually the data part.",
                    "label": 0
                },
                {
                    "sent": "So that depends.",
                    "label": 0
                },
                {
                    "sent": "So this would factorize in the variables in the latent variables X and then you'll see that the covariance the inverse covariance is just the inverse kernel plus a diagonal thing at the optimum, so essentially.",
                    "label": 0
                },
                {
                    "sent": "The covariance matrix can be parameterized by a diagonal matrix, at least the inverse one, so you have in fact for these types of models only two N parameters to optimize the mean and these diagonal matrix.",
                    "label": 0
                },
                {
                    "sent": "Yeah, the diagonal matrix.",
                    "label": 0
                },
                {
                    "sent": "So in fact the covariance matrix is something more.",
                    "label": 0
                },
                {
                    "sent": "Complicated, but the inverse is just the old inverse plus a diagonal matrix.",
                    "label": 0
                },
                {
                    "sent": "Well, some people know that already, and but I wasn't sure if everybody knows it, because some people argued Oh no, it's not OK.",
                    "label": 0
                },
                {
                    "sent": "So just anyhow, I thought somebody has to do it and say it and then maybe publish it.",
                    "label": 0
                },
                {
                    "sent": "So this is just an example, if you run.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This on the on on on this very simple regression problem, but this time with Laplace noise.",
                    "label": 0
                },
                {
                    "sent": "So you have a bunch of outliers here because of the more heavy tails of the noise and so the red curve is, well, you ignore the Laplacian, do just the regular fitting of Gaussian processes and the blue one.",
                    "label": 0
                },
                {
                    "sent": "Well, it tells you well.",
                    "label": 0
                },
                {
                    "sent": "OK, no, the other way round, the blue is of course the one that is sort of less robust in the red one is the.",
                    "label": 0
                },
                {
                    "sent": "The Laplace and so this one optimizes the hyperparameters and you can do a. Quasi Newton updates and it works.",
                    "label": 0
                },
                {
                    "sent": "It works OK so now, but this just to to tell you that in some cases the Gaussian approximation doesn't have so many parameters.",
                    "label": 0
                },
                {
                    "sent": "I want to move on to the infinite dimensional case and now we're back at the stochastic differential equations stochastic trend.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Differential equations, so our problem setting is the following.",
                    "label": 1
                },
                {
                    "sent": "We have a time evolution of a state function X.",
                    "label": 0
                },
                {
                    "sent": "With a general nonlinear function, FX driven by wienner process and for instance I just for simplicity, I just say all these variances are the same and replace it by a simple Sigma here.",
                    "label": 0
                },
                {
                    "sent": "And then we have noisy observations of the hidden process at certain times and certain discrete times Tien.",
                    "label": 1
                },
                {
                    "sent": "And that's the problem.",
                    "label": 0
                },
                {
                    "sent": "We try to compute, make inference about the function X50 conditioned on the on the observations based on the prior knowledge that we have from this process.",
                    "label": 0
                },
                {
                    "sent": "So the prior knowledge is, well this process, but it's a non Gaussian process.",
                    "label": 0
                },
                {
                    "sent": "Of course if F of X.",
                    "label": 0
                },
                {
                    "sent": "Is a nonlinear function, so we are dealing with a regression problem where the prior is non Gaussian and we can't really easily handle it and so this is kind of an implicit type of observation that we have.",
                    "label": 0
                },
                {
                    "sent": "Information, sorry.",
                    "label": 0
                },
                {
                    "sent": "Right, So what we wanted to do is, yeah, that's sort of the goal.",
                    "label": 0
                },
                {
                    "sent": "We tried to predict the latent path.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that would in this case be the unknown function.",
                    "label": 0
                },
                {
                    "sent": "I think it's it's yours, and here are some noisy observations and well, that would be probably not so good prediction of the unknown latent path, and we also like to get maybe an error bar.",
                    "label": 0
                },
                {
                    "sent": "And we claim maybe we can do better.",
                    "label": 0
                },
                {
                    "sent": "So what did we hear?",
                    "label": 0
                },
                {
                    "sent": "So we completely ignored?",
                    "label": 0
                },
                {
                    "sent": "The prior information or the nonlinearity and said, OK, let's use a vanilla Gaussian process regression problem where we have a radial basis function kernel and we optimize the kernel parameters, but we ignore that this is actually something.",
                    "label": 0
                },
                {
                    "sent": "Well, it comes from a bistable problem, so it's a it's a potential that has two minima and it can flip between two things.",
                    "label": 0
                },
                {
                    "sent": "But this simple application of a Gaussian process regression doesn't know about this thing, so it interprets the data is sorry.",
                    "label": 0
                },
                {
                    "sent": "A little bit in a wrong way so it doesn't see that.",
                    "label": 0
                },
                {
                    "sent": "Here is a sudden transition and so on.",
                    "label": 0
                },
                {
                    "sent": "OK, so just simply to demonstrate, it might be useful to do more than just what we then just an ordinary Gaussian process regression.",
                    "label": 0
                },
                {
                    "sent": "So first when we do Bayesian analysis, we have to talk about priors, so the prior induced by the state.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Differential equation I presented here in a discretized form in order to avoid problems with the more more fancy things like Ito Anstrom knowledge that was explained.",
                    "label": 0
                },
                {
                    "sent": "Well, probably no.",
                    "label": 0
                },
                {
                    "sent": "There was no Stratonovich this morning in Chris Williams.",
                    "label": 0
                },
                {
                    "sent": "Is talk well was there.",
                    "label": 0
                },
                {
                    "sent": "I don't remember.",
                    "label": 0
                },
                {
                    "sent": "OK so.",
                    "label": 0
                },
                {
                    "sent": "For the, for simplicity we work.",
                    "label": 0
                },
                {
                    "sent": "We work with the discrete time process to avoid any problems, so it means the change in the variable XK is given by.",
                    "label": 1
                },
                {
                    "sent": "Well, this forest times Delta T. And of course there is this stochastic element that scales with the square root of Delta T. As explained this morning by Chris Williams and Delta T is the time increment and epsilon case IID Gaussian noise.",
                    "label": 0
                },
                {
                    "sent": "Now we can write down the probability density for such a discrete path.",
                    "label": 1
                },
                {
                    "sent": "And well, since these noises are Gaussian, we get a product over all these conditional things here.",
                    "label": 0
                },
                {
                    "sent": "So we know that the difference between escape between Delta XC and this must be a Gaussian random variable.",
                    "label": 0
                },
                {
                    "sent": "So this is the proper joint probability for all the X case.",
                    "label": 0
                },
                {
                    "sent": "The discretized XK.",
                    "label": 0
                },
                {
                    "sent": "So this is well defined.",
                    "label": 1
                },
                {
                    "sent": "We're not going immediately to the Continuum, so this is prior.",
                    "label": 1
                },
                {
                    "sent": "And the prior is of course non Gaussian.",
                    "label": 0
                },
                {
                    "sent": "Let me see, Oh yes, I said there might.",
                    "label": 0
                },
                {
                    "sent": "There's a possibility to this to do right is a bit more fancy.",
                    "label": 0
                },
                {
                    "sent": "Yes, please.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Station is fixed in fixed intervals.",
                    "label": 0
                },
                {
                    "sent": "Yes, yes yes I did yes.",
                    "label": 0
                },
                {
                    "sent": "Of course, one might argue, isn't it possible to represent like a measure over continue over over the the?",
                    "label": 0
                },
                {
                    "sent": "Continuous time paths and you can do that with some with some if you were carefully and use a bit of.",
                    "label": 0
                },
                {
                    "sent": "Well, the way I understand stochastic calculus, I mean not an expert, but in some sense you can sort of show that the measure where the force is zero in some sense converges to the something that's called the venar measure and the measure given by the stochastic differential equation relative to the Wiener measure can be.",
                    "label": 0
                },
                {
                    "sent": "Are written in such a way.",
                    "label": 0
                },
                {
                    "sent": "Well, you argue there are some things that have to be into that have to be replaced by integrals, but you have to be careful in the meaning of such integrals.",
                    "label": 0
                },
                {
                    "sent": "These are, as Chris Williams this morning explained, so called Ito integrals, and you have to give him a proper meaning.",
                    "label": 0
                },
                {
                    "sent": "You can also expresses in terms of Stratonovich integrals.",
                    "label": 0
                },
                {
                    "sent": "Then they look a bit different.",
                    "label": 0
                },
                {
                    "sent": "So the only thing is if you try to work from the start with the continuous time formulation.",
                    "label": 0
                },
                {
                    "sent": "It's possible, but you have to be careful.",
                    "label": 0
                },
                {
                    "sent": "What what these integrals mean?",
                    "label": 0
                },
                {
                    "sent": "So that would be a Stratonovich integral, and that means for me.",
                    "label": 0
                },
                {
                    "sent": "I can do things with this integral like doing integration by parts so the things people love to do with these things, but for our purpose we just work with a discrete time thing and only when it comes to expectations.",
                    "label": 0
                },
                {
                    "sent": "We set Delta T to zero at the end and find out that we get a nice nice result when it comes to expectations.",
                    "label": 0
                },
                {
                    "sent": "All the the non differentiability of the paths at the end vanish is.",
                    "label": 0
                },
                {
                    "sent": "The expectation seems to be very nice.",
                    "label": 0
                },
                {
                    "sent": "Functions, so we had the prior.",
                    "label": 0
                },
                {
                    "sent": "The prior was yes, just to remind the prior was this.",
                    "label": 0
                },
                {
                    "sent": "And the posterior is simply we have to multiply.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Prior with the likelihood of the observation, so go at.",
                    "label": 0
                },
                {
                    "sent": "This happens only at discrete times and said would be the whole normalization.",
                    "label": 0
                },
                {
                    "sent": "We have to do at the end to have this probability.",
                    "label": 0
                },
                {
                    "sent": "Normalized so this is the sequence of the observations and the partition function is the probability of the entire observed sequence, and this is always a discrete observed sequence and we have for simplicity assumed that the likelihood is now a Gaussian one, so this would be an option.",
                    "label": 1
                },
                {
                    "sent": "Slightly more complicated if it was non Gaussian, but we concentrated on the non gaussianity of the prior.",
                    "label": 0
                },
                {
                    "sent": "So now comes the variational approx.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Imation, so in machine learning this variational approximation again is formed by minimizing the KL divergent between certain measures Q that we can handle end the posterior measure that we can't handle easily.",
                    "label": 0
                },
                {
                    "sent": "So how should this Q look like?",
                    "label": 0
                },
                {
                    "sent": "So the first argument is well conditioned on the data.",
                    "label": 0
                },
                {
                    "sent": "The posterior process is still a Markov process, so let's look for Markov queues.",
                    "label": 0
                },
                {
                    "sent": "Then, well, we should reverse this slightly.",
                    "label": 0
                },
                {
                    "sent": "We want to work with Gaussian approximation.",
                    "label": 0
                },
                {
                    "sent": "So if it's a Gaussian.",
                    "label": 0
                },
                {
                    "sent": "Stochastic.",
                    "label": 0
                },
                {
                    "sent": "Markov process?",
                    "label": 0
                },
                {
                    "sent": "Well, maybe we should model this well, the only way of getting a Gaussian process is to work with a linear stochastic differential equation that represents that posterior Markov process.",
                    "label": 0
                },
                {
                    "sent": "So there must be a linear one.",
                    "label": 0
                },
                {
                    "sent": "That means we say the posterior is sort of generated approximately by a stochastic differential of such equation of such a form where this FL is a.",
                    "label": 1
                },
                {
                    "sent": "Linear term and that means we have two parameters essentially that we can play with.",
                    "label": 0
                },
                {
                    "sent": "It's the yeah this plus.",
                    "label": 0
                },
                {
                    "sent": "Plus a bias term be.",
                    "label": 0
                },
                {
                    "sent": "And it turns out you can show in the limit the noise variance, the optimal noise variance.",
                    "label": 1
                },
                {
                    "sent": "Well, there should be a Sigma.",
                    "label": 0
                },
                {
                    "sent": "Here has to be the same as the original 1, otherwise your KL divergences between the two processes must be becomes infinite.",
                    "label": 1
                },
                {
                    "sent": "So immediately this is already given by Sigma, so there's no yes please.",
                    "label": 0
                },
                {
                    "sent": "Yes afts.",
                    "label": 0
                },
                {
                    "sent": "Find me.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "No, no, we don't.",
                    "label": 0
                },
                {
                    "sent": "We don't replace it by a constant.",
                    "label": 0
                },
                {
                    "sent": "This is actually a very important thing.",
                    "label": 0
                },
                {
                    "sent": "It has to depend on the time, because when it sees an observation, it has to do something.",
                    "label": 0
                },
                {
                    "sent": "So anytime there is some.",
                    "label": 0
                },
                {
                    "sent": "No, that was wrong.",
                    "label": 0
                },
                {
                    "sent": "We have two parameter functions.",
                    "label": 0
                },
                {
                    "sent": "And that's that's, yeah, that's an important point point.",
                    "label": 0
                },
                {
                    "sent": "A&B are parameter functions to be optimized.",
                    "label": 0
                },
                {
                    "sent": "They're essentially parametrization of the conditional density, and yeah, so the noise variance.",
                    "label": 0
                },
                {
                    "sent": "It's easy, we know it has to be the same one, and that is now the family of our variational functions.",
                    "label": 0
                },
                {
                    "sent": "And we claim that this is this is the class the optimum has to be in that class.",
                    "label": 0
                },
                {
                    "sent": "Right, so this is an example of a Markovian posterior which you can actually solve by hand and easily.",
                    "label": 0
                },
                {
                    "sent": "So let's say I have a process starts at 0 and it would be avenar process an I have a single noise free observation at time one or time T, and then I find out that the prior, well, the prior force was zero.",
                    "label": 0
                },
                {
                    "sent": "It's avenar process, there's no drift, but then you can compute a posterior drift which depends on time.",
                    "label": 0
                },
                {
                    "sent": "And that essentially is yeah, that gives you precisely that behavior.",
                    "label": 0
                },
                {
                    "sent": "You start at zero.",
                    "label": 0
                },
                {
                    "sent": "Yeah, you diffuse a bit and at the end at the end point you have to come back to zero.",
                    "label": 0
                },
                {
                    "sent": "And this is this process is known as the Brownian Bridge and it has this drift term.",
                    "label": 0
                },
                {
                    "sent": "You can play the same game also for the Ornstein Uhlenbeck process which Chris has introduced this morning.",
                    "label": 1
                },
                {
                    "sent": "So the prior would be minus gamma X the prior drift and the posterior one.",
                    "label": 0
                },
                {
                    "sent": "Also depends on time and you see anytime you you reach the point where the observation is and it's a fixed observation, there's no noise.",
                    "label": 0
                },
                {
                    "sent": "So really you have to clamp the point X2 two it's too it's value.",
                    "label": 0
                },
                {
                    "sent": "This drift becomes infinite.",
                    "label": 0
                },
                {
                    "sent": "That's the only way of clamping the point and preventing it from diffusing away.",
                    "label": 0
                },
                {
                    "sent": "So this is this is a bed maybe yeah, so at least this.",
                    "label": 0
                },
                {
                    "sent": "This is what we get if you have a real, annoys free observation.",
                    "label": 0
                },
                {
                    "sent": "Then your linear drift term has to go to infinite to to achieve Infinity.",
                    "label": 0
                },
                {
                    "sent": "To achieve that.",
                    "label": 0
                },
                {
                    "sent": "In these cases these posterior FS, these linear ones are not approximations because the processes the prior processes that we started with were Gaussian already and the posterior ones are then also Gaussian because the observation was a trivial Gaussian with zero variance.",
                    "label": 0
                },
                {
                    "sent": "Right, yeah, So what can we do about the kullback, Leiber, divergent?",
                    "label": 0
                },
                {
                    "sent": "So we had set out with the problem of minimizing KL divergences.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That family of densities and it turns out you work with the discrete time formula formulation.",
                    "label": 0
                },
                {
                    "sent": "You calculate the KL divergent for the fixed for this fixed discretization and and you do your do your expectations and at the end you get a big sum and there's some scales nicely with Delta T, so you replace it by an integral and there's no square root of Delta T things left.",
                    "label": 0
                },
                {
                    "sent": "After doing the expectation, you end up with something nice and this something nice is is this thing?",
                    "label": 0
                },
                {
                    "sent": "So if you have two diffusion processes P1 and P2, and it turns out these sums become an integral, so it's an integral from zero to T, that's our time over which we want to approximate the process, and it's given by the difference between the two drifts.",
                    "label": 1
                },
                {
                    "sent": "The norm of the differences averaged over the at the same time and averaged over.",
                    "label": 1
                },
                {
                    "sent": "The the distribution P1.",
                    "label": 0
                },
                {
                    "sent": "So if we knew what the marginal distributions of our approximating process are at each time marginals at each time, then we could easily well at least we could formally calculate that object and that's what we need to do.",
                    "label": 0
                },
                {
                    "sent": "So yeah, so it's a.",
                    "label": 0
                },
                {
                    "sent": "It's a fairly simple surprisingly simple expression and you could get the same result if you work with these type of yeah, ITO integrals fit OK so I felt a bit more on the safe side if I do it like that, yes, please.",
                    "label": 0
                },
                {
                    "sent": "Yes, I had fixed the initial condition but I am not sure if this plays a role here.",
                    "label": 0
                },
                {
                    "sent": "I don't know.",
                    "label": 0
                },
                {
                    "sent": "I fixed the initial condition actually.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Right, so this is the thing to be optimized.",
                    "label": 0
                },
                {
                    "sent": "So the only thing we need.",
                    "label": 0
                },
                {
                    "sent": "Remember, we have we need the marginals, but we also have an approximation for the conditional, so we need consistency between the marginals and the conditionals, like in a graphical model like in, for instance beta free energy.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Right, so this is the slightly.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Inflated picture if you do this so you have your Q, you have your posterior and there is a Lagrangian there.",
                    "label": 0
                },
                {
                    "sent": "A bit stuff that depend on the on the noise.",
                    "label": 0
                },
                {
                    "sent": "Well sorry they should could be a simple Sigma observation squared and so this is a part coming from the prior and there's a part coming from the observations.",
                    "label": 0
                },
                {
                    "sent": "So that that is the slight change by adding the observations you get a bunch of Delta functions at.",
                    "label": 0
                },
                {
                    "sent": "If you want to write everything under a time integral, you get some Delta functions.",
                    "label": 0
                },
                {
                    "sent": "So how do we do this in practice?",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well, we need to establish the consistency between the marginals.",
                    "label": 1
                },
                {
                    "sent": "We know that in our approximating posterior Gaussian process we have a drift and if we know the marginal here and we know what the drift.",
                    "label": 0
                },
                {
                    "sent": "If it is, we know we can find out what the marginal at the next point is, so everything has to be consistent and a similar equation has already appeared this morning, so there is a differential equation for the mean for the marginal mean in the marginal covariance, which is given by this and that.",
                    "label": 0
                },
                {
                    "sent": "So this is our exact equations for Gaussian diffusions where A&B were essentially these two parameters that we had.",
                    "label": 0
                },
                {
                    "sent": "In the model, so remember A&B came from.",
                    "label": 0
                },
                {
                    "sent": "Came from here, so our assumption was we have a linear drift which is linear in X and it was parameterized by A&B and these A&B's.",
                    "label": 0
                },
                {
                    "sent": "They tell you how you go from one marginal distribution at some time T to the next time T plus Delta T. And so these equations have to be put in as constraint into the Lagrangian into the KL divergent that we want to optimize.",
                    "label": 0
                },
                {
                    "sent": "So the idea was.",
                    "label": 0
                },
                {
                    "sent": "Well, skip that.",
                    "label": 0
                },
                {
                    "sent": "So the idea was just write down a Lagrangian function, so this is the thing that we want to minimum.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Lies.",
                    "label": 0
                },
                {
                    "sent": "But we have also a bunch of constraints to fulfill between the the marginal covariance and the marginal means and the variational parameters A&B, so we put them into such a LaGrange function.",
                    "label": 1
                },
                {
                    "sent": "I don't know if it's a very naive thing, but this is what we came up with and so treat this problem and do an independent variation with respect to a B the marginal covariance of the marginal mean.",
                    "label": 1
                },
                {
                    "sent": "And say this is now the optimum that we get.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "What do we get?",
                    "label": 0
                },
                {
                    "sent": "Well, it's interesting you can actually, if you forget about the Gaussian variational method and look for the truth, what is the true posterior prediction you can deal with that in a similar way?",
                    "label": 0
                },
                {
                    "sent": "Now you say OK, I don't have only a mean and a variance, but I have a whole probability density to propagate and I put it also under a Lagrangian function.",
                    "label": 0
                },
                {
                    "sent": "Now the lagrangian.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Multiplier is a function of X and time, and the Fokker Planck operator tells you how you go from the marginal density at time T to the marginal density at time T plus Delta T, but it's no longer a Gaussian approximation, it's the full thing, and then you can actually see what you would have to do in order to compute the posterior process.",
                    "label": 1
                },
                {
                    "sent": "The posterior process will have a drift G which is equal to the old.",
                    "label": 0
                },
                {
                    "sent": "Um, drift to the prior drift plus something which is a solution to the backward equation and there is a bunch of jump conditions, and so it's a it's a way.",
                    "label": 0
                },
                {
                    "sent": "So just wanted to see if this formulism gives us what we know.",
                    "label": 0
                },
                {
                    "sent": "So this is sort of the thing.",
                    "label": 0
                },
                {
                    "sent": "If you didn't want to do a Gaussian approximation but solve the true thing.",
                    "label": 0
                },
                {
                    "sent": "Right, so this is probably a bit boring.",
                    "label": 0
                },
                {
                    "sent": "You just do with.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Relational equations and they help you to eliminate some of the some of the parameters and at some point you end up.",
                    "label": 0
                },
                {
                    "sent": "Um, being able to do analytical stuff and you have to do some numerics so the next step is now.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Come up with an algorithm that computes the stationary paths of this Lagrangian function.",
                    "label": 0
                },
                {
                    "sent": "So our suggestion was the following start somewhere.",
                    "label": 0
                },
                {
                    "sent": "And actually, the starting point was the solution to to an ordinary Gaussian process regression.",
                    "label": 0
                },
                {
                    "sent": "So it's not a dumb estimate, but it's a kind of a guest guest estimate.",
                    "label": 0
                },
                {
                    "sent": "Then you say, well, I have to propagate forward the moment equations for the marginals forward in time.",
                    "label": 1
                },
                {
                    "sent": "I also have to solve then backwards, so if I have a forward sweep I have to do a backward sweep with given marginals I have to determine the LaGrange parameters of my problem and you have to solve these backwards and anytime you see and observe.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "They shun it.",
                    "label": 0
                },
                {
                    "sent": "Turns out if you look at the mathematics, anytime you see an observation so you come from backwards.",
                    "label": 0
                },
                {
                    "sent": "I don't know from backwards from you, probably from here.",
                    "label": 0
                },
                {
                    "sent": "So you come from there and you see an observation.",
                    "label": 0
                },
                {
                    "sent": "Then your LaGrange parameters do something they jump, and then you solve between the observations.",
                    "label": 0
                },
                {
                    "sent": "Again, the.",
                    "label": 0
                },
                {
                    "sent": "Nonlinear differential equations.",
                    "label": 0
                },
                {
                    "sent": "And that's what you hope to get convergence.",
                    "label": 0
                },
                {
                    "sent": "So, just to summarize, what have we achieved?",
                    "label": 0
                },
                {
                    "sent": "We have replaced all the zigzagging thing by ordinary nice differential equations, hopefully for some nice functions.",
                    "label": 0
                },
                {
                    "sent": "And let's see.",
                    "label": 0
                },
                {
                    "sent": "So you applied again because you hope this makes sense to something that you know exactly because you know the Ornstein Uhlenbeck process is again.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "See and process.",
                    "label": 0
                },
                {
                    "sent": "So if you use your formulism you should recover the exact result, so that's what we did.",
                    "label": 0
                },
                {
                    "sent": "So this is the orange diamondback process.",
                    "label": 0
                },
                {
                    "sent": "He had a couple of.",
                    "label": 0
                },
                {
                    "sent": "So this is a realization, and so I think the red points.",
                    "label": 0
                },
                {
                    "sent": "No, yeah, the green the green line is just connecting the slightly noisy observations and the green.",
                    "label": 0
                },
                {
                    "sent": "No, the red is is just our prediction for the path.",
                    "label": 0
                },
                {
                    "sent": "The optimal prediction, say a well optimal come on.",
                    "label": 0
                },
                {
                    "sent": "This is fluctuating, but this is this is the Bayes optimal prediction for for this process.",
                    "label": 0
                },
                {
                    "sent": "And so you see is this is.",
                    "label": 0
                },
                {
                    "sent": "This is something that this LaGrange parameter does, so it really is a bit of a nasty object, it's it's it's anytime it sees an observation it jumps and then it relaxes again and then it's kicked again anytime it sees.",
                    "label": 0
                },
                {
                    "sent": "And observation, so we solve that using this backward forward forward backward algorithm and it converged fine.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "The next thing is of course it's getting interesting when you have a bistable system and that's what people are.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "More interested in so you have a system which is driven by.",
                    "label": 0
                },
                {
                    "sent": "Yes, you have a.",
                    "label": 0
                },
                {
                    "sent": "Is this the prior information about your system?",
                    "label": 0
                },
                {
                    "sent": "It's something that that lives in this double well potential.",
                    "label": 0
                },
                {
                    "sent": "It doesn't over damped motion, so you can read this as an overdamped motion in such a.",
                    "label": 1
                },
                {
                    "sent": "Potential where the where the force is the gradient of such a thing, so it can just jump from here to there.",
                    "label": 0
                },
                {
                    "sent": "So we generate prior paths for this thing and for awhile nothing happens.",
                    "label": 0
                },
                {
                    "sent": "The particle just moves in here, so we discard all those and then we wait until we get this jump.",
                    "label": 0
                },
                {
                    "sent": "And then we say can we do inference in this window?",
                    "label": 0
                },
                {
                    "sent": "Yes, so let's see.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so we try to see what what, what other people.",
                    "label": 0
                },
                {
                    "sent": "Well other methods do so.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is again a picture I've shown you before, and that is probably not so good.",
                    "label": 0
                },
                {
                    "sent": "We just ignore it.",
                    "label": 0
                },
                {
                    "sent": "All these spy stability and just said we do a vanilla Gaussian process regression and so this misses a bit.",
                    "label": 0
                },
                {
                    "sent": "Yeah, the severity of the jump and here this is don't know exactly how it works.",
                    "label": 0
                },
                {
                    "sent": "It's an ensemble Kalman smoother.",
                    "label": 0
                },
                {
                    "sent": "It sees that there is a there is a jump at it, sort of.",
                    "label": 0
                },
                {
                    "sent": "It doesn't locate it at the right position, and I think there's also something you have in in your paper.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And yeah, so these are the ODS we would we have.",
                    "label": 0
                },
                {
                    "sent": "We had to solve and.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yes, so this is what we got.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So we say, OK, this is reasonable, so this is the red thing is our prediction and there is an error bar.",
                    "label": 0
                },
                {
                    "sent": "So you also see there are these little cusps and they are real because we have this, there's a stochastic differential equation.",
                    "label": 0
                },
                {
                    "sent": "These cusps are really there.",
                    "label": 0
                },
                {
                    "sent": "We say if we had a smooth noise process they weren't there.",
                    "label": 0
                },
                {
                    "sent": "But this is not an artifact of the method.",
                    "label": 0
                },
                {
                    "sent": "That is something that comes out, you know, because of the jumps of the LaGrange multipliers and that is a comparison with.",
                    "label": 0
                },
                {
                    "sent": "Well, we have to see I mean this is more recent stuff with a Markov chain Monte Carlo who's actually using one of your methods and I hope we all do the right thing is there's always a bit of a problem to exchange.",
                    "label": 0
                },
                {
                    "sent": "You see there's slight differences.",
                    "label": 0
                },
                {
                    "sent": "I mean, well, we just.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so so yeah you see, here is.",
                    "label": 0
                },
                {
                    "sent": "Yeah, there's a slight difference and important differences at the end, so the system moves on.",
                    "label": 0
                },
                {
                    "sent": "This was the last observation because of the Gaussian approximation.",
                    "label": 0
                },
                {
                    "sent": "Somehow you end up in in this minimum, and so you're getting stuck there.",
                    "label": 0
                },
                {
                    "sent": "But what the Monte Carlo approach seems to do is the following thing.",
                    "label": 0
                },
                {
                    "sent": "You don't know anymore where you are after awhile, and then you diffuse, but now you diffuse in the full double well.",
                    "label": 0
                },
                {
                    "sent": "And you get a much bigger uncertainty and also the mean moves again to the true mean.",
                    "label": 0
                },
                {
                    "sent": "But unfortunately in our case the Gaussian because you have this bistable thing, the Gaussian is stuck in one of the minimum, so that already gives gives us a bit of a problem, and this is probably a point to be discussed.",
                    "label": 0
                },
                {
                    "sent": "So the Gaussian thing is sort of a bit limited.",
                    "label": 0
                },
                {
                    "sent": "It doesn't see the other doesn't see the other potential well.",
                    "label": 0
                },
                {
                    "sent": "When you don't have any observations, so it's getting stuck there, but in between it's smooth.",
                    "label": 0
                },
                {
                    "sent": "This I thought fairly well right, but we have to say there's a few.",
                    "label": 0
                },
                {
                    "sent": "A few little problems in getting this actually to converge.",
                    "label": 0
                },
                {
                    "sent": "It turns out that the backward forward I mean correct me if I'm saying anything wrong that the backward forward is not so.",
                    "label": 0
                },
                {
                    "sent": "Is not so stable as we hoped it would be, so some of the LaGrange functions turn out to be.",
                    "label": 0
                },
                {
                    "sent": "They would love to run away to minus Infinity and you have to prevent them from doing this and solving solving a constrained problem and seeing that the final result is not sensitive to how you clamp this.",
                    "label": 0
                },
                {
                    "sent": "So we see at the end that with good accuracy all our variational equations are fulfilled and we're happy, but it's not not yet a nice method.",
                    "label": 0
                },
                {
                    "sent": "But I think I'm approaching the end of my talk slightly, do I?",
                    "label": 0
                },
                {
                    "sent": "Yes, Sir.",
                    "label": 0
                },
                {
                    "sent": "You just tell me how many minutes I got.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so just wanted to mention I and then we played a little bit with an attempt of getting rid of the Lagrangian parameters.",
                    "label": 0
                },
                {
                    "sent": "Five OK?",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And five I can do a lot so.",
                    "label": 0
                },
                {
                    "sent": "So I thought maybe it's like I have always this problems in understanding LaGrange parameters.",
                    "label": 0
                },
                {
                    "sent": "Maybe this is my personal problem, so I tried to get rid of them and and replace them by by something by the observables.",
                    "label": 0
                },
                {
                    "sent": "Essentially by the means and the marginal means, and the variance is of the Gaussian process.",
                    "label": 0
                },
                {
                    "sent": "So you can play a little bit with this Lagrangian function that we had that we wanted to minimize.",
                    "label": 0
                },
                {
                    "sent": "And Ascentia Lee wanted to use these two equations in order to.",
                    "label": 0
                },
                {
                    "sent": "Just get rid of the variational parameters A&B and replace them instead by M and it's time derivatives and S and it's time derivative so that you might end up with a nice LaGrange function that depends on on means and variances in their time derivatives.",
                    "label": 0
                },
                {
                    "sent": "And this you can do essentially in the case where you force field is a gradient of a potential energy, funny enough, and so if you play with this.",
                    "label": 0
                },
                {
                    "sent": "At least you get a nice expressions in dimension 1.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So it turns out dimension one.",
                    "label": 0
                },
                {
                    "sent": "You can get this action which you have to make stationary, which is essentially.",
                    "label": 0
                },
                {
                    "sent": "This has the sorry there should be an S. There's the standard deviation, so it's an action that depends on the marginal mean.",
                    "label": 0
                },
                {
                    "sent": "The marginal standard deviation, and it's time derivative and an effective potential.",
                    "label": 0
                },
                {
                    "sent": "That depends only on mean and variance, so it's a funny object, so which looks very much like in mechanics.",
                    "label": 0
                },
                {
                    "sent": "The only thing I did was staring at it and hoping that it reveals some of his secrets.",
                    "label": 0
                },
                {
                    "sent": "So at least it would be nice to have a function I don't have anymore LaGrange parameters, but I can do sort of ordinary LaGrange mechanics with it.",
                    "label": 0
                },
                {
                    "sent": "So I get Hamilton's equations, for instance, for this type of thing.",
                    "label": 0
                },
                {
                    "sent": "There's of course data.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the data turns essentially tell you you have to solve these things in anytime you have an observation, then your momentous at the momenta corresponding to the means and the corresponding the momenta corresponding to the variances.",
                    "label": 0
                },
                {
                    "sent": "They jump.",
                    "label": 0
                },
                {
                    "sent": "Anytime you see an observation and you have to solve that, we didn't yet.",
                    "label": 0
                },
                {
                    "sent": "So the only thing is if you stare a little bit.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "At this, for the Ornstein Uhlenbeck process it seems to make sense and here is this effective potential for the on standalone back process which actually separates in the mean.",
                    "label": 1
                },
                {
                    "sent": "Well that should be a mean of course the mean and the variance is so let's see you having a simple example.",
                    "label": 0
                },
                {
                    "sent": "This is the potential for the means.",
                    "label": 0
                },
                {
                    "sent": "Well it doesn't look like a nice one but it's the right one.",
                    "label": 0
                },
                {
                    "sent": "Let's say I start from here and I have an observation here.",
                    "label": 0
                },
                {
                    "sent": "Then it means the particle just travels from here to there.",
                    "label": 0
                },
                {
                    "sent": "And is accelerat, so it goes from zero and has an observation at at at time five at X = 3, so it just runs away and that would be the way the mean goes with time.",
                    "label": 0
                },
                {
                    "sent": "What does the variance do?",
                    "label": 0
                },
                {
                    "sent": "A variance?",
                    "label": 0
                },
                {
                    "sent": "So if I start from zero, so the variance the potential for the variance it starts from.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Zero, it bounces to its maximal variance and comes back, so you're at zero.",
                    "label": 0
                },
                {
                    "sent": "You get a maximal uncertainty, but since you make a measurement, a perfect measurement at the end, you get a variance 0 again.",
                    "label": 0
                },
                {
                    "sent": "So you can stare at these potentials and say OK, seems to make sense.",
                    "label": 0
                },
                {
                    "sent": "Now what happens if you go to your nice double well potential?",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, yeah, so I don't know maybe.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At some point in a discussion, you have two dimensional things and you get 3 dimensional plots and I'm very bad at those things and so to summarize, this last part of it.",
                    "label": 0
                },
                {
                    "sent": "Well, the first part is summarize the first part first.",
                    "label": 0
                },
                {
                    "sent": "We have a LaGrange formulation with LaGrange multipliers.",
                    "label": 0
                },
                {
                    "sent": "We have backward forward algorithm but not a guarantee for convergence and probably there are some communities that they know about these things and maybe it can be cured.",
                    "label": 0
                },
                {
                    "sent": "There's an alternative that seems to make sense for the case where we have a force field with a potential energy so you can write down something that looks very much like Hamilton mechanics, which I found simply neat and I don't know if it leads to anything practical, but when I find something theoretically need I do it.",
                    "label": 0
                },
                {
                    "sent": "Anyhow, so I'm.",
                    "label": 0
                },
                {
                    "sent": "Got 10 years so I can do that right?",
                    "label": 0
                },
                {
                    "sent": "So so this is it and just to end with a final with a list of things that we would love to do and actually it was at the end here but I got some more ideas.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well, the first thing I already mentioned right?",
                    "label": 0
                },
                {
                    "sent": "Get something to make this converge.",
                    "label": 0
                },
                {
                    "sent": "Then of course in practice for practical purposes there might be we have to make some optimal unset.",
                    "label": 0
                },
                {
                    "sent": "See restrict our Gaussian processes to something that is that is easier to parameterized.",
                    "label": 0
                },
                {
                    "sent": "Maybe something where some parameters are constant between two observations and things like that.",
                    "label": 0
                },
                {
                    "sent": "Well, we haven't talked about multiplicative noise, I guess in many practical applications we have not a constant diffusion, but also a state dependent diffusion.",
                    "label": 0
                },
                {
                    "sent": "Multiplicative noise, can we do that?",
                    "label": 0
                },
                {
                    "sent": "Don't know.",
                    "label": 0
                },
                {
                    "sent": "Well of course other processes.",
                    "label": 0
                },
                {
                    "sent": "At the moment we driving of course with Wiener processes, but there might be interesting problems.",
                    "label": 0
                },
                {
                    "sent": "Neil is going to talk about this this afternoon where you have priors over functions that are smooth.",
                    "label": 0
                },
                {
                    "sent": "Well could we do such a thing for other smooth processes?",
                    "label": 0
                },
                {
                    "sent": "And it's funny enough?",
                    "label": 0
                },
                {
                    "sent": "This is a sort of a religious problem now.",
                    "label": 0
                },
                {
                    "sent": "I mean you could do PAC Bayesian bounds like Matthias Egger did for Bayesian things.",
                    "label": 1
                },
                {
                    "sent": "Some people might say.",
                    "label": 0
                },
                {
                    "sent": "We don't want to do that, so OK other site.",
                    "label": 0
                },
                {
                    "sent": "Well, some of our some of the people in the in the committee and in the consortium are sort of non bayesians.",
                    "label": 0
                },
                {
                    "sent": "They're happy with that.",
                    "label": 0
                },
                {
                    "sent": "Something probably that's not going to work because everybody tells me it's not going to work, but I want to be convinced.",
                    "label": 0
                },
                {
                    "sent": "Important sampling we have now a prior something to sample from and people say the variational Gauss, the factorizing one.",
                    "label": 0
                },
                {
                    "sent": "That's not a good idea to do important sampling.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure if it's the same argument.",
                    "label": 0
                },
                {
                    "sent": "Apply immediately to this.",
                    "label": 0
                },
                {
                    "sent": "The final nice thing with Gaussians is, well, at least in physics.",
                    "label": 0
                },
                {
                    "sent": "We know we can sort of improve that step by step.",
                    "label": 0
                },
                {
                    "sent": "Not really improved, but we may get a divergent perturbation series which we can re somewhere.",
                    "label": 0
                },
                {
                    "sent": "Do other tricks with at least it has a principled way of improving step by step on that result using perturbation theory and this is well established.",
                    "label": 0
                },
                {
                    "sent": "We know we can write down corrections using Feynman, Feynman, Feynman, Feynman, graphs and things like that, so this is probably also something to look at, and I think this is enough.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                },
                {
                    "sent": "So I think it's very, very nice work.",
                    "label": 0
                },
                {
                    "sent": "Thank you, Beth.",
                    "label": 0
                },
                {
                    "sent": "This goes back to your slide way.",
                    "label": 0
                },
                {
                    "sent": "It is cumulation of minus signs.",
                    "label": 0
                },
                {
                    "sent": "Accumulation of minus signs.",
                    "label": 0
                },
                {
                    "sent": "In this last part, the potentially the - before yes here this one.",
                    "label": 0
                },
                {
                    "sent": "One more day.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Yes, just.",
                    "label": 0
                },
                {
                    "sent": "Is that if you have a normal Hamiltonian system, yes, some potential energy minus.",
                    "label": 0
                },
                {
                    "sent": "The kinetic energy.",
                    "label": 0
                },
                {
                    "sent": "Yes, that's kinetic minus potential and I write it in such a way, yes.",
                    "label": 0
                },
                {
                    "sent": "There.",
                    "label": 0
                },
                {
                    "sent": "Added beings so whereas in a normal system you say I have a fixed energy, you can divide it over extreme ocean or storing potential energy and it is a you know it has some tool constant actually controls different because there is potential is something you want to avoid is it is the area of high costs.",
                    "label": 0
                },
                {
                    "sent": "And so it means that in the places of high costs you gotta speed up very fast.",
                    "label": 0
                },
                {
                    "sent": "You want to get through those so HD you have there in a control issue.",
                    "label": 0
                },
                {
                    "sent": "You have the difference of potential energy.",
                    "label": 0
                },
                {
                    "sent": "And kinetic energy is constant.",
                    "label": 0
                },
                {
                    "sent": "And it seems that this is also happening here.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I can't, I well, I don't really know the connection to to control yet.",
                    "label": 0
                },
                {
                    "sent": "That's something we have to.",
                    "label": 0
                },
                {
                    "sent": "We have to explore.",
                    "label": 0
                },
                {
                    "sent": "The normal timing system, yet that the sum of his energies, yes.",
                    "label": 0
                },
                {
                    "sent": "The difference is that the trajectory is chosen such that no, but you still have an energy conservation in this case, so between between two observations, the system conserves energy in such when the energy is now defined by kinetic plus V. So this is order.",
                    "label": 0
                },
                {
                    "sent": "This Is Us.",
                    "label": 0
                },
                {
                    "sent": "This is really ordinary classical mechanics.",
                    "label": 0
                },
                {
                    "sent": "Yes, right?",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah, but I wanted to write it in such a way that resembles a LaGrange function.",
                    "label": 0
                },
                {
                    "sent": "Yeah, well, maybe this is just a.",
                    "label": 0
                },
                {
                    "sent": "So we didn't, yeah.",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                },
                {
                    "sent": "Effective may be reminiscent of the minus in education control.",
                    "label": 0
                },
                {
                    "sent": "OK, good.",
                    "label": 0
                },
                {
                    "sent": "Yes, I don't know who was first.",
                    "label": 0
                },
                {
                    "sent": "OK for the non gas in case I didn't quite understand your slide on that, but would it be related to taking the a capital A's that you find as optimal Ann and asking that that those be approximating the derivative?",
                    "label": 0
                },
                {
                    "sent": "So on the near F those points in states so so you mean a should approximate the gradient of F somehow?",
                    "label": 0
                },
                {
                    "sent": "Yeah it does, but they are not equal so they actually they are the differences is proportional to one of the LaGrange.",
                    "label": 0
                },
                {
                    "sent": "From meters and so now if F isn't if if F is not linear and not known, yes, could you use that personality to try to constrain?",
                    "label": 0
                },
                {
                    "sent": "OK, the problem is I have to say we at the moment we assume we know F Annina next step we would say we we we, we we we play with parametric X and then use the free energy in order to select the best parameters.",
                    "label": 0
                },
                {
                    "sent": "So this we haven't yet done.",
                    "label": 0
                },
                {
                    "sent": "I mean this goes on top.",
                    "label": 0
                },
                {
                    "sent": "We have an expression for the free energy and we can use it.",
                    "label": 0
                },
                {
                    "sent": "We hope to use it using a result.",
                    "label": 0
                },
                {
                    "sent": "Not sure.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure if that's true.",
                    "label": 0
                },
                {
                    "sent": "No, no no.",
                    "label": 0
                },
                {
                    "sent": "I have to see.",
                    "label": 0
                },
                {
                    "sent": "Yes, yes Sir, sorry.",
                    "label": 0
                },
                {
                    "sent": "You have perfect measurements, yes, no no, but that was just for illustration.",
                    "label": 0
                },
                {
                    "sent": "In general, I assume that there is some measurement noise.",
                    "label": 0
                },
                {
                    "sent": "Like this?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Space.",
                    "label": 0
                },
                {
                    "sent": "So in the in the Lagrangian formulation, this is the observation noise that the variance of the observation noise and it shows you you your LaGrange parameter jump by such an amount.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "I guess you guys are being way too hypercritical of your solution on bistable case, but so if a Gaussian works, why not a couple of 'em?",
                    "label": 0
                },
                {
                    "sent": "So why not have basically parametrization of basic a combination of Gaussians?",
                    "label": 0
                },
                {
                    "sent": "Yeah, the problem.",
                    "label": 0
                },
                {
                    "sent": "The problem is in the variational world.",
                    "label": 0
                },
                {
                    "sent": "This doesn't seem to be a simple thing.",
                    "label": 0
                },
                {
                    "sent": "I mean, people have tried mixtures of Gaussians rather than Gaussians in.",
                    "label": 0
                },
                {
                    "sent": "Yeah, many years ago and it turned out it's not so simple and it would mean we would have to do a mixture of Gaussian processes.",
                    "label": 0
                },
                {
                    "sent": "Probably then they could be nasty.",
                    "label": 0
                },
                {
                    "sent": "It means it's coupled with forwarding.",
                    "label": 0
                },
                {
                    "sent": "The backwards becomes couple, that's yeah.",
                    "label": 0
                },
                {
                    "sent": "Miracle solution difficult.",
                    "label": 0
                },
                {
                    "sent": "It would have to do that.",
                    "label": 0
                },
                {
                    "sent": "I mean, it seems like because if we're not only interested in smoothing, but in making forecasts, then we'd rather be able to to avoid these problems where we don't have any data.",
                    "label": 0
                },
                {
                    "sent": "Schedule questions.",
                    "label": 0
                }
            ]
        }
    }
}