{
    "id": "33vqgamlymxh5knyaab6dpoxr76iaulo",
    "title": "RDSZ: An approach for lossless RDF stream compression",
    "info": {
        "author": [
            "Norberto Fern\u00e1ndez Garc\u00eda, Carlos III University of Madrid"
        ],
        "published": "July 30, 2014",
        "recorded": "May 2014",
        "category": [
            "Top->Computer Science->Semantic Web",
            "Top->Computer Science->Big Data"
        ]
    },
    "url": "http://videolectures.net/eswc2014_garcia_stream_compression/",
    "segmentation": [
        [
            "My name is Robert Fernandez and I work at the Telematics Engineering Department of the University.",
            "And I'm going to send a paper that's in title earlier set an approach for a lot less earlier stream compression, which is a result of a collaboration between the people from the Telematics Engineering Department at UC3M and people from the Ontology Engineering Group at Universitat Politecnica de Madrid."
        ],
        [
            "I will structure my presentation to the following sections.",
            "I will show some slides, so try to motivate the need on rational for an earlier stream compression algorithm then I will show the RDS RDS set algorithm itself.",
            "I will start with some introductory slides showing the main ideas or inspiring principles of the algorithm and then I will show briefly his working details using our running example.",
            "Later on I will show some slides related to the evaluation.",
            "I will start showing the experimental setup and data sets used for evaluation and then I will show the results regarding compression performance on response time of the algorithm.",
            "Finally, some concluding remarks, some potential future lines of this work will close this presentation."
        ],
        [
            "So in recent years we have seen a popularisation of streaming data on the web with several different applications, like for instance social networking.",
            "We are all aware of public posts, streams of microblogging services like Twitter or Identica or also the so called Internet of Things where you usually have streams of data taken from sensors like where are sensors or temperature sensors or the like."
        ],
        [
            "So the popularisation of streaming data on the web has fostered the interest of the semantic web community in this kind of data, and you can find several different initiatives related with this interests, like for instance the RDF Stream processing Group that has recently been started at W3C Stream vision proposals, query languages for F strings like Sparkle string, or see Sparkle.",
            "This color live stream processing approaches like sequels clothes.",
            "Or the only work of previous work of the authors in scalable area for stream publishing in the context of streaming.",
            "I'm going to briefly introduce three me because it is relevant to motivate the need of earliest stream compression techniques."
        ],
        [
            "The frame is basically a middleware for scholarly F string publishing.",
            "Basically, the main idea behind a stream is to to try to publish earlier streams on top of HTTP, taking advantages of a synchronous input.",
            "Output capabilities of modern web servers.",
            "To to gain scale.",
            "Ability to achieve high scalability, we have the sign and implemented a prototype of the streaming and using Python that is currently able to serve string an earlier stream to up to 40,000 clients using a single server with less of just a few seconds.",
            "I will not get into the particular details of streaming because this is not the goal of this talk, but if you are interested you can find more information in the publication of the Journal web semantics or simply visit.",
            "The streaming demo of this conference next Thursday."
        ],
        [
            "What is important is relevant about streams at the swimming already uses early as a swing compression.",
            "When we designed and implemented streaming, there were several proposals for early F block compression approaches like HTTP.",
            "However, we were unable to find any earlier for specific extreme compression technique available in state of the art, so we simply decided to use a general purpose string compressor lights lift, which basically implements the protocol, but we found when implementing and evaluating the streaming was that the compression had big impact on the.",
            "System performance, including a drastic reduction in net core load and also reduction on CPU usage which contributes to increase the three miss capability."
        ],
        [
            "Given that compression seems to improve the performance of a tree, me an interesting question that we might ask is, can we improve the slip compression rates to try to achieve even better performance?",
            "Or initially prothesis us, but this was possible, right?",
            "Why?",
            "Because silly provides good compression rate for text, but it's in an area of a strainer usually generated by an software components following a schema or limited number of different schemas, so they have strong structural similarities and at the moment sleep takes limited advantage of this.",
            "Similarities or intuition is that if we could exploit these structural similarities, we could achieve better results than sleep."
        ],
        [
            "And those are the main idea.",
            "The main spine in principle behind early upset trying to use differential encoder to split structural similarities that is trying to represent an RDF item on the basis of previous items that have been already processed in the same string using an error.",
            "You less recently used cash at the encoder to save information about issues that have been previously processed.",
            "The result of the differential encoding processes just text that is later uncompressed with siblings that, as we have already said, provides good compression performance for text data."
        ],
        [
            "Once they have introduced the main idea or inspiring principle behind earlier set, I'm going to briefly describe the algorithm.",
            "You can see the block diagram in this slide on the left hand side you can see the compression site on the right hand side.",
            "You can see the compression side with different blocks.",
            "They both are connected through communication line, that in this case can be, for instance the network socket or something like that.",
            "You can also see at the compression side that with the with the inputs of the algorithm with the earliest ring with a set of items that constitute the string, we carry out two processes to parallel processes we compress.",
            "We compress the inputs using just leave slip using just deflate and in parallel we just compress data and using differential encoding plus slipped.",
            "We later on, compared ourselves of both techniques and simply send to the communication line the smaller option the smaller result.",
            "I will describe the functionality of the main or the most important blocks of earlier set in next slides I will be light with details I don't want you to mark me as the boring guide in the mobile application.",
            "In this quick mobile application so, but if you want to see the technical details.",
            "Check down on the paper right?"
        ],
        [
            "So you have the top corner.",
            "You can see that the blocks that I'm going to describe.",
            "So let us assume that the input or compression processes string constituted by a set of earlier items.",
            "The item one.",
            "Two, they don't want it to type that into the bottom.",
            "We can also assure we are also assuming that the item one is the first item in the stream.",
            "I mean, we have no previous state.",
            "The encoder has no previous hasn't seen any item before and after item one we are sending also item 2.",
            "As you can see in both the items are quite similar because they are generated following the same schema, so they both have the same properties.",
            "But obviously the values of the subject and the objects of the different properties are different, right?"
        ],
        [
            "So let's check the process of the differential encoder, right?",
            "What about the differential in current processing item one?",
            "So basically this is a three stage process.",
            "The first stage is just to compose the item the item 1 into a tribal pattern and a set of variable bindings.",
            "This is a triple pattern that is.",
            "Basically you can see that at the top it's basically an N triples representation of the earliest item where we have replaced the subjects and objects by variables.",
            "The variable being stable that is shown just below.",
            "It simply Maps the name of each variable to his particular value, right?",
            "Once we have the compose the RDF item at the input into a tribal pattern and a set of variable bindings.",
            "Next processing the stage is just to check if the pattern it's already included in the cache of the encoder.",
            "In this case, the answer is no, because we are assuming that this is the first item in the stream, so we have no previous state information.",
            "So in this case we cannot rely on differential encoding because we haven't seen any item before.",
            "So in this case when we don't have the pattern in the cash, when we cannot use differential encoding, we simply send.",
            "The turtle representation of the eating as is right.",
            "In any case, we have to save the triple pattern the variable buildings in the cash at the encoder for future reference for future reuse."
        ],
        [
            "What about item 2?",
            "How it's processed at differential encoder?",
            "Again, it's a three stage process.",
            "We start with process one, we just simply the compose the RDF item into tribal pattern at the left and a table of variable bindings at the right.",
            "You can see that in this case the triple pattern exactly the same as in previous slide.",
            "However, the variable buildings are mostly different because the subjects and predicates and objects as we have already set are different from one item to the other one.",
            "So again, when we check today when we arrived to the second processing stage, we check if the pattern is already included in the encoder cash.",
            "In this case the answer is yes, because the triple patterning is hardly the same as that of it and one, so it is already included in the cash at then coder.",
            "So in this case we can rely on differential encoding.",
            "We don't need to sign in again the pattern, we just need to send the difference between this item and item number one.",
            "So and this is exactly what we're going to do, we simply encode.",
            "The values of the variable building stable that are not included in the previous item right.",
            "The results are shown in.",
            "The slide is just some lines of text, right?",
            "You any case again we need to update the cash.",
            "We always need to update to store the triple pattern and valuable buildings in the cash to have an idea of the items that are being processed by the system, right?",
            "OK, this is regarding the differential encoder, So what?"
        ],
        [
            "Now the next block this call looks it's called most because it's a multiplexer.",
            "The idea of the multiplexer is just to concatenate the different items using a special delimiter right to be able to later on two separate these different items at reception site, right?",
            "So what's the input to multiplexer?",
            "It's the output of the differential encoding process, so for it, and while we have not used differential encoding, so we have just the turtles realization of the item, whereas for item two we have used differential encoding.",
            "So we just encode the differences.",
            "With respect to item one, right?",
            "So these are the two inputs.",
            "Today multiplexer multiplexes.",
            "Just concatenate these two strings using a delimiter.",
            "The limiter in the middle to be able later on to separate these two pieces of information, right?"
        ],
        [
            "OK, so the output of multiplexer it's later uncompressed with slip with DEFLATE.",
            "Note that the result of the multiplexer just text and sleep is quite good at compressing compressing text.",
            "Write the binary output is simply the manner of the compressor of sleep is simply sent to the network to the socket alright.",
            "What are the compressor?",
            "I'm not going to get into details because it's mainly the opposite process as this one.",
            "I mean you simply to compress the subtly binary data into a string later on at the multiplexer you just split using delimiter the different items.",
            "That constitute the string, and later on you just decode the different items.",
            "When you receive an item that is not in code that is represented in Turtle, you have nothing to do with the decoder.",
            "But when you have used differential encoding, you need to decode the item to obtain the charger representation of that item right.",
            "Note that in order to be able to properly decode the information that they also have a cash at the receiver site at the other color, it should be keeping In Sync with the cash.",
            "I've been color right."
        ],
        [
            "OK, once I have briefly describe the algorithm, I'm going to show the evaluation results first on details regarding the data sets and experimental setup, we have use 70 genes that assets to avoid shore approach.",
            "These are the sets and at one and two and just contain an weather information obtained from the Spanish material Logical Office.",
            "Both use earlier, but they use different schema that these are different data sets with different.",
            "Came up right.",
            "Identical, just built in from data for from the social networking site.",
            "Identica is just information about posts in this social networks.",
            "Wikipedia is just a stream composed of information from Wikipedia edits the author, the pipes, this banality, the timestamp of the Wikipedia edits.",
            "Petrol is synthetic data sets of credit card transactions in petrol stations.",
            "Lot Lincoln observation that is just another data set from weather information.",
            "A mix is just a random mixture of the items from the different data sets from the former data sets, right?"
        ],
        [
            "What about this setup?",
            "We have implemented the prototype in Python using earlier Flip library.",
            "This product was run on Ubuntu Machine with Intel Core 2 processor and eight gigabytes of RAM and we have two different configuration parameters that we can tune when it's the cashier size.",
            "We have already talked about the cash at the encoder.",
            "Under decoder.",
            "We can just tune this cache size.",
            "We can configure this cache size and the second parameter.",
            "It's called the batch size.",
            "The batch size is simply the number of items that are combined at the Muks block.",
            "And I assume that most of you are familiar with working details of string compressors.",
            "Basically, industry compressors just open data to a buffer and at some point in time you just call a method that usually called flush, and then you just get the data in the buffer, compressed the data and send it to the communication network.",
            "Right earlier set works follows that same approach you just up, and different items at the buffer in the compressor and at certain point in time just call flush and the different items are compressed and are sent to the communication network.",
            "Well, the batch size is the number of early of items there are happened to the buffer before calling flush, right?",
            "That's the idea.",
            "Note that this parameter it's very related with the deley perceive the receptor because for instance, if I set the batch size 25, that means that I have to wait till I have file 5 earlier items at the compressor before I can compress the data and send it to receptor.",
            "And obviously if I'm going team, that means deley at the receptor site that introduce delay at the receptor site.",
            "What about the performance metrics?",
            "These are more or less what you can expect the compression gain and the average processing time per item in the stream, right?"
        ],
        [
            "So let's go to the results.",
            "First, regarding compression performance, running compression performance we have in current out two sprints in this apartment, one we just used a fixed configuration.",
            "We have fixed catch size to 100 and batch size to five.",
            "We have compared the results of earlier set with two base lengths.",
            "One is a trivial baseline that is represent information using STARTTLS related in Turtle without any compression, and the second baseline is used.",
            "The turtle serialization compress only with sibling with deflate right?",
            "Whether the results were when you compare early upset with the turtle data without compression, you get gains around a 90% and when you compare and set the.",
            "Early offset with the results of the turtle serialization plus setliff plus deflate, we get gains in the range from zero to 31%.",
            "You can see the particular details for each particular data set in the table in the slide.",
            "This they're also including the paper right?",
            "In the last column you can see the game.",
            "You can see them for instance for the Wikipedia case.",
            "Again it's zero.",
            "Why it's zero?",
            "Because in this particular data set an all items in the in the stream have different triple patterns.",
            "There are no repeated triple patterns as they are not repeated triple patterns.",
            "We never are able to use differential encoding, so we simply send turtle representation in code with setliff compressed with setliff.",
            "So obviously we have no game we are doing exactly the same.",
            "This is done by Setliff, right?"
        ],
        [
            "What are the Spiderman 2IN Department?",
            "Do we simply use one data center?",
            "Is a mad one, but in this case we make the cache size and batch size variable.",
            "We can see part of the results in this slide in the bottom of the slide on the left hand side you can see the results when the average but size was set to two on the right hand side you can see the results with average size is set to 5.",
            "On the X axis you can see the catch size and on the Y axis you can see the average compressed size of them at one data set right?",
            "And you can see that in red you can see the baseline that in this case is just the turtle serialization compressed with sleep with the flight and you can see in blue the results from nearly offset.",
            "What you can see is that, for instance, for the baseline, obviously we're not using differential encoding, so they catch plays no role, so you get a flat line as expected, right for every asset.",
            "However, you see that if you increase the cache size you get better results till a limit why before because the number of different type of patterns in a string is limited.",
            "Once you have enough catch to catch them all, you don't get any additional games, right?",
            "Another interesting point that you can see is that if you increase the average box size from two to five, you see that the results are better both for the baseline and for every asset.",
            "What's the reason?",
            "Because both the base London earlier set relay on sublease relied on DEFLATE.",
            "Deflate every time you call slush on the flight.",
            "It includes some information regarding to Huffman code to Huffman coding that can be considered.",
            "That's overhead, so when you use small but size, you are calling deflate more frequent frequently, so you are adding more overhead from.",
            "See blip, right?",
            "And that explains why you get slightly better results on the right on the left.",
            "Now that you have a trade off here, because if you make the batch size larger, you have to wait more you have.",
            "Tiger Deley, but do getting a bit in compression site right so you have a trade or trade off here."
        ],
        [
            "Finally, evaluation regarding response time by should measure the total compression plus the compression average processing time per item in the in the streams, in the different data sets, and we find that this value was between H, millisecond and 200 milliseconds per item, right?",
            "Note that this is a result that is worse than if you use only save leave between two and three times worse.",
            "Right, so we are gaining in compression, right?",
            "But we're making it worse in compression time, right?",
            "We also tried to fit a linear regression model.",
            "Between using us as independent variable, the total average compression size and as the independent variable, the average number of triples per item, and we found that in fact there was a linear relation between these two variables.",
            "However, we have to note that in our seven data sets and data center we use in our evaluation data are rather small.",
            "I mean the average size interposes between 7:00 and a little less than 200, right?",
            "So it would be interesting to try with Tiger with.",
            "With bigger items, right?"
        ],
        [
            "Finally, the conclusion.",
            "Future lines, we can see that here they have set has better compression operations, better compression ratios than the simplest, which means that taking advantage of a structural similarity seems beneficial.",
            "However, at the cost of increasing the response time, now that we more or less expected the response time result because we have used a Python prototype that is not optimized for response time, right?",
            "What about future lines?",
            "Two potential future lines are first integrating area set into the stream system.",
            "To see if in fact it provides better scalability for streaming and another potential future line is just too and try to develop alternative compression schemes there need not to be the compressed to be used in for instance in querystring engines or instream reasoners, because area set at the moment is binary format.",
            "So you need to compress the air.",
            "We have set compression before you can use the stream in a query stream engine or in our stream richner.",
            "So developing alternative configuration or approaches that don't need this.",
            "Process would be interesting."
        ],
        [
            "So that's all from my side.",
            "Thank you very much for your attention.",
            "If you have any questions, I will be glad to try to answer it."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "My name is Robert Fernandez and I work at the Telematics Engineering Department of the University.",
                    "label": 0
                },
                {
                    "sent": "And I'm going to send a paper that's in title earlier set an approach for a lot less earlier stream compression, which is a result of a collaboration between the people from the Telematics Engineering Department at UC3M and people from the Ontology Engineering Group at Universitat Politecnica de Madrid.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I will structure my presentation to the following sections.",
                    "label": 0
                },
                {
                    "sent": "I will show some slides, so try to motivate the need on rational for an earlier stream compression algorithm then I will show the RDS RDS set algorithm itself.",
                    "label": 0
                },
                {
                    "sent": "I will start with some introductory slides showing the main ideas or inspiring principles of the algorithm and then I will show briefly his working details using our running example.",
                    "label": 1
                },
                {
                    "sent": "Later on I will show some slides related to the evaluation.",
                    "label": 1
                },
                {
                    "sent": "I will start showing the experimental setup and data sets used for evaluation and then I will show the results regarding compression performance on response time of the algorithm.",
                    "label": 0
                },
                {
                    "sent": "Finally, some concluding remarks, some potential future lines of this work will close this presentation.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in recent years we have seen a popularisation of streaming data on the web with several different applications, like for instance social networking.",
                    "label": 0
                },
                {
                    "sent": "We are all aware of public posts, streams of microblogging services like Twitter or Identica or also the so called Internet of Things where you usually have streams of data taken from sensors like where are sensors or temperature sensors or the like.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the popularisation of streaming data on the web has fostered the interest of the semantic web community in this kind of data, and you can find several different initiatives related with this interests, like for instance the RDF Stream processing Group that has recently been started at W3C Stream vision proposals, query languages for F strings like Sparkle string, or see Sparkle.",
                    "label": 1
                },
                {
                    "sent": "This color live stream processing approaches like sequels clothes.",
                    "label": 0
                },
                {
                    "sent": "Or the only work of previous work of the authors in scalable area for stream publishing in the context of streaming.",
                    "label": 0
                },
                {
                    "sent": "I'm going to briefly introduce three me because it is relevant to motivate the need of earliest stream compression techniques.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The frame is basically a middleware for scholarly F string publishing.",
                    "label": 1
                },
                {
                    "sent": "Basically, the main idea behind a stream is to to try to publish earlier streams on top of HTTP, taking advantages of a synchronous input.",
                    "label": 1
                },
                {
                    "sent": "Output capabilities of modern web servers.",
                    "label": 0
                },
                {
                    "sent": "To to gain scale.",
                    "label": 0
                },
                {
                    "sent": "Ability to achieve high scalability, we have the sign and implemented a prototype of the streaming and using Python that is currently able to serve string an earlier stream to up to 40,000 clients using a single server with less of just a few seconds.",
                    "label": 1
                },
                {
                    "sent": "I will not get into the particular details of streaming because this is not the goal of this talk, but if you are interested you can find more information in the publication of the Journal web semantics or simply visit.",
                    "label": 0
                },
                {
                    "sent": "The streaming demo of this conference next Thursday.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What is important is relevant about streams at the swimming already uses early as a swing compression.",
                    "label": 0
                },
                {
                    "sent": "When we designed and implemented streaming, there were several proposals for early F block compression approaches like HTTP.",
                    "label": 0
                },
                {
                    "sent": "However, we were unable to find any earlier for specific extreme compression technique available in state of the art, so we simply decided to use a general purpose string compressor lights lift, which basically implements the protocol, but we found when implementing and evaluating the streaming was that the compression had big impact on the.",
                    "label": 0
                },
                {
                    "sent": "System performance, including a drastic reduction in net core load and also reduction on CPU usage which contributes to increase the three miss capability.",
                    "label": 1
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Given that compression seems to improve the performance of a tree, me an interesting question that we might ask is, can we improve the slip compression rates to try to achieve even better performance?",
                    "label": 0
                },
                {
                    "sent": "Or initially prothesis us, but this was possible, right?",
                    "label": 0
                },
                {
                    "sent": "Why?",
                    "label": 0
                },
                {
                    "sent": "Because silly provides good compression rate for text, but it's in an area of a strainer usually generated by an software components following a schema or limited number of different schemas, so they have strong structural similarities and at the moment sleep takes limited advantage of this.",
                    "label": 1
                },
                {
                    "sent": "Similarities or intuition is that if we could exploit these structural similarities, we could achieve better results than sleep.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And those are the main idea.",
                    "label": 0
                },
                {
                    "sent": "The main spine in principle behind early upset trying to use differential encoder to split structural similarities that is trying to represent an RDF item on the basis of previous items that have been already processed in the same string using an error.",
                    "label": 1
                },
                {
                    "sent": "You less recently used cash at the encoder to save information about issues that have been previously processed.",
                    "label": 0
                },
                {
                    "sent": "The result of the differential encoding processes just text that is later uncompressed with siblings that, as we have already said, provides good compression performance for text data.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Once they have introduced the main idea or inspiring principle behind earlier set, I'm going to briefly describe the algorithm.",
                    "label": 0
                },
                {
                    "sent": "You can see the block diagram in this slide on the left hand side you can see the compression site on the right hand side.",
                    "label": 0
                },
                {
                    "sent": "You can see the compression side with different blocks.",
                    "label": 0
                },
                {
                    "sent": "They both are connected through communication line, that in this case can be, for instance the network socket or something like that.",
                    "label": 0
                },
                {
                    "sent": "You can also see at the compression side that with the with the inputs of the algorithm with the earliest ring with a set of items that constitute the string, we carry out two processes to parallel processes we compress.",
                    "label": 0
                },
                {
                    "sent": "We compress the inputs using just leave slip using just deflate and in parallel we just compress data and using differential encoding plus slipped.",
                    "label": 0
                },
                {
                    "sent": "We later on, compared ourselves of both techniques and simply send to the communication line the smaller option the smaller result.",
                    "label": 0
                },
                {
                    "sent": "I will describe the functionality of the main or the most important blocks of earlier set in next slides I will be light with details I don't want you to mark me as the boring guide in the mobile application.",
                    "label": 1
                },
                {
                    "sent": "In this quick mobile application so, but if you want to see the technical details.",
                    "label": 0
                },
                {
                    "sent": "Check down on the paper right?",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So you have the top corner.",
                    "label": 0
                },
                {
                    "sent": "You can see that the blocks that I'm going to describe.",
                    "label": 0
                },
                {
                    "sent": "So let us assume that the input or compression processes string constituted by a set of earlier items.",
                    "label": 0
                },
                {
                    "sent": "The item one.",
                    "label": 0
                },
                {
                    "sent": "Two, they don't want it to type that into the bottom.",
                    "label": 0
                },
                {
                    "sent": "We can also assure we are also assuming that the item one is the first item in the stream.",
                    "label": 0
                },
                {
                    "sent": "I mean, we have no previous state.",
                    "label": 0
                },
                {
                    "sent": "The encoder has no previous hasn't seen any item before and after item one we are sending also item 2.",
                    "label": 1
                },
                {
                    "sent": "As you can see in both the items are quite similar because they are generated following the same schema, so they both have the same properties.",
                    "label": 0
                },
                {
                    "sent": "But obviously the values of the subject and the objects of the different properties are different, right?",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's check the process of the differential encoder, right?",
                    "label": 0
                },
                {
                    "sent": "What about the differential in current processing item one?",
                    "label": 0
                },
                {
                    "sent": "So basically this is a three stage process.",
                    "label": 0
                },
                {
                    "sent": "The first stage is just to compose the item the item 1 into a tribal pattern and a set of variable bindings.",
                    "label": 0
                },
                {
                    "sent": "This is a triple pattern that is.",
                    "label": 0
                },
                {
                    "sent": "Basically you can see that at the top it's basically an N triples representation of the earliest item where we have replaced the subjects and objects by variables.",
                    "label": 0
                },
                {
                    "sent": "The variable being stable that is shown just below.",
                    "label": 0
                },
                {
                    "sent": "It simply Maps the name of each variable to his particular value, right?",
                    "label": 0
                },
                {
                    "sent": "Once we have the compose the RDF item at the input into a tribal pattern and a set of variable bindings.",
                    "label": 1
                },
                {
                    "sent": "Next processing the stage is just to check if the pattern it's already included in the cache of the encoder.",
                    "label": 1
                },
                {
                    "sent": "In this case, the answer is no, because we are assuming that this is the first item in the stream, so we have no previous state information.",
                    "label": 0
                },
                {
                    "sent": "So in this case we cannot rely on differential encoding because we haven't seen any item before.",
                    "label": 0
                },
                {
                    "sent": "So in this case when we don't have the pattern in the cash, when we cannot use differential encoding, we simply send.",
                    "label": 0
                },
                {
                    "sent": "The turtle representation of the eating as is right.",
                    "label": 0
                },
                {
                    "sent": "In any case, we have to save the triple pattern the variable buildings in the cash at the encoder for future reference for future reuse.",
                    "label": 1
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What about item 2?",
                    "label": 0
                },
                {
                    "sent": "How it's processed at differential encoder?",
                    "label": 0
                },
                {
                    "sent": "Again, it's a three stage process.",
                    "label": 0
                },
                {
                    "sent": "We start with process one, we just simply the compose the RDF item into tribal pattern at the left and a table of variable bindings at the right.",
                    "label": 1
                },
                {
                    "sent": "You can see that in this case the triple pattern exactly the same as in previous slide.",
                    "label": 0
                },
                {
                    "sent": "However, the variable buildings are mostly different because the subjects and predicates and objects as we have already set are different from one item to the other one.",
                    "label": 0
                },
                {
                    "sent": "So again, when we check today when we arrived to the second processing stage, we check if the pattern is already included in the encoder cash.",
                    "label": 0
                },
                {
                    "sent": "In this case the answer is yes, because the triple patterning is hardly the same as that of it and one, so it is already included in the cash at then coder.",
                    "label": 0
                },
                {
                    "sent": "So in this case we can rely on differential encoding.",
                    "label": 0
                },
                {
                    "sent": "We don't need to sign in again the pattern, we just need to send the difference between this item and item number one.",
                    "label": 0
                },
                {
                    "sent": "So and this is exactly what we're going to do, we simply encode.",
                    "label": 0
                },
                {
                    "sent": "The values of the variable building stable that are not included in the previous item right.",
                    "label": 0
                },
                {
                    "sent": "The results are shown in.",
                    "label": 0
                },
                {
                    "sent": "The slide is just some lines of text, right?",
                    "label": 0
                },
                {
                    "sent": "You any case again we need to update the cash.",
                    "label": 0
                },
                {
                    "sent": "We always need to update to store the triple pattern and valuable buildings in the cash to have an idea of the items that are being processed by the system, right?",
                    "label": 0
                },
                {
                    "sent": "OK, this is regarding the differential encoder, So what?",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now the next block this call looks it's called most because it's a multiplexer.",
                    "label": 0
                },
                {
                    "sent": "The idea of the multiplexer is just to concatenate the different items using a special delimiter right to be able to later on two separate these different items at reception site, right?",
                    "label": 0
                },
                {
                    "sent": "So what's the input to multiplexer?",
                    "label": 0
                },
                {
                    "sent": "It's the output of the differential encoding process, so for it, and while we have not used differential encoding, so we have just the turtles realization of the item, whereas for item two we have used differential encoding.",
                    "label": 0
                },
                {
                    "sent": "So we just encode the differences.",
                    "label": 1
                },
                {
                    "sent": "With respect to item one, right?",
                    "label": 0
                },
                {
                    "sent": "So these are the two inputs.",
                    "label": 0
                },
                {
                    "sent": "Today multiplexer multiplexes.",
                    "label": 0
                },
                {
                    "sent": "Just concatenate these two strings using a delimiter.",
                    "label": 1
                },
                {
                    "sent": "The limiter in the middle to be able later on to separate these two pieces of information, right?",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so the output of multiplexer it's later uncompressed with slip with DEFLATE.",
                    "label": 1
                },
                {
                    "sent": "Note that the result of the multiplexer just text and sleep is quite good at compressing compressing text.",
                    "label": 1
                },
                {
                    "sent": "Write the binary output is simply the manner of the compressor of sleep is simply sent to the network to the socket alright.",
                    "label": 0
                },
                {
                    "sent": "What are the compressor?",
                    "label": 1
                },
                {
                    "sent": "I'm not going to get into details because it's mainly the opposite process as this one.",
                    "label": 0
                },
                {
                    "sent": "I mean you simply to compress the subtly binary data into a string later on at the multiplexer you just split using delimiter the different items.",
                    "label": 1
                },
                {
                    "sent": "That constitute the string, and later on you just decode the different items.",
                    "label": 0
                },
                {
                    "sent": "When you receive an item that is not in code that is represented in Turtle, you have nothing to do with the decoder.",
                    "label": 0
                },
                {
                    "sent": "But when you have used differential encoding, you need to decode the item to obtain the charger representation of that item right.",
                    "label": 0
                },
                {
                    "sent": "Note that in order to be able to properly decode the information that they also have a cash at the receiver site at the other color, it should be keeping In Sync with the cash.",
                    "label": 0
                },
                {
                    "sent": "I've been color right.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, once I have briefly describe the algorithm, I'm going to show the evaluation results first on details regarding the data sets and experimental setup, we have use 70 genes that assets to avoid shore approach.",
                    "label": 0
                },
                {
                    "sent": "These are the sets and at one and two and just contain an weather information obtained from the Spanish material Logical Office.",
                    "label": 0
                },
                {
                    "sent": "Both use earlier, but they use different schema that these are different data sets with different.",
                    "label": 0
                },
                {
                    "sent": "Came up right.",
                    "label": 0
                },
                {
                    "sent": "Identical, just built in from data for from the social networking site.",
                    "label": 0
                },
                {
                    "sent": "Identica is just information about posts in this social networks.",
                    "label": 0
                },
                {
                    "sent": "Wikipedia is just a stream composed of information from Wikipedia edits the author, the pipes, this banality, the timestamp of the Wikipedia edits.",
                    "label": 0
                },
                {
                    "sent": "Petrol is synthetic data sets of credit card transactions in petrol stations.",
                    "label": 1
                },
                {
                    "sent": "Lot Lincoln observation that is just another data set from weather information.",
                    "label": 0
                },
                {
                    "sent": "A mix is just a random mixture of the items from the different data sets from the former data sets, right?",
                    "label": 1
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What about this setup?",
                    "label": 0
                },
                {
                    "sent": "We have implemented the prototype in Python using earlier Flip library.",
                    "label": 0
                },
                {
                    "sent": "This product was run on Ubuntu Machine with Intel Core 2 processor and eight gigabytes of RAM and we have two different configuration parameters that we can tune when it's the cashier size.",
                    "label": 0
                },
                {
                    "sent": "We have already talked about the cash at the encoder.",
                    "label": 0
                },
                {
                    "sent": "Under decoder.",
                    "label": 0
                },
                {
                    "sent": "We can just tune this cache size.",
                    "label": 0
                },
                {
                    "sent": "We can configure this cache size and the second parameter.",
                    "label": 0
                },
                {
                    "sent": "It's called the batch size.",
                    "label": 0
                },
                {
                    "sent": "The batch size is simply the number of items that are combined at the Muks block.",
                    "label": 1
                },
                {
                    "sent": "And I assume that most of you are familiar with working details of string compressors.",
                    "label": 0
                },
                {
                    "sent": "Basically, industry compressors just open data to a buffer and at some point in time you just call a method that usually called flush, and then you just get the data in the buffer, compressed the data and send it to the communication network.",
                    "label": 0
                },
                {
                    "sent": "Right earlier set works follows that same approach you just up, and different items at the buffer in the compressor and at certain point in time just call flush and the different items are compressed and are sent to the communication network.",
                    "label": 0
                },
                {
                    "sent": "Well, the batch size is the number of early of items there are happened to the buffer before calling flush, right?",
                    "label": 0
                },
                {
                    "sent": "That's the idea.",
                    "label": 0
                },
                {
                    "sent": "Note that this parameter it's very related with the deley perceive the receptor because for instance, if I set the batch size 25, that means that I have to wait till I have file 5 earlier items at the compressor before I can compress the data and send it to receptor.",
                    "label": 0
                },
                {
                    "sent": "And obviously if I'm going team, that means deley at the receptor site that introduce delay at the receptor site.",
                    "label": 1
                },
                {
                    "sent": "What about the performance metrics?",
                    "label": 0
                },
                {
                    "sent": "These are more or less what you can expect the compression gain and the average processing time per item in the stream, right?",
                    "label": 1
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's go to the results.",
                    "label": 0
                },
                {
                    "sent": "First, regarding compression performance, running compression performance we have in current out two sprints in this apartment, one we just used a fixed configuration.",
                    "label": 0
                },
                {
                    "sent": "We have fixed catch size to 100 and batch size to five.",
                    "label": 0
                },
                {
                    "sent": "We have compared the results of earlier set with two base lengths.",
                    "label": 0
                },
                {
                    "sent": "One is a trivial baseline that is represent information using STARTTLS related in Turtle without any compression, and the second baseline is used.",
                    "label": 0
                },
                {
                    "sent": "The turtle serialization compress only with sibling with deflate right?",
                    "label": 0
                },
                {
                    "sent": "Whether the results were when you compare early upset with the turtle data without compression, you get gains around a 90% and when you compare and set the.",
                    "label": 0
                },
                {
                    "sent": "Early offset with the results of the turtle serialization plus setliff plus deflate, we get gains in the range from zero to 31%.",
                    "label": 0
                },
                {
                    "sent": "You can see the particular details for each particular data set in the table in the slide.",
                    "label": 0
                },
                {
                    "sent": "This they're also including the paper right?",
                    "label": 0
                },
                {
                    "sent": "In the last column you can see the game.",
                    "label": 0
                },
                {
                    "sent": "You can see them for instance for the Wikipedia case.",
                    "label": 0
                },
                {
                    "sent": "Again it's zero.",
                    "label": 0
                },
                {
                    "sent": "Why it's zero?",
                    "label": 0
                },
                {
                    "sent": "Because in this particular data set an all items in the in the stream have different triple patterns.",
                    "label": 0
                },
                {
                    "sent": "There are no repeated triple patterns as they are not repeated triple patterns.",
                    "label": 0
                },
                {
                    "sent": "We never are able to use differential encoding, so we simply send turtle representation in code with setliff compressed with setliff.",
                    "label": 0
                },
                {
                    "sent": "So obviously we have no game we are doing exactly the same.",
                    "label": 0
                },
                {
                    "sent": "This is done by Setliff, right?",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What are the Spiderman 2IN Department?",
                    "label": 0
                },
                {
                    "sent": "Do we simply use one data center?",
                    "label": 0
                },
                {
                    "sent": "Is a mad one, but in this case we make the cache size and batch size variable.",
                    "label": 0
                },
                {
                    "sent": "We can see part of the results in this slide in the bottom of the slide on the left hand side you can see the results when the average but size was set to two on the right hand side you can see the results with average size is set to 5.",
                    "label": 0
                },
                {
                    "sent": "On the X axis you can see the catch size and on the Y axis you can see the average compressed size of them at one data set right?",
                    "label": 0
                },
                {
                    "sent": "And you can see that in red you can see the baseline that in this case is just the turtle serialization compressed with sleep with the flight and you can see in blue the results from nearly offset.",
                    "label": 0
                },
                {
                    "sent": "What you can see is that, for instance, for the baseline, obviously we're not using differential encoding, so they catch plays no role, so you get a flat line as expected, right for every asset.",
                    "label": 0
                },
                {
                    "sent": "However, you see that if you increase the cache size you get better results till a limit why before because the number of different type of patterns in a string is limited.",
                    "label": 0
                },
                {
                    "sent": "Once you have enough catch to catch them all, you don't get any additional games, right?",
                    "label": 0
                },
                {
                    "sent": "Another interesting point that you can see is that if you increase the average box size from two to five, you see that the results are better both for the baseline and for every asset.",
                    "label": 0
                },
                {
                    "sent": "What's the reason?",
                    "label": 0
                },
                {
                    "sent": "Because both the base London earlier set relay on sublease relied on DEFLATE.",
                    "label": 0
                },
                {
                    "sent": "Deflate every time you call slush on the flight.",
                    "label": 0
                },
                {
                    "sent": "It includes some information regarding to Huffman code to Huffman coding that can be considered.",
                    "label": 0
                },
                {
                    "sent": "That's overhead, so when you use small but size, you are calling deflate more frequent frequently, so you are adding more overhead from.",
                    "label": 0
                },
                {
                    "sent": "See blip, right?",
                    "label": 0
                },
                {
                    "sent": "And that explains why you get slightly better results on the right on the left.",
                    "label": 0
                },
                {
                    "sent": "Now that you have a trade off here, because if you make the batch size larger, you have to wait more you have.",
                    "label": 0
                },
                {
                    "sent": "Tiger Deley, but do getting a bit in compression site right so you have a trade or trade off here.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Finally, evaluation regarding response time by should measure the total compression plus the compression average processing time per item in the in the streams, in the different data sets, and we find that this value was between H, millisecond and 200 milliseconds per item, right?",
                    "label": 1
                },
                {
                    "sent": "Note that this is a result that is worse than if you use only save leave between two and three times worse.",
                    "label": 0
                },
                {
                    "sent": "Right, so we are gaining in compression, right?",
                    "label": 0
                },
                {
                    "sent": "But we're making it worse in compression time, right?",
                    "label": 0
                },
                {
                    "sent": "We also tried to fit a linear regression model.",
                    "label": 0
                },
                {
                    "sent": "Between using us as independent variable, the total average compression size and as the independent variable, the average number of triples per item, and we found that in fact there was a linear relation between these two variables.",
                    "label": 0
                },
                {
                    "sent": "However, we have to note that in our seven data sets and data center we use in our evaluation data are rather small.",
                    "label": 0
                },
                {
                    "sent": "I mean the average size interposes between 7:00 and a little less than 200, right?",
                    "label": 0
                },
                {
                    "sent": "So it would be interesting to try with Tiger with.",
                    "label": 0
                },
                {
                    "sent": "With bigger items, right?",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Finally, the conclusion.",
                    "label": 0
                },
                {
                    "sent": "Future lines, we can see that here they have set has better compression operations, better compression ratios than the simplest, which means that taking advantage of a structural similarity seems beneficial.",
                    "label": 1
                },
                {
                    "sent": "However, at the cost of increasing the response time, now that we more or less expected the response time result because we have used a Python prototype that is not optimized for response time, right?",
                    "label": 0
                },
                {
                    "sent": "What about future lines?",
                    "label": 0
                },
                {
                    "sent": "Two potential future lines are first integrating area set into the stream system.",
                    "label": 0
                },
                {
                    "sent": "To see if in fact it provides better scalability for streaming and another potential future line is just too and try to develop alternative compression schemes there need not to be the compressed to be used in for instance in querystring engines or instream reasoners, because area set at the moment is binary format.",
                    "label": 0
                },
                {
                    "sent": "So you need to compress the air.",
                    "label": 0
                },
                {
                    "sent": "We have set compression before you can use the stream in a query stream engine or in our stream richner.",
                    "label": 0
                },
                {
                    "sent": "So developing alternative configuration or approaches that don't need this.",
                    "label": 0
                },
                {
                    "sent": "Process would be interesting.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that's all from my side.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much for your attention.",
                    "label": 1
                },
                {
                    "sent": "If you have any questions, I will be glad to try to answer it.",
                    "label": 0
                }
            ]
        }
    }
}