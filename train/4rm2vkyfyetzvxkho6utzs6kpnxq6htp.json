{
    "id": "4rm2vkyfyetzvxkho6utzs6kpnxq6htp",
    "title": "Markov Chain Monte Carlo",
    "info": {
        "author": [
            "Iain Murray, School of Informatics, University of Edinburgh"
        ],
        "published": "Nov. 2, 2009",
        "recorded": "August 2009",
        "category": [
            "Top->Computer Science->Machine Learning->Monte Carlo Methods",
            "Top->Mathematics->Statistics"
        ]
    },
    "url": "http://videolectures.net/mlss09uk_murray_mcmc/",
    "segmentation": [
        [
            "I mean Mari, and as you know, I'm going to be talking about Markov chain Monte Carlo.",
            "So just before I start, could I have a show of hands who has actually used MCMC in their work already?",
            "OK, and I know from talking to somebody this morning, some of you haven't said to those that have.",
            "I apologize that it might be a bit slow.",
            "Hopefully you'll get something out of it, but I'm going to give an overview of just why we would do Monte Carlo with any sort at all.",
            "And for those of you already know, empty might not see anything new until maybe the second breakthrough."
        ],
        [
            "So you've seen a lot about big probability distributions and graphs, and in the morning, so I'm going to start with something very trivial.",
            "This is, I think, probably the first statistical problem given in high school, which is how do you find the mean of a bunch of objects.",
            "So if I was interested in knowing the average height of a bunch of people, I would go and measure their Heights and I would add them up and I would divide and.",
            "Or if I was interested in some other quantities.",
            "Just the same algorithm, their IQ, or for some reason John Wayne is asked us all whether we left or right handed for the practical.",
            "Say there are people who actually go out and do this sort of thing.",
            "Now the danger of going to a lot of technical lectures about graphical models and probability distributions is that you end up adopting a funny language.",
            "So let's say instead of knowing the height of lecturers here, I was interested in knowing the average height of people in Cambridge.",
            "Then that's a sum of the height of each person someday.",
            "But all people in Cambridge divided by the number of people in Cambridge.",
            "And when you go to these lectures, you now adopt the language where you say this is an intractable inference problem, because it's a very large computation.",
            "Whereas we know that you know this isn't a difficult problem.",
            "All you actually need to do is just go and grab a bunch of people.",
            "Look at how high they are, average their Heights, and you'll have a pretty good idea of what the average height of people in Cambridge is.",
            "For a lot of the problems that we've lost about how difficult they are, it's just as easy to solve problem."
        ],
        [
            "We are interested in so if you've got any integral that's an expectation, see it's an integral over a probability distribution of some function.",
            "You can play exactly the same trick instead of actually on your computer visiting every little element of your space and measuring the height of your function and adding them all up, you can just take a bunch of samples from the distribution that you're averaging over.",
            "Take the empirical average over the samples that you gathered, and get a pretty good idea of what the integral is, and that's the idea of simplement.",
            "Monte Carlo that that is all Monte Carlo with, so it's an application.",
            "Say you had a Bayesian inference problem and you had some data and you wanted to make a prediction about some new quantity, then this predicted distribution is just an average.",
            "You look at the posterior distribution over the parameters in whatever your probabilistic model is, and you say, well, if only I knew those parameters, I would know how to make predictions if I someone told me what the ground truth will parameter in the model is, I would make predictions.",
            "So I do that.",
            "For every setting of the parameters and wait by how probable later.",
            "And again you just.",
            "You can do it by just sampling the parameters from the distribution and taking empirical average.",
            "So Monte Carlo has an obvious application whenever you're doing Bayesian inference.",
            "If integrals like this are difficult, it also has applications in all sorts of places where probability distributions come up.",
            "So if you ever fit parameters using an algorithm called them, then you often need to compute statistics that can be written as averages and Jeff Hinton next week might talk a lot about Boltzmann machines and Boltzmann.",
            "Machine learning algorithm involves this sort of sampling average."
        ],
        [
            "OK, so we can pass a bit more formal than saying we just grab a bunch of samples and look at the average we can.",
            "We can say properties about it so we can look at the expectation of this estimator and it's trivial to show that this is unbiased.",
            "So on average this estimator will get the right answer and you can also say well how big, how much will the estimate to deviate from the true answer so you can compute the variance of the estimator.",
            "And what's nice is that it shrinks with the number of samples.",
            "Say if you want a better answer, you just gather more samples.",
            "You don't have to go in implementing new algorithm, you just wait longer.",
            "And because this is a variance in, we normally interested in error bars, the error bars shrink with the square root of the number of samples.",
            "So you just have to wait longer, you end up having to wait longer and longer if you want your balls to be 10 times shorter, you're going to have to wait 100 times longer, so there's a tradeoff."
        ],
        [
            "OK, so.",
            "I saw this example along time ago.",
            "I'm sure a lot of people have done, but a concrete example of how sampling works.",
            "Say we want to approximate Pi, which is four times the area of this red area.",
            "If this is a unit square.",
            "Right, this is an integral which is the integral of the indicator function saying.",
            "Are you inside this area, averaged over a uniform distribution within this square?",
            "So this is like the most stupid way of computing Pi you can possibly imagine.",
            "So Pi is equal to four times this integral, and you can now approximate this integral by sampling from distribution, which is throw down points in the square and then just see whether you get a one or a zero.",
            "Are you in this red circle or not?",
            "So without knowing anything really about geometry you can get with 12 samples, that pie is about 3.",
            "And that's sort of the feel of Monte Carlo.",
            "You can just get a few samples and you get a general idea of what's going on it 'cause you're ballpark figure, which can be good to sort of sanity check if you're doing something else, like EP or a different approximate inference algorithm.",
            "Figure completely different ballpark number.",
            "You know you've done something wrong.",
            "You can also be patient and wait longer so I could draw 10,000,000 samples and I would get that Pi is 3.14 something, but it's not very accurate, and this is never going to be a way to get really precise numbers.",
            "So if you're interested in that, you probably don't want to be doing."
        ],
        [
            "Cali I mean.",
            "Specifically, if you wanted to compute Pi by numerical integration, you could just use numerical quadrature and with only 100 valuations or maybe 1000 you can get \u03c0 to sort of as accurate as you can represent.",
            "So you really don't want to be doing multi color for this sort of sort of integral, and this was summarized by Alan Cycle.",
            "He's a funny guy and he was quite was the opening to his lecture course on Monte Carlo methods.",
            "An he is actually done an awful lot of good work in multicolor methods as well, and I don't completely agree with this quite well.",
            "I sort of agree with it, but I think you could replace multicolor with anything, because if X is a method, it should only be used when all the other methods are worse.",
            "I think you can agree with that for any X.",
            "So I. I think that's a question that you want to sort of be asking yourself.",
            "In my practical, I'm going to try and get you to sort of look at the problem with doing multi color actually makes some sense.",
            "There's other practical that will be looking at other methods and you know they'll be looking problems with their appropriate.",
            "So the question is really it's Monte Carlo.",
            "The right approach feed for you, and maybe the way to find that out is that you have to implement it and compare.",
            "You do the sanity check of whether the numbers in the right ballpark and then you go for the first method or you go for this 'cause it's the only thing that works."
        ],
        [
            "OK, there's actually another motivation for drawing samples.",
            "We concentrate a lot on sort of numerical computation, that's 'cause it's a concrete thing to do, but I just think samples are pretty, so this is a figure from David Mackay's textbook, and this isn't a machine learning application, but there are people who are interested in tiling shapes, and there's a whole sort of field of geometrical combinatorics, and so this is a problem when you pack lozenges inside a hexagon and you randomly sort of create.",
            "You can think of this as a hub that holds bricks that are sort of in a pilot filling it.",
            "If you can see that optical illusion an this is a random sort of way of stacking bricks into a HUD.",
            "And when he's just glance at this, you can see that the sort of this circle forms, and there's a whole literature on describing the properties of this circle, but you might not notice it was there unless you just looked at samples.",
            "You could have found that the circle exists and described the properties of it just by doing mathematics, but you know that it's something that you should go and look for by just glancing at the sample.",
            "And for us, I think if you can visualize what your probabilistic model is doing, and you can draw samples, then it might give you hints of sort of things that you should go away and you should do so.",
            "Here's a really simple example.",
            "By now a bit of a toy problem in machine learning, but.",
            "Here are some very low resolution binary images of digits and these are samples drawn from probabilistic models that have been fitted to the digits so that these here are 16 samples drawn from a model which that mixture of multivariate Beninese.",
            "So this is a probabilistic model that basically says.",
            "The way I'm going to generate an image is I'm going to pick some template, exactly exemplar image, and I'm going to add a bit of noise to it, and then that's going to be the images, but also the way that you explain any image you see is.",
            "You say this is a bit like one of my templates, and it's a bit different, so I'll explain that by noise.",
            "And when you draw samples, you see there really noisy, and so that immediately tells you that this sort of model under fits.",
            "So you can't explain all of the variations in digits by just 100 templates, which is what was fitted here.",
            "You need to have sort of a more flexible model that can capture all of the invariants is that you get in images."
        ],
        [
            "There's actually a long history of this sort of justice, eyeballing things and seeing how things turn out so Monte Carlo methods really took off in the 50s when the first computers, but before that, Fermi, who was the physicist was?",
            "Or it's astounding his colleagues, because he would come in, and he would say, oh, I think that this neutron experiment will come out like this, and he was often right, and he his answers are in the right ballpark, and it's 'cause he was up at night with a hand adding machine, running Monte Carlo simulations on his desk without a computer.",
            "Now we've got the computing power that we can just do these things trivially, so we really should."
        ],
        [
            "So for us, if we've written down our model as a directed graph rather than the sort of series of dynamical equations for new neutrons, we should know how to sample from our model.",
            "And if we've gone the route of writing down a directed graphical model or a Bayes net is some people call them, then the algorithm is really simple and I'm sorry I Miss Stevens lectures, so I don't know if you went through this so the way that you would sample from this base net which was in slides as a running example.",
            "Is that you first just sample all of the parents right at the top and we know what their distribution is.",
            "Because when this graph is giving us a joint distribution which tells us what these distributions are, and then we sample all the children once we know what their parents are just from the conditional distributions that we've written out.",
            "So this graph just gives us the natural generative structure.",
            "I mean, that's one of the reasons are great for modeling.",
            "So once we've gone through that effort, we may evaluate that and see what it does and see if it's captured.",
            "The things we wanted it to.",
            "I."
        ],
        [
            "So how do we actually implement that?",
            "How do we do this ancestral passenger?",
            "All these variables and the short answer is that you know we just use Matlab or we use whatever computing environment provides, because it's going to have implemented in it already.",
            "Alot of these standard distributions that we use, so drawing from the prior is going to be simple and if your library didn't provide these functions and there's a good book which you can just download that explains how a lot of these algorithms work under the hood.",
            "So this is sort of old established stuff, but we're going to have to understand how a couple of these library routines actually work 'cause.",
            "That's going to sort of tell us how we're going to improve on them, and that's unless you really know what's going on.",
            "You can't move forward from that."
        ],
        [
            "So here's a really standard way of drawing samples from a distribution.",
            "You have some probability density and you just sample uniformly points underneath the area from this curve.",
            "So you just there's an area here and you just choose something randomly from inside there, and then if you read off the location in the input space you're interested in, that's your sample.",
            "So the reason this works is just that.",
            "If the curve here is twice as high than here, then there's twice as much area underneath it, and so your choice is likely to sample it so it respects the distribution.",
            "And the way you implement that is you notice that.",
            "So this point here has about half of the probability mass to its left, and this point here has, say, about a sixth of the probability mass to its left.",
            "So this amount of masses to the left hand side of the points is actually a uniform random variable.",
            "So you implemented by drawing this uniform random variable and then working out how far through the curve you should be."
        ],
        [
            "So mathematically, what you do is you workout the cumulative distribution of the curve.",
            "You draw uniform random variable and then you shove that through the inverse cumulative.",
            "So I set in MATLAB brand.",
            "It gives me .7.",
            "I read across to this cumulative curve I read down and that's my sample.",
            "And that's great, as long as we can actually compute the blue curve and invert it, which we can do for Gaussians and exponentials and simple 1D.",
            "Distributions, but we can't always do it.",
            "So if you look inside the source code for something like a gamma random number generator, depending on which library or you're looking at, it might do a series of horrendously complicated things depending on which parameter regime, urine and one of the."
        ],
        [
            "That might do for some of the parameter regimes is rejection sampling.",
            "Say.",
            "We want to sample points underneath this blue curve that for distribution.",
            "And we don't know how to do that because we don't know how to compute this cumulative and invert it.",
            "But we do know how to sample from a bunch of other distributions, like Gaussians, uniform distributions, piecewise uniform distributions.",
            "So we get some other distribution that we do know how to sample from, like a Gaussian and we scale up the function such that it's always above the blue curve.",
            "Then we sample.",
            "From the green distribution, the key distribution and we pick a random height uniformly so that we're sampling points underneath this green curve somewhere.",
            "Now what we're doing is we're summing points uniformly under the green curve.",
            "If we toss out all the ones underneath the blue curve, then we'll just be left with samples drawn uniformly from the blue curve.",
            "So the algorithm is draw sample.",
            "Oh, it's above the blue curve, reject it.",
            "Draw a sample is underneath the blue curve.",
            "We keep it, and we have a sample.",
            "Say.",
            "This is this is pretty general.",
            "The only technical requirement is that you need to be able to bound this function because you need to construct this thing that will be above it everywhere.",
            "Anne.",
            "The only problem with it really is that it seems a bit wasteful because you do all this computation and then if you have a rejection you just sort of throw it away and you get nothing from it.",
            "And potentially can spend most of your computer time just sort of computing these functions and then doing nothing with that computation and throwing them out.",
            "Say."
        ],
        [
            "There's a trick that means that you never have to reject samples if you, if you're in a regime where you can't draw samples in the distribution you want to, but you can draw from some other distribution.",
            "Important sampling is a trick that allows you to just sample from the distribution you actually want to instead.",
            "Say you have an integral to solve.",
            "This is what we want to estimate.",
            "And we multiply by Q, which is the distribution we can sample from and we divide by key.",
            "So this is just multiplying by one as long as we never divide by zero and so this is an identity.",
            "And now this is just an integral which is an expectation under key and the function is this whole object here.",
            "So now we just supply simple Monte Carlo with sample from key and we evaluate the rest of the integrand.",
            "And what's nice about this trick is that actually your integral didn't need to be an expectation in the 1st place.",
            "You'll notice here that nothing about this relied on P here being a distribution.",
            "You think of FP together being the integral integrand, and that just sticks together.",
            "You could do that with any integrand.",
            "It wouldn't have to be an expectation.",
            "Yeah.",
            "Sample from.",
            "Yeah, so that's it.",
            "That's a great question.",
            "How do you choose Q?",
            "So I've said you can choose any Q like one that you can draw a sample from.",
            "As long as we don't divide by zero.",
            "So that technical requirement, but.",
            "It's probably clear that some queues are going to work much better than others, so there's sort of a question of why and how we might pick and so.",
            "I mean, if we had an input space and this was our true distribution, and you know we're interested in the average of some function which runs runs through the space as well, then clearly if we picked a distribution that had most of its mass over here, then the samples over here aren't going to tell us much about the expectation of this function under this distribution.",
            "So we're going to want a distribution that has its mass in much the same place.",
            "And.",
            "Something else we want to really avoid is making Q small one peers big.",
            "So for example, imagine what a variational.",
            "If you know about variational approximations, what they would do is find a mode and seek into that.",
            "So if I did a Gaussian approximation to this under some cost functions, I would fit a Gaussian around the Titans made.",
            "Now that means I'm very rarely going to get samples over here.",
            "So now if I do very occasionally, I'll get a sample here.",
            "And now I evaluate the importance of this sample and the important is P / Q. OK, so now in the tail of the Gaussian Q is really small and P is quite big and the importance of this sample ends up being absolutely enormous and so that means that in this empirical thumb over my samples, maybe one of the terms will be hugely bigger than any of the others, and effectively I've only drawn 1 sample.",
            "So what you want to do is construct a distribution that roughly covers the distribution and make sure that it's never really small where there's appreciable amounts of mass.",
            "It's fine to have your key distribution have a bit of tail where there's no mass, because you'll just occasionally get a sample out there and give it no wait, and you've wasted a bit, but nothing blows up.",
            "So the question is, in rejection sampling.",
            "We sample from the subtree distribution and sometimes we say oh, we sample here too often because our Q is big here compared to PC will throw them out and here we just softly rejecting because we down weight them a bit.",
            "But it looks much the same and.",
            "It's just slightly more efficient in the soft, so if we're not interested in the samples themselves were interested in this expectation, then it's lower variance to attach a real number to every single sample you've got them to make a hard decision.",
            "If I'm going to wait the sample by zero or one.",
            "So if you compute the variance of the estimators, this turns out to be more efficient.",
            "Look for me that the easiest way in.",
            "The best way to choose just uniform distribution, which is where they constantly talk.",
            "Yeah, say.",
            "So if we can bound the function, say, this is the biggest thing and we know the extent of it.",
            "We could just have a top hat like that if.",
            "If P was something like a Gaussian that has infinite tails, then a uniform distribution would have to go out forever, and then it would be improper and we can touch the sample from it.",
            "But you're right, if the distribution has compact support, then you know maybe uniform distribution would work fine.",
            "It depends on the problem.",
            "Sometimes you'll have clever tricks where you know really tight bounds of the function in some places, and there are also adaptive rejection sampling algorithms that sort of conform really good approximation for you on the fly."
        ],
        [
            "Right?",
            "So on the previous slide, I assumed that we could evaluate both P&Q.",
            "That's not actually always true, so if we have.",
            "Under over here.",
            "If we have a parameter posterior.",
            "Pets are parameters given data.",
            "Then we can normally evaluate the likelihood probability of the data given their parameters.",
            "We can normally evaluate the prior owner parameters.",
            "It's often something very simple.",
            "This might be evaluating joint probability under a graph or something, but it's usually fairly tractable.",
            "What we don't know is this thing on the bottom.",
            "The normalizing constant for the marginal likelihood of the model.",
            "But the evidence for the model probability data has many names.",
            "This thing here is a difficult integral to compute, so normally.",
            "What we like our algorithms that work with the distribution that's proportional to something we can evaluate and would like to drop constants.",
            "So there's a version of rejection sampling that works when you don't know the normalizing constant of the distribution and.",
            "It basically works by pulling out a ratio of normalizing constants from P&Q and separately estimating that.",
            "But it turns out that you can estimate this ratio from the same samples that you've drawn, and what's neat is that.",
            "Approximating this ratio turns out to be equivalent to working out all your important weights and then re normalizing them so they add up to one.",
            "So you run this algorithm except instead of waiting by Pierre Vicky, you wait by these things normalized so that if you sum over all your samples, these things add up to one.",
            "And it's a few lines to show that this is a valid thing to do, but I'm sure you'll be able to wait that out.",
            "And if you can't, I can show you afterwards."
        ],
        [
            "OK, say.",
            "What I've talked about so far is just plain simple Monte Carlo.",
            "Haven't mentioned anything to do Markov chains yet, and so this is just the summary of what I've said so far and it's great.",
            "I've had lots of questions, so I think hopefully you'll have a good idea of what's going going on with what we've covered.",
            "One thing I would say is why would we ever do rejection sampling?",
            "So there's a question of why do important sampling?",
            "Because it looks much the same, so I gave a reason why important something is better.",
            "Why did I bother to tell you about rejection sampling?",
            "Any ideas?",
            "So imagine that I'm one of these people doing a physical simulation, wanting to look at the output of a system and it dynamics of it involves a sequence of draws from random number generators, so I know that when this particle diffuses, its next step will come from this distribution.",
            "Then for my simulation to make any sense, I really want to be drawing from specific distributions and it will be much harder to interpret.",
            "If I have a load of weights attached to everything and they're not coming from the right distribution, so there are times when you actually want real samples, and that's what rejection sampling is for."
        ],
        [
            "OK, so why aren't we done?",
            "Like I just said, Monte Carlo is the Super general thing.",
            "You can workout any integral you want and I've given you example algorithms that can sample from any distribution.",
            "The reason it's not the end of the lecture is because the simple algorithm that I showed you don't really scale up to the sort of problems that we're interested in with solving inference problems.",
            "So I have two examples here.",
            "If you have an undirected graphical model, then you can't sample from it with one of these ancestral path.",
            "There isn't this sort of nice directed interpretation of it, so if you have a large undirected graphical model or a mark of random field, or defined by a model defined by factor graph, then you're not able to just draw a sample from that distribution even to look at it.",
            "And this is very high dimensional distribution, so.",
            "Any any algorithm that's just designed to work in later mentions isn't going to work.",
            "Similarly, even if you have a directed model and you're interested in.",
            "Actually, looking at data rather than just looking at how pretty it is if we condition on a variable and then we want to know the distribution conditioned on that, then again we have a distribution where we don't know the normalizing constant.",
            "It's a high dimensional object and this looks as though it's going to be a tricky distribution to sample from."
        ],
        [
            "Say it might not be obvious why rejection sampling and important something don't work in high dimensions.",
            "So as a toy example, imagine the distribution we were interested in was a spherical Gaussian distribution.",
            "We just didn't know it, so we could evaluate this distribution point wise, and it happens to be its vertical Gaussian.",
            "But we didn't know that.",
            "So we're going to use a different distribution Q.",
            "Which is a different circle, Gaussian in order to either do rejection sampling or important sampling.",
            "OK, so now we can say how well with these algorithms work.",
            "How long will we have to wait before we can accept a sample and rejection sampling?",
            "Or we're doing important sampler?",
            "How goodwill are estimated be?",
            "Safe rejection sampling to get the bounding.",
            "It turns out that Q has to be wider than P because if it's narrower than you end up multiplying it by Infinity to make it above it everywhere.",
            "So you have to make it wider and imagine that P is slightly different from a normal distribution somewhere so that you can't quite fit it to be the same width.",
            "Then the fraction of the proposals that you end up accepting falls off exponentially with the width of Q.",
            "So if you just have a proposal distribution which is slightly wider.",
            "Or slightly misfit in some way.",
            "In high dimensions, it means that the number of proposals you accept can just drop towards 0, like if you're in 100 dimensions and Sigma is 1.1, then you're going to be waiting a long time for your samples.",
            "It takes a few lines to show this and to be honest this might be wrong.",
            "'cause I did it last night, but the variance of important some importance weights?",
            "Is this or something like this and I'm sure it's going to scale exponentially with Sigma, so if you're doing important sampling then the variance of your estimator also blows up.",
            "If you have a distribution that's too wide and then for the reasons I explained you can't have a distribution that's too narrow either or that's going to be problems in that turns out here if Sigma.",
            "If Sigma ends up being really small, then you end up with the variance blowing up too."
        ],
        [
            "I'm and you don't even need to be in that high dimension to begin to think.",
            "Get some intuition that these algorithms aren't the right thing to do so.",
            "I've got here a very very toy data modeling application.",
            "I'm doing linear regression and I'm pretending I didn't know how to do this analytically, so I have a data set and they have the green line, which is a randomly drawn regression line.",
            "So I'm doing important sampling and I'm saying I'm going to draw a whole bunch of possible lines and then I'm going to from an arbitrary distribution that considers sort of all all lines, and then I'm going to wait them using important sampling to say which ones actually fit the data so that I can approximate things under the posterior distribution.",
            "So most of these lines are rubbish like you know they have nothing to do with the data and say their importance.",
            "Weights end up being really small.",
            "Light sensor minus 810 -- 9/10 -- 51 and only a few of them by chance actually happened to sort of go through the data and so very small number of them pick up most of the importance weights.",
            "I'm of course this would be much more extreme if you had more than two parameters.",
            "I fixed the noise here so it's only sampling from 2 parameters.",
            "And notice what happens.",
            "So the algorithms running in this order.",
            "Although you could do this in parallel 'cause there is no ordering really.",
            "But I drew this sample.",
            "I draw this sample, I'd rather sample.",
            "I finally get one that's any good, and then I completely ignore that and continue drawing from my dumb distribution and soda or a silly one.",
            "Again, I get one, that's OK, but then I make it worse again and make it even worse.",
            "And I never learn from what I'm doing.",
            "And.",
            "Surely once I sort of got alignments in the right ballpark, I should be able to do something with that?",
            "So it's a lot of urine."
        ],
        [
            "In a.",
            "The idea of Markov chain Monte Carlo is to come up with algorithms that instead of just randomly drawing IID proposals from distributions, you instead evolve samples and take smaller steps.",
            "So here is an algorithm that will go into more detail later that does something different.",
            "Instead of drawing samples independently, it proposes small changes to what you've currently got, so now there is a time ordering to this algorithm.",
            "It's running along here.",
            "So we started off.",
            "With this green regressive here and the algorithm does perturbed that and propose the different regressor and it's colored red to say, oh that look worse.",
            "I'm going to reject it.",
            "So it kept the same regressor, it didn't throw it away, and it can't propose a different progressive.",
            "And it was still there, so it kept the old one again and then eventually.",
            "A small perturbation the other way produces a good regression fit, and once it's in the right ballpark, small perturbations tend to be good, and so you get a sequence of reasonable samples that look as though they might come from the posterior distribution over regression lines that go through this data set.",
            "So this is a series of pictures in data space and then in terms of the parameter space of our model, the algorithm looks like this.",
            "You've got parameters for the describe where the line lies and the algorithm is moving around the space of parameters and the red line show that sometimes you propose to a point in the parameter space which has low posterior probability and so you don't go there, you stay where you are and you move somewhere else.",
            "Yeah.",
            "OK, so the question is, is this the same as hillclimbing and say?",
            "What I literally said sounds like that because I didn't add any stochastic element to it, so I said, you know you perturb something.",
            "If it's better you go there, and if it's worth you don't.",
            "And that would be, you know, an optimization method.",
            "It some people claiming this algorithm.",
            "Says if you tweak it and it's better than definitely go there, but if you tweak it in it's worse, then sometimes you might go there anyway and so that stops it from being an optimization algorithm.",
            "So we're not going to be doing maximum likelihood or map.",
            "We're going to find the best parameters.",
            "We're going to tend to move towards a better parameters, but will also sort of randomly move around a bit, and that's what's going to let us sample from the posterior distribution.",
            "So at the moment, this is where you do.",
            "I haven't explained how this works, I'm just saying this is the flavor of the algorithm we want, and then over the next few slides will understand where it's actually come from.",
            "Yep.",
            "Ha ha say.",
            "What's the difference between simulated annealing and this algorithm?",
            "This algorithm predates simulated annealing, so this algorithm was invented in the 50s and let salamas when they're doing developing nuclear weapons and simulated annealing, I think was the 80s and simulated annealing uses this algorithm in.",
            "It's in a loop, but then it does something else to change the distribution at each iteration, so this is a key part of simulated annealing."
        ],
        [
            "OK, so here's the key idea of Markov chain Monte Carlo.",
            "We're interested in some probability distribution, and it might lie in a high dimensional space.",
            "We can only evaluate it up to a constant, but we can evaluate it point wise up to constant wherever we like, and we want to construct some sort of random walk or diffusion process that will explore this distribution.",
            "So will initialize our walk in some arbitrary way, because often these problems are intractable, we don't know.",
            "Like good places in our parameter space.",
            "Also we initialize in some way and then we're going to follow a Markov chain.",
            "That is the way that we draw the next step only depends on the previous step and nothing else.",
            "So we have a probability distribution over where we go next given where we were before and using that simple rule, we're going to want to take steps that wander around and eventually after some burning period of sort of finding the distribution, will explore the distribution such that if we looked at where all of the points of what visited are, which of these blue dots, after a while I stop during the black line and justice.",
            "Particular dot wherever it went.",
            "Those blue dots look as though their samples from the distribution we're interested in.",
            "So what we're interested in doing is constructing Markov chains, finding transition operators or distributions T that if we were to simulate these Markov chains have this property and will draw samples for us.",
            "Yeah, these samples are correlated.",
            "Yes, there so more samples.",
            "And hit what's there.",
            "The question is, the samples are correlated and so in some ways they're not fair.",
            "Or you know, there's maybe not as good in some senses independently drawn samples.",
            "That rejection sampling gave us and, and that's all certainly true.",
            "It turns out that if you put these correlated samples into the simple Monte Carlo estimator, then ignoring this issue with burn and maybe we'll get onto this later, it's still an unbiased estimator, so you don't need independent samples to construct it estimates of expectations, but certainly you shouldn't treat them as if they are independent.",
            "So if you're doing something that requires independent samples, then this isn't good enough.",
            "And there are methods of using Markov chains to then produce independent samples, which roughly tell you how long you have to walk forward before you can draw another sample.",
            "But I don't know if I'll get onto them.",
            "Would not decrease as fast as it there, right?",
            "So I said that you can use them in the estimator and that's all.",
            "I'm biased, but it's been pointed out the variance is not going to be as good so.",
            "Here's a process for me giving you.",
            "Correlated or dependent samples.",
            "I draw a sample using rejection sampling.",
            "I then copy it and give it to you again.",
            "I then draw another sample from rejection sampling and then copy it and give it to you again.",
            "So I give you a series of samples where every other sample is the same as the previous one.",
            "Now, marginally, all of those samples that come from the correct distribution, and you can tell if I throw those into the Monte Carlo estimator, then the mean is going to be exactly the same right?",
            "And get the same answer.",
            "But if I assume that I had twice as many samples as I really had to construct error bars, then I'll be really overconfident, so we can't construct error bars in the way that you would for simple multi color.",
            "We're going to have to estimate how many effective samples we have."
        ],
        [
            "OK, so.",
            "I've got a really simple example, just to show you what.",
            "The Markov chain dynamics actually mean just say that we know the meaning T so.",
            "Ah, stationary distribution is going to be a discrete distribution that has three possible states 1, two and three, and they have probability 3, fifth one, 5th and 1/5.",
            "This is the distribution I want to sample from.",
            "Here is a transition matrix.",
            "Which will allow me to sample from this distribution, so the meaning of this is that if I'm in State 2, which is this state with probability half I'll go to the more probable state.",
            "I'm not going to stay where I am, so if I don't do that, I'm going to go to the other state and state one which is the most probable state.",
            "Sometimes just stays where it is, and sometimes it wanders off to the other states.",
            "So.",
            "The reason that I can use this transition operator for this stationary distribution is that.",
            "In Jagan P. Star is an invariant distribution of T, which means that if I multiply this vector by this matrix, I get the same vector back again.",
            "So the distribution I'm interested in is an eigenvector of this matrix with eigenvalue one.",
            "And.",
            "Say.",
            "If I were to start in some arbitrary state and workout the probability of where I would be after 100 steps, then I can do that by multiplying by.",
            "The Matrix 100 times and to machine precision you get out the distribution over where you end up.",
            "Is this so?",
            "If you apply a transition operator or matrix many, many times to a vector, then the distribution over what you end up with is it.",
            "Let's plug in vector.",
            "Now we're not actually going to want to construct these big matrices, because we're going to have a very large state space and the problems were interested in.",
            "And if it's intractable to deal with something order N, which is the size of our state space and we're not going to want to construct an order and squared transition matrix, so we tend to have just some compact way of writing down what are transition rule is, so we tend to write instead of matrix equations like.",
            "This will tend to say that what we want is that if we draw a sample from our distribution.",
            "Averaged over that.",
            "If we then took one step without transition operator, the distribution over where we'd end up is the same.",
            "So you can imagine if somehow this algorithm manages to be sampling from the correct distribution.",
            "Then if we take another step, the distribution over where it will be after that step is also the correct distribution.",
            "So this is a basic consistency condition that this random walk is going to have to satisfy.",
            "This condition by itself isn't actually enough, so.",
            "Imagine that your transition matrix is the identity matrix or the operator is wherever you are, stay there.",
            "And don't move then.",
            "That's a bit like the draw sample and copy operator that I told you before.",
            "If you only ever applied the copy operator then you would never move anywhere in your space and you never did any samples, but it would satisfy this condition.",
            "'cause if you draw a sample and you stay put, then you where you end up is the right distribution.",
            "So we need another condition on top of this which basically just says it is possible to move around the whole state space you are going to sometimes move to every place and as long as you impose that then these two conditions together.",
            "Give you something that satisfies the properties that I asked for in this picture.",
            "OK, so during the break is pointed out to me that just as I was rushing towards a breaker this some of this isn't so clear so.",
            "There's a difference between what I wrote down here and what an actual sampler actually does when you're implementing it.",
            "So if you're running the code of one of these samplers, you actually simulating a Markov chain, so you start at a particular place in your state space, and at every state of the algorithm you're just considering where you are now to draw a distribution of where you're going next, and you'll go to one particular place, and So what it looks like is, as I drew a sort of a path that runs through your state space.",
            "Anne.",
            "What this is computing is the probability distribution.",
            "Over way would end up after 100 points.",
            "So if I start in one of the states with probability one, that means that I will definitely be in that one state.",
            "Then if I multiply by T, that gives me the distribution over the next step.",
            "If I * 200 times that gives me the probability distribution over where I'll be in 100 steps.",
            "So if I were to run this algorithm many, many times, I would end up in a particular place each time and then.",
            "If I were to look at the frequency of how often I was in state one over those many ensembles, that would be 3/5 and so on.",
            "OK, so importantly, when you're running this algorithm, you don't actually have to visit every point in the state space.",
            "Remember the idea of sampling is that we're just going to get a few places in the state space, and that's going to give us an idea of what's going on in our problem.",
            "So if our algorithm had to visit every point in the state space, it will be useless algorithm because we may as well just enumerate them all at the beginning.",
            "So what we want is that.",
            "The probability over where the algorithm ends up.",
            "It could potentially see every point in your state space, and that's sort of what means that it's valid because we're able to sample from a distribution that.",
            "That's fair, that could sample from anywhere.",
            "We're not actually going to do that, and so we shouldn't be when we're analyzing, the algorithms are looking at whether they're going to work.",
            "We shouldn't actually be saying, Oh well, is it able to sort of recover these frequencies that visit every point in our state space with the right frequency?",
            "Because most states is never going to visit the number of times it goes there in a run of your algorithm will be 0.",
            "OK, so.",
            "How do we actually do this?",
            "I said that we want a transition operator that satisfies these two rules and for this problem with three states, I wrote down a matrix that happens to satisfy this.",
            "This rule, I mean, you might ask where I plug that matrix from, but I said we can't write down a quadratically size matrix.",
            "So how can we come up with a transition rule that will satisfy these properties without having to do some computations which was hard as the ones that we're trying to avoid?",
            "It's a bit like the opposite to the problem that you are usually given in mathematics classes, so.",
            "Mathematics classes they will give you an operator, and they'll sell derive the eigen values or I can functions or eigenvectors of this operator.",
            "Here we know what we know, what the eigenvector we wanted and now we have to construct an operator that has that eigenvector and we have a lot of choice and how we could do that.",
            "We don't need to be able to do it since I'm trying to."
        ],
        [
            "There's a principle which a lot of people use, and this is usually in the introduction to books on MCMC that allows us to construct transition operators that have the correct stationary distribution, and that's called detailed balance is actually very simple principle.",
            "Imagine that you've got some walk through your state space.",
            "This is the trajectory of the algorithm and you just look at two adjacent states.",
            "So at some time it was in State X and the next time it went to state X prime.",
            "So you've got a pair of two adjacent states.",
            "The probability of seeing that pair in a very long run of the algorithm is the probability that this would be drawn from the stationary distribution, because this long walk is exploring the stationary distribution.",
            "Multiplied by the probability that given you're there, you will transition to X prime.",
            "Say that's what we got on the left hand side.",
            "Detail balance says that this joint probability of this pair appearing in this order X to X prime should be the same as seeing the pair in the opposite order, so it should be just as plausible that you would see this picture along random walk, which at some point goes to X prime and then transitions to X.",
            "So that's a way of saying this, sort of this walk process is time reversible.",
            "It doesn't have a preferred direction, it's just as likely to end up here and go here is the other way around.",
            "And so the reason that this makes things easier is that we just have to check this condition for every pair of states.",
            "We don't have to in order to check this condition.",
            "We don't have to do a big sum over all states or anything like that.",
            "This condition implies the one we want the stationary distribution condition because we just sum it both sides over X.",
            "So the left hand side someday, if X is that when we sum this side over X, this here is a probability distribution over X.",
            "And probability distribution sum to one so that some just disappears and we're left with this.",
            "And this is the distribution that we wanted the condition that we wanted.",
            "I'm seeing some notes and some puzzles looks.",
            "OK, sorry.",
            "It's a mathematical condition and it happens to satisfy what we want.",
            "And if you're puzzled for the moment, you can just take the SunTrust.",
            "What, why?",
            "There is no problem that like we need to sample from some distribution issues or which doesn't know.",
            "Or is it some reasonable is optional?",
            "Open assumption.",
            "OK, I'm not sure what the question is, will replace it with a different one and it might be the same so.",
            "This is a necessary condition.",
            "Sorry it's a sufficient condition and that if you have this condition then the thing we want follows.",
            "It isn't a necessary condition.",
            "OK, so this doesn't have to be true for this to be true, and that always bothered me.",
            "So you read these books and they give you this sort of magical rule and they say make your chain satisfy detailed balance and then this will happen.",
            "This is a sufficient condition but not necessary, and you're like well, what do the other transition operators look like like?",
            "You know, if you can have transition operators that don't satisfy this, then what do they do?",
            "And I think it's unsatisfying that most of the books don't tell you what the Nessa."
        ],
        [
            "Condition it so here it is.",
            "So imagine that festival.",
            "This is going to be something which is necessary, and then I'll show that that.",
            "OK, imagine that you've got transition operator, which does satisfy the property.",
            "We're going to start off with that as a starting point.",
            "Then for any such transition operator, we can define another transition operator in the following way we say.",
            "Construct a different transition operator T Tilda, where the if you're in X prime, then the distribution of going to X is proportional to this thing here, so we can always do this.",
            "We can say we need to define the probability distribution, so we're just going to assert its proportional to some positive function and then will re normalize it to make it a distribution.",
            "If the state space is discrete and bounded, we can definitely do that.",
            "You might worry about whether you can normalize it in general.",
            "OK, so that's what I've done.",
            "I've just done this general thing.",
            "We can always do.",
            "I've invented in the probability distribution.",
            "And then I can say, well, what is the normalizing constant?",
            "I'll just sum this over all values of X, which is what the distribution is over.",
            "So here is the normalizing constant.",
            "OK, this is looking a bit like Bayes rule, so it should be fairly familiar now.",
            "This thing here is the.",
            "One side of the stationary condition so becausw T that we started with is a transition operator, then this thing here just returns the probability.",
            "OK, so now I have to find a new transition operator which is equal to this and it's completely general.",
            "You can always do this for any transition operator.",
            "Now if I just multiply both sides by this then I get this condition.",
            "So this looks just like detailed balance, except there's a~ here.",
            "Say for any T you're going to have this satisfied with the T~ here.",
            "Now they wear this thing for reasons.",
            "That I won't go into now.",
            "It's called the reverse operator.",
            "So now if you get this and you some both sides over X then you get the stationary condition returned again.",
            "So that's exactly the same as the detailed balance proof.",
            "Tilda disappeared so you don't actually have to work out what it is or or have it in your hand, so for.",
            "Any T that satisfies stationarity.",
            "You must necessarily have a condition like this.",
            "And then similarly, if you can find a T~ that satisfies this everywhere, then you can sum over X an show the T satisfies the stationary condition distribution.",
            "So this is both necessary and sufficient.",
            "And it's only a really small tweak on this picture.",
            "This picture said if you run the chain for a long time and you look at a pair of States and you workout the probability of that pair appearing, then that same pair should appear just as often the other way around.",
            "The general condition just says.",
            "If you've got a transition operator and you look at the probability of a pair, then there must exist some other transition operator which could be the same one if you want, but it could be a different one for which the probability of getting the power in the reverse order is always the same for all pairs.",
            "So if you have something that tends to like to walk in some direction so it's not time reversible, then you just need to identify something that tends to like to walk in the other direction such that it'll matches up to satisfy this condition.",
            "Now.",
            "You don't always use this a lot of times due to balance is actually the most convenient thing, but more and more I'm finding this peaceful identity to use, and I think it should be.",
            "The textbook should replace their detailed balance section with this.",
            "I mean just the condition.",
            "So the question isn't this hard to check.",
            "'cause I mean, maybe you have to look at every point in the state space to check the condition.",
            "If you had to explicitly enumerate all States and check each of these separately, then yes it would be hard.",
            "So the idea is that hopefully will be able to analytically show that this condition holds simultaneously across selects without having to compute them or enumerate them explicitly, so we'll see explicit examples where this is satisfied without having to do any computational link."
        ],
        [
            "OK, so here's the explicit example, so this is more or less the motivating algorithm I showed you where I didn't explain what was going on, I just said we're perturbing our parameters and we're wondering around.",
            "Metropolis invented the Metropolis algorithm in the 50s and then Hastings, who is a statistician, slightly generalized it in the 70s.",
            "For a long time, this algorithm is more or less synonymous with Markov chain Monte Carlo, so.",
            "It makes sense that it's the first algorithm at length and the transition operators defined in the following way.",
            "Justice with rejection, sampling or important sampling.",
            "It's really good if we can sample from some convenient distribution, one that we've got a library generator for, say we're going to sample our proposals from a distribution key.",
            "But unlike rejection sampling or important sampling where Q just drew a new independent sample each time this proposal distribution is going to depend on where we currently are.",
            "So we're currently attacks and it's going to propose an ex prime.",
            "So an example of a proposal distribution could be.",
            "A Gaussian distribution with mean where we currently are and some noise.",
            "So instead of drawing from some global distribution that's going to fix mean we're going to just add noise around where we are now.",
            "So that's how we're going to propose the next step, so I might go there.",
            "But before I do that, I workout an acceptance probability.",
            "Which is some expression and that gives me a probability where I decide to either move to that place or I stay still.",
            "So in the parameter inference algorithm.",
            "This was a bit where if the new state was more probable than it turned out that with probability one I accepted the move and if it was worth this ratio which I haven't unpacked yet, well tell you that sometimes you shouldn't take that move because it goes to a low probability place.",
            "You should just stay put.",
            "OK, so.",
            "There are two terms in this ratio which match that intuition that I said that the term on the top says the new state should be probable and the old state should be less probable.",
            "So if the new state is more probable than that, this ratio will be bigger than one.",
            "There are also times to do with these proposal probabilities, and this is where this idea of reverse ability in detail balance comes in so.",
            "This is an algorithm that satisfies detailed balance and so that means that it has to be time reversible.",
            "So.",
            "If I don't have a nice symmetrical perturbation like this, is a proposal distribution, I can pick any Qi like if I have a proposal distribution that really likes proposing some particular part of my space, then if I'm not in the part that it likes proposing.",
            "It doesn't look as it's going to be very time reversible because it will propose that I go over there where it links, but if I go there, it's never going to propose the time I should go back to where I am now.",
            "And so it looks very unlikely that I'm going to time reverse just as easily and satisfy this data balance.",
            "So this ratio here is constructed to make the detail balance relationship hold it says.",
            "It's better to take the move if it's easy to go back, and it's worse to take the move if it's easy to.",
            "It's worth to technically, if it, if the proposal that you're currently considering is a very common proposal and it just turns out that if you substitute.",
            "The transition operator into the detail balance relationship then.",
            "It holds and you can just say that analytically.",
            "So for you later I've put in very small type the proof, but the main thing to know is what this mysterious T actually is.",
            "So I'll write that big an so in order to substitute it into the relationship to check it, we need to know what this probability distribution is.",
            "If we're currently at some state, what's the probability distribution over the next state and say under this algorithm it's just?",
            "Well, first I've got to propose to go there, so that's.",
            "Key.",
            "And then I've also got to accept it.",
            "So I multiplied by the probability of accepting.",
            "Given that I proposed and that's this min one ratio thing.",
            "So just a for the acceptance ratio so that this is the definition of T. And if you substitute that into the detail balance relationship, you see that it holds the probability of staying in the same players.",
            "OK, so this is the probability distribution for X prime not equal to X if it's a continuous state space, then never going to propose to stay exactly where you are.",
            "You also have to show what's the probability of staying still and it's 1 minus the sum of all of that.",
            "OK, so this is very easy to show if you substitute this into detail balance relationship, you immediately show that you satisfy.",
            "Then if your transition is the same place, you suddenly worry because you think to workout the probability of staying where I am.",
            "I'm going to have to sum over all places I might propose and reject, and that's a big sum.",
            "But Fortunately any move that says stay still is automatically stationary because of the reasons I said before.",
            "If you don't move anywhere, you leave whatever distribution you have invariant and so that checks.",
            "Probably you don't have to do any big sums."
        ],
        [
            "Right, say I don't like going through code in lectures, but I put it in the slide so because I like it to be explicit what I'm doing.",
            "So this is the entire code of the demos which go on the next slide and it's an implementation of the Metropolis Hastings algorithm, so it just says input estate, perturb it using a Gaussian distribution, and you make the decisions about whether to stay or go by evaluating a log probability which doesn't have to be normalized.",
            "You positive function handle, so it's a general algorithm you can run for any problem where you can part a function handle saying.",
            "This is my log probability up to a constant."
        ],
        [
            "OK, say.",
            "Then I get the code on the previous slide which is MATLAB Octave and I create another function which will.",
            "Plot the course of running this algorithm to explore Gaussian distribution using different proposal distributions so the game we're going to play is we're going to try and draw correlated samples from zero mean unit.",
            "Gaussian using this algorithm.",
            "So obviously we should just draw these samples directly, but if we draw samples from a distribution, we understand them, we can see what the properties of the algorithm and the steps that we're going to propose are around where we are, and we're going to.",
            "Perturb the position using a Gaussian of different widths, so the parameter here is the width of the Gaussian that we're going to use to make our walk.",
            "Say find perturb with a Gaussian of width 100.",
            "Then say I initialize the algorithm at the origin.",
            "Then typically I'm going to propose moving to sort of plus or minus 100, sort of, which isn't very probable under unit Gaussian.",
            "So on almost all iterations I'm going to reject them even stay where I am, and then just by chance my perturbation is going to draw a small value, and I'm going to perturb my current position by a small amount, and I will accept the move, and then I will stay where I am for a very long time again.",
            "So if your proposals are.",
            "Always proposing that you get very low probable places, then you have very low acceptance and you get acceptance rates or less than a percent.",
            "And so now we clearly don't have very many effective samples in our estimate.",
            "Will you know we shouldn't have very good error bars?",
            "We certainly shouldn't assume we've got 1000 samples.",
            "OK, if you make.",
            "The size of the proposal that proposal smaller than you start accepting a lot more and you start really bouncing around the state space.",
            "So here the width of the proposals is similar to the width of the distribution that we're actually exploring.",
            "You notice that we don't actually always accept, so the reason that we don't always accept is our proposal distribution isn't the same as the true distribution.",
            "It's got the same width, but it's centered around where we currently are, which means that sometimes will propose going further out than is reasonable life.",
            "We are currently in the tail.",
            "OK, so this looks good.",
            "We accept more and we reduced the step size so maybe we should reduce the step size again and then we'll accept even more and maybe that will be good.",
            "So this is what happens if you make very very small perturbations.",
            "So now as we're moving at any given iteration, we only travel a very small distance from where we were at the previous iteration, and given where we were at the previous iteration was a reasonable place to be, where we will be at the next iteration will be a reasonable place to be, so almost almost accepted.",
            "In fact, in this round of 1000 iterations only two moves got rejected.",
            "OK, and this is a very bad thing.",
            "So in rejection sampling you just want to accept as often as possible.",
            "Here, the fact that we hardly ever reject is terrible because the rejections are actually the only thing that tell us about the distribution that we're wanting to explore.",
            "So the algorithm is taking an arbitrary random walk.",
            "It's proposing by Q, and it has nothing to do with the problem we're interested in.",
            "And then there's an accept reject stage where it says, do I want this move or do I not?",
            "And that bit of information that yes, you should take it or not you shouldn't, is the only input to the algorithm about the distribution here.",
            "Interested in that you get.",
            "So.",
            "If you always get the almost always get the same answer, you're not being told anything about the distribution you want.",
            "In fact, this is almost exactly just a Gaussian diffusion.",
            "Using steps of this size.",
            "And it's just been kicked twice in 100 of the runs, so this run here hardly has any effective samples.",
            "It doesn't spend much time, any theory, and if you use a long run using this algorithm in an estimator, that will also have very poor properties, so the optimal acceptance rate isn't 100%, it's for various theoretical reasons.",
            "It's a bit less than 50% on a lot of problems, and so people often equate values of 45 or 47% or something like that.",
            "About 1/2 is what you're aiming for, and it's not going to be too critical like this looks fine, even though it's a bit too much.",
            "Otherwise it'll be less than half.",
            "Seems reasonable.",
            "That was sort of maximize the entropy or the amount of information.",
            "The question is why?",
            "Why is it less than half and not a half?",
            "So there's an argument, and David Mackay's book of why it should be half based on information theory grounds, which is sort of the argument over graduating that you know you get this information input about the function of this bit zero or one, and surely the maximum information, is maximum entropy where you zeros and ones are equally probable, and that's the way to extract most information.",
            "It's a bit more complicated than that, cause the pieces of information you're being given aren't independent because you know that you're going to be close to where you were last time, so that's why that that argument, although very nice, isn't exactly true.",
            "There's a lot of complicated mathematic statistic processes that drive the lesson, half assuming certain regularity conditions on the distribution and so.",
            "Ariel like Al Gore Switch CEO, should adapt Sigma during the process or OK.",
            "So the question is.",
            "Maybe we should change Sigma, because if we, perhaps, if we're running to signal, it is far too big.",
            "We notice that we are rejecting all the time and we know that we should take smaller steps and maybe if we were suspiciously accepting all the time we should increase Sigma.",
            "It's certainly a whole literature on adaptive Monte Carlo algorithms.",
            "I mean there's this special issue in the general recently on adaptive MCMC.",
            "You have to be very, very careful about how you do it though, so.",
            "If you.",
            "Change Sigma in an arbitrary way as you run the algorithm.",
            "Then you aren't going to get the correct stationary distribution.",
            "And.",
            "Not sure if I can construct an example of this.",
            "There might not be one true Sigma.",
            "It might be that depending on where you are in the state space, sometimes a small step size would be good and sometimes a big step size would be good.",
            "So if the contours of your distribution look like this and you had a very.",
            "Large basin and a narrow base, and that you know, maybe you want to take small steps here in large steps over here Now, if you.",
            "Have a fixed Sigma.",
            "Then magically the algorithm will spend the right amount of time in this room and the right amount of time in this room.",
            "If you.",
            "Wander into here.",
            "Start rejecting a lot and then reduce your step size.",
            "Then you'll stay in that room for longer than you would have done otherwise, and so you upset the distribution and you end up staying longer in places where you would have a smaller step size.",
            "So you can't do it in an arbitrary way, but there are ways of doing it.",
            "Can you say something about combining different transition operators?",
            "I don't know if you're going to say that.",
            "Yeah."
        ],
        [
            "OK, so I'll do the slide that is before that and then I'll do that.",
            "Say.",
            "The next slide was just I don't want you to get a misconception that perhaps for some Sigma, as in this picture, you can almost draw from the distribution exactly.",
            "So here if you wait a few iterations, then you're almost drawing independent samples.",
            "It's mixing very, very quickly through the space, and it looks as though as long as you set Sigma correctly, you'll have something which is close to ideal sampling that isn't actually true because we're not interested in these toy 1D diffusions and real problems are harder.",
            "So.",
            "It's very common to have correlations amongst the variables.",
            "If we didn't have them, computations would be so hard.",
            "And so our distribution might impose constraints on Sigma that Andre satisfactory.",
            "So if we have a dumb proposal like you is a spherical perturbation around where we are and the contours of the distribution look like this, then.",
            "You're not going to be able to make steps that are sort of much bigger than the largest than the smallest width of the distribution, or you'll forever be stepping off this manifold of high probability.",
            "So the shape of the distribution might limit your step size if you only have one of them, and then given that you've clamped to that step size, it might take you a very long time to diffuse up and down the distribution.",
            "They.",
            "I think this figures in David's book and maybe Christmas book as well that argue that in this situation, if your step size is Sigma and the length scale that you need to wander along is L, then it's going to take you over Sigma squared iterations to sort of wander up and down.",
            "This is sort of the properties of a random walk with steps of this size, so it's going to take you many, many iterations to sort of explore the whole space and make it such that the probability distribution over where you end up is potentially anywhere which is the property we want.",
            "To draw samples.",
            "I should I should just?",
            "I'm drawing all of these type pictures.",
            "I don't want to spend too long on any particular application because there are so many other lectures that are doing specific things.",
            "But an example of where you might get a distribution that has this shape.",
            "You're doing any regression.",
            "You've got a current regression.",
            "This has an intercept.",
            "See and it's like N. Then if we move the intercept up independently then the whole curve will fall off the manifold.",
            "But if we change the slope simultaneously then it might look a lot more reasonable.",
            "So these two parameters are going to be anti correlated so.",
            "Almost the simplest model you can write down with two parameters.",
            "You look at the posterior.",
            "There's going to be strong in this case anti correlation, but in an ellipse shaped pistori.",
            "Save."
        ],
        [
            "Combining operators.",
            "I said that the might not be one.",
            "Ideal stigmatising might partly depend on where you are and say one thing.",
            "My question is, well, perhaps sometimes I could use one and sometimes I could use another, so we need some way of.",
            "Being able to use different transition operators.",
            "It is actually fine to just invent as many transitions operators as you want, which could be 10 different versions of Metropolis, Hastings or with different step sizes and just apply them in turn.",
            "And the reason it's OK to apply them in turn is because doing that lease your stationary distribution invariant, which is the property we want so.",
            "Imagine that your initial condition was drawn from your stationary distribution.",
            "So you've run the chain for a long time and we've got a sample from your stationary distribution.",
            "And you apply transition approach to a.",
            "So you go from this initial condition to X1.",
            "What's the probability distribution over where you end up?",
            "While you sum over all of the places, the X, nor could be weighted by the probability and then you look at the distribution given those of where you would go and becausw TA is a valid transition operator that's going to be your stationary distribution.",
            "OK, now we apply a different transition operator to X1 to go to XT.",
            "We look at what's the probability distribution everywhere we end up.",
            "I think you might see where this is going.",
            "You get you average over all of the places that the previous step could be for which we've already worked out its distribution, and then you see that it's the stationary condition again and say, X2 also has the stationary distribution.",
            "You apply a bunch of operators that leave the stationary distribution invariant, and you leave the stationary distribution invariant so it doesn't matter that these are different operators.",
            "And we can just concatenate them altogether.",
            "Or we could pick them randomly and then our transition operator.",
            "Would we have?",
            "K transition operators are effective, transition operator would be 1 / K some over the transition operators would just be the average of them.",
            "A nice fact about this is that.",
            "There were two conditions that we had to satisfy.",
            "One was that we had to have this stationary condition and one was that we had to be able to get anywhere in the state space so that we didn't sort of get stuck somewhere.",
            "For this concatenation to be OK, we just need the stationary condition and then the concatenated operator of applying A, then B, then C is going to be together a valid operator.",
            "So what you can have is some operators that only move in some of the space, and some operators which are only able to involve the subspaces and concatenate them together and that result.",
            "As long as that combined thing can get everywhere, will be a valid operator."
        ],
        [
            "That might be a bit abstract, so an example of that is Gibbs sampling, which I know about more than half of you will or already name.",
            "So Gibbs sampling is another MCMC algorithm.",
            "It's a way of defining a transition operator that moves around the space, and it works by getting a multivariate quantity.",
            "So a vector with two components and successively drawing each dimension from the conditional distribution of that variable.",
            "Conditioned on all the other variables.",
            "So if I'm currently at this point here, then one of the move says I'm going to workout the conditional distribution along this slice, where X2 is climate an that conditional distribution will look like this and then I will make a move along here and then once I've done that, I will take a slice in the other direction and workout the conditional distribution in the other direction and so all of the moves only move along the axes.",
            "Now any of these individual moves.",
            "If you would supply that lots of times, couldn't get everywhere in this space because it's constrained to lie on this slice, but when you put them together, it's possible now to walk anywhere in the space, and that's why the overall thing is a valid multicolour algorithm.",
            "Sorry.",
            "OK, why is it good?",
            "So this is probably the most popular Markov chain Monte Carlo Rhythm.",
            "For a variety of reasons."
        ],
        [
            "Anne.",
            "One of them is that it's sometimes very easy to implement, so there isn't a step science to pick you notice there is.",
            "There is maybe a free parameter and that you could choose the parameterisation of your problem in the 1st place, but that's complicated most of the time people are going to stick with one parametrization apply, give something so.",
            "One of the conditional distributions of a variable given all of the others is just proportional to the joint probability.",
            "So imagine you've got a big graphical model and you're interested in updating one variable.",
            "For each different setting of that variable, you can evaluate the joint probability of the whole graph as it is with that one variable changed.",
            "And all of the graphical models that set up to do that.",
            "They define a joint probability distribution up to a constant technique.",
            "So this conditional distribution you can write out what it's proportional T, and then if your variables are discrete, you can just explicitly normalize that and you're only summing over all settings of 1 variable.",
            "So if you had a binary variable, this is the sum over 2 terms, so this distribution isn't hard to compute, and often for a lot of models with continuous variables the conditional distributions are simple things like.",
            "Gamma, so Gaussians or things that we have some samples for so.",
            "For a lot of problems, applying Gibbs sampling looks fairly routine.",
            "You can derive all of the conditional distributions in close form or in a form that there's an algorithm to sample from an.",
            "Then you just run through each variable, resampling it, and turn.",
            "An and an example of why how routine it is is that there are very longstanding software packages for Gibbs sampling in graphical models, where you define your graphical model and then it will derive the Gibbs sampler for you, compile it into program and run it.",
            "It also both of these programs bugs come with diagnostic tools to help you sort of see what's going on as well, so that's one of the reasons it's very popular, but get to it.",
            "I've been to stats meeting where a good fraction of the posters said blah blah blah blah with winbugs.",
            "And you'll also sit in talks where they'll say so.",
            "We define this model and at this stage we could do everything in bugs and then we added this bit and bugs can deal with that.",
            "And so we had to go and cut up some cells.",
            "So that's sort of a good fraction.",
            "Problems could be solved just with Gibbs sampling alone.",
            "Trouble is, hosting is.",
            "I just didn't get it.",
            "So it's it's different all right OK?",
            "Thanks.",
            "Metropolis Hastings didn't sample from conditional distributions.",
            "You saw.",
            "You move the variable by doing an arbitrary proposal Q and then deciding whether to accept or reject it.",
            "And it's not one algorithm cause it depends on the choice of key and Q could be something horrendous.",
            "Lee complicated, it could be.",
            "Go off and run some big approximate inference scheme to like approximate your whole distribution sample from that approximation and then decide whether together or not or it could be perturbed where you are with the Gaussian.",
            "So you can't really compare to the metropolis Hastings.",
            "In some applications people will have a really good idea of how to pick you, and so it will be the best approach because you can't be the domain expert he's come up with really good moves in other applications, not so much.",
            "One link is that one way that you can show that gives something as valid algorithm is you can say, well, what if I use Metropolis Hastings and proposed moving using this conditional distribution.",
            "And if you substitute the conditional distributions into the acceptance ratio, Metropolis Hastings and the acceptance probability is 1 always for any move and that means that you don't actually have to check it.",
            "You don't have to draw a random number to accept or reject them.",
            "If you know that the move will always be accepted.",
            "So that is one way that people say that you can see that it's immediately valid.",
            "Yep.",
            "So when you talk about combining operators, you said the combination of operators evaluate the CNC.",
            "Apparently.",
            "Yeah, we say for the sample in between.",
            "Like say you have a sequence of Gibbs sampling and then at the end when you combine that developer.",
            "But what about the simple in between keep them?",
            "So the question is that.",
            "Description of.",
            "How to concatenate operators?",
            "I said that.",
            "You have a few together and that object is a valid transition operator, so you don't need to go away proving this negativity property for each one.",
            "But the way that we tend to run MCMC is that we will actually look at the intermediate samples after applying each one.",
            "Is it OK to use things?",
            "Say.",
            "We can imagine that we've got a block of transitions that we've applied, and then we had another block transitions and we had another block transitions and we've got saved the states after each individual transition and at the edge of each block.",
            "And we could wonder that maybe we should only use each of these samples.",
            "Now.",
            "Each of these samples, as long as we run the chain for a long time, it's going to marginally come from the correct distribution, because this whole objectives are Gothic and each operator satisfies the stationary condition, so the given that this was drawn from the correct distribution.",
            "These ones will also come from the correct stationary distribution.",
            "It's just that there's no way that you could get from here to anywhere else in the state space, but marginally this will still have to create distribution.",
            "I don't need to 'cause it's tacked onto a whole thing which is there godik.",
            "So it is true that you can use all intermediate things as long as.",
            "Stuff that came before allowed you to say that this marginally came from the correct distribution.",
            "Think that's right, I've never been asked that before.",
            "OK. Say oh, time.",
            "And let's see if I should say anything closing.",
            "That is for both lectures."
        ],
        [
            "OK, so given you well, winter just through straight Monte Carlo, why we want to be sampling at all in the way that the standard samples that we have in Matlab and other packages work?",
            "And hopefully the motivation of why they're not good enough for problems that a lot of us will be wanting.",
            "We're interested in high dimensional problems that don't have a lot of tractability about them, so these MCMC algorithms they tend to make local moves that's not always true.",
            "They can sometimes make big moves, but if you have algorithms that.",
            "Always try to make big moves.",
            "They tend to suffer from the failures.",
            "The rejection sampling had.",
            "Luckily, we can concatenate operators so we can make big moves and little meats and make sure that we get everywhere an an as with Gibbs sampling.",
            "All this dumb Metropolis algorithm for which I gave you the whole code.",
            "They're very easy to implement.",
            "The harder to diagnose, and I'll talk about that more in the second lecture, but in principle you can go away and cut them up and run them immediately.",
            "Probably the easiest approximate inference algorithms to implement maybe not the easiest to run, so I'll be around for the whole 2 weeks saying.",
            "Those of you already know a lot about him, so you can come and talk with me.",
            "I'd love to talk with you about your problems and those who haven't seen this before.",
            "Also, any questions anytime.",
            "Thanks very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I mean Mari, and as you know, I'm going to be talking about Markov chain Monte Carlo.",
                    "label": 1
                },
                {
                    "sent": "So just before I start, could I have a show of hands who has actually used MCMC in their work already?",
                    "label": 0
                },
                {
                    "sent": "OK, and I know from talking to somebody this morning, some of you haven't said to those that have.",
                    "label": 0
                },
                {
                    "sent": "I apologize that it might be a bit slow.",
                    "label": 0
                },
                {
                    "sent": "Hopefully you'll get something out of it, but I'm going to give an overview of just why we would do Monte Carlo with any sort at all.",
                    "label": 0
                },
                {
                    "sent": "And for those of you already know, empty might not see anything new until maybe the second breakthrough.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So you've seen a lot about big probability distributions and graphs, and in the morning, so I'm going to start with something very trivial.",
                    "label": 0
                },
                {
                    "sent": "This is, I think, probably the first statistical problem given in high school, which is how do you find the mean of a bunch of objects.",
                    "label": 0
                },
                {
                    "sent": "So if I was interested in knowing the average height of a bunch of people, I would go and measure their Heights and I would add them up and I would divide and.",
                    "label": 1
                },
                {
                    "sent": "Or if I was interested in some other quantities.",
                    "label": 0
                },
                {
                    "sent": "Just the same algorithm, their IQ, or for some reason John Wayne is asked us all whether we left or right handed for the practical.",
                    "label": 0
                },
                {
                    "sent": "Say there are people who actually go out and do this sort of thing.",
                    "label": 0
                },
                {
                    "sent": "Now the danger of going to a lot of technical lectures about graphical models and probability distributions is that you end up adopting a funny language.",
                    "label": 0
                },
                {
                    "sent": "So let's say instead of knowing the height of lecturers here, I was interested in knowing the average height of people in Cambridge.",
                    "label": 0
                },
                {
                    "sent": "Then that's a sum of the height of each person someday.",
                    "label": 0
                },
                {
                    "sent": "But all people in Cambridge divided by the number of people in Cambridge.",
                    "label": 0
                },
                {
                    "sent": "And when you go to these lectures, you now adopt the language where you say this is an intractable inference problem, because it's a very large computation.",
                    "label": 0
                },
                {
                    "sent": "Whereas we know that you know this isn't a difficult problem.",
                    "label": 0
                },
                {
                    "sent": "All you actually need to do is just go and grab a bunch of people.",
                    "label": 1
                },
                {
                    "sent": "Look at how high they are, average their Heights, and you'll have a pretty good idea of what the average height of people in Cambridge is.",
                    "label": 0
                },
                {
                    "sent": "For a lot of the problems that we've lost about how difficult they are, it's just as easy to solve problem.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We are interested in so if you've got any integral that's an expectation, see it's an integral over a probability distribution of some function.",
                    "label": 0
                },
                {
                    "sent": "You can play exactly the same trick instead of actually on your computer visiting every little element of your space and measuring the height of your function and adding them all up, you can just take a bunch of samples from the distribution that you're averaging over.",
                    "label": 0
                },
                {
                    "sent": "Take the empirical average over the samples that you gathered, and get a pretty good idea of what the integral is, and that's the idea of simplement.",
                    "label": 0
                },
                {
                    "sent": "Monte Carlo that that is all Monte Carlo with, so it's an application.",
                    "label": 0
                },
                {
                    "sent": "Say you had a Bayesian inference problem and you had some data and you wanted to make a prediction about some new quantity, then this predicted distribution is just an average.",
                    "label": 0
                },
                {
                    "sent": "You look at the posterior distribution over the parameters in whatever your probabilistic model is, and you say, well, if only I knew those parameters, I would know how to make predictions if I someone told me what the ground truth will parameter in the model is, I would make predictions.",
                    "label": 0
                },
                {
                    "sent": "So I do that.",
                    "label": 0
                },
                {
                    "sent": "For every setting of the parameters and wait by how probable later.",
                    "label": 0
                },
                {
                    "sent": "And again you just.",
                    "label": 0
                },
                {
                    "sent": "You can do it by just sampling the parameters from the distribution and taking empirical average.",
                    "label": 0
                },
                {
                    "sent": "So Monte Carlo has an obvious application whenever you're doing Bayesian inference.",
                    "label": 0
                },
                {
                    "sent": "If integrals like this are difficult, it also has applications in all sorts of places where probability distributions come up.",
                    "label": 0
                },
                {
                    "sent": "So if you ever fit parameters using an algorithm called them, then you often need to compute statistics that can be written as averages and Jeff Hinton next week might talk a lot about Boltzmann machines and Boltzmann.",
                    "label": 0
                },
                {
                    "sent": "Machine learning algorithm involves this sort of sampling average.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so we can pass a bit more formal than saying we just grab a bunch of samples and look at the average we can.",
                    "label": 0
                },
                {
                    "sent": "We can say properties about it so we can look at the expectation of this estimator and it's trivial to show that this is unbiased.",
                    "label": 1
                },
                {
                    "sent": "So on average this estimator will get the right answer and you can also say well how big, how much will the estimate to deviate from the true answer so you can compute the variance of the estimator.",
                    "label": 0
                },
                {
                    "sent": "And what's nice is that it shrinks with the number of samples.",
                    "label": 0
                },
                {
                    "sent": "Say if you want a better answer, you just gather more samples.",
                    "label": 0
                },
                {
                    "sent": "You don't have to go in implementing new algorithm, you just wait longer.",
                    "label": 0
                },
                {
                    "sent": "And because this is a variance in, we normally interested in error bars, the error bars shrink with the square root of the number of samples.",
                    "label": 1
                },
                {
                    "sent": "So you just have to wait longer, you end up having to wait longer and longer if you want your balls to be 10 times shorter, you're going to have to wait 100 times longer, so there's a tradeoff.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "I saw this example along time ago.",
                    "label": 0
                },
                {
                    "sent": "I'm sure a lot of people have done, but a concrete example of how sampling works.",
                    "label": 0
                },
                {
                    "sent": "Say we want to approximate Pi, which is four times the area of this red area.",
                    "label": 0
                },
                {
                    "sent": "If this is a unit square.",
                    "label": 0
                },
                {
                    "sent": "Right, this is an integral which is the integral of the indicator function saying.",
                    "label": 0
                },
                {
                    "sent": "Are you inside this area, averaged over a uniform distribution within this square?",
                    "label": 0
                },
                {
                    "sent": "So this is like the most stupid way of computing Pi you can possibly imagine.",
                    "label": 0
                },
                {
                    "sent": "So Pi is equal to four times this integral, and you can now approximate this integral by sampling from distribution, which is throw down points in the square and then just see whether you get a one or a zero.",
                    "label": 0
                },
                {
                    "sent": "Are you in this red circle or not?",
                    "label": 0
                },
                {
                    "sent": "So without knowing anything really about geometry you can get with 12 samples, that pie is about 3.",
                    "label": 0
                },
                {
                    "sent": "And that's sort of the feel of Monte Carlo.",
                    "label": 0
                },
                {
                    "sent": "You can just get a few samples and you get a general idea of what's going on it 'cause you're ballpark figure, which can be good to sort of sanity check if you're doing something else, like EP or a different approximate inference algorithm.",
                    "label": 0
                },
                {
                    "sent": "Figure completely different ballpark number.",
                    "label": 0
                },
                {
                    "sent": "You know you've done something wrong.",
                    "label": 0
                },
                {
                    "sent": "You can also be patient and wait longer so I could draw 10,000,000 samples and I would get that Pi is 3.14 something, but it's not very accurate, and this is never going to be a way to get really precise numbers.",
                    "label": 0
                },
                {
                    "sent": "So if you're interested in that, you probably don't want to be doing.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Cali I mean.",
                    "label": 0
                },
                {
                    "sent": "Specifically, if you wanted to compute Pi by numerical integration, you could just use numerical quadrature and with only 100 valuations or maybe 1000 you can get \u03c0 to sort of as accurate as you can represent.",
                    "label": 0
                },
                {
                    "sent": "So you really don't want to be doing multi color for this sort of sort of integral, and this was summarized by Alan Cycle.",
                    "label": 0
                },
                {
                    "sent": "He's a funny guy and he was quite was the opening to his lecture course on Monte Carlo methods.",
                    "label": 0
                },
                {
                    "sent": "An he is actually done an awful lot of good work in multicolor methods as well, and I don't completely agree with this quite well.",
                    "label": 0
                },
                {
                    "sent": "I sort of agree with it, but I think you could replace multicolor with anything, because if X is a method, it should only be used when all the other methods are worse.",
                    "label": 1
                },
                {
                    "sent": "I think you can agree with that for any X.",
                    "label": 0
                },
                {
                    "sent": "So I. I think that's a question that you want to sort of be asking yourself.",
                    "label": 0
                },
                {
                    "sent": "In my practical, I'm going to try and get you to sort of look at the problem with doing multi color actually makes some sense.",
                    "label": 0
                },
                {
                    "sent": "There's other practical that will be looking at other methods and you know they'll be looking problems with their appropriate.",
                    "label": 1
                },
                {
                    "sent": "So the question is really it's Monte Carlo.",
                    "label": 0
                },
                {
                    "sent": "The right approach feed for you, and maybe the way to find that out is that you have to implement it and compare.",
                    "label": 0
                },
                {
                    "sent": "You do the sanity check of whether the numbers in the right ballpark and then you go for the first method or you go for this 'cause it's the only thing that works.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, there's actually another motivation for drawing samples.",
                    "label": 0
                },
                {
                    "sent": "We concentrate a lot on sort of numerical computation, that's 'cause it's a concrete thing to do, but I just think samples are pretty, so this is a figure from David Mackay's textbook, and this isn't a machine learning application, but there are people who are interested in tiling shapes, and there's a whole sort of field of geometrical combinatorics, and so this is a problem when you pack lozenges inside a hexagon and you randomly sort of create.",
                    "label": 0
                },
                {
                    "sent": "You can think of this as a hub that holds bricks that are sort of in a pilot filling it.",
                    "label": 0
                },
                {
                    "sent": "If you can see that optical illusion an this is a random sort of way of stacking bricks into a HUD.",
                    "label": 0
                },
                {
                    "sent": "And when he's just glance at this, you can see that the sort of this circle forms, and there's a whole literature on describing the properties of this circle, but you might not notice it was there unless you just looked at samples.",
                    "label": 0
                },
                {
                    "sent": "You could have found that the circle exists and described the properties of it just by doing mathematics, but you know that it's something that you should go and look for by just glancing at the sample.",
                    "label": 0
                },
                {
                    "sent": "And for us, I think if you can visualize what your probabilistic model is doing, and you can draw samples, then it might give you hints of sort of things that you should go away and you should do so.",
                    "label": 0
                },
                {
                    "sent": "Here's a really simple example.",
                    "label": 0
                },
                {
                    "sent": "By now a bit of a toy problem in machine learning, but.",
                    "label": 0
                },
                {
                    "sent": "Here are some very low resolution binary images of digits and these are samples drawn from probabilistic models that have been fitted to the digits so that these here are 16 samples drawn from a model which that mixture of multivariate Beninese.",
                    "label": 0
                },
                {
                    "sent": "So this is a probabilistic model that basically says.",
                    "label": 0
                },
                {
                    "sent": "The way I'm going to generate an image is I'm going to pick some template, exactly exemplar image, and I'm going to add a bit of noise to it, and then that's going to be the images, but also the way that you explain any image you see is.",
                    "label": 0
                },
                {
                    "sent": "You say this is a bit like one of my templates, and it's a bit different, so I'll explain that by noise.",
                    "label": 0
                },
                {
                    "sent": "And when you draw samples, you see there really noisy, and so that immediately tells you that this sort of model under fits.",
                    "label": 0
                },
                {
                    "sent": "So you can't explain all of the variations in digits by just 100 templates, which is what was fitted here.",
                    "label": 0
                },
                {
                    "sent": "You need to have sort of a more flexible model that can capture all of the invariants is that you get in images.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There's actually a long history of this sort of justice, eyeballing things and seeing how things turn out so Monte Carlo methods really took off in the 50s when the first computers, but before that, Fermi, who was the physicist was?",
                    "label": 0
                },
                {
                    "sent": "Or it's astounding his colleagues, because he would come in, and he would say, oh, I think that this neutron experiment will come out like this, and he was often right, and he his answers are in the right ballpark, and it's 'cause he was up at night with a hand adding machine, running Monte Carlo simulations on his desk without a computer.",
                    "label": 1
                },
                {
                    "sent": "Now we've got the computing power that we can just do these things trivially, so we really should.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for us, if we've written down our model as a directed graph rather than the sort of series of dynamical equations for new neutrons, we should know how to sample from our model.",
                    "label": 0
                },
                {
                    "sent": "And if we've gone the route of writing down a directed graphical model or a Bayes net is some people call them, then the algorithm is really simple and I'm sorry I Miss Stevens lectures, so I don't know if you went through this so the way that you would sample from this base net which was in slides as a running example.",
                    "label": 0
                },
                {
                    "sent": "Is that you first just sample all of the parents right at the top and we know what their distribution is.",
                    "label": 0
                },
                {
                    "sent": "Because when this graph is giving us a joint distribution which tells us what these distributions are, and then we sample all the children once we know what their parents are just from the conditional distributions that we've written out.",
                    "label": 0
                },
                {
                    "sent": "So this graph just gives us the natural generative structure.",
                    "label": 0
                },
                {
                    "sent": "I mean, that's one of the reasons are great for modeling.",
                    "label": 0
                },
                {
                    "sent": "So once we've gone through that effort, we may evaluate that and see what it does and see if it's captured.",
                    "label": 0
                },
                {
                    "sent": "The things we wanted it to.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how do we actually implement that?",
                    "label": 0
                },
                {
                    "sent": "How do we do this ancestral passenger?",
                    "label": 0
                },
                {
                    "sent": "All these variables and the short answer is that you know we just use Matlab or we use whatever computing environment provides, because it's going to have implemented in it already.",
                    "label": 0
                },
                {
                    "sent": "Alot of these standard distributions that we use, so drawing from the prior is going to be simple and if your library didn't provide these functions and there's a good book which you can just download that explains how a lot of these algorithms work under the hood.",
                    "label": 0
                },
                {
                    "sent": "So this is sort of old established stuff, but we're going to have to understand how a couple of these library routines actually work 'cause.",
                    "label": 0
                },
                {
                    "sent": "That's going to sort of tell us how we're going to improve on them, and that's unless you really know what's going on.",
                    "label": 0
                },
                {
                    "sent": "You can't move forward from that.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's a really standard way of drawing samples from a distribution.",
                    "label": 0
                },
                {
                    "sent": "You have some probability density and you just sample uniformly points underneath the area from this curve.",
                    "label": 0
                },
                {
                    "sent": "So you just there's an area here and you just choose something randomly from inside there, and then if you read off the location in the input space you're interested in, that's your sample.",
                    "label": 0
                },
                {
                    "sent": "So the reason this works is just that.",
                    "label": 0
                },
                {
                    "sent": "If the curve here is twice as high than here, then there's twice as much area underneath it, and so your choice is likely to sample it so it respects the distribution.",
                    "label": 0
                },
                {
                    "sent": "And the way you implement that is you notice that.",
                    "label": 0
                },
                {
                    "sent": "So this point here has about half of the probability mass to its left, and this point here has, say, about a sixth of the probability mass to its left.",
                    "label": 1
                },
                {
                    "sent": "So this amount of masses to the left hand side of the points is actually a uniform random variable.",
                    "label": 1
                },
                {
                    "sent": "So you implemented by drawing this uniform random variable and then working out how far through the curve you should be.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So mathematically, what you do is you workout the cumulative distribution of the curve.",
                    "label": 0
                },
                {
                    "sent": "You draw uniform random variable and then you shove that through the inverse cumulative.",
                    "label": 0
                },
                {
                    "sent": "So I set in MATLAB brand.",
                    "label": 0
                },
                {
                    "sent": "It gives me .7.",
                    "label": 0
                },
                {
                    "sent": "I read across to this cumulative curve I read down and that's my sample.",
                    "label": 0
                },
                {
                    "sent": "And that's great, as long as we can actually compute the blue curve and invert it, which we can do for Gaussians and exponentials and simple 1D.",
                    "label": 0
                },
                {
                    "sent": "Distributions, but we can't always do it.",
                    "label": 1
                },
                {
                    "sent": "So if you look inside the source code for something like a gamma random number generator, depending on which library or you're looking at, it might do a series of horrendously complicated things depending on which parameter regime, urine and one of the.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That might do for some of the parameter regimes is rejection sampling.",
                    "label": 0
                },
                {
                    "sent": "Say.",
                    "label": 0
                },
                {
                    "sent": "We want to sample points underneath this blue curve that for distribution.",
                    "label": 0
                },
                {
                    "sent": "And we don't know how to do that because we don't know how to compute this cumulative and invert it.",
                    "label": 0
                },
                {
                    "sent": "But we do know how to sample from a bunch of other distributions, like Gaussians, uniform distributions, piecewise uniform distributions.",
                    "label": 0
                },
                {
                    "sent": "So we get some other distribution that we do know how to sample from, like a Gaussian and we scale up the function such that it's always above the blue curve.",
                    "label": 0
                },
                {
                    "sent": "Then we sample.",
                    "label": 0
                },
                {
                    "sent": "From the green distribution, the key distribution and we pick a random height uniformly so that we're sampling points underneath this green curve somewhere.",
                    "label": 0
                },
                {
                    "sent": "Now what we're doing is we're summing points uniformly under the green curve.",
                    "label": 0
                },
                {
                    "sent": "If we toss out all the ones underneath the blue curve, then we'll just be left with samples drawn uniformly from the blue curve.",
                    "label": 0
                },
                {
                    "sent": "So the algorithm is draw sample.",
                    "label": 0
                },
                {
                    "sent": "Oh, it's above the blue curve, reject it.",
                    "label": 0
                },
                {
                    "sent": "Draw a sample is underneath the blue curve.",
                    "label": 0
                },
                {
                    "sent": "We keep it, and we have a sample.",
                    "label": 0
                },
                {
                    "sent": "Say.",
                    "label": 0
                },
                {
                    "sent": "This is this is pretty general.",
                    "label": 0
                },
                {
                    "sent": "The only technical requirement is that you need to be able to bound this function because you need to construct this thing that will be above it everywhere.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "The only problem with it really is that it seems a bit wasteful because you do all this computation and then if you have a rejection you just sort of throw it away and you get nothing from it.",
                    "label": 0
                },
                {
                    "sent": "And potentially can spend most of your computer time just sort of computing these functions and then doing nothing with that computation and throwing them out.",
                    "label": 0
                },
                {
                    "sent": "Say.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There's a trick that means that you never have to reject samples if you, if you're in a regime where you can't draw samples in the distribution you want to, but you can draw from some other distribution.",
                    "label": 0
                },
                {
                    "sent": "Important sampling is a trick that allows you to just sample from the distribution you actually want to instead.",
                    "label": 0
                },
                {
                    "sent": "Say you have an integral to solve.",
                    "label": 0
                },
                {
                    "sent": "This is what we want to estimate.",
                    "label": 0
                },
                {
                    "sent": "And we multiply by Q, which is the distribution we can sample from and we divide by key.",
                    "label": 0
                },
                {
                    "sent": "So this is just multiplying by one as long as we never divide by zero and so this is an identity.",
                    "label": 0
                },
                {
                    "sent": "And now this is just an integral which is an expectation under key and the function is this whole object here.",
                    "label": 1
                },
                {
                    "sent": "So now we just supply simple Monte Carlo with sample from key and we evaluate the rest of the integrand.",
                    "label": 0
                },
                {
                    "sent": "And what's nice about this trick is that actually your integral didn't need to be an expectation in the 1st place.",
                    "label": 0
                },
                {
                    "sent": "You'll notice here that nothing about this relied on P here being a distribution.",
                    "label": 0
                },
                {
                    "sent": "You think of FP together being the integral integrand, and that just sticks together.",
                    "label": 0
                },
                {
                    "sent": "You could do that with any integrand.",
                    "label": 0
                },
                {
                    "sent": "It wouldn't have to be an expectation.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Sample from.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so that's it.",
                    "label": 0
                },
                {
                    "sent": "That's a great question.",
                    "label": 0
                },
                {
                    "sent": "How do you choose Q?",
                    "label": 0
                },
                {
                    "sent": "So I've said you can choose any Q like one that you can draw a sample from.",
                    "label": 0
                },
                {
                    "sent": "As long as we don't divide by zero.",
                    "label": 0
                },
                {
                    "sent": "So that technical requirement, but.",
                    "label": 0
                },
                {
                    "sent": "It's probably clear that some queues are going to work much better than others, so there's sort of a question of why and how we might pick and so.",
                    "label": 0
                },
                {
                    "sent": "I mean, if we had an input space and this was our true distribution, and you know we're interested in the average of some function which runs runs through the space as well, then clearly if we picked a distribution that had most of its mass over here, then the samples over here aren't going to tell us much about the expectation of this function under this distribution.",
                    "label": 0
                },
                {
                    "sent": "So we're going to want a distribution that has its mass in much the same place.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Something else we want to really avoid is making Q small one peers big.",
                    "label": 0
                },
                {
                    "sent": "So for example, imagine what a variational.",
                    "label": 0
                },
                {
                    "sent": "If you know about variational approximations, what they would do is find a mode and seek into that.",
                    "label": 0
                },
                {
                    "sent": "So if I did a Gaussian approximation to this under some cost functions, I would fit a Gaussian around the Titans made.",
                    "label": 0
                },
                {
                    "sent": "Now that means I'm very rarely going to get samples over here.",
                    "label": 0
                },
                {
                    "sent": "So now if I do very occasionally, I'll get a sample here.",
                    "label": 0
                },
                {
                    "sent": "And now I evaluate the importance of this sample and the important is P / Q. OK, so now in the tail of the Gaussian Q is really small and P is quite big and the importance of this sample ends up being absolutely enormous and so that means that in this empirical thumb over my samples, maybe one of the terms will be hugely bigger than any of the others, and effectively I've only drawn 1 sample.",
                    "label": 0
                },
                {
                    "sent": "So what you want to do is construct a distribution that roughly covers the distribution and make sure that it's never really small where there's appreciable amounts of mass.",
                    "label": 0
                },
                {
                    "sent": "It's fine to have your key distribution have a bit of tail where there's no mass, because you'll just occasionally get a sample out there and give it no wait, and you've wasted a bit, but nothing blows up.",
                    "label": 0
                },
                {
                    "sent": "So the question is, in rejection sampling.",
                    "label": 0
                },
                {
                    "sent": "We sample from the subtree distribution and sometimes we say oh, we sample here too often because our Q is big here compared to PC will throw them out and here we just softly rejecting because we down weight them a bit.",
                    "label": 0
                },
                {
                    "sent": "But it looks much the same and.",
                    "label": 0
                },
                {
                    "sent": "It's just slightly more efficient in the soft, so if we're not interested in the samples themselves were interested in this expectation, then it's lower variance to attach a real number to every single sample you've got them to make a hard decision.",
                    "label": 0
                },
                {
                    "sent": "If I'm going to wait the sample by zero or one.",
                    "label": 0
                },
                {
                    "sent": "So if you compute the variance of the estimators, this turns out to be more efficient.",
                    "label": 0
                },
                {
                    "sent": "Look for me that the easiest way in.",
                    "label": 0
                },
                {
                    "sent": "The best way to choose just uniform distribution, which is where they constantly talk.",
                    "label": 0
                },
                {
                    "sent": "Yeah, say.",
                    "label": 0
                },
                {
                    "sent": "So if we can bound the function, say, this is the biggest thing and we know the extent of it.",
                    "label": 0
                },
                {
                    "sent": "We could just have a top hat like that if.",
                    "label": 0
                },
                {
                    "sent": "If P was something like a Gaussian that has infinite tails, then a uniform distribution would have to go out forever, and then it would be improper and we can touch the sample from it.",
                    "label": 0
                },
                {
                    "sent": "But you're right, if the distribution has compact support, then you know maybe uniform distribution would work fine.",
                    "label": 0
                },
                {
                    "sent": "It depends on the problem.",
                    "label": 0
                },
                {
                    "sent": "Sometimes you'll have clever tricks where you know really tight bounds of the function in some places, and there are also adaptive rejection sampling algorithms that sort of conform really good approximation for you on the fly.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "So on the previous slide, I assumed that we could evaluate both P&Q.",
                    "label": 1
                },
                {
                    "sent": "That's not actually always true, so if we have.",
                    "label": 0
                },
                {
                    "sent": "Under over here.",
                    "label": 0
                },
                {
                    "sent": "If we have a parameter posterior.",
                    "label": 0
                },
                {
                    "sent": "Pets are parameters given data.",
                    "label": 0
                },
                {
                    "sent": "Then we can normally evaluate the likelihood probability of the data given their parameters.",
                    "label": 0
                },
                {
                    "sent": "We can normally evaluate the prior owner parameters.",
                    "label": 0
                },
                {
                    "sent": "It's often something very simple.",
                    "label": 0
                },
                {
                    "sent": "This might be evaluating joint probability under a graph or something, but it's usually fairly tractable.",
                    "label": 0
                },
                {
                    "sent": "What we don't know is this thing on the bottom.",
                    "label": 0
                },
                {
                    "sent": "The normalizing constant for the marginal likelihood of the model.",
                    "label": 0
                },
                {
                    "sent": "But the evidence for the model probability data has many names.",
                    "label": 0
                },
                {
                    "sent": "This thing here is a difficult integral to compute, so normally.",
                    "label": 0
                },
                {
                    "sent": "What we like our algorithms that work with the distribution that's proportional to something we can evaluate and would like to drop constants.",
                    "label": 0
                },
                {
                    "sent": "So there's a version of rejection sampling that works when you don't know the normalizing constant of the distribution and.",
                    "label": 0
                },
                {
                    "sent": "It basically works by pulling out a ratio of normalizing constants from P&Q and separately estimating that.",
                    "label": 0
                },
                {
                    "sent": "But it turns out that you can estimate this ratio from the same samples that you've drawn, and what's neat is that.",
                    "label": 0
                },
                {
                    "sent": "Approximating this ratio turns out to be equivalent to working out all your important weights and then re normalizing them so they add up to one.",
                    "label": 0
                },
                {
                    "sent": "So you run this algorithm except instead of waiting by Pierre Vicky, you wait by these things normalized so that if you sum over all your samples, these things add up to one.",
                    "label": 0
                },
                {
                    "sent": "And it's a few lines to show that this is a valid thing to do, but I'm sure you'll be able to wait that out.",
                    "label": 0
                },
                {
                    "sent": "And if you can't, I can show you afterwards.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, say.",
                    "label": 0
                },
                {
                    "sent": "What I've talked about so far is just plain simple Monte Carlo.",
                    "label": 1
                },
                {
                    "sent": "Haven't mentioned anything to do Markov chains yet, and so this is just the summary of what I've said so far and it's great.",
                    "label": 0
                },
                {
                    "sent": "I've had lots of questions, so I think hopefully you'll have a good idea of what's going going on with what we've covered.",
                    "label": 0
                },
                {
                    "sent": "One thing I would say is why would we ever do rejection sampling?",
                    "label": 0
                },
                {
                    "sent": "So there's a question of why do important sampling?",
                    "label": 0
                },
                {
                    "sent": "Because it looks much the same, so I gave a reason why important something is better.",
                    "label": 0
                },
                {
                    "sent": "Why did I bother to tell you about rejection sampling?",
                    "label": 0
                },
                {
                    "sent": "Any ideas?",
                    "label": 0
                },
                {
                    "sent": "So imagine that I'm one of these people doing a physical simulation, wanting to look at the output of a system and it dynamics of it involves a sequence of draws from random number generators, so I know that when this particle diffuses, its next step will come from this distribution.",
                    "label": 0
                },
                {
                    "sent": "Then for my simulation to make any sense, I really want to be drawing from specific distributions and it will be much harder to interpret.",
                    "label": 0
                },
                {
                    "sent": "If I have a load of weights attached to everything and they're not coming from the right distribution, so there are times when you actually want real samples, and that's what rejection sampling is for.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so why aren't we done?",
                    "label": 0
                },
                {
                    "sent": "Like I just said, Monte Carlo is the Super general thing.",
                    "label": 0
                },
                {
                    "sent": "You can workout any integral you want and I've given you example algorithms that can sample from any distribution.",
                    "label": 0
                },
                {
                    "sent": "The reason it's not the end of the lecture is because the simple algorithm that I showed you don't really scale up to the sort of problems that we're interested in with solving inference problems.",
                    "label": 0
                },
                {
                    "sent": "So I have two examples here.",
                    "label": 0
                },
                {
                    "sent": "If you have an undirected graphical model, then you can't sample from it with one of these ancestral path.",
                    "label": 1
                },
                {
                    "sent": "There isn't this sort of nice directed interpretation of it, so if you have a large undirected graphical model or a mark of random field, or defined by a model defined by factor graph, then you're not able to just draw a sample from that distribution even to look at it.",
                    "label": 0
                },
                {
                    "sent": "And this is very high dimensional distribution, so.",
                    "label": 0
                },
                {
                    "sent": "Any any algorithm that's just designed to work in later mentions isn't going to work.",
                    "label": 1
                },
                {
                    "sent": "Similarly, even if you have a directed model and you're interested in.",
                    "label": 0
                },
                {
                    "sent": "Actually, looking at data rather than just looking at how pretty it is if we condition on a variable and then we want to know the distribution conditioned on that, then again we have a distribution where we don't know the normalizing constant.",
                    "label": 0
                },
                {
                    "sent": "It's a high dimensional object and this looks as though it's going to be a tricky distribution to sample from.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Say it might not be obvious why rejection sampling and important something don't work in high dimensions.",
                    "label": 0
                },
                {
                    "sent": "So as a toy example, imagine the distribution we were interested in was a spherical Gaussian distribution.",
                    "label": 0
                },
                {
                    "sent": "We just didn't know it, so we could evaluate this distribution point wise, and it happens to be its vertical Gaussian.",
                    "label": 0
                },
                {
                    "sent": "But we didn't know that.",
                    "label": 0
                },
                {
                    "sent": "So we're going to use a different distribution Q.",
                    "label": 0
                },
                {
                    "sent": "Which is a different circle, Gaussian in order to either do rejection sampling or important sampling.",
                    "label": 0
                },
                {
                    "sent": "OK, so now we can say how well with these algorithms work.",
                    "label": 0
                },
                {
                    "sent": "How long will we have to wait before we can accept a sample and rejection sampling?",
                    "label": 0
                },
                {
                    "sent": "Or we're doing important sampler?",
                    "label": 0
                },
                {
                    "sent": "How goodwill are estimated be?",
                    "label": 0
                },
                {
                    "sent": "Safe rejection sampling to get the bounding.",
                    "label": 1
                },
                {
                    "sent": "It turns out that Q has to be wider than P because if it's narrower than you end up multiplying it by Infinity to make it above it everywhere.",
                    "label": 0
                },
                {
                    "sent": "So you have to make it wider and imagine that P is slightly different from a normal distribution somewhere so that you can't quite fit it to be the same width.",
                    "label": 1
                },
                {
                    "sent": "Then the fraction of the proposals that you end up accepting falls off exponentially with the width of Q.",
                    "label": 0
                },
                {
                    "sent": "So if you just have a proposal distribution which is slightly wider.",
                    "label": 0
                },
                {
                    "sent": "Or slightly misfit in some way.",
                    "label": 0
                },
                {
                    "sent": "In high dimensions, it means that the number of proposals you accept can just drop towards 0, like if you're in 100 dimensions and Sigma is 1.1, then you're going to be waiting a long time for your samples.",
                    "label": 0
                },
                {
                    "sent": "It takes a few lines to show this and to be honest this might be wrong.",
                    "label": 0
                },
                {
                    "sent": "'cause I did it last night, but the variance of important some importance weights?",
                    "label": 1
                },
                {
                    "sent": "Is this or something like this and I'm sure it's going to scale exponentially with Sigma, so if you're doing important sampling then the variance of your estimator also blows up.",
                    "label": 0
                },
                {
                    "sent": "If you have a distribution that's too wide and then for the reasons I explained you can't have a distribution that's too narrow either or that's going to be problems in that turns out here if Sigma.",
                    "label": 0
                },
                {
                    "sent": "If Sigma ends up being really small, then you end up with the variance blowing up too.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm and you don't even need to be in that high dimension to begin to think.",
                    "label": 0
                },
                {
                    "sent": "Get some intuition that these algorithms aren't the right thing to do so.",
                    "label": 0
                },
                {
                    "sent": "I've got here a very very toy data modeling application.",
                    "label": 0
                },
                {
                    "sent": "I'm doing linear regression and I'm pretending I didn't know how to do this analytically, so I have a data set and they have the green line, which is a randomly drawn regression line.",
                    "label": 0
                },
                {
                    "sent": "So I'm doing important sampling and I'm saying I'm going to draw a whole bunch of possible lines and then I'm going to from an arbitrary distribution that considers sort of all all lines, and then I'm going to wait them using important sampling to say which ones actually fit the data so that I can approximate things under the posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "So most of these lines are rubbish like you know they have nothing to do with the data and say their importance.",
                    "label": 0
                },
                {
                    "sent": "Weights end up being really small.",
                    "label": 0
                },
                {
                    "sent": "Light sensor minus 810 -- 9/10 -- 51 and only a few of them by chance actually happened to sort of go through the data and so very small number of them pick up most of the importance weights.",
                    "label": 0
                },
                {
                    "sent": "I'm of course this would be much more extreme if you had more than two parameters.",
                    "label": 0
                },
                {
                    "sent": "I fixed the noise here so it's only sampling from 2 parameters.",
                    "label": 0
                },
                {
                    "sent": "And notice what happens.",
                    "label": 0
                },
                {
                    "sent": "So the algorithms running in this order.",
                    "label": 0
                },
                {
                    "sent": "Although you could do this in parallel 'cause there is no ordering really.",
                    "label": 0
                },
                {
                    "sent": "But I drew this sample.",
                    "label": 0
                },
                {
                    "sent": "I draw this sample, I'd rather sample.",
                    "label": 0
                },
                {
                    "sent": "I finally get one that's any good, and then I completely ignore that and continue drawing from my dumb distribution and soda or a silly one.",
                    "label": 0
                },
                {
                    "sent": "Again, I get one, that's OK, but then I make it worse again and make it even worse.",
                    "label": 0
                },
                {
                    "sent": "And I never learn from what I'm doing.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Surely once I sort of got alignments in the right ballpark, I should be able to do something with that?",
                    "label": 0
                },
                {
                    "sent": "So it's a lot of urine.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In a.",
                    "label": 0
                },
                {
                    "sent": "The idea of Markov chain Monte Carlo is to come up with algorithms that instead of just randomly drawing IID proposals from distributions, you instead evolve samples and take smaller steps.",
                    "label": 0
                },
                {
                    "sent": "So here is an algorithm that will go into more detail later that does something different.",
                    "label": 0
                },
                {
                    "sent": "Instead of drawing samples independently, it proposes small changes to what you've currently got, so now there is a time ordering to this algorithm.",
                    "label": 0
                },
                {
                    "sent": "It's running along here.",
                    "label": 0
                },
                {
                    "sent": "So we started off.",
                    "label": 0
                },
                {
                    "sent": "With this green regressive here and the algorithm does perturbed that and propose the different regressor and it's colored red to say, oh that look worse.",
                    "label": 0
                },
                {
                    "sent": "I'm going to reject it.",
                    "label": 0
                },
                {
                    "sent": "So it kept the same regressor, it didn't throw it away, and it can't propose a different progressive.",
                    "label": 0
                },
                {
                    "sent": "And it was still there, so it kept the old one again and then eventually.",
                    "label": 0
                },
                {
                    "sent": "A small perturbation the other way produces a good regression fit, and once it's in the right ballpark, small perturbations tend to be good, and so you get a sequence of reasonable samples that look as though they might come from the posterior distribution over regression lines that go through this data set.",
                    "label": 0
                },
                {
                    "sent": "So this is a series of pictures in data space and then in terms of the parameter space of our model, the algorithm looks like this.",
                    "label": 0
                },
                {
                    "sent": "You've got parameters for the describe where the line lies and the algorithm is moving around the space of parameters and the red line show that sometimes you propose to a point in the parameter space which has low posterior probability and so you don't go there, you stay where you are and you move somewhere else.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "OK, so the question is, is this the same as hillclimbing and say?",
                    "label": 0
                },
                {
                    "sent": "What I literally said sounds like that because I didn't add any stochastic element to it, so I said, you know you perturb something.",
                    "label": 0
                },
                {
                    "sent": "If it's better you go there, and if it's worth you don't.",
                    "label": 0
                },
                {
                    "sent": "And that would be, you know, an optimization method.",
                    "label": 0
                },
                {
                    "sent": "It some people claiming this algorithm.",
                    "label": 0
                },
                {
                    "sent": "Says if you tweak it and it's better than definitely go there, but if you tweak it in it's worse, then sometimes you might go there anyway and so that stops it from being an optimization algorithm.",
                    "label": 0
                },
                {
                    "sent": "So we're not going to be doing maximum likelihood or map.",
                    "label": 0
                },
                {
                    "sent": "We're going to find the best parameters.",
                    "label": 0
                },
                {
                    "sent": "We're going to tend to move towards a better parameters, but will also sort of randomly move around a bit, and that's what's going to let us sample from the posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "So at the moment, this is where you do.",
                    "label": 0
                },
                {
                    "sent": "I haven't explained how this works, I'm just saying this is the flavor of the algorithm we want, and then over the next few slides will understand where it's actually come from.",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "Ha ha say.",
                    "label": 0
                },
                {
                    "sent": "What's the difference between simulated annealing and this algorithm?",
                    "label": 0
                },
                {
                    "sent": "This algorithm predates simulated annealing, so this algorithm was invented in the 50s and let salamas when they're doing developing nuclear weapons and simulated annealing, I think was the 80s and simulated annealing uses this algorithm in.",
                    "label": 0
                },
                {
                    "sent": "It's in a loop, but then it does something else to change the distribution at each iteration, so this is a key part of simulated annealing.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so here's the key idea of Markov chain Monte Carlo.",
                    "label": 1
                },
                {
                    "sent": "We're interested in some probability distribution, and it might lie in a high dimensional space.",
                    "label": 0
                },
                {
                    "sent": "We can only evaluate it up to a constant, but we can evaluate it point wise up to constant wherever we like, and we want to construct some sort of random walk or diffusion process that will explore this distribution.",
                    "label": 0
                },
                {
                    "sent": "So will initialize our walk in some arbitrary way, because often these problems are intractable, we don't know.",
                    "label": 0
                },
                {
                    "sent": "Like good places in our parameter space.",
                    "label": 0
                },
                {
                    "sent": "Also we initialize in some way and then we're going to follow a Markov chain.",
                    "label": 0
                },
                {
                    "sent": "That is the way that we draw the next step only depends on the previous step and nothing else.",
                    "label": 0
                },
                {
                    "sent": "So we have a probability distribution over where we go next given where we were before and using that simple rule, we're going to want to take steps that wander around and eventually after some burning period of sort of finding the distribution, will explore the distribution such that if we looked at where all of the points of what visited are, which of these blue dots, after a while I stop during the black line and justice.",
                    "label": 0
                },
                {
                    "sent": "Particular dot wherever it went.",
                    "label": 0
                },
                {
                    "sent": "Those blue dots look as though their samples from the distribution we're interested in.",
                    "label": 0
                },
                {
                    "sent": "So what we're interested in doing is constructing Markov chains, finding transition operators or distributions T that if we were to simulate these Markov chains have this property and will draw samples for us.",
                    "label": 0
                },
                {
                    "sent": "Yeah, these samples are correlated.",
                    "label": 0
                },
                {
                    "sent": "Yes, there so more samples.",
                    "label": 0
                },
                {
                    "sent": "And hit what's there.",
                    "label": 0
                },
                {
                    "sent": "The question is, the samples are correlated and so in some ways they're not fair.",
                    "label": 0
                },
                {
                    "sent": "Or you know, there's maybe not as good in some senses independently drawn samples.",
                    "label": 0
                },
                {
                    "sent": "That rejection sampling gave us and, and that's all certainly true.",
                    "label": 0
                },
                {
                    "sent": "It turns out that if you put these correlated samples into the simple Monte Carlo estimator, then ignoring this issue with burn and maybe we'll get onto this later, it's still an unbiased estimator, so you don't need independent samples to construct it estimates of expectations, but certainly you shouldn't treat them as if they are independent.",
                    "label": 0
                },
                {
                    "sent": "So if you're doing something that requires independent samples, then this isn't good enough.",
                    "label": 0
                },
                {
                    "sent": "And there are methods of using Markov chains to then produce independent samples, which roughly tell you how long you have to walk forward before you can draw another sample.",
                    "label": 0
                },
                {
                    "sent": "But I don't know if I'll get onto them.",
                    "label": 0
                },
                {
                    "sent": "Would not decrease as fast as it there, right?",
                    "label": 0
                },
                {
                    "sent": "So I said that you can use them in the estimator and that's all.",
                    "label": 0
                },
                {
                    "sent": "I'm biased, but it's been pointed out the variance is not going to be as good so.",
                    "label": 0
                },
                {
                    "sent": "Here's a process for me giving you.",
                    "label": 0
                },
                {
                    "sent": "Correlated or dependent samples.",
                    "label": 0
                },
                {
                    "sent": "I draw a sample using rejection sampling.",
                    "label": 0
                },
                {
                    "sent": "I then copy it and give it to you again.",
                    "label": 0
                },
                {
                    "sent": "I then draw another sample from rejection sampling and then copy it and give it to you again.",
                    "label": 0
                },
                {
                    "sent": "So I give you a series of samples where every other sample is the same as the previous one.",
                    "label": 0
                },
                {
                    "sent": "Now, marginally, all of those samples that come from the correct distribution, and you can tell if I throw those into the Monte Carlo estimator, then the mean is going to be exactly the same right?",
                    "label": 0
                },
                {
                    "sent": "And get the same answer.",
                    "label": 0
                },
                {
                    "sent": "But if I assume that I had twice as many samples as I really had to construct error bars, then I'll be really overconfident, so we can't construct error bars in the way that you would for simple multi color.",
                    "label": 0
                },
                {
                    "sent": "We're going to have to estimate how many effective samples we have.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "I've got a really simple example, just to show you what.",
                    "label": 0
                },
                {
                    "sent": "The Markov chain dynamics actually mean just say that we know the meaning T so.",
                    "label": 0
                },
                {
                    "sent": "Ah, stationary distribution is going to be a discrete distribution that has three possible states 1, two and three, and they have probability 3, fifth one, 5th and 1/5.",
                    "label": 0
                },
                {
                    "sent": "This is the distribution I want to sample from.",
                    "label": 0
                },
                {
                    "sent": "Here is a transition matrix.",
                    "label": 0
                },
                {
                    "sent": "Which will allow me to sample from this distribution, so the meaning of this is that if I'm in State 2, which is this state with probability half I'll go to the more probable state.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to stay where I am, so if I don't do that, I'm going to go to the other state and state one which is the most probable state.",
                    "label": 0
                },
                {
                    "sent": "Sometimes just stays where it is, and sometimes it wanders off to the other states.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The reason that I can use this transition operator for this stationary distribution is that.",
                    "label": 0
                },
                {
                    "sent": "In Jagan P. Star is an invariant distribution of T, which means that if I multiply this vector by this matrix, I get the same vector back again.",
                    "label": 1
                },
                {
                    "sent": "So the distribution I'm interested in is an eigenvector of this matrix with eigenvalue one.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Say.",
                    "label": 0
                },
                {
                    "sent": "If I were to start in some arbitrary state and workout the probability of where I would be after 100 steps, then I can do that by multiplying by.",
                    "label": 1
                },
                {
                    "sent": "The Matrix 100 times and to machine precision you get out the distribution over where you end up.",
                    "label": 0
                },
                {
                    "sent": "Is this so?",
                    "label": 0
                },
                {
                    "sent": "If you apply a transition operator or matrix many, many times to a vector, then the distribution over what you end up with is it.",
                    "label": 0
                },
                {
                    "sent": "Let's plug in vector.",
                    "label": 0
                },
                {
                    "sent": "Now we're not actually going to want to construct these big matrices, because we're going to have a very large state space and the problems were interested in.",
                    "label": 0
                },
                {
                    "sent": "And if it's intractable to deal with something order N, which is the size of our state space and we're not going to want to construct an order and squared transition matrix, so we tend to have just some compact way of writing down what are transition rule is, so we tend to write instead of matrix equations like.",
                    "label": 0
                },
                {
                    "sent": "This will tend to say that what we want is that if we draw a sample from our distribution.",
                    "label": 0
                },
                {
                    "sent": "Averaged over that.",
                    "label": 0
                },
                {
                    "sent": "If we then took one step without transition operator, the distribution over where we'd end up is the same.",
                    "label": 0
                },
                {
                    "sent": "So you can imagine if somehow this algorithm manages to be sampling from the correct distribution.",
                    "label": 0
                },
                {
                    "sent": "Then if we take another step, the distribution over where it will be after that step is also the correct distribution.",
                    "label": 0
                },
                {
                    "sent": "So this is a basic consistency condition that this random walk is going to have to satisfy.",
                    "label": 0
                },
                {
                    "sent": "This condition by itself isn't actually enough, so.",
                    "label": 0
                },
                {
                    "sent": "Imagine that your transition matrix is the identity matrix or the operator is wherever you are, stay there.",
                    "label": 0
                },
                {
                    "sent": "And don't move then.",
                    "label": 0
                },
                {
                    "sent": "That's a bit like the draw sample and copy operator that I told you before.",
                    "label": 0
                },
                {
                    "sent": "If you only ever applied the copy operator then you would never move anywhere in your space and you never did any samples, but it would satisfy this condition.",
                    "label": 0
                },
                {
                    "sent": "'cause if you draw a sample and you stay put, then you where you end up is the right distribution.",
                    "label": 0
                },
                {
                    "sent": "So we need another condition on top of this which basically just says it is possible to move around the whole state space you are going to sometimes move to every place and as long as you impose that then these two conditions together.",
                    "label": 0
                },
                {
                    "sent": "Give you something that satisfies the properties that I asked for in this picture.",
                    "label": 0
                },
                {
                    "sent": "OK, so during the break is pointed out to me that just as I was rushing towards a breaker this some of this isn't so clear so.",
                    "label": 0
                },
                {
                    "sent": "There's a difference between what I wrote down here and what an actual sampler actually does when you're implementing it.",
                    "label": 0
                },
                {
                    "sent": "So if you're running the code of one of these samplers, you actually simulating a Markov chain, so you start at a particular place in your state space, and at every state of the algorithm you're just considering where you are now to draw a distribution of where you're going next, and you'll go to one particular place, and So what it looks like is, as I drew a sort of a path that runs through your state space.",
                    "label": 1
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "What this is computing is the probability distribution.",
                    "label": 0
                },
                {
                    "sent": "Over way would end up after 100 points.",
                    "label": 0
                },
                {
                    "sent": "So if I start in one of the states with probability one, that means that I will definitely be in that one state.",
                    "label": 0
                },
                {
                    "sent": "Then if I multiply by T, that gives me the distribution over the next step.",
                    "label": 0
                },
                {
                    "sent": "If I * 200 times that gives me the probability distribution over where I'll be in 100 steps.",
                    "label": 0
                },
                {
                    "sent": "So if I were to run this algorithm many, many times, I would end up in a particular place each time and then.",
                    "label": 0
                },
                {
                    "sent": "If I were to look at the frequency of how often I was in state one over those many ensembles, that would be 3/5 and so on.",
                    "label": 0
                },
                {
                    "sent": "OK, so importantly, when you're running this algorithm, you don't actually have to visit every point in the state space.",
                    "label": 0
                },
                {
                    "sent": "Remember the idea of sampling is that we're just going to get a few places in the state space, and that's going to give us an idea of what's going on in our problem.",
                    "label": 0
                },
                {
                    "sent": "So if our algorithm had to visit every point in the state space, it will be useless algorithm because we may as well just enumerate them all at the beginning.",
                    "label": 0
                },
                {
                    "sent": "So what we want is that.",
                    "label": 0
                },
                {
                    "sent": "The probability over where the algorithm ends up.",
                    "label": 0
                },
                {
                    "sent": "It could potentially see every point in your state space, and that's sort of what means that it's valid because we're able to sample from a distribution that.",
                    "label": 0
                },
                {
                    "sent": "That's fair, that could sample from anywhere.",
                    "label": 0
                },
                {
                    "sent": "We're not actually going to do that, and so we shouldn't be when we're analyzing, the algorithms are looking at whether they're going to work.",
                    "label": 0
                },
                {
                    "sent": "We shouldn't actually be saying, Oh well, is it able to sort of recover these frequencies that visit every point in our state space with the right frequency?",
                    "label": 0
                },
                {
                    "sent": "Because most states is never going to visit the number of times it goes there in a run of your algorithm will be 0.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "How do we actually do this?",
                    "label": 0
                },
                {
                    "sent": "I said that we want a transition operator that satisfies these two rules and for this problem with three states, I wrote down a matrix that happens to satisfy this.",
                    "label": 0
                },
                {
                    "sent": "This rule, I mean, you might ask where I plug that matrix from, but I said we can't write down a quadratically size matrix.",
                    "label": 0
                },
                {
                    "sent": "So how can we come up with a transition rule that will satisfy these properties without having to do some computations which was hard as the ones that we're trying to avoid?",
                    "label": 0
                },
                {
                    "sent": "It's a bit like the opposite to the problem that you are usually given in mathematics classes, so.",
                    "label": 0
                },
                {
                    "sent": "Mathematics classes they will give you an operator, and they'll sell derive the eigen values or I can functions or eigenvectors of this operator.",
                    "label": 0
                },
                {
                    "sent": "Here we know what we know, what the eigenvector we wanted and now we have to construct an operator that has that eigenvector and we have a lot of choice and how we could do that.",
                    "label": 0
                },
                {
                    "sent": "We don't need to be able to do it since I'm trying to.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There's a principle which a lot of people use, and this is usually in the introduction to books on MCMC that allows us to construct transition operators that have the correct stationary distribution, and that's called detailed balance is actually very simple principle.",
                    "label": 1
                },
                {
                    "sent": "Imagine that you've got some walk through your state space.",
                    "label": 0
                },
                {
                    "sent": "This is the trajectory of the algorithm and you just look at two adjacent states.",
                    "label": 0
                },
                {
                    "sent": "So at some time it was in State X and the next time it went to state X prime.",
                    "label": 0
                },
                {
                    "sent": "So you've got a pair of two adjacent states.",
                    "label": 0
                },
                {
                    "sent": "The probability of seeing that pair in a very long run of the algorithm is the probability that this would be drawn from the stationary distribution, because this long walk is exploring the stationary distribution.",
                    "label": 0
                },
                {
                    "sent": "Multiplied by the probability that given you're there, you will transition to X prime.",
                    "label": 0
                },
                {
                    "sent": "Say that's what we got on the left hand side.",
                    "label": 0
                },
                {
                    "sent": "Detail balance says that this joint probability of this pair appearing in this order X to X prime should be the same as seeing the pair in the opposite order, so it should be just as plausible that you would see this picture along random walk, which at some point goes to X prime and then transitions to X.",
                    "label": 0
                },
                {
                    "sent": "So that's a way of saying this, sort of this walk process is time reversible.",
                    "label": 0
                },
                {
                    "sent": "It doesn't have a preferred direction, it's just as likely to end up here and go here is the other way around.",
                    "label": 0
                },
                {
                    "sent": "And so the reason that this makes things easier is that we just have to check this condition for every pair of states.",
                    "label": 0
                },
                {
                    "sent": "We don't have to in order to check this condition.",
                    "label": 0
                },
                {
                    "sent": "We don't have to do a big sum over all states or anything like that.",
                    "label": 1
                },
                {
                    "sent": "This condition implies the one we want the stationary distribution condition because we just sum it both sides over X.",
                    "label": 0
                },
                {
                    "sent": "So the left hand side someday, if X is that when we sum this side over X, this here is a probability distribution over X.",
                    "label": 0
                },
                {
                    "sent": "And probability distribution sum to one so that some just disappears and we're left with this.",
                    "label": 0
                },
                {
                    "sent": "And this is the distribution that we wanted the condition that we wanted.",
                    "label": 0
                },
                {
                    "sent": "I'm seeing some notes and some puzzles looks.",
                    "label": 0
                },
                {
                    "sent": "OK, sorry.",
                    "label": 0
                },
                {
                    "sent": "It's a mathematical condition and it happens to satisfy what we want.",
                    "label": 0
                },
                {
                    "sent": "And if you're puzzled for the moment, you can just take the SunTrust.",
                    "label": 0
                },
                {
                    "sent": "What, why?",
                    "label": 0
                },
                {
                    "sent": "There is no problem that like we need to sample from some distribution issues or which doesn't know.",
                    "label": 0
                },
                {
                    "sent": "Or is it some reasonable is optional?",
                    "label": 0
                },
                {
                    "sent": "Open assumption.",
                    "label": 0
                },
                {
                    "sent": "OK, I'm not sure what the question is, will replace it with a different one and it might be the same so.",
                    "label": 0
                },
                {
                    "sent": "This is a necessary condition.",
                    "label": 0
                },
                {
                    "sent": "Sorry it's a sufficient condition and that if you have this condition then the thing we want follows.",
                    "label": 0
                },
                {
                    "sent": "It isn't a necessary condition.",
                    "label": 1
                },
                {
                    "sent": "OK, so this doesn't have to be true for this to be true, and that always bothered me.",
                    "label": 0
                },
                {
                    "sent": "So you read these books and they give you this sort of magical rule and they say make your chain satisfy detailed balance and then this will happen.",
                    "label": 0
                },
                {
                    "sent": "This is a sufficient condition but not necessary, and you're like well, what do the other transition operators look like like?",
                    "label": 0
                },
                {
                    "sent": "You know, if you can have transition operators that don't satisfy this, then what do they do?",
                    "label": 0
                },
                {
                    "sent": "And I think it's unsatisfying that most of the books don't tell you what the Nessa.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Condition it so here it is.",
                    "label": 0
                },
                {
                    "sent": "So imagine that festival.",
                    "label": 0
                },
                {
                    "sent": "This is going to be something which is necessary, and then I'll show that that.",
                    "label": 1
                },
                {
                    "sent": "OK, imagine that you've got transition operator, which does satisfy the property.",
                    "label": 0
                },
                {
                    "sent": "We're going to start off with that as a starting point.",
                    "label": 0
                },
                {
                    "sent": "Then for any such transition operator, we can define another transition operator in the following way we say.",
                    "label": 1
                },
                {
                    "sent": "Construct a different transition operator T Tilda, where the if you're in X prime, then the distribution of going to X is proportional to this thing here, so we can always do this.",
                    "label": 0
                },
                {
                    "sent": "We can say we need to define the probability distribution, so we're just going to assert its proportional to some positive function and then will re normalize it to make it a distribution.",
                    "label": 0
                },
                {
                    "sent": "If the state space is discrete and bounded, we can definitely do that.",
                    "label": 0
                },
                {
                    "sent": "You might worry about whether you can normalize it in general.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's what I've done.",
                    "label": 0
                },
                {
                    "sent": "I've just done this general thing.",
                    "label": 0
                },
                {
                    "sent": "We can always do.",
                    "label": 0
                },
                {
                    "sent": "I've invented in the probability distribution.",
                    "label": 0
                },
                {
                    "sent": "And then I can say, well, what is the normalizing constant?",
                    "label": 0
                },
                {
                    "sent": "I'll just sum this over all values of X, which is what the distribution is over.",
                    "label": 0
                },
                {
                    "sent": "So here is the normalizing constant.",
                    "label": 0
                },
                {
                    "sent": "OK, this is looking a bit like Bayes rule, so it should be fairly familiar now.",
                    "label": 0
                },
                {
                    "sent": "This thing here is the.",
                    "label": 0
                },
                {
                    "sent": "One side of the stationary condition so becausw T that we started with is a transition operator, then this thing here just returns the probability.",
                    "label": 0
                },
                {
                    "sent": "OK, so now I have to find a new transition operator which is equal to this and it's completely general.",
                    "label": 0
                },
                {
                    "sent": "You can always do this for any transition operator.",
                    "label": 0
                },
                {
                    "sent": "Now if I just multiply both sides by this then I get this condition.",
                    "label": 0
                },
                {
                    "sent": "So this looks just like detailed balance, except there's a~ here.",
                    "label": 0
                },
                {
                    "sent": "Say for any T you're going to have this satisfied with the T~ here.",
                    "label": 0
                },
                {
                    "sent": "Now they wear this thing for reasons.",
                    "label": 0
                },
                {
                    "sent": "That I won't go into now.",
                    "label": 1
                },
                {
                    "sent": "It's called the reverse operator.",
                    "label": 1
                },
                {
                    "sent": "So now if you get this and you some both sides over X then you get the stationary condition returned again.",
                    "label": 0
                },
                {
                    "sent": "So that's exactly the same as the detailed balance proof.",
                    "label": 1
                },
                {
                    "sent": "Tilda disappeared so you don't actually have to work out what it is or or have it in your hand, so for.",
                    "label": 0
                },
                {
                    "sent": "Any T that satisfies stationarity.",
                    "label": 0
                },
                {
                    "sent": "You must necessarily have a condition like this.",
                    "label": 0
                },
                {
                    "sent": "And then similarly, if you can find a T~ that satisfies this everywhere, then you can sum over X an show the T satisfies the stationary condition distribution.",
                    "label": 0
                },
                {
                    "sent": "So this is both necessary and sufficient.",
                    "label": 0
                },
                {
                    "sent": "And it's only a really small tweak on this picture.",
                    "label": 0
                },
                {
                    "sent": "This picture said if you run the chain for a long time and you look at a pair of States and you workout the probability of that pair appearing, then that same pair should appear just as often the other way around.",
                    "label": 0
                },
                {
                    "sent": "The general condition just says.",
                    "label": 0
                },
                {
                    "sent": "If you've got a transition operator and you look at the probability of a pair, then there must exist some other transition operator which could be the same one if you want, but it could be a different one for which the probability of getting the power in the reverse order is always the same for all pairs.",
                    "label": 0
                },
                {
                    "sent": "So if you have something that tends to like to walk in some direction so it's not time reversible, then you just need to identify something that tends to like to walk in the other direction such that it'll matches up to satisfy this condition.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "You don't always use this a lot of times due to balance is actually the most convenient thing, but more and more I'm finding this peaceful identity to use, and I think it should be.",
                    "label": 0
                },
                {
                    "sent": "The textbook should replace their detailed balance section with this.",
                    "label": 0
                },
                {
                    "sent": "I mean just the condition.",
                    "label": 0
                },
                {
                    "sent": "So the question isn't this hard to check.",
                    "label": 0
                },
                {
                    "sent": "'cause I mean, maybe you have to look at every point in the state space to check the condition.",
                    "label": 0
                },
                {
                    "sent": "If you had to explicitly enumerate all States and check each of these separately, then yes it would be hard.",
                    "label": 0
                },
                {
                    "sent": "So the idea is that hopefully will be able to analytically show that this condition holds simultaneously across selects without having to compute them or enumerate them explicitly, so we'll see explicit examples where this is satisfied without having to do any computational link.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so here's the explicit example, so this is more or less the motivating algorithm I showed you where I didn't explain what was going on, I just said we're perturbing our parameters and we're wondering around.",
                    "label": 0
                },
                {
                    "sent": "Metropolis invented the Metropolis algorithm in the 50s and then Hastings, who is a statistician, slightly generalized it in the 70s.",
                    "label": 1
                },
                {
                    "sent": "For a long time, this algorithm is more or less synonymous with Markov chain Monte Carlo, so.",
                    "label": 0
                },
                {
                    "sent": "It makes sense that it's the first algorithm at length and the transition operators defined in the following way.",
                    "label": 0
                },
                {
                    "sent": "Justice with rejection, sampling or important sampling.",
                    "label": 0
                },
                {
                    "sent": "It's really good if we can sample from some convenient distribution, one that we've got a library generator for, say we're going to sample our proposals from a distribution key.",
                    "label": 0
                },
                {
                    "sent": "But unlike rejection sampling or important sampling where Q just drew a new independent sample each time this proposal distribution is going to depend on where we currently are.",
                    "label": 0
                },
                {
                    "sent": "So we're currently attacks and it's going to propose an ex prime.",
                    "label": 0
                },
                {
                    "sent": "So an example of a proposal distribution could be.",
                    "label": 0
                },
                {
                    "sent": "A Gaussian distribution with mean where we currently are and some noise.",
                    "label": 0
                },
                {
                    "sent": "So instead of drawing from some global distribution that's going to fix mean we're going to just add noise around where we are now.",
                    "label": 0
                },
                {
                    "sent": "So that's how we're going to propose the next step, so I might go there.",
                    "label": 0
                },
                {
                    "sent": "But before I do that, I workout an acceptance probability.",
                    "label": 0
                },
                {
                    "sent": "Which is some expression and that gives me a probability where I decide to either move to that place or I stay still.",
                    "label": 0
                },
                {
                    "sent": "So in the parameter inference algorithm.",
                    "label": 0
                },
                {
                    "sent": "This was a bit where if the new state was more probable than it turned out that with probability one I accepted the move and if it was worth this ratio which I haven't unpacked yet, well tell you that sometimes you shouldn't take that move because it goes to a low probability place.",
                    "label": 0
                },
                {
                    "sent": "You should just stay put.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "There are two terms in this ratio which match that intuition that I said that the term on the top says the new state should be probable and the old state should be less probable.",
                    "label": 0
                },
                {
                    "sent": "So if the new state is more probable than that, this ratio will be bigger than one.",
                    "label": 0
                },
                {
                    "sent": "There are also times to do with these proposal probabilities, and this is where this idea of reverse ability in detail balance comes in so.",
                    "label": 0
                },
                {
                    "sent": "This is an algorithm that satisfies detailed balance and so that means that it has to be time reversible.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "If I don't have a nice symmetrical perturbation like this, is a proposal distribution, I can pick any Qi like if I have a proposal distribution that really likes proposing some particular part of my space, then if I'm not in the part that it likes proposing.",
                    "label": 0
                },
                {
                    "sent": "It doesn't look as it's going to be very time reversible because it will propose that I go over there where it links, but if I go there, it's never going to propose the time I should go back to where I am now.",
                    "label": 0
                },
                {
                    "sent": "And so it looks very unlikely that I'm going to time reverse just as easily and satisfy this data balance.",
                    "label": 0
                },
                {
                    "sent": "So this ratio here is constructed to make the detail balance relationship hold it says.",
                    "label": 0
                },
                {
                    "sent": "It's better to take the move if it's easy to go back, and it's worse to take the move if it's easy to.",
                    "label": 0
                },
                {
                    "sent": "It's worth to technically, if it, if the proposal that you're currently considering is a very common proposal and it just turns out that if you substitute.",
                    "label": 1
                },
                {
                    "sent": "The transition operator into the detail balance relationship then.",
                    "label": 0
                },
                {
                    "sent": "It holds and you can just say that analytically.",
                    "label": 1
                },
                {
                    "sent": "So for you later I've put in very small type the proof, but the main thing to know is what this mysterious T actually is.",
                    "label": 0
                },
                {
                    "sent": "So I'll write that big an so in order to substitute it into the relationship to check it, we need to know what this probability distribution is.",
                    "label": 0
                },
                {
                    "sent": "If we're currently at some state, what's the probability distribution over the next state and say under this algorithm it's just?",
                    "label": 0
                },
                {
                    "sent": "Well, first I've got to propose to go there, so that's.",
                    "label": 0
                },
                {
                    "sent": "Key.",
                    "label": 0
                },
                {
                    "sent": "And then I've also got to accept it.",
                    "label": 0
                },
                {
                    "sent": "So I multiplied by the probability of accepting.",
                    "label": 0
                },
                {
                    "sent": "Given that I proposed and that's this min one ratio thing.",
                    "label": 0
                },
                {
                    "sent": "So just a for the acceptance ratio so that this is the definition of T. And if you substitute that into the detail balance relationship, you see that it holds the probability of staying in the same players.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is the probability distribution for X prime not equal to X if it's a continuous state space, then never going to propose to stay exactly where you are.",
                    "label": 0
                },
                {
                    "sent": "You also have to show what's the probability of staying still and it's 1 minus the sum of all of that.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is very easy to show if you substitute this into detail balance relationship, you immediately show that you satisfy.",
                    "label": 0
                },
                {
                    "sent": "Then if your transition is the same place, you suddenly worry because you think to workout the probability of staying where I am.",
                    "label": 0
                },
                {
                    "sent": "I'm going to have to sum over all places I might propose and reject, and that's a big sum.",
                    "label": 0
                },
                {
                    "sent": "But Fortunately any move that says stay still is automatically stationary because of the reasons I said before.",
                    "label": 0
                },
                {
                    "sent": "If you don't move anywhere, you leave whatever distribution you have invariant and so that checks.",
                    "label": 0
                },
                {
                    "sent": "Probably you don't have to do any big sums.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right, say I don't like going through code in lectures, but I put it in the slide so because I like it to be explicit what I'm doing.",
                    "label": 0
                },
                {
                    "sent": "So this is the entire code of the demos which go on the next slide and it's an implementation of the Metropolis Hastings algorithm, so it just says input estate, perturb it using a Gaussian distribution, and you make the decisions about whether to stay or go by evaluating a log probability which doesn't have to be normalized.",
                    "label": 0
                },
                {
                    "sent": "You positive function handle, so it's a general algorithm you can run for any problem where you can part a function handle saying.",
                    "label": 0
                },
                {
                    "sent": "This is my log probability up to a constant.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, say.",
                    "label": 0
                },
                {
                    "sent": "Then I get the code on the previous slide which is MATLAB Octave and I create another function which will.",
                    "label": 0
                },
                {
                    "sent": "Plot the course of running this algorithm to explore Gaussian distribution using different proposal distributions so the game we're going to play is we're going to try and draw correlated samples from zero mean unit.",
                    "label": 0
                },
                {
                    "sent": "Gaussian using this algorithm.",
                    "label": 0
                },
                {
                    "sent": "So obviously we should just draw these samples directly, but if we draw samples from a distribution, we understand them, we can see what the properties of the algorithm and the steps that we're going to propose are around where we are, and we're going to.",
                    "label": 0
                },
                {
                    "sent": "Perturb the position using a Gaussian of different widths, so the parameter here is the width of the Gaussian that we're going to use to make our walk.",
                    "label": 0
                },
                {
                    "sent": "Say find perturb with a Gaussian of width 100.",
                    "label": 0
                },
                {
                    "sent": "Then say I initialize the algorithm at the origin.",
                    "label": 0
                },
                {
                    "sent": "Then typically I'm going to propose moving to sort of plus or minus 100, sort of, which isn't very probable under unit Gaussian.",
                    "label": 0
                },
                {
                    "sent": "So on almost all iterations I'm going to reject them even stay where I am, and then just by chance my perturbation is going to draw a small value, and I'm going to perturb my current position by a small amount, and I will accept the move, and then I will stay where I am for a very long time again.",
                    "label": 0
                },
                {
                    "sent": "So if your proposals are.",
                    "label": 0
                },
                {
                    "sent": "Always proposing that you get very low probable places, then you have very low acceptance and you get acceptance rates or less than a percent.",
                    "label": 0
                },
                {
                    "sent": "And so now we clearly don't have very many effective samples in our estimate.",
                    "label": 0
                },
                {
                    "sent": "Will you know we shouldn't have very good error bars?",
                    "label": 0
                },
                {
                    "sent": "We certainly shouldn't assume we've got 1000 samples.",
                    "label": 0
                },
                {
                    "sent": "OK, if you make.",
                    "label": 0
                },
                {
                    "sent": "The size of the proposal that proposal smaller than you start accepting a lot more and you start really bouncing around the state space.",
                    "label": 0
                },
                {
                    "sent": "So here the width of the proposals is similar to the width of the distribution that we're actually exploring.",
                    "label": 0
                },
                {
                    "sent": "You notice that we don't actually always accept, so the reason that we don't always accept is our proposal distribution isn't the same as the true distribution.",
                    "label": 0
                },
                {
                    "sent": "It's got the same width, but it's centered around where we currently are, which means that sometimes will propose going further out than is reasonable life.",
                    "label": 0
                },
                {
                    "sent": "We are currently in the tail.",
                    "label": 0
                },
                {
                    "sent": "OK, so this looks good.",
                    "label": 0
                },
                {
                    "sent": "We accept more and we reduced the step size so maybe we should reduce the step size again and then we'll accept even more and maybe that will be good.",
                    "label": 0
                },
                {
                    "sent": "So this is what happens if you make very very small perturbations.",
                    "label": 0
                },
                {
                    "sent": "So now as we're moving at any given iteration, we only travel a very small distance from where we were at the previous iteration, and given where we were at the previous iteration was a reasonable place to be, where we will be at the next iteration will be a reasonable place to be, so almost almost accepted.",
                    "label": 0
                },
                {
                    "sent": "In fact, in this round of 1000 iterations only two moves got rejected.",
                    "label": 0
                },
                {
                    "sent": "OK, and this is a very bad thing.",
                    "label": 0
                },
                {
                    "sent": "So in rejection sampling you just want to accept as often as possible.",
                    "label": 0
                },
                {
                    "sent": "Here, the fact that we hardly ever reject is terrible because the rejections are actually the only thing that tell us about the distribution that we're wanting to explore.",
                    "label": 0
                },
                {
                    "sent": "So the algorithm is taking an arbitrary random walk.",
                    "label": 0
                },
                {
                    "sent": "It's proposing by Q, and it has nothing to do with the problem we're interested in.",
                    "label": 0
                },
                {
                    "sent": "And then there's an accept reject stage where it says, do I want this move or do I not?",
                    "label": 0
                },
                {
                    "sent": "And that bit of information that yes, you should take it or not you shouldn't, is the only input to the algorithm about the distribution here.",
                    "label": 0
                },
                {
                    "sent": "Interested in that you get.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "If you always get the almost always get the same answer, you're not being told anything about the distribution you want.",
                    "label": 0
                },
                {
                    "sent": "In fact, this is almost exactly just a Gaussian diffusion.",
                    "label": 0
                },
                {
                    "sent": "Using steps of this size.",
                    "label": 0
                },
                {
                    "sent": "And it's just been kicked twice in 100 of the runs, so this run here hardly has any effective samples.",
                    "label": 0
                },
                {
                    "sent": "It doesn't spend much time, any theory, and if you use a long run using this algorithm in an estimator, that will also have very poor properties, so the optimal acceptance rate isn't 100%, it's for various theoretical reasons.",
                    "label": 0
                },
                {
                    "sent": "It's a bit less than 50% on a lot of problems, and so people often equate values of 45 or 47% or something like that.",
                    "label": 0
                },
                {
                    "sent": "About 1/2 is what you're aiming for, and it's not going to be too critical like this looks fine, even though it's a bit too much.",
                    "label": 0
                },
                {
                    "sent": "Otherwise it'll be less than half.",
                    "label": 0
                },
                {
                    "sent": "Seems reasonable.",
                    "label": 0
                },
                {
                    "sent": "That was sort of maximize the entropy or the amount of information.",
                    "label": 0
                },
                {
                    "sent": "The question is why?",
                    "label": 0
                },
                {
                    "sent": "Why is it less than half and not a half?",
                    "label": 0
                },
                {
                    "sent": "So there's an argument, and David Mackay's book of why it should be half based on information theory grounds, which is sort of the argument over graduating that you know you get this information input about the function of this bit zero or one, and surely the maximum information, is maximum entropy where you zeros and ones are equally probable, and that's the way to extract most information.",
                    "label": 0
                },
                {
                    "sent": "It's a bit more complicated than that, cause the pieces of information you're being given aren't independent because you know that you're going to be close to where you were last time, so that's why that that argument, although very nice, isn't exactly true.",
                    "label": 0
                },
                {
                    "sent": "There's a lot of complicated mathematic statistic processes that drive the lesson, half assuming certain regularity conditions on the distribution and so.",
                    "label": 0
                },
                {
                    "sent": "Ariel like Al Gore Switch CEO, should adapt Sigma during the process or OK.",
                    "label": 0
                },
                {
                    "sent": "So the question is.",
                    "label": 0
                },
                {
                    "sent": "Maybe we should change Sigma, because if we, perhaps, if we're running to signal, it is far too big.",
                    "label": 0
                },
                {
                    "sent": "We notice that we are rejecting all the time and we know that we should take smaller steps and maybe if we were suspiciously accepting all the time we should increase Sigma.",
                    "label": 0
                },
                {
                    "sent": "It's certainly a whole literature on adaptive Monte Carlo algorithms.",
                    "label": 0
                },
                {
                    "sent": "I mean there's this special issue in the general recently on adaptive MCMC.",
                    "label": 0
                },
                {
                    "sent": "You have to be very, very careful about how you do it though, so.",
                    "label": 0
                },
                {
                    "sent": "If you.",
                    "label": 0
                },
                {
                    "sent": "Change Sigma in an arbitrary way as you run the algorithm.",
                    "label": 0
                },
                {
                    "sent": "Then you aren't going to get the correct stationary distribution.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Not sure if I can construct an example of this.",
                    "label": 0
                },
                {
                    "sent": "There might not be one true Sigma.",
                    "label": 0
                },
                {
                    "sent": "It might be that depending on where you are in the state space, sometimes a small step size would be good and sometimes a big step size would be good.",
                    "label": 0
                },
                {
                    "sent": "So if the contours of your distribution look like this and you had a very.",
                    "label": 0
                },
                {
                    "sent": "Large basin and a narrow base, and that you know, maybe you want to take small steps here in large steps over here Now, if you.",
                    "label": 0
                },
                {
                    "sent": "Have a fixed Sigma.",
                    "label": 0
                },
                {
                    "sent": "Then magically the algorithm will spend the right amount of time in this room and the right amount of time in this room.",
                    "label": 0
                },
                {
                    "sent": "If you.",
                    "label": 0
                },
                {
                    "sent": "Wander into here.",
                    "label": 0
                },
                {
                    "sent": "Start rejecting a lot and then reduce your step size.",
                    "label": 0
                },
                {
                    "sent": "Then you'll stay in that room for longer than you would have done otherwise, and so you upset the distribution and you end up staying longer in places where you would have a smaller step size.",
                    "label": 0
                },
                {
                    "sent": "So you can't do it in an arbitrary way, but there are ways of doing it.",
                    "label": 0
                },
                {
                    "sent": "Can you say something about combining different transition operators?",
                    "label": 0
                },
                {
                    "sent": "I don't know if you're going to say that.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so I'll do the slide that is before that and then I'll do that.",
                    "label": 0
                },
                {
                    "sent": "Say.",
                    "label": 0
                },
                {
                    "sent": "The next slide was just I don't want you to get a misconception that perhaps for some Sigma, as in this picture, you can almost draw from the distribution exactly.",
                    "label": 0
                },
                {
                    "sent": "So here if you wait a few iterations, then you're almost drawing independent samples.",
                    "label": 0
                },
                {
                    "sent": "It's mixing very, very quickly through the space, and it looks as though as long as you set Sigma correctly, you'll have something which is close to ideal sampling that isn't actually true because we're not interested in these toy 1D diffusions and real problems are harder.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "It's very common to have correlations amongst the variables.",
                    "label": 0
                },
                {
                    "sent": "If we didn't have them, computations would be so hard.",
                    "label": 0
                },
                {
                    "sent": "And so our distribution might impose constraints on Sigma that Andre satisfactory.",
                    "label": 0
                },
                {
                    "sent": "So if we have a dumb proposal like you is a spherical perturbation around where we are and the contours of the distribution look like this, then.",
                    "label": 0
                },
                {
                    "sent": "You're not going to be able to make steps that are sort of much bigger than the largest than the smallest width of the distribution, or you'll forever be stepping off this manifold of high probability.",
                    "label": 0
                },
                {
                    "sent": "So the shape of the distribution might limit your step size if you only have one of them, and then given that you've clamped to that step size, it might take you a very long time to diffuse up and down the distribution.",
                    "label": 0
                },
                {
                    "sent": "They.",
                    "label": 0
                },
                {
                    "sent": "I think this figures in David's book and maybe Christmas book as well that argue that in this situation, if your step size is Sigma and the length scale that you need to wander along is L, then it's going to take you over Sigma squared iterations to sort of wander up and down.",
                    "label": 0
                },
                {
                    "sent": "This is sort of the properties of a random walk with steps of this size, so it's going to take you many, many iterations to sort of explore the whole space and make it such that the probability distribution over where you end up is potentially anywhere which is the property we want.",
                    "label": 0
                },
                {
                    "sent": "To draw samples.",
                    "label": 0
                },
                {
                    "sent": "I should I should just?",
                    "label": 0
                },
                {
                    "sent": "I'm drawing all of these type pictures.",
                    "label": 0
                },
                {
                    "sent": "I don't want to spend too long on any particular application because there are so many other lectures that are doing specific things.",
                    "label": 0
                },
                {
                    "sent": "But an example of where you might get a distribution that has this shape.",
                    "label": 0
                },
                {
                    "sent": "You're doing any regression.",
                    "label": 0
                },
                {
                    "sent": "You've got a current regression.",
                    "label": 0
                },
                {
                    "sent": "This has an intercept.",
                    "label": 0
                },
                {
                    "sent": "See and it's like N. Then if we move the intercept up independently then the whole curve will fall off the manifold.",
                    "label": 0
                },
                {
                    "sent": "But if we change the slope simultaneously then it might look a lot more reasonable.",
                    "label": 0
                },
                {
                    "sent": "So these two parameters are going to be anti correlated so.",
                    "label": 0
                },
                {
                    "sent": "Almost the simplest model you can write down with two parameters.",
                    "label": 0
                },
                {
                    "sent": "You look at the posterior.",
                    "label": 0
                },
                {
                    "sent": "There's going to be strong in this case anti correlation, but in an ellipse shaped pistori.",
                    "label": 0
                },
                {
                    "sent": "Save.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Combining operators.",
                    "label": 0
                },
                {
                    "sent": "I said that the might not be one.",
                    "label": 1
                },
                {
                    "sent": "Ideal stigmatising might partly depend on where you are and say one thing.",
                    "label": 0
                },
                {
                    "sent": "My question is, well, perhaps sometimes I could use one and sometimes I could use another, so we need some way of.",
                    "label": 0
                },
                {
                    "sent": "Being able to use different transition operators.",
                    "label": 0
                },
                {
                    "sent": "It is actually fine to just invent as many transitions operators as you want, which could be 10 different versions of Metropolis, Hastings or with different step sizes and just apply them in turn.",
                    "label": 0
                },
                {
                    "sent": "And the reason it's OK to apply them in turn is because doing that lease your stationary distribution invariant, which is the property we want so.",
                    "label": 0
                },
                {
                    "sent": "Imagine that your initial condition was drawn from your stationary distribution.",
                    "label": 0
                },
                {
                    "sent": "So you've run the chain for a long time and we've got a sample from your stationary distribution.",
                    "label": 0
                },
                {
                    "sent": "And you apply transition approach to a.",
                    "label": 0
                },
                {
                    "sent": "So you go from this initial condition to X1.",
                    "label": 0
                },
                {
                    "sent": "What's the probability distribution over where you end up?",
                    "label": 0
                },
                {
                    "sent": "While you sum over all of the places, the X, nor could be weighted by the probability and then you look at the distribution given those of where you would go and becausw TA is a valid transition operator that's going to be your stationary distribution.",
                    "label": 1
                },
                {
                    "sent": "OK, now we apply a different transition operator to X1 to go to XT.",
                    "label": 0
                },
                {
                    "sent": "We look at what's the probability distribution everywhere we end up.",
                    "label": 0
                },
                {
                    "sent": "I think you might see where this is going.",
                    "label": 1
                },
                {
                    "sent": "You get you average over all of the places that the previous step could be for which we've already worked out its distribution, and then you see that it's the stationary condition again and say, X2 also has the stationary distribution.",
                    "label": 0
                },
                {
                    "sent": "You apply a bunch of operators that leave the stationary distribution invariant, and you leave the stationary distribution invariant so it doesn't matter that these are different operators.",
                    "label": 0
                },
                {
                    "sent": "And we can just concatenate them altogether.",
                    "label": 0
                },
                {
                    "sent": "Or we could pick them randomly and then our transition operator.",
                    "label": 1
                },
                {
                    "sent": "Would we have?",
                    "label": 0
                },
                {
                    "sent": "K transition operators are effective, transition operator would be 1 / K some over the transition operators would just be the average of them.",
                    "label": 0
                },
                {
                    "sent": "A nice fact about this is that.",
                    "label": 0
                },
                {
                    "sent": "There were two conditions that we had to satisfy.",
                    "label": 0
                },
                {
                    "sent": "One was that we had to have this stationary condition and one was that we had to be able to get anywhere in the state space so that we didn't sort of get stuck somewhere.",
                    "label": 0
                },
                {
                    "sent": "For this concatenation to be OK, we just need the stationary condition and then the concatenated operator of applying A, then B, then C is going to be together a valid operator.",
                    "label": 0
                },
                {
                    "sent": "So what you can have is some operators that only move in some of the space, and some operators which are only able to involve the subspaces and concatenate them together and that result.",
                    "label": 0
                },
                {
                    "sent": "As long as that combined thing can get everywhere, will be a valid operator.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That might be a bit abstract, so an example of that is Gibbs sampling, which I know about more than half of you will or already name.",
                    "label": 0
                },
                {
                    "sent": "So Gibbs sampling is another MCMC algorithm.",
                    "label": 1
                },
                {
                    "sent": "It's a way of defining a transition operator that moves around the space, and it works by getting a multivariate quantity.",
                    "label": 0
                },
                {
                    "sent": "So a vector with two components and successively drawing each dimension from the conditional distribution of that variable.",
                    "label": 0
                },
                {
                    "sent": "Conditioned on all the other variables.",
                    "label": 0
                },
                {
                    "sent": "So if I'm currently at this point here, then one of the move says I'm going to workout the conditional distribution along this slice, where X2 is climate an that conditional distribution will look like this and then I will make a move along here and then once I've done that, I will take a slice in the other direction and workout the conditional distribution in the other direction and so all of the moves only move along the axes.",
                    "label": 0
                },
                {
                    "sent": "Now any of these individual moves.",
                    "label": 1
                },
                {
                    "sent": "If you would supply that lots of times, couldn't get everywhere in this space because it's constrained to lie on this slice, but when you put them together, it's possible now to walk anywhere in the space, and that's why the overall thing is a valid multicolour algorithm.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "OK, why is it good?",
                    "label": 0
                },
                {
                    "sent": "So this is probably the most popular Markov chain Monte Carlo Rhythm.",
                    "label": 0
                },
                {
                    "sent": "For a variety of reasons.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "One of them is that it's sometimes very easy to implement, so there isn't a step science to pick you notice there is.",
                    "label": 0
                },
                {
                    "sent": "There is maybe a free parameter and that you could choose the parameterisation of your problem in the 1st place, but that's complicated most of the time people are going to stick with one parametrization apply, give something so.",
                    "label": 0
                },
                {
                    "sent": "One of the conditional distributions of a variable given all of the others is just proportional to the joint probability.",
                    "label": 0
                },
                {
                    "sent": "So imagine you've got a big graphical model and you're interested in updating one variable.",
                    "label": 0
                },
                {
                    "sent": "For each different setting of that variable, you can evaluate the joint probability of the whole graph as it is with that one variable changed.",
                    "label": 0
                },
                {
                    "sent": "And all of the graphical models that set up to do that.",
                    "label": 0
                },
                {
                    "sent": "They define a joint probability distribution up to a constant technique.",
                    "label": 0
                },
                {
                    "sent": "So this conditional distribution you can write out what it's proportional T, and then if your variables are discrete, you can just explicitly normalize that and you're only summing over all settings of 1 variable.",
                    "label": 0
                },
                {
                    "sent": "So if you had a binary variable, this is the sum over 2 terms, so this distribution isn't hard to compute, and often for a lot of models with continuous variables the conditional distributions are simple things like.",
                    "label": 0
                },
                {
                    "sent": "Gamma, so Gaussians or things that we have some samples for so.",
                    "label": 0
                },
                {
                    "sent": "For a lot of problems, applying Gibbs sampling looks fairly routine.",
                    "label": 0
                },
                {
                    "sent": "You can derive all of the conditional distributions in close form or in a form that there's an algorithm to sample from an.",
                    "label": 0
                },
                {
                    "sent": "Then you just run through each variable, resampling it, and turn.",
                    "label": 0
                },
                {
                    "sent": "An and an example of why how routine it is is that there are very longstanding software packages for Gibbs sampling in graphical models, where you define your graphical model and then it will derive the Gibbs sampler for you, compile it into program and run it.",
                    "label": 0
                },
                {
                    "sent": "It also both of these programs bugs come with diagnostic tools to help you sort of see what's going on as well, so that's one of the reasons it's very popular, but get to it.",
                    "label": 0
                },
                {
                    "sent": "I've been to stats meeting where a good fraction of the posters said blah blah blah blah with winbugs.",
                    "label": 0
                },
                {
                    "sent": "And you'll also sit in talks where they'll say so.",
                    "label": 0
                },
                {
                    "sent": "We define this model and at this stage we could do everything in bugs and then we added this bit and bugs can deal with that.",
                    "label": 0
                },
                {
                    "sent": "And so we had to go and cut up some cells.",
                    "label": 0
                },
                {
                    "sent": "So that's sort of a good fraction.",
                    "label": 0
                },
                {
                    "sent": "Problems could be solved just with Gibbs sampling alone.",
                    "label": 0
                },
                {
                    "sent": "Trouble is, hosting is.",
                    "label": 0
                },
                {
                    "sent": "I just didn't get it.",
                    "label": 0
                },
                {
                    "sent": "So it's it's different all right OK?",
                    "label": 0
                },
                {
                    "sent": "Thanks.",
                    "label": 0
                },
                {
                    "sent": "Metropolis Hastings didn't sample from conditional distributions.",
                    "label": 0
                },
                {
                    "sent": "You saw.",
                    "label": 0
                },
                {
                    "sent": "You move the variable by doing an arbitrary proposal Q and then deciding whether to accept or reject it.",
                    "label": 0
                },
                {
                    "sent": "And it's not one algorithm cause it depends on the choice of key and Q could be something horrendous.",
                    "label": 0
                },
                {
                    "sent": "Lee complicated, it could be.",
                    "label": 0
                },
                {
                    "sent": "Go off and run some big approximate inference scheme to like approximate your whole distribution sample from that approximation and then decide whether together or not or it could be perturbed where you are with the Gaussian.",
                    "label": 0
                },
                {
                    "sent": "So you can't really compare to the metropolis Hastings.",
                    "label": 0
                },
                {
                    "sent": "In some applications people will have a really good idea of how to pick you, and so it will be the best approach because you can't be the domain expert he's come up with really good moves in other applications, not so much.",
                    "label": 0
                },
                {
                    "sent": "One link is that one way that you can show that gives something as valid algorithm is you can say, well, what if I use Metropolis Hastings and proposed moving using this conditional distribution.",
                    "label": 0
                },
                {
                    "sent": "And if you substitute the conditional distributions into the acceptance ratio, Metropolis Hastings and the acceptance probability is 1 always for any move and that means that you don't actually have to check it.",
                    "label": 0
                },
                {
                    "sent": "You don't have to draw a random number to accept or reject them.",
                    "label": 0
                },
                {
                    "sent": "If you know that the move will always be accepted.",
                    "label": 0
                },
                {
                    "sent": "So that is one way that people say that you can see that it's immediately valid.",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "So when you talk about combining operators, you said the combination of operators evaluate the CNC.",
                    "label": 0
                },
                {
                    "sent": "Apparently.",
                    "label": 0
                },
                {
                    "sent": "Yeah, we say for the sample in between.",
                    "label": 0
                },
                {
                    "sent": "Like say you have a sequence of Gibbs sampling and then at the end when you combine that developer.",
                    "label": 0
                },
                {
                    "sent": "But what about the simple in between keep them?",
                    "label": 0
                },
                {
                    "sent": "So the question is that.",
                    "label": 0
                },
                {
                    "sent": "Description of.",
                    "label": 0
                },
                {
                    "sent": "How to concatenate operators?",
                    "label": 0
                },
                {
                    "sent": "I said that.",
                    "label": 0
                },
                {
                    "sent": "You have a few together and that object is a valid transition operator, so you don't need to go away proving this negativity property for each one.",
                    "label": 0
                },
                {
                    "sent": "But the way that we tend to run MCMC is that we will actually look at the intermediate samples after applying each one.",
                    "label": 0
                },
                {
                    "sent": "Is it OK to use things?",
                    "label": 0
                },
                {
                    "sent": "Say.",
                    "label": 0
                },
                {
                    "sent": "We can imagine that we've got a block of transitions that we've applied, and then we had another block transitions and we had another block transitions and we've got saved the states after each individual transition and at the edge of each block.",
                    "label": 0
                },
                {
                    "sent": "And we could wonder that maybe we should only use each of these samples.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "Each of these samples, as long as we run the chain for a long time, it's going to marginally come from the correct distribution, because this whole objectives are Gothic and each operator satisfies the stationary condition, so the given that this was drawn from the correct distribution.",
                    "label": 0
                },
                {
                    "sent": "These ones will also come from the correct stationary distribution.",
                    "label": 0
                },
                {
                    "sent": "It's just that there's no way that you could get from here to anywhere else in the state space, but marginally this will still have to create distribution.",
                    "label": 0
                },
                {
                    "sent": "I don't need to 'cause it's tacked onto a whole thing which is there godik.",
                    "label": 0
                },
                {
                    "sent": "So it is true that you can use all intermediate things as long as.",
                    "label": 0
                },
                {
                    "sent": "Stuff that came before allowed you to say that this marginally came from the correct distribution.",
                    "label": 0
                },
                {
                    "sent": "Think that's right, I've never been asked that before.",
                    "label": 0
                },
                {
                    "sent": "OK. Say oh, time.",
                    "label": 0
                },
                {
                    "sent": "And let's see if I should say anything closing.",
                    "label": 0
                },
                {
                    "sent": "That is for both lectures.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so given you well, winter just through straight Monte Carlo, why we want to be sampling at all in the way that the standard samples that we have in Matlab and other packages work?",
                    "label": 0
                },
                {
                    "sent": "And hopefully the motivation of why they're not good enough for problems that a lot of us will be wanting.",
                    "label": 0
                },
                {
                    "sent": "We're interested in high dimensional problems that don't have a lot of tractability about them, so these MCMC algorithms they tend to make local moves that's not always true.",
                    "label": 1
                },
                {
                    "sent": "They can sometimes make big moves, but if you have algorithms that.",
                    "label": 0
                },
                {
                    "sent": "Always try to make big moves.",
                    "label": 0
                },
                {
                    "sent": "They tend to suffer from the failures.",
                    "label": 0
                },
                {
                    "sent": "The rejection sampling had.",
                    "label": 0
                },
                {
                    "sent": "Luckily, we can concatenate operators so we can make big moves and little meats and make sure that we get everywhere an an as with Gibbs sampling.",
                    "label": 0
                },
                {
                    "sent": "All this dumb Metropolis algorithm for which I gave you the whole code.",
                    "label": 1
                },
                {
                    "sent": "They're very easy to implement.",
                    "label": 0
                },
                {
                    "sent": "The harder to diagnose, and I'll talk about that more in the second lecture, but in principle you can go away and cut them up and run them immediately.",
                    "label": 0
                },
                {
                    "sent": "Probably the easiest approximate inference algorithms to implement maybe not the easiest to run, so I'll be around for the whole 2 weeks saying.",
                    "label": 0
                },
                {
                    "sent": "Those of you already know a lot about him, so you can come and talk with me.",
                    "label": 0
                },
                {
                    "sent": "I'd love to talk with you about your problems and those who haven't seen this before.",
                    "label": 0
                },
                {
                    "sent": "Also, any questions anytime.",
                    "label": 0
                },
                {
                    "sent": "Thanks very much.",
                    "label": 0
                }
            ]
        }
    }
}