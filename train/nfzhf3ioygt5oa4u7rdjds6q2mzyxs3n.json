{
    "id": "nfzhf3ioygt5oa4u7rdjds6q2mzyxs3n",
    "title": "Focal flow: Measuring depth and velocity from defocus and differential motion",
    "info": {
        "author": [
            "Emma Alexander, Harvard School of Engineering and Applied Sciences, Harvard University"
        ],
        "published": "Oct. 24, 2016",
        "recorded": "October 2016",
        "category": [
            "Top->Computer Science->Computer Vision"
        ]
    },
    "url": "http://videolectures.net/eccv2016_alexander_focal_flow/",
    "segmentation": [
        [
            "As a community, we have done very well."
        ],
        [
            "At designing low level vision systems that can accurately infer low level seen properties like depth and 3D scene velocity, this is particularly true for large scale systems which are optimized for accuracy on big datasets and we're not strongly concerned about power consumption at runtime."
        ],
        [
            "We're even doing well in forming, inferring depth, geometry and velocity on embedded platforms like these, where peak power consumption is on the order of Watts."
        ],
        [
            "But on the horizon there's a new generation of microscale platforms like Swarm, robots, microwaves, and self sustaining sensor platforms.",
            "The power budgets of these devices are hundreds to millions of times smaller than the embedded systems measured in milliwatts, and even fractions of microwatts.",
            "It's not clear what visual sensing can accomplish at these scales."
        ],
        [
            "So today I'm going to show you focal flow and you potentially highly efficient way to measure depth and velocity from a combination of optical defocus and differential motion.",
            "We consider a simple camera."
        ],
        [
            "It collects images of a moving scene and from this video."
        ],
        [
            "We will take useful scene measurements using very few adds and multiplies."
        ],
        [
            "Additionally, the camera is entirely passive with fixed and calibrated parameters.",
            "I'm going to show you that we can take advantage of the motion of these platforms and the scenes they observe."
        ],
        [
            "And that was just a thin lens and attenuating filter at the aperture there exists."
        ],
        [
            "Unique linear constraint on scene depth in 3D velocity so that a four by four linear system can be solved at each image.",
            "Patch for depth and velocity at the back projection of the patches center."
        ],
        [
            "Most of this talk will be used to introduce this linear constraint."
        ],
        [
            "At a given pixel, we only compute a few image derivatives.",
            "The first derivatives in horizontal and vertical directions, a sum."
        ],
        [
            "Of these, weighted by their pixel location on the image plane for the directional derivative in the radial direction."
        ],
        [
            "A rotationally symmetric 2nd order derivative the image Laplacian."
        ],
        [
            "And the partial derivative in time, these simple."
        ],
        [
            "Measurements computed at a single pixel constrain a vector.",
            "That is why."
        ],
        [
            "Into one with the depth and 3D scene velocity at the back projection of that pixel I will show."
        ],
        [
            "So that this constraint is valid regardless of the texture in the scene.",
            "Not only that, but that under radially symmetric optics."
        ],
        [
            "Is the only such constraint, and it holds exactly when the blue."
        ],
        [
            "Kernels of the camera are Gaussian.",
            "I will do."
        ],
        [
            "Show some preliminary experimental results demonstrating the effectiveness of this Q in practice."
        ],
        [
            "To begin, we review differential optical flow.",
            "Imagine a pinhole camera observing a textured plane."
        ],
        [
            "Collects an image P which is a stretched version of this text."
        ],
        [
            "If the plane approaches the pinhole camera, we observe image expansion as a result."
        ],
        [
            "And under arbitrary scene velocity images show a combination of scaling and shifting overtime."
        ],
        [
            "Each image point corresponds to an unchanging texture point, so that matching image points will have the same brightness."
        ],
        [
            "When the frame rate of the camera is high enough, that scene motion is subpixel.",
            "This observation gives a familiar constraint.",
            "It says that the."
        ],
        [
            "Change in pixel bright."
        ],
        [
            "This PT overtime can be expressed as a weighted sum of the 1st."
        ],
        [
            "Primitives in image coordinates X&Y.",
            "If we consider this to hold at every pixel in a Patch, we can create a matrix of the derivative values at each of these pixels and solve."
        ],
        [
            "Two by two linear system for the on image motion at the back door."
        ],
        [
            "Action of that Patch considering such patches over the image, we build up the optical flow fields.",
            "Now."
        ],
        [
            "Now we consider what happens when you open up that aperture and place a thin lens an an attenuating filter, where the pinhole used to be."
        ],
        [
            "This filter could be a pill box."
        ],
        [
            "A binary code Oracle."
        ],
        [
            "This function we restrict our analysis to the radially symmetric case, but other than that it can be just about anything."
        ],
        [
            "Now consider the same."
        ],
        [
            "Team that we saw before.",
            "Now image through a pill pill box aperture in addition to the scaling and stretching we have a change in contrast as the object comes into and out of focus.",
            "This turns out to be a very valuable additional piece of information about the scene, but it requires a specific combination of optical in computational manipulation to access it directly.",
            "We begin with the simple observation that the brightness of a fixed point on the object.",
            "Is no longer constant."
        ],
        [
            "Across our images."
        ],
        [
            "This is true even under differential motion, which means."
        ],
        [
            "But if we compute this same derivatives as before, so derivatives and image brightness with respect to time T and pixel location X&Y are familiar constraint on optical flow does not hold instead."
        ],
        [
            "This weighted sum of image derivatives will leave some residual brightness change R at every pixel, which is just the amount of brightness change due to defocus after on image motion has been accounted for with our."
        ],
        [
            "Thin lens model.",
            "We can write the exact form of this residual brightness change and render it as this other image shown here.",
            "We find that it is scaled overall by the approach."
        ],
        [
            "Velocity of the object and its depth, both of which we would like to measure."
        ],
        [
            "It also depends on an expression involving the blur kernel K, which will be a depth scaled version of the aperture filter Kappa."
        ],
        [
            "Unfortunately, this expression is convolved with the pinhole image P, which as we saw is a scaled in translation version of the scene texture."
        ],
        [
            "Now this is really the heart of the problem.",
            "We only collect a blurred image, so this."
        ],
        [
            "Underlying sharp texture is something that we don't have access to.",
            "In general, the own."
        ],
        [
            "Any way to turn this residual brightness change from a source of error into his signal is either to do some kind of expensive inference on the underlying scene which our microscope sensors probably can't do, or to find a way to measure it directly from the image."
        ],
        [
            "So this becomes our goal.",
            "We seek an image operator M and an aperture filter Kappa so that the residual R that is the brightness change due to defocus after on image motion has been accounted for.",
            "Him is proportional to the convolution of our operator with the blurred image for any underlying scene."
        ],
        [
            "We prove in the paper that this is possible when and only when the aperture filter is Gaussian and the image operator is the Laplacian."
        ],
        [
            "We do this by specifying the form of each term."
        ],
        [
            "Texture independence comes from dropping this pinhole image."
        ],
        [
            "This condition in the frequency domain whoops, sorry.",
            "The important part about this derivative before I move on."
        ],
        [
            "So our condition is when we apply our operator to the blur kernel, we want something proportional to twice the original blur kernel plus it's radial derivative.",
            "And this derivative is not just going to be a traditional functional derivative, right?",
            "Because we want to consider things like pin holes and pillboxes and binary codes which are not differentiable and so we have to use the different distribution ull derivative instead.",
            "This includes regular functions but also more exotic things like the direct Delta.",
            "So that's how we get the generality of our proof.",
            "Is by treating this as a distributional derivative rather than a functional one."
        ],
        [
            "This condition on the blur kernel derivative in the frequency domain gives us a differential equation which we solve for a large class of solutions.",
            "We restrict these solutions to those with non negative filter transmittance using a combination of Bochner's theorem and the Fourier slice theorem, and we also restrict our image operator to apply to a sub infinite number of pixels under these requirements."
        ],
        [
            "A unique and familiar class of solutions remains."
        ],
        [
            "From here, the focal flow constraint is all but all but derive."
        ],
        [
            "We assume Gaussian blur.",
            "And we note."
        ],
        [
            "After accounting for on image motion, some quantity remains which is proportional to the image Laplacian."
        ],
        [
            "We then split the spatial derivative terms into translation, an expansion components by in."
        ],
        [
            "Cluding their location weighted sum, moving the Laplacian to the other side of the equation."
        ],
        [
            "Gives our constraint in its final form."
        ],
        [
            "So this is what our theorem means.",
            "We can create an extremely efficient Patch wise measurement algorithm by simply computing image derivatives as before."
        ],
        [
            "Now augmented with second spatial derivatives."
        ],
        [
            "Within each Patch we accumulate the derivatives into a matrix equation.",
            "The least squares."
        ],
        [
            "Solution to this equation gives a four vector and this."
        ],
        [
            "Is equivalent to knowing the depth and velocity at the back projection of the Patch.",
            "We consider this over the entire image and build up the depth and velocity Maps.",
            "And that's it.",
            "OK, after this, we're done.",
            "There's no iteration, there's no intermediate inference about displacements or blur kernels or texture features.",
            "There's no network, there's no data.",
            "OK, this is a simple feedforward computation derived from first principles that uses very few multiplies and adds.",
            "We were looking for a very cheap way to measure depth and velocity from images, and that's exactly what this is."
        ],
        [
            "So I've shown you are per pixel constraint on image derivatives and seen quantities.",
            "I've told you that it's valid for any scene texture that it's the only linear constraint with this in variance and that it requires the blur kernels of the camera to be Gaussian."
        ],
        [
            "Now we turn to experimental results to answer the question does."
        ],
        [
            "This algorithm work in practice from our uniqueness proof, we know that our constraint holds exactly only when a perfect Gaussian filter with a perfect then lens creates perfect Gaussian blur kernels."
        ],
        [
            "Real cameras rely on thick lenses and the result."
        ],
        [
            "Your kernels look more like this.",
            "Through Gaussian filter."
        ],
        [
            "Or like this through a pillbox aperture.",
            "In both cases, there are obvious deviations from the ideal Gaussian blur.",
            "Now we can still apply, or."
        ],
        [
            "Algorithm by solving the same linear system from the same simple image measurements.",
            "But our constraint is now only approximately true.",
            "Instead of refining our active optics, we ask will it work anyway?"
        ],
        [
            "Happily, we find."
        ],
        [
            "A prototype camera equipped with a thick lens and a Gaussian filter.",
            "Can or in fact a pill box aperture both will work, is able to perform the measurements we described we created."
        ],
        [
            "The small multi plane scene which was imaged at precise depth intervals as it came into an went out of focus show."
        ],
        [
            "Here is a triplet of images over which we collected."
        ],
        [
            "Primitives in two per Patch matrices centered at each pixel."
        ],
        [
            "And solve for the depth and velocity at the back projection of each of these patches.",
            "And from this SIM."
        ],
        [
            "Measurement algorithm we recovered the shape, location and speed of the object accurately.",
            "We also showed."
        ],
        [
            "Simple slanted plane from which."
        ],
        [
            "We collected these images considered."
        ],
        [
            "These larger patches."
        ],
        [
            "Again, collecting depth estimates."
        ],
        [
            "Consistent with ground truth.",
            "I."
        ],
        [
            "Need to speak briefly on the working range of this sensor.",
            "Fundamentally the focal focal floqi relies on small changes in brightness."
        ],
        [
            "Both between adjacent pixels and within a single pixel.",
            "Overtime when an object is very out of focus, its images get blurred out and these changes become very small.",
            "So here's the kind of performance you can expect."
        ],
        [
            "Near the cameras in focus depth shown with the dotted line, we recover high accuracy measurements on the ground truth slanted line."
        ],
        [
            "If you go too far in either direction, the accuracy of this measurement decreases rapidly this."
        ],
        [
            "Trend continues."
        ],
        [
            "We focus further out with a larger working range, corresponding to higher variance measurements within the working range, so we trade off precision and range when we design the optics of the system."
        ],
        [
            "This trend also holds from velocity measurements shown here with ground truth on the horizontal line.",
            "We provide a theoretical analysis of the Q sensitivity in the paper and several systematic experiments in the Associated Technical report."
        ],
        [
            "In addition to the trade off in the optics, we identify another in sensor resolution over space.",
            "Time and brightness, strengthen one of these areas can theoretically mitigate weakness in another.",
            "However, we have not yet developed multiscale methods for this cues, so the resolutions that you pick will affect the scenes that are well measured.",
            "As it stands, arm."
        ],
        [
            "German performance suffers under sensor noise and just like stereo optical flow or depth from defocus, the focal flow cube breaks down locali in regions that lack texture have high slanter curvature or are at discontinuity's and seen shape and while."
        ],
        [
            "We focused on efficiency.",
            "There are many possible tradeoffs to be made between performance and computational cost, which we have not yet begun to characterize, so there's clearly a lot of work to be done here, and we hope that you'll join us in exploring and experimenting with this new queue.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As a community, we have done very well.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At designing low level vision systems that can accurately infer low level seen properties like depth and 3D scene velocity, this is particularly true for large scale systems which are optimized for accuracy on big datasets and we're not strongly concerned about power consumption at runtime.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We're even doing well in forming, inferring depth, geometry and velocity on embedded platforms like these, where peak power consumption is on the order of Watts.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But on the horizon there's a new generation of microscale platforms like Swarm, robots, microwaves, and self sustaining sensor platforms.",
                    "label": 0
                },
                {
                    "sent": "The power budgets of these devices are hundreds to millions of times smaller than the embedded systems measured in milliwatts, and even fractions of microwatts.",
                    "label": 0
                },
                {
                    "sent": "It's not clear what visual sensing can accomplish at these scales.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So today I'm going to show you focal flow and you potentially highly efficient way to measure depth and velocity from a combination of optical defocus and differential motion.",
                    "label": 0
                },
                {
                    "sent": "We consider a simple camera.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It collects images of a moving scene and from this video.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We will take useful scene measurements using very few adds and multiplies.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Additionally, the camera is entirely passive with fixed and calibrated parameters.",
                    "label": 0
                },
                {
                    "sent": "I'm going to show you that we can take advantage of the motion of these platforms and the scenes they observe.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And that was just a thin lens and attenuating filter at the aperture there exists.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Unique linear constraint on scene depth in 3D velocity so that a four by four linear system can be solved at each image.",
                    "label": 0
                },
                {
                    "sent": "Patch for depth and velocity at the back projection of the patches center.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Most of this talk will be used to introduce this linear constraint.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At a given pixel, we only compute a few image derivatives.",
                    "label": 0
                },
                {
                    "sent": "The first derivatives in horizontal and vertical directions, a sum.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of these, weighted by their pixel location on the image plane for the directional derivative in the radial direction.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A rotationally symmetric 2nd order derivative the image Laplacian.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the partial derivative in time, these simple.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Measurements computed at a single pixel constrain a vector.",
                    "label": 0
                },
                {
                    "sent": "That is why.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Into one with the depth and 3D scene velocity at the back projection of that pixel I will show.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that this constraint is valid regardless of the texture in the scene.",
                    "label": 0
                },
                {
                    "sent": "Not only that, but that under radially symmetric optics.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is the only such constraint, and it holds exactly when the blue.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Kernels of the camera are Gaussian.",
                    "label": 0
                },
                {
                    "sent": "I will do.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Show some preliminary experimental results demonstrating the effectiveness of this Q in practice.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To begin, we review differential optical flow.",
                    "label": 0
                },
                {
                    "sent": "Imagine a pinhole camera observing a textured plane.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Collects an image P which is a stretched version of this text.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If the plane approaches the pinhole camera, we observe image expansion as a result.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And under arbitrary scene velocity images show a combination of scaling and shifting overtime.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Each image point corresponds to an unchanging texture point, so that matching image points will have the same brightness.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "When the frame rate of the camera is high enough, that scene motion is subpixel.",
                    "label": 0
                },
                {
                    "sent": "This observation gives a familiar constraint.",
                    "label": 0
                },
                {
                    "sent": "It says that the.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Change in pixel bright.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This PT overtime can be expressed as a weighted sum of the 1st.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Primitives in image coordinates X&Y.",
                    "label": 0
                },
                {
                    "sent": "If we consider this to hold at every pixel in a Patch, we can create a matrix of the derivative values at each of these pixels and solve.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Two by two linear system for the on image motion at the back door.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Action of that Patch considering such patches over the image, we build up the optical flow fields.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now we consider what happens when you open up that aperture and place a thin lens an an attenuating filter, where the pinhole used to be.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This filter could be a pill box.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A binary code Oracle.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This function we restrict our analysis to the radially symmetric case, but other than that it can be just about anything.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now consider the same.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Team that we saw before.",
                    "label": 0
                },
                {
                    "sent": "Now image through a pill pill box aperture in addition to the scaling and stretching we have a change in contrast as the object comes into and out of focus.",
                    "label": 0
                },
                {
                    "sent": "This turns out to be a very valuable additional piece of information about the scene, but it requires a specific combination of optical in computational manipulation to access it directly.",
                    "label": 0
                },
                {
                    "sent": "We begin with the simple observation that the brightness of a fixed point on the object.",
                    "label": 0
                },
                {
                    "sent": "Is no longer constant.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Across our images.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is true even under differential motion, which means.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But if we compute this same derivatives as before, so derivatives and image brightness with respect to time T and pixel location X&Y are familiar constraint on optical flow does not hold instead.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This weighted sum of image derivatives will leave some residual brightness change R at every pixel, which is just the amount of brightness change due to defocus after on image motion has been accounted for with our.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thin lens model.",
                    "label": 0
                },
                {
                    "sent": "We can write the exact form of this residual brightness change and render it as this other image shown here.",
                    "label": 0
                },
                {
                    "sent": "We find that it is scaled overall by the approach.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Velocity of the object and its depth, both of which we would like to measure.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It also depends on an expression involving the blur kernel K, which will be a depth scaled version of the aperture filter Kappa.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Unfortunately, this expression is convolved with the pinhole image P, which as we saw is a scaled in translation version of the scene texture.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now this is really the heart of the problem.",
                    "label": 0
                },
                {
                    "sent": "We only collect a blurred image, so this.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Underlying sharp texture is something that we don't have access to.",
                    "label": 0
                },
                {
                    "sent": "In general, the own.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Any way to turn this residual brightness change from a source of error into his signal is either to do some kind of expensive inference on the underlying scene which our microscope sensors probably can't do, or to find a way to measure it directly from the image.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this becomes our goal.",
                    "label": 0
                },
                {
                    "sent": "We seek an image operator M and an aperture filter Kappa so that the residual R that is the brightness change due to defocus after on image motion has been accounted for.",
                    "label": 0
                },
                {
                    "sent": "Him is proportional to the convolution of our operator with the blurred image for any underlying scene.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We prove in the paper that this is possible when and only when the aperture filter is Gaussian and the image operator is the Laplacian.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We do this by specifying the form of each term.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Texture independence comes from dropping this pinhole image.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This condition in the frequency domain whoops, sorry.",
                    "label": 0
                },
                {
                    "sent": "The important part about this derivative before I move on.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So our condition is when we apply our operator to the blur kernel, we want something proportional to twice the original blur kernel plus it's radial derivative.",
                    "label": 0
                },
                {
                    "sent": "And this derivative is not just going to be a traditional functional derivative, right?",
                    "label": 0
                },
                {
                    "sent": "Because we want to consider things like pin holes and pillboxes and binary codes which are not differentiable and so we have to use the different distribution ull derivative instead.",
                    "label": 0
                },
                {
                    "sent": "This includes regular functions but also more exotic things like the direct Delta.",
                    "label": 0
                },
                {
                    "sent": "So that's how we get the generality of our proof.",
                    "label": 0
                },
                {
                    "sent": "Is by treating this as a distributional derivative rather than a functional one.",
                    "label": 1
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This condition on the blur kernel derivative in the frequency domain gives us a differential equation which we solve for a large class of solutions.",
                    "label": 0
                },
                {
                    "sent": "We restrict these solutions to those with non negative filter transmittance using a combination of Bochner's theorem and the Fourier slice theorem, and we also restrict our image operator to apply to a sub infinite number of pixels under these requirements.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A unique and familiar class of solutions remains.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "From here, the focal flow constraint is all but all but derive.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We assume Gaussian blur.",
                    "label": 0
                },
                {
                    "sent": "And we note.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "After accounting for on image motion, some quantity remains which is proportional to the image Laplacian.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We then split the spatial derivative terms into translation, an expansion components by in.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Cluding their location weighted sum, moving the Laplacian to the other side of the equation.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Gives our constraint in its final form.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is what our theorem means.",
                    "label": 0
                },
                {
                    "sent": "We can create an extremely efficient Patch wise measurement algorithm by simply computing image derivatives as before.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now augmented with second spatial derivatives.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Within each Patch we accumulate the derivatives into a matrix equation.",
                    "label": 0
                },
                {
                    "sent": "The least squares.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Solution to this equation gives a four vector and this.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is equivalent to knowing the depth and velocity at the back projection of the Patch.",
                    "label": 0
                },
                {
                    "sent": "We consider this over the entire image and build up the depth and velocity Maps.",
                    "label": 0
                },
                {
                    "sent": "And that's it.",
                    "label": 0
                },
                {
                    "sent": "OK, after this, we're done.",
                    "label": 0
                },
                {
                    "sent": "There's no iteration, there's no intermediate inference about displacements or blur kernels or texture features.",
                    "label": 0
                },
                {
                    "sent": "There's no network, there's no data.",
                    "label": 0
                },
                {
                    "sent": "OK, this is a simple feedforward computation derived from first principles that uses very few multiplies and adds.",
                    "label": 0
                },
                {
                    "sent": "We were looking for a very cheap way to measure depth and velocity from images, and that's exactly what this is.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I've shown you are per pixel constraint on image derivatives and seen quantities.",
                    "label": 0
                },
                {
                    "sent": "I've told you that it's valid for any scene texture that it's the only linear constraint with this in variance and that it requires the blur kernels of the camera to be Gaussian.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now we turn to experimental results to answer the question does.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This algorithm work in practice from our uniqueness proof, we know that our constraint holds exactly only when a perfect Gaussian filter with a perfect then lens creates perfect Gaussian blur kernels.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Real cameras rely on thick lenses and the result.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Your kernels look more like this.",
                    "label": 0
                },
                {
                    "sent": "Through Gaussian filter.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Or like this through a pillbox aperture.",
                    "label": 0
                },
                {
                    "sent": "In both cases, there are obvious deviations from the ideal Gaussian blur.",
                    "label": 1
                },
                {
                    "sent": "Now we can still apply, or.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Algorithm by solving the same linear system from the same simple image measurements.",
                    "label": 0
                },
                {
                    "sent": "But our constraint is now only approximately true.",
                    "label": 0
                },
                {
                    "sent": "Instead of refining our active optics, we ask will it work anyway?",
                    "label": 1
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Happily, we find.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A prototype camera equipped with a thick lens and a Gaussian filter.",
                    "label": 0
                },
                {
                    "sent": "Can or in fact a pill box aperture both will work, is able to perform the measurements we described we created.",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The small multi plane scene which was imaged at precise depth intervals as it came into an went out of focus show.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here is a triplet of images over which we collected.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Primitives in two per Patch matrices centered at each pixel.",
                    "label": 0
                }
            ]
        },
        "clip_80": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And solve for the depth and velocity at the back projection of each of these patches.",
                    "label": 0
                },
                {
                    "sent": "And from this SIM.",
                    "label": 0
                }
            ]
        },
        "clip_81": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Measurement algorithm we recovered the shape, location and speed of the object accurately.",
                    "label": 0
                },
                {
                    "sent": "We also showed.",
                    "label": 0
                }
            ]
        },
        "clip_82": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Simple slanted plane from which.",
                    "label": 0
                }
            ]
        },
        "clip_83": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We collected these images considered.",
                    "label": 0
                }
            ]
        },
        "clip_84": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "These larger patches.",
                    "label": 0
                }
            ]
        },
        "clip_85": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Again, collecting depth estimates.",
                    "label": 0
                }
            ]
        },
        "clip_86": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Consistent with ground truth.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                }
            ]
        },
        "clip_87": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Need to speak briefly on the working range of this sensor.",
                    "label": 0
                },
                {
                    "sent": "Fundamentally the focal focal floqi relies on small changes in brightness.",
                    "label": 0
                }
            ]
        },
        "clip_88": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Both between adjacent pixels and within a single pixel.",
                    "label": 0
                },
                {
                    "sent": "Overtime when an object is very out of focus, its images get blurred out and these changes become very small.",
                    "label": 0
                },
                {
                    "sent": "So here's the kind of performance you can expect.",
                    "label": 0
                }
            ]
        },
        "clip_89": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Near the cameras in focus depth shown with the dotted line, we recover high accuracy measurements on the ground truth slanted line.",
                    "label": 0
                }
            ]
        },
        "clip_90": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you go too far in either direction, the accuracy of this measurement decreases rapidly this.",
                    "label": 0
                }
            ]
        },
        "clip_91": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Trend continues.",
                    "label": 0
                }
            ]
        },
        "clip_92": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We focus further out with a larger working range, corresponding to higher variance measurements within the working range, so we trade off precision and range when we design the optics of the system.",
                    "label": 0
                }
            ]
        },
        "clip_93": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This trend also holds from velocity measurements shown here with ground truth on the horizontal line.",
                    "label": 0
                },
                {
                    "sent": "We provide a theoretical analysis of the Q sensitivity in the paper and several systematic experiments in the Associated Technical report.",
                    "label": 0
                }
            ]
        },
        "clip_94": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In addition to the trade off in the optics, we identify another in sensor resolution over space.",
                    "label": 0
                },
                {
                    "sent": "Time and brightness, strengthen one of these areas can theoretically mitigate weakness in another.",
                    "label": 0
                },
                {
                    "sent": "However, we have not yet developed multiscale methods for this cues, so the resolutions that you pick will affect the scenes that are well measured.",
                    "label": 0
                },
                {
                    "sent": "As it stands, arm.",
                    "label": 0
                }
            ]
        },
        "clip_95": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "German performance suffers under sensor noise and just like stereo optical flow or depth from defocus, the focal flow cube breaks down locali in regions that lack texture have high slanter curvature or are at discontinuity's and seen shape and while.",
                    "label": 0
                }
            ]
        },
        "clip_96": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We focused on efficiency.",
                    "label": 0
                },
                {
                    "sent": "There are many possible tradeoffs to be made between performance and computational cost, which we have not yet begun to characterize, so there's clearly a lot of work to be done here, and we hope that you'll join us in exploring and experimenting with this new queue.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        },
        "clip_97": {
            "is_summarization_sample": false,
            "summarization_data": []
        }
    }
}