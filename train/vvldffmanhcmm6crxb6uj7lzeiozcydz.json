{
    "id": "vvldffmanhcmm6crxb6uj7lzeiozcydz",
    "title": "Phoneme Recognition with Large Hierarchical Reservoirs",
    "info": {
        "author": [
            "Fabian Triefenbach, Electronics and Information Systems Department, Ghent University"
        ],
        "published": "Jan. 12, 2011",
        "recorded": "December 2010",
        "category": [
            "Top->Computer Science->Speech Analysis"
        ]
    },
    "url": "http://videolectures.net/nips2010_triefenbach_prl/",
    "segmentation": [
        [
            "Hello everybody, I'm Fabien from the speech lab at Kent University and I'm going to present today some work based on speech recognition by means of reservoir computing."
        ],
        [
            "So I first have to apologize.",
            "It will be quite engineering based talk so I just have one equation in total.",
            "But I hope you guys still enjoy to see our machine learning speech recognition and no networks can be formed a unit.",
            "And yeah, what we which results we obtained with our system.",
            "So I will start today with some basic of speech recognition followed by acoustic modeling and how we can use machine learning in context of these acoustic modeling.",
            "And then I will show some experimental evaluation and some conclusions and future work."
        ],
        [
            "OK, so first of all, the question is what is speech recognition and speech recognition?",
            "Is the art of converting a continuous time signal into a discrete word sequence.",
            "So we get a speaker utterance and we try to extract what did the speaker set, which works were?",
            "Omitted"
        ],
        [
            "And looking at the signal signal, we can use the properties of the signal because we can observe that it consists of crazy stationary segments and."
        ],
        [
            "See in this example there's a sentence you duck suit and to see a very clear blocks of these signal which all represent so called acoustic units of basic sounds and namely we call them phonemes or phones.",
            "And in this picture you see there are two kinds.",
            "The first one is the normal phoneme, so that's the classical unit we use in speech recognition.",
            "And like the U&J&U that there are two sounds, but some of these sounds can be split into smaller subunits, so called phones.",
            "So like the D and the K in this example, closed, divided into a closure, sound and sound itself."
        ],
        [
            "OK, and this acoustic modeling is one of the basic parts of speech recognizer and is very important if we want to extract the web sync sequence out of.",
            "Out and out."
        ],
        [
            "So how does the speech recognizer works?",
            "We want to put in the speech and just get out the sentence.",
            "So very basic setup.",
            "But to do so we need some advanced comp."
        ],
        [
            "Moments, so first of all we do some preprocessing that's very straightforward, so we just extract speech features and normally we use MFC vectors."
        ],
        [
            "And then we start to build the acoustic models.",
            "So as I presented before we built for each phoneme and model which describes how this phoneme is acoustically realized or represented, and to use this model information."
        ],
        [
            "To get the word sequence at the end, we use phonetic dictionary.",
            "So this phonetic dictionary contains all the words we want to recognize, and for each of the words, we know the pronunciation, so we know which sequence of sounds or which sequence of phonemes we have to expect."
        ],
        [
            "And in the highest level, we use a language model, so this language model tells us how the natural order of words in the language is.",
            "So it's a statistical approach of applying a grammar to a sequence of words we recognized."
        ],
        [
            "OK, and now in the machine learning community."
        ],
        [
            "The part where we adapt the normal speech recognition process by applying some normal networks is doing the acoustic modeling.",
            "So doing the modeling of the basic sounds.",
            "And to do so, we use the so-called weather walk computing.",
            "So I will start with explaining what a reservoir is and how we can use it for acoustic modeling.",
            "SOA Reservoir is a kind of recurrent neural network, so it's a very simple architecture.",
            "It's just a set of random nonlinear.",
            "We currently connected noise once.",
            "And yeah, these new ones have an input layer which is also randomly connected, so our extracted features are fed to the input layer and water this.",
            "I'm connected now wants."
        ],
        [
            "And the state of the reservoir can be computed at each time step by just using the weight of the inputs for these time steps and taking the previous state with a weight matrix of recurrent connections.",
            "And of course only non linearity.",
            "And we can extend this basic weather or concept, so instead just making having normal computer."
        ],
        [
            "Notes we can introduce a leaky integrator into each of these new ones.",
            "So what we get is that we can define affecter Lambda which allows us to control how much fading memory want to have in the network.",
            "So which states how long the states should be kept doing the execution process."
        ],
        [
            "And to use this reservoir we put a readout layer at the end so it's a output layer which each node represents a linear function.",
            "So for each class we have in our model, or each phoneme, we have one note and."
        ],
        [
            "We simply do a linear function or train a linear function that for each class we have a linear classifier based on the reservoir States and these linear classifiers are simply trained using which regression.",
            "So it's a very simple model we put in the data into random set of nodes, map it to a high dimensional space and then learn linear classifiers to extract information."
        ],
        [
            "And you, what are the advantages of these concept for acoustic modeling or even general?",
            "One advantage is that linear regression actually leads to a unique solution, so we don't have to risk of lending and abet local optimum like we serve fully traditionally trained.",
            "We can all network and we can do the training in one shot so we don't have an iterative process like in Hmm's.",
            "So we can just solve a set of equations."
        ],
        [
            "Second, important advantage of the weather wise, especially for speech that it can model dynamics.",
            "So on the one hand we have we currency.",
            "We have recurrent connections which keep the information circulating in the network and we have the integration inside each Neumann which gives us a kind of memory.",
            "And yeah, these two properties can implicitly model the acoustic context, so again, in comparison with HMM, which is normally context independent, we have the network that keeps this information over a certain time."
        ],
        [
            "And yeah, the last advantage is that normal implementation of specially for speech recognizer seems very compelling from a biological perspective, so having no ones doing the drop sounds quite interesting, so that's one of the reasons why we started to investigate these kind of systems for speech recognition."
        ],
        [
            "And yeah, of course these systems have some downsides as well, so if we compared to SVM support vector machines, the inner space we create is actually not optimized, it's just a big random mapping and we try to classify in these big space, but the space is not really trained to optimize."
        ],
        [
            "That means that all the results are more or less bound to the weight initialization process, so we have to set control parameters and we have to find good weights in the initialization process.",
            "And that of course is.",
            "Yeah, take some time doing perimeter sweeping."
        ],
        [
            "OK and yeah to use this concept in a full speech recognizer, we started with the first proof of context and just build up a phoneme recognizer.",
            "So instead of expecting the words, we start to extract the phone, see."
        ],
        [
            "1st, and to do so, we just take the speech signal at the preprocessing as described before creating some features."
        ],
        [
            "And then we build an acoustic model which is just a simple weather wall and the readout layer which is trained with which regression.",
            "So we put into 39 features and get out 41 classification result."
        ],
        [
            "And yeah.",
            "We take these readouts or these values which are coming from the readout and use them for decoding so the decoder is a classical Viterbi algorithm and we just use a phonemic language model on the phone level to extract the sequence of phonemes."
        ],
        [
            "But this system is quite simple, so we thought about using an hierarchical extension so we can take the single weather which is in the middle of this plot."
        ],
        [
            "And just extend it with a cascade of reservoirs.",
            "So every time we reservoir and trained readout and each layer is trained with the outputs of the previous layer.",
            "So we just stack them on top."
        ],
        [
            "And the idea is that these higher layers learn kind of error, patting pattern emerging from the previous layer."
        ],
        [
            "And yeah, to analyze these architecture, we didn't benchmark on the known TIMIT database, so that's relative small database for speech, it's only 1,000,000 frames and 6000 words, so 630 speakers.",
            "But it's interesting that we have the phonetic labels for each frame in this data set, so that's normally not the case, and it's perfect for acoustic modeling because we know for each frame which phoneme we have and we can simply do supervised training with this training data."
        ],
        [
            "OK, and the performance criterion to use for all our experiments is the recognition error rate.",
            "So what we do is collect how many edit operations, so substitutions, deletions, and inserts do we need to match the recognize sequence with our?",
            "Reference sequence so you see a 2 sample 2.",
            "Strings here and."
        ],
        [
            "The error measurement is quite simple, we just look how many if we align the two sequences, how many deletions, substitutions and inserts we do and get an error rate in percentage."
        ],
        [
            "Yeah, just one remark.",
            "We didn't do any experiments or optimizations to using the test set."
        ],
        [
            "And doing the experiments, we found out that as an initial observation, that small reservoir systems, so with less than 1000 notes, showed very disappointing results.",
            "So we didn't came to the area of state of the art."
        ],
        [
            "But knowing that with the reduced number of recurrent connections, we can already get a synthetic performance, so we don't need a fully connected normal network.",
            "We just need a fraction of connections."
        ],
        [
            "And that actually allows us to to make sparse weather walls and makes them quite big because we don't have all these recurrency."
        ],
        [
            "And if we introduce these large reservoirs, you can see that the phone ever wait the phone recognition error rate significantly goes down.",
            "If we double the number of nodes.",
            "So we did this until reaching the number of 20,000.",
            "And.",
            "We always have to double the number of nodes, so that's important that we really do big steps by increasing the size.",
            "And yeah, you can see that for the case of 20,000, we already get quite good error rate of 30%.",
            "And compared to the test train set we have a difference of 10%."
        ],
        [
            "So you might ask now why we stopped at 20,000 votes in this plot?",
            "And the simple answer is that having 20,000 notes means means the quite big metrics to just do regression on it.",
            "And we did a simple simple programming approach, so we just stopped because of memory limitations."
        ],
        [
            "But we also stopped because we don't see that we can cannot get much more out of these situations.",
            "We seem to come to this situation.",
            "So even if we doubled the notes even more.",
            "Might give 1% more, but it's not the key I guess.",
            "But hierarchical systems seem to be offer a better trade off, and that will be."
        ],
        [
            "Next part, so if we introduce hierarchies of reservoirs.",
            "So what we did is just stacking the same size two other walls on top again."
        ],
        [
            "And in this plot you see three kinds of reservoirs.",
            "Small, medium and large sized deep end, and the number of layers.",
            "And yeah, the first point is that we can say that the previous statement that hierarchies are more efficient than similar levels can be shown with the.",
            "This point here.",
            "So it's twice 5000 notes actually has the same performance as one 20,000, but it takes the half of trainable parameters.",
            "So confused computationally, that's more efficient, more efficient.",
            "And it's also to see that in all cases, stacking weather wars with at least two layers gives clear improvement for all systems.",
            "But if we stack more layers, we come to situation slowly and in the case of 20,000 we actually reached the limit of trainable parameters.",
            "So the plot goes up at the end.",
            "If we stick 4 * 20,000 layers."
        ],
        [
            "And the results we could obtain with this system I shown in this table.",
            "So we worked on phones and phonemes to have a good comparison with the literature.",
            "And first of all, our results are competitive with the current state of the art system.",
            "So context dependent HMMS and recurrent neural networks.",
            "So there's something like 1% difference between the power system and the state of the art.",
            "But of course, better systems do exist.",
            "So like the deep belief networks, and yeah, one poster presented here, they get even better results."
        ],
        [
            "And yeah, So what we can conclude from this experiment we did is first of all that the weather or computing seems to offer a good basis for the recognition of continuous speech.",
            "So at least on the phoneme level.",
            "And our results are quite promising given this really relative simple architecture.",
            "So we just have the big mapping and the linear regression, and the system was developed in a short time compared to the decades of work which is spent on Hmm's and normal recurrent neural networks."
        ],
        [
            "And yeah, more specifically, we showed that the dynamics in the weather or can help the model the acoustic context.",
            "So we have shown that we current connections are important and that they can help to model this and even the integration inside than oil.",
            "And so we found the optimal value of integration time, which is clearly in line with results from speech."
        ],
        [
            "We search and we also showed that the randomly connected reservoir is already competitive with a fully trained recurrent neural network but with less effort and much simpler training approach."
        ],
        [
            "And the last point is that we have shown that hierarchies of reservoirs seem to perform a kind of error corrections, and that they are completely computationally more attractive than single layer system."
        ],
        [
            "And yeah, for the future work, that means that we will try to use these acoustic models to set them into a full speech recognizer and try to apply the outputs of the acoustic model in combination with standard techniques for lexical and linguistic layers.",
            "So that will be the next big step to see is this acoustic model only good on phonemes or is it really good on word recognition?",
            "Because that's actually the main gold gold."
        ],
        [
            "Another field.",
            "But there are even more theoretical.",
            "Questions so can we improve our architecture to get more gains on the phones and on the word level?",
            "So first of all, can we introduce feedbacks?",
            "Can we maybe do what nature members doing?",
            "Can we model context dependent phenomic classes?",
            "So building Triphones and try to.",
            "Have more classes to have a better classification result?",
            "Can we bring some structure inside the reservoir?",
            "Can we select a number of Senseable Neumann so there are many basic things we could do on the architecture?"
        ],
        [
            "Self.",
            "And for us also interesting step will be can we can we do more with normal networks?",
            "Can we do more than just doing acoustic modeling?",
            "Can we build language models?",
            "Can we build a dictionary based on normal implementations?",
            "That will be definitely work for the future."
        ],
        [
            "Yep, thank you.",
            "Question.",
            "Did you try to see whether the mistakes that different models make are in the same place or not?",
            "So is there a hope for so we can are the mistakes that different model like your model HMM based model, another model?",
            "Are on the same phone names or do they have different mistakes that that?",
            "Maybe there is a hope for building and symbols and getting better performance?",
            "Do you mean if we use states of the phonemes know when you make the prediction so you show it you showed us a result of the experiment that you ran.",
            "Yeah, showing the different models have comparably similar error rates, but either making result at the same places, because if they are not making the errors, it's in places.",
            "You can build in symbols.",
            "I really don't understand so.",
            "Yeah, it's I don't hear it, really.",
            "No, no, it's too loud, not loud enough.",
            "Yep.",
            "So again, the different you showed us that the different models have similar error rates.",
            "Yeah, but are there making the errors or in the same places?",
            "Because if they are not, we can build and samples of these models and get even better performance.",
            "As you mean with the phones and phonemes, yeah, ah, OK, yeah, so we can construct the phonemes from the phones and the phones are easier to recognize, so that will help to get better models so we can actually use the phones to get the phonemes.",
            "And yeah, so we could build up states for the phones before the phonemes based on films.",
            "That was the question.",
            "Yeah, OK so.",
            "Yeah, regarding the big networks.",
            "Have you tried to dig up the effect of the size of the network with the just the sheer number of parameters an overfitting?",
            "So for example, just connecting to a subset of neurons.",
            "We normally use only use L1 instead of L2 that we normally use fully connected outputs.",
            "So we connect to our neurons.",
            "But we thought about implementing a way of selecting the efficient node once because there are definitely no ones which do not lead to classical to central information.",
            "So doing the regression we could make a selection procedure to find those nodes which actually have a linear connection or linear dependency with the results.",
            "We want to have.",
            "Yeah, that's definitely to do, yeah.",
            "Yep."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hello everybody, I'm Fabien from the speech lab at Kent University and I'm going to present today some work based on speech recognition by means of reservoir computing.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I first have to apologize.",
                    "label": 0
                },
                {
                    "sent": "It will be quite engineering based talk so I just have one equation in total.",
                    "label": 0
                },
                {
                    "sent": "But I hope you guys still enjoy to see our machine learning speech recognition and no networks can be formed a unit.",
                    "label": 0
                },
                {
                    "sent": "And yeah, what we which results we obtained with our system.",
                    "label": 0
                },
                {
                    "sent": "So I will start today with some basic of speech recognition followed by acoustic modeling and how we can use machine learning in context of these acoustic modeling.",
                    "label": 0
                },
                {
                    "sent": "And then I will show some experimental evaluation and some conclusions and future work.",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so first of all, the question is what is speech recognition and speech recognition?",
                    "label": 0
                },
                {
                    "sent": "Is the art of converting a continuous time signal into a discrete word sequence.",
                    "label": 1
                },
                {
                    "sent": "So we get a speaker utterance and we try to extract what did the speaker set, which works were?",
                    "label": 0
                },
                {
                    "sent": "Omitted",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And looking at the signal signal, we can use the properties of the signal because we can observe that it consists of crazy stationary segments and.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "See in this example there's a sentence you duck suit and to see a very clear blocks of these signal which all represent so called acoustic units of basic sounds and namely we call them phonemes or phones.",
                    "label": 1
                },
                {
                    "sent": "And in this picture you see there are two kinds.",
                    "label": 1
                },
                {
                    "sent": "The first one is the normal phoneme, so that's the classical unit we use in speech recognition.",
                    "label": 1
                },
                {
                    "sent": "And like the U&J&U that there are two sounds, but some of these sounds can be split into smaller subunits, so called phones.",
                    "label": 0
                },
                {
                    "sent": "So like the D and the K in this example, closed, divided into a closure, sound and sound itself.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and this acoustic modeling is one of the basic parts of speech recognizer and is very important if we want to extract the web sync sequence out of.",
                    "label": 0
                },
                {
                    "sent": "Out and out.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how does the speech recognizer works?",
                    "label": 0
                },
                {
                    "sent": "We want to put in the speech and just get out the sentence.",
                    "label": 0
                },
                {
                    "sent": "So very basic setup.",
                    "label": 0
                },
                {
                    "sent": "But to do so we need some advanced comp.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Moments, so first of all we do some preprocessing that's very straightforward, so we just extract speech features and normally we use MFC vectors.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we start to build the acoustic models.",
                    "label": 0
                },
                {
                    "sent": "So as I presented before we built for each phoneme and model which describes how this phoneme is acoustically realized or represented, and to use this model information.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To get the word sequence at the end, we use phonetic dictionary.",
                    "label": 0
                },
                {
                    "sent": "So this phonetic dictionary contains all the words we want to recognize, and for each of the words, we know the pronunciation, so we know which sequence of sounds or which sequence of phonemes we have to expect.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in the highest level, we use a language model, so this language model tells us how the natural order of words in the language is.",
                    "label": 0
                },
                {
                    "sent": "So it's a statistical approach of applying a grammar to a sequence of words we recognized.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and now in the machine learning community.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The part where we adapt the normal speech recognition process by applying some normal networks is doing the acoustic modeling.",
                    "label": 0
                },
                {
                    "sent": "So doing the modeling of the basic sounds.",
                    "label": 0
                },
                {
                    "sent": "And to do so, we use the so-called weather walk computing.",
                    "label": 0
                },
                {
                    "sent": "So I will start with explaining what a reservoir is and how we can use it for acoustic modeling.",
                    "label": 0
                },
                {
                    "sent": "SOA Reservoir is a kind of recurrent neural network, so it's a very simple architecture.",
                    "label": 0
                },
                {
                    "sent": "It's just a set of random nonlinear.",
                    "label": 1
                },
                {
                    "sent": "We currently connected noise once.",
                    "label": 0
                },
                {
                    "sent": "And yeah, these new ones have an input layer which is also randomly connected, so our extracted features are fed to the input layer and water this.",
                    "label": 0
                },
                {
                    "sent": "I'm connected now wants.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the state of the reservoir can be computed at each time step by just using the weight of the inputs for these time steps and taking the previous state with a weight matrix of recurrent connections.",
                    "label": 1
                },
                {
                    "sent": "And of course only non linearity.",
                    "label": 0
                },
                {
                    "sent": "And we can extend this basic weather or concept, so instead just making having normal computer.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Notes we can introduce a leaky integrator into each of these new ones.",
                    "label": 0
                },
                {
                    "sent": "So what we get is that we can define affecter Lambda which allows us to control how much fading memory want to have in the network.",
                    "label": 0
                },
                {
                    "sent": "So which states how long the states should be kept doing the execution process.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And to use this reservoir we put a readout layer at the end so it's a output layer which each node represents a linear function.",
                    "label": 0
                },
                {
                    "sent": "So for each class we have in our model, or each phoneme, we have one note and.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We simply do a linear function or train a linear function that for each class we have a linear classifier based on the reservoir States and these linear classifiers are simply trained using which regression.",
                    "label": 0
                },
                {
                    "sent": "So it's a very simple model we put in the data into random set of nodes, map it to a high dimensional space and then learn linear classifiers to extract information.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And you, what are the advantages of these concept for acoustic modeling or even general?",
                    "label": 0
                },
                {
                    "sent": "One advantage is that linear regression actually leads to a unique solution, so we don't have to risk of lending and abet local optimum like we serve fully traditionally trained.",
                    "label": 1
                },
                {
                    "sent": "We can all network and we can do the training in one shot so we don't have an iterative process like in Hmm's.",
                    "label": 0
                },
                {
                    "sent": "So we can just solve a set of equations.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Second, important advantage of the weather wise, especially for speech that it can model dynamics.",
                    "label": 1
                },
                {
                    "sent": "So on the one hand we have we currency.",
                    "label": 0
                },
                {
                    "sent": "We have recurrent connections which keep the information circulating in the network and we have the integration inside each Neumann which gives us a kind of memory.",
                    "label": 0
                },
                {
                    "sent": "And yeah, these two properties can implicitly model the acoustic context, so again, in comparison with HMM, which is normally context independent, we have the network that keeps this information over a certain time.",
                    "label": 1
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And yeah, the last advantage is that normal implementation of specially for speech recognizer seems very compelling from a biological perspective, so having no ones doing the drop sounds quite interesting, so that's one of the reasons why we started to investigate these kind of systems for speech recognition.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And yeah, of course these systems have some downsides as well, so if we compared to SVM support vector machines, the inner space we create is actually not optimized, it's just a big random mapping and we try to classify in these big space, but the space is not really trained to optimize.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That means that all the results are more or less bound to the weight initialization process, so we have to set control parameters and we have to find good weights in the initialization process.",
                    "label": 1
                },
                {
                    "sent": "And that of course is.",
                    "label": 0
                },
                {
                    "sent": "Yeah, take some time doing perimeter sweeping.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK and yeah to use this concept in a full speech recognizer, we started with the first proof of context and just build up a phoneme recognizer.",
                    "label": 0
                },
                {
                    "sent": "So instead of expecting the words, we start to extract the phone, see.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "1st, and to do so, we just take the speech signal at the preprocessing as described before creating some features.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we build an acoustic model which is just a simple weather wall and the readout layer which is trained with which regression.",
                    "label": 0
                },
                {
                    "sent": "So we put into 39 features and get out 41 classification result.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And yeah.",
                    "label": 0
                },
                {
                    "sent": "We take these readouts or these values which are coming from the readout and use them for decoding so the decoder is a classical Viterbi algorithm and we just use a phonemic language model on the phone level to extract the sequence of phonemes.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But this system is quite simple, so we thought about using an hierarchical extension so we can take the single weather which is in the middle of this plot.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And just extend it with a cascade of reservoirs.",
                    "label": 0
                },
                {
                    "sent": "So every time we reservoir and trained readout and each layer is trained with the outputs of the previous layer.",
                    "label": 0
                },
                {
                    "sent": "So we just stack them on top.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the idea is that these higher layers learn kind of error, patting pattern emerging from the previous layer.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And yeah, to analyze these architecture, we didn't benchmark on the known TIMIT database, so that's relative small database for speech, it's only 1,000,000 frames and 6000 words, so 630 speakers.",
                    "label": 0
                },
                {
                    "sent": "But it's interesting that we have the phonetic labels for each frame in this data set, so that's normally not the case, and it's perfect for acoustic modeling because we know for each frame which phoneme we have and we can simply do supervised training with this training data.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, and the performance criterion to use for all our experiments is the recognition error rate.",
                    "label": 1
                },
                {
                    "sent": "So what we do is collect how many edit operations, so substitutions, deletions, and inserts do we need to match the recognize sequence with our?",
                    "label": 1
                },
                {
                    "sent": "Reference sequence so you see a 2 sample 2.",
                    "label": 0
                },
                {
                    "sent": "Strings here and.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The error measurement is quite simple, we just look how many if we align the two sequences, how many deletions, substitutions and inserts we do and get an error rate in percentage.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, just one remark.",
                    "label": 0
                },
                {
                    "sent": "We didn't do any experiments or optimizations to using the test set.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And doing the experiments, we found out that as an initial observation, that small reservoir systems, so with less than 1000 notes, showed very disappointing results.",
                    "label": 0
                },
                {
                    "sent": "So we didn't came to the area of state of the art.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But knowing that with the reduced number of recurrent connections, we can already get a synthetic performance, so we don't need a fully connected normal network.",
                    "label": 0
                },
                {
                    "sent": "We just need a fraction of connections.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And that actually allows us to to make sparse weather walls and makes them quite big because we don't have all these recurrency.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And if we introduce these large reservoirs, you can see that the phone ever wait the phone recognition error rate significantly goes down.",
                    "label": 0
                },
                {
                    "sent": "If we double the number of nodes.",
                    "label": 1
                },
                {
                    "sent": "So we did this until reaching the number of 20,000.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "We always have to double the number of nodes, so that's important that we really do big steps by increasing the size.",
                    "label": 0
                },
                {
                    "sent": "And yeah, you can see that for the case of 20,000, we already get quite good error rate of 30%.",
                    "label": 0
                },
                {
                    "sent": "And compared to the test train set we have a difference of 10%.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So you might ask now why we stopped at 20,000 votes in this plot?",
                    "label": 0
                },
                {
                    "sent": "And the simple answer is that having 20,000 notes means means the quite big metrics to just do regression on it.",
                    "label": 0
                },
                {
                    "sent": "And we did a simple simple programming approach, so we just stopped because of memory limitations.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But we also stopped because we don't see that we can cannot get much more out of these situations.",
                    "label": 0
                },
                {
                    "sent": "We seem to come to this situation.",
                    "label": 0
                },
                {
                    "sent": "So even if we doubled the notes even more.",
                    "label": 0
                },
                {
                    "sent": "Might give 1% more, but it's not the key I guess.",
                    "label": 0
                },
                {
                    "sent": "But hierarchical systems seem to be offer a better trade off, and that will be.",
                    "label": 1
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Next part, so if we introduce hierarchies of reservoirs.",
                    "label": 0
                },
                {
                    "sent": "So what we did is just stacking the same size two other walls on top again.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And in this plot you see three kinds of reservoirs.",
                    "label": 0
                },
                {
                    "sent": "Small, medium and large sized deep end, and the number of layers.",
                    "label": 1
                },
                {
                    "sent": "And yeah, the first point is that we can say that the previous statement that hierarchies are more efficient than similar levels can be shown with the.",
                    "label": 0
                },
                {
                    "sent": "This point here.",
                    "label": 1
                },
                {
                    "sent": "So it's twice 5000 notes actually has the same performance as one 20,000, but it takes the half of trainable parameters.",
                    "label": 0
                },
                {
                    "sent": "So confused computationally, that's more efficient, more efficient.",
                    "label": 0
                },
                {
                    "sent": "And it's also to see that in all cases, stacking weather wars with at least two layers gives clear improvement for all systems.",
                    "label": 1
                },
                {
                    "sent": "But if we stack more layers, we come to situation slowly and in the case of 20,000 we actually reached the limit of trainable parameters.",
                    "label": 0
                },
                {
                    "sent": "So the plot goes up at the end.",
                    "label": 0
                },
                {
                    "sent": "If we stick 4 * 20,000 layers.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the results we could obtain with this system I shown in this table.",
                    "label": 0
                },
                {
                    "sent": "So we worked on phones and phonemes to have a good comparison with the literature.",
                    "label": 0
                },
                {
                    "sent": "And first of all, our results are competitive with the current state of the art system.",
                    "label": 1
                },
                {
                    "sent": "So context dependent HMMS and recurrent neural networks.",
                    "label": 1
                },
                {
                    "sent": "So there's something like 1% difference between the power system and the state of the art.",
                    "label": 1
                },
                {
                    "sent": "But of course, better systems do exist.",
                    "label": 1
                },
                {
                    "sent": "So like the deep belief networks, and yeah, one poster presented here, they get even better results.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And yeah, So what we can conclude from this experiment we did is first of all that the weather or computing seems to offer a good basis for the recognition of continuous speech.",
                    "label": 1
                },
                {
                    "sent": "So at least on the phoneme level.",
                    "label": 0
                },
                {
                    "sent": "And our results are quite promising given this really relative simple architecture.",
                    "label": 0
                },
                {
                    "sent": "So we just have the big mapping and the linear regression, and the system was developed in a short time compared to the decades of work which is spent on Hmm's and normal recurrent neural networks.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And yeah, more specifically, we showed that the dynamics in the weather or can help the model the acoustic context.",
                    "label": 1
                },
                {
                    "sent": "So we have shown that we current connections are important and that they can help to model this and even the integration inside than oil.",
                    "label": 0
                },
                {
                    "sent": "And so we found the optimal value of integration time, which is clearly in line with results from speech.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We search and we also showed that the randomly connected reservoir is already competitive with a fully trained recurrent neural network but with less effort and much simpler training approach.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the last point is that we have shown that hierarchies of reservoirs seem to perform a kind of error corrections, and that they are completely computationally more attractive than single layer system.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And yeah, for the future work, that means that we will try to use these acoustic models to set them into a full speech recognizer and try to apply the outputs of the acoustic model in combination with standard techniques for lexical and linguistic layers.",
                    "label": 1
                },
                {
                    "sent": "So that will be the next big step to see is this acoustic model only good on phonemes or is it really good on word recognition?",
                    "label": 0
                },
                {
                    "sent": "Because that's actually the main gold gold.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Another field.",
                    "label": 0
                },
                {
                    "sent": "But there are even more theoretical.",
                    "label": 0
                },
                {
                    "sent": "Questions so can we improve our architecture to get more gains on the phones and on the word level?",
                    "label": 0
                },
                {
                    "sent": "So first of all, can we introduce feedbacks?",
                    "label": 0
                },
                {
                    "sent": "Can we maybe do what nature members doing?",
                    "label": 0
                },
                {
                    "sent": "Can we model context dependent phenomic classes?",
                    "label": 0
                },
                {
                    "sent": "So building Triphones and try to.",
                    "label": 0
                },
                {
                    "sent": "Have more classes to have a better classification result?",
                    "label": 0
                },
                {
                    "sent": "Can we bring some structure inside the reservoir?",
                    "label": 1
                },
                {
                    "sent": "Can we select a number of Senseable Neumann so there are many basic things we could do on the architecture?",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Self.",
                    "label": 0
                },
                {
                    "sent": "And for us also interesting step will be can we can we do more with normal networks?",
                    "label": 0
                },
                {
                    "sent": "Can we do more than just doing acoustic modeling?",
                    "label": 0
                },
                {
                    "sent": "Can we build language models?",
                    "label": 0
                },
                {
                    "sent": "Can we build a dictionary based on normal implementations?",
                    "label": 0
                },
                {
                    "sent": "That will be definitely work for the future.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yep, thank you.",
                    "label": 0
                },
                {
                    "sent": "Question.",
                    "label": 0
                },
                {
                    "sent": "Did you try to see whether the mistakes that different models make are in the same place or not?",
                    "label": 0
                },
                {
                    "sent": "So is there a hope for so we can are the mistakes that different model like your model HMM based model, another model?",
                    "label": 0
                },
                {
                    "sent": "Are on the same phone names or do they have different mistakes that that?",
                    "label": 0
                },
                {
                    "sent": "Maybe there is a hope for building and symbols and getting better performance?",
                    "label": 0
                },
                {
                    "sent": "Do you mean if we use states of the phonemes know when you make the prediction so you show it you showed us a result of the experiment that you ran.",
                    "label": 0
                },
                {
                    "sent": "Yeah, showing the different models have comparably similar error rates, but either making result at the same places, because if they are not making the errors, it's in places.",
                    "label": 0
                },
                {
                    "sent": "You can build in symbols.",
                    "label": 0
                },
                {
                    "sent": "I really don't understand so.",
                    "label": 0
                },
                {
                    "sent": "Yeah, it's I don't hear it, really.",
                    "label": 0
                },
                {
                    "sent": "No, no, it's too loud, not loud enough.",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "So again, the different you showed us that the different models have similar error rates.",
                    "label": 0
                },
                {
                    "sent": "Yeah, but are there making the errors or in the same places?",
                    "label": 0
                },
                {
                    "sent": "Because if they are not, we can build and samples of these models and get even better performance.",
                    "label": 0
                },
                {
                    "sent": "As you mean with the phones and phonemes, yeah, ah, OK, yeah, so we can construct the phonemes from the phones and the phones are easier to recognize, so that will help to get better models so we can actually use the phones to get the phonemes.",
                    "label": 0
                },
                {
                    "sent": "And yeah, so we could build up states for the phones before the phonemes based on films.",
                    "label": 0
                },
                {
                    "sent": "That was the question.",
                    "label": 0
                },
                {
                    "sent": "Yeah, OK so.",
                    "label": 0
                },
                {
                    "sent": "Yeah, regarding the big networks.",
                    "label": 0
                },
                {
                    "sent": "Have you tried to dig up the effect of the size of the network with the just the sheer number of parameters an overfitting?",
                    "label": 0
                },
                {
                    "sent": "So for example, just connecting to a subset of neurons.",
                    "label": 0
                },
                {
                    "sent": "We normally use only use L1 instead of L2 that we normally use fully connected outputs.",
                    "label": 0
                },
                {
                    "sent": "So we connect to our neurons.",
                    "label": 0
                },
                {
                    "sent": "But we thought about implementing a way of selecting the efficient node once because there are definitely no ones which do not lead to classical to central information.",
                    "label": 0
                },
                {
                    "sent": "So doing the regression we could make a selection procedure to find those nodes which actually have a linear connection or linear dependency with the results.",
                    "label": 0
                },
                {
                    "sent": "We want to have.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that's definitely to do, yeah.",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                }
            ]
        }
    }
}