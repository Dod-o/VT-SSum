{
    "id": "bne7yhdkvihrrbu6d5sry6fimxnlrg2q",
    "title": "Kullback-Leibler Divergence Estimation of Continuous Distributions",
    "info": {
        "author": [
            "Fernando Perez-Cruz, Princeton University"
        ],
        "published": "Feb. 25, 2008",
        "recorded": "December 2007",
        "category": [
            "Top->Mathematics"
        ]
    },
    "url": "http://videolectures.net/ripd07_cruz_kld/",
    "segmentation": [
        [
            "Hello everyone, I'm going to talk about Google labor differences estimation for continuous distribution."
        ],
        [
            "So.",
            "We are going to visit the overview of talk.",
            "I will.",
            "First person to problem set up.",
            "Then I'm going to show their one dimensional solution, which I think is.",
            "Is more intuitive than the multiple there multiple?",
            "Multi dimensional solution and then I will end up with some examples.",
            "I also have a poster over here in case somebody wants more information about it."
        ],
        [
            "OK, so the problem is quite simple.",
            "We want to estimate the differences between P&Q.",
            "When?",
            "And we know that this division's is finite.",
            "If P is absolutely continuous with respect to keep.",
            "And we want to estimate this density from a set of samples from P of X and a set of sample of key of X.",
            "And more important, we want to do this without estimating P of X key of X or the ratio of the two.",
            "OK, we had these nips.",
            "We have somebody estimating POS on the radio there waiting between P of XNQ of X.",
            "Or something it was on Monday, a poster.",
            "We are not and we will show that our method.",
            "Converges to estimating the cool bar label density, but we can say that we are using a proxy for P of X&Q of X, but those are not going to converge.",
            "To the true values."
        ],
        [
            "Alright.",
            "So for the 1 dimensional solution we use.",
            "Their cumulative distribution function, but we're going to use our piecewise continuous approximation to it.",
            "OK, so we have in the example.",
            "I think it's easy to see we have the standard one where we have the step function and then we just do a continuous piecewise approximation over it and they were going to estimate the color label.",
            "Density is just taking a small.",
            "Delta function around PC and thank you see and XI are the points coming from PC.",
            "Alright, and we can prove that the convergence is almost surely.",
            "To the density I mean the divergent between P and Q + 1.",
            "Well, you could say so, but if you do that, you can say that what we're doing is we're computing on Instagram with one sample per stream.",
            "What size?",
            "So the excise are drawn from Pfc Pompey.",
            "OK. Well, that's the thing.",
            "They have to be.",
            "They have to be.",
            "P has to be continually has to be.",
            "Absolutely continuous with this vector Q. OK, I mean if you go very far away name will take you lots of thankful to converge this.",
            "I mean that's the only thing that we have is.",
            "And I mean I'm going to move on because I'm sure that we can talk about that.",
            "That's a technicality, but it's not really important.",
            "It just it will tell you that you will need many, many, many samples to converge.",
            "But we can do it without me.",
            "It will take long.",
            "That's that's the easy way out.",
            "OK, and we got a new question where estimating an Instagram which has only one sample 1 sample per bin.",
            "OK, so if the number of bins grows linearly with the number of samples, the history and doesn't converge to the density.",
            "OK, that's a thing.",
            "In your token, mention the Noble and logo sheet paper and they have two conditions for an Instagram base of the samples to converge, you need the number of history has to grow sublinearly with animal symbols.",
            "Excuse me mutually.",
            "Searching that both of them are continuous and they are absolutely continuous with respect to each other."
        ],
        [
            "And the proof.",
            "Or the cubicle in the proof is noticing that.",
            "If we, the difference between the true.",
            "Cumulative distribution and the piecewise linear array using behaves as an exponential distribution.",
            "Becausw PC's I minus PCs I -- 1 where I suppose that samples are order is 1 divided over N. And the difference between two samples that come from the same distribution?",
            "They're going to be distributed according to a uniform, and the difference is going to be an exponential distribution."
        ],
        [
            "OK, for the multi dimensional solution what we do is instead of using this density this.",
            "Instead of using.",
            "This community distribution we do an density estimation using the K nearest neighbor solution.",
            "OK, so we measure so the K nearest neighbor solution from XI to all the possible points in XIF XI an from the Y from the.",
            "Sorry from the samples and come from Q.",
            "Do that XI.",
            "And then we assume that we have a bowl of radius.",
            "Of that size and the number of points in each one.",
            "Alright, so we can show that this is the same case as before.",
            "We only have 1 sample per bin.",
            "If we use K equal to 1 and that means that the histogram in this piece of.",
            "Be hard of K&Q have K they're not going to converge to the density, but we can prove.",
            "That"
        ],
        [
            "We converge to the.",
            "To the to the true one, so to true divergences for doing that.",
            "Well, we show is that P of X the true density divided by P1 of X converges in probability.",
            "That's a mistake to an exponential distribution of over one, and to see that we first assume that P of X is a dimensional uniform distribution of a given support.",
            "If we define the set of XI of all the samples that are are close.",
            "2X I.",
            "And then we measure this query and distance they are uniformly distributed.",
            "Which means that the difference between the origin and the first one.",
            "They are distributed as an exponential distribution.",
            "OK and then for non uniform the only thing that we need to know is to use the continuity.",
            "Property then the nearest neighbour will tend to P of X as the number of samples Infinity.",
            "Alright, so now we can."
        ],
        [
            "Change our an global labor density before so we have.",
            "I have multiplied by P of X&Q undivided by P of X and I have multiplied by key of X and divided by key events.",
            "So the first time.",
            "Converges to the.",
            "Today Kaylie divergance.",
            "I show you before that this.",
            "Is this evidence potential distribution?",
            "This one is also distributed aspirational distribution, so they cancel each other out when the number of samples tend to Infinity.",
            "Alright, and then although the convergence here is in probability.",
            "If you have a sum of random Brother converge in probability, a commercial mostly."
        ],
        [
            "And then I have a few examples.",
            "In which we show.",
            "The convergence."
        ],
        [
            "Then I have another one here, in which what I wanted to show here is that using K1 is usually better than using a larger value of K. So the.",
            "This curve over here is for K1 and this one over here is 4.",
            "Kten the same thing here is for K1 and these four K10 and this continues value.",
            "Are they true divergences?",
            "And then finally I want to compare."
        ],
        [
            "Within MMD test that Arthur presented last year to show that although what we're computing is the resurgence.",
            "The test will be very similar to what you can get with them in the test and we have proved this for the end MNIST data set.",
            "Comparing three with the two values.",
            "OK. That's weird."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hello everyone, I'm going to talk about Google labor differences estimation for continuous distribution.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We are going to visit the overview of talk.",
                    "label": 0
                },
                {
                    "sent": "I will.",
                    "label": 0
                },
                {
                    "sent": "First person to problem set up.",
                    "label": 1
                },
                {
                    "sent": "Then I'm going to show their one dimensional solution, which I think is.",
                    "label": 0
                },
                {
                    "sent": "Is more intuitive than the multiple there multiple?",
                    "label": 1
                },
                {
                    "sent": "Multi dimensional solution and then I will end up with some examples.",
                    "label": 0
                },
                {
                    "sent": "I also have a poster over here in case somebody wants more information about it.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so the problem is quite simple.",
                    "label": 0
                },
                {
                    "sent": "We want to estimate the differences between P&Q.",
                    "label": 1
                },
                {
                    "sent": "When?",
                    "label": 1
                },
                {
                    "sent": "And we know that this division's is finite.",
                    "label": 0
                },
                {
                    "sent": "If P is absolutely continuous with respect to keep.",
                    "label": 1
                },
                {
                    "sent": "And we want to estimate this density from a set of samples from P of X and a set of sample of key of X.",
                    "label": 0
                },
                {
                    "sent": "And more important, we want to do this without estimating P of X key of X or the ratio of the two.",
                    "label": 0
                },
                {
                    "sent": "OK, we had these nips.",
                    "label": 0
                },
                {
                    "sent": "We have somebody estimating POS on the radio there waiting between P of XNQ of X.",
                    "label": 0
                },
                {
                    "sent": "Or something it was on Monday, a poster.",
                    "label": 0
                },
                {
                    "sent": "We are not and we will show that our method.",
                    "label": 0
                },
                {
                    "sent": "Converges to estimating the cool bar label density, but we can say that we are using a proxy for P of X&Q of X, but those are not going to converge.",
                    "label": 0
                },
                {
                    "sent": "To the true values.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright.",
                    "label": 0
                },
                {
                    "sent": "So for the 1 dimensional solution we use.",
                    "label": 0
                },
                {
                    "sent": "Their cumulative distribution function, but we're going to use our piecewise continuous approximation to it.",
                    "label": 0
                },
                {
                    "sent": "OK, so we have in the example.",
                    "label": 0
                },
                {
                    "sent": "I think it's easy to see we have the standard one where we have the step function and then we just do a continuous piecewise approximation over it and they were going to estimate the color label.",
                    "label": 0
                },
                {
                    "sent": "Density is just taking a small.",
                    "label": 0
                },
                {
                    "sent": "Delta function around PC and thank you see and XI are the points coming from PC.",
                    "label": 0
                },
                {
                    "sent": "Alright, and we can prove that the convergence is almost surely.",
                    "label": 0
                },
                {
                    "sent": "To the density I mean the divergent between P and Q + 1.",
                    "label": 0
                },
                {
                    "sent": "Well, you could say so, but if you do that, you can say that what we're doing is we're computing on Instagram with one sample per stream.",
                    "label": 0
                },
                {
                    "sent": "What size?",
                    "label": 0
                },
                {
                    "sent": "So the excise are drawn from Pfc Pompey.",
                    "label": 0
                },
                {
                    "sent": "OK. Well, that's the thing.",
                    "label": 0
                },
                {
                    "sent": "They have to be.",
                    "label": 0
                },
                {
                    "sent": "They have to be.",
                    "label": 0
                },
                {
                    "sent": "P has to be continually has to be.",
                    "label": 0
                },
                {
                    "sent": "Absolutely continuous with this vector Q. OK, I mean if you go very far away name will take you lots of thankful to converge this.",
                    "label": 0
                },
                {
                    "sent": "I mean that's the only thing that we have is.",
                    "label": 0
                },
                {
                    "sent": "And I mean I'm going to move on because I'm sure that we can talk about that.",
                    "label": 0
                },
                {
                    "sent": "That's a technicality, but it's not really important.",
                    "label": 0
                },
                {
                    "sent": "It just it will tell you that you will need many, many, many samples to converge.",
                    "label": 0
                },
                {
                    "sent": "But we can do it without me.",
                    "label": 0
                },
                {
                    "sent": "It will take long.",
                    "label": 0
                },
                {
                    "sent": "That's that's the easy way out.",
                    "label": 0
                },
                {
                    "sent": "OK, and we got a new question where estimating an Instagram which has only one sample 1 sample per bin.",
                    "label": 0
                },
                {
                    "sent": "OK, so if the number of bins grows linearly with the number of samples, the history and doesn't converge to the density.",
                    "label": 0
                },
                {
                    "sent": "OK, that's a thing.",
                    "label": 0
                },
                {
                    "sent": "In your token, mention the Noble and logo sheet paper and they have two conditions for an Instagram base of the samples to converge, you need the number of history has to grow sublinearly with animal symbols.",
                    "label": 0
                },
                {
                    "sent": "Excuse me mutually.",
                    "label": 0
                },
                {
                    "sent": "Searching that both of them are continuous and they are absolutely continuous with respect to each other.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the proof.",
                    "label": 0
                },
                {
                    "sent": "Or the cubicle in the proof is noticing that.",
                    "label": 1
                },
                {
                    "sent": "If we, the difference between the true.",
                    "label": 0
                },
                {
                    "sent": "Cumulative distribution and the piecewise linear array using behaves as an exponential distribution.",
                    "label": 0
                },
                {
                    "sent": "Becausw PC's I minus PCs I -- 1 where I suppose that samples are order is 1 divided over N. And the difference between two samples that come from the same distribution?",
                    "label": 0
                },
                {
                    "sent": "They're going to be distributed according to a uniform, and the difference is going to be an exponential distribution.",
                    "label": 1
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, for the multi dimensional solution what we do is instead of using this density this.",
                    "label": 0
                },
                {
                    "sent": "Instead of using.",
                    "label": 0
                },
                {
                    "sent": "This community distribution we do an density estimation using the K nearest neighbor solution.",
                    "label": 0
                },
                {
                    "sent": "OK, so we measure so the K nearest neighbor solution from XI to all the possible points in XIF XI an from the Y from the.",
                    "label": 0
                },
                {
                    "sent": "Sorry from the samples and come from Q.",
                    "label": 0
                },
                {
                    "sent": "Do that XI.",
                    "label": 0
                },
                {
                    "sent": "And then we assume that we have a bowl of radius.",
                    "label": 0
                },
                {
                    "sent": "Of that size and the number of points in each one.",
                    "label": 0
                },
                {
                    "sent": "Alright, so we can show that this is the same case as before.",
                    "label": 0
                },
                {
                    "sent": "We only have 1 sample per bin.",
                    "label": 0
                },
                {
                    "sent": "If we use K equal to 1 and that means that the histogram in this piece of.",
                    "label": 0
                },
                {
                    "sent": "Be hard of K&Q have K they're not going to converge to the density, but we can prove.",
                    "label": 0
                },
                {
                    "sent": "That",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We converge to the.",
                    "label": 0
                },
                {
                    "sent": "To the to the true one, so to true divergences for doing that.",
                    "label": 0
                },
                {
                    "sent": "Well, we show is that P of X the true density divided by P1 of X converges in probability.",
                    "label": 0
                },
                {
                    "sent": "That's a mistake to an exponential distribution of over one, and to see that we first assume that P of X is a dimensional uniform distribution of a given support.",
                    "label": 0
                },
                {
                    "sent": "If we define the set of XI of all the samples that are are close.",
                    "label": 0
                },
                {
                    "sent": "2X I.",
                    "label": 0
                },
                {
                    "sent": "And then we measure this query and distance they are uniformly distributed.",
                    "label": 0
                },
                {
                    "sent": "Which means that the difference between the origin and the first one.",
                    "label": 0
                },
                {
                    "sent": "They are distributed as an exponential distribution.",
                    "label": 0
                },
                {
                    "sent": "OK and then for non uniform the only thing that we need to know is to use the continuity.",
                    "label": 0
                },
                {
                    "sent": "Property then the nearest neighbour will tend to P of X as the number of samples Infinity.",
                    "label": 0
                },
                {
                    "sent": "Alright, so now we can.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Change our an global labor density before so we have.",
                    "label": 0
                },
                {
                    "sent": "I have multiplied by P of X&Q undivided by P of X and I have multiplied by key of X and divided by key events.",
                    "label": 0
                },
                {
                    "sent": "So the first time.",
                    "label": 0
                },
                {
                    "sent": "Converges to the.",
                    "label": 0
                },
                {
                    "sent": "Today Kaylie divergance.",
                    "label": 0
                },
                {
                    "sent": "I show you before that this.",
                    "label": 0
                },
                {
                    "sent": "Is this evidence potential distribution?",
                    "label": 0
                },
                {
                    "sent": "This one is also distributed aspirational distribution, so they cancel each other out when the number of samples tend to Infinity.",
                    "label": 0
                },
                {
                    "sent": "Alright, and then although the convergence here is in probability.",
                    "label": 0
                },
                {
                    "sent": "If you have a sum of random Brother converge in probability, a commercial mostly.",
                    "label": 1
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then I have a few examples.",
                    "label": 0
                },
                {
                    "sent": "In which we show.",
                    "label": 0
                },
                {
                    "sent": "The convergence.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then I have another one here, in which what I wanted to show here is that using K1 is usually better than using a larger value of K. So the.",
                    "label": 0
                },
                {
                    "sent": "This curve over here is for K1 and this one over here is 4.",
                    "label": 0
                },
                {
                    "sent": "Kten the same thing here is for K1 and these four K10 and this continues value.",
                    "label": 0
                },
                {
                    "sent": "Are they true divergences?",
                    "label": 0
                },
                {
                    "sent": "And then finally I want to compare.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Within MMD test that Arthur presented last year to show that although what we're computing is the resurgence.",
                    "label": 0
                },
                {
                    "sent": "The test will be very similar to what you can get with them in the test and we have proved this for the end MNIST data set.",
                    "label": 0
                },
                {
                    "sent": "Comparing three with the two values.",
                    "label": 0
                },
                {
                    "sent": "OK. That's weird.",
                    "label": 0
                }
            ]
        }
    }
}