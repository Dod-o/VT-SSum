{
    "id": "436i77iwj2klnb2g6pafdl6seznxyh5t",
    "title": "THOTH: Neural Translation and Enrichment of Knowledge Bases",
    "info": {
        "author": [
            "Diego Moussallem, Universit\u00e4t Paderborn"
        ],
        "published": "Nov. 27, 2019",
        "recorded": "October 2019",
        "category": [
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/iswc2019_moussallem_enrichment_knowledge_bases/",
    "segmentation": [
        [
            "Hi everybody actually going to talk about to Hooters and Euro translation enrichment of knowledge graphs.",
            "It's a work done by me and my colleagues actually to Tomaso and my supervisor Axel."
        ],
        [
            "So I.",
            "That's what we produce every day on the web.",
            "It's more than 2.5 exabytes per day."
        ],
        [
            "But actually most of this information is available in English, so an."
        ],
        [
            "It's reflected in the semantic web.",
            "I mean, that's the DV.",
            "Pedia language chapters.",
            "And we you can see that English is the biggest one.",
            "I mean, is the largest one.",
            "So."
        ],
        [
            "How can we support multilinguality adoption of knowledge graphs across all these companies and universities and applications so?"
        ],
        [
            "We can work on Knowledge Graph translation but.",
            "What it has been done so far, I mean.",
            "How people have been doing researchers.",
            "They have been applying localization which doesn't consider the graph structure and it only translates labels so.",
            "The most important part is the graph structure, because it applies to the disambiguation.",
            "So suppose you have some I mean the same written form like Omar Graphes and you need to simulate them and these the edges will be very important."
        ],
        [
            "So for example, this is for a language basically arise, so we're not talking about wiki data or for example Bible net.",
            "So here we are talking about for example DB pedia or another one which language based.",
            "So, for example, suppose we have here United Kingdom.",
            "We have the label 19 Kid Kingdom and we want to apply localization and it's for hygiene.",
            "It's qualifies in German, but this just translated the label and the UI remains the same.",
            "But it's wrong because it exists in the German.",
            "Version so how we can overcome this?",
            "We"
        ],
        [
            "Again.",
            "Create a translation approach which considers the graph structure while translating labels.",
            "So for this we created the hood.",
            "But before talking about So what I have to say that this is not for releasing a gold standard knowledge graph.",
            "It's for trying to alleviate some problems because most of the NLP applications are in English and so we need which are knowledge, the ones which are knowledge graph based.",
            "And I mean somebody wants to port this for German, Spanish, Italian, African, Telugu or whatever language so to which is for supporting these."
        ],
        [
            "And it's based on 2 main components.",
            "Yeah, the 1st is a newer machine translation.",
            "I will not get into details because it would be so much time.",
            "Takes so much time.",
            "For example this.",
            "But basically it's a composed by encoding decoder.",
            "The encoder is.",
            "Encodes the source sentence.",
            "The decoder decodes the source centers in the in the target language and for training you need a parallel bilingual corpora so it can be text.",
            "But for in our case it will be triples and text and it generates.",
            "The translation output."
        ],
        [
            "And the second component is a knowledge graph.",
            "Embeddings, basically to works as a word beddings, but for representing entities and relations in a vector space.",
            "So here you can see entities in different types, I mean four different types."
        ],
        [
            "So now I'm going to talk about the hoot is basically given that knowledge graphs are composed of facts extracted from text.",
            "We can port me a sentence, I mean as text where your eyes are tokens an.",
            "I mean everything is tokens.",
            "I mean are tokens.",
            "So we can train the neural machine translation model and translate facts from one language to another.",
            "So, so it is divided like a translation problem.",
            "It will have a training and I have a translation.",
            "I mean the test.",
            "So for this I have a source knowledge base, a target knowledge base, but we need bilingual knowledge between them and we extract this bilingual knowledge and we train a triple based neural network model and for translating their labels we have the.",
            "Bilingual generic corpora acquired in the web from the web so.",
            "But I'm going to talk about deeply about, I mean each part how the training and the translation you have.",
            "For example, the source KB you have English and you want to translate in German.",
            "But we already have the German, but you just want to enrich with the English connections and labels.",
            "So."
        ],
        [
            "That's how the training works.",
            "We have a spark query.",
            "I mean, that's the overview.",
            "Let's go step by step."
        ],
        [
            "So here you have the.",
            "You have this park aquarium.",
            "You have a triple store with the English and the German knowledge base.",
            "And once you perform a sparkleberry mean simple one."
        ],
        [
            "Like this to get subject and object which has which have same as in common.",
            "I mean as a predicate, but the predicate must not be same as it has to be another.",
            "I mean capital birthday, place something and need to return."
        ],
        [
            "Sorry.",
            "What happened, yeah?"
        ],
        [
            "So it returns like this English, German, English in German.",
            "I mean they are aligned, which is a very important thing for training a translation model.",
            "Anne."
        ],
        [
            "After that first we get the triples with subject, predicate and object and after that we get the labels of them.",
            "I mean for these New Zealand have NZ an NOI Zealand will have noisy and for German of course and."
        ],
        [
            "OK, after having the bilingual knowledge we split.",
            "I mean, we apply processing techniques to divide in the OK, subject, predicate and object and subject, predicate and labels.",
            "And for then we create a knowledge graph.",
            "Embeddings.",
            "I mean combining all of them.",
            "We have the triples with objects and we get the labels and enrich the vector with the literals.",
            "So and then we use these two concatenating both neural network models.",
            "But for training, the tax base will have these and then you can say they agree this is like a localization for translating labels.",
            "No, it's not because the the Knowledge Graph is with the Knowledge graph embedding and this is connected.",
            "I mean concatenated in the.",
            "Hidden layer so.",
            "That's a is different, so we consider an OK and these triples which objects they are used for.",
            "Training the triple based model.",
            "And then the training happens."
        ],
        [
            "So in the translation step I mean the test phase you have, for example 22 triples with one with object, another with the label.",
            "Very simple script that straightforward that you divide OK.",
            "This is with objects and this is with the label the label comes to the text based and here we put a placeholder which refers to these and this is different as I said from localization, I mean the current applying, I mean the current.",
            "Localization approach, because here there is a connection.",
            "Between them and then we can translate these two noisy land and put back in the triple so and we have these.",
            "I mean, the translator tip triples in German, for example."
        ],
        [
            "And then for evaluating these and to answer the following three questions, can euro networks along with knowledge graph embeddings, supported through translation of knowledge graph.",
            "Let's see and the 2nd is.",
            "How accurate are the triples generated by to hoot and the third one is if these artificially enriched knowledge graph can improve some NLP techniques.",
            "For example, interlinking recognition, generation, translation.",
            "And so forth.",
            "And but for evaluating these, we divided in our evaluation in a threefold manner.",
            "It's a translation quality.",
            "Ex recently on two tasks, fact validation and entity linking an.",
            "After that we performed a manual evaluation.",
            "See if the translation is makes sense."
        ],
        [
            "So for the experimental setup we use open and empty the Python version.",
            "We would fight some things for concatenating the Knowledge Graph embeddings, but you can find it on GitHub.",
            "That's OK. Now we get to the Knowledge Graph was DVP there we chose English in German.",
            "I know that German is big enough, but we had to choose German to show that it makes sense because there are benchmarking's in German more than others languages, at least for this task, OK?",
            "And OK, the English is 4 million entities, 600 relations, 2 million labels.",
            "the German 1 million.",
            "And OK, this is the most important part.",
            "It is by Limbo training with 300,000 service checked relation.",
            "And it's almost 1 million triples with enough for training neural network for this task and the knowledge graph we computed many.",
            "I mean we perform evaluation on different ones like complexity hole.",
            "And but we came up with Fasttext, which performed better than others and the dimension.",
            "OK, that started the settings you."
        ],
        [
            "Find more information on the paper.",
            "So let's go to the translation task with you.",
            "We use the benchmark.",
            "I mean that or which test set, remember that."
        ],
        [
            "Bilingual training we divide."
        ],
        [
            "In oops.",
            "In 8% training the development and test and these, we use this test.",
            "10% of the lingo as a test set an evaluation, I mean the measure was blur, which is a standard in machine."
        ],
        [
            "Translation OK, and the goal.",
            "The fact validation we use multilingual fact bench to 375% effects is just to evaluate the completeness of that route.",
            "Generated ripples.",
            "The evaluation measure was accuracy and we competed on this really."
        ],
        [
            "The NLP task was entity linking.",
            "We compare.",
            "I mean, we experimented the performance of Meguire using the German.",
            "The original German DVD ended.",
            "Who's German DB pedia?",
            "And we use the zurb you debate, the baseline was Megaforce, evaluation was microphone measure.",
            "I mean we chose magazine which languages because it's a deterministic algorithm.",
            "It doesn't require any training, and it we could have always really quickly and the German datasets folks around and German abstract.",
            "And there's the full set."
        ],
        [
            "Things OK, that are the results.",
            "The translation curious is subject is really nice predicates in really nice objects.",
            "92 weed high OK and it dropped here in the triples here.",
            "I'm going to talk about this in a manner evaluation.",
            "And but we could answer the first one which supports the full translation of knowledge."
        ],
        [
            "Says the second one.",
            "It was fact validation.",
            "You can see that the which is the blue and the original is yellow and OK for our predicates.",
            "I mean predicates to hit contributed a lot.",
            "I mean generated many triples on these relation birthplace and death place.",
            "Not too much, but it's two.",
            "But this is related to the the harvesting of.",
            "Data from the Wikipedia to DB Pedia and leader to have contributed to Zalatan staring as well so we could answer the second research question."
        ],
        [
            "The third one was NLP task.",
            "We got the mag with the original DB Pedia and Meg with the hoot.",
            "This is our with original dividia and this is really OK. You topic and then we analyze these manually because it's almost 1.0 F measure.",
            "And we could see that those benchmarks were based on the English.",
            "So when we translated from English to German, the connections were there and we could then be with quite easily.",
            "So that's why it's really high.",
            "But for these these are really recent research, and I mean it's a benchmark data set in German and OK.",
            "It reflects the real case.",
            "I mean we OK we improved, but not so like 1.0 not 100%.",
            "But as you know it improves NLP.",
            "I mean for entertaining."
        ],
        [
            "And OK, remember that there I said, OK, the triples dropped a lot and 68.83% in comparison to, for example, 93% of the object or subject.",
            "And we could say that it's why because?",
            "When it happens, for example, this is the reference and went to whose output these.",
            "This is Qu\u00e9bec and invest multi is in Qu\u00e9bec, but it's not.",
            "I mean it was not here and it this was not present in the training.",
            "So it's fascinating because the neural network could generate zombie grated you are I.",
            "It's very very interesting, but we compute this at zero because for computing the translation quality, if it's not exact match we score of 0.",
            "So it what happens here, it's intriguing.",
            "Another example like oversized and citizenship Switzerland and to its generated birthplace.",
            "Why?",
            "Because in the knowledge graph vector space I mean the in vector space, the knowledge graph embedding vector space, citizenship, an birthplace they they are basically over each other because the domain is the same, the range is the same, so it couldn't disambiguate.",
            "I mean in this point, but we have investigated different knowledge graph embeddings and we could.",
            "Come up with a solution, but it will be another submission to a Journal track because it requires much more analysis.",
            "But both are really very interesting."
        ],
        [
            "So.",
            "The summary Torhout active overall 888.56, which is a overall considering the triples and the only subject only predicates and only object.",
            "It improved on fact validation around almost 20% entity linking as well and what next to resolve the situation of the intriguing we plan to apply oops subgraphs.",
            "Within the Knowledge Graph embeddings exploit order in neural network architecture like Transformer, Excel, net.",
            "In others.",
            "And graph based attention.",
            "I mean graph attention, neural networks and so on and so forth.",
            "An investigate different knowledge graph embeds with have has been doing.",
            "I mean, we have been doing this."
        ],
        [
            "Yeah, and that's all.",
            "Thank you.",
            "Can you discuss their relationship to Wiki data which is of multilingual to start with and you have multilingual labels for all the items, the properties?",
            "So in a sense you don't have this problem, or do you know, for example, in the?",
            "In this case, I mean the beginning, let's go.",
            "Yeah, we don't have this problem because we could.",
            "Data is based on numbers an only.",
            "I mean it's numeric ID and so it remains the same and only which changes are the labels.",
            "But still they we can treat this as tokens and we actually applied the same thing on weekday to Yahoo and Barnett and we could get some improvements as well.",
            "But for as a first analysis we applied on language basically arise.",
            "Ann and see that how I mean, try to see how it would perform and but we it's portable two week data, but therefore at first glance I mean we could try to make this analysis on language based to your eyes.",
            "I mean the thing I I don't understand is perhaps because I don't understand the multilingual DB PDS is I mean why do you need to solve this problem?",
            "If Wiki data has already solved it?",
            "No, it's not to resolve or solve.",
            "The problem is to port the knowledge.",
            "For example, even weak data they have more content in English than in others.",
            "Other chapters, but weak data is moved to Limbo deep.",
            "It is booty lingo as well, but the pedia is divided in chapters which are connected by same as wiki data.",
            "They are mucho lingo and they the labels are within the same graph.",
            "But much contents are only available in English.",
            "For example, some cultural stuff, some some things.",
            "And the idea is to translate the labels as well as their relations and enrich.",
            "Yeah, if you open I can open up that we can data.",
            "Wikipedia pages in all the languages.",
            "Yeah.",
            "All the labels with all the languages for the same.",
            "I think yeah, but let's not only think about DBPR wiki data.",
            "Let's think about some domain specific knowledge graph for Inter prize knowledge graph.",
            "The idea is to port the knowledge from one knowledge graph to another or enrich them.",
            "Anne, try to to come up with some solution, alleviate the problem of.",
            "Only English yet.",
            "For example, if you access some some entities, they are only key data.",
            "Most of the country in English in French, but for example Portuguese and Spanish.",
            "Yeah, you can access and see.",
            "Yeah, if you allow me to jump in the conversation you were presenting the way you were using the link the same as link that you have on the job because it's separated by chapters too.",
            "You know, discover and then after enrich.",
            "But maybe I mean what you are suggesting is that with the data you don't have to do that because you already have everything like in the molecules are already available.",
            "So what would be then the shape of the sparkle query and the because you you have you are using the same as a trick you know to to link together and stuff so we could get from the language tag and we could get some I mean.",
            "But my question is like if we stop considering easier depending on which data and jump on those are like kind of data set that would be available then how would you?",
            "Bootstrap the process because you will be trapped in a language tag.",
            "For example in the the.",
            "In the literal, who have had an English or at German I we could start by searching through this.",
            "Yeah.",
            "Time for one last question.",
            "OK, so then we can close this session.",
            "Thank you very much again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi everybody actually going to talk about to Hooters and Euro translation enrichment of knowledge graphs.",
                    "label": 0
                },
                {
                    "sent": "It's a work done by me and my colleagues actually to Tomaso and my supervisor Axel.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I.",
                    "label": 0
                },
                {
                    "sent": "That's what we produce every day on the web.",
                    "label": 0
                },
                {
                    "sent": "It's more than 2.5 exabytes per day.",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But actually most of this information is available in English, so an.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's reflected in the semantic web.",
                    "label": 0
                },
                {
                    "sent": "I mean, that's the DV.",
                    "label": 0
                },
                {
                    "sent": "Pedia language chapters.",
                    "label": 0
                },
                {
                    "sent": "And we you can see that English is the biggest one.",
                    "label": 0
                },
                {
                    "sent": "I mean, is the largest one.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How can we support multilinguality adoption of knowledge graphs across all these companies and universities and applications so?",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We can work on Knowledge Graph translation but.",
                    "label": 0
                },
                {
                    "sent": "What it has been done so far, I mean.",
                    "label": 1
                },
                {
                    "sent": "How people have been doing researchers.",
                    "label": 0
                },
                {
                    "sent": "They have been applying localization which doesn't consider the graph structure and it only translates labels so.",
                    "label": 0
                },
                {
                    "sent": "The most important part is the graph structure, because it applies to the disambiguation.",
                    "label": 0
                },
                {
                    "sent": "So suppose you have some I mean the same written form like Omar Graphes and you need to simulate them and these the edges will be very important.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for example, this is for a language basically arise, so we're not talking about wiki data or for example Bible net.",
                    "label": 0
                },
                {
                    "sent": "So here we are talking about for example DB pedia or another one which language based.",
                    "label": 0
                },
                {
                    "sent": "So, for example, suppose we have here United Kingdom.",
                    "label": 0
                },
                {
                    "sent": "We have the label 19 Kid Kingdom and we want to apply localization and it's for hygiene.",
                    "label": 0
                },
                {
                    "sent": "It's qualifies in German, but this just translated the label and the UI remains the same.",
                    "label": 0
                },
                {
                    "sent": "But it's wrong because it exists in the German.",
                    "label": 0
                },
                {
                    "sent": "Version so how we can overcome this?",
                    "label": 0
                },
                {
                    "sent": "We",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Again.",
                    "label": 0
                },
                {
                    "sent": "Create a translation approach which considers the graph structure while translating labels.",
                    "label": 1
                },
                {
                    "sent": "So for this we created the hood.",
                    "label": 0
                },
                {
                    "sent": "But before talking about So what I have to say that this is not for releasing a gold standard knowledge graph.",
                    "label": 0
                },
                {
                    "sent": "It's for trying to alleviate some problems because most of the NLP applications are in English and so we need which are knowledge, the ones which are knowledge graph based.",
                    "label": 0
                },
                {
                    "sent": "And I mean somebody wants to port this for German, Spanish, Italian, African, Telugu or whatever language so to which is for supporting these.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And it's based on 2 main components.",
                    "label": 1
                },
                {
                    "sent": "Yeah, the 1st is a newer machine translation.",
                    "label": 1
                },
                {
                    "sent": "I will not get into details because it would be so much time.",
                    "label": 0
                },
                {
                    "sent": "Takes so much time.",
                    "label": 0
                },
                {
                    "sent": "For example this.",
                    "label": 0
                },
                {
                    "sent": "But basically it's a composed by encoding decoder.",
                    "label": 0
                },
                {
                    "sent": "The encoder is.",
                    "label": 0
                },
                {
                    "sent": "Encodes the source sentence.",
                    "label": 0
                },
                {
                    "sent": "The decoder decodes the source centers in the in the target language and for training you need a parallel bilingual corpora so it can be text.",
                    "label": 0
                },
                {
                    "sent": "But for in our case it will be triples and text and it generates.",
                    "label": 0
                },
                {
                    "sent": "The translation output.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the second component is a knowledge graph.",
                    "label": 1
                },
                {
                    "sent": "Embeddings, basically to works as a word beddings, but for representing entities and relations in a vector space.",
                    "label": 0
                },
                {
                    "sent": "So here you can see entities in different types, I mean four different types.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now I'm going to talk about the hoot is basically given that knowledge graphs are composed of facts extracted from text.",
                    "label": 1
                },
                {
                    "sent": "We can port me a sentence, I mean as text where your eyes are tokens an.",
                    "label": 0
                },
                {
                    "sent": "I mean everything is tokens.",
                    "label": 0
                },
                {
                    "sent": "I mean are tokens.",
                    "label": 1
                },
                {
                    "sent": "So we can train the neural machine translation model and translate facts from one language to another.",
                    "label": 0
                },
                {
                    "sent": "So, so it is divided like a translation problem.",
                    "label": 0
                },
                {
                    "sent": "It will have a training and I have a translation.",
                    "label": 0
                },
                {
                    "sent": "I mean the test.",
                    "label": 0
                },
                {
                    "sent": "So for this I have a source knowledge base, a target knowledge base, but we need bilingual knowledge between them and we extract this bilingual knowledge and we train a triple based neural network model and for translating their labels we have the.",
                    "label": 0
                },
                {
                    "sent": "Bilingual generic corpora acquired in the web from the web so.",
                    "label": 0
                },
                {
                    "sent": "But I'm going to talk about deeply about, I mean each part how the training and the translation you have.",
                    "label": 0
                },
                {
                    "sent": "For example, the source KB you have English and you want to translate in German.",
                    "label": 0
                },
                {
                    "sent": "But we already have the German, but you just want to enrich with the English connections and labels.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's how the training works.",
                    "label": 0
                },
                {
                    "sent": "We have a spark query.",
                    "label": 0
                },
                {
                    "sent": "I mean, that's the overview.",
                    "label": 0
                },
                {
                    "sent": "Let's go step by step.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here you have the.",
                    "label": 0
                },
                {
                    "sent": "You have this park aquarium.",
                    "label": 0
                },
                {
                    "sent": "You have a triple store with the English and the German knowledge base.",
                    "label": 0
                },
                {
                    "sent": "And once you perform a sparkleberry mean simple one.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Like this to get subject and object which has which have same as in common.",
                    "label": 0
                },
                {
                    "sent": "I mean as a predicate, but the predicate must not be same as it has to be another.",
                    "label": 0
                },
                {
                    "sent": "I mean capital birthday, place something and need to return.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "What happened, yeah?",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So it returns like this English, German, English in German.",
                    "label": 0
                },
                {
                    "sent": "I mean they are aligned, which is a very important thing for training a translation model.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "After that first we get the triples with subject, predicate and object and after that we get the labels of them.",
                    "label": 0
                },
                {
                    "sent": "I mean for these New Zealand have NZ an NOI Zealand will have noisy and for German of course and.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, after having the bilingual knowledge we split.",
                    "label": 0
                },
                {
                    "sent": "I mean, we apply processing techniques to divide in the OK, subject, predicate and object and subject, predicate and labels.",
                    "label": 0
                },
                {
                    "sent": "And for then we create a knowledge graph.",
                    "label": 0
                },
                {
                    "sent": "Embeddings.",
                    "label": 0
                },
                {
                    "sent": "I mean combining all of them.",
                    "label": 0
                },
                {
                    "sent": "We have the triples with objects and we get the labels and enrich the vector with the literals.",
                    "label": 0
                },
                {
                    "sent": "So and then we use these two concatenating both neural network models.",
                    "label": 0
                },
                {
                    "sent": "But for training, the tax base will have these and then you can say they agree this is like a localization for translating labels.",
                    "label": 0
                },
                {
                    "sent": "No, it's not because the the Knowledge Graph is with the Knowledge graph embedding and this is connected.",
                    "label": 0
                },
                {
                    "sent": "I mean concatenated in the.",
                    "label": 0
                },
                {
                    "sent": "Hidden layer so.",
                    "label": 0
                },
                {
                    "sent": "That's a is different, so we consider an OK and these triples which objects they are used for.",
                    "label": 0
                },
                {
                    "sent": "Training the triple based model.",
                    "label": 0
                },
                {
                    "sent": "And then the training happens.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in the translation step I mean the test phase you have, for example 22 triples with one with object, another with the label.",
                    "label": 0
                },
                {
                    "sent": "Very simple script that straightforward that you divide OK.",
                    "label": 0
                },
                {
                    "sent": "This is with objects and this is with the label the label comes to the text based and here we put a placeholder which refers to these and this is different as I said from localization, I mean the current applying, I mean the current.",
                    "label": 0
                },
                {
                    "sent": "Localization approach, because here there is a connection.",
                    "label": 0
                },
                {
                    "sent": "Between them and then we can translate these two noisy land and put back in the triple so and we have these.",
                    "label": 0
                },
                {
                    "sent": "I mean, the translator tip triples in German, for example.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then for evaluating these and to answer the following three questions, can euro networks along with knowledge graph embeddings, supported through translation of knowledge graph.",
                    "label": 1
                },
                {
                    "sent": "Let's see and the 2nd is.",
                    "label": 0
                },
                {
                    "sent": "How accurate are the triples generated by to hoot and the third one is if these artificially enriched knowledge graph can improve some NLP techniques.",
                    "label": 1
                },
                {
                    "sent": "For example, interlinking recognition, generation, translation.",
                    "label": 0
                },
                {
                    "sent": "And so forth.",
                    "label": 0
                },
                {
                    "sent": "And but for evaluating these, we divided in our evaluation in a threefold manner.",
                    "label": 0
                },
                {
                    "sent": "It's a translation quality.",
                    "label": 0
                },
                {
                    "sent": "Ex recently on two tasks, fact validation and entity linking an.",
                    "label": 1
                },
                {
                    "sent": "After that we performed a manual evaluation.",
                    "label": 0
                },
                {
                    "sent": "See if the translation is makes sense.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for the experimental setup we use open and empty the Python version.",
                    "label": 0
                },
                {
                    "sent": "We would fight some things for concatenating the Knowledge Graph embeddings, but you can find it on GitHub.",
                    "label": 0
                },
                {
                    "sent": "That's OK. Now we get to the Knowledge Graph was DVP there we chose English in German.",
                    "label": 0
                },
                {
                    "sent": "I know that German is big enough, but we had to choose German to show that it makes sense because there are benchmarking's in German more than others languages, at least for this task, OK?",
                    "label": 0
                },
                {
                    "sent": "And OK, the English is 4 million entities, 600 relations, 2 million labels.",
                    "label": 0
                },
                {
                    "sent": "the German 1 million.",
                    "label": 0
                },
                {
                    "sent": "And OK, this is the most important part.",
                    "label": 0
                },
                {
                    "sent": "It is by Limbo training with 300,000 service checked relation.",
                    "label": 0
                },
                {
                    "sent": "And it's almost 1 million triples with enough for training neural network for this task and the knowledge graph we computed many.",
                    "label": 0
                },
                {
                    "sent": "I mean we perform evaluation on different ones like complexity hole.",
                    "label": 0
                },
                {
                    "sent": "And but we came up with Fasttext, which performed better than others and the dimension.",
                    "label": 0
                },
                {
                    "sent": "OK, that started the settings you.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Find more information on the paper.",
                    "label": 0
                },
                {
                    "sent": "So let's go to the translation task with you.",
                    "label": 0
                },
                {
                    "sent": "We use the benchmark.",
                    "label": 0
                },
                {
                    "sent": "I mean that or which test set, remember that.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Bilingual training we divide.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In oops.",
                    "label": 0
                },
                {
                    "sent": "In 8% training the development and test and these, we use this test.",
                    "label": 0
                },
                {
                    "sent": "10% of the lingo as a test set an evaluation, I mean the measure was blur, which is a standard in machine.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Translation OK, and the goal.",
                    "label": 0
                },
                {
                    "sent": "The fact validation we use multilingual fact bench to 375% effects is just to evaluate the completeness of that route.",
                    "label": 1
                },
                {
                    "sent": "Generated ripples.",
                    "label": 1
                },
                {
                    "sent": "The evaluation measure was accuracy and we competed on this really.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The NLP task was entity linking.",
                    "label": 0
                },
                {
                    "sent": "We compare.",
                    "label": 0
                },
                {
                    "sent": "I mean, we experimented the performance of Meguire using the German.",
                    "label": 1
                },
                {
                    "sent": "The original German DVD ended.",
                    "label": 0
                },
                {
                    "sent": "Who's German DB pedia?",
                    "label": 0
                },
                {
                    "sent": "And we use the zurb you debate, the baseline was Megaforce, evaluation was microphone measure.",
                    "label": 0
                },
                {
                    "sent": "I mean we chose magazine which languages because it's a deterministic algorithm.",
                    "label": 1
                },
                {
                    "sent": "It doesn't require any training, and it we could have always really quickly and the German datasets folks around and German abstract.",
                    "label": 0
                },
                {
                    "sent": "And there's the full set.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Things OK, that are the results.",
                    "label": 0
                },
                {
                    "sent": "The translation curious is subject is really nice predicates in really nice objects.",
                    "label": 0
                },
                {
                    "sent": "92 weed high OK and it dropped here in the triples here.",
                    "label": 0
                },
                {
                    "sent": "I'm going to talk about this in a manner evaluation.",
                    "label": 0
                },
                {
                    "sent": "And but we could answer the first one which supports the full translation of knowledge.",
                    "label": 1
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Says the second one.",
                    "label": 0
                },
                {
                    "sent": "It was fact validation.",
                    "label": 0
                },
                {
                    "sent": "You can see that the which is the blue and the original is yellow and OK for our predicates.",
                    "label": 0
                },
                {
                    "sent": "I mean predicates to hit contributed a lot.",
                    "label": 0
                },
                {
                    "sent": "I mean generated many triples on these relation birthplace and death place.",
                    "label": 0
                },
                {
                    "sent": "Not too much, but it's two.",
                    "label": 0
                },
                {
                    "sent": "But this is related to the the harvesting of.",
                    "label": 0
                },
                {
                    "sent": "Data from the Wikipedia to DB Pedia and leader to have contributed to Zalatan staring as well so we could answer the second research question.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The third one was NLP task.",
                    "label": 1
                },
                {
                    "sent": "We got the mag with the original DB Pedia and Meg with the hoot.",
                    "label": 0
                },
                {
                    "sent": "This is our with original dividia and this is really OK. You topic and then we analyze these manually because it's almost 1.0 F measure.",
                    "label": 0
                },
                {
                    "sent": "And we could see that those benchmarks were based on the English.",
                    "label": 0
                },
                {
                    "sent": "So when we translated from English to German, the connections were there and we could then be with quite easily.",
                    "label": 0
                },
                {
                    "sent": "So that's why it's really high.",
                    "label": 0
                },
                {
                    "sent": "But for these these are really recent research, and I mean it's a benchmark data set in German and OK.",
                    "label": 0
                },
                {
                    "sent": "It reflects the real case.",
                    "label": 0
                },
                {
                    "sent": "I mean we OK we improved, but not so like 1.0 not 100%.",
                    "label": 0
                },
                {
                    "sent": "But as you know it improves NLP.",
                    "label": 0
                },
                {
                    "sent": "I mean for entertaining.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And OK, remember that there I said, OK, the triples dropped a lot and 68.83% in comparison to, for example, 93% of the object or subject.",
                    "label": 0
                },
                {
                    "sent": "And we could say that it's why because?",
                    "label": 0
                },
                {
                    "sent": "When it happens, for example, this is the reference and went to whose output these.",
                    "label": 0
                },
                {
                    "sent": "This is Qu\u00e9bec and invest multi is in Qu\u00e9bec, but it's not.",
                    "label": 0
                },
                {
                    "sent": "I mean it was not here and it this was not present in the training.",
                    "label": 0
                },
                {
                    "sent": "So it's fascinating because the neural network could generate zombie grated you are I.",
                    "label": 0
                },
                {
                    "sent": "It's very very interesting, but we compute this at zero because for computing the translation quality, if it's not exact match we score of 0.",
                    "label": 0
                },
                {
                    "sent": "So it what happens here, it's intriguing.",
                    "label": 0
                },
                {
                    "sent": "Another example like oversized and citizenship Switzerland and to its generated birthplace.",
                    "label": 0
                },
                {
                    "sent": "Why?",
                    "label": 0
                },
                {
                    "sent": "Because in the knowledge graph vector space I mean the in vector space, the knowledge graph embedding vector space, citizenship, an birthplace they they are basically over each other because the domain is the same, the range is the same, so it couldn't disambiguate.",
                    "label": 0
                },
                {
                    "sent": "I mean in this point, but we have investigated different knowledge graph embeddings and we could.",
                    "label": 0
                },
                {
                    "sent": "Come up with a solution, but it will be another submission to a Journal track because it requires much more analysis.",
                    "label": 0
                },
                {
                    "sent": "But both are really very interesting.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The summary Torhout active overall 888.56, which is a overall considering the triples and the only subject only predicates and only object.",
                    "label": 0
                },
                {
                    "sent": "It improved on fact validation around almost 20% entity linking as well and what next to resolve the situation of the intriguing we plan to apply oops subgraphs.",
                    "label": 1
                },
                {
                    "sent": "Within the Knowledge Graph embeddings exploit order in neural network architecture like Transformer, Excel, net.",
                    "label": 0
                },
                {
                    "sent": "In others.",
                    "label": 0
                },
                {
                    "sent": "And graph based attention.",
                    "label": 0
                },
                {
                    "sent": "I mean graph attention, neural networks and so on and so forth.",
                    "label": 1
                },
                {
                    "sent": "An investigate different knowledge graph embeds with have has been doing.",
                    "label": 0
                },
                {
                    "sent": "I mean, we have been doing this.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, and that's all.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Can you discuss their relationship to Wiki data which is of multilingual to start with and you have multilingual labels for all the items, the properties?",
                    "label": 0
                },
                {
                    "sent": "So in a sense you don't have this problem, or do you know, for example, in the?",
                    "label": 0
                },
                {
                    "sent": "In this case, I mean the beginning, let's go.",
                    "label": 0
                },
                {
                    "sent": "Yeah, we don't have this problem because we could.",
                    "label": 0
                },
                {
                    "sent": "Data is based on numbers an only.",
                    "label": 0
                },
                {
                    "sent": "I mean it's numeric ID and so it remains the same and only which changes are the labels.",
                    "label": 0
                },
                {
                    "sent": "But still they we can treat this as tokens and we actually applied the same thing on weekday to Yahoo and Barnett and we could get some improvements as well.",
                    "label": 0
                },
                {
                    "sent": "But for as a first analysis we applied on language basically arise.",
                    "label": 0
                },
                {
                    "sent": "Ann and see that how I mean, try to see how it would perform and but we it's portable two week data, but therefore at first glance I mean we could try to make this analysis on language based to your eyes.",
                    "label": 0
                },
                {
                    "sent": "I mean the thing I I don't understand is perhaps because I don't understand the multilingual DB PDS is I mean why do you need to solve this problem?",
                    "label": 0
                },
                {
                    "sent": "If Wiki data has already solved it?",
                    "label": 0
                },
                {
                    "sent": "No, it's not to resolve or solve.",
                    "label": 0
                },
                {
                    "sent": "The problem is to port the knowledge.",
                    "label": 0
                },
                {
                    "sent": "For example, even weak data they have more content in English than in others.",
                    "label": 0
                },
                {
                    "sent": "Other chapters, but weak data is moved to Limbo deep.",
                    "label": 0
                },
                {
                    "sent": "It is booty lingo as well, but the pedia is divided in chapters which are connected by same as wiki data.",
                    "label": 0
                },
                {
                    "sent": "They are mucho lingo and they the labels are within the same graph.",
                    "label": 0
                },
                {
                    "sent": "But much contents are only available in English.",
                    "label": 0
                },
                {
                    "sent": "For example, some cultural stuff, some some things.",
                    "label": 0
                },
                {
                    "sent": "And the idea is to translate the labels as well as their relations and enrich.",
                    "label": 0
                },
                {
                    "sent": "Yeah, if you open I can open up that we can data.",
                    "label": 0
                },
                {
                    "sent": "Wikipedia pages in all the languages.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "All the labels with all the languages for the same.",
                    "label": 0
                },
                {
                    "sent": "I think yeah, but let's not only think about DBPR wiki data.",
                    "label": 0
                },
                {
                    "sent": "Let's think about some domain specific knowledge graph for Inter prize knowledge graph.",
                    "label": 0
                },
                {
                    "sent": "The idea is to port the knowledge from one knowledge graph to another or enrich them.",
                    "label": 0
                },
                {
                    "sent": "Anne, try to to come up with some solution, alleviate the problem of.",
                    "label": 0
                },
                {
                    "sent": "Only English yet.",
                    "label": 0
                },
                {
                    "sent": "For example, if you access some some entities, they are only key data.",
                    "label": 0
                },
                {
                    "sent": "Most of the country in English in French, but for example Portuguese and Spanish.",
                    "label": 0
                },
                {
                    "sent": "Yeah, you can access and see.",
                    "label": 0
                },
                {
                    "sent": "Yeah, if you allow me to jump in the conversation you were presenting the way you were using the link the same as link that you have on the job because it's separated by chapters too.",
                    "label": 0
                },
                {
                    "sent": "You know, discover and then after enrich.",
                    "label": 0
                },
                {
                    "sent": "But maybe I mean what you are suggesting is that with the data you don't have to do that because you already have everything like in the molecules are already available.",
                    "label": 0
                },
                {
                    "sent": "So what would be then the shape of the sparkle query and the because you you have you are using the same as a trick you know to to link together and stuff so we could get from the language tag and we could get some I mean.",
                    "label": 0
                },
                {
                    "sent": "But my question is like if we stop considering easier depending on which data and jump on those are like kind of data set that would be available then how would you?",
                    "label": 0
                },
                {
                    "sent": "Bootstrap the process because you will be trapped in a language tag.",
                    "label": 0
                },
                {
                    "sent": "For example in the the.",
                    "label": 0
                },
                {
                    "sent": "In the literal, who have had an English or at German I we could start by searching through this.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Time for one last question.",
                    "label": 0
                },
                {
                    "sent": "OK, so then we can close this session.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much again.",
                    "label": 0
                }
            ]
        }
    }
}