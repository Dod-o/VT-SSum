{
    "id": "pepk4o6yql7ltz6wsmfzvyg2q4qd3xqt",
    "title": "Semantic role frames graph-based multidocument summarization",
    "info": {
        "author": [
            "Ercan Canhasi, Faculty of Computer and Information Science, University of Ljubljana"
        ],
        "published": "Nov. 4, 2011",
        "recorded": "October 2011",
        "category": [
            "Top->Computer Science->Text Mining->Document Summarization",
            "Top->Computer Science->Semantic Web",
            "Top->Computer Science->Network Analysis"
        ]
    },
    "url": "http://videolectures.net/sikdd2011_canhasi_multidocument/",
    "segmentation": [
        [
            "Good morning, my name is agents and hussian.",
            "I'm here present to you.",
            "Some recent recent results of my ongoing research work on multi Document Summarization Task shortly MDSM.",
            "This is a process of filtering information for generating the compressed version of."
        ],
        [
            "One set of documents.",
            "Although this is almost half century old research topic, there is still big gap in automatically generated summaries and human written abstracts.",
            "One can with very shallow field reviews showed that the main reason for this gap.",
            "R. Smith, semantically image methods used for taking this kind of hard topic.",
            "So based on this evidence we have defined our goals in this research as showing how wanted to show how is it possible to improve the efficiency of summarization using semantically rich representation and based on this new representation to develop or at least to propose to adopt an existing method for summarization."
        ],
        [
            "As a starting point, in our research we have used.",
            "Approach known as graphviz models for MD's desk.",
            "They have been proposed back in 2004 and in order to give you an.",
            "Overview of how does this methodology work?",
            "I have made up here a simple example where we have two documents and four sentences, two in each document.",
            "Let's say that we want to compute the similarity between the all the pairs of sentences and put the results in similarity metrics from similarity metrics by taking nodes in a graph to be sentences and connection or edges in a graph as similarity measure, which is both some threshold.",
            "We can in this way.",
            "Generate and sentence similarity graph.",
            "Then by employing any kind of note, significance estimator estimating algorithms such as patient vehicle, we can rank nodes according to their significance and by selecting the most important.",
            "And once we can form our summary from this example, you can see that the first sentence has two connections with high similarity with two other sentences, so it's obviously the first sentence is most important one, and it is chosen to represent our our documents as a summer."
        ],
        [
            "No one can see that there are two issues in those kinds of methods.",
            "The first one is the question how to model the set is the set of documents as a text graph and the second one is how to estimate the significance of nodes in generated graph.",
            "In this work we are mainly concentrated on the first question."
        ],
        [
            "So what are the novelties that we propose in this work instead of using sentences as we already saw in previous works instead of using sentences as nodes in a graph, we propose using semantic role frames for edge instead of using a simple.",
            "Word overlap or have questions similarity from vector space model.",
            "Instead of using this kind of shallow similarity measure measurement functions, we propose using semantically enriched similarity methods an for first time.",
            "Our graph generation is based on the cognitive model for text understanding.",
            "For ranking is already said, we have just adopted existing approach which which is the Pagerank algorithm.",
            "What was the exactly motivation for using the semantic role or semantic frame graphs as we already know?",
            "Even that humans do not always agree on the content to be chosen to represent the set of documents they perform very well on this task.",
            "So therefore we should find a way of mimicking the human kind human.",
            "Cognition behind the process of text reading.",
            "Text understanding.",
            "For this challenge, we have considered using the cognitive model for text understanding, namely the event indexing model."
        ],
        [
            "According to this model.",
            "Human like system while processing documents should keep track on changes on on five different indices or dimensions starting from protagonist temporary information.",
            "Causal locational, an intentional information.",
            "While we were the dealing with the problem of exact extracting this information from a text, we realized that there is 1 to one mapping from semantic role parsers output to event indexing model.",
            "Semantic role parsers are machine learned models able to label part of the sentences which are in direct connection with the predicate.",
            "So for example, for for a sentence such as Christina hit Squad with baseball yesterday.",
            "Antique roll parser will.",
            "Extract following frame, we call this frame where in the center we have a predicate hit and then the arguments connected to predicates such as subject Christina, objects, code location, temporal information yesterday, etc."
        ],
        [
            "SOB.",
            "This marked the summarization method that we propose box in follow case.",
            "You can see from the picture on the slide we start with the documents which are given to the semantic role parser where their semantic frames are extracted from every sentence.",
            "Then we compute composite similarity between the frames extra extracted in the previous step and by using the semantic frame as the nodes and.",
            "Composite similarities edge.",
            "We can we create our frame similarity graph.",
            "On which by using Pagerank algorithm we are ranking notes based on their significance and summing up notes, notes or frame scores.",
            "Page rank scores which are originated from the same sentence.",
            "Since we know that.",
            "Complex sentence can.",
            "Can contain more than one predicate, so there will be more than one.",
            "Paper, paper, sentence.",
            "In this way, we score sentences and then we choose the first or highest incentives depending on the desired length of the summary, and in this way, of course, perform our resulting summary.",
            "Of our graph, modeling is based on two functions, vertex labeling and edge labeling functions.",
            "Alpha and beta functions, Alpha function levels, nodes or age notes.",
            "Based on the completeness of the frame and one frame is considered as complete if it has at least subject object and predicate.",
            "So complete frames are labeled with the value of 1 / N, N is the total number of extracted frames.",
            "An otherwise frames are labeled with the value to over 2 NH function is composite similarity function, which is again.",
            "The define and calculated based on the event indexing model which says that.",
            "The proposed indexes or dimensions are in decreasing order of significance or importance starting from protagonist down to causality.",
            "Those better.",
            "Paramaters, or beta coefficients, are defined to reflect this importance order.",
            "I mean, it's in some way that code defined values, but since this is kind of.",
            "Linear combination of atributes in future.",
            "We would like to experiment with the learning methods of those parameters in this way generated frame similarity matrix is then given to page rank algorithm as input vector H and the result we get rent.",
            "Order of friends."
        ],
        [
            "Here we have some preliminary results.",
            "Since we are still working on this task.",
            "We have tested our.",
            "Method on that is provided by Document Understanding Conference particular data set from 2004 where the task was to.",
            "To summarize, the group of topic related articles, there are 50 groups with ten articles approximately in each group.",
            "And for evaluation we use the tool known as Rose, which is statistical evaluation.",
            "Some Revelation 2 which which is which measures the quality of summary.",
            "By doing some statistics over the number of Co occurrence or word overlaps with between ideal an automatically generated summary.",
            "Also, the results here are not so significantly different.",
            "We are kind of.",
            "Happy with our results because we fulfill our first goal, which was to show that.",
            "We can do better in some in summarizing by using semantically rich textual representation.",
            "Even that in this version of our method we didn't, not we did not use any of summary quality improvement techniques such as sentence reordering or sentence reduction, or in our case, frame merging."
        ],
        [
            "So for a less light, I would like to say some few words about our future work in this work.",
            "As a result, we have presented a novel model for graph based document summarization where we proposed using frame similarity graph.",
            "Which is in some ways similar to the previous one, but it goes deeper in semantic analysts because previous one was just the method of representing sentence similarities.",
            "So we can say that the works up to date are mainly concentrated on homogeneous connections between the sentences, and some reasons work are working on our presenting approach of heterogeneous connections between the sentences and documents.",
            "Uh.",
            "We are now working on an multilayer graph model where we will introduce additional 2 layers to our.",
            "Previous work I mean this one, which I present here by Ed by adding these two layers will get an semantically rich three layered multi layered graph model which will need also be adopted to page rank algorithm which layers.",
            "So we said that we have frame then can sentence and the third one is document.",
            "Since we are dealing with multi document summarization.",
            "This right now it's kind of single document summarization because we are putting them all together.",
            "Questions, so let's say.",
            "Getting these results which you were showing us so and having this similarity function with."
        ],
        [
            "All the terms, can you say which terms contributed?",
            "How much to the result?",
            "Yes, right now we are working on this particular statistical.",
            "Explanation so far of our models because right now I have just implemented the model and tested on the data set.",
            "I didn't do any dips.",
            "Statistical analyzes of of.",
            "OK, so this is I guess, first thing which you should do really understand why you're getting results.",
            "You're getting through the well which which term in this formula Now contributes the most.",
            "In fact they are not terms they can be at the combination of terms because protagonists.",
            "Yes, yeah.",
            "OK, I guess it was also in our To Do List to to think about how we can change also this parameters which are right now very naively chosen based on the event indexing model.",
            "So 1 one question about.",
            "SLR parsers so.",
            "Whenever you do this, semantic role labeling so this process by itself it's not accurate enough.",
            "Yes, it's statistical method.",
            "Yeah, so how accurate the results you get this?",
            "Or how much how much error you introducing for the first step?",
            "This must be also this error.",
            "Propagate through the whole pipeline then so each person was used.",
            "Here I experiment with few ones against the one that I last used.",
            "This something like Hilda or Hitler.",
            "There are plenty of them, and yes, they are performing on let's say around 80% up to 85% precision in in this labeling.",
            "And now the questions.",
            "So maybe just a comment.",
            "So you said that this is normal.",
            "So I mean the summarization based on this semantic graph.",
            "So this is this is not so new.",
            "Yeah it is.",
            "As I already said in the beginning, it's almost South Central research topic and it also also.",
            "This summarization itself, but also this semantic graph.",
            "So yes, you could check with a bit more.",
            "The literature, I guess.",
            "This was done already in this area.",
            "We've gone as well.",
            "So yes, since I have already read your your works about triplet extraction, but.",
            "So just be careful on the evaluation side, so that's why.",
            "Start now to discuss.",
            "Approach the keys relation.",
            "What contributes to summarization, whatnot.",
            "OK understood."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Good morning, my name is agents and hussian.",
                    "label": 0
                },
                {
                    "sent": "I'm here present to you.",
                    "label": 0
                },
                {
                    "sent": "Some recent recent results of my ongoing research work on multi Document Summarization Task shortly MDSM.",
                    "label": 0
                },
                {
                    "sent": "This is a process of filtering information for generating the compressed version of.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "One set of documents.",
                    "label": 0
                },
                {
                    "sent": "Although this is almost half century old research topic, there is still big gap in automatically generated summaries and human written abstracts.",
                    "label": 0
                },
                {
                    "sent": "One can with very shallow field reviews showed that the main reason for this gap.",
                    "label": 0
                },
                {
                    "sent": "R. Smith, semantically image methods used for taking this kind of hard topic.",
                    "label": 0
                },
                {
                    "sent": "So based on this evidence we have defined our goals in this research as showing how wanted to show how is it possible to improve the efficiency of summarization using semantically rich representation and based on this new representation to develop or at least to propose to adopt an existing method for summarization.",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As a starting point, in our research we have used.",
                    "label": 0
                },
                {
                    "sent": "Approach known as graphviz models for MD's desk.",
                    "label": 0
                },
                {
                    "sent": "They have been proposed back in 2004 and in order to give you an.",
                    "label": 0
                },
                {
                    "sent": "Overview of how does this methodology work?",
                    "label": 0
                },
                {
                    "sent": "I have made up here a simple example where we have two documents and four sentences, two in each document.",
                    "label": 0
                },
                {
                    "sent": "Let's say that we want to compute the similarity between the all the pairs of sentences and put the results in similarity metrics from similarity metrics by taking nodes in a graph to be sentences and connection or edges in a graph as similarity measure, which is both some threshold.",
                    "label": 0
                },
                {
                    "sent": "We can in this way.",
                    "label": 0
                },
                {
                    "sent": "Generate and sentence similarity graph.",
                    "label": 0
                },
                {
                    "sent": "Then by employing any kind of note, significance estimator estimating algorithms such as patient vehicle, we can rank nodes according to their significance and by selecting the most important.",
                    "label": 0
                },
                {
                    "sent": "And once we can form our summary from this example, you can see that the first sentence has two connections with high similarity with two other sentences, so it's obviously the first sentence is most important one, and it is chosen to represent our our documents as a summer.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "No one can see that there are two issues in those kinds of methods.",
                    "label": 0
                },
                {
                    "sent": "The first one is the question how to model the set is the set of documents as a text graph and the second one is how to estimate the significance of nodes in generated graph.",
                    "label": 1
                },
                {
                    "sent": "In this work we are mainly concentrated on the first question.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what are the novelties that we propose in this work instead of using sentences as we already saw in previous works instead of using sentences as nodes in a graph, we propose using semantic role frames for edge instead of using a simple.",
                    "label": 0
                },
                {
                    "sent": "Word overlap or have questions similarity from vector space model.",
                    "label": 0
                },
                {
                    "sent": "Instead of using this kind of shallow similarity measure measurement functions, we propose using semantically enriched similarity methods an for first time.",
                    "label": 0
                },
                {
                    "sent": "Our graph generation is based on the cognitive model for text understanding.",
                    "label": 1
                },
                {
                    "sent": "For ranking is already said, we have just adopted existing approach which which is the Pagerank algorithm.",
                    "label": 0
                },
                {
                    "sent": "What was the exactly motivation for using the semantic role or semantic frame graphs as we already know?",
                    "label": 0
                },
                {
                    "sent": "Even that humans do not always agree on the content to be chosen to represent the set of documents they perform very well on this task.",
                    "label": 0
                },
                {
                    "sent": "So therefore we should find a way of mimicking the human kind human.",
                    "label": 0
                },
                {
                    "sent": "Cognition behind the process of text reading.",
                    "label": 0
                },
                {
                    "sent": "Text understanding.",
                    "label": 1
                },
                {
                    "sent": "For this challenge, we have considered using the cognitive model for text understanding, namely the event indexing model.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "According to this model.",
                    "label": 0
                },
                {
                    "sent": "Human like system while processing documents should keep track on changes on on five different indices or dimensions starting from protagonist temporary information.",
                    "label": 0
                },
                {
                    "sent": "Causal locational, an intentional information.",
                    "label": 0
                },
                {
                    "sent": "While we were the dealing with the problem of exact extracting this information from a text, we realized that there is 1 to one mapping from semantic role parsers output to event indexing model.",
                    "label": 1
                },
                {
                    "sent": "Semantic role parsers are machine learned models able to label part of the sentences which are in direct connection with the predicate.",
                    "label": 0
                },
                {
                    "sent": "So for example, for for a sentence such as Christina hit Squad with baseball yesterday.",
                    "label": 0
                },
                {
                    "sent": "Antique roll parser will.",
                    "label": 0
                },
                {
                    "sent": "Extract following frame, we call this frame where in the center we have a predicate hit and then the arguments connected to predicates such as subject Christina, objects, code location, temporal information yesterday, etc.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "SOB.",
                    "label": 0
                },
                {
                    "sent": "This marked the summarization method that we propose box in follow case.",
                    "label": 0
                },
                {
                    "sent": "You can see from the picture on the slide we start with the documents which are given to the semantic role parser where their semantic frames are extracted from every sentence.",
                    "label": 0
                },
                {
                    "sent": "Then we compute composite similarity between the frames extra extracted in the previous step and by using the semantic frame as the nodes and.",
                    "label": 0
                },
                {
                    "sent": "Composite similarities edge.",
                    "label": 0
                },
                {
                    "sent": "We can we create our frame similarity graph.",
                    "label": 0
                },
                {
                    "sent": "On which by using Pagerank algorithm we are ranking notes based on their significance and summing up notes, notes or frame scores.",
                    "label": 0
                },
                {
                    "sent": "Page rank scores which are originated from the same sentence.",
                    "label": 0
                },
                {
                    "sent": "Since we know that.",
                    "label": 0
                },
                {
                    "sent": "Complex sentence can.",
                    "label": 0
                },
                {
                    "sent": "Can contain more than one predicate, so there will be more than one.",
                    "label": 0
                },
                {
                    "sent": "Paper, paper, sentence.",
                    "label": 0
                },
                {
                    "sent": "In this way, we score sentences and then we choose the first or highest incentives depending on the desired length of the summary, and in this way, of course, perform our resulting summary.",
                    "label": 0
                },
                {
                    "sent": "Of our graph, modeling is based on two functions, vertex labeling and edge labeling functions.",
                    "label": 1
                },
                {
                    "sent": "Alpha and beta functions, Alpha function levels, nodes or age notes.",
                    "label": 0
                },
                {
                    "sent": "Based on the completeness of the frame and one frame is considered as complete if it has at least subject object and predicate.",
                    "label": 0
                },
                {
                    "sent": "So complete frames are labeled with the value of 1 / N, N is the total number of extracted frames.",
                    "label": 0
                },
                {
                    "sent": "An otherwise frames are labeled with the value to over 2 NH function is composite similarity function, which is again.",
                    "label": 0
                },
                {
                    "sent": "The define and calculated based on the event indexing model which says that.",
                    "label": 0
                },
                {
                    "sent": "The proposed indexes or dimensions are in decreasing order of significance or importance starting from protagonist down to causality.",
                    "label": 0
                },
                {
                    "sent": "Those better.",
                    "label": 0
                },
                {
                    "sent": "Paramaters, or beta coefficients, are defined to reflect this importance order.",
                    "label": 0
                },
                {
                    "sent": "I mean, it's in some way that code defined values, but since this is kind of.",
                    "label": 0
                },
                {
                    "sent": "Linear combination of atributes in future.",
                    "label": 0
                },
                {
                    "sent": "We would like to experiment with the learning methods of those parameters in this way generated frame similarity matrix is then given to page rank algorithm as input vector H and the result we get rent.",
                    "label": 0
                },
                {
                    "sent": "Order of friends.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here we have some preliminary results.",
                    "label": 0
                },
                {
                    "sent": "Since we are still working on this task.",
                    "label": 0
                },
                {
                    "sent": "We have tested our.",
                    "label": 0
                },
                {
                    "sent": "Method on that is provided by Document Understanding Conference particular data set from 2004 where the task was to.",
                    "label": 0
                },
                {
                    "sent": "To summarize, the group of topic related articles, there are 50 groups with ten articles approximately in each group.",
                    "label": 0
                },
                {
                    "sent": "And for evaluation we use the tool known as Rose, which is statistical evaluation.",
                    "label": 0
                },
                {
                    "sent": "Some Revelation 2 which which is which measures the quality of summary.",
                    "label": 0
                },
                {
                    "sent": "By doing some statistics over the number of Co occurrence or word overlaps with between ideal an automatically generated summary.",
                    "label": 0
                },
                {
                    "sent": "Also, the results here are not so significantly different.",
                    "label": 0
                },
                {
                    "sent": "We are kind of.",
                    "label": 0
                },
                {
                    "sent": "Happy with our results because we fulfill our first goal, which was to show that.",
                    "label": 0
                },
                {
                    "sent": "We can do better in some in summarizing by using semantically rich textual representation.",
                    "label": 0
                },
                {
                    "sent": "Even that in this version of our method we didn't, not we did not use any of summary quality improvement techniques such as sentence reordering or sentence reduction, or in our case, frame merging.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for a less light, I would like to say some few words about our future work in this work.",
                    "label": 0
                },
                {
                    "sent": "As a result, we have presented a novel model for graph based document summarization where we proposed using frame similarity graph.",
                    "label": 0
                },
                {
                    "sent": "Which is in some ways similar to the previous one, but it goes deeper in semantic analysts because previous one was just the method of representing sentence similarities.",
                    "label": 0
                },
                {
                    "sent": "So we can say that the works up to date are mainly concentrated on homogeneous connections between the sentences, and some reasons work are working on our presenting approach of heterogeneous connections between the sentences and documents.",
                    "label": 0
                },
                {
                    "sent": "Uh.",
                    "label": 0
                },
                {
                    "sent": "We are now working on an multilayer graph model where we will introduce additional 2 layers to our.",
                    "label": 0
                },
                {
                    "sent": "Previous work I mean this one, which I present here by Ed by adding these two layers will get an semantically rich three layered multi layered graph model which will need also be adopted to page rank algorithm which layers.",
                    "label": 0
                },
                {
                    "sent": "So we said that we have frame then can sentence and the third one is document.",
                    "label": 0
                },
                {
                    "sent": "Since we are dealing with multi document summarization.",
                    "label": 0
                },
                {
                    "sent": "This right now it's kind of single document summarization because we are putting them all together.",
                    "label": 0
                },
                {
                    "sent": "Questions, so let's say.",
                    "label": 0
                },
                {
                    "sent": "Getting these results which you were showing us so and having this similarity function with.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "All the terms, can you say which terms contributed?",
                    "label": 0
                },
                {
                    "sent": "How much to the result?",
                    "label": 0
                },
                {
                    "sent": "Yes, right now we are working on this particular statistical.",
                    "label": 0
                },
                {
                    "sent": "Explanation so far of our models because right now I have just implemented the model and tested on the data set.",
                    "label": 0
                },
                {
                    "sent": "I didn't do any dips.",
                    "label": 0
                },
                {
                    "sent": "Statistical analyzes of of.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is I guess, first thing which you should do really understand why you're getting results.",
                    "label": 0
                },
                {
                    "sent": "You're getting through the well which which term in this formula Now contributes the most.",
                    "label": 0
                },
                {
                    "sent": "In fact they are not terms they can be at the combination of terms because protagonists.",
                    "label": 0
                },
                {
                    "sent": "Yes, yeah.",
                    "label": 0
                },
                {
                    "sent": "OK, I guess it was also in our To Do List to to think about how we can change also this parameters which are right now very naively chosen based on the event indexing model.",
                    "label": 0
                },
                {
                    "sent": "So 1 one question about.",
                    "label": 0
                },
                {
                    "sent": "SLR parsers so.",
                    "label": 0
                },
                {
                    "sent": "Whenever you do this, semantic role labeling so this process by itself it's not accurate enough.",
                    "label": 0
                },
                {
                    "sent": "Yes, it's statistical method.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so how accurate the results you get this?",
                    "label": 0
                },
                {
                    "sent": "Or how much how much error you introducing for the first step?",
                    "label": 0
                },
                {
                    "sent": "This must be also this error.",
                    "label": 0
                },
                {
                    "sent": "Propagate through the whole pipeline then so each person was used.",
                    "label": 0
                },
                {
                    "sent": "Here I experiment with few ones against the one that I last used.",
                    "label": 0
                },
                {
                    "sent": "This something like Hilda or Hitler.",
                    "label": 0
                },
                {
                    "sent": "There are plenty of them, and yes, they are performing on let's say around 80% up to 85% precision in in this labeling.",
                    "label": 0
                },
                {
                    "sent": "And now the questions.",
                    "label": 0
                },
                {
                    "sent": "So maybe just a comment.",
                    "label": 0
                },
                {
                    "sent": "So you said that this is normal.",
                    "label": 0
                },
                {
                    "sent": "So I mean the summarization based on this semantic graph.",
                    "label": 0
                },
                {
                    "sent": "So this is this is not so new.",
                    "label": 0
                },
                {
                    "sent": "Yeah it is.",
                    "label": 0
                },
                {
                    "sent": "As I already said in the beginning, it's almost South Central research topic and it also also.",
                    "label": 0
                },
                {
                    "sent": "This summarization itself, but also this semantic graph.",
                    "label": 0
                },
                {
                    "sent": "So yes, you could check with a bit more.",
                    "label": 0
                },
                {
                    "sent": "The literature, I guess.",
                    "label": 0
                },
                {
                    "sent": "This was done already in this area.",
                    "label": 0
                },
                {
                    "sent": "We've gone as well.",
                    "label": 0
                },
                {
                    "sent": "So yes, since I have already read your your works about triplet extraction, but.",
                    "label": 0
                },
                {
                    "sent": "So just be careful on the evaluation side, so that's why.",
                    "label": 0
                },
                {
                    "sent": "Start now to discuss.",
                    "label": 0
                },
                {
                    "sent": "Approach the keys relation.",
                    "label": 0
                },
                {
                    "sent": "What contributes to summarization, whatnot.",
                    "label": 0
                },
                {
                    "sent": "OK understood.",
                    "label": 0
                }
            ]
        }
    }
}