{
    "id": "6jixdc7425y7wso45eumr4he3jd4hsep",
    "title": "The Recommender Problem Revisited",
    "info": {
        "author": [
            "Xavier Amatriain, Netflix, Inc.",
            "Bamshad Mobasher, College of Computing and Digital Media, DePaul University"
        ],
        "published": "Oct. 7, 2014",
        "recorded": "August 2014",
        "category": [
            "Top->Computer Science->Data Mining",
            "Top->Computer Science->Knowledge Extraction"
        ]
    },
    "url": "http://videolectures.net/kdd2014_amatriain_mobasher_recommender_problem/",
    "segmentation": [
        [
            "So I'm chubby.",
            "I'm again, I'm director of Netflix and I'll eat recommendation and personalization team.",
            "And there we also do all other kinds of algorithms like search and so on.",
            "But I'm going to be focusing on recommendations today and we're going to be giving this tutorial together with my friend Bombshell Mobasher who's sitting there on the 2nd row and he will be giving the second part.",
            "And I don't usually wear political T shirts when I give tutorials, but I thought there was a special event Ann.",
            "Given all this discussion around net neutrality, I thought I have to support Frank Underwood for his 2016 election.",
            "How many of you know who Frank Underwood is?",
            "OK, that's good.",
            "How many of you know what the Netflix price was?",
            "More people?",
            "OK, that's that's what I what I call my geekiness in this index right.",
            "It's the amount of people that know about the Netflix prize divided by the amount of people who know who Frank Underwood is.",
            "Frank Underwood is a character in one of Netflix TV shows, House of Cards, which I really recommend you watch.",
            "So anyway."
        ],
        [
            "Here's the rough outline, so there's going to be 2 parts of this tutorial.",
            "The first part is going to be taking us 2 hours.",
            "There's a coffee break in between, so there's a coffee break at 10 and I'm going to be introducing the recommender problem and talking about.",
            "Traditional an beyond traditional method and then bam shot is going to take it from there and focus on one very particular interesting area of sort of like non traditional method which is context aware.",
            "Recommendations."
        ],
        [
            "And well, I had a list of publications here."
        ],
        [
            "Some of the things that I have in this slide, including the references you should have access to them through the website.",
            "I just put them here so you can then later reference to them.",
            "And this is the index of my talk.",
            "I should mention, I really love questions and interruptions.",
            "I was thinking that if I do get many questions, though, it's impossible that I get through my slide.",
            "So we're going to do something slightly different, although I usually recommend people and encourage people to ask me questions throughout my presentation, I thought it might be better to just drive it, at least for the first hour with few questions or probably no questions.",
            "Will have half an hour during the coffee break for me to answer all your questions.",
            "And then on the second hour that I give, I'll open it up, especially if I get interesting questions during the coffee break.",
            "I'll refer to them and maybe answer them for.",
            "All the attendees, but just to make it, make sure that at least I guess I get through most of the slides that I have and I get to the more advanced topics that I guess most of you will be mostly interested.",
            "I'll kind of drive it through the first hour with few interruptions as possible.",
            "OK so."
        ],
        [
            "The first part is probably going to be well known for most of you.",
            "I hope I'm going to be giving a slightly different angle, and I think it's important to start there because even if you've heard about collaborative filtering, content based recommendation, maybe you haven't heard it in the context of what I'm going to be explaining later on, so I think it's good to set the foundations and the basis for what we're going to be talking for.",
            "The other part of the tutorial.",
            "And then on."
        ],
        [
            "Beyond traditional methods, I'm going to go through a bunch of different approaches.",
            "Some are new, some are not, so new, but all of them are kind of different to what I would call the traditional content and collaborative filtering approaches.",
            "OK.",
            "So.",
            "Let's start by giving the.",
            "Basic introduction to the problem of recommendations right and I think of recommendations as a way.",
            "Or not only it away, but the way to access information in an age where we have so much information, write an creates Anderson in the long tail, set it in the in chapter.",
            "In the book we're leaving the Age of information entering the age of recommendations.",
            "Even search in itself at some point.",
            "Once the user has issued, the query can become a sort of recommendation, right?",
            "And I work on personalized search algorithms that basically at the end become some sort of recommendations.",
            "Advertising is slightly different, but it also uses many of the similar approaches that we will be talking about here where you want to tailor and personalize and target the user according to her his taste."
        ],
        [
            "OK so I like to talk.",
            "Also about this paradox of choice.",
            "This is a very interesting book.",
            "There is a YouTube video of a talk that very sparse gave at Google, which I hardly recommend.",
            "It's very interesting book and the idea this is from a psychology standpoint is this idea that sometimes we have this feeling that the more choices we have it, the better.",
            "It turns out that choice overload produces this paralysis by analysis effect, where people have a harder time choosing when they have more choices and there is a very interesting experiment.",
            "Which I usually refer to with some different jams in a little store in town in I think it was in California, but the idea was very simple.",
            "Put some different flavors of jams to taste, and there were two different experiments.",
            "In the first one, they use 16 different flavors.",
            "In the second one, they use 64 different flavors of jams, right?",
            "And people will walk into the store.",
            "They would have them there to taste, and then they would decide if they wanted to buy or not, and guess in which case people bought more gems.",
            "In the case where you had 16 versus 64, right?",
            "Because having 64 gems in front of you, and deciding which one of those you like.",
            "It's a huge problem and people just said you know what?",
            "I'm not going to buy anything right?",
            "So that's I think it's a very interesting explanation of why we want to reduce the choice and make sure that we present the best ones for each user.",
            "And.",
            "At the end of the day, everything ends up being personalized and we have many examples of why personalizing and recommending is actually something that is good for the user.",
            "I'm going to be using throughout my talk a lot of experiments for Netflix.",
            "Obviously some of them are not from Netflix, but many are.",
            "I thought this headline that came out.",
            "A few months ago was really interesting, right?",
            "This is not something we wrote somebody.",
            "It's a journalist that roast Netflix.",
            "New feature knows you better than you know yourself because of algorithms.",
            "And that's exactly true.",
            "There's something that happened and we may be tested.",
            "And we measured and we realize.",
            "So there is a feature in Netflix.",
            "For those of you that don't know it, it's called my list where users can actually save things that they want to watch in the future, right?",
            "And you say, oh, this documentary is awesome.",
            "I'll just add it to my list and I'll watch it someday.",
            "Well, you know, you're never going to watch it no matter what you just added there because it looks cool, right?",
            "To have documentaries in your list.",
            "But the bottom line is we."
        ],
        [
            "So that people were adding a lot of things to the list and then wouldn't watch them again.",
            "And the problem was we also allowed users to sort the list however they wanted, right?",
            "So some people very few people like tiny fraction of the people would spend a lot of time sorting things out and I'm going to put them in different order and I know which one I want to watch first.",
            "Those were the minority of people.",
            "Most people would just add stuff in the queue and would never watch it again.",
            "So we decided to.",
            "Implement an algorithm which would take into account different signals to personalize and to say hey OK will let you add as much as many things as you want to the list, but then will rank them and sort them as we think that you want to see them and the result was very positive, so people started consuming for the list much more than they did before, right?",
            "So this is an example of why even letting users take the initiative and take the action of sorting and organizing things might not be as good as.",
            "An algorithm can do for them.",
            "OK."
        ],
        [
            "So the traditional definition of recommender system, which I guess that's the one we will be deconstructing and recreating here in this tutorial today is we estimate a utility function that automatically predicts how a user will like an item and we do that based on past behavior relations to other users, adding similarity, context and whatever else you can throw to the problem.",
            "The problem right?",
            "So basically.",
            "The traditional definition is we want to estimate a function that comes out with.",
            "Number, which could be a probability of how much the user is likely to consume or two, like a given item."
        ],
        [
            "Now the core of the recommender system is actually pretty much a data mining problem, right?",
            "And this is a.",
            "Picture or.",
            "Dataflow that I used in one of chapter four book.",
            "It's called data mining methods for recommender systems.",
            "It's part of a very interesting book I recommend which is the Handbook for Recommender Systems or sorry, the Recommender Systems Handbook.",
            "So anyway, the basic idea is that the coral for recommender system is going to be a data mining system where you have the three blocks of data preprocessing, the model, learning and then the testing and validation.",
            "And actually, most of the methods that you can think about in traditional data mining or machine learning, like supervised and unsupervised methods, and you have a huge list here.",
            "Many of them can be used or have been used in a recommender system.",
            "It doesn't mean that they all work very well, but they can be used right and will be going through some of them.",
            "However, I do want to highlight that."
        ],
        [
            "Little, you know we're hearing Kitty and we're going to be focusing on the recommender.",
            "Problem from a data mining perspective.",
            "There are many other things that go into recommender systems that we won't be talking about, or at least we won't be talking about at length.",
            "But those are equally important.",
            "Or some of them are even more important.",
            "For example, the user interface, right?",
            "So it doesn't matter how good your algorithm is if you actually hide your recommendations in place in a web page that nobody can see, well, you're not going to get anything out of the recommendation, right, so?",
            "Obviously the user interface and how you present that it's really important.",
            "System requirements will talk about some of them sometimes like scalability and so on.",
            "Privacy those are all very important serendipity, diversity, awareness explanations.",
            "And this last I will be talking this last four I will be talking a little bit more about them because we can do something about them in the algorithm makes sense.",
            "So serendipity in particular."
        ],
        [
            "It's super important, right?",
            "Because we define serendipity as something finding something that you weren't looking for.",
            "An surprises you in a way that really beyond what you expected to find.",
            "Now.",
            "This is.",
            "In essence, a key feature of a recommender system, right?",
            "If we only recommend things the user already knew that were there already knew that he or she could find that really defeating the purpose of the recommender system.",
            "So we do want to, in some sense, push for some serendipity and try to have some sort of exploration built in.",
            "The recommendations that we present to the user, and we can have some ways we can.",
            "Add some things to some algorithms that induce some sort of exploration or some sort of serendipity, and in other words, we don't want to do something like if the user first time that comes into our service decides to watch an anime title all of a sudden, all his recommendation, all his webpage, it's made of animated movies right?",
            "Because?",
            "Probably the user had other tastes and we do want the user to explore those other tastes.",
            "Then X."
        ],
        [
            "Nation and support for recommendations.",
            "That's also an important piece of the puzzle, and something that you can build algorithmic components around.",
            "The idea is that.",
            "You want to get the user involved in the recommendation and the personalization process itself, and you do by you do that in different ways.",
            "One is by giving some incentives to the user to give you feedback and the other one which is this one is by giving explanations to this or why you're recommending something so the user sees the value of the recommendation system and keeps giving you feedback right?",
            "So here you have an example.",
            "This is from the.",
            "Netflix UI, where if you put your mouse over a movie, you'll get what we call the Blob, which is something like this.",
            "This little thing has a ton of recommend.",
            "Sorry of explanations around it were giving you so much information about why this is being recommended to you.",
            "Of course there's the typical one about.",
            "OK, you know the title, the rating, the duration, the year.",
            "There's all these actors.",
            "The director.",
            "That's something that might have gone into the recommendation algorithm, right?",
            "There's also here based on your interest in Arrow, meant to annexe meant and whatever.",
            "So we're telling you, OK, if you like those things are going to like this.",
            "This is another support.",
            "Another explanation, we're also giving you the rating right?",
            "So we're also giving you the rating prediction, which is also supporting the fact that you're going to like this, and that's why we're recommending it.",
            "Even telling you this is an old picture we this is the list feature that I was calling you that was explaining before it was previously called Instinct, but we're basically telling you, hey, you save this for watching before, so you probably want to watch it right?",
            "Even using this is another screenshot from the.",
            "IPhone application, even using social support and telling you hey you have some friends that watch that.",
            "So all those pieces which can make it into the algorithm and actually will talk about how they can make it.",
            "You should also think about using them in the form of support or explanation for the recommendation, OK?",
            "And."
        ],
        [
            "I also I already mentioned awareness.",
            "We want to make the users aware and part of the recommendation process.",
            "We do that for example here in the top ten we use the name of the user and we are actually making it explicit that this is for you and it's has been personalized and also diversity is another key issue that I won't be talking a lot about.",
            "But sometimes we want to include some form of.",
            "Induced diversity into our algorithms in a way that we can, for example, in the case of Netflix for many households, we are not making the recommendation for a single person will actually make them making them for a household that is made of different people.",
            "This is actually my household and I have a son, a daughter and my wife.",
            "And then when I look at this recommendations that go here into this list, I can actually see recommendations that would be better for one or the other or for the conjunction of all of them.",
            "And that's something.",
            "But we also need to build into our algorithms."
        ],
        [
            "OK, so in general what works right?",
            "And this is a question that I get many times, specially when I talk to.",
            "Small companies startups like OK, You know this is all very fancy and you're talking about deep learning and about what not.",
            "But if I want to start small, I want something.",
            "What's the easiest thing that I can do that works so?",
            "Course the answer is it depends on your problem in the domain and the data you have and everything else.",
            "But if I had to go blindly with something, I would say go with collaborative filtering an if I had to even narrow it down to something smaller or something that I could tell you.",
            "Start right away.",
            "I would say, well, start with some kind of dimensionality reduction like matrix factorization or SVD, because those have proven to be simple and useful in the general case right?",
            "And will go through.",
            "All this in more detail, but this is roughly the idea or the simplification of solving the traditional recommender problem in a way that in many cases will work.",
            "Now when I talk about the recommender problem in the."
        ],
        [
            "Solution that we're going to be looking at during the tutorial.",
            "This is the picture that I want you to.",
            "Getting your head.",
            "So.",
            "In the Netflix Prize, we simplify the recommendation problem to predicting a rating, and we said, well, we know the recommend recommendation problem has a lot of many other things.",
            "As we've already seen before.",
            "But let's try to find something that is easily an objective and easy to optimize, easy to measure, and that is going to focus people in just optimizing for one simple metric, right?",
            "So well are messy rating prediction.",
            "That's easy and we simplified to one single number.",
            "One prediction problem, an root mean square error.",
            "And that's OK. That's a good simplification.",
            "But the recommendation problem is much broader than that, and what we're going to be doing in this tutorial is actually going kind of adding different dimensions to the recommender problem and a way to look at it is, well, we started with a single point, which is a rating prediction.",
            "We can expand that to something that actually much better than rating prediction, which is ranking really what you want to do in a recommender system is you want to predict the rating because at the end you want to produce.",
            "Well, rating you want to predict score because at the end you want to produce a ranking right?",
            "So let's talk about ranking and we'll be talking about learning to rank.",
            "If we make this even more complicated, really people don't have a single list in their homepage or in their device or wherever they're looking at their recommendation.",
            "They actually have a full page of things and some compete with each other, and there's attention modeling going on, and there are many things that we need to take into account so we can go into the.",
            "Dimensional problem of page optimization and finally.",
            "If we add context into it, which we can add actually not only three dimensions as many dimensions as you want.",
            "If you think about it, we're not only thinking about the user looking at a page, we're actually looking, thinking about looking at the user.",
            "So thinking about the user looking at a page in a given context, it will be on a given day on a given time of the day with a given device and a given location and all of that piles into the recommended problem.",
            "And it's something that we will be tackling with different algorithms, OK?",
            "So let's get started."
        ],
        [
            "This was kind of like introduction into the problem that we're going to be.",
            "Talking about and we'll start with the traditional methods and collaborative filtering, so bear with me."
        ],
        [
            "This is known for many of you, but I think it's good as I said too.",
            "Set the basis of what we're going to be talking about.",
            "So the."
        ],
        [
            "Collaborative filtering ingredients.",
            "Simple, we have a list of users, some items and.",
            "Some of those items have an associated opinion which could be explicit and we talk about explicit feedback when we have a number that is associated with the user telling us.",
            "OK, this is how much I liked this item.",
            "Or can be implicit an implicit means it's been derived from an interaction from the user.",
            "So if the user clicked on that, we assume the user liked it.",
            "That's not always the case, right?",
            "And we have to be careful with that in many domains.",
            "For example, when I work on witches movie, watching if you click on a movie and you watch it for five minutes, but you stop and never watch it again, that might not be a good thing, right?",
            "It's like you started watching it didn't like it so.",
            "How you define your implicit feedback and how do you find whether it's positive or negative?",
            "That's a whole other story.",
            "We won't get into, but in any case you have explicit or implicit feedback associated with a list of items in a list of users.",
            "And then basically you take one active user, so I know about all the people in this room and I take one active users.",
            "OK, now I'm going to try to figure out a recommendation for you.",
            "And.",
            "In the traditional approach.",
            "What I need is a similarity between users and a method for selecting a subset of neighbors for that person, right?",
            "So basically once I pick my person in the room and say OK, I'm going to recommend something for you.",
            "My next question becomes OK, let me find who are the most similar people to you in this room and I'll pick five people and I'll ask questions to those five people say hey, what do you guys like?",
            "And looking at those answers I'll figure out what you as the active user would want to watch."
        ],
        [
            "Anne.",
            "A good question to ask is how does that compare to the non personalized case, right?",
            "There's a much easier approach, which is actually always a good baseline to keep in mind, which is, like, you know, this sounds very complicated.",
            "Why don't I instead of figuring out who your best the people most similar to you are, let me ask everyone in the room just what's their favorite movie, and then when I want to predict something for you, I'll just pick whatever everyone has said, right?",
            "That's the unpersonalized.",
            "If everyone likes very much this movie, chances are you're going to like it, right?",
            "And that's actually not a bad baseline.",
            "Having popularity of global popularity.",
            "Baseline, the non personalized is something a good starting point, right?",
            "So how do the two approaches compare?",
            "So here."
        ],
        [
            "There is a.",
            "2 charts that I think are interesting to keep in mind.",
            "The first one relates to the Netflix price.",
            "So here on this axis you see the root mean square error.",
            "Ann here there are different approaches to figuring out the recommendation.",
            "The first one, which is really bad is the random right?",
            "So I'll just give you a random rating for as a prediction for you now.",
            "This one here.",
            "Is the average rating, so this is the unpersonalized average which I was talking about.",
            "Take all the ratings, average them and just predict with the average.",
            "This other one in red one.",
            "This is the Cinemax.",
            "So this is basically the one Netflix gave out as the baseline to beat, and this one here was the price right?",
            "So the first thing you see or the first thing that you realize is well in terms of room, in square or whatever the metric you figure out really.",
            "There's not much difference between something perfect if you will, I mean, well, perfect will be would be 0 but.",
            "The price is pretty good and something which is just the average right?",
            "So beating the average of the Unpersonalized case is not as easy an sometimes.",
            "Simple to come up with something reasonable and beating that something reasonable with something that is better than reasonable.",
            "It takes a lot of effort and all of time it actually took three years and thousands of people working on the Netflix Prize.",
            "Right now.",
            "However, the tricky Anki issue here is.",
            "That doesn't mean that it's not valuable, it is actually valuable.",
            "And it's very.",
            "That's why we're all here, I guess, right?",
            "Or that's why I have a job.",
            "It's because it's really valuable to increase the accuracy and to improve the algorithms in recommendations to the business, right?",
            "Just measure in how much more money that business is going to make.",
            "Just increasing that harmacy by percentage point is worth a lot of money, so it's interesting to see that from the algorithmic perspective, improving that 1% on the metric.",
            "Even a few percentage points over the baseline, it's complicated.",
            "However, it's really worth it from a business perspective.",
            "Here there's another comparison.",
            "There's different public datasets that you probably should be used to.",
            "Movie Lens is the most typical one.",
            "The gesture for news and each movie.",
            "And here you have the comparison.",
            "This is mean average error instead of root mean square error.",
            "But basically it's the same and you see the comparison between the non personalized average and the personalized average OK?",
            "So."
        ],
        [
            "So how do we do collaborative filtering?"
        ],
        [
            "How do we do user based collaborative filtering?",
            "Which is the initial and the most simple approach to recommendation, right?",
            "So again, we find the neighborhood.",
            "For the target user, according to a similarity function between users, and then we identify those products that that neighborhood liked and we generate the prediction based on those items that those users liked.",
            "Basically, to put in some formulation into it."
        ],
        [
            "We have a collection of users and a collection of products and then we can think and we will usually think of this as a matrix of North by M ratings.",
            "Where the rating will be unknown.",
            "If the user I did not write that product J right so then how do we come up with a prediction for a user I and approach A so we can do it in two different ways.",
            "The simpler approach is we say we just average over the users an we wait.",
            "That rating that those neighbors had by a similarity, or we do slightly more complicated thing, which is basically we just.",
            "Instead of.",
            "Average averaging over the direct rating of those neighbors we average over the deviation from the average right?",
            "So V sub K is the average rating.",
            "That item has an we.",
            "Compute the deviation from each user to the average and then we weighted by the similarity.",
            "And of course we add that to the global average.",
            "So the basic idea is we get those neighbors.",
            "We see how they rated that item.",
            "We see how similar they are to you, right?",
            "Because now we're not just assuming that those five people that we found that are similar to the target user are equally similar.",
            "There is a similarity function.",
            "We wait there at rating by the similarity to the target user and then we compute the prediction this way.",
            "And there's different ways to compute that U, which is the similarity.",
            "You can compute it using.",
            "Pearson correlation you can use just a cosine similarity.",
            "There are different ways that you can compute similarity, but the idea is always the same, right?",
            "And this is the basic approach and this is this by the way.",
            "Going back to the Netflix Prize is pretty similar to what was being done in the baseline.",
            "The Cinemax prediction, once the Netflix Prize was published.",
            "And this is it makes sense.",
            "It's from an intuitive perspective looking at the users looking at how similar those neighbors are to you, looking at their predictions, an waiting their predictions by how similar they are to you.",
            "It's very intuitive approach.",
            "So.",
            "If we look at it."
        ],
        [
            "This way this is exactly what I just explained, but in an example right and here we have different users and different shows and how they rated those shows from one to five stars.",
            "And the."
        ],
        [
            "First thing we do is we compute the similarity from a user to a user.",
            "So."
        ],
        [
            "Basically.",
            "We're looking at.",
            "Making predictions from this user and we're trying to figure out what's the similarity from this user to all the different users, right?",
            "For example, the similarity from this user to this user will be based on the single movie that they rated equally, which is The Avengers, and then the similarity will be one."
        ],
        [
            "The similarity between these two users will be minus one."
        ],
        [
            "I'm using the Pearson correlation by the way here.",
            "And then once we have the similarity from the different users, basically what we do is go to their ratings and we base the prediction for the user on the.",
            "Product of the different users.",
            "Their ratings and the similarity to the target user.",
            "And that's sorry."
        ],
        [
            "We would get as an estimate of this ratings for this given user, so it's a very simple and very effective way of doing a prediction for giving user.",
            "The first change that we do to that is well, instead of using user based neighborhoods and user base similarities, why don't we think about it in the terms of in the form of item?"
        ],
        [
            "And that takes us to the item based collaborative filtering algorithm, which is usually by the way more effective, right?",
            "So if you think about user based collaborative filtering as being more intuitive.",
            "The first, the first thing you should know is the item base is more effective for.",
            "Different reasons, one of them is usually the item space is more reviews than your user space usually have more users than you do items.",
            "But the idea of item based collaborative filtering is exactly the same, except that you reverse the access.",
            "So you look at the items that the target user has rated, and then you compute the similarity between those target items that you want to predict and those items that the user has rated.",
            "Now, very important here is you still only using ratings or opinions from the users, right?",
            "So here you are building a similarity function between items, but that similarity function is only based on the opinion from the users or the rating from the user.",
            "So basically instead of figuring out out figuring out now how similar you are to him now I'm figuring out how similar those two movies are between themselves and I'm figuring that out just based on what the user rated, right?",
            "So I'm.",
            "Using the rating from the users to figure that out.",
            "And."
        ],
        [
            "There's different ways that I can compute that similarity, and again I can use the.",
            "Cosine similarity or a little.",
            "Better thing that I can do is use the adjusted cosine similarity, which takes into account something that we usually need to adjust for, which is the difference in rating scales.",
            "An rating averages between different items."
        ],
        [
            "So this would be, you know, it's simple.",
            "It's intuitive, but it doesn't work that well all the time and why it doesn't work that well.",
            "And why do we need to go beyond this today?"
        ],
        [
            "Approaches.",
            "Well, the process of this is that it requires minimal knowledge.",
            "You don't need to know about anything about the items, by the way, the same approach that I'm using for movies.",
            "I can use it for books or for recommending cats and dogs.",
            "It's going to work is the same.",
            "And it produces good enough results that we said, you know, it's a good enough baseline.",
            "But there are many challenges.",
            "The two main challenges that will tackle in the next slides is sparsity.",
            "If we have in most datasets what we have is that we only have interactions for about, say, less than 1% of user item pairs and 1% is already pretty high number, right?",
            "It depends on the size of your catalog, but if you think about size of catalogs like say eBay with millions of items in the catalog, you're going to have much less than 1%.",
            "So figuring out the similarities between users or items based on such a sparse matrix, it's very challenging.",
            "Scalability is another challenge.",
            "Scaling up this neighborhood based method is super difficult.",
            "I mean, if you just think again, think about the user based collaborative filtering approach.",
            "If I have to decide which are your five best neighbors out of a collection of say 100 million users, well I'm going to have to compute 100 million distances and similarities for each user, right?",
            "So that square?",
            "OK."
        ],
        [
            "Going a little bit more into the sparsity problem.",
            "So as I was saying, you will have large product set set an only ratings and only interaction from users to a very tiny proportion of those ratings.",
            "If we look at the rating, the ratings in the Netflix price.",
            "Basically what we have is 500,000.",
            "Items times sorry users times 17,000 items or movies which gives us around 8.5 billion positions in this matrix, out of which only 100 millions are non 0 right?",
            "So basically what you're looking at is a huge matrix full of zeros and every now and then you see a one here or a one or a.",
            "Five or three, but most of it is made of zeros, and that's a challenge for this neighborhood based approaches."
        ],
        [
            "So that brings us to the next step.",
            "OK, So what can we do better?",
            "So those methods that we talked about, what we call memory based?",
            "They don't really build a model, they just used using the ratings as they are, and building predictions out of the similarities and out of the ratings themselves.",
            "But we know better than that and we can build models, right?"
        ],
        [
            "And we can build all sorts of models because we've all read a bunch of machine learning books an we say, well, we can use probabilistic models like various networks, non supervised approaches, clustering rule based approaches like Association rule.",
            "We can build a classifier, use regression, LDA, whatnot can throw everything at the problem.",
            "Right now the question is knowing.",
            "What should we use?",
            "So."
        ],
        [
            "What did we learn from the price?",
            "And I think that's what the price the Netflix Prize bertels was from this initial idea of like let's use memory based collaborative filtering to being a little bit smarter and saying, OK, let's build models and let's use a model based approach.",
            "What do we learn?"
        ],
        [
            "So again, just as a reminder, the question we were.",
            "We had this, can you improve the cinemat with which I said was roughly based based on a neighborhood approach, the cinemate.",
            "Predictions by 10%.",
            "If you do that and 10% measuring root mean square error, you'll get $1,000,000, right?"
        ],
        [
            "So the top two algorithms, even after the first year, so that was the 2007 progress price where SVD or a form of SVD that I'll get into in a little bit.",
            "Which had a room in square of Zero 8914 an restricted Boltzmann machines, which I'll also explain.",
            "With Zero Point 8990 and if you did a simple linear blend of those two algorithms, you got zero 88.",
            "Now.",
            "We were so excited by that time with the results of these algorithms already beating the Cinemax that actually those two algorithms made it into production.",
            "So there even as of today they are part of the production system that predicts the ratings, not the rest of the things with the ratings of the Netflix system.",
            "And of course there were some challenges on the engineering side, but basically bottom line is those two algorithms as they were, were pretty good in terms of prediction.",
            "Now.",
            "Let's talk a little bit about SV."
        ],
        [
            "Ian Metrization and why it matters and why.",
            "I said it's one of the.",
            "Default method that you should.",
            "You think about using if you.",
            "Don't know what else to use.",
            "So.",
            "The initial thing where you have to think about.",
            "Major factorization is basically you're taking highly dimensional problem, breaking it into smaller dimensionality by splitting a big matrix into three smaller matrices, right?",
            "An?",
            "The idea is that you have N * M and you have users and you have items.",
            "Sorry here I'm using M4 users and N for videos or items and you break it into three matrices.",
            "In which now for all of them there's a new dimension that comes up here, which is R, which is the number of latent factors that you decide that that problem is going to have, and that makes your problem so much easier.",
            "In the case of the Netflix price, most of the approaches successful approaches were using as little as 50, sometimes from 50 to 100 latent factor.",
            "So you were reducing the dimensionality of the problem.",
            "Too much smaller matrix then in this case it still had all your users, but now have 50 factors.",
            "Instead of having thousands of items, right?",
            "And there's another added benefit to this is that now instead of having a sparse matrix, you have a matrix that is actually non sparse.",
            "Um?",
            "So how?"
        ],
        [
            "Did you do that?",
            "So it's it's tricky to compute the SVD of a large matrix, especially when it's so sparse and has so many zeros.",
            "But turn out that.",
            "In 2006, at the end of 2006, in the context of a Netflix price, there was this interesting blog post by Simon Funk in New Zealand who explained something he was doing to the Netflix Prize data set by using an approximate, it's actually not.",
            "A mathematical SPD.",
            "This approximate way to compute the SVD by using gradient descent, and that's become the defacto way of actually doing the matrix.",
            "Factorization for large sparse datasets.",
            "By using this gradient descent approach in which basically you are avoiding overfitting by adding a regularization term.",
            "That's the basic idea.",
            "Um?"
        ],
        [
            "So how do you do?",
            "How do you use this in in performer rating prediction?",
            "How do you use these matrices and the result of the metric factorization or the approximate SVD for rating factorization?",
            "So the way to think about it is first by thinking.",
            "Well, once you have this decomposition here where you have this matrix you here in this matrix V what you actually have is.",
            "Two different kinds of vectors.",
            "The user factors, which are the piece of you and the Atom factors with which are the cues of V. And then all you do.",
            "Is multiply the user factors times the item factors, which is something you do here in this term.",
            "And you add them too.",
            "A baseline or a bias term, right?",
            "So first you estimate your baseline as the user and the item deviation from an average.",
            "Right, this is the BUV which is your bias or your baseline.",
            "And then you sum the product of the item vector and the user vector and this is how you use.",
            "In essence, Metrization or SVD to perform a rating prediction.",
            "Now, during the Netflix price that got more interesting and more complicated, right?",
            "And there was a.",
            "Famous paper by Yehuda Koren and others about factorization meets the neighborhood where they talked about something they named SVD Plus plus.",
            "And as part of that paper there was this other model.",
            "This is the symmetric SVD.",
            "I usually I usually refer to this one at SB C++, but that's not really true if you read the paper, there's a difference there between this one and the SVD plus plus, which I'll just mention, But basically let let's let's look at this as a metric SVD and how this is different from the standard rating prediction with metric factorization.",
            "So the basic idea in this asymmetric SVD is that.",
            "You still have here the item vector that you're multiplying, but instead of multiplying the item vector times a single user vector, which is what you expect to have here, right there P. So you you're actually not.",
            "Paramount Rising the users, but you're representing them by two different terms, and those two different terms respond to two different things one.",
            "Is the ratings and the other one is the implicit?",
            "Interaction of the user and an item.",
            "So the key realization here.",
            "They do have the.",
            "And their team had?",
            "Is that the fact that user is actually rating an item by itself?",
            "It's an important information and it's different.",
            "It's a different information, right?",
            "If I rate a movie, it means that I've watched it, and that's important in itself.",
            "And by the way, there were some items in the data set that had no ratings.",
            "Those were the atoms in the test set for which you have to build prediction for that wasn't interesting information.",
            "You knew that if Netflix was asking you to predict an item and then the user had actually watched that, that was an important information, right?",
            "So you wanted to model that, and you could model that by putting it as an implicit feedback saying, hey, I know the user was that I don't know what the user said about that show, because that's what I need to find.",
            "But at least I know, and this is model in this part here and the other one is the rating which are basically modeling in this in this other part over here, right?",
            "And.",
            "Again, this has.",
            "This is the symmetric SVD which or what they call the symmetric SVD, which has a number of interesting.",
            "Properties and one of them is that you have.",
            "Much less parameters to estimate, so you can actually make this model.",
            "Invert and in a much better way than if you were going here to this other method where you have to decompose the whole user dimension, which is usually higher again in the items.",
            "So I said before this is not what they ended up using in the price.",
            "They use the SVD plus plus, which basically it's a hybrid between these two in which the explicit rating part is actually.",
            "It is modeled as a user vector user factor vector and the implicit one is left as it is here as a independent term.",
            "But the only reason they use that one is because they empirically got better results, but.",
            "In principle, if you have as much implicit as explicit feedback, you could use this decomposition and you should be able to get.",
            "Better results that in the Netflix Prize where the issue there is that you had many more explicit feedback.",
            "And by the way you were your objective function were ratings.",
            "It wasn't so much figuring out what the user like, but more of a rating prediction problem.",
            "OK, so the next one."
        ],
        [
            "This RBM restricted Boltzmann machine.",
            "Let me see how I'm doing in time.",
            "OK, we have 15 minutes until the break.",
            "So I'll probably go a little bit quicker on this.",
            "So restricted Boltzmann machine.",
            "Think of them as a form of neural network right there used right now as the basis for many of the deep learning approaches as part of the deep neural net and the basic idea is that they.",
            "To make learning easier, they restrict the kind of connectivity so they say well in general you only have one layer of hidden units.",
            "You can have more, but that's the general case, and more importantly you don't have connections between hidden units.",
            "And the hidden units are independent from the visible state.",
            "But again, maybe more."
        ],
        [
            "Important that what an RBM is is how it can be used for rating prediction, and this is something that.",
            "Actually Russell, and who is?",
            "I think he's giving a tutorial right now in parallel to this one.",
            "In one paper, very related to the Netflix price.",
            "I recommend you read this paper of restricted Boltzmann machine for collaborative filtering.",
            "They explained how to use our VM's for the Netflix Prize an using the Netflix Prize data set.",
            "And the basic idea is that you build an RBM.",
            "Restricted Boltzmann machine for every user.",
            "And you have the visibles.",
            "Which are the items?",
            "And then you can the number of hidden that you have here is actually a parameter and you.",
            "Activate you activate Visa buys for only those users that that.",
            "Sorry, only those items that the user has rated and basically use you have the algorithm here, but I just leave it for you to read later, but the idea is that you have to estimate this wedge the weights here that relate the visible to the heavens by doing a process that is very similar to the feed forward propagation that you would use in a neural net.",
            "Now there's a couple of important key findings that are presented in this paper.",
            "There are go beyond the traditional.",
            "DBM used usage that had happened until then.",
            "One of them is the fact that they also make use of those implicit ratings, so they actually implicit ratings, meaning those ratings in the data set that had.",
            "In the testing set that we knew the user had rated, but we didn't know the value for it, so they have a way of incorporating them into the PBM and the other one is what they call the factorize PBM's.",
            "Because the main problem you have here, once you define a machine for every user is that you have a huge number of parameters to estimate and you don't have.",
            "It's hard to make the collaboration happen between the different weights, so the idea here of every all the JS is that you want them to be the same.",
            "If a user rated an item and there's a hidden here and a different user rating another item so rated the same item you want this WI J to be the same right?",
            "And you need to put that into your objective into your training.",
            "Approach now doing that directly, you end up with a lot of parameters and it's complicated to solve.",
            "So what they actually did is the factorize this WIJ matrix.",
            "To reduce the number of parameters and to make the learning.",
            "Not only faster, but actually reduce the number of parameters that you had on the learning phase.",
            "So factorize restricted Boltzmann machines.",
            "That's a very interesting learning from the Netflix price.",
            "That is, again is being used in production."
        ],
        [
            "Now remember that as I said, the final system that went into production is actually a linear combination of this.",
            "Both these methods.",
            "Anne."
        ],
        [
            "Next question that I get always like hey wait a second, but I remember reading in the final Netflix Prize there were 107.",
            "Methods that were combined in an example using gradient boosted decision trees.",
            "What happened to the other 105 methods right?",
            "So the reality is that we never put them into production.",
            "And we didn't for a number of reasons.",
            "One of the main reasons is that the increase in harmacy from the first year.",
            "From the first year progress prize, using these two only, these two methods combine and the 107 was not so huge and the other one is because we realize that you know the engineering complexity of putting 105 more methods compared to increasing our messy was not really worth it.",
            "Now you're going to say wait, wait a second.",
            "You said that sometimes just a tiny increase in RMC might be worth millions.",
            "Why wasn't that worth it?",
            "The main reason it wasn't worth it is because.",
            "The focus of Netflix had changed at that point and rating prediction.",
            "We had realized that it was not a really key problem and we had many other algorithms that we wanted to worry about and those weren't really solved by improving the rating prediction, but by doing many other things that I'll discuss later, right?",
            "So again, rating prediction.",
            "Can be improved by adding all these other methods, but the tiny increase in Arma see for the business was not worth as much as improving many other algorithms that were different from the rating prediction one."
        ],
        [
            "OK, so let me talk about.",
            "Other things that you can do which I kind of, including this traditional approaches and one of them is clustering, and the reason include clustering here is because, well, you know we're talking about metrization as a way to reduce dimensionality as a way to address sparsity, and a way to also address the scalability problem that we have with nearest neighbor approaches.",
            "And if you thought about it.",
            "Just a little bit, you think?",
            "Well, you know another way to do this is by using cluster."
        ],
        [
            "So what how can we use clustering in the context of collaborative filtering?",
            "So clustering.",
            "The goal is to just group users.",
            "There are similar right?",
            "You could do the same with items, but I'm just focusing on users for now.",
            "And then you can.",
            "Compute recommendations at the cluster level so you say, well, this is really, you know, it's really very similar to what you were telling us before of the nearest neighbor approach, but we know that there are some methods for clustering their scale pretty well, and they're pretty efficient, right?",
            "So why not do that?",
            "So yeah, you can do that, and as a matter of fact."
        ],
        [
            "Clustering has been used in many different ways, and there's many different approaches that clustering have been used in practice.",
            "And one of them is LSH, actually, LSH, locality sensitive hashing.",
            "Which is a method for grouping.",
            "Element in a high dimensional this space.",
            "Basically, based on finding a hashing function that Maps or groups similar things to the same bucket, this is.",
            "This is really, I mean the main application of LSH is to approximate nearest neighbor, right?",
            "So it's a clear application that could be used.",
            "For collaborative filtering, and it has been used with some success.",
            "I know that, for example, that the folks at LinkedIn have said in the past and present it publicly that they were using LSH in some of their recommendation solutions.",
            "I don't know if they were using it anymore, but at least a couple of years ago they were talking about using LSH.",
            "And.",
            "Any form of clustering can be used as an even a preprocessing step to annuus neighbor approach right?",
            "So you can.",
            "Used"
        ],
        [
            "Things like K means and all its variations.",
            "Other things that I know have been used to some success are things like affinity propagation, which is just a better graph based K means if you will spectral clustering an nonparametric Bayesian clustering, for example here, ockleberry lyrically processes there was a last year here.",
            "Alex smola.",
            "Namor gave a very interesting tutorial.",
            "On this method, and if you learn here, you can go through their slides or some of the papers, but that's another very interesting approach to grouping users or items that are similar and therefore.",
            "Can be used either as a preprocessing step or as a replacement for some of these nearest neighbor approaches and.",
            "And I didn't mention this when I was talking about neutralization, about saying, well, how does this address many of the concerns that we have with nearest neighbor approaches.",
            "I didn't mention the title of the paper from who the current which was factorization meets the neighborhood, which actually in that paper itself they were all they were presenting.",
            "This asymmetric SPD and SPD plus plus at the end of the paper the goal was to combine both the maitre factorization plus the nearest neighbor approach because they both bring in.",
            "Similarity is a different level of granularity, so at the end both of these approaches are used are useful and you can combine them in different ways, right?",
            "And it's the same with clustering.",
            "You can use clustering plus or instead of nearest neighbors and plus or instead of matrix factorization."
        ],
        [
            "Another traditional approach which.",
            "Was not really using the context of the Netflix Prize, but I think I had to put it here because it's."
        ],
        [
            "It's pretty much.",
            "Widely using some context specially in.",
            "Shops in in.",
            "In domains where you have this idea of this notion of transaction right?",
            "So.",
            "The idea of transaction is you have a purchase or an action that you do, in which if you're buying, say, book.",
            "What do I have?",
            "If you.",
            "People who bought Book 3 or this person but book 3 and also bought book five and six in the context of a given transaction.",
            "So you build this Association rules in what you say.",
            "Well, people who buy this also by these other things in a given transaction, right in the context of supermarket market or shop or so on.",
            "It's it has clear applications right where you see there's a shopping cart and there's the.",
            "Classical sort of counter example of the diapers and beers and saying when people buy diapers they also buy beers and this is a sort of like.",
            "Probably it is an urban legend, but it's a way of explaining a good way of explaining this Association rules which are based on Co occurrences or things that happen together in the context of a transaction, right?",
            "An you have the classical apriori algorithm, which is fast to implement and execute, and this is an approach the Association rules approaches.",
            "Approach.",
            "It's classic traditional, but you should keep it in mind if your goal is to recommend things in the context of a given transaction, right?",
            "And if you have this notion of hey, the user is buying stuff, and I know what the user is buying right now, I just want to add things to what the user is buying right now.",
            "Sociation rules.",
            "Is a good approach.",
            "K."
        ],
        [
            "How am I doing have a?",
            "2 minutes, maybe let me try to.",
            "Quickly go through this so we know about classifiers, right?"
        ],
        [
            "We know that we can use them in many different ways, but here in the context of recommender systems, how do we use classifiers?",
            "Well, the most simplistic approach is if I have to decide if a user likes or doesn't like something.",
            "I can treat that as a 1 one class classification problem.",
            "Where I have or binary classification problem where I have positives and negatives an I have the users, the items the user liked, the atoms are user didn't like and just build a classifier right?",
            "So if you have ratings and you have a rating scale while you have to do something about it but you can do many things but the most simplistic approach, OK, I'll just treat anything there is one or two hours didn't like and four and five is like and I don't know what I'll do with the three.",
            "There's something to be done there but.",
            "The idea is that you can build.",
            "You can use all this.",
            "You know?",
            "Supervised learning literature and use things like logistic regression, support vector machines, tree and samples and so on and throw it at recognition problems.",
            "And it does.",
            "Pretty well, and as a matter of fact we will talk more about this when we talk about learning to rank.",
            "As some of you might know, the first approach and the simple approach to learning to rank is to treat it as a classification problem.",
            "So that's your initial step and you can build a rank ranking approach by using a classifier.",
            "The other into."
        ],
        [
            "Thing thing is that classifiers can use in collaborative filtering and content based.",
            "You need a relevant training set and you have to make take care of regularization to avoid overfitting."
        ],
        [
            "So let me finish with."
        ],
        [
            "Some limitation of collaborative filtering that will take us to content based later after the break.",
            "So cold start is an important one.",
            "And it's something you know many of these systems struggle with.",
            "Obviously, because you're basing all your recommendations on the interaction between the users and the items.",
            "When a user comes in, you have no interaction, so you have to.",
            "Cold start the system in a way, and that's a tricky thing for pure collaborative filtering approaches.",
            "The popularity bias is another one.",
            "Because your matrix is sparse and you have.",
            "You know ratings only.",
            "For a few items and those items tends to be the most popular ones.",
            "Those are the ones that tend to be recommended, right?",
            "And the unpopular items.",
            "It's harder to even call stardom or it's harder to make them bubble up and to recommend them will deal with some of them later on.",
            "Content based approaches.",
            "OK, so the content based recommendations which are very popular for text based products.",
            "The basic idea is that.",
            "You are going to build some feature vectors related to the items and those feature vectors are going to be based on the content."
        ],
        [
            "The items themselves.",
            "And then you can build a user model in a similar way an use that model you have from the user and the model you have based on the features from the item and then build things like.",
            "Now we go back to the classifier.",
            "For example classifying what are the items the user will like, what're the items the user won't like.",
            "It's the complete opposite approach to what we're doing before we don't take into account whatsoever the actions between users and items.",
            "We're purely based basing it on the similarity of the items and the content in the items."
        ],
        [
            "Now we don't have cold start problems.",
            "We don't have sparsity problems.",
            "We're pretty much able to recommend to users with unique taste.",
            "And we're able to recommend very unpopular items, because at the end is only based on the content, right?",
            "So if I know that you like dark comedies from the late 70s, all I need to find is those other dark comedies from the late 70s, and it doesn't matter how many people have liked it and you can provide explanations for that.",
            "I can tell you, hey, I recommended this to you because I know you like dark comedies from the late 70s.",
            "Now there are many problems to it, so actually it's not the.",
            "Something that we can go with, and it's not even something that can replace collaborative filtering.",
            "The.",
            "One of them is we need to find a way to encode items in a meaningful way through features, and that's not easy in other domains, right?",
            "So defining or representing a movie with a feature space of items based on the content, it's a tricky thing, but let alone movies, right?",
            "If you start going into some other trickier domains and say, OK, Now I want to represent, I need to represent clothes and I need to represent books and I need to represent everything that I wanted to recommend.",
            "In a way that I'm.",
            "Uniquely defining the content is tricky.",
            "The other one is that it's which are very related, is that difficult to implement serendipity, and it's easy to.",
            "Overfit or two pitching hold users for which you have few data points, right?",
            "What I was saying before that example of like, well if you watch an enemy all I'm going to give you our enemies or the dark comedies from the 70s.",
            "It's going to be the same thing, right?",
            "It's like because I'm basing all that I'm giving to you on the content.",
            "It's hard now to get you out from this niche content that you're watching to recommend something that has more serendipity."
        ],
        [
            "And there's another one, which is, I think, highlighted in this paper that came out of after the Netflix price.",
            "The monkey stick and his students were talking about even a few ratings are more valuable than metadata.",
            "What they did here is they try to use IMDb data to expand the data set from Netflix Price and to improve accuracy and what they saw is that you know, as much meta data that you added from the movies as much as they try to find content features, it really just a few ratings.",
            "They had made a much bigger improvement than all the data that they could use from the meta data.",
            "It's a very interesting paper.",
            "I recommend reading so in general, when somebody asked me like should I use a condom based approach?",
            "I said, well, you're better off starting with collaborative filtering.",
            "And make sure you have a way to address the star problem and some of the other issues.",
            "But content based is even trickier to get working."
        ],
        [
            "OK, and just to finish, you can combine methods in different ways and of."
        ],
        [
            "Course, you know if you have content and you have collaborative, why not building an example of both?",
            "And this is a graphic."
        ],
        [
            "You can see that.",
            "You know that adding both methods is always going to give you as always, right?",
            "We know samples work because if there are uncorrelated predictors, you're only going to get better results by combining them.",
            "So why not combine both methods?"
        ],
        [
            "And there's many different ways that you can hybridize or combine methods in recommender systems, which are here in this slide.",
            "And with that I'm going to."
        ],
        [
            "Let you go for coffee again.",
            "If you guys have questions or comments now during this 30 minutes, please come to me and I'll.",
            "Happily take questions an if not, I'll see you in the next part.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I'm chubby.",
                    "label": 0
                },
                {
                    "sent": "I'm again, I'm director of Netflix and I'll eat recommendation and personalization team.",
                    "label": 0
                },
                {
                    "sent": "And there we also do all other kinds of algorithms like search and so on.",
                    "label": 0
                },
                {
                    "sent": "But I'm going to be focusing on recommendations today and we're going to be giving this tutorial together with my friend Bombshell Mobasher who's sitting there on the 2nd row and he will be giving the second part.",
                    "label": 0
                },
                {
                    "sent": "And I don't usually wear political T shirts when I give tutorials, but I thought there was a special event Ann.",
                    "label": 0
                },
                {
                    "sent": "Given all this discussion around net neutrality, I thought I have to support Frank Underwood for his 2016 election.",
                    "label": 0
                },
                {
                    "sent": "How many of you know who Frank Underwood is?",
                    "label": 0
                },
                {
                    "sent": "OK, that's good.",
                    "label": 0
                },
                {
                    "sent": "How many of you know what the Netflix price was?",
                    "label": 0
                },
                {
                    "sent": "More people?",
                    "label": 0
                },
                {
                    "sent": "OK, that's that's what I what I call my geekiness in this index right.",
                    "label": 0
                },
                {
                    "sent": "It's the amount of people that know about the Netflix prize divided by the amount of people who know who Frank Underwood is.",
                    "label": 0
                },
                {
                    "sent": "Frank Underwood is a character in one of Netflix TV shows, House of Cards, which I really recommend you watch.",
                    "label": 0
                },
                {
                    "sent": "So anyway.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here's the rough outline, so there's going to be 2 parts of this tutorial.",
                    "label": 0
                },
                {
                    "sent": "The first part is going to be taking us 2 hours.",
                    "label": 0
                },
                {
                    "sent": "There's a coffee break in between, so there's a coffee break at 10 and I'm going to be introducing the recommender problem and talking about.",
                    "label": 1
                },
                {
                    "sent": "Traditional an beyond traditional method and then bam shot is going to take it from there and focus on one very particular interesting area of sort of like non traditional method which is context aware.",
                    "label": 0
                },
                {
                    "sent": "Recommendations.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And well, I had a list of publications here.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some of the things that I have in this slide, including the references you should have access to them through the website.",
                    "label": 0
                },
                {
                    "sent": "I just put them here so you can then later reference to them.",
                    "label": 0
                },
                {
                    "sent": "And this is the index of my talk.",
                    "label": 0
                },
                {
                    "sent": "I should mention, I really love questions and interruptions.",
                    "label": 0
                },
                {
                    "sent": "I was thinking that if I do get many questions, though, it's impossible that I get through my slide.",
                    "label": 0
                },
                {
                    "sent": "So we're going to do something slightly different, although I usually recommend people and encourage people to ask me questions throughout my presentation, I thought it might be better to just drive it, at least for the first hour with few questions or probably no questions.",
                    "label": 0
                },
                {
                    "sent": "Will have half an hour during the coffee break for me to answer all your questions.",
                    "label": 0
                },
                {
                    "sent": "And then on the second hour that I give, I'll open it up, especially if I get interesting questions during the coffee break.",
                    "label": 0
                },
                {
                    "sent": "I'll refer to them and maybe answer them for.",
                    "label": 0
                },
                {
                    "sent": "All the attendees, but just to make it, make sure that at least I guess I get through most of the slides that I have and I get to the more advanced topics that I guess most of you will be mostly interested.",
                    "label": 0
                },
                {
                    "sent": "I'll kind of drive it through the first hour with few interruptions as possible.",
                    "label": 0
                },
                {
                    "sent": "OK so.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The first part is probably going to be well known for most of you.",
                    "label": 0
                },
                {
                    "sent": "I hope I'm going to be giving a slightly different angle, and I think it's important to start there because even if you've heard about collaborative filtering, content based recommendation, maybe you haven't heard it in the context of what I'm going to be explaining later on, so I think it's good to set the foundations and the basis for what we're going to be talking for.",
                    "label": 0
                },
                {
                    "sent": "The other part of the tutorial.",
                    "label": 0
                },
                {
                    "sent": "And then on.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Beyond traditional methods, I'm going to go through a bunch of different approaches.",
                    "label": 0
                },
                {
                    "sent": "Some are new, some are not, so new, but all of them are kind of different to what I would call the traditional content and collaborative filtering approaches.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Let's start by giving the.",
                    "label": 0
                },
                {
                    "sent": "Basic introduction to the problem of recommendations right and I think of recommendations as a way.",
                    "label": 0
                },
                {
                    "sent": "Or not only it away, but the way to access information in an age where we have so much information, write an creates Anderson in the long tail, set it in the in chapter.",
                    "label": 0
                },
                {
                    "sent": "In the book we're leaving the Age of information entering the age of recommendations.",
                    "label": 1
                },
                {
                    "sent": "Even search in itself at some point.",
                    "label": 0
                },
                {
                    "sent": "Once the user has issued, the query can become a sort of recommendation, right?",
                    "label": 0
                },
                {
                    "sent": "And I work on personalized search algorithms that basically at the end become some sort of recommendations.",
                    "label": 0
                },
                {
                    "sent": "Advertising is slightly different, but it also uses many of the similar approaches that we will be talking about here where you want to tailor and personalize and target the user according to her his taste.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK so I like to talk.",
                    "label": 0
                },
                {
                    "sent": "Also about this paradox of choice.",
                    "label": 0
                },
                {
                    "sent": "This is a very interesting book.",
                    "label": 0
                },
                {
                    "sent": "There is a YouTube video of a talk that very sparse gave at Google, which I hardly recommend.",
                    "label": 0
                },
                {
                    "sent": "It's very interesting book and the idea this is from a psychology standpoint is this idea that sometimes we have this feeling that the more choices we have it, the better.",
                    "label": 0
                },
                {
                    "sent": "It turns out that choice overload produces this paralysis by analysis effect, where people have a harder time choosing when they have more choices and there is a very interesting experiment.",
                    "label": 0
                },
                {
                    "sent": "Which I usually refer to with some different jams in a little store in town in I think it was in California, but the idea was very simple.",
                    "label": 0
                },
                {
                    "sent": "Put some different flavors of jams to taste, and there were two different experiments.",
                    "label": 0
                },
                {
                    "sent": "In the first one, they use 16 different flavors.",
                    "label": 0
                },
                {
                    "sent": "In the second one, they use 64 different flavors of jams, right?",
                    "label": 0
                },
                {
                    "sent": "And people will walk into the store.",
                    "label": 0
                },
                {
                    "sent": "They would have them there to taste, and then they would decide if they wanted to buy or not, and guess in which case people bought more gems.",
                    "label": 0
                },
                {
                    "sent": "In the case where you had 16 versus 64, right?",
                    "label": 0
                },
                {
                    "sent": "Because having 64 gems in front of you, and deciding which one of those you like.",
                    "label": 0
                },
                {
                    "sent": "It's a huge problem and people just said you know what?",
                    "label": 0
                },
                {
                    "sent": "I'm not going to buy anything right?",
                    "label": 0
                },
                {
                    "sent": "So that's I think it's a very interesting explanation of why we want to reduce the choice and make sure that we present the best ones for each user.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "At the end of the day, everything ends up being personalized and we have many examples of why personalizing and recommending is actually something that is good for the user.",
                    "label": 0
                },
                {
                    "sent": "I'm going to be using throughout my talk a lot of experiments for Netflix.",
                    "label": 0
                },
                {
                    "sent": "Obviously some of them are not from Netflix, but many are.",
                    "label": 0
                },
                {
                    "sent": "I thought this headline that came out.",
                    "label": 0
                },
                {
                    "sent": "A few months ago was really interesting, right?",
                    "label": 0
                },
                {
                    "sent": "This is not something we wrote somebody.",
                    "label": 0
                },
                {
                    "sent": "It's a journalist that roast Netflix.",
                    "label": 0
                },
                {
                    "sent": "New feature knows you better than you know yourself because of algorithms.",
                    "label": 0
                },
                {
                    "sent": "And that's exactly true.",
                    "label": 0
                },
                {
                    "sent": "There's something that happened and we may be tested.",
                    "label": 0
                },
                {
                    "sent": "And we measured and we realize.",
                    "label": 0
                },
                {
                    "sent": "So there is a feature in Netflix.",
                    "label": 0
                },
                {
                    "sent": "For those of you that don't know it, it's called my list where users can actually save things that they want to watch in the future, right?",
                    "label": 0
                },
                {
                    "sent": "And you say, oh, this documentary is awesome.",
                    "label": 0
                },
                {
                    "sent": "I'll just add it to my list and I'll watch it someday.",
                    "label": 0
                },
                {
                    "sent": "Well, you know, you're never going to watch it no matter what you just added there because it looks cool, right?",
                    "label": 0
                },
                {
                    "sent": "To have documentaries in your list.",
                    "label": 0
                },
                {
                    "sent": "But the bottom line is we.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that people were adding a lot of things to the list and then wouldn't watch them again.",
                    "label": 0
                },
                {
                    "sent": "And the problem was we also allowed users to sort the list however they wanted, right?",
                    "label": 0
                },
                {
                    "sent": "So some people very few people like tiny fraction of the people would spend a lot of time sorting things out and I'm going to put them in different order and I know which one I want to watch first.",
                    "label": 0
                },
                {
                    "sent": "Those were the minority of people.",
                    "label": 0
                },
                {
                    "sent": "Most people would just add stuff in the queue and would never watch it again.",
                    "label": 0
                },
                {
                    "sent": "So we decided to.",
                    "label": 0
                },
                {
                    "sent": "Implement an algorithm which would take into account different signals to personalize and to say hey OK will let you add as much as many things as you want to the list, but then will rank them and sort them as we think that you want to see them and the result was very positive, so people started consuming for the list much more than they did before, right?",
                    "label": 0
                },
                {
                    "sent": "So this is an example of why even letting users take the initiative and take the action of sorting and organizing things might not be as good as.",
                    "label": 0
                },
                {
                    "sent": "An algorithm can do for them.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the traditional definition of recommender system, which I guess that's the one we will be deconstructing and recreating here in this tutorial today is we estimate a utility function that automatically predicts how a user will like an item and we do that based on past behavior relations to other users, adding similarity, context and whatever else you can throw to the problem.",
                    "label": 1
                },
                {
                    "sent": "The problem right?",
                    "label": 0
                },
                {
                    "sent": "So basically.",
                    "label": 0
                },
                {
                    "sent": "The traditional definition is we want to estimate a function that comes out with.",
                    "label": 0
                },
                {
                    "sent": "Number, which could be a probability of how much the user is likely to consume or two, like a given item.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now the core of the recommender system is actually pretty much a data mining problem, right?",
                    "label": 1
                },
                {
                    "sent": "And this is a.",
                    "label": 0
                },
                {
                    "sent": "Picture or.",
                    "label": 0
                },
                {
                    "sent": "Dataflow that I used in one of chapter four book.",
                    "label": 0
                },
                {
                    "sent": "It's called data mining methods for recommender systems.",
                    "label": 1
                },
                {
                    "sent": "It's part of a very interesting book I recommend which is the Handbook for Recommender Systems or sorry, the Recommender Systems Handbook.",
                    "label": 0
                },
                {
                    "sent": "So anyway, the basic idea is that the coral for recommender system is going to be a data mining system where you have the three blocks of data preprocessing, the model, learning and then the testing and validation.",
                    "label": 0
                },
                {
                    "sent": "And actually, most of the methods that you can think about in traditional data mining or machine learning, like supervised and unsupervised methods, and you have a huge list here.",
                    "label": 0
                },
                {
                    "sent": "Many of them can be used or have been used in a recommender system.",
                    "label": 0
                },
                {
                    "sent": "It doesn't mean that they all work very well, but they can be used right and will be going through some of them.",
                    "label": 0
                },
                {
                    "sent": "However, I do want to highlight that.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Little, you know we're hearing Kitty and we're going to be focusing on the recommender.",
                    "label": 0
                },
                {
                    "sent": "Problem from a data mining perspective.",
                    "label": 0
                },
                {
                    "sent": "There are many other things that go into recommender systems that we won't be talking about, or at least we won't be talking about at length.",
                    "label": 0
                },
                {
                    "sent": "But those are equally important.",
                    "label": 0
                },
                {
                    "sent": "Or some of them are even more important.",
                    "label": 0
                },
                {
                    "sent": "For example, the user interface, right?",
                    "label": 1
                },
                {
                    "sent": "So it doesn't matter how good your algorithm is if you actually hide your recommendations in place in a web page that nobody can see, well, you're not going to get anything out of the recommendation, right, so?",
                    "label": 0
                },
                {
                    "sent": "Obviously the user interface and how you present that it's really important.",
                    "label": 0
                },
                {
                    "sent": "System requirements will talk about some of them sometimes like scalability and so on.",
                    "label": 0
                },
                {
                    "sent": "Privacy those are all very important serendipity, diversity, awareness explanations.",
                    "label": 1
                },
                {
                    "sent": "And this last I will be talking this last four I will be talking a little bit more about them because we can do something about them in the algorithm makes sense.",
                    "label": 0
                },
                {
                    "sent": "So serendipity in particular.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It's super important, right?",
                    "label": 0
                },
                {
                    "sent": "Because we define serendipity as something finding something that you weren't looking for.",
                    "label": 0
                },
                {
                    "sent": "An surprises you in a way that really beyond what you expected to find.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "This is.",
                    "label": 0
                },
                {
                    "sent": "In essence, a key feature of a recommender system, right?",
                    "label": 0
                },
                {
                    "sent": "If we only recommend things the user already knew that were there already knew that he or she could find that really defeating the purpose of the recommender system.",
                    "label": 1
                },
                {
                    "sent": "So we do want to, in some sense, push for some serendipity and try to have some sort of exploration built in.",
                    "label": 0
                },
                {
                    "sent": "The recommendations that we present to the user, and we can have some ways we can.",
                    "label": 0
                },
                {
                    "sent": "Add some things to some algorithms that induce some sort of exploration or some sort of serendipity, and in other words, we don't want to do something like if the user first time that comes into our service decides to watch an anime title all of a sudden, all his recommendation, all his webpage, it's made of animated movies right?",
                    "label": 0
                },
                {
                    "sent": "Because?",
                    "label": 0
                },
                {
                    "sent": "Probably the user had other tastes and we do want the user to explore those other tastes.",
                    "label": 0
                },
                {
                    "sent": "Then X.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Nation and support for recommendations.",
                    "label": 1
                },
                {
                    "sent": "That's also an important piece of the puzzle, and something that you can build algorithmic components around.",
                    "label": 0
                },
                {
                    "sent": "The idea is that.",
                    "label": 0
                },
                {
                    "sent": "You want to get the user involved in the recommendation and the personalization process itself, and you do by you do that in different ways.",
                    "label": 0
                },
                {
                    "sent": "One is by giving some incentives to the user to give you feedback and the other one which is this one is by giving explanations to this or why you're recommending something so the user sees the value of the recommendation system and keeps giving you feedback right?",
                    "label": 0
                },
                {
                    "sent": "So here you have an example.",
                    "label": 0
                },
                {
                    "sent": "This is from the.",
                    "label": 0
                },
                {
                    "sent": "Netflix UI, where if you put your mouse over a movie, you'll get what we call the Blob, which is something like this.",
                    "label": 0
                },
                {
                    "sent": "This little thing has a ton of recommend.",
                    "label": 0
                },
                {
                    "sent": "Sorry of explanations around it were giving you so much information about why this is being recommended to you.",
                    "label": 0
                },
                {
                    "sent": "Of course there's the typical one about.",
                    "label": 0
                },
                {
                    "sent": "OK, you know the title, the rating, the duration, the year.",
                    "label": 0
                },
                {
                    "sent": "There's all these actors.",
                    "label": 0
                },
                {
                    "sent": "The director.",
                    "label": 0
                },
                {
                    "sent": "That's something that might have gone into the recommendation algorithm, right?",
                    "label": 0
                },
                {
                    "sent": "There's also here based on your interest in Arrow, meant to annexe meant and whatever.",
                    "label": 0
                },
                {
                    "sent": "So we're telling you, OK, if you like those things are going to like this.",
                    "label": 0
                },
                {
                    "sent": "This is another support.",
                    "label": 0
                },
                {
                    "sent": "Another explanation, we're also giving you the rating right?",
                    "label": 0
                },
                {
                    "sent": "So we're also giving you the rating prediction, which is also supporting the fact that you're going to like this, and that's why we're recommending it.",
                    "label": 0
                },
                {
                    "sent": "Even telling you this is an old picture we this is the list feature that I was calling you that was explaining before it was previously called Instinct, but we're basically telling you, hey, you save this for watching before, so you probably want to watch it right?",
                    "label": 0
                },
                {
                    "sent": "Even using this is another screenshot from the.",
                    "label": 0
                },
                {
                    "sent": "IPhone application, even using social support and telling you hey you have some friends that watch that.",
                    "label": 0
                },
                {
                    "sent": "So all those pieces which can make it into the algorithm and actually will talk about how they can make it.",
                    "label": 0
                },
                {
                    "sent": "You should also think about using them in the form of support or explanation for the recommendation, OK?",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I also I already mentioned awareness.",
                    "label": 0
                },
                {
                    "sent": "We want to make the users aware and part of the recommendation process.",
                    "label": 0
                },
                {
                    "sent": "We do that for example here in the top ten we use the name of the user and we are actually making it explicit that this is for you and it's has been personalized and also diversity is another key issue that I won't be talking a lot about.",
                    "label": 0
                },
                {
                    "sent": "But sometimes we want to include some form of.",
                    "label": 0
                },
                {
                    "sent": "Induced diversity into our algorithms in a way that we can, for example, in the case of Netflix for many households, we are not making the recommendation for a single person will actually make them making them for a household that is made of different people.",
                    "label": 0
                },
                {
                    "sent": "This is actually my household and I have a son, a daughter and my wife.",
                    "label": 0
                },
                {
                    "sent": "And then when I look at this recommendations that go here into this list, I can actually see recommendations that would be better for one or the other or for the conjunction of all of them.",
                    "label": 0
                },
                {
                    "sent": "And that's something.",
                    "label": 0
                },
                {
                    "sent": "But we also need to build into our algorithms.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so in general what works right?",
                    "label": 1
                },
                {
                    "sent": "And this is a question that I get many times, specially when I talk to.",
                    "label": 0
                },
                {
                    "sent": "Small companies startups like OK, You know this is all very fancy and you're talking about deep learning and about what not.",
                    "label": 0
                },
                {
                    "sent": "But if I want to start small, I want something.",
                    "label": 0
                },
                {
                    "sent": "What's the easiest thing that I can do that works so?",
                    "label": 0
                },
                {
                    "sent": "Course the answer is it depends on your problem in the domain and the data you have and everything else.",
                    "label": 1
                },
                {
                    "sent": "But if I had to go blindly with something, I would say go with collaborative filtering an if I had to even narrow it down to something smaller or something that I could tell you.",
                    "label": 0
                },
                {
                    "sent": "Start right away.",
                    "label": 1
                },
                {
                    "sent": "I would say, well, start with some kind of dimensionality reduction like matrix factorization or SVD, because those have proven to be simple and useful in the general case right?",
                    "label": 0
                },
                {
                    "sent": "And will go through.",
                    "label": 0
                },
                {
                    "sent": "All this in more detail, but this is roughly the idea or the simplification of solving the traditional recommender problem in a way that in many cases will work.",
                    "label": 0
                },
                {
                    "sent": "Now when I talk about the recommender problem in the.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Solution that we're going to be looking at during the tutorial.",
                    "label": 0
                },
                {
                    "sent": "This is the picture that I want you to.",
                    "label": 0
                },
                {
                    "sent": "Getting your head.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "In the Netflix Prize, we simplify the recommendation problem to predicting a rating, and we said, well, we know the recommend recommendation problem has a lot of many other things.",
                    "label": 0
                },
                {
                    "sent": "As we've already seen before.",
                    "label": 0
                },
                {
                    "sent": "But let's try to find something that is easily an objective and easy to optimize, easy to measure, and that is going to focus people in just optimizing for one simple metric, right?",
                    "label": 0
                },
                {
                    "sent": "So well are messy rating prediction.",
                    "label": 0
                },
                {
                    "sent": "That's easy and we simplified to one single number.",
                    "label": 0
                },
                {
                    "sent": "One prediction problem, an root mean square error.",
                    "label": 0
                },
                {
                    "sent": "And that's OK. That's a good simplification.",
                    "label": 0
                },
                {
                    "sent": "But the recommendation problem is much broader than that, and what we're going to be doing in this tutorial is actually going kind of adding different dimensions to the recommender problem and a way to look at it is, well, we started with a single point, which is a rating prediction.",
                    "label": 0
                },
                {
                    "sent": "We can expand that to something that actually much better than rating prediction, which is ranking really what you want to do in a recommender system is you want to predict the rating because at the end you want to produce.",
                    "label": 0
                },
                {
                    "sent": "Well, rating you want to predict score because at the end you want to produce a ranking right?",
                    "label": 0
                },
                {
                    "sent": "So let's talk about ranking and we'll be talking about learning to rank.",
                    "label": 0
                },
                {
                    "sent": "If we make this even more complicated, really people don't have a single list in their homepage or in their device or wherever they're looking at their recommendation.",
                    "label": 0
                },
                {
                    "sent": "They actually have a full page of things and some compete with each other, and there's attention modeling going on, and there are many things that we need to take into account so we can go into the.",
                    "label": 0
                },
                {
                    "sent": "Dimensional problem of page optimization and finally.",
                    "label": 1
                },
                {
                    "sent": "If we add context into it, which we can add actually not only three dimensions as many dimensions as you want.",
                    "label": 0
                },
                {
                    "sent": "If you think about it, we're not only thinking about the user looking at a page, we're actually looking, thinking about looking at the user.",
                    "label": 0
                },
                {
                    "sent": "So thinking about the user looking at a page in a given context, it will be on a given day on a given time of the day with a given device and a given location and all of that piles into the recommended problem.",
                    "label": 0
                },
                {
                    "sent": "And it's something that we will be tackling with different algorithms, OK?",
                    "label": 0
                },
                {
                    "sent": "So let's get started.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This was kind of like introduction into the problem that we're going to be.",
                    "label": 0
                },
                {
                    "sent": "Talking about and we'll start with the traditional methods and collaborative filtering, so bear with me.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is known for many of you, but I think it's good as I said too.",
                    "label": 0
                },
                {
                    "sent": "Set the basis of what we're going to be talking about.",
                    "label": 0
                },
                {
                    "sent": "So the.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Collaborative filtering ingredients.",
                    "label": 0
                },
                {
                    "sent": "Simple, we have a list of users, some items and.",
                    "label": 0
                },
                {
                    "sent": "Some of those items have an associated opinion which could be explicit and we talk about explicit feedback when we have a number that is associated with the user telling us.",
                    "label": 0
                },
                {
                    "sent": "OK, this is how much I liked this item.",
                    "label": 0
                },
                {
                    "sent": "Or can be implicit an implicit means it's been derived from an interaction from the user.",
                    "label": 0
                },
                {
                    "sent": "So if the user clicked on that, we assume the user liked it.",
                    "label": 0
                },
                {
                    "sent": "That's not always the case, right?",
                    "label": 0
                },
                {
                    "sent": "And we have to be careful with that in many domains.",
                    "label": 0
                },
                {
                    "sent": "For example, when I work on witches movie, watching if you click on a movie and you watch it for five minutes, but you stop and never watch it again, that might not be a good thing, right?",
                    "label": 0
                },
                {
                    "sent": "It's like you started watching it didn't like it so.",
                    "label": 0
                },
                {
                    "sent": "How you define your implicit feedback and how do you find whether it's positive or negative?",
                    "label": 0
                },
                {
                    "sent": "That's a whole other story.",
                    "label": 0
                },
                {
                    "sent": "We won't get into, but in any case you have explicit or implicit feedback associated with a list of items in a list of users.",
                    "label": 1
                },
                {
                    "sent": "And then basically you take one active user, so I know about all the people in this room and I take one active users.",
                    "label": 0
                },
                {
                    "sent": "OK, now I'm going to try to figure out a recommendation for you.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "In the traditional approach.",
                    "label": 0
                },
                {
                    "sent": "What I need is a similarity between users and a method for selecting a subset of neighbors for that person, right?",
                    "label": 1
                },
                {
                    "sent": "So basically once I pick my person in the room and say OK, I'm going to recommend something for you.",
                    "label": 0
                },
                {
                    "sent": "My next question becomes OK, let me find who are the most similar people to you in this room and I'll pick five people and I'll ask questions to those five people say hey, what do you guys like?",
                    "label": 0
                },
                {
                    "sent": "And looking at those answers I'll figure out what you as the active user would want to watch.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "A good question to ask is how does that compare to the non personalized case, right?",
                    "label": 0
                },
                {
                    "sent": "There's a much easier approach, which is actually always a good baseline to keep in mind, which is, like, you know, this sounds very complicated.",
                    "label": 0
                },
                {
                    "sent": "Why don't I instead of figuring out who your best the people most similar to you are, let me ask everyone in the room just what's their favorite movie, and then when I want to predict something for you, I'll just pick whatever everyone has said, right?",
                    "label": 0
                },
                {
                    "sent": "That's the unpersonalized.",
                    "label": 0
                },
                {
                    "sent": "If everyone likes very much this movie, chances are you're going to like it, right?",
                    "label": 0
                },
                {
                    "sent": "And that's actually not a bad baseline.",
                    "label": 0
                },
                {
                    "sent": "Having popularity of global popularity.",
                    "label": 0
                },
                {
                    "sent": "Baseline, the non personalized is something a good starting point, right?",
                    "label": 0
                },
                {
                    "sent": "So how do the two approaches compare?",
                    "label": 1
                },
                {
                    "sent": "So here.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There is a.",
                    "label": 0
                },
                {
                    "sent": "2 charts that I think are interesting to keep in mind.",
                    "label": 0
                },
                {
                    "sent": "The first one relates to the Netflix price.",
                    "label": 0
                },
                {
                    "sent": "So here on this axis you see the root mean square error.",
                    "label": 0
                },
                {
                    "sent": "Ann here there are different approaches to figuring out the recommendation.",
                    "label": 0
                },
                {
                    "sent": "The first one, which is really bad is the random right?",
                    "label": 0
                },
                {
                    "sent": "So I'll just give you a random rating for as a prediction for you now.",
                    "label": 0
                },
                {
                    "sent": "This one here.",
                    "label": 0
                },
                {
                    "sent": "Is the average rating, so this is the unpersonalized average which I was talking about.",
                    "label": 0
                },
                {
                    "sent": "Take all the ratings, average them and just predict with the average.",
                    "label": 0
                },
                {
                    "sent": "This other one in red one.",
                    "label": 0
                },
                {
                    "sent": "This is the Cinemax.",
                    "label": 0
                },
                {
                    "sent": "So this is basically the one Netflix gave out as the baseline to beat, and this one here was the price right?",
                    "label": 0
                },
                {
                    "sent": "So the first thing you see or the first thing that you realize is well in terms of room, in square or whatever the metric you figure out really.",
                    "label": 0
                },
                {
                    "sent": "There's not much difference between something perfect if you will, I mean, well, perfect will be would be 0 but.",
                    "label": 0
                },
                {
                    "sent": "The price is pretty good and something which is just the average right?",
                    "label": 0
                },
                {
                    "sent": "So beating the average of the Unpersonalized case is not as easy an sometimes.",
                    "label": 0
                },
                {
                    "sent": "Simple to come up with something reasonable and beating that something reasonable with something that is better than reasonable.",
                    "label": 0
                },
                {
                    "sent": "It takes a lot of effort and all of time it actually took three years and thousands of people working on the Netflix Prize.",
                    "label": 0
                },
                {
                    "sent": "Right now.",
                    "label": 0
                },
                {
                    "sent": "However, the tricky Anki issue here is.",
                    "label": 0
                },
                {
                    "sent": "That doesn't mean that it's not valuable, it is actually valuable.",
                    "label": 0
                },
                {
                    "sent": "And it's very.",
                    "label": 0
                },
                {
                    "sent": "That's why we're all here, I guess, right?",
                    "label": 0
                },
                {
                    "sent": "Or that's why I have a job.",
                    "label": 0
                },
                {
                    "sent": "It's because it's really valuable to increase the accuracy and to improve the algorithms in recommendations to the business, right?",
                    "label": 0
                },
                {
                    "sent": "Just measure in how much more money that business is going to make.",
                    "label": 0
                },
                {
                    "sent": "Just increasing that harmacy by percentage point is worth a lot of money, so it's interesting to see that from the algorithmic perspective, improving that 1% on the metric.",
                    "label": 0
                },
                {
                    "sent": "Even a few percentage points over the baseline, it's complicated.",
                    "label": 0
                },
                {
                    "sent": "However, it's really worth it from a business perspective.",
                    "label": 0
                },
                {
                    "sent": "Here there's another comparison.",
                    "label": 0
                },
                {
                    "sent": "There's different public datasets that you probably should be used to.",
                    "label": 0
                },
                {
                    "sent": "Movie Lens is the most typical one.",
                    "label": 0
                },
                {
                    "sent": "The gesture for news and each movie.",
                    "label": 0
                },
                {
                    "sent": "And here you have the comparison.",
                    "label": 0
                },
                {
                    "sent": "This is mean average error instead of root mean square error.",
                    "label": 0
                },
                {
                    "sent": "But basically it's the same and you see the comparison between the non personalized average and the personalized average OK?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how do we do collaborative filtering?",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "How do we do user based collaborative filtering?",
                    "label": 0
                },
                {
                    "sent": "Which is the initial and the most simple approach to recommendation, right?",
                    "label": 0
                },
                {
                    "sent": "So again, we find the neighborhood.",
                    "label": 0
                },
                {
                    "sent": "For the target user, according to a similarity function between users, and then we identify those products that that neighborhood liked and we generate the prediction based on those items that those users liked.",
                    "label": 1
                },
                {
                    "sent": "Basically, to put in some formulation into it.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We have a collection of users and a collection of products and then we can think and we will usually think of this as a matrix of North by M ratings.",
                    "label": 1
                },
                {
                    "sent": "Where the rating will be unknown.",
                    "label": 1
                },
                {
                    "sent": "If the user I did not write that product J right so then how do we come up with a prediction for a user I and approach A so we can do it in two different ways.",
                    "label": 0
                },
                {
                    "sent": "The simpler approach is we say we just average over the users an we wait.",
                    "label": 0
                },
                {
                    "sent": "That rating that those neighbors had by a similarity, or we do slightly more complicated thing, which is basically we just.",
                    "label": 0
                },
                {
                    "sent": "Instead of.",
                    "label": 0
                },
                {
                    "sent": "Average averaging over the direct rating of those neighbors we average over the deviation from the average right?",
                    "label": 0
                },
                {
                    "sent": "So V sub K is the average rating.",
                    "label": 0
                },
                {
                    "sent": "That item has an we.",
                    "label": 0
                },
                {
                    "sent": "Compute the deviation from each user to the average and then we weighted by the similarity.",
                    "label": 0
                },
                {
                    "sent": "And of course we add that to the global average.",
                    "label": 0
                },
                {
                    "sent": "So the basic idea is we get those neighbors.",
                    "label": 0
                },
                {
                    "sent": "We see how they rated that item.",
                    "label": 0
                },
                {
                    "sent": "We see how similar they are to you, right?",
                    "label": 0
                },
                {
                    "sent": "Because now we're not just assuming that those five people that we found that are similar to the target user are equally similar.",
                    "label": 0
                },
                {
                    "sent": "There is a similarity function.",
                    "label": 0
                },
                {
                    "sent": "We wait there at rating by the similarity to the target user and then we compute the prediction this way.",
                    "label": 0
                },
                {
                    "sent": "And there's different ways to compute that U, which is the similarity.",
                    "label": 0
                },
                {
                    "sent": "You can compute it using.",
                    "label": 0
                },
                {
                    "sent": "Pearson correlation you can use just a cosine similarity.",
                    "label": 0
                },
                {
                    "sent": "There are different ways that you can compute similarity, but the idea is always the same, right?",
                    "label": 0
                },
                {
                    "sent": "And this is the basic approach and this is this by the way.",
                    "label": 0
                },
                {
                    "sent": "Going back to the Netflix Prize is pretty similar to what was being done in the baseline.",
                    "label": 0
                },
                {
                    "sent": "The Cinemax prediction, once the Netflix Prize was published.",
                    "label": 0
                },
                {
                    "sent": "And this is it makes sense.",
                    "label": 0
                },
                {
                    "sent": "It's from an intuitive perspective looking at the users looking at how similar those neighbors are to you, looking at their predictions, an waiting their predictions by how similar they are to you.",
                    "label": 0
                },
                {
                    "sent": "It's very intuitive approach.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "If we look at it.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This way this is exactly what I just explained, but in an example right and here we have different users and different shows and how they rated those shows from one to five stars.",
                    "label": 0
                },
                {
                    "sent": "And the.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "First thing we do is we compute the similarity from a user to a user.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Basically.",
                    "label": 0
                },
                {
                    "sent": "We're looking at.",
                    "label": 0
                },
                {
                    "sent": "Making predictions from this user and we're trying to figure out what's the similarity from this user to all the different users, right?",
                    "label": 0
                },
                {
                    "sent": "For example, the similarity from this user to this user will be based on the single movie that they rated equally, which is The Avengers, and then the similarity will be one.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The similarity between these two users will be minus one.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm using the Pearson correlation by the way here.",
                    "label": 0
                },
                {
                    "sent": "And then once we have the similarity from the different users, basically what we do is go to their ratings and we base the prediction for the user on the.",
                    "label": 0
                },
                {
                    "sent": "Product of the different users.",
                    "label": 0
                },
                {
                    "sent": "Their ratings and the similarity to the target user.",
                    "label": 0
                },
                {
                    "sent": "And that's sorry.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We would get as an estimate of this ratings for this given user, so it's a very simple and very effective way of doing a prediction for giving user.",
                    "label": 0
                },
                {
                    "sent": "The first change that we do to that is well, instead of using user based neighborhoods and user base similarities, why don't we think about it in the terms of in the form of item?",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And that takes us to the item based collaborative filtering algorithm, which is usually by the way more effective, right?",
                    "label": 1
                },
                {
                    "sent": "So if you think about user based collaborative filtering as being more intuitive.",
                    "label": 0
                },
                {
                    "sent": "The first, the first thing you should know is the item base is more effective for.",
                    "label": 0
                },
                {
                    "sent": "Different reasons, one of them is usually the item space is more reviews than your user space usually have more users than you do items.",
                    "label": 0
                },
                {
                    "sent": "But the idea of item based collaborative filtering is exactly the same, except that you reverse the access.",
                    "label": 0
                },
                {
                    "sent": "So you look at the items that the target user has rated, and then you compute the similarity between those target items that you want to predict and those items that the user has rated.",
                    "label": 1
                },
                {
                    "sent": "Now, very important here is you still only using ratings or opinions from the users, right?",
                    "label": 0
                },
                {
                    "sent": "So here you are building a similarity function between items, but that similarity function is only based on the opinion from the users or the rating from the user.",
                    "label": 0
                },
                {
                    "sent": "So basically instead of figuring out out figuring out now how similar you are to him now I'm figuring out how similar those two movies are between themselves and I'm figuring that out just based on what the user rated, right?",
                    "label": 0
                },
                {
                    "sent": "So I'm.",
                    "label": 0
                },
                {
                    "sent": "Using the rating from the users to figure that out.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There's different ways that I can compute that similarity, and again I can use the.",
                    "label": 0
                },
                {
                    "sent": "Cosine similarity or a little.",
                    "label": 0
                },
                {
                    "sent": "Better thing that I can do is use the adjusted cosine similarity, which takes into account something that we usually need to adjust for, which is the difference in rating scales.",
                    "label": 1
                },
                {
                    "sent": "An rating averages between different items.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this would be, you know, it's simple.",
                    "label": 0
                },
                {
                    "sent": "It's intuitive, but it doesn't work that well all the time and why it doesn't work that well.",
                    "label": 0
                },
                {
                    "sent": "And why do we need to go beyond this today?",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Approaches.",
                    "label": 0
                },
                {
                    "sent": "Well, the process of this is that it requires minimal knowledge.",
                    "label": 1
                },
                {
                    "sent": "You don't need to know about anything about the items, by the way, the same approach that I'm using for movies.",
                    "label": 0
                },
                {
                    "sent": "I can use it for books or for recommending cats and dogs.",
                    "label": 0
                },
                {
                    "sent": "It's going to work is the same.",
                    "label": 0
                },
                {
                    "sent": "And it produces good enough results that we said, you know, it's a good enough baseline.",
                    "label": 0
                },
                {
                    "sent": "But there are many challenges.",
                    "label": 0
                },
                {
                    "sent": "The two main challenges that will tackle in the next slides is sparsity.",
                    "label": 1
                },
                {
                    "sent": "If we have in most datasets what we have is that we only have interactions for about, say, less than 1% of user item pairs and 1% is already pretty high number, right?",
                    "label": 0
                },
                {
                    "sent": "It depends on the size of your catalog, but if you think about size of catalogs like say eBay with millions of items in the catalog, you're going to have much less than 1%.",
                    "label": 0
                },
                {
                    "sent": "So figuring out the similarities between users or items based on such a sparse matrix, it's very challenging.",
                    "label": 0
                },
                {
                    "sent": "Scalability is another challenge.",
                    "label": 0
                },
                {
                    "sent": "Scaling up this neighborhood based method is super difficult.",
                    "label": 0
                },
                {
                    "sent": "I mean, if you just think again, think about the user based collaborative filtering approach.",
                    "label": 0
                },
                {
                    "sent": "If I have to decide which are your five best neighbors out of a collection of say 100 million users, well I'm going to have to compute 100 million distances and similarities for each user, right?",
                    "label": 0
                },
                {
                    "sent": "So that square?",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Going a little bit more into the sparsity problem.",
                    "label": 1
                },
                {
                    "sent": "So as I was saying, you will have large product set set an only ratings and only interaction from users to a very tiny proportion of those ratings.",
                    "label": 1
                },
                {
                    "sent": "If we look at the rating, the ratings in the Netflix price.",
                    "label": 0
                },
                {
                    "sent": "Basically what we have is 500,000.",
                    "label": 0
                },
                {
                    "sent": "Items times sorry users times 17,000 items or movies which gives us around 8.5 billion positions in this matrix, out of which only 100 millions are non 0 right?",
                    "label": 1
                },
                {
                    "sent": "So basically what you're looking at is a huge matrix full of zeros and every now and then you see a one here or a one or a.",
                    "label": 0
                },
                {
                    "sent": "Five or three, but most of it is made of zeros, and that's a challenge for this neighborhood based approaches.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that brings us to the next step.",
                    "label": 0
                },
                {
                    "sent": "OK, So what can we do better?",
                    "label": 0
                },
                {
                    "sent": "So those methods that we talked about, what we call memory based?",
                    "label": 0
                },
                {
                    "sent": "They don't really build a model, they just used using the ratings as they are, and building predictions out of the similarities and out of the ratings themselves.",
                    "label": 0
                },
                {
                    "sent": "But we know better than that and we can build models, right?",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we can build all sorts of models because we've all read a bunch of machine learning books an we say, well, we can use probabilistic models like various networks, non supervised approaches, clustering rule based approaches like Association rule.",
                    "label": 0
                },
                {
                    "sent": "We can build a classifier, use regression, LDA, whatnot can throw everything at the problem.",
                    "label": 0
                },
                {
                    "sent": "Right now the question is knowing.",
                    "label": 0
                },
                {
                    "sent": "What should we use?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What did we learn from the price?",
                    "label": 1
                },
                {
                    "sent": "And I think that's what the price the Netflix Prize bertels was from this initial idea of like let's use memory based collaborative filtering to being a little bit smarter and saying, OK, let's build models and let's use a model based approach.",
                    "label": 0
                },
                {
                    "sent": "What do we learn?",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So again, just as a reminder, the question we were.",
                    "label": 1
                },
                {
                    "sent": "We had this, can you improve the cinemat with which I said was roughly based based on a neighborhood approach, the cinemate.",
                    "label": 0
                },
                {
                    "sent": "Predictions by 10%.",
                    "label": 0
                },
                {
                    "sent": "If you do that and 10% measuring root mean square error, you'll get $1,000,000, right?",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the top two algorithms, even after the first year, so that was the 2007 progress price where SVD or a form of SVD that I'll get into in a little bit.",
                    "label": 1
                },
                {
                    "sent": "Which had a room in square of Zero 8914 an restricted Boltzmann machines, which I'll also explain.",
                    "label": 0
                },
                {
                    "sent": "With Zero Point 8990 and if you did a simple linear blend of those two algorithms, you got zero 88.",
                    "label": 1
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "We were so excited by that time with the results of these algorithms already beating the Cinemax that actually those two algorithms made it into production.",
                    "label": 0
                },
                {
                    "sent": "So there even as of today they are part of the production system that predicts the ratings, not the rest of the things with the ratings of the Netflix system.",
                    "label": 1
                },
                {
                    "sent": "And of course there were some challenges on the engineering side, but basically bottom line is those two algorithms as they were, were pretty good in terms of prediction.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "Let's talk a little bit about SV.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Ian Metrization and why it matters and why.",
                    "label": 0
                },
                {
                    "sent": "I said it's one of the.",
                    "label": 0
                },
                {
                    "sent": "Default method that you should.",
                    "label": 0
                },
                {
                    "sent": "You think about using if you.",
                    "label": 0
                },
                {
                    "sent": "Don't know what else to use.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The initial thing where you have to think about.",
                    "label": 0
                },
                {
                    "sent": "Major factorization is basically you're taking highly dimensional problem, breaking it into smaller dimensionality by splitting a big matrix into three smaller matrices, right?",
                    "label": 0
                },
                {
                    "sent": "An?",
                    "label": 0
                },
                {
                    "sent": "The idea is that you have N * M and you have users and you have items.",
                    "label": 0
                },
                {
                    "sent": "Sorry here I'm using M4 users and N for videos or items and you break it into three matrices.",
                    "label": 0
                },
                {
                    "sent": "In which now for all of them there's a new dimension that comes up here, which is R, which is the number of latent factors that you decide that that problem is going to have, and that makes your problem so much easier.",
                    "label": 0
                },
                {
                    "sent": "In the case of the Netflix price, most of the approaches successful approaches were using as little as 50, sometimes from 50 to 100 latent factor.",
                    "label": 0
                },
                {
                    "sent": "So you were reducing the dimensionality of the problem.",
                    "label": 0
                },
                {
                    "sent": "Too much smaller matrix then in this case it still had all your users, but now have 50 factors.",
                    "label": 0
                },
                {
                    "sent": "Instead of having thousands of items, right?",
                    "label": 0
                },
                {
                    "sent": "And there's another added benefit to this is that now instead of having a sparse matrix, you have a matrix that is actually non sparse.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So how?",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Did you do that?",
                    "label": 0
                },
                {
                    "sent": "So it's it's tricky to compute the SVD of a large matrix, especially when it's so sparse and has so many zeros.",
                    "label": 0
                },
                {
                    "sent": "But turn out that.",
                    "label": 0
                },
                {
                    "sent": "In 2006, at the end of 2006, in the context of a Netflix price, there was this interesting blog post by Simon Funk in New Zealand who explained something he was doing to the Netflix Prize data set by using an approximate, it's actually not.",
                    "label": 0
                },
                {
                    "sent": "A mathematical SPD.",
                    "label": 0
                },
                {
                    "sent": "This approximate way to compute the SVD by using gradient descent, and that's become the defacto way of actually doing the matrix.",
                    "label": 1
                },
                {
                    "sent": "Factorization for large sparse datasets.",
                    "label": 0
                },
                {
                    "sent": "By using this gradient descent approach in which basically you are avoiding overfitting by adding a regularization term.",
                    "label": 0
                },
                {
                    "sent": "That's the basic idea.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how do you do?",
                    "label": 0
                },
                {
                    "sent": "How do you use this in in performer rating prediction?",
                    "label": 0
                },
                {
                    "sent": "How do you use these matrices and the result of the metric factorization or the approximate SVD for rating factorization?",
                    "label": 1
                },
                {
                    "sent": "So the way to think about it is first by thinking.",
                    "label": 0
                },
                {
                    "sent": "Well, once you have this decomposition here where you have this matrix you here in this matrix V what you actually have is.",
                    "label": 0
                },
                {
                    "sent": "Two different kinds of vectors.",
                    "label": 0
                },
                {
                    "sent": "The user factors, which are the piece of you and the Atom factors with which are the cues of V. And then all you do.",
                    "label": 0
                },
                {
                    "sent": "Is multiply the user factors times the item factors, which is something you do here in this term.",
                    "label": 0
                },
                {
                    "sent": "And you add them too.",
                    "label": 0
                },
                {
                    "sent": "A baseline or a bias term, right?",
                    "label": 0
                },
                {
                    "sent": "So first you estimate your baseline as the user and the item deviation from an average.",
                    "label": 1
                },
                {
                    "sent": "Right, this is the BUV which is your bias or your baseline.",
                    "label": 0
                },
                {
                    "sent": "And then you sum the product of the item vector and the user vector and this is how you use.",
                    "label": 0
                },
                {
                    "sent": "In essence, Metrization or SVD to perform a rating prediction.",
                    "label": 0
                },
                {
                    "sent": "Now, during the Netflix price that got more interesting and more complicated, right?",
                    "label": 0
                },
                {
                    "sent": "And there was a.",
                    "label": 0
                },
                {
                    "sent": "Famous paper by Yehuda Koren and others about factorization meets the neighborhood where they talked about something they named SVD Plus plus.",
                    "label": 0
                },
                {
                    "sent": "And as part of that paper there was this other model.",
                    "label": 0
                },
                {
                    "sent": "This is the symmetric SVD.",
                    "label": 0
                },
                {
                    "sent": "I usually I usually refer to this one at SB C++, but that's not really true if you read the paper, there's a difference there between this one and the SVD plus plus, which I'll just mention, But basically let let's let's look at this as a metric SVD and how this is different from the standard rating prediction with metric factorization.",
                    "label": 0
                },
                {
                    "sent": "So the basic idea in this asymmetric SVD is that.",
                    "label": 0
                },
                {
                    "sent": "You still have here the item vector that you're multiplying, but instead of multiplying the item vector times a single user vector, which is what you expect to have here, right there P. So you you're actually not.",
                    "label": 0
                },
                {
                    "sent": "Paramount Rising the users, but you're representing them by two different terms, and those two different terms respond to two different things one.",
                    "label": 0
                },
                {
                    "sent": "Is the ratings and the other one is the implicit?",
                    "label": 0
                },
                {
                    "sent": "Interaction of the user and an item.",
                    "label": 0
                },
                {
                    "sent": "So the key realization here.",
                    "label": 0
                },
                {
                    "sent": "They do have the.",
                    "label": 0
                },
                {
                    "sent": "And their team had?",
                    "label": 0
                },
                {
                    "sent": "Is that the fact that user is actually rating an item by itself?",
                    "label": 0
                },
                {
                    "sent": "It's an important information and it's different.",
                    "label": 0
                },
                {
                    "sent": "It's a different information, right?",
                    "label": 0
                },
                {
                    "sent": "If I rate a movie, it means that I've watched it, and that's important in itself.",
                    "label": 0
                },
                {
                    "sent": "And by the way, there were some items in the data set that had no ratings.",
                    "label": 0
                },
                {
                    "sent": "Those were the atoms in the test set for which you have to build prediction for that wasn't interesting information.",
                    "label": 0
                },
                {
                    "sent": "You knew that if Netflix was asking you to predict an item and then the user had actually watched that, that was an important information, right?",
                    "label": 0
                },
                {
                    "sent": "So you wanted to model that, and you could model that by putting it as an implicit feedback saying, hey, I know the user was that I don't know what the user said about that show, because that's what I need to find.",
                    "label": 0
                },
                {
                    "sent": "But at least I know, and this is model in this part here and the other one is the rating which are basically modeling in this in this other part over here, right?",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Again, this has.",
                    "label": 0
                },
                {
                    "sent": "This is the symmetric SVD which or what they call the symmetric SVD, which has a number of interesting.",
                    "label": 0
                },
                {
                    "sent": "Properties and one of them is that you have.",
                    "label": 0
                },
                {
                    "sent": "Much less parameters to estimate, so you can actually make this model.",
                    "label": 0
                },
                {
                    "sent": "Invert and in a much better way than if you were going here to this other method where you have to decompose the whole user dimension, which is usually higher again in the items.",
                    "label": 0
                },
                {
                    "sent": "So I said before this is not what they ended up using in the price.",
                    "label": 0
                },
                {
                    "sent": "They use the SVD plus plus, which basically it's a hybrid between these two in which the explicit rating part is actually.",
                    "label": 0
                },
                {
                    "sent": "It is modeled as a user vector user factor vector and the implicit one is left as it is here as a independent term.",
                    "label": 0
                },
                {
                    "sent": "But the only reason they use that one is because they empirically got better results, but.",
                    "label": 0
                },
                {
                    "sent": "In principle, if you have as much implicit as explicit feedback, you could use this decomposition and you should be able to get.",
                    "label": 0
                },
                {
                    "sent": "Better results that in the Netflix Prize where the issue there is that you had many more explicit feedback.",
                    "label": 0
                },
                {
                    "sent": "And by the way you were your objective function were ratings.",
                    "label": 0
                },
                {
                    "sent": "It wasn't so much figuring out what the user like, but more of a rating prediction problem.",
                    "label": 0
                },
                {
                    "sent": "OK, so the next one.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This RBM restricted Boltzmann machine.",
                    "label": 1
                },
                {
                    "sent": "Let me see how I'm doing in time.",
                    "label": 0
                },
                {
                    "sent": "OK, we have 15 minutes until the break.",
                    "label": 0
                },
                {
                    "sent": "So I'll probably go a little bit quicker on this.",
                    "label": 0
                },
                {
                    "sent": "So restricted Boltzmann machine.",
                    "label": 0
                },
                {
                    "sent": "Think of them as a form of neural network right there used right now as the basis for many of the deep learning approaches as part of the deep neural net and the basic idea is that they.",
                    "label": 0
                },
                {
                    "sent": "To make learning easier, they restrict the kind of connectivity so they say well in general you only have one layer of hidden units.",
                    "label": 1
                },
                {
                    "sent": "You can have more, but that's the general case, and more importantly you don't have connections between hidden units.",
                    "label": 1
                },
                {
                    "sent": "And the hidden units are independent from the visible state.",
                    "label": 0
                },
                {
                    "sent": "But again, maybe more.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Important that what an RBM is is how it can be used for rating prediction, and this is something that.",
                    "label": 0
                },
                {
                    "sent": "Actually Russell, and who is?",
                    "label": 0
                },
                {
                    "sent": "I think he's giving a tutorial right now in parallel to this one.",
                    "label": 0
                },
                {
                    "sent": "In one paper, very related to the Netflix price.",
                    "label": 0
                },
                {
                    "sent": "I recommend you read this paper of restricted Boltzmann machine for collaborative filtering.",
                    "label": 0
                },
                {
                    "sent": "They explained how to use our VM's for the Netflix Prize an using the Netflix Prize data set.",
                    "label": 0
                },
                {
                    "sent": "And the basic idea is that you build an RBM.",
                    "label": 0
                },
                {
                    "sent": "Restricted Boltzmann machine for every user.",
                    "label": 0
                },
                {
                    "sent": "And you have the visibles.",
                    "label": 0
                },
                {
                    "sent": "Which are the items?",
                    "label": 0
                },
                {
                    "sent": "And then you can the number of hidden that you have here is actually a parameter and you.",
                    "label": 0
                },
                {
                    "sent": "Activate you activate Visa buys for only those users that that.",
                    "label": 0
                },
                {
                    "sent": "Sorry, only those items that the user has rated and basically use you have the algorithm here, but I just leave it for you to read later, but the idea is that you have to estimate this wedge the weights here that relate the visible to the heavens by doing a process that is very similar to the feed forward propagation that you would use in a neural net.",
                    "label": 0
                },
                {
                    "sent": "Now there's a couple of important key findings that are presented in this paper.",
                    "label": 0
                },
                {
                    "sent": "There are go beyond the traditional.",
                    "label": 0
                },
                {
                    "sent": "DBM used usage that had happened until then.",
                    "label": 0
                },
                {
                    "sent": "One of them is the fact that they also make use of those implicit ratings, so they actually implicit ratings, meaning those ratings in the data set that had.",
                    "label": 0
                },
                {
                    "sent": "In the testing set that we knew the user had rated, but we didn't know the value for it, so they have a way of incorporating them into the PBM and the other one is what they call the factorize PBM's.",
                    "label": 0
                },
                {
                    "sent": "Because the main problem you have here, once you define a machine for every user is that you have a huge number of parameters to estimate and you don't have.",
                    "label": 0
                },
                {
                    "sent": "It's hard to make the collaboration happen between the different weights, so the idea here of every all the JS is that you want them to be the same.",
                    "label": 0
                },
                {
                    "sent": "If a user rated an item and there's a hidden here and a different user rating another item so rated the same item you want this WI J to be the same right?",
                    "label": 0
                },
                {
                    "sent": "And you need to put that into your objective into your training.",
                    "label": 0
                },
                {
                    "sent": "Approach now doing that directly, you end up with a lot of parameters and it's complicated to solve.",
                    "label": 0
                },
                {
                    "sent": "So what they actually did is the factorize this WIJ matrix.",
                    "label": 0
                },
                {
                    "sent": "To reduce the number of parameters and to make the learning.",
                    "label": 0
                },
                {
                    "sent": "Not only faster, but actually reduce the number of parameters that you had on the learning phase.",
                    "label": 0
                },
                {
                    "sent": "So factorize restricted Boltzmann machines.",
                    "label": 0
                },
                {
                    "sent": "That's a very interesting learning from the Netflix price.",
                    "label": 0
                },
                {
                    "sent": "That is, again is being used in production.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now remember that as I said, the final system that went into production is actually a linear combination of this.",
                    "label": 1
                },
                {
                    "sent": "Both these methods.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Next question that I get always like hey wait a second, but I remember reading in the final Netflix Prize there were 107.",
                    "label": 1
                },
                {
                    "sent": "Methods that were combined in an example using gradient boosted decision trees.",
                    "label": 0
                },
                {
                    "sent": "What happened to the other 105 methods right?",
                    "label": 0
                },
                {
                    "sent": "So the reality is that we never put them into production.",
                    "label": 0
                },
                {
                    "sent": "And we didn't for a number of reasons.",
                    "label": 0
                },
                {
                    "sent": "One of the main reasons is that the increase in harmacy from the first year.",
                    "label": 0
                },
                {
                    "sent": "From the first year progress prize, using these two only, these two methods combine and the 107 was not so huge and the other one is because we realize that you know the engineering complexity of putting 105 more methods compared to increasing our messy was not really worth it.",
                    "label": 0
                },
                {
                    "sent": "Now you're going to say wait, wait a second.",
                    "label": 0
                },
                {
                    "sent": "You said that sometimes just a tiny increase in RMC might be worth millions.",
                    "label": 0
                },
                {
                    "sent": "Why wasn't that worth it?",
                    "label": 0
                },
                {
                    "sent": "The main reason it wasn't worth it is because.",
                    "label": 0
                },
                {
                    "sent": "The focus of Netflix had changed at that point and rating prediction.",
                    "label": 0
                },
                {
                    "sent": "We had realized that it was not a really key problem and we had many other algorithms that we wanted to worry about and those weren't really solved by improving the rating prediction, but by doing many other things that I'll discuss later, right?",
                    "label": 0
                },
                {
                    "sent": "So again, rating prediction.",
                    "label": 0
                },
                {
                    "sent": "Can be improved by adding all these other methods, but the tiny increase in Arma see for the business was not worth as much as improving many other algorithms that were different from the rating prediction one.",
                    "label": 1
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so let me talk about.",
                    "label": 0
                },
                {
                    "sent": "Other things that you can do which I kind of, including this traditional approaches and one of them is clustering, and the reason include clustering here is because, well, you know we're talking about metrization as a way to reduce dimensionality as a way to address sparsity, and a way to also address the scalability problem that we have with nearest neighbor approaches.",
                    "label": 0
                },
                {
                    "sent": "And if you thought about it.",
                    "label": 0
                },
                {
                    "sent": "Just a little bit, you think?",
                    "label": 0
                },
                {
                    "sent": "Well, you know another way to do this is by using cluster.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what how can we use clustering in the context of collaborative filtering?",
                    "label": 0
                },
                {
                    "sent": "So clustering.",
                    "label": 0
                },
                {
                    "sent": "The goal is to just group users.",
                    "label": 0
                },
                {
                    "sent": "There are similar right?",
                    "label": 0
                },
                {
                    "sent": "You could do the same with items, but I'm just focusing on users for now.",
                    "label": 0
                },
                {
                    "sent": "And then you can.",
                    "label": 0
                },
                {
                    "sent": "Compute recommendations at the cluster level so you say, well, this is really, you know, it's really very similar to what you were telling us before of the nearest neighbor approach, but we know that there are some methods for clustering their scale pretty well, and they're pretty efficient, right?",
                    "label": 1
                },
                {
                    "sent": "So why not do that?",
                    "label": 0
                },
                {
                    "sent": "So yeah, you can do that, and as a matter of fact.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Clustering has been used in many different ways, and there's many different approaches that clustering have been used in practice.",
                    "label": 0
                },
                {
                    "sent": "And one of them is LSH, actually, LSH, locality sensitive hashing.",
                    "label": 1
                },
                {
                    "sent": "Which is a method for grouping.",
                    "label": 1
                },
                {
                    "sent": "Element in a high dimensional this space.",
                    "label": 0
                },
                {
                    "sent": "Basically, based on finding a hashing function that Maps or groups similar things to the same bucket, this is.",
                    "label": 1
                },
                {
                    "sent": "This is really, I mean the main application of LSH is to approximate nearest neighbor, right?",
                    "label": 0
                },
                {
                    "sent": "So it's a clear application that could be used.",
                    "label": 0
                },
                {
                    "sent": "For collaborative filtering, and it has been used with some success.",
                    "label": 0
                },
                {
                    "sent": "I know that, for example, that the folks at LinkedIn have said in the past and present it publicly that they were using LSH in some of their recommendation solutions.",
                    "label": 0
                },
                {
                    "sent": "I don't know if they were using it anymore, but at least a couple of years ago they were talking about using LSH.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Any form of clustering can be used as an even a preprocessing step to annuus neighbor approach right?",
                    "label": 0
                },
                {
                    "sent": "So you can.",
                    "label": 0
                },
                {
                    "sent": "Used",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Things like K means and all its variations.",
                    "label": 1
                },
                {
                    "sent": "Other things that I know have been used to some success are things like affinity propagation, which is just a better graph based K means if you will spectral clustering an nonparametric Bayesian clustering, for example here, ockleberry lyrically processes there was a last year here.",
                    "label": 0
                },
                {
                    "sent": "Alex smola.",
                    "label": 0
                },
                {
                    "sent": "Namor gave a very interesting tutorial.",
                    "label": 0
                },
                {
                    "sent": "On this method, and if you learn here, you can go through their slides or some of the papers, but that's another very interesting approach to grouping users or items that are similar and therefore.",
                    "label": 0
                },
                {
                    "sent": "Can be used either as a preprocessing step or as a replacement for some of these nearest neighbor approaches and.",
                    "label": 0
                },
                {
                    "sent": "And I didn't mention this when I was talking about neutralization, about saying, well, how does this address many of the concerns that we have with nearest neighbor approaches.",
                    "label": 0
                },
                {
                    "sent": "I didn't mention the title of the paper from who the current which was factorization meets the neighborhood, which actually in that paper itself they were all they were presenting.",
                    "label": 0
                },
                {
                    "sent": "This asymmetric SPD and SPD plus plus at the end of the paper the goal was to combine both the maitre factorization plus the nearest neighbor approach because they both bring in.",
                    "label": 0
                },
                {
                    "sent": "Similarity is a different level of granularity, so at the end both of these approaches are used are useful and you can combine them in different ways, right?",
                    "label": 0
                },
                {
                    "sent": "And it's the same with clustering.",
                    "label": 0
                },
                {
                    "sent": "You can use clustering plus or instead of nearest neighbors and plus or instead of matrix factorization.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another traditional approach which.",
                    "label": 0
                },
                {
                    "sent": "Was not really using the context of the Netflix Prize, but I think I had to put it here because it's.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It's pretty much.",
                    "label": 0
                },
                {
                    "sent": "Widely using some context specially in.",
                    "label": 0
                },
                {
                    "sent": "Shops in in.",
                    "label": 0
                },
                {
                    "sent": "In domains where you have this idea of this notion of transaction right?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The idea of transaction is you have a purchase or an action that you do, in which if you're buying, say, book.",
                    "label": 0
                },
                {
                    "sent": "What do I have?",
                    "label": 0
                },
                {
                    "sent": "If you.",
                    "label": 0
                },
                {
                    "sent": "People who bought Book 3 or this person but book 3 and also bought book five and six in the context of a given transaction.",
                    "label": 0
                },
                {
                    "sent": "So you build this Association rules in what you say.",
                    "label": 0
                },
                {
                    "sent": "Well, people who buy this also by these other things in a given transaction, right in the context of supermarket market or shop or so on.",
                    "label": 0
                },
                {
                    "sent": "It's it has clear applications right where you see there's a shopping cart and there's the.",
                    "label": 0
                },
                {
                    "sent": "Classical sort of counter example of the diapers and beers and saying when people buy diapers they also buy beers and this is a sort of like.",
                    "label": 0
                },
                {
                    "sent": "Probably it is an urban legend, but it's a way of explaining a good way of explaining this Association rules which are based on Co occurrences or things that happen together in the context of a transaction, right?",
                    "label": 0
                },
                {
                    "sent": "An you have the classical apriori algorithm, which is fast to implement and execute, and this is an approach the Association rules approaches.",
                    "label": 1
                },
                {
                    "sent": "Approach.",
                    "label": 0
                },
                {
                    "sent": "It's classic traditional, but you should keep it in mind if your goal is to recommend things in the context of a given transaction, right?",
                    "label": 0
                },
                {
                    "sent": "And if you have this notion of hey, the user is buying stuff, and I know what the user is buying right now, I just want to add things to what the user is buying right now.",
                    "label": 0
                },
                {
                    "sent": "Sociation rules.",
                    "label": 0
                },
                {
                    "sent": "Is a good approach.",
                    "label": 0
                },
                {
                    "sent": "K.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How am I doing have a?",
                    "label": 0
                },
                {
                    "sent": "2 minutes, maybe let me try to.",
                    "label": 0
                },
                {
                    "sent": "Quickly go through this so we know about classifiers, right?",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We know that we can use them in many different ways, but here in the context of recommender systems, how do we use classifiers?",
                    "label": 0
                },
                {
                    "sent": "Well, the most simplistic approach is if I have to decide if a user likes or doesn't like something.",
                    "label": 0
                },
                {
                    "sent": "I can treat that as a 1 one class classification problem.",
                    "label": 0
                },
                {
                    "sent": "Where I have or binary classification problem where I have positives and negatives an I have the users, the items the user liked, the atoms are user didn't like and just build a classifier right?",
                    "label": 0
                },
                {
                    "sent": "So if you have ratings and you have a rating scale while you have to do something about it but you can do many things but the most simplistic approach, OK, I'll just treat anything there is one or two hours didn't like and four and five is like and I don't know what I'll do with the three.",
                    "label": 0
                },
                {
                    "sent": "There's something to be done there but.",
                    "label": 0
                },
                {
                    "sent": "The idea is that you can build.",
                    "label": 0
                },
                {
                    "sent": "You can use all this.",
                    "label": 0
                },
                {
                    "sent": "You know?",
                    "label": 0
                },
                {
                    "sent": "Supervised learning literature and use things like logistic regression, support vector machines, tree and samples and so on and throw it at recognition problems.",
                    "label": 1
                },
                {
                    "sent": "And it does.",
                    "label": 0
                },
                {
                    "sent": "Pretty well, and as a matter of fact we will talk more about this when we talk about learning to rank.",
                    "label": 0
                },
                {
                    "sent": "As some of you might know, the first approach and the simple approach to learning to rank is to treat it as a classification problem.",
                    "label": 0
                },
                {
                    "sent": "So that's your initial step and you can build a rank ranking approach by using a classifier.",
                    "label": 0
                },
                {
                    "sent": "The other into.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thing thing is that classifiers can use in collaborative filtering and content based.",
                    "label": 0
                },
                {
                    "sent": "You need a relevant training set and you have to make take care of regularization to avoid overfitting.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let me finish with.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Some limitation of collaborative filtering that will take us to content based later after the break.",
                    "label": 1
                },
                {
                    "sent": "So cold start is an important one.",
                    "label": 1
                },
                {
                    "sent": "And it's something you know many of these systems struggle with.",
                    "label": 0
                },
                {
                    "sent": "Obviously, because you're basing all your recommendations on the interaction between the users and the items.",
                    "label": 0
                },
                {
                    "sent": "When a user comes in, you have no interaction, so you have to.",
                    "label": 0
                },
                {
                    "sent": "Cold start the system in a way, and that's a tricky thing for pure collaborative filtering approaches.",
                    "label": 1
                },
                {
                    "sent": "The popularity bias is another one.",
                    "label": 0
                },
                {
                    "sent": "Because your matrix is sparse and you have.",
                    "label": 0
                },
                {
                    "sent": "You know ratings only.",
                    "label": 1
                },
                {
                    "sent": "For a few items and those items tends to be the most popular ones.",
                    "label": 0
                },
                {
                    "sent": "Those are the ones that tend to be recommended, right?",
                    "label": 0
                },
                {
                    "sent": "And the unpopular items.",
                    "label": 0
                },
                {
                    "sent": "It's harder to even call stardom or it's harder to make them bubble up and to recommend them will deal with some of them later on.",
                    "label": 0
                },
                {
                    "sent": "Content based approaches.",
                    "label": 0
                },
                {
                    "sent": "OK, so the content based recommendations which are very popular for text based products.",
                    "label": 0
                },
                {
                    "sent": "The basic idea is that.",
                    "label": 0
                },
                {
                    "sent": "You are going to build some feature vectors related to the items and those feature vectors are going to be based on the content.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The items themselves.",
                    "label": 0
                },
                {
                    "sent": "And then you can build a user model in a similar way an use that model you have from the user and the model you have based on the features from the item and then build things like.",
                    "label": 1
                },
                {
                    "sent": "Now we go back to the classifier.",
                    "label": 0
                },
                {
                    "sent": "For example classifying what are the items the user will like, what're the items the user won't like.",
                    "label": 0
                },
                {
                    "sent": "It's the complete opposite approach to what we're doing before we don't take into account whatsoever the actions between users and items.",
                    "label": 1
                },
                {
                    "sent": "We're purely based basing it on the similarity of the items and the content in the items.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now we don't have cold start problems.",
                    "label": 0
                },
                {
                    "sent": "We don't have sparsity problems.",
                    "label": 0
                },
                {
                    "sent": "We're pretty much able to recommend to users with unique taste.",
                    "label": 1
                },
                {
                    "sent": "And we're able to recommend very unpopular items, because at the end is only based on the content, right?",
                    "label": 0
                },
                {
                    "sent": "So if I know that you like dark comedies from the late 70s, all I need to find is those other dark comedies from the late 70s, and it doesn't matter how many people have liked it and you can provide explanations for that.",
                    "label": 0
                },
                {
                    "sent": "I can tell you, hey, I recommended this to you because I know you like dark comedies from the late 70s.",
                    "label": 0
                },
                {
                    "sent": "Now there are many problems to it, so actually it's not the.",
                    "label": 0
                },
                {
                    "sent": "Something that we can go with, and it's not even something that can replace collaborative filtering.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "One of them is we need to find a way to encode items in a meaningful way through features, and that's not easy in other domains, right?",
                    "label": 0
                },
                {
                    "sent": "So defining or representing a movie with a feature space of items based on the content, it's a tricky thing, but let alone movies, right?",
                    "label": 0
                },
                {
                    "sent": "If you start going into some other trickier domains and say, OK, Now I want to represent, I need to represent clothes and I need to represent books and I need to represent everything that I wanted to recommend.",
                    "label": 0
                },
                {
                    "sent": "In a way that I'm.",
                    "label": 0
                },
                {
                    "sent": "Uniquely defining the content is tricky.",
                    "label": 1
                },
                {
                    "sent": "The other one is that it's which are very related, is that difficult to implement serendipity, and it's easy to.",
                    "label": 0
                },
                {
                    "sent": "Overfit or two pitching hold users for which you have few data points, right?",
                    "label": 0
                },
                {
                    "sent": "What I was saying before that example of like, well if you watch an enemy all I'm going to give you our enemies or the dark comedies from the 70s.",
                    "label": 0
                },
                {
                    "sent": "It's going to be the same thing, right?",
                    "label": 0
                },
                {
                    "sent": "It's like because I'm basing all that I'm giving to you on the content.",
                    "label": 0
                },
                {
                    "sent": "It's hard now to get you out from this niche content that you're watching to recommend something that has more serendipity.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And there's another one, which is, I think, highlighted in this paper that came out of after the Netflix price.",
                    "label": 0
                },
                {
                    "sent": "The monkey stick and his students were talking about even a few ratings are more valuable than metadata.",
                    "label": 0
                },
                {
                    "sent": "What they did here is they try to use IMDb data to expand the data set from Netflix Price and to improve accuracy and what they saw is that you know, as much meta data that you added from the movies as much as they try to find content features, it really just a few ratings.",
                    "label": 0
                },
                {
                    "sent": "They had made a much bigger improvement than all the data that they could use from the meta data.",
                    "label": 0
                },
                {
                    "sent": "It's a very interesting paper.",
                    "label": 0
                },
                {
                    "sent": "I recommend reading so in general, when somebody asked me like should I use a condom based approach?",
                    "label": 0
                },
                {
                    "sent": "I said, well, you're better off starting with collaborative filtering.",
                    "label": 0
                },
                {
                    "sent": "And make sure you have a way to address the star problem and some of the other issues.",
                    "label": 0
                },
                {
                    "sent": "But content based is even trickier to get working.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and just to finish, you can combine methods in different ways and of.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Course, you know if you have content and you have collaborative, why not building an example of both?",
                    "label": 0
                },
                {
                    "sent": "And this is a graphic.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can see that.",
                    "label": 0
                },
                {
                    "sent": "You know that adding both methods is always going to give you as always, right?",
                    "label": 0
                },
                {
                    "sent": "We know samples work because if there are uncorrelated predictors, you're only going to get better results by combining them.",
                    "label": 0
                },
                {
                    "sent": "So why not combine both methods?",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And there's many different ways that you can hybridize or combine methods in recommender systems, which are here in this slide.",
                    "label": 0
                },
                {
                    "sent": "And with that I'm going to.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let you go for coffee again.",
                    "label": 0
                },
                {
                    "sent": "If you guys have questions or comments now during this 30 minutes, please come to me and I'll.",
                    "label": 0
                },
                {
                    "sent": "Happily take questions an if not, I'll see you in the next part.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}