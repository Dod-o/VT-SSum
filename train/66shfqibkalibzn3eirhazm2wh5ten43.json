{
    "id": "66shfqibkalibzn3eirhazm2wh5ten43",
    "title": "Clustered Graph Randomization: Network Exposure to Multiple Universes",
    "info": {
        "author": [
            "Johan Ugander, Center for Applied Mathematics, Cornell University"
        ],
        "published": "Sept. 27, 2013",
        "recorded": "August 2013",
        "category": [
            "Top->Computer Science->Data Mining",
            "Top->Computer Science->Knowledge Extraction"
        ]
    },
    "url": "http://videolectures.net/kdd2013_ugander_multiple_universes/",
    "segmentation": [
        [
            "Thank you, some gender and like so this is trying to work with collaborators of Facebook.",
            "Brian car in large Backstrom and my thesis advisor, John Kleinberg Cornell."
        ],
        [
            "So the fundamental problem that this talk in this paper is about is that of a B testing in the presence of network effects, which is sort of applied problem for in a graph clustering session.",
            "But the methodology ends up fundamentally building upon the language and tools and insights of sort of the literature of graph clustering.",
            "So the problem here is that you have a website such as Facebook and all of your users are experiencing some version of that website.",
            "When you're running experiments.",
            "But when you."
        ],
        [
            "Launch a product you don't only alter the experience of that of that user.",
            "You're actually altering the experience of that user's friends on the site, because if you for example change the news feed algorithm, you might end up changing the content that a person produces, how it's distributed, so that ends up affecting the neighbors of a person along a graph.",
            "And there are these sort of spillover effects, interference effects.",
            "So typically when you launch an experiment on a website, you flip a coin for every user of the site.",
            "Every visitor of the site, and you show them one of two versions with a certain probability or one of many versions.",
            "And so if you were to do this on a site like Facebook with a product like so."
        ],
        [
            "We wanted to launch video chat in this way you would have a big problem because the users who are receiving video chat are not at all necessarily experiencing video chat as it's meant to be experienced.",
            "They might have received the video chat product such as this sort of a user here on the periphery, but none of their friends have video chat, so they're not actually experiencing video chat and your ability to measure the revenue and the impact upon sight time Visitation is greatly diminished because.",
            "You can only measure.",
            "You can only base your measurement based on people that are somehow truly experiencing video chat and comparing the people who are truly still in the old version of the site so."
        ],
        [
            "That's where graph clustering comes in, because here we just have two users that are sort of truly surrounded that we would be able to compare, but we want to be able to compare more users and that we want to compare as many as possible.",
            "So."
        ],
        [
            "So importantly, this is not just a graph partitioning problem in the classical sense.",
            "If I want to partition bisect the graph into two halves or something like that, because doing that on a website like Facebook is."
        ],
        [
            "Is invariably going to discover demographic correlates.",
            "So you do this on with a graph like the social graph on Facebook, and you're going to end up running.",
            "You're going to partition the US graph, and you're going to find something very close to the Mississippi, and you're going to be launching one product on the East Coast, One product in the West Coast, and actually, you're going to be confounded with many, many problems.",
            "You're going to have covariates and better demographic.",
            "You're going to cover it in terms of how far the users are from your servers, so there's going to be delays on some of the users.",
            "So the problem that this boils down to is you want to somehow.",
            "Create clusters so that people are socially surrounded and experiencing an experiment together with their friends, but at the same time you have enough clusters so that you can get decent variance error, but good error bars on what your average treatment effect is, so that's the whole motivation of this problem, and from this point we're going to start talking about how to do this in the language of graph clustering."
        ],
        [
            "So average treatment effect is this classic quantity in the running of online experiments where you treat people either one or zero sort of zi is individualized treatment, and they're either experiencing, let's say, video chat or not video chat and then that leads to response.",
            "So there either.",
            "Maybe if they don't have video chat, one individual might spend an hour on the site, and if they receive video chat, this is a wonderful product for them.",
            "Maybe it will increase their usage time to two hours on this site, or maybe it will decrease it.",
            "These things are rarely intuitive.",
            "So you measure the average treatment effects.",
            "Ideally, you would be able to observe every individual both with and without video chat, and these are sort of these two extreme universes where everybody has video chat and nobody has video chat and this is this is an estimator that you can actually compute because it's assuming that you're observing individualy both with and without video chat and observing the difference of the effect on the response, and then you're averaging it across the many users, but you can't actually compute this ever.",
            "So the classic way to do this.",
            "Is to flip a coin and that's the whole insight of a B testing in the web framework is that you do this and you inverse probability weights.",
            "So let's say 5% of your users are receiving a product and then you properly re wait by the probability of being in the treatment.",
            "The probability of being control and you can get this at this estimator, sometimes called a horrible Thompson estimator, inverse probability weighting estimator and you can measure this in expectation sort of get you get draws from this.",
            "Z is here around a variable that you're randomizing and you get draws from this distribution.",
            "That this estimator has.",
            "So interference on this network effects problem is exactly the problem of no longer only depending on yourself.",
            "So this ZI ordinarily is the Z vector, is the 01 treatment of every individual on your website, and it's no longer just about ZI, but now you might defend depend on the full Z, or at least your neighborhood on the Z or some larger ball out from you on on the graph, which is sort of the people that you depend on and you need to order food experience video chat you need for.",
            "Those other people also have video chat.",
            "So this is been cropping up very recently in the statistics literature, and this paper is about trying to apply this on sort of the scale of tremendously large web experiments."
        ],
        [
            "So the two extreme corners of this 01 N cube hypercube that you're looking at is the one vector and the zero vector everybody, and nobody and those are the two universes that we want to compare between.",
            "But we can't observe them at the same time.",
            "So ordinarily, you make the assumption that.",
            "You will respond as if everybody's video chat.",
            "If you have video chat, and that's specifically not true for chat, but it is true when you're testing the shade of blue on a search engine, and similarly you will respond as if everybody is in control.",
            "If you are in control.",
            "So that's not true when you depend on other people.",
            "And the abstraction we used, or the mathematics that we used to characterize when you are experiencing the universe one in the Universe 0, is this idea of just looking at the sets across the 01 an space where you are experiencing your approximately experiencing sort of modeling assumption the product fully and approximately spraying the absence of the product in the sense that none of your friends have it, and they're not sort of doing there.",
            "Maybe if all your friends got video chat and you didn't, they would stop talking to you 'cause.",
            "All day, they're just on video chat talking to their other friends.",
            "You have video chat, so it's important to separate these two universes.",
            "And so the question is then, how do you define these sets?",
            "And then how do you also compute these probabilities?",
            "'cause now you're asking this question of what's the probability of the randomized vector that you're flipping for everybody?",
            "What's the probability of it being in your set for every individual?",
            "For you you individual I so this then becomes your average treatment effect estimator 80 estimator as a as a Horvitz Thompson estimator.",
            "In this literature as it's called."
        ],
        [
            "So with this problem, the agenda that I want to lay out now for the remainder of the talk is this idea of when are you network exposed?",
            "When is this Sigma Zero and Sigma 1A good approximation of you being in control?",
            "Or you could approximation of you being truly network exposed to treatment.",
            "And then I want to talk about how you can approach this problem with graph clustering and show that there is a dynamic program that you can use to compute the probabilities of you being in this set even when you have correlated treatments.",
            "Because basically the trick of using graph clustering is to say we're going rather than flipping individual coins.",
            "We're going to flip coins on a cluster level, so we're going to take graph clusters and flip their coins together, and they're all going to get treated in graph clusters and put them together, and they're all going to get control.",
            "And so those probabilities become non trivial to compute, but tractable.",
            "Once we complete this probabilities, we can analyze the variance of the estimator and when is when is the variance good?",
            "What's the important question is how large should you make the clusters?",
            "If you make really really small clusters or making trivially small clusters, so you're flipping individuals, and that's sort of intuitively bad 'cause nobody is going to experience the product with their friends and you make really, really large clusters you run into these confounding problems of the East Coast West Coast problem that I was describing earlier.",
            "So at the end of this talk, I'm going to give a sort of formal graph theoretic assumption that we can that when true, lets us do some formal math, improve abound on the variance, and while not a graph theoretic condition, that's likely to be true in many real world graphs, strictly speaking, it is very helpful for getting the intuition for tackling this problem, and has been helping us a lot in making further and further progress on this very hard problem that's been holding up.",
            "Testing problems at companies like Facebook."
        ],
        [
            "So defining network exposure."
        ],
        [
            "So we talked about.",
            "There is the treatment in the control.",
            "There is video chat and not video chat.",
            "That's just a treatment, but that's different than exposure.",
            "So when are you network exposed to treatment or when are you network exposed to control is the question and the language that I'm going to talk about first is that of being neighborhood exposed.",
            "So for example we will say you are fully neighborhood exposed to the treatment when you and all your neighbors are treated and you are fully neighborhood exposed to the control.",
            "When you and all your friends are in control.",
            "There is.",
            "Obvious analogs of this, where you say your neighborhood exposed when K of your for you.",
            "In case if your friends are exposed to the treatment, you in case your friends are exposed to the control, and similarly there's a fractional approach.",
            "So what does this look like?",
            "The relevant space for this that helps understand this problem is there's the weather.",
            "The ego is treated whether you are treated there is that sort of a 01 coin flip.",
            "And then there's the fraction or the count of the number of friends that were treated.",
            "And there's really this case of you not being treated and none of your friends and you being created in all of your friends or sort of the extreme universes.",
            "So you're trying to compare when you do a B tests and that's readily accessible if there isn't this dependence, or when there is interference but becomes a problem otherwise.",
            "And so when we define these sets, Sigma were actually sort of making a fudge assumption of what are the conditions where you're experiencing the product equivalent to.",
            "If everybody had it or didn't have it.",
            "So here were saying, Oh well, you basically have your basically experiencing video to full capacity.",
            "If more than 80% of your friends have video chat and you haven't.",
            "And similarly, if less than 20% and how to define those is sort of important modeling assumption that.",
            "1."
        ],
        [
            "It's Mick.",
            "So simple example.",
            "Very simple graph.",
            "Here we see the person the leftmost person on the.",
            "Your leftmost person on the slide who has video chat.",
            "They are now 2/3 network exposed to the treatment and on the right side there's a person there who's 2/3 network exposed to the control and so those are the types of people that we want to be comparing.",
            "When we run these types of experiments because there's sort of some version of adequately exposed.",
            "So this is this is if you're willing to buy neighborhood exposure as a good a good exposure model.",
            "In the paper we talk about something called that we call a component exposure, which is saying well.",
            "There is a huge problem with this figure, and that's that the person all the way to the left.",
            "Sure, they have video chat insure 2/3 of their friends video chat, but actually those friends you're the only person who they know who has video chat and the individual.",
            "On the top there they have two other friends who don't video chat and you're the only person why should they really started using video chat.",
            "They already talked to you on text messaging all the time or or they're not here strongest friend.",
            "And you're not the relevant person for this product for them, so that's where you actually want to define sort of recursive notion of.",
            "You are never exposed only if 2/3 of your friends are exposed in 2/3 of the 2/3 of those friends are in turn have 2/3 of their friends exposed and sort of this recursive notion, and that ends up being then we write it down on the paper exactly the question of are you in the cake or of the induced sub graph of people treated?",
            "Or are you in the cake or of the induced subgraphs to people who are in the control so that ends computing the probabilities of when that happens is not something we were able to solve.",
            "So we kind of left that out, but I'm going to talk about neighborhood exposure where it's just the notion of some fraction of your friends being treated.",
            "But I think that the component exposure notion is sort of important enough to include this paper, but we didn't really make any further progress on it."
        ],
        [
            "So now we have this notion of when are you surrounded?",
            "When are you experiencing your universe and now we want to cluster the graph and randomize clusters."
        ],
        [
            "So how do we partition the graph?",
            "This is Facebook 2010 and this reveal is a very good way to select clusters which is geographically because this is showing every user as a node and edges or these blue arcs and it's basically showing this firestorm locali around places because you're friends with people who live close to you.",
            "Very intuitive so the very good way to run an."
        ],
        [
            "Is to take a country like NZ and run an experiment in that country.",
            "The problem with that is that New Zealand is not is sort of there an English speaking language so you don't know that much about how your translations into other languages are doing.",
            "You might have bugs and your internationalization code.",
            "They're just a different country that there might be other competition on that market that you don't necessarily know, and it's hard to pick a country that's truly representative, so."
        ],
        [
            "What we do in this approach is to say, OK, let's cluster the graph.",
            "The very, very large graph into many, many small clusters, and I mean."
        ],
        [
            "Sort of.",
            "Many many, many small clusters.",
            "You want 10,000 or more when we've been testing this in work, that's not including this paper, we've been doing 64,000 clusters and things like that, and you want to flip a coin for every one of those clusters, and so you're really sort of randomizing talent.",
            "Some towns in various parts of Illinois are getting one and maybe Chicago.",
            "It's the other and various or not depending on if you're doing clustering geographically or not.",
            "We're basically looking to cluster these small small regions, but many of them to get a large effective population."
        ],
        [
            "So what are some algorithms that are graphic graphical for this?",
            "The problem with the geometric, the geographic stuff is that you don't really.",
            "You don't have many guarantees on what your actual performance is going to be.",
            "If you're working at the scale of the Facebook graph, you really need to work with the highly highly scalable algorithms, so some of the algorithms that we've been working with is the label propagation and the Louvin method for Community detection that does a good job of running very fast.",
            "I had a paper with my Co author who I've worked on with this large.",
            "Backstrom had wisdom early this year on something called balance labor propagation, which we used at Facebook in another context to partition the full Facebook graph into many parts.",
            "There's also lightweight algorithms.",
            "Standing Quote was a paper or KD last year on streaming got partitioning.",
            "There's a paper by Store caucus that's closely related, and then as an advertisement for a paper that I had in the poster session yesterday with my Co author Joel Nishimura, honoree, streaming algorithm that has the same speed advantage of streaming graph partitioning and can work at this sort of tremendous scales.",
            "So how are you going to carve up the globe, as are two European counterparts were doing there in something century everything century?",
            "Little cartoon so at the end of this I'm going to talk about a clustering algorithm where we can prove things which is interesting because all those others are heuristics and the way in which the proof follows says a lot about how you should calibrate those other algorithms.",
            "So that's sort of the lesson that we want to leverage out of that.",
            "The analysis of that algorithm.",
            "But it's not necessarily the best algorithm I want to say that, importantly, if you want to go out and deploy our deploy experiments in a clustered manner, I wouldn't necessarily recommend flipping to the end of our paper and taking this algorithm, and.",
            "Implementing it, but I would recommend processing the lessons of it for how to set it guides how you should scale your clusters so those other algorithms are modern, fast things that are good at this problem.",
            "Medecins great if you can fit your craft in memory.",
            "Otherwise as an offline clustering algorithm."
        ],
        [
            "So I said we have to compute probability weights.",
            "To do this normalization in the Harvard Thompson estimator.",
            "So that's this interesting problem.",
            "Now you've clustered your graph into these black circles, and you have these coins.",
            "They're flipping, and let's say you're the yellow individual in the middle, and you now depend on 4 coins, and so I need to.",
            "Sorry, you only depend on 3 coins.",
            "I need to know that your chance of having all of your neighborhood treated is some version of Peter the beta 3.",
            "But if I'm interested in fractional treatment, which I need to be if I want to.",
            "Be able to count people who are pretty much experiencing video chat.",
            "In my experiment I need to do this exercise of computing the probability of 80% of my friends are treated so this."
        ],
        [
            "Turns out to be a dynamic program, and you can actually exactly compute the full distribution in this space of 01 cross interval 01, and then you say OK, how much probability mass is in these two yellow boxes, so you can compute that for every individual you need to do it, but it is embarrassingly parallelizable and you can compute those probabilities so you can compute your estimate."
        ],
        [
            "OK, so the fact that we can do this probability so that that estimator is something we cannot work with.",
            "Can we analyze the variances then the big question."
        ],
        [
            "So the answer is yes, this is work in parens.",
            "Tommy toes in 12 that center Bogra fee.",
            "It's an expensive expression, but the probabilities that come up here are the ones that you need to compete with the dynamic program.",
            "So you compute those probabilities and you can sort of analyze the variance of estimator, and now this is the variance estimator is what we want to bring down.",
            "So this."
        ],
        [
            "Is the motivating example that then leads to our algorithm, which is basically we started by saying.",
            "What can we do on the simplest case of a cycle graph cycle graph has a various obvious, very obvious clustering."
        ],
        [
            "You want to cluster the graph into sort of groups of two 345 continuously along the graph?",
            "How well, what at what scale is our variance minimized when we do this?",
            "So the model here is it's doing full exposure, so it's just if you and all your friends so you and your two neighbors both have to be in the same treatment.",
            "And the response model is that there's some sort of East Coast West Coast gradient of half the people responded to treatment have the people responded to treatment where and your numbers, and if you're in control, you're responding zero and we said OK, can we analyze the variance of this?"
        ],
        [
            "Depending on how you choose the size of your cluster."
        ],
        [
            "And it turns out that you can do this close form and you get this nice internal Optima which says that you should be clustering sort of three nodes at a time.",
            "And that was really interesting.",
            "'cause where is 3 in this figure?",
            "It's the size of the neighborhood.",
            "So then we stepped over to simulations."
        ],
        [
            "I have powers of the psychograph and said OK, where is the Optima there and it turns out that again."
        ],
        [
            "Then the Optima very clearly fall."
        ],
        [
            "As the lowest point on the variance curve is choosing clusters that are the size of neighborhoods.",
            "These are regular graphs.",
            "The neighborhoods are all the same size.",
            "And what's even more interesting is that as you increase the average degree from sort of having one on one note on each side, two nodes inside 345, your variance is growing only linearly in your degree."
        ],
        [
            "And that's relevant because when you did IID randomization, you're actually getting exponential growth in your variance.",
            "So here is where we said OK, there's something important about looking at these basic cycle graphs where you get linear variance as opposed to exponential variance if you choose your clusters at the right size and there's this intermediate internal sweet spot that you want to try and get.",
            "That is very clear on these simple graphs, and it's harder to see very hard."
        ],
        [
            "See unreal."
        ],
        [
            "Graphs.",
            "So to conclude, there's this important generalization of cycle graphs where rather than just looking at a cycle graph, you look at a restricted growth graph, which is basically any graph that the size of the of the successive balls is bounded by some factor Kappa, so."
        ],
        [
            "So for bounded degree graphs, this is some sort of.",
            "This is trivially sort of the Max degree plus one is this Kappa quantity, but for anything that's close to a Euclidean as close to uniform bedding in the Euclidean space, you're going to see a very low Kappa, and this is borrowing intuition from the carbon rule literature on nearest neighbor search in metric spaces, where they say OK if you have this bounded growth metric which is similar to the restricted growth that we're talking about, it's different, so it's a different name then.",
            "You can use that use the metric to create your or you can.",
            "You can use the fact that.",
            "You and then you know things about how different nodes can be adjacent to each other and how things can pack into different corners."
        ],
        [
            "That was a weird formulation, but that basically lets you say that if you do what's called A3 net clustering, where three.",
            "Net is a trademarked term from the bounded growth literature on sort of epsilon nuts.",
            "If you create just you mark arbitrary vertices and take their two balls, and that's a clustering algorithm, there's an important tiebreaking detail the timing, but you basically just create you cluster the graph based on two hop to hop out from an individual vertices.",
            "They're selecting a random.",
            "If you do that."
        ],
        [
            "We show in the paper that that means that you depend on a bounded number of clusters independent of your degree.",
            "So even if you have really high degree, you're only depending on a few clusters.",
            "'cause Euclidean space you can't reach that many different clusters approximately Euclidean space, and that means that we have this linear variance bounds.",
            "So that means that on graphs that are sort of random geometric graphs, and if you're willing to consider something like a social graph as being embedded in a geometric geographic space, then you have some version of this.",
            "That means that doing these neighborhood clusterings is going to give you.",
            "Very favorable variance behavior compared to, certainly compared to IID coin flipping."
        ],
        [
            "So the lessons of this paper is sort of an exploration of this really hard problem that we've been working.",
            "I've been working on with people at Facebook, which is that of running a B tests when in the presence of network effects and your variance of matter, which is what you're trying to drive down, so you can actually measure something.",
            "So the variances in larger than your effect that depends on how you characterize your exposure and what algorithm you use.",
            "So there's sort of space here for testing a lot of different algorithms that are beyond what we've been looking at.",
            "And we have this condition that lets you bound variance.",
            "But really any graph clustering algorithm can greatly reduce the variance.",
            "So we've been experimentally testing a bunch of different algorithms in various tests of Facebook, so it's sort of a problem that we are actively fanatically working on with these collaborators so.",
            "Thank you very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you, some gender and like so this is trying to work with collaborators of Facebook.",
                    "label": 0
                },
                {
                    "sent": "Brian car in large Backstrom and my thesis advisor, John Kleinberg Cornell.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the fundamental problem that this talk in this paper is about is that of a B testing in the presence of network effects, which is sort of applied problem for in a graph clustering session.",
                    "label": 0
                },
                {
                    "sent": "But the methodology ends up fundamentally building upon the language and tools and insights of sort of the literature of graph clustering.",
                    "label": 0
                },
                {
                    "sent": "So the problem here is that you have a website such as Facebook and all of your users are experiencing some version of that website.",
                    "label": 0
                },
                {
                    "sent": "When you're running experiments.",
                    "label": 0
                },
                {
                    "sent": "But when you.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Launch a product you don't only alter the experience of that of that user.",
                    "label": 0
                },
                {
                    "sent": "You're actually altering the experience of that user's friends on the site, because if you for example change the news feed algorithm, you might end up changing the content that a person produces, how it's distributed, so that ends up affecting the neighbors of a person along a graph.",
                    "label": 0
                },
                {
                    "sent": "And there are these sort of spillover effects, interference effects.",
                    "label": 0
                },
                {
                    "sent": "So typically when you launch an experiment on a website, you flip a coin for every user of the site.",
                    "label": 0
                },
                {
                    "sent": "Every visitor of the site, and you show them one of two versions with a certain probability or one of many versions.",
                    "label": 0
                },
                {
                    "sent": "And so if you were to do this on a site like Facebook with a product like so.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We wanted to launch video chat in this way you would have a big problem because the users who are receiving video chat are not at all necessarily experiencing video chat as it's meant to be experienced.",
                    "label": 0
                },
                {
                    "sent": "They might have received the video chat product such as this sort of a user here on the periphery, but none of their friends have video chat, so they're not actually experiencing video chat and your ability to measure the revenue and the impact upon sight time Visitation is greatly diminished because.",
                    "label": 0
                },
                {
                    "sent": "You can only measure.",
                    "label": 0
                },
                {
                    "sent": "You can only base your measurement based on people that are somehow truly experiencing video chat and comparing the people who are truly still in the old version of the site so.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's where graph clustering comes in, because here we just have two users that are sort of truly surrounded that we would be able to compare, but we want to be able to compare more users and that we want to compare as many as possible.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So importantly, this is not just a graph partitioning problem in the classical sense.",
                    "label": 0
                },
                {
                    "sent": "If I want to partition bisect the graph into two halves or something like that, because doing that on a website like Facebook is.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is invariably going to discover demographic correlates.",
                    "label": 0
                },
                {
                    "sent": "So you do this on with a graph like the social graph on Facebook, and you're going to end up running.",
                    "label": 0
                },
                {
                    "sent": "You're going to partition the US graph, and you're going to find something very close to the Mississippi, and you're going to be launching one product on the East Coast, One product in the West Coast, and actually, you're going to be confounded with many, many problems.",
                    "label": 0
                },
                {
                    "sent": "You're going to have covariates and better demographic.",
                    "label": 0
                },
                {
                    "sent": "You're going to cover it in terms of how far the users are from your servers, so there's going to be delays on some of the users.",
                    "label": 0
                },
                {
                    "sent": "So the problem that this boils down to is you want to somehow.",
                    "label": 0
                },
                {
                    "sent": "Create clusters so that people are socially surrounded and experiencing an experiment together with their friends, but at the same time you have enough clusters so that you can get decent variance error, but good error bars on what your average treatment effect is, so that's the whole motivation of this problem, and from this point we're going to start talking about how to do this in the language of graph clustering.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So average treatment effect is this classic quantity in the running of online experiments where you treat people either one or zero sort of zi is individualized treatment, and they're either experiencing, let's say, video chat or not video chat and then that leads to response.",
                    "label": 1
                },
                {
                    "sent": "So there either.",
                    "label": 0
                },
                {
                    "sent": "Maybe if they don't have video chat, one individual might spend an hour on the site, and if they receive video chat, this is a wonderful product for them.",
                    "label": 0
                },
                {
                    "sent": "Maybe it will increase their usage time to two hours on this site, or maybe it will decrease it.",
                    "label": 0
                },
                {
                    "sent": "These things are rarely intuitive.",
                    "label": 0
                },
                {
                    "sent": "So you measure the average treatment effects.",
                    "label": 0
                },
                {
                    "sent": "Ideally, you would be able to observe every individual both with and without video chat, and these are sort of these two extreme universes where everybody has video chat and nobody has video chat and this is this is an estimator that you can actually compute because it's assuming that you're observing individualy both with and without video chat and observing the difference of the effect on the response, and then you're averaging it across the many users, but you can't actually compute this ever.",
                    "label": 0
                },
                {
                    "sent": "So the classic way to do this.",
                    "label": 0
                },
                {
                    "sent": "Is to flip a coin and that's the whole insight of a B testing in the web framework is that you do this and you inverse probability weights.",
                    "label": 0
                },
                {
                    "sent": "So let's say 5% of your users are receiving a product and then you properly re wait by the probability of being in the treatment.",
                    "label": 0
                },
                {
                    "sent": "The probability of being control and you can get this at this estimator, sometimes called a horrible Thompson estimator, inverse probability weighting estimator and you can measure this in expectation sort of get you get draws from this.",
                    "label": 1
                },
                {
                    "sent": "Z is here around a variable that you're randomizing and you get draws from this distribution.",
                    "label": 1
                },
                {
                    "sent": "That this estimator has.",
                    "label": 0
                },
                {
                    "sent": "So interference on this network effects problem is exactly the problem of no longer only depending on yourself.",
                    "label": 0
                },
                {
                    "sent": "So this ZI ordinarily is the Z vector, is the 01 treatment of every individual on your website, and it's no longer just about ZI, but now you might defend depend on the full Z, or at least your neighborhood on the Z or some larger ball out from you on on the graph, which is sort of the people that you depend on and you need to order food experience video chat you need for.",
                    "label": 0
                },
                {
                    "sent": "Those other people also have video chat.",
                    "label": 0
                },
                {
                    "sent": "So this is been cropping up very recently in the statistics literature, and this paper is about trying to apply this on sort of the scale of tremendously large web experiments.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the two extreme corners of this 01 N cube hypercube that you're looking at is the one vector and the zero vector everybody, and nobody and those are the two universes that we want to compare between.",
                    "label": 0
                },
                {
                    "sent": "But we can't observe them at the same time.",
                    "label": 0
                },
                {
                    "sent": "So ordinarily, you make the assumption that.",
                    "label": 0
                },
                {
                    "sent": "You will respond as if everybody's video chat.",
                    "label": 0
                },
                {
                    "sent": "If you have video chat, and that's specifically not true for chat, but it is true when you're testing the shade of blue on a search engine, and similarly you will respond as if everybody is in control.",
                    "label": 0
                },
                {
                    "sent": "If you are in control.",
                    "label": 0
                },
                {
                    "sent": "So that's not true when you depend on other people.",
                    "label": 0
                },
                {
                    "sent": "And the abstraction we used, or the mathematics that we used to characterize when you are experiencing the universe one in the Universe 0, is this idea of just looking at the sets across the 01 an space where you are experiencing your approximately experiencing sort of modeling assumption the product fully and approximately spraying the absence of the product in the sense that none of your friends have it, and they're not sort of doing there.",
                    "label": 0
                },
                {
                    "sent": "Maybe if all your friends got video chat and you didn't, they would stop talking to you 'cause.",
                    "label": 0
                },
                {
                    "sent": "All day, they're just on video chat talking to their other friends.",
                    "label": 0
                },
                {
                    "sent": "You have video chat, so it's important to separate these two universes.",
                    "label": 1
                },
                {
                    "sent": "And so the question is then, how do you define these sets?",
                    "label": 0
                },
                {
                    "sent": "And then how do you also compute these probabilities?",
                    "label": 0
                },
                {
                    "sent": "'cause now you're asking this question of what's the probability of the randomized vector that you're flipping for everybody?",
                    "label": 0
                },
                {
                    "sent": "What's the probability of it being in your set for every individual?",
                    "label": 0
                },
                {
                    "sent": "For you you individual I so this then becomes your average treatment effect estimator 80 estimator as a as a Horvitz Thompson estimator.",
                    "label": 1
                },
                {
                    "sent": "In this literature as it's called.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So with this problem, the agenda that I want to lay out now for the remainder of the talk is this idea of when are you network exposed?",
                    "label": 0
                },
                {
                    "sent": "When is this Sigma Zero and Sigma 1A good approximation of you being in control?",
                    "label": 0
                },
                {
                    "sent": "Or you could approximation of you being truly network exposed to treatment.",
                    "label": 0
                },
                {
                    "sent": "And then I want to talk about how you can approach this problem with graph clustering and show that there is a dynamic program that you can use to compute the probabilities of you being in this set even when you have correlated treatments.",
                    "label": 0
                },
                {
                    "sent": "Because basically the trick of using graph clustering is to say we're going rather than flipping individual coins.",
                    "label": 0
                },
                {
                    "sent": "We're going to flip coins on a cluster level, so we're going to take graph clusters and flip their coins together, and they're all going to get treated in graph clusters and put them together, and they're all going to get control.",
                    "label": 0
                },
                {
                    "sent": "And so those probabilities become non trivial to compute, but tractable.",
                    "label": 0
                },
                {
                    "sent": "Once we complete this probabilities, we can analyze the variance of the estimator and when is when is the variance good?",
                    "label": 0
                },
                {
                    "sent": "What's the important question is how large should you make the clusters?",
                    "label": 0
                },
                {
                    "sent": "If you make really really small clusters or making trivially small clusters, so you're flipping individuals, and that's sort of intuitively bad 'cause nobody is going to experience the product with their friends and you make really, really large clusters you run into these confounding problems of the East Coast West Coast problem that I was describing earlier.",
                    "label": 0
                },
                {
                    "sent": "So at the end of this talk, I'm going to give a sort of formal graph theoretic assumption that we can that when true, lets us do some formal math, improve abound on the variance, and while not a graph theoretic condition, that's likely to be true in many real world graphs, strictly speaking, it is very helpful for getting the intuition for tackling this problem, and has been helping us a lot in making further and further progress on this very hard problem that's been holding up.",
                    "label": 0
                },
                {
                    "sent": "Testing problems at companies like Facebook.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So defining network exposure.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we talked about.",
                    "label": 0
                },
                {
                    "sent": "There is the treatment in the control.",
                    "label": 0
                },
                {
                    "sent": "There is video chat and not video chat.",
                    "label": 0
                },
                {
                    "sent": "That's just a treatment, but that's different than exposure.",
                    "label": 0
                },
                {
                    "sent": "So when are you network exposed to treatment or when are you network exposed to control is the question and the language that I'm going to talk about first is that of being neighborhood exposed.",
                    "label": 0
                },
                {
                    "sent": "So for example we will say you are fully neighborhood exposed to the treatment when you and all your neighbors are treated and you are fully neighborhood exposed to the control.",
                    "label": 1
                },
                {
                    "sent": "When you and all your friends are in control.",
                    "label": 0
                },
                {
                    "sent": "There is.",
                    "label": 0
                },
                {
                    "sent": "Obvious analogs of this, where you say your neighborhood exposed when K of your for you.",
                    "label": 0
                },
                {
                    "sent": "In case if your friends are exposed to the treatment, you in case your friends are exposed to the control, and similarly there's a fractional approach.",
                    "label": 0
                },
                {
                    "sent": "So what does this look like?",
                    "label": 0
                },
                {
                    "sent": "The relevant space for this that helps understand this problem is there's the weather.",
                    "label": 0
                },
                {
                    "sent": "The ego is treated whether you are treated there is that sort of a 01 coin flip.",
                    "label": 0
                },
                {
                    "sent": "And then there's the fraction or the count of the number of friends that were treated.",
                    "label": 0
                },
                {
                    "sent": "And there's really this case of you not being treated and none of your friends and you being created in all of your friends or sort of the extreme universes.",
                    "label": 0
                },
                {
                    "sent": "So you're trying to compare when you do a B tests and that's readily accessible if there isn't this dependence, or when there is interference but becomes a problem otherwise.",
                    "label": 0
                },
                {
                    "sent": "And so when we define these sets, Sigma were actually sort of making a fudge assumption of what are the conditions where you're experiencing the product equivalent to.",
                    "label": 0
                },
                {
                    "sent": "If everybody had it or didn't have it.",
                    "label": 0
                },
                {
                    "sent": "So here were saying, Oh well, you basically have your basically experiencing video to full capacity.",
                    "label": 0
                },
                {
                    "sent": "If more than 80% of your friends have video chat and you haven't.",
                    "label": 0
                },
                {
                    "sent": "And similarly, if less than 20% and how to define those is sort of important modeling assumption that.",
                    "label": 0
                },
                {
                    "sent": "1.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It's Mick.",
                    "label": 0
                },
                {
                    "sent": "So simple example.",
                    "label": 0
                },
                {
                    "sent": "Very simple graph.",
                    "label": 0
                },
                {
                    "sent": "Here we see the person the leftmost person on the.",
                    "label": 0
                },
                {
                    "sent": "Your leftmost person on the slide who has video chat.",
                    "label": 0
                },
                {
                    "sent": "They are now 2/3 network exposed to the treatment and on the right side there's a person there who's 2/3 network exposed to the control and so those are the types of people that we want to be comparing.",
                    "label": 1
                },
                {
                    "sent": "When we run these types of experiments because there's sort of some version of adequately exposed.",
                    "label": 1
                },
                {
                    "sent": "So this is this is if you're willing to buy neighborhood exposure as a good a good exposure model.",
                    "label": 1
                },
                {
                    "sent": "In the paper we talk about something called that we call a component exposure, which is saying well.",
                    "label": 0
                },
                {
                    "sent": "There is a huge problem with this figure, and that's that the person all the way to the left.",
                    "label": 0
                },
                {
                    "sent": "Sure, they have video chat insure 2/3 of their friends video chat, but actually those friends you're the only person who they know who has video chat and the individual.",
                    "label": 0
                },
                {
                    "sent": "On the top there they have two other friends who don't video chat and you're the only person why should they really started using video chat.",
                    "label": 0
                },
                {
                    "sent": "They already talked to you on text messaging all the time or or they're not here strongest friend.",
                    "label": 0
                },
                {
                    "sent": "And you're not the relevant person for this product for them, so that's where you actually want to define sort of recursive notion of.",
                    "label": 1
                },
                {
                    "sent": "You are never exposed only if 2/3 of your friends are exposed in 2/3 of the 2/3 of those friends are in turn have 2/3 of their friends exposed and sort of this recursive notion, and that ends up being then we write it down on the paper exactly the question of are you in the cake or of the induced sub graph of people treated?",
                    "label": 0
                },
                {
                    "sent": "Or are you in the cake or of the induced subgraphs to people who are in the control so that ends computing the probabilities of when that happens is not something we were able to solve.",
                    "label": 0
                },
                {
                    "sent": "So we kind of left that out, but I'm going to talk about neighborhood exposure where it's just the notion of some fraction of your friends being treated.",
                    "label": 0
                },
                {
                    "sent": "But I think that the component exposure notion is sort of important enough to include this paper, but we didn't really make any further progress on it.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now we have this notion of when are you surrounded?",
                    "label": 0
                },
                {
                    "sent": "When are you experiencing your universe and now we want to cluster the graph and randomize clusters.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how do we partition the graph?",
                    "label": 1
                },
                {
                    "sent": "This is Facebook 2010 and this reveal is a very good way to select clusters which is geographically because this is showing every user as a node and edges or these blue arcs and it's basically showing this firestorm locali around places because you're friends with people who live close to you.",
                    "label": 0
                },
                {
                    "sent": "Very intuitive so the very good way to run an.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is to take a country like NZ and run an experiment in that country.",
                    "label": 0
                },
                {
                    "sent": "The problem with that is that New Zealand is not is sort of there an English speaking language so you don't know that much about how your translations into other languages are doing.",
                    "label": 0
                },
                {
                    "sent": "You might have bugs and your internationalization code.",
                    "label": 0
                },
                {
                    "sent": "They're just a different country that there might be other competition on that market that you don't necessarily know, and it's hard to pick a country that's truly representative, so.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What we do in this approach is to say, OK, let's cluster the graph.",
                    "label": 0
                },
                {
                    "sent": "The very, very large graph into many, many small clusters, and I mean.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sort of.",
                    "label": 0
                },
                {
                    "sent": "Many many, many small clusters.",
                    "label": 0
                },
                {
                    "sent": "You want 10,000 or more when we've been testing this in work, that's not including this paper, we've been doing 64,000 clusters and things like that, and you want to flip a coin for every one of those clusters, and so you're really sort of randomizing talent.",
                    "label": 0
                },
                {
                    "sent": "Some towns in various parts of Illinois are getting one and maybe Chicago.",
                    "label": 0
                },
                {
                    "sent": "It's the other and various or not depending on if you're doing clustering geographically or not.",
                    "label": 0
                },
                {
                    "sent": "We're basically looking to cluster these small small regions, but many of them to get a large effective population.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what are some algorithms that are graphic graphical for this?",
                    "label": 0
                },
                {
                    "sent": "The problem with the geometric, the geographic stuff is that you don't really.",
                    "label": 0
                },
                {
                    "sent": "You don't have many guarantees on what your actual performance is going to be.",
                    "label": 0
                },
                {
                    "sent": "If you're working at the scale of the Facebook graph, you really need to work with the highly highly scalable algorithms, so some of the algorithms that we've been working with is the label propagation and the Louvin method for Community detection that does a good job of running very fast.",
                    "label": 1
                },
                {
                    "sent": "I had a paper with my Co author who I've worked on with this large.",
                    "label": 0
                },
                {
                    "sent": "Backstrom had wisdom early this year on something called balance labor propagation, which we used at Facebook in another context to partition the full Facebook graph into many parts.",
                    "label": 0
                },
                {
                    "sent": "There's also lightweight algorithms.",
                    "label": 0
                },
                {
                    "sent": "Standing Quote was a paper or KD last year on streaming got partitioning.",
                    "label": 0
                },
                {
                    "sent": "There's a paper by Store caucus that's closely related, and then as an advertisement for a paper that I had in the poster session yesterday with my Co author Joel Nishimura, honoree, streaming algorithm that has the same speed advantage of streaming graph partitioning and can work at this sort of tremendous scales.",
                    "label": 0
                },
                {
                    "sent": "So how are you going to carve up the globe, as are two European counterparts were doing there in something century everything century?",
                    "label": 0
                },
                {
                    "sent": "Little cartoon so at the end of this I'm going to talk about a clustering algorithm where we can prove things which is interesting because all those others are heuristics and the way in which the proof follows says a lot about how you should calibrate those other algorithms.",
                    "label": 0
                },
                {
                    "sent": "So that's sort of the lesson that we want to leverage out of that.",
                    "label": 0
                },
                {
                    "sent": "The analysis of that algorithm.",
                    "label": 0
                },
                {
                    "sent": "But it's not necessarily the best algorithm I want to say that, importantly, if you want to go out and deploy our deploy experiments in a clustered manner, I wouldn't necessarily recommend flipping to the end of our paper and taking this algorithm, and.",
                    "label": 0
                },
                {
                    "sent": "Implementing it, but I would recommend processing the lessons of it for how to set it guides how you should scale your clusters so those other algorithms are modern, fast things that are good at this problem.",
                    "label": 0
                },
                {
                    "sent": "Medecins great if you can fit your craft in memory.",
                    "label": 0
                },
                {
                    "sent": "Otherwise as an offline clustering algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I said we have to compute probability weights.",
                    "label": 1
                },
                {
                    "sent": "To do this normalization in the Harvard Thompson estimator.",
                    "label": 0
                },
                {
                    "sent": "So that's this interesting problem.",
                    "label": 0
                },
                {
                    "sent": "Now you've clustered your graph into these black circles, and you have these coins.",
                    "label": 0
                },
                {
                    "sent": "They're flipping, and let's say you're the yellow individual in the middle, and you now depend on 4 coins, and so I need to.",
                    "label": 0
                },
                {
                    "sent": "Sorry, you only depend on 3 coins.",
                    "label": 0
                },
                {
                    "sent": "I need to know that your chance of having all of your neighborhood treated is some version of Peter the beta 3.",
                    "label": 0
                },
                {
                    "sent": "But if I'm interested in fractional treatment, which I need to be if I want to.",
                    "label": 0
                },
                {
                    "sent": "Be able to count people who are pretty much experiencing video chat.",
                    "label": 1
                },
                {
                    "sent": "In my experiment I need to do this exercise of computing the probability of 80% of my friends are treated so this.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Turns out to be a dynamic program, and you can actually exactly compute the full distribution in this space of 01 cross interval 01, and then you say OK, how much probability mass is in these two yellow boxes, so you can compute that for every individual you need to do it, but it is embarrassingly parallelizable and you can compute those probabilities so you can compute your estimate.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so the fact that we can do this probability so that that estimator is something we cannot work with.",
                    "label": 0
                },
                {
                    "sent": "Can we analyze the variances then the big question.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the answer is yes, this is work in parens.",
                    "label": 0
                },
                {
                    "sent": "Tommy toes in 12 that center Bogra fee.",
                    "label": 0
                },
                {
                    "sent": "It's an expensive expression, but the probabilities that come up here are the ones that you need to compete with the dynamic program.",
                    "label": 0
                },
                {
                    "sent": "So you compute those probabilities and you can sort of analyze the variance of estimator, and now this is the variance estimator is what we want to bring down.",
                    "label": 0
                },
                {
                    "sent": "So this.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is the motivating example that then leads to our algorithm, which is basically we started by saying.",
                    "label": 0
                },
                {
                    "sent": "What can we do on the simplest case of a cycle graph cycle graph has a various obvious, very obvious clustering.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You want to cluster the graph into sort of groups of two 345 continuously along the graph?",
                    "label": 0
                },
                {
                    "sent": "How well, what at what scale is our variance minimized when we do this?",
                    "label": 0
                },
                {
                    "sent": "So the model here is it's doing full exposure, so it's just if you and all your friends so you and your two neighbors both have to be in the same treatment.",
                    "label": 0
                },
                {
                    "sent": "And the response model is that there's some sort of East Coast West Coast gradient of half the people responded to treatment have the people responded to treatment where and your numbers, and if you're in control, you're responding zero and we said OK, can we analyze the variance of this?",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Depending on how you choose the size of your cluster.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And it turns out that you can do this close form and you get this nice internal Optima which says that you should be clustering sort of three nodes at a time.",
                    "label": 0
                },
                {
                    "sent": "And that was really interesting.",
                    "label": 0
                },
                {
                    "sent": "'cause where is 3 in this figure?",
                    "label": 0
                },
                {
                    "sent": "It's the size of the neighborhood.",
                    "label": 0
                },
                {
                    "sent": "So then we stepped over to simulations.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I have powers of the psychograph and said OK, where is the Optima there and it turns out that again.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then the Optima very clearly fall.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As the lowest point on the variance curve is choosing clusters that are the size of neighborhoods.",
                    "label": 0
                },
                {
                    "sent": "These are regular graphs.",
                    "label": 0
                },
                {
                    "sent": "The neighborhoods are all the same size.",
                    "label": 0
                },
                {
                    "sent": "And what's even more interesting is that as you increase the average degree from sort of having one on one note on each side, two nodes inside 345, your variance is growing only linearly in your degree.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And that's relevant because when you did IID randomization, you're actually getting exponential growth in your variance.",
                    "label": 0
                },
                {
                    "sent": "So here is where we said OK, there's something important about looking at these basic cycle graphs where you get linear variance as opposed to exponential variance if you choose your clusters at the right size and there's this intermediate internal sweet spot that you want to try and get.",
                    "label": 0
                },
                {
                    "sent": "That is very clear on these simple graphs, and it's harder to see very hard.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "See unreal.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Graphs.",
                    "label": 0
                },
                {
                    "sent": "So to conclude, there's this important generalization of cycle graphs where rather than just looking at a cycle graph, you look at a restricted growth graph, which is basically any graph that the size of the of the successive balls is bounded by some factor Kappa, so.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for bounded degree graphs, this is some sort of.",
                    "label": 0
                },
                {
                    "sent": "This is trivially sort of the Max degree plus one is this Kappa quantity, but for anything that's close to a Euclidean as close to uniform bedding in the Euclidean space, you're going to see a very low Kappa, and this is borrowing intuition from the carbon rule literature on nearest neighbor search in metric spaces, where they say OK if you have this bounded growth metric which is similar to the restricted growth that we're talking about, it's different, so it's a different name then.",
                    "label": 1
                },
                {
                    "sent": "You can use that use the metric to create your or you can.",
                    "label": 0
                },
                {
                    "sent": "You can use the fact that.",
                    "label": 0
                },
                {
                    "sent": "You and then you know things about how different nodes can be adjacent to each other and how things can pack into different corners.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That was a weird formulation, but that basically lets you say that if you do what's called A3 net clustering, where three.",
                    "label": 0
                },
                {
                    "sent": "Net is a trademarked term from the bounded growth literature on sort of epsilon nuts.",
                    "label": 0
                },
                {
                    "sent": "If you create just you mark arbitrary vertices and take their two balls, and that's a clustering algorithm, there's an important tiebreaking detail the timing, but you basically just create you cluster the graph based on two hop to hop out from an individual vertices.",
                    "label": 0
                },
                {
                    "sent": "They're selecting a random.",
                    "label": 0
                },
                {
                    "sent": "If you do that.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We show in the paper that that means that you depend on a bounded number of clusters independent of your degree.",
                    "label": 0
                },
                {
                    "sent": "So even if you have really high degree, you're only depending on a few clusters.",
                    "label": 0
                },
                {
                    "sent": "'cause Euclidean space you can't reach that many different clusters approximately Euclidean space, and that means that we have this linear variance bounds.",
                    "label": 0
                },
                {
                    "sent": "So that means that on graphs that are sort of random geometric graphs, and if you're willing to consider something like a social graph as being embedded in a geometric geographic space, then you have some version of this.",
                    "label": 0
                },
                {
                    "sent": "That means that doing these neighborhood clusterings is going to give you.",
                    "label": 0
                },
                {
                    "sent": "Very favorable variance behavior compared to, certainly compared to IID coin flipping.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the lessons of this paper is sort of an exploration of this really hard problem that we've been working.",
                    "label": 0
                },
                {
                    "sent": "I've been working on with people at Facebook, which is that of running a B tests when in the presence of network effects and your variance of matter, which is what you're trying to drive down, so you can actually measure something.",
                    "label": 0
                },
                {
                    "sent": "So the variances in larger than your effect that depends on how you characterize your exposure and what algorithm you use.",
                    "label": 0
                },
                {
                    "sent": "So there's sort of space here for testing a lot of different algorithms that are beyond what we've been looking at.",
                    "label": 0
                },
                {
                    "sent": "And we have this condition that lets you bound variance.",
                    "label": 1
                },
                {
                    "sent": "But really any graph clustering algorithm can greatly reduce the variance.",
                    "label": 1
                },
                {
                    "sent": "So we've been experimentally testing a bunch of different algorithms in various tests of Facebook, so it's sort of a problem that we are actively fanatically working on with these collaborators so.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                }
            ]
        }
    }
}