{
    "id": "mluhisrycp77so4ybqzcdn3mgj7ycuuu",
    "title": "A Naturalistic Open Source Movie for Optical Flow Evaluation",
    "info": {
        "author": [
            "Daniel J. Butler, University of Washington"
        ],
        "chairman": [
            "Bernt Schiele, Max Planck Institut Informatik, Max Planck Institute",
            "David Forsyth, Department of Computer Science, University of Illinois at Urbana-Champaign"
        ],
        "published": "Nov. 12, 2012",
        "recorded": "October 2012",
        "category": [
            "Top->Computer Science->Computer Vision"
        ]
    },
    "url": "http://videolectures.net/eccv2012_butler_optical/",
    "segmentation": [
        [
            "I'm Dan Butler.",
            "I'm a PhD student at the University of Washington in Seattle and I'll be presenting a naturalistic open source movie for optical flow evaluation."
        ],
        [
            "This is joint work with Jonas Wolf, Garrett Stanley and Michael Black."
        ],
        [
            "Many advances in computer vision have been driven by new datasets, and optical flow is no different.",
            "Let's take a look at the current gold standard for optical flow data.",
            "The Middlebury data set."
        ],
        [
            "This video consists of all the sequences from the middle."
        ],
        [
            "Reset the contain ground truth optical flow.",
            "While Middlebury has had a huge impact on the field and led to large improvements in the state of the art, you might notice some slightly weird things about this data set.",
            "First, it's a bit unnatural looking.",
            "These scenes were not designed to capture fully capture the real world statistics of the world.",
            "For example, there are no large displacements of over 40 pixels.",
            "Second, it's idealized.",
            "There are no real world nuisances like motion blur."
        ],
        [
            "Finally, it's small.",
            "There are 16 sequences, each with just 8 frames or fewer and only one ground truth flow field for each sequence.",
            "Right now you're looking at all of the ground truth flow fields from Middlebury.",
            "This is not really the fault of the authors though.",
            "Ground truth optical flow data is genuinely difficult to obtain since there are no sensors that measure it directly.",
            "This modest amount of data may be part of the reason that machine learning approaches have not flourished in the area of optical flow.",
            "Throughout the talk, I'll use this visualization scheme.",
            "He represents direction and saturation, represents speed, lower saturation indicating lower speed.",
            "Next, let's let's look at the impact Middlebury has had on optical flow."
        ],
        [
            "Research this plot shows the error of the top ranked 5th ranked and 10th ranked methods on the Middlebury data set.",
            "Overtime as more and more methods have been submitted.",
            "The error measure called average endpoint error or EP, is just the average Euclidean distance between the estimated flow and the true flow.",
            "The takeaway from this plot is that over the last five years, the air of the top method on Middlebury has almost been cut in half, but progress is slowing and the top ten methods are becoming tightly clustered in terms of performance.",
            "All this sub."
        ],
        [
            "Jess, we need a challenging new data set and indeed there have been a number of proposals.",
            "The ketiv."
        ],
        [
            "Asian benchmark consists of flow derived from depth data captured from a laser range Finder on a moving vehicle.",
            "Because of the nature of the collection method, this data set contains only rigid scenes there.",
            "There's no flow data for objects moving independently in 3D.",
            "It's also tailored specifically to automotive applications.",
            "The HCI robust Vision Challenge consists of extremely challenging real world sequences, also filmed from a moving vehicle.",
            "The downside is that no ground truth flow data is available.",
            "Flow estimates are to be judged qualitatively by humans.",
            "The UCL groundtruth optical flow data set consists of simple synthetic scenes.",
            "These scenes have the distinct advantage of being fully controllable and easy, easily extensible, but they exhibit fairly limited visual complexity.",
            "Finally, the Human assisted motion annotation data set consists of flow fields generated interactively from human annotations and the assistance of an existing optical flow algorithm.",
            "The scenes are real and quite natural looking, but the ground truth flow is approximate.",
            "With that, I'd like to introduce the MPI Cinta."
        ],
        [
            "Optical flow data set.",
            "MPI Sintel is derived from the open source 3D animated short film Sintel.",
            "It features long sequences of 50 frames.",
            "Large nonrigid motions, speeds of over 100 pixels per frame, and real world challenges such as motion blur, defocus, blur and atmospheric effects.",
            "It contains 35 sequences just over 1600 video frames and just under 1600.",
            "Ground truth optical flow fields.",
            "The short film Sintel was created by the Blender Foundation.",
            "In order to test and promote the blender open source animation suite."
        ],
        [
            "Now we would have loved to get our hands on Hollywood animated film like Avatar or Wally.",
            "But there's a key feature of this movie that makes it special.",
            "It's free and open source.",
            "All of the graphics data have been released under a generous Creative Commons license, so we can render it ourselves.",
            "Also, the rendering software is open source so we can make bug fixes and other modifications necessary to generate usable ground truth optical flow.",
            "There's a natural question that always comes up when using computer generated imagery for computer vision."
        ],
        [
            "And that is is synthetic data good enough?",
            "Synthetic datasets have played a crucial role in optical flow evaluation in the past, and this question has always loomed large.",
            "To start to answer it, we had an idea."
        ],
        [
            "We could compare the visual statistics of sintel to the statistics of local."
        ],
        [
            "Like sequences are look alike, sequences are real videos with similar semantic content to Synta.",
            "Here are some of the local like sequences played at 3X.",
            "Our question was, are there videos that are fairly representative of videos from the web that matched the 1st order statistics of Syntel?",
            "We did simple keyword searches on sites like YouTube and Vimeo to find our look alikes and then we ran a series of statistical."
        ],
        [
            "Comparisons.",
            "First we looked at image statistics.",
            "In particular luminance histograms, power Spectra, and derivative."
        ],
        [
            "Histograms here's a representative example of our results.",
            "A comparison of the image derivative log histograms, the X axes of the two plots represent the partial derivatives of image intensity in the X&Y directions, respectively.",
            "The Axis represents the log fraction of pixels.",
            "The look alikes are in blue Syntel is in red and Middlebury is in green.",
            "We were hoping that Syntel in Red and the look alikes in blue would be a close match, and as we can see there reasonably close for quantitative results.",
            "We refer you to the paper.",
            "But what about most?"
        ],
        [
            "In statistics, image statistics are only half the problem.",
            "Do the motions of Syntel resemble natural motions?",
            "Our approach was to run the optical flow algorithm on both the look alikes and the Syntel sequences to serve as a proxy for ground truth optical flow on the look alikes.",
            "We then compared the statistics of this estimated flow.",
            "In particular, we looked at histograms of horizontal and vert."
        ],
        [
            "Components of flow speed histogram."
        ],
        [
            "And derivative histograms.",
            "Here we see the results of the speed histogram comparison.",
            "The X axis is the speed of a given pixel and units of pixels per frame and the Y axis Y axis is the log fraction of pixels.",
            "Again, look like certain blue Syntel's in red in middlebury's in green.",
            "Remember this plot describes this statistics of estimated flow for comparison.",
            "We also show the histogram from this Intel ground truth as a red dotted line, although this is not part of the main comparison, and again Syntel shown in red is reasonably close to the look alikes in blue."
        ],
        [
            "The realism story isn't over, though obviously Sintel is not photo realistic.",
            "However, it does pass these sanity checks.",
            "We think some important directions for future work or the use of more photo realistic graphics data and the general problem of evaluating the realism of synthetic data for use in computer vision.",
            "For audience members interested in the second problem, we refer you to the recent work of my strengh Underman."
        ],
        [
            "But CG data is not just good enough.",
            "It also has major advantages, tight control over the rendering process allows us to evaluate optical flow methods in new ways."
        ],
        [
            "We render sintel under different lighting conditions or passes to evaluate where and why flow algorithms fail.",
            "The albedo pass contains no shading and obeys brightness constancy everywhere except in unmatched regions.",
            "The Clean path pass in the middle adds smooth shading and specularities well.",
            "The final pass on the right ads motion blur, defocus, blur, and atmospheric effects."
        ],
        [
            "Using computer graphics also allows us to examine the effects of occlusion boundaries.",
            "Current flow methods seem to do badly near occlusion boundaries and to quantify this, it's important to even identify exactly where these boundaries are, because we have access to the underlying graphics data, we're able to produce high accuracy boundary masks by intersecting high flow gradient areas with object boundaries.",
            "See our paper for more details."
        ],
        [
            "Because the displacement since Intel are much larger than previous datasets, it makes sense to distinguish between occlusion boundaries and what we call unmatched regions.",
            "These are parts of the scene that are visible in one frame but not in the next.",
            "As we'll see later, these regions are a major source of error from modern flow methods, let's."
        ],
        [
            "Let's take a look at some results."
        ],
        [
            "We've created an online submission system for flow results and seated the system with seven publicly available methods.",
            "We invite you to take a look right now at Syntel Dot IS dot UE dot MPG dot D. On this site you can view a performance table of the seed methods with errors broken down by different masks, matched and unmatched regions, regions near and far from occlusion boundaries and regions with high and low speeds.",
            "On this web page you can also download the trainings data set with full ground truth optical flow and the video frames of the test set.",
            "Finally, we invite you to evaluate your own up to run your own optical flow methods on our data set and submit your results.",
            "Anne.",
            "Here."
        ],
        [
            "Some results from the MDP flow two algorithm, currently the highest ranked method on both Middlebury and Syntel.",
            "The image on the top is an estimated flow field and the image on the bottom is a map of the endpoint error, with white indicating higher errors."
        ],
        [
            "Here's the corresponding ground truth for comparison.",
            "The first thing to notice is that the errors here are much more pronounced than on Middlebury."
        ],
        [
            "In fact, the error of this method on CentOS about 35 times larger than its error on Middlebury."
        ],
        [
            "Some key takeaways from our evaluation so far unmatched regions are really hard with an average error of about 45 pixels versus only about 5 pixels in matched regions.",
            "Regions that move it more than 40 pixels per frame show much worse error than regions moving less than 10 pixels per frame, about 50 pixels versus only 1.5 pixels error last but not least, the final pass is much harder than a clean path or is part of the class.",
            "About 15 to 40% depending on the method.",
            "Some lessons learned from this project.",
            "We thought this would be."
        ],
        [
            "Easy, but it really wasn't movies.",
            "Just need to look good full control of the graphics data and rendering pipeline was necessary to create image sequences with accurate optical flow and to find out more about what we had to do to create this data set, see our poster at the Workshop on Unsolved problems in optical flow and stereo estimation tomorrow at 2:00 PM."
        ],
        [
            "Central poses several grand challenges for optical flow estimation.",
            "First, unmatched regions because unmatched regions are such an important aspect of this data set, we think Syntel will encourage new methods that integrate information overtime and incorporate layering.",
            "The second is high speeds.",
            "Our comparison with the look alikes confirms what many people already suspected that optical flow methods need to be better at handling.",
            "Large displacements between frames.",
            "The 3rd and final grand challenges.",
            "Real world effects like Motion blur, defocus, blur, in atmospherics these pose serious problems for current methods and will need to be addressed."
        ],
        [
            "Thank you very much for your attention.",
            "Questions for speaker.",
            "Beautiful work.",
            "I'm so happy you guys have done this.",
            "I think it will make a tremendous difference to our field and result in better flow algorithms.",
            "One thing you didn't mention was noise.",
            "Did you ever try adding synthetic noise?",
            "Because under low light like party videos we still see a fair amount of just grain and noise in regular video cameras.",
            "That's a good question.",
            "No, we didn't introduce noise explicitly, but this is an interesting future direction.",
            "Thank you.",
            "Yep, so I also think it's really a great work.",
            "I guess I'm wondering is going forward.",
            "Is optical flow really the right thing to be concentrating on in terms of evaluation?",
            "I mean clearly you can do so much more with this data in terms of ground truth for nonrigid 3D reconstruction, for instance.",
            "I mean what?",
            "What's the application of optical flow?",
            "And if you've got a real sequence of images, you're never really going to just do pairwise optical flow, you're going to start doing reconstruction and so on, so.",
            "Is it right to stay focused on optical flow?",
            "That's a valid question.",
            "I think in the optical flow isn't necessarily the focus, but this is provides a benchmark to see how well you've reconstructed a scene, or how well you understand to see Nana Raible to reconstruct those motions.",
            "I think ultimately there's lots of different applications, like segmentation and reconstruction and so forth, and actually Syntel could provide reasonable ground truth in those areas as well.",
            "Although we haven't generated that sort of data yet.",
            "OK.",
            "I have a question about occlusion boundaries, so people seem to have some funny notions about what an occlusion boundary is, and it seems to be distinct from a depth discontinuity.",
            "What is your idea of an occlusion boundary?",
            "So our idea of an occlusion boundary is it's an object boundary where there's a high flow gradient and we are definition of object boundary.",
            "Now you know, we've sort of pushed the significant question on to that in this data set, we look at the boundaries of the objects that were defined by the animators plus up material boundaries plus depth boundaries.",
            "So that's how we defined object boundaries in our data set.",
            "So if I have an arm with an elbow, is the lower arm in the upper arm?",
            "Is there an occlusion boundary between them?",
            "So in this data set node, there wouldn't be if that was like a semantically meaningful difference than those that would be an object boundary an if in addition there was a large flow discontinuity at the boundary between those between your elbow and your arm, then there would also be an inclusion boundary, but we wouldn't see large flow discontinuity's there, so no, it would not be.",
            "That's your question.",
            "I don't see any further questions.",
            "Let's think there's one more hold up, hold up.",
            "Not quite yet.",
            "Do you plan to extend this work for stereo matching?",
            "We don't have immediate plans, but this is something we'd love to do.",
            "So if you're interested in that data, please contact us.",
            "OK, that's thank you, speak again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm Dan Butler.",
                    "label": 0
                },
                {
                    "sent": "I'm a PhD student at the University of Washington in Seattle and I'll be presenting a naturalistic open source movie for optical flow evaluation.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is joint work with Jonas Wolf, Garrett Stanley and Michael Black.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Many advances in computer vision have been driven by new datasets, and optical flow is no different.",
                    "label": 0
                },
                {
                    "sent": "Let's take a look at the current gold standard for optical flow data.",
                    "label": 0
                },
                {
                    "sent": "The Middlebury data set.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This video consists of all the sequences from the middle.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Reset the contain ground truth optical flow.",
                    "label": 0
                },
                {
                    "sent": "While Middlebury has had a huge impact on the field and led to large improvements in the state of the art, you might notice some slightly weird things about this data set.",
                    "label": 0
                },
                {
                    "sent": "First, it's a bit unnatural looking.",
                    "label": 0
                },
                {
                    "sent": "These scenes were not designed to capture fully capture the real world statistics of the world.",
                    "label": 0
                },
                {
                    "sent": "For example, there are no large displacements of over 40 pixels.",
                    "label": 0
                },
                {
                    "sent": "Second, it's idealized.",
                    "label": 0
                },
                {
                    "sent": "There are no real world nuisances like motion blur.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Finally, it's small.",
                    "label": 0
                },
                {
                    "sent": "There are 16 sequences, each with just 8 frames or fewer and only one ground truth flow field for each sequence.",
                    "label": 0
                },
                {
                    "sent": "Right now you're looking at all of the ground truth flow fields from Middlebury.",
                    "label": 0
                },
                {
                    "sent": "This is not really the fault of the authors though.",
                    "label": 0
                },
                {
                    "sent": "Ground truth optical flow data is genuinely difficult to obtain since there are no sensors that measure it directly.",
                    "label": 0
                },
                {
                    "sent": "This modest amount of data may be part of the reason that machine learning approaches have not flourished in the area of optical flow.",
                    "label": 0
                },
                {
                    "sent": "Throughout the talk, I'll use this visualization scheme.",
                    "label": 0
                },
                {
                    "sent": "He represents direction and saturation, represents speed, lower saturation indicating lower speed.",
                    "label": 0
                },
                {
                    "sent": "Next, let's let's look at the impact Middlebury has had on optical flow.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Research this plot shows the error of the top ranked 5th ranked and 10th ranked methods on the Middlebury data set.",
                    "label": 0
                },
                {
                    "sent": "Overtime as more and more methods have been submitted.",
                    "label": 0
                },
                {
                    "sent": "The error measure called average endpoint error or EP, is just the average Euclidean distance between the estimated flow and the true flow.",
                    "label": 1
                },
                {
                    "sent": "The takeaway from this plot is that over the last five years, the air of the top method on Middlebury has almost been cut in half, but progress is slowing and the top ten methods are becoming tightly clustered in terms of performance.",
                    "label": 0
                },
                {
                    "sent": "All this sub.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Jess, we need a challenging new data set and indeed there have been a number of proposals.",
                    "label": 0
                },
                {
                    "sent": "The ketiv.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Asian benchmark consists of flow derived from depth data captured from a laser range Finder on a moving vehicle.",
                    "label": 0
                },
                {
                    "sent": "Because of the nature of the collection method, this data set contains only rigid scenes there.",
                    "label": 0
                },
                {
                    "sent": "There's no flow data for objects moving independently in 3D.",
                    "label": 0
                },
                {
                    "sent": "It's also tailored specifically to automotive applications.",
                    "label": 0
                },
                {
                    "sent": "The HCI robust Vision Challenge consists of extremely challenging real world sequences, also filmed from a moving vehicle.",
                    "label": 1
                },
                {
                    "sent": "The downside is that no ground truth flow data is available.",
                    "label": 0
                },
                {
                    "sent": "Flow estimates are to be judged qualitatively by humans.",
                    "label": 0
                },
                {
                    "sent": "The UCL groundtruth optical flow data set consists of simple synthetic scenes.",
                    "label": 0
                },
                {
                    "sent": "These scenes have the distinct advantage of being fully controllable and easy, easily extensible, but they exhibit fairly limited visual complexity.",
                    "label": 0
                },
                {
                    "sent": "Finally, the Human assisted motion annotation data set consists of flow fields generated interactively from human annotations and the assistance of an existing optical flow algorithm.",
                    "label": 0
                },
                {
                    "sent": "The scenes are real and quite natural looking, but the ground truth flow is approximate.",
                    "label": 0
                },
                {
                    "sent": "With that, I'd like to introduce the MPI Cinta.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Optical flow data set.",
                    "label": 0
                },
                {
                    "sent": "MPI Sintel is derived from the open source 3D animated short film Sintel.",
                    "label": 0
                },
                {
                    "sent": "It features long sequences of 50 frames.",
                    "label": 0
                },
                {
                    "sent": "Large nonrigid motions, speeds of over 100 pixels per frame, and real world challenges such as motion blur, defocus, blur and atmospheric effects.",
                    "label": 0
                },
                {
                    "sent": "It contains 35 sequences just over 1600 video frames and just under 1600.",
                    "label": 0
                },
                {
                    "sent": "Ground truth optical flow fields.",
                    "label": 1
                },
                {
                    "sent": "The short film Sintel was created by the Blender Foundation.",
                    "label": 0
                },
                {
                    "sent": "In order to test and promote the blender open source animation suite.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now we would have loved to get our hands on Hollywood animated film like Avatar or Wally.",
                    "label": 0
                },
                {
                    "sent": "But there's a key feature of this movie that makes it special.",
                    "label": 0
                },
                {
                    "sent": "It's free and open source.",
                    "label": 1
                },
                {
                    "sent": "All of the graphics data have been released under a generous Creative Commons license, so we can render it ourselves.",
                    "label": 0
                },
                {
                    "sent": "Also, the rendering software is open source so we can make bug fixes and other modifications necessary to generate usable ground truth optical flow.",
                    "label": 0
                },
                {
                    "sent": "There's a natural question that always comes up when using computer generated imagery for computer vision.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And that is is synthetic data good enough?",
                    "label": 1
                },
                {
                    "sent": "Synthetic datasets have played a crucial role in optical flow evaluation in the past, and this question has always loomed large.",
                    "label": 0
                },
                {
                    "sent": "To start to answer it, we had an idea.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We could compare the visual statistics of sintel to the statistics of local.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Like sequences are look alike, sequences are real videos with similar semantic content to Synta.",
                    "label": 0
                },
                {
                    "sent": "Here are some of the local like sequences played at 3X.",
                    "label": 0
                },
                {
                    "sent": "Our question was, are there videos that are fairly representative of videos from the web that matched the 1st order statistics of Syntel?",
                    "label": 0
                },
                {
                    "sent": "We did simple keyword searches on sites like YouTube and Vimeo to find our look alikes and then we ran a series of statistical.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Comparisons.",
                    "label": 0
                },
                {
                    "sent": "First we looked at image statistics.",
                    "label": 0
                },
                {
                    "sent": "In particular luminance histograms, power Spectra, and derivative.",
                    "label": 1
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Histograms here's a representative example of our results.",
                    "label": 0
                },
                {
                    "sent": "A comparison of the image derivative log histograms, the X axes of the two plots represent the partial derivatives of image intensity in the X&Y directions, respectively.",
                    "label": 1
                },
                {
                    "sent": "The Axis represents the log fraction of pixels.",
                    "label": 0
                },
                {
                    "sent": "The look alikes are in blue Syntel is in red and Middlebury is in green.",
                    "label": 0
                },
                {
                    "sent": "We were hoping that Syntel in Red and the look alikes in blue would be a close match, and as we can see there reasonably close for quantitative results.",
                    "label": 0
                },
                {
                    "sent": "We refer you to the paper.",
                    "label": 0
                },
                {
                    "sent": "But what about most?",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In statistics, image statistics are only half the problem.",
                    "label": 1
                },
                {
                    "sent": "Do the motions of Syntel resemble natural motions?",
                    "label": 0
                },
                {
                    "sent": "Our approach was to run the optical flow algorithm on both the look alikes and the Syntel sequences to serve as a proxy for ground truth optical flow on the look alikes.",
                    "label": 0
                },
                {
                    "sent": "We then compared the statistics of this estimated flow.",
                    "label": 0
                },
                {
                    "sent": "In particular, we looked at histograms of horizontal and vert.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Components of flow speed histogram.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And derivative histograms.",
                    "label": 0
                },
                {
                    "sent": "Here we see the results of the speed histogram comparison.",
                    "label": 0
                },
                {
                    "sent": "The X axis is the speed of a given pixel and units of pixels per frame and the Y axis Y axis is the log fraction of pixels.",
                    "label": 0
                },
                {
                    "sent": "Again, look like certain blue Syntel's in red in middlebury's in green.",
                    "label": 0
                },
                {
                    "sent": "Remember this plot describes this statistics of estimated flow for comparison.",
                    "label": 0
                },
                {
                    "sent": "We also show the histogram from this Intel ground truth as a red dotted line, although this is not part of the main comparison, and again Syntel shown in red is reasonably close to the look alikes in blue.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The realism story isn't over, though obviously Sintel is not photo realistic.",
                    "label": 1
                },
                {
                    "sent": "However, it does pass these sanity checks.",
                    "label": 0
                },
                {
                    "sent": "We think some important directions for future work or the use of more photo realistic graphics data and the general problem of evaluating the realism of synthetic data for use in computer vision.",
                    "label": 0
                },
                {
                    "sent": "For audience members interested in the second problem, we refer you to the recent work of my strengh Underman.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But CG data is not just good enough.",
                    "label": 0
                },
                {
                    "sent": "It also has major advantages, tight control over the rendering process allows us to evaluate optical flow methods in new ways.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We render sintel under different lighting conditions or passes to evaluate where and why flow algorithms fail.",
                    "label": 0
                },
                {
                    "sent": "The albedo pass contains no shading and obeys brightness constancy everywhere except in unmatched regions.",
                    "label": 0
                },
                {
                    "sent": "The Clean path pass in the middle adds smooth shading and specularities well.",
                    "label": 0
                },
                {
                    "sent": "The final pass on the right ads motion blur, defocus, blur, and atmospheric effects.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Using computer graphics also allows us to examine the effects of occlusion boundaries.",
                    "label": 0
                },
                {
                    "sent": "Current flow methods seem to do badly near occlusion boundaries and to quantify this, it's important to even identify exactly where these boundaries are, because we have access to the underlying graphics data, we're able to produce high accuracy boundary masks by intersecting high flow gradient areas with object boundaries.",
                    "label": 1
                },
                {
                    "sent": "See our paper for more details.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Because the displacement since Intel are much larger than previous datasets, it makes sense to distinguish between occlusion boundaries and what we call unmatched regions.",
                    "label": 0
                },
                {
                    "sent": "These are parts of the scene that are visible in one frame but not in the next.",
                    "label": 0
                },
                {
                    "sent": "As we'll see later, these regions are a major source of error from modern flow methods, let's.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's take a look at some results.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We've created an online submission system for flow results and seated the system with seven publicly available methods.",
                    "label": 0
                },
                {
                    "sent": "We invite you to take a look right now at Syntel Dot IS dot UE dot MPG dot D. On this site you can view a performance table of the seed methods with errors broken down by different masks, matched and unmatched regions, regions near and far from occlusion boundaries and regions with high and low speeds.",
                    "label": 0
                },
                {
                    "sent": "On this web page you can also download the trainings data set with full ground truth optical flow and the video frames of the test set.",
                    "label": 0
                },
                {
                    "sent": "Finally, we invite you to evaluate your own up to run your own optical flow methods on our data set and submit your results.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "Here.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some results from the MDP flow two algorithm, currently the highest ranked method on both Middlebury and Syntel.",
                    "label": 0
                },
                {
                    "sent": "The image on the top is an estimated flow field and the image on the bottom is a map of the endpoint error, with white indicating higher errors.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here's the corresponding ground truth for comparison.",
                    "label": 0
                },
                {
                    "sent": "The first thing to notice is that the errors here are much more pronounced than on Middlebury.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In fact, the error of this method on CentOS about 35 times larger than its error on Middlebury.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Some key takeaways from our evaluation so far unmatched regions are really hard with an average error of about 45 pixels versus only about 5 pixels in matched regions.",
                    "label": 1
                },
                {
                    "sent": "Regions that move it more than 40 pixels per frame show much worse error than regions moving less than 10 pixels per frame, about 50 pixels versus only 1.5 pixels error last but not least, the final pass is much harder than a clean path or is part of the class.",
                    "label": 0
                },
                {
                    "sent": "About 15 to 40% depending on the method.",
                    "label": 0
                },
                {
                    "sent": "Some lessons learned from this project.",
                    "label": 0
                },
                {
                    "sent": "We thought this would be.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Easy, but it really wasn't movies.",
                    "label": 0
                },
                {
                    "sent": "Just need to look good full control of the graphics data and rendering pipeline was necessary to create image sequences with accurate optical flow and to find out more about what we had to do to create this data set, see our poster at the Workshop on Unsolved problems in optical flow and stereo estimation tomorrow at 2:00 PM.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Central poses several grand challenges for optical flow estimation.",
                    "label": 1
                },
                {
                    "sent": "First, unmatched regions because unmatched regions are such an important aspect of this data set, we think Syntel will encourage new methods that integrate information overtime and incorporate layering.",
                    "label": 1
                },
                {
                    "sent": "The second is high speeds.",
                    "label": 0
                },
                {
                    "sent": "Our comparison with the look alikes confirms what many people already suspected that optical flow methods need to be better at handling.",
                    "label": 0
                },
                {
                    "sent": "Large displacements between frames.",
                    "label": 0
                },
                {
                    "sent": "The 3rd and final grand challenges.",
                    "label": 1
                },
                {
                    "sent": "Real world effects like Motion blur, defocus, blur, in atmospherics these pose serious problems for current methods and will need to be addressed.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you very much for your attention.",
                    "label": 0
                },
                {
                    "sent": "Questions for speaker.",
                    "label": 0
                },
                {
                    "sent": "Beautiful work.",
                    "label": 0
                },
                {
                    "sent": "I'm so happy you guys have done this.",
                    "label": 0
                },
                {
                    "sent": "I think it will make a tremendous difference to our field and result in better flow algorithms.",
                    "label": 0
                },
                {
                    "sent": "One thing you didn't mention was noise.",
                    "label": 0
                },
                {
                    "sent": "Did you ever try adding synthetic noise?",
                    "label": 0
                },
                {
                    "sent": "Because under low light like party videos we still see a fair amount of just grain and noise in regular video cameras.",
                    "label": 0
                },
                {
                    "sent": "That's a good question.",
                    "label": 0
                },
                {
                    "sent": "No, we didn't introduce noise explicitly, but this is an interesting future direction.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Yep, so I also think it's really a great work.",
                    "label": 0
                },
                {
                    "sent": "I guess I'm wondering is going forward.",
                    "label": 0
                },
                {
                    "sent": "Is optical flow really the right thing to be concentrating on in terms of evaluation?",
                    "label": 0
                },
                {
                    "sent": "I mean clearly you can do so much more with this data in terms of ground truth for nonrigid 3D reconstruction, for instance.",
                    "label": 0
                },
                {
                    "sent": "I mean what?",
                    "label": 0
                },
                {
                    "sent": "What's the application of optical flow?",
                    "label": 0
                },
                {
                    "sent": "And if you've got a real sequence of images, you're never really going to just do pairwise optical flow, you're going to start doing reconstruction and so on, so.",
                    "label": 0
                },
                {
                    "sent": "Is it right to stay focused on optical flow?",
                    "label": 0
                },
                {
                    "sent": "That's a valid question.",
                    "label": 0
                },
                {
                    "sent": "I think in the optical flow isn't necessarily the focus, but this is provides a benchmark to see how well you've reconstructed a scene, or how well you understand to see Nana Raible to reconstruct those motions.",
                    "label": 0
                },
                {
                    "sent": "I think ultimately there's lots of different applications, like segmentation and reconstruction and so forth, and actually Syntel could provide reasonable ground truth in those areas as well.",
                    "label": 0
                },
                {
                    "sent": "Although we haven't generated that sort of data yet.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "I have a question about occlusion boundaries, so people seem to have some funny notions about what an occlusion boundary is, and it seems to be distinct from a depth discontinuity.",
                    "label": 0
                },
                {
                    "sent": "What is your idea of an occlusion boundary?",
                    "label": 0
                },
                {
                    "sent": "So our idea of an occlusion boundary is it's an object boundary where there's a high flow gradient and we are definition of object boundary.",
                    "label": 0
                },
                {
                    "sent": "Now you know, we've sort of pushed the significant question on to that in this data set, we look at the boundaries of the objects that were defined by the animators plus up material boundaries plus depth boundaries.",
                    "label": 0
                },
                {
                    "sent": "So that's how we defined object boundaries in our data set.",
                    "label": 0
                },
                {
                    "sent": "So if I have an arm with an elbow, is the lower arm in the upper arm?",
                    "label": 0
                },
                {
                    "sent": "Is there an occlusion boundary between them?",
                    "label": 0
                },
                {
                    "sent": "So in this data set node, there wouldn't be if that was like a semantically meaningful difference than those that would be an object boundary an if in addition there was a large flow discontinuity at the boundary between those between your elbow and your arm, then there would also be an inclusion boundary, but we wouldn't see large flow discontinuity's there, so no, it would not be.",
                    "label": 0
                },
                {
                    "sent": "That's your question.",
                    "label": 0
                },
                {
                    "sent": "I don't see any further questions.",
                    "label": 0
                },
                {
                    "sent": "Let's think there's one more hold up, hold up.",
                    "label": 0
                },
                {
                    "sent": "Not quite yet.",
                    "label": 0
                },
                {
                    "sent": "Do you plan to extend this work for stereo matching?",
                    "label": 0
                },
                {
                    "sent": "We don't have immediate plans, but this is something we'd love to do.",
                    "label": 0
                },
                {
                    "sent": "So if you're interested in that data, please contact us.",
                    "label": 0
                },
                {
                    "sent": "OK, that's thank you, speak again.",
                    "label": 0
                }
            ]
        }
    }
}