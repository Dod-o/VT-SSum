{
    "id": "mxjqtb62pqcvqaugy77ih4n37t3j64q6",
    "title": "Learning from Labeled and Unlabelled Data: When the Smoothness Assumption Holds",
    "info": {
        "author": [
            "Michelangelo Ceci, University of Bari"
        ],
        "published": "March 11, 2011",
        "recorded": "February 2011",
        "category": [
            "Top->Computer Science->Machine Learning",
            "Top->Computer Science->Data Mining"
        ]
    },
    "url": "http://videolectures.net/solomon_ceci_ssl/",
    "segmentation": [
        [
            "So I had the great pleasure to introduce the speaker off today, Michelangelo Kacian from the University of by Department of the Informatica.",
            "It is so the he works in the group of Professor Donato Malerba and broader for Rihanna is positive.",
            "They they work, among other things, on two topics which are very strong interest to our group.",
            "Here in Louisiana, one is mining relational data, the other one is mining spatial data, geographic data and Michelangelo has been easy thing.",
            "Me and my colleagues here since the beginning of this year.",
            "So for two months.",
            "In total and we have been working together on developing some methods for spatial data mining, but today he will talk about a broader topic that we saw his research interest, namely learning from labeled and unlabeled data which she has exploited both in this context of mining relational data in the context of mining spatial data.",
            "Otherwise his Masters was on relational.",
            "Elearning at because since worked also on mining spatial data in both inductive and transductive settings.",
            "So I should not take too much of his time just to say that I'm very pleased that they spending two months in Louisiana and we enjoy working very much and I will then hand over to Michelangelo.",
            "OK, thank you.",
            "Thank you everybody for coming.",
            "Thank you for Sasha for introducing me but also for inviting me and working to work together.",
            "On this interesting research topics, what I'm going to present today is researcher we are doing.",
            "And actually I start with the introduction of the topic and the topic is labeling from learning from labeled and unlabeled data into particular.",
            "I'll present the topic of semi supervised learning and transactive learning.",
            "And I will present some properties of data and properties of these methods and also I'll present some work.",
            "So we have done in spatial data mining but also in learning from in text categorization learning from.",
            "Documents textual documents."
        ],
        [
            "OK. Let's start with the sum definition.",
            "I'll transact even semi supervised learning is different from the classical inductive learning while in inductive learning we use only label data to obtain when prediction predicting when learning a prediction model we only use labeled data for generating it classifiers.",
            "A classifier.",
            "In the case of the transductive and semi supervised.",
            "We do not use only label data, but we also use unlabeled data, this becauses, in some sense unlabeled data.",
            "If even if they are not labeled, they bring information with them."
        ],
        [
            "Here an example just to see what we are doing in a semi supervised learning or in transductive learning.",
            "If you movie.",
            "Prefer it.",
            "Suppose we have two or four examples.",
            "They are labeled examples and we try to learn a simple classifier, let's say support vector machine.",
            "We have that all the four examples are support vectors.",
            "So the hyperplane that is learned is this.",
            "But if you consider maybe also unlabeled examples, we can see that the distribution of the data is.",
            "Not what we supposed here, and maybe the correct hyperplane is not that type airplane, but is disappear plane.",
            "But we we see these only when we consider unlabeled data."
        ],
        [
            "So there are several motivations for transductive and semi supervised learning, or the first one is philosophical.",
            "Human brain can exploit unlabeled data."
        ],
        [
            "As you have seen here, have you, as you have done here, you have exploited unlabeled data to see to?",
            "See that this is the correct type airplane that's."
        ],
        [
            "Operates examples.",
            "There is also a pragmatic motivation.",
            "Unlabeled data is usually cheap to collect and."
        ],
        [
            "Going in deep in this respect, we can see say that first label data.",
            "Is scarce and expensive.",
            "It needs for expert knowledge.",
            "Obtaining label data is tedious and time consuming, but also is very expensive, not from the human effort point of view but also from other points of view.",
            "For example, consider computational biology.",
            "In that case, some it is necessary to obtain data it is necessary to run to perform experiments.",
            "And experiments in that field are very expensive.",
            "On the contrary, unclassified instances are abundant and cheap.",
            "For example, we can access primary structure of proteins in DNA, but also we can extract vectorized Maps from satellite images by means of simple variance of available tools."
        ],
        [
            "Feel free to interrupt me if you have questions OK?",
            "Anyway, there is a significant difference between the transductive and semi supervised learning.",
            "We have said that both consider unlabeled data when learning, but.",
            "While a transductive learning takes closed world assumption in sense that we know in advance what is the test set?",
            "What are the examples where we want to apply our classifier or predictive model in general this is not true in semi supervised learning where in some supervirus in earning we exploit unlabeled data but we still induce a classifier prediction prediction model.",
            "And so this means that semi supervised learning words works on open world assumption because the final goal is to learn a classifier to be used on all available potentially available data.",
            "This is not true.",
            "Repeat fortran."
        ],
        [
            "Active learning, so the difference is also in the experimental protocol.",
            "So suppose we have a number of labeled examples, a number of unlabeled examples and.",
            "Who and the whole set of examples possibly not available during learning?",
            "Also in transactive setting we have that the number of examples is equal to the number of unlabeled example plus the number of labeled examples, while in semi supervised setting we use labeled and unlabeled data to obtain a classifier.",
            "But we can apply it to remaining set of examples."
        ],
        [
            "This means what?",
            "What it means that the transactive classifier is a kind of classifier that works from particular to particular in sense that it is not necessary to build a general classifier so it can work directly on the data without trying to generalize and to find the general rule valid for all possible examples.",
            "The idea is that in transductive learning with respect to semi supervised learning, we do not try to solve the problem by Saul.",
            "Moving a more difficult intermediate problem, but we directly try to classify those examples we have at the beginning, and we know that we want to classify those examples.",
            "Anyway, it is also possible to learn a classifier for transactive learning.",
            "If you need a classifier, you can also run a transductive learning approach and then learn a classifier from the examples that that have been automatically learned."
        ],
        [
            "Um?",
            "OK um.",
            "By summarizing, we have a.",
            "We've seen that transductive algorithm.",
            "The solution of the application of a transductive algorithm depends on the test points that are given.",
            "Differently, On the contrary, inductive algorithm, the solution depends only on the labeled data we have, while semi supervised the solution depends on both labeled and able data."
        ],
        [
            "Transductive learning as a long story.",
            "Since 1974, Vapnik introduced this term.",
            "Anyway, it was not at that time, not novel concept.",
            "In fact, Art Leanne Rao in 1978 suggested.",
            "Approach that they did not call transductive learning, but that was very similar to what is done in transductive learning and it is this approach worked on combination are a combinatorial optimization problem.",
            "Indeed, the interesting transactive learning increased after 1994 when Vapnik wrote the book.",
            "Uh.",
            "Was statistical learning theory and there introduced.",
            "Explained very well with the with support vector machines, the term of transductive learning and then it was applied to a lot of in a lot of cases.",
            "Mostly in text."
        ],
        [
            "Trigger isation OK, we have described some general definitions, but there are also some aspects or properties that the transductive learning and also the supervised learning take into account during the learning phase and in particular this one of the properties, the smoothness assumption.",
            "We can start from the classicals motrice assumption that is.",
            "Used in classical inductive learning, the definition says that if two points X, 1X and X2 are closer then so should be corresponding output outputs.",
            "XY1 and Y2.",
            "OK, this is at the basis of most of the learning algorithms.",
            "We know that use a distance function and use kernel function and such as KNN algorithms.",
            "Vector machines and so on.",
            "What happens in, for example in KNN OK and then we have a set of examples and then we have a new example to be classified and then we compare these examples with examples in the neighborhood and we decide what is the class OK and in this respect this algorithm considers that.",
            "Isn't necessary."
        ],
        [
            "Option.",
            "Indeed, in semi supervised learning this assumption changed.",
            "And the definition is that is reported here.",
            "If two points X1 and X2 in a high density region and this is the difference are closed, then so should be the corresponding outputs away one and Y 2.",
            "So the difference is here and I density region.",
            "What does it mean?",
            "It means that if we have two examples that are separated by a low density region, they we are not sure that they belong to the same class even if they are close each other."
        ],
        [
            "I showed this with an example.",
            "Consider this case probably here.",
            "There is a negative example.",
            "OK here there is a positive example.",
            "And here there is example to be classified if we just take a look at this graphic, we say that the class for this example is minus OK.",
            "But if we have a look at the distribution over the data we see here a cluster here.",
            "A cluster.",
            "This example is separated by this example by region that is characterized by a low density.",
            "So probably this example does not belong to the class minus, but it belongs to the class plus becauses actually in the same cluster of the examples labeled as plus."
        ],
        [
            "A similar situation.",
            "We have a similar situation here.",
            "Here we have the minus.",
            "The example of class minus service example of class plus an example to be classified.",
            "Again, we have that the distance here is smaller than this distance between the example would be classified and the plus example.",
            "But if we look at the distribution of the data actually possibly not labeled data.",
            "We can see here that this example following the distribution is more close to this example than this example OK."
        ],
        [
            "So this is we introduced the concept of cluster here, because actually this is the so called cluster assumption.",
            "If points are in the same cluster, they are likely to be in the same class and this is at the basis of most of the algorithms that use clustering to predict new values like like predictive model trees, predictive clustering trees.",
            "Um?",
            "So here the assumption is the same and the conclusion is that the decision boundary should should lie in a low density region instead of an identity region."
        ],
        [
            "These assumptions are valid.",
            "Assumptions are all valid in semi supervised learning and they are still valid in the transductive learning as we can suppose, and this is a result recognized by shuttle in two."
        ],
        [
            "6.",
            "There is also a connection between transductive learning and local learning.",
            "Local learning, like in lazy learning.",
            "We have a test pointer and one should focus on the training points that are close to that point.",
            "Actually, if you if we if we consider.",
            "The training set and we consider.",
            "Just one example to be classified.",
            "The KNN algorithm works as a transductive algorithm.",
            "Algorithm will do OK. Feel free to interrupt me if so.",
            "Yeah yeah, if you have several examples.",
            "OK, training examples labeled examples and you have just one example to be classified.",
            "Then the effect of a simple lazy learning approach is the same as in the transductive setting."
        ],
        [
            "OK, um, this property of smoothness of that characterizes semi supervised learning approaches and also transductive approaches is correlated significantly correlated with the concept of autocorrelation for the auto correlation we can give here definition given a random variable Y representing the output of some observations.",
            "XI and the distance function defined on observation.",
            "Auto correlation is the correlation among output values.",
            "Physically related, not to the values to the response values, but to the proximity of the observations obtained on.",
            "On the.",
            "Description of based on the independent variables.",
            "Auto correlation is positive or negative.",
            "In the case of positive autocorrelation, we have that positive correlation is the tendency for similar values to cluster, while negative autocorrelation is the tendency for similar dissimilar values to cluster lights like in a chess board.",
            "Um?",
            "Indeed, the positive autocorrelation is more common than negative autocorrelation in real."
        ],
        [
            "All data here.",
            "There is an example of positive autocorrelation.",
            "This is a case of spatial data and here we measure the autocorrelation of the mortality rate in infant mortality rate in Nigeria.",
            "And here we compute to obtain the value of the auto correlation.",
            "The local Morenci that is static statistiques eustatic used for measuring the auto correlation.",
            "And here we can see that the values here are significantly connected each other the response values."
        ],
        [
            "Indeed, a.",
            "We have said that the positive outlook turns out a correlation is significantly conected to smoothness assumption.",
            "Indeed, positive operation entails the smoothness assumption and.",
            "But we can see some finger also in the case of semi supervised smoothness assumption.",
            "Because under certain constant conditions, positive autocorrelation entails this move.",
            "The semi supervised smoothness assumption.",
            "OK. What is the condition?",
            "The condition is that the distance function that is used.",
            "Never considers similar 2 examples that are closer that are separated, separated by a low density region.",
            "In this case, the positive operation entails also the semi supervised assumption.",
            "So it depends on the distance function we are defining."
        ],
        [
            "Autocorrelation, where is valid autocorrelation is valid in general in network data, but in particular in spatial data.",
            "And this is the case of spatial autocorrelation.",
            "But also in many other fields such aladji we're mining bioinformatics, Anson, such aladji for example when we have social relations between items or web mining where we have distance function between pages that is based on the content that permits to catch the content of the page in by informatix two proteins that are structured.",
            "Are similar, similarly structure and maybe have the same affect and so on.",
            "The important thing here is.",
            "Probably I pushed some.",
            "The important thing is that in this field these stands should reflect the properties of interest, otherwise we are not able to catch these mouthless that to represent the auto correlation but also to catch the smoothness assumption when learning."
        ],
        [
            "We say that the auto correlation is.",
            "An interesting properties, especially in the case of spay or spatial data.",
            "Special Auto correlation is the property of random values, so this is the definition that is used in this field.",
            "Is the property of random values taking value set piece of location at certain distance apart that are most similar than expected from randomly associated pairs.",
            "So the distance meter in the evaluation in fact, for example, we can see the temperature.",
            "And obviously the temperature here depends on a close support closer point then a point that is far away from that."
        ],
        [
            "The general case is that of network data where we have several nodes, so we have that edges are labeled with the distance and also in.",
            "Now our case.",
            "In the case of semi supervised or transductive learning we have that some of the nodes are labeled, others are not labeled here.",
            "Blue examples are labeled red.",
            "Examples are not labeled.",
            "Do not have."
        ],
        [
            "Label associated to them.",
            "OK, after this introduction long introduction of some properties of the data, some properties of the transductive learning algorithms and semi supervised learning algorithms we I will now show some approaches.",
            "We have proposed Indonesia that resource to the trans active learning setting.",
            "The first is HT.",
            "That is an algorithm that is used for archical classification of textual documents.",
            "The other is preco is for special regression with Co training and the last one is trans escheat.",
            "Ancestry is transductive learning that works on multi relational data, is a multi relational data mining system."
        ],
        [
            "Um, let's start from HSG tha."
        ],
        [
            "GT is a variant, let's say of the system web cluster and the problem solved by Sgt is formalized in these in this slide.",
            "Given a set of categories, A.",
            "They function are called function that permits to structure the categories in hierarchical structure.",
            "So categories are organized hierarchically.",
            "Training training set and the working set examples in the training set are labeled with one only one of the categories reported here, OK. Um, the works.",
            "The working set are in the working set.",
            "We have documents examples but they are not.",
            "We do not have the label associated with them.",
            "What we intend to find is a prediction function that, given an example for each example in the working set, asociates the correct class.",
            "In this case the class."
        ],
        [
            "Can be one of the classes in the area are key.",
            "Even internal nodes of the hierarchy and.",
            "We do not work in the multiobjective setting in the sense that.",
            "Example is associated only one class.",
            "So is a single label classification.",
            "The idea this starts from the system web cluster that we propose.",
            "Several years ago.",
            "The idea is that when a new document arrives, we have to decide in which category the document has to be passed down, and this decision is based on a classifier that returns for each couple of classes CC prime.",
            "The score, the score estimates the belief of associating an example that arrives in a class, let's say here to another class.",
            "Let's say this one.",
            "This is Cora.",
            "If the score returned by the classifier gram of CC prime of D is greater than a threshold, because there are thresholds for each edge, then the document example is passed down peculiarity of web classes that each internal node over the hierarchy, each document is representing a different way.",
            "The same document is represented on a different way because.",
            "A feature selection is applied at each internal node over there."
        ],
        [
            "So, um.",
            "Thresholds are determined automatically by minimizing the error."
        ],
        [
            "Overclassification the algorithm we embedded in web class and we adopted in web classes.",
            "Sgt Classifier, Spectrograph Transducer originally proposed by Jakim's in 2003 and now the problem for each classification.",
            "So we have a class and another class that is the.",
            "The child of the Class C. So C prime is child off, see.",
            "And each classification problem can be formalized in this way.",
            "Given an internal internal category C and its direct subcategory C prime.",
            "A set of the set of examples of training examples is David is divided in positive examples that are examples that fall here, and the negative examples that are examples that foliar but not here, and all the examples that fall in sibling categories of C prime.",
            "Kitty.",
            "We have we also have a set of unlabeled examples, possibly belonging to see and its descendants, and the goal of the use of the Sgt Classifier is to compute the score for each document that belongs both to the training set and to the working so."
        ],
        [
            "After before describing in detail the algorithm, we have to say just few words about document representation.",
            "In this case we have to say that we process documents in order to remove tags up induction marks number.",
            "In the short talk, and so we perform stemming and we sort features according to these measures, DF, DF, DF and in this way we compute the feature set to be associated to each internal node of the error, and documents are represented according to the classical TF IDF measure.",
            "And this similarity measure is the cosine correlation.",
            "We need this last part because."
        ],
        [
            "Sweet.",
            "Have to represent the network now.",
            "The problem is that we try to find the best cut, the best cut and.",
            "Such data.",
            "That some of the distances that crossed the cutter are maximised.",
            "In this way the two sets are divided at best."
        ],
        [
            "OK, we use two different.",
            "Actually they are taking from the original system Sgt.",
            "We use two different maximization procedures but differently from what Sgt Do we do not have art class assignments at the end.",
            "But we need the score.",
            "The score is obtained by working on predictor vector that is used during the maximization step.",
            "This way, for each documented I we have discord that permits to assign a document belonging to.",
            "See also in the sub category C prime."
        ],
        [
            "We also embedded in this system relevant example selection algorithm that permits to work with high dimensional data.",
            "And we introduced two techniques in order to sample data from training set and working set in order to reduce the size of the data set where we work on the 1st technique is based on the class on a clustering algorithm and it takes the centroid of the cluster or representative example.",
            "The other is based on class border identification in.",
            "Practice we try to identify support vectors and we use only support vectors because they are on the border of the class."
        ],
        [
            "We've done experiments on RC one and the mods for these for this system and here we have some interesting results.",
            "What is interesting is that this is typical of transductive learning.",
            "We have small training set and the huge working set of test data, and this is also.",
            "In this case, where our CV one is split according to the Lewis Split, and in this case we have a lot of very few training examples and a lot of working example labeled examples.",
            "So here we perform preform default cross validation and for three fold cross validation.",
            "What we did is to work not in the usual way but in the contrary way.",
            "I mean we used one folder for learning as a training set and the remaining two folds as working set."
        ],
        [
            "India Summer is also reported for these algoritma.",
            "This is the predictive accuracy for the six different datasets that the last three or obtained for MCV one the 1st three are obtained form from the modes data set and we can see here that relevant example selection is beneficial because we improve the accuracy over the.",
            "So the original algorithm."
        ],
        [
            "Implemented in web plus the second approach that uses transductive learning is a sprinkle sprinkle.",
            "The acronym of spatial regression with."
        ],
        [
            "Training and the problem solved here is formalizing this in this slide we have.",
            "Data set that is composed by training and working sample some.",
            "Which example is represented by means of an ID but also by means of the independent variables and the predictive variable the dependent variable, but also is represented by means of the coordinates.",
            "So what we need also is a special distance.",
            "The text value in.",
            "In R-squared and returns values in R. Um?"
        ],
        [
            "The goal actually is that of predicting the value of the unknown value on the of the class that the this is regression.",
            "So this is the.",
            "Response variable for each observation in the working."
        ],
        [
            "Sector.",
            "OK, in this approach we.",
            "Driver from the original data set two different views of the data of the same data set, and we work separately on both.",
            "This is a coherent with the Co training style proposed by Blue Mitchell in Ant."
        ],
        [
            "In 98 and here we somewhere summarize what we do.",
            "The idea is this.",
            "We have labeled examples and labeled examples.",
            "We extract the two alternative views of the same data set, and then we might prediction model.",
            "In this case the predictable predictive model we use is inductive learner.",
            "And it learns model trees proposed by a pitch and their office key 2007.",
            "And once we have classified unlabeled examples, we swap confident labels for.",
            "But only confidently bolts for the data set and we rerun the learning the the learning learner OK.",
            "So the first aspect are we had to face with was out were extract alternative view."
        ],
        [
            "As well, the views we extracted are two, one is.",
            "One is the original data set, the second is obtained by the original data set by some summarization.",
            "In particular, we try to catch on this data set.",
            "Are the smoothness assumption and we consider.",
            "The summarization according to the neighborhood of the values of the attributes.",
            "The distance we use is the Gaussian distance said that is was formalized reported here.",
            "Where distance here is the Euclidean distance and this is the Gaussian distance for all."
        ],
        [
            "Um?",
            "The two views actually yeah very dependent OK?",
            "Yeah OK, I I agree with your point.",
            "Or something?",
            "Yeah, but we tried to partition just partition the feature space, I mean just to say this features in one view and these other features in the other view, but results were not so good for this data set.",
            "Yes, yeah, by summarizing and we explained."
        ],
        [
            "Yeah, I know that in the original proposal of local training, the two views have to be independent each other, but in this case we are able to catch the smoothness assumption.",
            "This mood rest of the data so that one of you is low level features and the other view is some summarized.",
            "Yeah yeah, the second view all the features in the second view, our high level in the sense of yes yes yes yes.",
            "Complementary in Avaya.",
            "In a way of decreasing in the detail and increasing yes.",
            "This helps.",
            "This was for.",
            "For the."
        ],
        [
            "Determination of the two views, the."
        ],
        [
            "The other point I got back here.",
            "The other point is here to swap confident labels, but we have to define what are the confidence confident labels."
        ],
        [
            "Indeed, we use these simple algorithm A to say that the feature is the label is confident or not and the idea is that for each example, if we remove the classification of that example.",
            "In, if you remove the classification of that example, we have to check if the neighbor order.",
            "The predictive capabilities increase or decrease if they decrease.",
            "Probably the classification is not so reliable.",
            "So use this simple algorithm to obtain to see to see if the examples."
        ],
        [
            "We're reliable or not, and then we."
        ],
        [
            "I return here we come.",
            "The algorithm actually iterates here and tries to insert in the in the in the training set.",
            "Those examples that have been classified as reliable and they are used for next classifications like in self training and at the end.",
            "As just stopping criterion we define truce topic, do different stopping criteria.",
            "The first one is the trivial number of iterates, and if we exceed given number of iterates, the algorithm stops.",
            "The second stopping criteria is that.",
            "When there is no, we are not able to add new examples.",
            "New labels in the training set labeled examples in training set.",
            "The algorithm stops.",
            "Um?"
        ],
        [
            "And the algorithm stops the response variable.",
            "The response for each value is the average of the responses returned by the two classifiers.",
            "The last two classifiers."
        ],
        [
            "We used for experiments, several datasets, most of them have been provided by Sasha.",
            "And we run both 10 fold cross validation and five fold cross validation.",
            "Also in this case we used one folder as training set and the remaining folds as working set."
        ],
        [
            "Yeah, there are some results.",
            "What we can see here is that sprinkle in blue and violator.",
            "Always outperform the inductive counterparts.",
            "Error yes, the errors are massive."
        ],
        [
            "The other algorithm A is the transition."
        ],
        [
            "OK so I have.",
            "Question why is the previous one transductive why?",
            "Why are you I mean?"
        ],
        [
            "This one.",
            "Perspective and not time supervised, but there are models.",
            "Hopefully they generalize, yeah.",
            "Data which is not nice.",
            "Yeah, because actually the model we learn at the end.",
            "Are not if you have the classifications at the end.",
            "Those classifications you try to apply the last.",
            "Model so it is possible that the model do not return the same classification you have cause it is possible that classification, classification or prediction regression in this case is the prediction is given by a previous version of the trees.",
            "Have the models because I teach iteration, you learn a new model.",
            "What changes from one iteration to the other is the fact that you are the reliable examples in the training set and those reliable examples are not changed from that point.",
            "OK, OK I know.",
            "OK, OK, I'll explain again.",
            "In different words here, you run the learner, you obtain a model.",
            "OK, then you try to see if the the prediction are liable or not.",
            "If they are reliable examples are considered the training examples and you run again the algorithm.",
            "So it is possible that when you run again the algorithm.",
            "Use debt example as training examples, not as tested sample obviously, so it is possible that the prediction of the new model is different from the prediction of the older model.",
            "So this is this is the reason because you do not have a model at the end that works for all the examples in the same way.",
            "They actually did.",
            "Transductive and not semi supervised.",
            "I mean you are free to use the final model on any data in yes you can use the final model for any data but.",
            "You are not sure that the classification is that the algorithm says.",
            "So actually I left at the end at the end.",
            "No, it's at the end.",
            "You have.",
            "The result is the combination of a lot of classes of models.",
            "I mean, you have generated many models, but hopefully the last one, yeah, but you are not sure that last one works at the same way you predicted in the first iteration.",
            "Nothing."
        ],
        [
            "OK, the last algoritma translates.",
            "She is the acronym of Transactive Structural Classifier.",
            "It is based on the transductive learning framework.",
            "It exploits the expressive power or relational learning.",
            "Classification is probabilistic and what we do is to extend the system.",
            "The original system USBC that is multi relational classifier in the case.",
            "Of transductive learning"
        ],
        [
            "The problem is solved by this algorithm.",
            "A is reported here.",
            "Given a data set schema this time, which consists of a set of relational tables and a set of primary constraints as well as a set of foreign key constraints on the schema.",
            "As we have also a target relation T that is one of the H tables here of S and the interior is also the.",
            "The target disk Attack put that represents the response value.",
            "The class.",
            "We have the training set that is any stanza TS of this database schema of the database schema is where we have values for Y and we have the working set that is again an instance of the database schema S, But in this case we do not have values for Y.",
            "The goal is to find the prediction for the examples in the working set.",
            "It is important to say that in this case.",
            "The example is according to the relational framework example, is not a single tuple, but is represented by a single tap all over the target table, but also by means of the topics that are related according to foreign key constraints to the table.",
            "In the database."
        ],
        [
            "The idea is of, the algorithm is reported here.",
            "The mean.",
            "The top level description of the algorithm.",
            "We use an initial classifier then.",
            "We use an initial classifier to obtain a classification.",
            "Then in this iteration we change.",
            "We classify examples on the basis of the neighborhood of that example and finally we.",
            "We can also change the class for those examples that belong to the border of the class.",
            "So the iteration is repeated.",
            "So is repeated until the number of iterations exceeds the maximum number of iterations or when until the.",
            "Number of the examples for which the class has been changed is been changed.",
            "Not.",
            "Is actually similar to the set of examples for which have been the classes.",
            "This changed in the previous iteration, so there is no significant variation from one iteration in the other.",
            "Here the initial classifica."
        ],
        [
            "Vision is based on MSNBC that classifieds samples by means of a something like Bayesian classifier for relational data."
        ],
        [
            "But then we apply a relational version of the key and an algorithm in order to change the class of the examples that are not for which the class is not reliable.",
            "Um?",
            "We also modify the class for those examples that are on the border of the class and the border is measured according to the entropy.",
            "The entropy associated to the probability of the class of an example."
        ],
        [
            "We already talked about the stopping criteria and."
        ],
        [
            "Here we report some results.",
            "The 1st results are obtained on Northwest England Census data differently from the previous representation.",
            "In this case we use a relational representation of this data set and.",
            "In particular, we predict the German indexer, that is a deprivation factor of associated to award.",
            "In this case, the units of analysis are the words.",
            "And we also used relations spatial relations obtained by the 9 intersection model in order to find, for example, the overlapping relation between award and.",
            "I don't know what are net or real net sorry way.",
            "And so on.",
            "Would you please send it example in a different each layer in a different relational table and words in other?"
        ],
        [
            "Tables.",
            "Here we report some results.",
            "Are we report results of the 10 fold cross validation but also of the 20 fold cross validation.",
            "Also in this case we use one fold as training set the other fold as the other faults as working set and in this case we can see that we are able to reduce the error with respect to the inductive counterparts.",
            "Also in this case working with.",
            "Unlabeled data in addition to label data is beneficial."
        ],
        [
            "The second data set is Munich census data.",
            "With this data set is obtained is represents the.",
            "Mount Re rent per square meter for flats in Munich, in Germany and we represent layers here such as.",
            "Transport stops.",
            "Railways and bus stops.",
            "And we use the discretization for the target attribute, because this is a classification a classification task."
        ],
        [
            "Here are the results are also.",
            "In this case.",
            "We notice that when we work in the transact resecting we reduce the error of the inductive original algorithm.",
            "So the iterations are actually beneficial."
        ],
        [
            "OK.",
            "Thank you for your attention.",
            "I would mention the normal bandana Lisa picture that actually worked with me with you on this project.",
            "And I will thank all the audience.",
            "Attending here thank you.",
            "Thank you very much Michelangelo.",
            "We have time for questions so if there are any questions please.",
            "Yeah, the second algorithm.",
            "Yeah, a method for checking how reliable a prediction is, but you you you went through that a little bit too quickly.",
            "OK, interested in that, yeah."
        ],
        [
            "OK, in a new version of the algorithm we modified this.",
            "Anyway, we worked actually on the standard deviation."
        ],
        [
            "And the last version that is still in this is still work in progress.",
            "We have more views and we consider reliable those examples for which the standard deviation of the prediction is not so high.",
            "That is the new version in this."
        ],
        [
            "Version of the algorithm we compute.",
            "Actually the error given an example, OK.",
            "If given example for all the examples P in the neighbor of V, we compute the error and we compute here by.",
            "With the KNN algorithm, by introducing EM by removing a. OK, if the classification.",
            "So if the prediction of all the examples in the neighbor of East.",
            "In any age and some if the the predictive capabilities of the algorithm introducing removing E increase increases, then it means that the algorithm that yeah, it's not.",
            "It's not good, thank you.",
            "How much do you rely on the smoothness versus enforcement?",
            "Because I've noticed this algorithm, you lose Gaussian distances, yeah, so in some sense you're smoothing everything else to enforce.",
            "Yes, that is we do what we do.",
            "Actually, in other experiments we considered in addition to."
        ],
        [
            "The Gaussian measure only the Euclidean distance, and in that case the algorithm actually was more sensitive to.",
            "Also to.",
            "Appliers.",
            "What about using something in some graph distance like we did in the 1st?",
            "Yeah, it can be.",
            "All it's the same music here, graphic graphics tension.",
            "I mean you can here look at examples as nodes in the graph.",
            "Question would be more, what is the future to whether the local structure is by using some graph distance as opposed to this meeting?",
            "Right, because in Euclidean distance you're still installed and above.",
            "Global distance yeah, so the difference would be.",
            "My question would be, did you check how?",
            "How smooth the distance is a priority for smoothing it.",
            "OK, yeah, there's a work that we tried to do distance here already, right?",
            "I mean, there's some intrinsic distance.",
            "Anyway, um.",
            "We did not check on the data set, what happens, but.",
            "It will be interesting to check yes, I agree.",
            "I have a question you already started talking along those lines instead of just the two views in con training, can you use multiple views and is that beneficial?",
            "Yeah, there is a work by.",
            "Erna Viktora, I don't know if you know from Canada, and in that work they tried to extract several views from relational data and then apply some algorithm.",
            "I don't know some classical algorithm.",
            "What we were saying, we are trying now actually to do is to consider.",
            "The different views they have, as in the independent views and to apply these not Co training.",
            "I mean there are multiple multiple.",
            "Views, not just two views, but did you use that views to obtain the obtain different classifications and then to combine them for?",
            "Saying that, if the examples are reliably classified or not.",
            "Are there any other questions?",
            "I was just wondering on a high level.",
            "Semi supervised and transductive.",
            "So why?",
            "Why would you not want to have more general things so?",
            "Or in principle it is an easier task.",
            "Maybe what I understood you don't care about other examples you care just about those at hand.",
            "Yeah, and you think you will never need to classify any other examples, so you can kind of tune to the examples that yes, right?",
            "Yes.",
            "And then hopefully you because you know you don't care about others.",
            "You can do better job on this example.",
            "Yeah, this is important in principle.",
            "Yes, yes.",
            "Then you have shown us three approaches or three you know to different kind of data and so on.",
            "And you say OK, they are transacted.",
            "So if you would.",
            "Use Semi supervised approach, whatever it means now and compare the results.",
            "Yeah, can you show that because of used reductive approach?",
            "Because you know that will be interesting.",
            "Yeah, now you have better results in the end that will be interesting to explore.",
            "I've never tried, I mean.",
            "Anybody else tried that?",
            "Yeah, but the problem is that.",
            "When you compare the two approaches, they have to be compatible, I mean.",
            "You just completed.",
            "Yeah, but the approaches have to be.",
            "At the same level I mean the comparison have to be fair to say at the end.",
            "That reason is why you use a semi supervised instead of some transductor or vice versa.",
            "And what if it depends on the single algorithm you are using?",
            "Yeah, and it would be interesting, but I think it is not easy to prove that even empirically."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I had the great pleasure to introduce the speaker off today, Michelangelo Kacian from the University of by Department of the Informatica.",
                    "label": 0
                },
                {
                    "sent": "It is so the he works in the group of Professor Donato Malerba and broader for Rihanna is positive.",
                    "label": 0
                },
                {
                    "sent": "They they work, among other things, on two topics which are very strong interest to our group.",
                    "label": 0
                },
                {
                    "sent": "Here in Louisiana, one is mining relational data, the other one is mining spatial data, geographic data and Michelangelo has been easy thing.",
                    "label": 0
                },
                {
                    "sent": "Me and my colleagues here since the beginning of this year.",
                    "label": 0
                },
                {
                    "sent": "So for two months.",
                    "label": 0
                },
                {
                    "sent": "In total and we have been working together on developing some methods for spatial data mining, but today he will talk about a broader topic that we saw his research interest, namely learning from labeled and unlabeled data which she has exploited both in this context of mining relational data in the context of mining spatial data.",
                    "label": 0
                },
                {
                    "sent": "Otherwise his Masters was on relational.",
                    "label": 0
                },
                {
                    "sent": "Elearning at because since worked also on mining spatial data in both inductive and transductive settings.",
                    "label": 0
                },
                {
                    "sent": "So I should not take too much of his time just to say that I'm very pleased that they spending two months in Louisiana and we enjoy working very much and I will then hand over to Michelangelo.",
                    "label": 0
                },
                {
                    "sent": "OK, thank you.",
                    "label": 0
                },
                {
                    "sent": "Thank you everybody for coming.",
                    "label": 0
                },
                {
                    "sent": "Thank you for Sasha for introducing me but also for inviting me and working to work together.",
                    "label": 0
                },
                {
                    "sent": "On this interesting research topics, what I'm going to present today is researcher we are doing.",
                    "label": 0
                },
                {
                    "sent": "And actually I start with the introduction of the topic and the topic is labeling from learning from labeled and unlabeled data into particular.",
                    "label": 1
                },
                {
                    "sent": "I'll present the topic of semi supervised learning and transactive learning.",
                    "label": 0
                },
                {
                    "sent": "And I will present some properties of data and properties of these methods and also I'll present some work.",
                    "label": 0
                },
                {
                    "sent": "So we have done in spatial data mining but also in learning from in text categorization learning from.",
                    "label": 0
                },
                {
                    "sent": "Documents textual documents.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK. Let's start with the sum definition.",
                    "label": 0
                },
                {
                    "sent": "I'll transact even semi supervised learning is different from the classical inductive learning while in inductive learning we use only label data to obtain when prediction predicting when learning a prediction model we only use labeled data for generating it classifiers.",
                    "label": 1
                },
                {
                    "sent": "A classifier.",
                    "label": 0
                },
                {
                    "sent": "In the case of the transductive and semi supervised.",
                    "label": 0
                },
                {
                    "sent": "We do not use only label data, but we also use unlabeled data, this becauses, in some sense unlabeled data.",
                    "label": 0
                },
                {
                    "sent": "If even if they are not labeled, they bring information with them.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here an example just to see what we are doing in a semi supervised learning or in transductive learning.",
                    "label": 0
                },
                {
                    "sent": "If you movie.",
                    "label": 0
                },
                {
                    "sent": "Prefer it.",
                    "label": 0
                },
                {
                    "sent": "Suppose we have two or four examples.",
                    "label": 0
                },
                {
                    "sent": "They are labeled examples and we try to learn a simple classifier, let's say support vector machine.",
                    "label": 0
                },
                {
                    "sent": "We have that all the four examples are support vectors.",
                    "label": 0
                },
                {
                    "sent": "So the hyperplane that is learned is this.",
                    "label": 0
                },
                {
                    "sent": "But if you consider maybe also unlabeled examples, we can see that the distribution of the data is.",
                    "label": 0
                },
                {
                    "sent": "Not what we supposed here, and maybe the correct hyperplane is not that type airplane, but is disappear plane.",
                    "label": 0
                },
                {
                    "sent": "But we we see these only when we consider unlabeled data.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So there are several motivations for transductive and semi supervised learning, or the first one is philosophical.",
                    "label": 0
                },
                {
                    "sent": "Human brain can exploit unlabeled data.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As you have seen here, have you, as you have done here, you have exploited unlabeled data to see to?",
                    "label": 0
                },
                {
                    "sent": "See that this is the correct type airplane that's.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Operates examples.",
                    "label": 0
                },
                {
                    "sent": "There is also a pragmatic motivation.",
                    "label": 0
                },
                {
                    "sent": "Unlabeled data is usually cheap to collect and.",
                    "label": 1
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Going in deep in this respect, we can see say that first label data.",
                    "label": 0
                },
                {
                    "sent": "Is scarce and expensive.",
                    "label": 0
                },
                {
                    "sent": "It needs for expert knowledge.",
                    "label": 1
                },
                {
                    "sent": "Obtaining label data is tedious and time consuming, but also is very expensive, not from the human effort point of view but also from other points of view.",
                    "label": 1
                },
                {
                    "sent": "For example, consider computational biology.",
                    "label": 0
                },
                {
                    "sent": "In that case, some it is necessary to obtain data it is necessary to run to perform experiments.",
                    "label": 0
                },
                {
                    "sent": "And experiments in that field are very expensive.",
                    "label": 0
                },
                {
                    "sent": "On the contrary, unclassified instances are abundant and cheap.",
                    "label": 1
                },
                {
                    "sent": "For example, we can access primary structure of proteins in DNA, but also we can extract vectorized Maps from satellite images by means of simple variance of available tools.",
                    "label": 1
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Feel free to interrupt me if you have questions OK?",
                    "label": 0
                },
                {
                    "sent": "Anyway, there is a significant difference between the transductive and semi supervised learning.",
                    "label": 0
                },
                {
                    "sent": "We have said that both consider unlabeled data when learning, but.",
                    "label": 1
                },
                {
                    "sent": "While a transductive learning takes closed world assumption in sense that we know in advance what is the test set?",
                    "label": 1
                },
                {
                    "sent": "What are the examples where we want to apply our classifier or predictive model in general this is not true in semi supervised learning where in some supervirus in earning we exploit unlabeled data but we still induce a classifier prediction prediction model.",
                    "label": 0
                },
                {
                    "sent": "And so this means that semi supervised learning words works on open world assumption because the final goal is to learn a classifier to be used on all available potentially available data.",
                    "label": 0
                },
                {
                    "sent": "This is not true.",
                    "label": 0
                },
                {
                    "sent": "Repeat fortran.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Active learning, so the difference is also in the experimental protocol.",
                    "label": 1
                },
                {
                    "sent": "So suppose we have a number of labeled examples, a number of unlabeled examples and.",
                    "label": 1
                },
                {
                    "sent": "Who and the whole set of examples possibly not available during learning?",
                    "label": 0
                },
                {
                    "sent": "Also in transactive setting we have that the number of examples is equal to the number of unlabeled example plus the number of labeled examples, while in semi supervised setting we use labeled and unlabeled data to obtain a classifier.",
                    "label": 0
                },
                {
                    "sent": "But we can apply it to remaining set of examples.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This means what?",
                    "label": 0
                },
                {
                    "sent": "What it means that the transactive classifier is a kind of classifier that works from particular to particular in sense that it is not necessary to build a general classifier so it can work directly on the data without trying to generalize and to find the general rule valid for all possible examples.",
                    "label": 1
                },
                {
                    "sent": "The idea is that in transductive learning with respect to semi supervised learning, we do not try to solve the problem by Saul.",
                    "label": 1
                },
                {
                    "sent": "Moving a more difficult intermediate problem, but we directly try to classify those examples we have at the beginning, and we know that we want to classify those examples.",
                    "label": 0
                },
                {
                    "sent": "Anyway, it is also possible to learn a classifier for transactive learning.",
                    "label": 0
                },
                {
                    "sent": "If you need a classifier, you can also run a transductive learning approach and then learn a classifier from the examples that that have been automatically learned.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "OK um.",
                    "label": 0
                },
                {
                    "sent": "By summarizing, we have a.",
                    "label": 0
                },
                {
                    "sent": "We've seen that transductive algorithm.",
                    "label": 0
                },
                {
                    "sent": "The solution of the application of a transductive algorithm depends on the test points that are given.",
                    "label": 1
                },
                {
                    "sent": "Differently, On the contrary, inductive algorithm, the solution depends only on the labeled data we have, while semi supervised the solution depends on both labeled and able data.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Transductive learning as a long story.",
                    "label": 1
                },
                {
                    "sent": "Since 1974, Vapnik introduced this term.",
                    "label": 0
                },
                {
                    "sent": "Anyway, it was not at that time, not novel concept.",
                    "label": 0
                },
                {
                    "sent": "In fact, Art Leanne Rao in 1978 suggested.",
                    "label": 0
                },
                {
                    "sent": "Approach that they did not call transductive learning, but that was very similar to what is done in transductive learning and it is this approach worked on combination are a combinatorial optimization problem.",
                    "label": 1
                },
                {
                    "sent": "Indeed, the interesting transactive learning increased after 1994 when Vapnik wrote the book.",
                    "label": 0
                },
                {
                    "sent": "Uh.",
                    "label": 0
                },
                {
                    "sent": "Was statistical learning theory and there introduced.",
                    "label": 0
                },
                {
                    "sent": "Explained very well with the with support vector machines, the term of transductive learning and then it was applied to a lot of in a lot of cases.",
                    "label": 0
                },
                {
                    "sent": "Mostly in text.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Trigger isation OK, we have described some general definitions, but there are also some aspects or properties that the transductive learning and also the supervised learning take into account during the learning phase and in particular this one of the properties, the smoothness assumption.",
                    "label": 0
                },
                {
                    "sent": "We can start from the classicals motrice assumption that is.",
                    "label": 0
                },
                {
                    "sent": "Used in classical inductive learning, the definition says that if two points X, 1X and X2 are closer then so should be corresponding output outputs.",
                    "label": 1
                },
                {
                    "sent": "XY1 and Y2.",
                    "label": 0
                },
                {
                    "sent": "OK, this is at the basis of most of the learning algorithms.",
                    "label": 0
                },
                {
                    "sent": "We know that use a distance function and use kernel function and such as KNN algorithms.",
                    "label": 0
                },
                {
                    "sent": "Vector machines and so on.",
                    "label": 0
                },
                {
                    "sent": "What happens in, for example in KNN OK and then we have a set of examples and then we have a new example to be classified and then we compare these examples with examples in the neighborhood and we decide what is the class OK and in this respect this algorithm considers that.",
                    "label": 0
                },
                {
                    "sent": "Isn't necessary.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Option.",
                    "label": 0
                },
                {
                    "sent": "Indeed, in semi supervised learning this assumption changed.",
                    "label": 0
                },
                {
                    "sent": "And the definition is that is reported here.",
                    "label": 0
                },
                {
                    "sent": "If two points X1 and X2 in a high density region and this is the difference are closed, then so should be the corresponding outputs away one and Y 2.",
                    "label": 1
                },
                {
                    "sent": "So the difference is here and I density region.",
                    "label": 0
                },
                {
                    "sent": "What does it mean?",
                    "label": 0
                },
                {
                    "sent": "It means that if we have two examples that are separated by a low density region, they we are not sure that they belong to the same class even if they are close each other.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I showed this with an example.",
                    "label": 0
                },
                {
                    "sent": "Consider this case probably here.",
                    "label": 0
                },
                {
                    "sent": "There is a negative example.",
                    "label": 0
                },
                {
                    "sent": "OK here there is a positive example.",
                    "label": 0
                },
                {
                    "sent": "And here there is example to be classified if we just take a look at this graphic, we say that the class for this example is minus OK.",
                    "label": 0
                },
                {
                    "sent": "But if we have a look at the distribution over the data we see here a cluster here.",
                    "label": 0
                },
                {
                    "sent": "A cluster.",
                    "label": 0
                },
                {
                    "sent": "This example is separated by this example by region that is characterized by a low density.",
                    "label": 0
                },
                {
                    "sent": "So probably this example does not belong to the class minus, but it belongs to the class plus becauses actually in the same cluster of the examples labeled as plus.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A similar situation.",
                    "label": 0
                },
                {
                    "sent": "We have a similar situation here.",
                    "label": 0
                },
                {
                    "sent": "Here we have the minus.",
                    "label": 0
                },
                {
                    "sent": "The example of class minus service example of class plus an example to be classified.",
                    "label": 0
                },
                {
                    "sent": "Again, we have that the distance here is smaller than this distance between the example would be classified and the plus example.",
                    "label": 0
                },
                {
                    "sent": "But if we look at the distribution of the data actually possibly not labeled data.",
                    "label": 0
                },
                {
                    "sent": "We can see here that this example following the distribution is more close to this example than this example OK.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is we introduced the concept of cluster here, because actually this is the so called cluster assumption.",
                    "label": 0
                },
                {
                    "sent": "If points are in the same cluster, they are likely to be in the same class and this is at the basis of most of the algorithms that use clustering to predict new values like like predictive model trees, predictive clustering trees.",
                    "label": 1
                },
                {
                    "sent": "Um?",
                    "label": 1
                },
                {
                    "sent": "So here the assumption is the same and the conclusion is that the decision boundary should should lie in a low density region instead of an identity region.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "These assumptions are valid.",
                    "label": 0
                },
                {
                    "sent": "Assumptions are all valid in semi supervised learning and they are still valid in the transductive learning as we can suppose, and this is a result recognized by shuttle in two.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "6.",
                    "label": 0
                },
                {
                    "sent": "There is also a connection between transductive learning and local learning.",
                    "label": 1
                },
                {
                    "sent": "Local learning, like in lazy learning.",
                    "label": 0
                },
                {
                    "sent": "We have a test pointer and one should focus on the training points that are close to that point.",
                    "label": 1
                },
                {
                    "sent": "Actually, if you if we if we consider.",
                    "label": 0
                },
                {
                    "sent": "The training set and we consider.",
                    "label": 0
                },
                {
                    "sent": "Just one example to be classified.",
                    "label": 0
                },
                {
                    "sent": "The KNN algorithm works as a transductive algorithm.",
                    "label": 0
                },
                {
                    "sent": "Algorithm will do OK. Feel free to interrupt me if so.",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah, if you have several examples.",
                    "label": 0
                },
                {
                    "sent": "OK, training examples labeled examples and you have just one example to be classified.",
                    "label": 0
                },
                {
                    "sent": "Then the effect of a simple lazy learning approach is the same as in the transductive setting.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, um, this property of smoothness of that characterizes semi supervised learning approaches and also transductive approaches is correlated significantly correlated with the concept of autocorrelation for the auto correlation we can give here definition given a random variable Y representing the output of some observations.",
                    "label": 1
                },
                {
                    "sent": "XI and the distance function defined on observation.",
                    "label": 1
                },
                {
                    "sent": "Auto correlation is the correlation among output values.",
                    "label": 0
                },
                {
                    "sent": "Physically related, not to the values to the response values, but to the proximity of the observations obtained on.",
                    "label": 0
                },
                {
                    "sent": "On the.",
                    "label": 0
                },
                {
                    "sent": "Description of based on the independent variables.",
                    "label": 0
                },
                {
                    "sent": "Auto correlation is positive or negative.",
                    "label": 0
                },
                {
                    "sent": "In the case of positive autocorrelation, we have that positive correlation is the tendency for similar values to cluster, while negative autocorrelation is the tendency for similar dissimilar values to cluster lights like in a chess board.",
                    "label": 1
                },
                {
                    "sent": "Um?",
                    "label": 1
                },
                {
                    "sent": "Indeed, the positive autocorrelation is more common than negative autocorrelation in real.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "All data here.",
                    "label": 0
                },
                {
                    "sent": "There is an example of positive autocorrelation.",
                    "label": 0
                },
                {
                    "sent": "This is a case of spatial data and here we measure the autocorrelation of the mortality rate in infant mortality rate in Nigeria.",
                    "label": 1
                },
                {
                    "sent": "And here we compute to obtain the value of the auto correlation.",
                    "label": 0
                },
                {
                    "sent": "The local Morenci that is static statistiques eustatic used for measuring the auto correlation.",
                    "label": 0
                },
                {
                    "sent": "And here we can see that the values here are significantly connected each other the response values.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Indeed, a.",
                    "label": 0
                },
                {
                    "sent": "We have said that the positive outlook turns out a correlation is significantly conected to smoothness assumption.",
                    "label": 0
                },
                {
                    "sent": "Indeed, positive operation entails the smoothness assumption and.",
                    "label": 1
                },
                {
                    "sent": "But we can see some finger also in the case of semi supervised smoothness assumption.",
                    "label": 1
                },
                {
                    "sent": "Because under certain constant conditions, positive autocorrelation entails this move.",
                    "label": 1
                },
                {
                    "sent": "The semi supervised smoothness assumption.",
                    "label": 1
                },
                {
                    "sent": "OK. What is the condition?",
                    "label": 0
                },
                {
                    "sent": "The condition is that the distance function that is used.",
                    "label": 0
                },
                {
                    "sent": "Never considers similar 2 examples that are closer that are separated, separated by a low density region.",
                    "label": 0
                },
                {
                    "sent": "In this case, the positive operation entails also the semi supervised assumption.",
                    "label": 0
                },
                {
                    "sent": "So it depends on the distance function we are defining.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Autocorrelation, where is valid autocorrelation is valid in general in network data, but in particular in spatial data.",
                    "label": 1
                },
                {
                    "sent": "And this is the case of spatial autocorrelation.",
                    "label": 0
                },
                {
                    "sent": "But also in many other fields such aladji we're mining bioinformatics, Anson, such aladji for example when we have social relations between items or web mining where we have distance function between pages that is based on the content that permits to catch the content of the page in by informatix two proteins that are structured.",
                    "label": 1
                },
                {
                    "sent": "Are similar, similarly structure and maybe have the same affect and so on.",
                    "label": 0
                },
                {
                    "sent": "The important thing here is.",
                    "label": 0
                },
                {
                    "sent": "Probably I pushed some.",
                    "label": 1
                },
                {
                    "sent": "The important thing is that in this field these stands should reflect the properties of interest, otherwise we are not able to catch these mouthless that to represent the auto correlation but also to catch the smoothness assumption when learning.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We say that the auto correlation is.",
                    "label": 0
                },
                {
                    "sent": "An interesting properties, especially in the case of spay or spatial data.",
                    "label": 0
                },
                {
                    "sent": "Special Auto correlation is the property of random values, so this is the definition that is used in this field.",
                    "label": 0
                },
                {
                    "sent": "Is the property of random values taking value set piece of location at certain distance apart that are most similar than expected from randomly associated pairs.",
                    "label": 1
                },
                {
                    "sent": "So the distance meter in the evaluation in fact, for example, we can see the temperature.",
                    "label": 0
                },
                {
                    "sent": "And obviously the temperature here depends on a close support closer point then a point that is far away from that.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The general case is that of network data where we have several nodes, so we have that edges are labeled with the distance and also in.",
                    "label": 0
                },
                {
                    "sent": "Now our case.",
                    "label": 0
                },
                {
                    "sent": "In the case of semi supervised or transductive learning we have that some of the nodes are labeled, others are not labeled here.",
                    "label": 0
                },
                {
                    "sent": "Blue examples are labeled red.",
                    "label": 0
                },
                {
                    "sent": "Examples are not labeled.",
                    "label": 0
                },
                {
                    "sent": "Do not have.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Label associated to them.",
                    "label": 0
                },
                {
                    "sent": "OK, after this introduction long introduction of some properties of the data, some properties of the transductive learning algorithms and semi supervised learning algorithms we I will now show some approaches.",
                    "label": 0
                },
                {
                    "sent": "We have proposed Indonesia that resource to the trans active learning setting.",
                    "label": 0
                },
                {
                    "sent": "The first is HT.",
                    "label": 0
                },
                {
                    "sent": "That is an algorithm that is used for archical classification of textual documents.",
                    "label": 1
                },
                {
                    "sent": "The other is preco is for special regression with Co training and the last one is trans escheat.",
                    "label": 1
                },
                {
                    "sent": "Ancestry is transductive learning that works on multi relational data, is a multi relational data mining system.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um, let's start from HSG tha.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "GT is a variant, let's say of the system web cluster and the problem solved by Sgt is formalized in these in this slide.",
                    "label": 0
                },
                {
                    "sent": "Given a set of categories, A.",
                    "label": 1
                },
                {
                    "sent": "They function are called function that permits to structure the categories in hierarchical structure.",
                    "label": 0
                },
                {
                    "sent": "So categories are organized hierarchically.",
                    "label": 0
                },
                {
                    "sent": "Training training set and the working set examples in the training set are labeled with one only one of the categories reported here, OK. Um, the works.",
                    "label": 1
                },
                {
                    "sent": "The working set are in the working set.",
                    "label": 0
                },
                {
                    "sent": "We have documents examples but they are not.",
                    "label": 0
                },
                {
                    "sent": "We do not have the label associated with them.",
                    "label": 1
                },
                {
                    "sent": "What we intend to find is a prediction function that, given an example for each example in the working set, asociates the correct class.",
                    "label": 0
                },
                {
                    "sent": "In this case the class.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Can be one of the classes in the area are key.",
                    "label": 1
                },
                {
                    "sent": "Even internal nodes of the hierarchy and.",
                    "label": 1
                },
                {
                    "sent": "We do not work in the multiobjective setting in the sense that.",
                    "label": 0
                },
                {
                    "sent": "Example is associated only one class.",
                    "label": 0
                },
                {
                    "sent": "So is a single label classification.",
                    "label": 0
                },
                {
                    "sent": "The idea this starts from the system web cluster that we propose.",
                    "label": 0
                },
                {
                    "sent": "Several years ago.",
                    "label": 0
                },
                {
                    "sent": "The idea is that when a new document arrives, we have to decide in which category the document has to be passed down, and this decision is based on a classifier that returns for each couple of classes CC prime.",
                    "label": 1
                },
                {
                    "sent": "The score, the score estimates the belief of associating an example that arrives in a class, let's say here to another class.",
                    "label": 0
                },
                {
                    "sent": "Let's say this one.",
                    "label": 0
                },
                {
                    "sent": "This is Cora.",
                    "label": 1
                },
                {
                    "sent": "If the score returned by the classifier gram of CC prime of D is greater than a threshold, because there are thresholds for each edge, then the document example is passed down peculiarity of web classes that each internal node over the hierarchy, each document is representing a different way.",
                    "label": 0
                },
                {
                    "sent": "The same document is represented on a different way because.",
                    "label": 1
                },
                {
                    "sent": "A feature selection is applied at each internal node over there.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So, um.",
                    "label": 0
                },
                {
                    "sent": "Thresholds are determined automatically by minimizing the error.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Overclassification the algorithm we embedded in web class and we adopted in web classes.",
                    "label": 0
                },
                {
                    "sent": "Sgt Classifier, Spectrograph Transducer originally proposed by Jakim's in 2003 and now the problem for each classification.",
                    "label": 0
                },
                {
                    "sent": "So we have a class and another class that is the.",
                    "label": 0
                },
                {
                    "sent": "The child of the Class C. So C prime is child off, see.",
                    "label": 0
                },
                {
                    "sent": "And each classification problem can be formalized in this way.",
                    "label": 0
                },
                {
                    "sent": "Given an internal internal category C and its direct subcategory C prime.",
                    "label": 1
                },
                {
                    "sent": "A set of the set of examples of training examples is David is divided in positive examples that are examples that fall here, and the negative examples that are examples that foliar but not here, and all the examples that fall in sibling categories of C prime.",
                    "label": 0
                },
                {
                    "sent": "Kitty.",
                    "label": 0
                },
                {
                    "sent": "We have we also have a set of unlabeled examples, possibly belonging to see and its descendants, and the goal of the use of the Sgt Classifier is to compute the score for each document that belongs both to the training set and to the working so.",
                    "label": 1
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "After before describing in detail the algorithm, we have to say just few words about document representation.",
                    "label": 0
                },
                {
                    "sent": "In this case we have to say that we process documents in order to remove tags up induction marks number.",
                    "label": 0
                },
                {
                    "sent": "In the short talk, and so we perform stemming and we sort features according to these measures, DF, DF, DF and in this way we compute the feature set to be associated to each internal node of the error, and documents are represented according to the classical TF IDF measure.",
                    "label": 1
                },
                {
                    "sent": "And this similarity measure is the cosine correlation.",
                    "label": 0
                },
                {
                    "sent": "We need this last part because.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sweet.",
                    "label": 0
                },
                {
                    "sent": "Have to represent the network now.",
                    "label": 0
                },
                {
                    "sent": "The problem is that we try to find the best cut, the best cut and.",
                    "label": 0
                },
                {
                    "sent": "Such data.",
                    "label": 0
                },
                {
                    "sent": "That some of the distances that crossed the cutter are maximised.",
                    "label": 0
                },
                {
                    "sent": "In this way the two sets are divided at best.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, we use two different.",
                    "label": 0
                },
                {
                    "sent": "Actually they are taking from the original system Sgt.",
                    "label": 0
                },
                {
                    "sent": "We use two different maximization procedures but differently from what Sgt Do we do not have art class assignments at the end.",
                    "label": 0
                },
                {
                    "sent": "But we need the score.",
                    "label": 0
                },
                {
                    "sent": "The score is obtained by working on predictor vector that is used during the maximization step.",
                    "label": 1
                },
                {
                    "sent": "This way, for each documented I we have discord that permits to assign a document belonging to.",
                    "label": 0
                },
                {
                    "sent": "See also in the sub category C prime.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We also embedded in this system relevant example selection algorithm that permits to work with high dimensional data.",
                    "label": 1
                },
                {
                    "sent": "And we introduced two techniques in order to sample data from training set and working set in order to reduce the size of the data set where we work on the 1st technique is based on the class on a clustering algorithm and it takes the centroid of the cluster or representative example.",
                    "label": 1
                },
                {
                    "sent": "The other is based on class border identification in.",
                    "label": 0
                },
                {
                    "sent": "Practice we try to identify support vectors and we use only support vectors because they are on the border of the class.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We've done experiments on RC one and the mods for these for this system and here we have some interesting results.",
                    "label": 0
                },
                {
                    "sent": "What is interesting is that this is typical of transductive learning.",
                    "label": 0
                },
                {
                    "sent": "We have small training set and the huge working set of test data, and this is also.",
                    "label": 0
                },
                {
                    "sent": "In this case, where our CV one is split according to the Lewis Split, and in this case we have a lot of very few training examples and a lot of working example labeled examples.",
                    "label": 0
                },
                {
                    "sent": "So here we perform preform default cross validation and for three fold cross validation.",
                    "label": 0
                },
                {
                    "sent": "What we did is to work not in the usual way but in the contrary way.",
                    "label": 0
                },
                {
                    "sent": "I mean we used one folder for learning as a training set and the remaining two folds as working set.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "India Summer is also reported for these algoritma.",
                    "label": 0
                },
                {
                    "sent": "This is the predictive accuracy for the six different datasets that the last three or obtained for MCV one the 1st three are obtained form from the modes data set and we can see here that relevant example selection is beneficial because we improve the accuracy over the.",
                    "label": 0
                },
                {
                    "sent": "So the original algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Implemented in web plus the second approach that uses transductive learning is a sprinkle sprinkle.",
                    "label": 0
                },
                {
                    "sent": "The acronym of spatial regression with.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Training and the problem solved here is formalizing this in this slide we have.",
                    "label": 0
                },
                {
                    "sent": "Data set that is composed by training and working sample some.",
                    "label": 0
                },
                {
                    "sent": "Which example is represented by means of an ID but also by means of the independent variables and the predictive variable the dependent variable, but also is represented by means of the coordinates.",
                    "label": 0
                },
                {
                    "sent": "So what we need also is a special distance.",
                    "label": 0
                },
                {
                    "sent": "The text value in.",
                    "label": 0
                },
                {
                    "sent": "In R-squared and returns values in R. Um?",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The goal actually is that of predicting the value of the unknown value on the of the class that the this is regression.",
                    "label": 0
                },
                {
                    "sent": "So this is the.",
                    "label": 0
                },
                {
                    "sent": "Response variable for each observation in the working.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sector.",
                    "label": 0
                },
                {
                    "sent": "OK, in this approach we.",
                    "label": 0
                },
                {
                    "sent": "Driver from the original data set two different views of the data of the same data set, and we work separately on both.",
                    "label": 0
                },
                {
                    "sent": "This is a coherent with the Co training style proposed by Blue Mitchell in Ant.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In 98 and here we somewhere summarize what we do.",
                    "label": 0
                },
                {
                    "sent": "The idea is this.",
                    "label": 0
                },
                {
                    "sent": "We have labeled examples and labeled examples.",
                    "label": 0
                },
                {
                    "sent": "We extract the two alternative views of the same data set, and then we might prediction model.",
                    "label": 0
                },
                {
                    "sent": "In this case the predictable predictive model we use is inductive learner.",
                    "label": 1
                },
                {
                    "sent": "And it learns model trees proposed by a pitch and their office key 2007.",
                    "label": 0
                },
                {
                    "sent": "And once we have classified unlabeled examples, we swap confident labels for.",
                    "label": 1
                },
                {
                    "sent": "But only confidently bolts for the data set and we rerun the learning the the learning learner OK.",
                    "label": 0
                },
                {
                    "sent": "So the first aspect are we had to face with was out were extract alternative view.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As well, the views we extracted are two, one is.",
                    "label": 0
                },
                {
                    "sent": "One is the original data set, the second is obtained by the original data set by some summarization.",
                    "label": 0
                },
                {
                    "sent": "In particular, we try to catch on this data set.",
                    "label": 0
                },
                {
                    "sent": "Are the smoothness assumption and we consider.",
                    "label": 1
                },
                {
                    "sent": "The summarization according to the neighborhood of the values of the attributes.",
                    "label": 1
                },
                {
                    "sent": "The distance we use is the Gaussian distance said that is was formalized reported here.",
                    "label": 0
                },
                {
                    "sent": "Where distance here is the Euclidean distance and this is the Gaussian distance for all.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "The two views actually yeah very dependent OK?",
                    "label": 0
                },
                {
                    "sent": "Yeah OK, I I agree with your point.",
                    "label": 0
                },
                {
                    "sent": "Or something?",
                    "label": 0
                },
                {
                    "sent": "Yeah, but we tried to partition just partition the feature space, I mean just to say this features in one view and these other features in the other view, but results were not so good for this data set.",
                    "label": 0
                },
                {
                    "sent": "Yes, yeah, by summarizing and we explained.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, I know that in the original proposal of local training, the two views have to be independent each other, but in this case we are able to catch the smoothness assumption.",
                    "label": 0
                },
                {
                    "sent": "This mood rest of the data so that one of you is low level features and the other view is some summarized.",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah, the second view all the features in the second view, our high level in the sense of yes yes yes yes.",
                    "label": 0
                },
                {
                    "sent": "Complementary in Avaya.",
                    "label": 0
                },
                {
                    "sent": "In a way of decreasing in the detail and increasing yes.",
                    "label": 0
                },
                {
                    "sent": "This helps.",
                    "label": 0
                },
                {
                    "sent": "This was for.",
                    "label": 0
                },
                {
                    "sent": "For the.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Determination of the two views, the.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The other point I got back here.",
                    "label": 0
                },
                {
                    "sent": "The other point is here to swap confident labels, but we have to define what are the confidence confident labels.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Indeed, we use these simple algorithm A to say that the feature is the label is confident or not and the idea is that for each example, if we remove the classification of that example.",
                    "label": 0
                },
                {
                    "sent": "In, if you remove the classification of that example, we have to check if the neighbor order.",
                    "label": 0
                },
                {
                    "sent": "The predictive capabilities increase or decrease if they decrease.",
                    "label": 0
                },
                {
                    "sent": "Probably the classification is not so reliable.",
                    "label": 0
                },
                {
                    "sent": "So use this simple algorithm to obtain to see to see if the examples.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We're reliable or not, and then we.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I return here we come.",
                    "label": 0
                },
                {
                    "sent": "The algorithm actually iterates here and tries to insert in the in the in the training set.",
                    "label": 0
                },
                {
                    "sent": "Those examples that have been classified as reliable and they are used for next classifications like in self training and at the end.",
                    "label": 0
                },
                {
                    "sent": "As just stopping criterion we define truce topic, do different stopping criteria.",
                    "label": 0
                },
                {
                    "sent": "The first one is the trivial number of iterates, and if we exceed given number of iterates, the algorithm stops.",
                    "label": 0
                },
                {
                    "sent": "The second stopping criteria is that.",
                    "label": 0
                },
                {
                    "sent": "When there is no, we are not able to add new examples.",
                    "label": 0
                },
                {
                    "sent": "New labels in the training set labeled examples in training set.",
                    "label": 0
                },
                {
                    "sent": "The algorithm stops.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the algorithm stops the response variable.",
                    "label": 0
                },
                {
                    "sent": "The response for each value is the average of the responses returned by the two classifiers.",
                    "label": 0
                },
                {
                    "sent": "The last two classifiers.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We used for experiments, several datasets, most of them have been provided by Sasha.",
                    "label": 0
                },
                {
                    "sent": "And we run both 10 fold cross validation and five fold cross validation.",
                    "label": 0
                },
                {
                    "sent": "Also in this case we used one folder as training set and the remaining folds as working set.",
                    "label": 1
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, there are some results.",
                    "label": 0
                },
                {
                    "sent": "What we can see here is that sprinkle in blue and violator.",
                    "label": 0
                },
                {
                    "sent": "Always outperform the inductive counterparts.",
                    "label": 0
                },
                {
                    "sent": "Error yes, the errors are massive.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The other algorithm A is the transition.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK so I have.",
                    "label": 0
                },
                {
                    "sent": "Question why is the previous one transductive why?",
                    "label": 0
                },
                {
                    "sent": "Why are you I mean?",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This one.",
                    "label": 0
                },
                {
                    "sent": "Perspective and not time supervised, but there are models.",
                    "label": 0
                },
                {
                    "sent": "Hopefully they generalize, yeah.",
                    "label": 0
                },
                {
                    "sent": "Data which is not nice.",
                    "label": 0
                },
                {
                    "sent": "Yeah, because actually the model we learn at the end.",
                    "label": 0
                },
                {
                    "sent": "Are not if you have the classifications at the end.",
                    "label": 0
                },
                {
                    "sent": "Those classifications you try to apply the last.",
                    "label": 0
                },
                {
                    "sent": "Model so it is possible that the model do not return the same classification you have cause it is possible that classification, classification or prediction regression in this case is the prediction is given by a previous version of the trees.",
                    "label": 0
                },
                {
                    "sent": "Have the models because I teach iteration, you learn a new model.",
                    "label": 0
                },
                {
                    "sent": "What changes from one iteration to the other is the fact that you are the reliable examples in the training set and those reliable examples are not changed from that point.",
                    "label": 0
                },
                {
                    "sent": "OK, OK I know.",
                    "label": 0
                },
                {
                    "sent": "OK, OK, I'll explain again.",
                    "label": 0
                },
                {
                    "sent": "In different words here, you run the learner, you obtain a model.",
                    "label": 0
                },
                {
                    "sent": "OK, then you try to see if the the prediction are liable or not.",
                    "label": 0
                },
                {
                    "sent": "If they are reliable examples are considered the training examples and you run again the algorithm.",
                    "label": 0
                },
                {
                    "sent": "So it is possible that when you run again the algorithm.",
                    "label": 0
                },
                {
                    "sent": "Use debt example as training examples, not as tested sample obviously, so it is possible that the prediction of the new model is different from the prediction of the older model.",
                    "label": 0
                },
                {
                    "sent": "So this is this is the reason because you do not have a model at the end that works for all the examples in the same way.",
                    "label": 0
                },
                {
                    "sent": "They actually did.",
                    "label": 0
                },
                {
                    "sent": "Transductive and not semi supervised.",
                    "label": 0
                },
                {
                    "sent": "I mean you are free to use the final model on any data in yes you can use the final model for any data but.",
                    "label": 0
                },
                {
                    "sent": "You are not sure that the classification is that the algorithm says.",
                    "label": 0
                },
                {
                    "sent": "So actually I left at the end at the end.",
                    "label": 0
                },
                {
                    "sent": "No, it's at the end.",
                    "label": 0
                },
                {
                    "sent": "You have.",
                    "label": 0
                },
                {
                    "sent": "The result is the combination of a lot of classes of models.",
                    "label": 0
                },
                {
                    "sent": "I mean, you have generated many models, but hopefully the last one, yeah, but you are not sure that last one works at the same way you predicted in the first iteration.",
                    "label": 0
                },
                {
                    "sent": "Nothing.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, the last algoritma translates.",
                    "label": 0
                },
                {
                    "sent": "She is the acronym of Transactive Structural Classifier.",
                    "label": 1
                },
                {
                    "sent": "It is based on the transductive learning framework.",
                    "label": 1
                },
                {
                    "sent": "It exploits the expressive power or relational learning.",
                    "label": 1
                },
                {
                    "sent": "Classification is probabilistic and what we do is to extend the system.",
                    "label": 0
                },
                {
                    "sent": "The original system USBC that is multi relational classifier in the case.",
                    "label": 0
                },
                {
                    "sent": "Of transductive learning",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The problem is solved by this algorithm.",
                    "label": 0
                },
                {
                    "sent": "A is reported here.",
                    "label": 0
                },
                {
                    "sent": "Given a data set schema this time, which consists of a set of relational tables and a set of primary constraints as well as a set of foreign key constraints on the schema.",
                    "label": 1
                },
                {
                    "sent": "As we have also a target relation T that is one of the H tables here of S and the interior is also the.",
                    "label": 0
                },
                {
                    "sent": "The target disk Attack put that represents the response value.",
                    "label": 0
                },
                {
                    "sent": "The class.",
                    "label": 0
                },
                {
                    "sent": "We have the training set that is any stanza TS of this database schema of the database schema is where we have values for Y and we have the working set that is again an instance of the database schema S, But in this case we do not have values for Y.",
                    "label": 1
                },
                {
                    "sent": "The goal is to find the prediction for the examples in the working set.",
                    "label": 0
                },
                {
                    "sent": "It is important to say that in this case.",
                    "label": 0
                },
                {
                    "sent": "The example is according to the relational framework example, is not a single tuple, but is represented by a single tap all over the target table, but also by means of the topics that are related according to foreign key constraints to the table.",
                    "label": 0
                },
                {
                    "sent": "In the database.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The idea is of, the algorithm is reported here.",
                    "label": 0
                },
                {
                    "sent": "The mean.",
                    "label": 0
                },
                {
                    "sent": "The top level description of the algorithm.",
                    "label": 0
                },
                {
                    "sent": "We use an initial classifier then.",
                    "label": 0
                },
                {
                    "sent": "We use an initial classifier to obtain a classification.",
                    "label": 0
                },
                {
                    "sent": "Then in this iteration we change.",
                    "label": 0
                },
                {
                    "sent": "We classify examples on the basis of the neighborhood of that example and finally we.",
                    "label": 0
                },
                {
                    "sent": "We can also change the class for those examples that belong to the border of the class.",
                    "label": 0
                },
                {
                    "sent": "So the iteration is repeated.",
                    "label": 0
                },
                {
                    "sent": "So is repeated until the number of iterations exceeds the maximum number of iterations or when until the.",
                    "label": 0
                },
                {
                    "sent": "Number of the examples for which the class has been changed is been changed.",
                    "label": 0
                },
                {
                    "sent": "Not.",
                    "label": 0
                },
                {
                    "sent": "Is actually similar to the set of examples for which have been the classes.",
                    "label": 0
                },
                {
                    "sent": "This changed in the previous iteration, so there is no significant variation from one iteration in the other.",
                    "label": 0
                },
                {
                    "sent": "Here the initial classifica.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Vision is based on MSNBC that classifieds samples by means of a something like Bayesian classifier for relational data.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But then we apply a relational version of the key and an algorithm in order to change the class of the examples that are not for which the class is not reliable.",
                    "label": 1
                },
                {
                    "sent": "Um?",
                    "label": 1
                },
                {
                    "sent": "We also modify the class for those examples that are on the border of the class and the border is measured according to the entropy.",
                    "label": 0
                },
                {
                    "sent": "The entropy associated to the probability of the class of an example.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We already talked about the stopping criteria and.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here we report some results.",
                    "label": 0
                },
                {
                    "sent": "The 1st results are obtained on Northwest England Census data differently from the previous representation.",
                    "label": 0
                },
                {
                    "sent": "In this case we use a relational representation of this data set and.",
                    "label": 0
                },
                {
                    "sent": "In particular, we predict the German indexer, that is a deprivation factor of associated to award.",
                    "label": 0
                },
                {
                    "sent": "In this case, the units of analysis are the words.",
                    "label": 0
                },
                {
                    "sent": "And we also used relations spatial relations obtained by the 9 intersection model in order to find, for example, the overlapping relation between award and.",
                    "label": 0
                },
                {
                    "sent": "I don't know what are net or real net sorry way.",
                    "label": 0
                },
                {
                    "sent": "And so on.",
                    "label": 0
                },
                {
                    "sent": "Would you please send it example in a different each layer in a different relational table and words in other?",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Tables.",
                    "label": 0
                },
                {
                    "sent": "Here we report some results.",
                    "label": 0
                },
                {
                    "sent": "Are we report results of the 10 fold cross validation but also of the 20 fold cross validation.",
                    "label": 0
                },
                {
                    "sent": "Also in this case we use one fold as training set the other fold as the other faults as working set and in this case we can see that we are able to reduce the error with respect to the inductive counterparts.",
                    "label": 1
                },
                {
                    "sent": "Also in this case working with.",
                    "label": 0
                },
                {
                    "sent": "Unlabeled data in addition to label data is beneficial.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The second data set is Munich census data.",
                    "label": 1
                },
                {
                    "sent": "With this data set is obtained is represents the.",
                    "label": 0
                },
                {
                    "sent": "Mount Re rent per square meter for flats in Munich, in Germany and we represent layers here such as.",
                    "label": 1
                },
                {
                    "sent": "Transport stops.",
                    "label": 0
                },
                {
                    "sent": "Railways and bus stops.",
                    "label": 0
                },
                {
                    "sent": "And we use the discretization for the target attribute, because this is a classification a classification task.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here are the results are also.",
                    "label": 0
                },
                {
                    "sent": "In this case.",
                    "label": 0
                },
                {
                    "sent": "We notice that when we work in the transact resecting we reduce the error of the inductive original algorithm.",
                    "label": 0
                },
                {
                    "sent": "So the iterations are actually beneficial.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Thank you for your attention.",
                    "label": 0
                },
                {
                    "sent": "I would mention the normal bandana Lisa picture that actually worked with me with you on this project.",
                    "label": 0
                },
                {
                    "sent": "And I will thank all the audience.",
                    "label": 0
                },
                {
                    "sent": "Attending here thank you.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much Michelangelo.",
                    "label": 0
                },
                {
                    "sent": "We have time for questions so if there are any questions please.",
                    "label": 0
                },
                {
                    "sent": "Yeah, the second algorithm.",
                    "label": 0
                },
                {
                    "sent": "Yeah, a method for checking how reliable a prediction is, but you you you went through that a little bit too quickly.",
                    "label": 0
                },
                {
                    "sent": "OK, interested in that, yeah.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, in a new version of the algorithm we modified this.",
                    "label": 0
                },
                {
                    "sent": "Anyway, we worked actually on the standard deviation.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the last version that is still in this is still work in progress.",
                    "label": 0
                },
                {
                    "sent": "We have more views and we consider reliable those examples for which the standard deviation of the prediction is not so high.",
                    "label": 0
                },
                {
                    "sent": "That is the new version in this.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Version of the algorithm we compute.",
                    "label": 0
                },
                {
                    "sent": "Actually the error given an example, OK.",
                    "label": 0
                },
                {
                    "sent": "If given example for all the examples P in the neighbor of V, we compute the error and we compute here by.",
                    "label": 0
                },
                {
                    "sent": "With the KNN algorithm, by introducing EM by removing a. OK, if the classification.",
                    "label": 0
                },
                {
                    "sent": "So if the prediction of all the examples in the neighbor of East.",
                    "label": 0
                },
                {
                    "sent": "In any age and some if the the predictive capabilities of the algorithm introducing removing E increase increases, then it means that the algorithm that yeah, it's not.",
                    "label": 0
                },
                {
                    "sent": "It's not good, thank you.",
                    "label": 0
                },
                {
                    "sent": "How much do you rely on the smoothness versus enforcement?",
                    "label": 0
                },
                {
                    "sent": "Because I've noticed this algorithm, you lose Gaussian distances, yeah, so in some sense you're smoothing everything else to enforce.",
                    "label": 0
                },
                {
                    "sent": "Yes, that is we do what we do.",
                    "label": 0
                },
                {
                    "sent": "Actually, in other experiments we considered in addition to.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The Gaussian measure only the Euclidean distance, and in that case the algorithm actually was more sensitive to.",
                    "label": 0
                },
                {
                    "sent": "Also to.",
                    "label": 0
                },
                {
                    "sent": "Appliers.",
                    "label": 0
                },
                {
                    "sent": "What about using something in some graph distance like we did in the 1st?",
                    "label": 0
                },
                {
                    "sent": "Yeah, it can be.",
                    "label": 0
                },
                {
                    "sent": "All it's the same music here, graphic graphics tension.",
                    "label": 0
                },
                {
                    "sent": "I mean you can here look at examples as nodes in the graph.",
                    "label": 0
                },
                {
                    "sent": "Question would be more, what is the future to whether the local structure is by using some graph distance as opposed to this meeting?",
                    "label": 0
                },
                {
                    "sent": "Right, because in Euclidean distance you're still installed and above.",
                    "label": 0
                },
                {
                    "sent": "Global distance yeah, so the difference would be.",
                    "label": 0
                },
                {
                    "sent": "My question would be, did you check how?",
                    "label": 0
                },
                {
                    "sent": "How smooth the distance is a priority for smoothing it.",
                    "label": 0
                },
                {
                    "sent": "OK, yeah, there's a work that we tried to do distance here already, right?",
                    "label": 0
                },
                {
                    "sent": "I mean, there's some intrinsic distance.",
                    "label": 0
                },
                {
                    "sent": "Anyway, um.",
                    "label": 0
                },
                {
                    "sent": "We did not check on the data set, what happens, but.",
                    "label": 0
                },
                {
                    "sent": "It will be interesting to check yes, I agree.",
                    "label": 0
                },
                {
                    "sent": "I have a question you already started talking along those lines instead of just the two views in con training, can you use multiple views and is that beneficial?",
                    "label": 0
                },
                {
                    "sent": "Yeah, there is a work by.",
                    "label": 0
                },
                {
                    "sent": "Erna Viktora, I don't know if you know from Canada, and in that work they tried to extract several views from relational data and then apply some algorithm.",
                    "label": 0
                },
                {
                    "sent": "I don't know some classical algorithm.",
                    "label": 0
                },
                {
                    "sent": "What we were saying, we are trying now actually to do is to consider.",
                    "label": 0
                },
                {
                    "sent": "The different views they have, as in the independent views and to apply these not Co training.",
                    "label": 0
                },
                {
                    "sent": "I mean there are multiple multiple.",
                    "label": 0
                },
                {
                    "sent": "Views, not just two views, but did you use that views to obtain the obtain different classifications and then to combine them for?",
                    "label": 0
                },
                {
                    "sent": "Saying that, if the examples are reliably classified or not.",
                    "label": 0
                },
                {
                    "sent": "Are there any other questions?",
                    "label": 0
                },
                {
                    "sent": "I was just wondering on a high level.",
                    "label": 0
                },
                {
                    "sent": "Semi supervised and transductive.",
                    "label": 0
                },
                {
                    "sent": "So why?",
                    "label": 0
                },
                {
                    "sent": "Why would you not want to have more general things so?",
                    "label": 0
                },
                {
                    "sent": "Or in principle it is an easier task.",
                    "label": 0
                },
                {
                    "sent": "Maybe what I understood you don't care about other examples you care just about those at hand.",
                    "label": 0
                },
                {
                    "sent": "Yeah, and you think you will never need to classify any other examples, so you can kind of tune to the examples that yes, right?",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "And then hopefully you because you know you don't care about others.",
                    "label": 0
                },
                {
                    "sent": "You can do better job on this example.",
                    "label": 0
                },
                {
                    "sent": "Yeah, this is important in principle.",
                    "label": 0
                },
                {
                    "sent": "Yes, yes.",
                    "label": 0
                },
                {
                    "sent": "Then you have shown us three approaches or three you know to different kind of data and so on.",
                    "label": 0
                },
                {
                    "sent": "And you say OK, they are transacted.",
                    "label": 0
                },
                {
                    "sent": "So if you would.",
                    "label": 0
                },
                {
                    "sent": "Use Semi supervised approach, whatever it means now and compare the results.",
                    "label": 0
                },
                {
                    "sent": "Yeah, can you show that because of used reductive approach?",
                    "label": 0
                },
                {
                    "sent": "Because you know that will be interesting.",
                    "label": 0
                },
                {
                    "sent": "Yeah, now you have better results in the end that will be interesting to explore.",
                    "label": 0
                },
                {
                    "sent": "I've never tried, I mean.",
                    "label": 0
                },
                {
                    "sent": "Anybody else tried that?",
                    "label": 0
                },
                {
                    "sent": "Yeah, but the problem is that.",
                    "label": 0
                },
                {
                    "sent": "When you compare the two approaches, they have to be compatible, I mean.",
                    "label": 0
                },
                {
                    "sent": "You just completed.",
                    "label": 0
                },
                {
                    "sent": "Yeah, but the approaches have to be.",
                    "label": 0
                },
                {
                    "sent": "At the same level I mean the comparison have to be fair to say at the end.",
                    "label": 0
                },
                {
                    "sent": "That reason is why you use a semi supervised instead of some transductor or vice versa.",
                    "label": 0
                },
                {
                    "sent": "And what if it depends on the single algorithm you are using?",
                    "label": 0
                },
                {
                    "sent": "Yeah, and it would be interesting, but I think it is not easy to prove that even empirically.",
                    "label": 0
                }
            ]
        }
    }
}