{
    "id": "7h3gohtrodmwzzzp37h2dprjr5i3jfui",
    "title": "Deep learning for plant identification",
    "info": {
        "author": [
            "Ivica Dimitrovski, Department of Knowledge Technologies, Jo\u017eef Stefan Institute"
        ],
        "published": "Jan. 31, 2017",
        "recorded": "September 2016",
        "category": [
            "Top->Computer Science",
            "Top->Data Science"
        ]
    },
    "url": "http://videolectures.net/miningdata2016_dimitrovski_plant_identification/",
    "segmentation": [
        [
            "I will present an application of deep learning for.",
            "Case of plant identification, so this is.",
            "Application application that we.",
            "That we have doing in the last five years first revealed firstly using conventional feature extraction methods and learning methods and anything.",
            "The last two years deep learning so.",
            "The outline."
        ],
        [
            "Presentation first, I will give a brief introduction of the problem.",
            "Then I will explain the data set that we used in this particular research.",
            "Then I will give an overview of the plant identification approaches before the deep learning.",
            "The segmentation methods, the feature extraction methods, the classification methods and so on.",
            "And then I will explain how.",
            "Explain how we are using deep learning for the purpose of a plant identification.",
            "Some experiments, results, issues, some problems that we have to solve and some conclusion, conclusions and for the work that we are planning.",
            "That we are planning for the near future."
        ],
        [
            "If you don't find plant species is usually impossible for the general public, and often it is a very difficult task for even a professional, such as farmers for enthusia, stick with exploiters and so on.",
            "Typical cycle pass for the botanist themselves, so the image based image based plans in Ification is the most problem.",
            "Promising solutions solution towards bringing the bridging.",
            "The botanical taxonomic gap in the recent years there there is an emergence of dedicated mobile applications such as Leaf snap and plant net that can be used for.",
            "Image classification image identification application.",
            "These applications are quite promising, but their performance is still far from the requirements of a fully automated ecological surveillance scenario just."
        ],
        [
            "Does the example in 2015 more than two million 2 million square stepping submitted by the users of the plant net mobile applications, the OS version and Android version but only less than 3% of them were finally shared on collaboratively validated?",
            "This is a very low percentage of them.",
            "Entire set of queries that have been submitted, so it is crucial.",
            "To boost the performance of the machine learning algorithms for the purpose of automated identification, notification of these plans, but most only building effective computer vision and machine learning technique.",
            "This is crucial for for bridging this taxonomical gap problem, it is crucial to have appropriate training data and so collecting computing appropriate training data is becoming one of the most central problems for solving the economic gap problem."
        ],
        [
            "Now you search, we're using the plant cube data set for this data set contains more than 100,000 images.",
            "Some example images are shown on this slide.",
            "This slide we are using two versions of this data set.",
            "The version the version from 2014 and 2015 Plant Cliff competition.",
            "The images from the test data set are from mom classes in this case and for the plant left for 2016.",
            "We have a open world recognition problem in the test set we have images that are not planned on images that are images with plans that are from different classes that we have in the training set.",
            "So the plant left 2016 is more and more challenging or data set so more challenging."
        ],
        [
            "Problem some example images from this data set just to see how the images and the plans are diverse.",
            "Their diverse taking into account the leaf.",
            "We have coloration, global shape variation.",
            "We have left margin variation, number of leaflets, variation, leafless relative position variation and so on.",
            "So it's quite.",
            "Quite leaf diversity."
        ],
        [
            "If we.",
            "If we analyze this flower images, we can see that there is also diversity.",
            "The buffer between the Flowers present in this data set.",
            "The flower is often the key to identify a specious of the plant, but as I mentioned, there is a great diversity within the Flowers of Flowers.",
            "For the data set can be categorized according to the color to the Cemetery, to the structure, orientation and the size.",
            "Also for one same species, the Flowers still have different colors, so this is even more.",
            "Other, more challenging."
        ],
        [
            "On this slide, slide some.",
            "Sorry.",
            "What this slide?",
            "We have some variation in the fruit table stem type, the entire plant in the branch.",
            "Great diversity of the type of fruits that are better represented throughout the speeches of the plan.",
            "View data set.",
            "The stem is generally a difficult plant organ for identifying suspicious, maybe because the visual information is mainly expressed with texture, not color and shape, and because of the age of the plant the stem is changing through time.",
            "So we have to take this into account also also this the entire view of the tree generally does not contain enough information.",
            "So we cannot use it.",
            "First, the purpose of plant identification, but surely can help.",
            "You can help.",
            "Combined with the other plant organs, very different appearance depending on the geographical and climatical condition condition.",
            "This is for the entire plant and for the branch."
        ],
        [
            "From the images of this data set, we have a rich metadata.",
            "The metadata is described here.",
            "The most important part is observation ID.",
            "The plan operation idea for, from which several picture can be associated with.",
            "We have also here the species, genus, family, the data vault, the average of the user rating of the image quality locality, and so on.",
            "Uh."
        ],
        [
            "What is observation over plant is a set of 1 several images depicting the same individual plant observed, observed by the same person the same day.",
            "We will say in the device there is example.",
            "Here we have this plant and several images representing leaves and Flowers of these plans.",
            "So all of these images will have the same observation ID and actually all of these images we can use later too.",
            "Predict the species for this particular plant."
        ],
        [
            "Some general information of the the two version of the of the data set for the plank left 2015.",
            "Seven plant organs, 17th image content, flower fruit, fruit leaves.",
            "Live scan, entire tree branches, theme stem and so on.",
            "1000 plant classes.",
            "More than 100,000 images for over 43,000 operation as I mentioned.",
            "One of the nation 15 images of a plant and this is actually a multi query challenge.",
            "We have to take into account all the images when classifying.",
            "Come on observation."
        ],
        [
            "For the blank left 2016, as I mentioned, the test data set is composed of unknown plants, vicious and normal plant objects.",
            "To create an open world plant data set so we have recognized unknown class features, but also to reject downloading plans and the objects.",
            "Also example images from this this.",
            "Except these are the example images from the test set.",
            "The train step is the same as the lamp class 2015."
        ],
        [
            "15 So that the.",
            "Platelets 2016 is open center or open world recognition challenging testing computer vision as well as samples from how long classes could be present so we have to develop algorithm that is robust to unknown and never see an inventories.",
            "So beyond the brute force classification across the known classes of the training set of big challenge, here is to automatically reject the foldable positive classification hits caused by the unknown classes and unknown object.",
            "So image is present in the present in the data set."
        ],
        [
            "The test set is composed of 8000 images.",
            "Some of the images are labeled with one of the 1000 known classes of the training set.",
            "The rest of the images are from unknown classes or even known plant images.",
            "Among the first images that are that are labeled with known classes, they are 366 images stacked as invasive, according to a select list of potentially.",
            "Invasive species"
        ],
        [
            "That is the description of the datasets that we used in our experiments.",
            "Now briefly overview of the plant edification approaches that were used before deep learning approach.",
            "I will tell you something about English innovation, feature extraction, classification, and Fusion.",
            "The image."
        ],
        [
            "Imitation process can be crucial in the plant ification test becausw the image segmentation is trying to segment the main object and extract the regional feed interests and remove the relevant background which could introduce noise to our classifier that we are using different segmentation approaches for the different plan to organize we have to use brief."
        ],
        [
            "Be about these segmentation approaches.",
            "For example, for the flower and fruit images, if we attempted a flower or fruit is usually more red compared to the lives we can locate the region of which there red channel is larger than the green channels and later on each color image we can convert to a great value in each and the localized red regions are then employed as initial masking.",
            "Nothing, anything the flower or fruit in the great value me choosing the active contour method.",
            "Then we can compute the minimum bounding box of the flower or fruit.",
            "The regional features do example images and the region of interest extracted from these images.",
            "In so in the classification step we are using these images instead of the.",
            "We are using this the small images instead of the entire image with the background."
        ],
        [
            "This data set contain contains also release scans, either as simple images.",
            "The lift is can't usually on the white background, but there is a variation among the background color for the segmentation purpose.",
            "Here in this scenario we are no normalizing the background with the consistent.",
            "Why follow later on we are converting the core images to a great value mission applied automatically to computer.",
            "Shall the pixel values the floors official letter level this big around an old big big round pixel in the personal info images are signed with the white Board to example images images after the simple."
        ],
        [
            "Quotation for the leaf images.",
            "Because the leaf is usually located in the center area of the picture, there are typically some margin between the leaf boundaries and the picture border.",
            "So we in this area.",
            "In this case, we're just extracting the object that is located in the center of the of the pictures.",
            "To remove them the background."
        ],
        [
            "For the same images.",
            "See similar as the leaf usually located in the center of language.",
            "Compared the color image to Gray value image.",
            "Credit created central Mask of the image by cropping percent from left to right.",
            "The great value in each using this mask bounding box of the resulting idea to obtain the region of interest for the steam image."
        ],
        [
            "OK, what we have done.",
            "The user segmentation then we are proceeding with the next step.",
            "The feature extraction step.",
            "In this step we are using basically some of the feature that on the way already mentioning his presentation, we're using her local feature extraction around here, just pointing the segmented images.",
            "Some example in some example of feature extraction methods that can be used our rotation invariant invariant local band.",
            "Binary partners still inviting future can storm the speedup fahrion surf full of food at his program.",
            "Instrumentation histogram.",
            "Some variants of the histogram in different color spaces and so on when where we have the local features, we can construct a visual index of this local features.",
            "For example, if you're computing the local features from the training images.",
            "Then we can compress and index them using for example random maximum margin, fishing, tehnika stables and later on for each local features from feature from the query image we compressed it with this.",
            "With this caching then approximative K means neighbors or search probing multiple neighboring buckets in the hash tables to obtain the panel list of most relevant images for this query.",
            "For this query image."
        ],
        [
            "Besides the doing this, we can also construct the standard bag of visual words.",
            "You can use the standard bag of visual words approach.",
            "We can construct us.",
            "We can construct for example visual codebook for each plant organ.",
            "For doing this we can use.",
            "For example K means or approximative K means or predicted or even predicted clustering trees if we have many number of local strip clubs and if we are clustering.",
            "These local distributors seen many clusters or visual words.",
            "We cannot experience experiments using Approximative Kings.",
            "Also, predictive clustering trees later on we can use the term frequency inverse document frequency.",
            "Some normalization normalization to count the similarities between these images.",
            "Also besides the bag of visual words, we can use the feature parallel feature coding.",
            "We can compute losing richer models in the SIFT.",
            "The space that this alternative to the bag of visual words approaching these are the local feature extraction techniques that thing that can be used."
        ],
        [
            "Can also use some feature extraction techniques that are global that they take into account the entire the entire image.",
            "Entire picture.",
            "For example, we have the multi scale triangle shape.",
            "Descriptor that can that is.",
            "Validated on variously database, very robust and fast to compute.",
            "It is used for local makes, mention of shapes and that's why it is best for the images with Leafs.",
            "How it briefly, how it is computed, the shape boundary is represented with a sequence sequence on of sampling points which are uniformly distributed over the contours.",
            "Another thing the code base in order for example, and then for each point each point actually is represented by a.",
            "383 angles computed at different different different scales."
        ],
        [
            "The classification algorithms we can use.",
            "And then classifier we can build for example for example 7 classifier for the seven different plant organs.",
            "We can use support vector machines.",
            "We can use different similarity metrics.",
            "Is crucial to use some sort of Fusion scheme to obtain the final prediction.",
            "We cause.",
            "Usually we have many feature descriptors also seven classifiers.",
            "So somehow to obtain the the classes for the observation we have to fuse these different predictions from the different feature extraction methods and from the different from the different classifiers."
        ],
        [
            "Summary of this approach is.",
            "As I mentioned, these approaches are before the before the start, before deep learning applied to the planning signification problem.",
            "If you want to use something that is not declaring the best choice would be Fisher.",
            "Vector encoding contain state of the art results results.",
            "Extract benefits and polar moments in the images to produce each local feature to a 60 four dimension dimensions after using PCA.",
            "Estimated using mixture models, for example with five current until components to produce the Fisher vector representation for the images, and then as a classifier to use them.",
            "Linear SVM, one for each side of the future.",
            "Features the seat and the.",
            "Polar moments this is the paper that describes this.",
            "This is set up.",
            "The results are about 40% of miniature precision.",
            "OK."
        ],
        [
            "And now something about the deep learning approach.",
            "You know that thing deep.",
            "Learning the raw data data is fit into the convolutional neural network in multiple levels.",
            "Evolution of neural network automatically discover, discover, Skype level features or plant which is recognition.",
            "The deep learning approaches Sky computational complexity to be trained from scratch, and that's why usually we're using pre trained networks that are fine tuned for plant identification purposes.",
            "For example, we're using.",
            "CNET or Google Maps to.",
            "That are pre trained on the large image set and later on we are fine tuning them for the purpose of plant plant identification purposes."
        ],
        [
            "The first step is that we are going in the deep learning approaches, day termination date of meditation.",
            "We're applying data augmentation to decrease the chance of overfitting during training and to improve the performance of them of the convolutional neural networks.",
            "Actually with the with the data innovation, we're increasing the data set size.",
            "We're doing artificial expansion of the data set.",
            "Using accommodation by rotation by mirroring quest curing.",
            "All sorts of different augmentation techniques can be used to artificially expand the the initial data set.",
            "The white spaces after the mentation or filled with the latest set mean value."
        ],
        [
            "Some example image via the initial image and the image obtain after the rotation augmented image.",
            "The white spaces are filled with the data set mean value."
        ],
        [
            "Then augmentation by mirroring."
        ],
        [
            "In augmentation by skewing.",
            "In this way, we are enlarging the training data set data set that we are.",
            "We are going to use for training for fine tuning to classify."
        ],
        [
            "This is the overall overall."
        ],
        [
            "System architecture we have the initial training set and test set.",
            "The training set is.",
            "Through the application model module.",
            "To obtain the Elemental train set with artificially added images, we are using the Google Maps Model 3 training on the large set of images, 40,000,000 images from image net.",
            "If you are fine tuning this model with the elemented.",
            "Documented datasets from the from the Plant Review.",
            "We are obtaining the predictions and in the later phase we are using some sort of Fusion to take into account the images in the observation and we're doing some evaluation and presenting that final result."
        ],
        [
            "Results.",
            "This is the global net model that we used in this application as a nation is pre trained on the image.",
            "Net data set implemented in the fake convolutional neural network with 27 layers we take into account the inception layers.",
            "Receptive field is 224 by 224 images that are in the energy color space and as I mentioned we have inception architecture.",
            "We have accept."
        ],
        [
            "Inception architecture in this model, the inception model in the convolutional neural network are designed to allow for deeper, larger convolutional layers, while at the same time allowing for more efficient computations.",
            "How is this done?",
            "This is done by using one by one convolution convolutions with small feature map size example here.",
            "190 two, 28 by 28 sites feature Maps can be reduced to 6428 by 28 future Max 264 one by one convolution because of the reduced size.",
            "This one by our convolution can be follow up with larger convolution conclusions for size 3 by 3 or 5 by 5 by 5 in the output of the reception module.",
            "All the.",
            "Large convolutions are concatenated into a big feature map, which is then fed into the next layer of the of the convolutional neural net."
        ],
        [
            "The Google Maps layer Sir presented here.",
            "You can see the convolutional layers.",
            "The Max pooling layers, the inception layers and in the later the last layer is the softmax layer.",
            "You can see also here the output size of each layer, also the parameters.",
            "Oh, did we obtain each of these layers?"
        ],
        [
            "Some experiments first.",
            "Experiments to see how the data set size and the diversity of the data set data set to impact the classification performance.",
            "Then we also did some experiments to see how the data argumentation impact the overall performance of of our.",
            "Approach."
        ],
        [
            "Power system these are the experiments.",
            "Here we are using the volumes for the 2014 and plan 2015 data set several experiments only using Google, Google Maps, Google Maps, model train from scratch using the plant 2014 data.",
            "Set up your Google Maps only on the image net not fine tuned on the plan data set Google Net on Image net and.",
            "Fine Tune complaint 2014 Google Net retrain from image net.",
            "Fine tuned with the difference.",
            "Expand Expanded datasets using them, augmentation methods, and in the last the last experiment, experiment with using the Google Net.",
            "Jeanette, but fine tunes on the plants 2015."
        ],
        [
            "Sets the results as I as as to be expected.",
            "If you're using your Google Maps not fine tune on the planet data set we are obtaining.",
            "Very low.",
            "Accuracy very little, very bit resolve.",
            "These are the results if we are using.",
            "If you're using convolutional neural network training from scratch using only the plant 2014 data set, the results are between 18%.",
            "This is the Google net trained on image net training, retraining, Connect and fine tune with the images from.",
            "Left 2014 you can see that boosting.",
            "Mercy.",
            "The first images only take into account.",
            "If we if we have the correct label for the first image, so we are.",
            "We are prisoners.",
            "Google net on the image net pre training and plan 2014.",
            "See the boosting the performance compared to the Google Maps trained from scratch from this data set.",
            "If we compare the performance of the augmented data sets sets, we can see that if we augmented the data set then we obtain further improvement of the performance compared to the original original data set.",
            "If we use them.",
            "Plant 2015 data set we are obtaining.",
            "We are the difference between the.",
            "Then 2014 and plan 2015 is dead.",
            "The plan 2015 has 1000 classes and the plan 2014 has 500 classes.",
            "So this data set is actually bigger than this data set.",
            "We are training on the we are training the fine tuning the network on the these data set, but we are testing on on the plans 2014.",
            "I wanted to ask so if you have 500,000 plus is so accuracy 45% is quite good.",
            "Would you check?",
            "So, did you try measuring the accuracy in North or identifying each individual species, but instead seeing if the genus is correct?",
            "No, we have not taken into account here here that economy afraid you're only interested in the in the lower.",
            "I would guess people would be interested in that as well.",
            "It might be much, much better perhaps.",
            "Actually, we we we are playing this for the framework we are.",
            "We are somehow trying to incorporate the hierarchy of the excellent into the learning process.",
            "Some count, but we haven't done that yet.",
            "We are planning to do that.",
            "So when you say you're fine tuning Imagenet.",
            "You're throwing away the last layer.",
            "Keeping the weights from Imagemaps very trainable.",
            "So have you tested how much though?",
            "The weights of the lower level are actually changing.",
            "Or is it just that you are just living a different classifier on the representation of engagement?",
            "And what happens if you run like?",
            "Super vector machine on the on.",
            "The representation for measurement if we run without, you know.",
            "Doing backpropagation and we have done that, but the results are worse, much worse.",
            "Maybe by I don't know.",
            "I don't know the exact number, so I think by 50% or maybe worse, OK?",
            "That's why we decided to use this new setup.",
            "The results were similar with the the other approaches that I mentioned before.",
            "The linear SVM instrumentation.",
            "The whole message as official Victor performed here, sorry.",
            "You're not deep learning.",
            "It was interesting in the 2014 competition.",
            "The Fisher vector encoding using linear SVM's was the best ranked.",
            "Result it was around 50% I think in the final scoring and the same team applied also deep learning deep learning the results from different learning more about 20 or so percent so.",
            "But in the next year most of the team started using only deep learning and the results increased quite for this year.",
            "The best result is.",
            "80%.",
            "Quiting increase compared to the previous years.",
            "We participated in.",
            "2014 and we did not manage to submit the results for 2015, but if we have submitted we would view rank type thing.",
            "Second transfer."
        ],
        [
            "This is the learning curve.",
            "Increase of accuracy and the increase of the loss during the training process and want to get into details."
        ],
        [
            "Here it was interesting as I mentioned, for the planet left 2016.",
            "The organizers of this competition includes unknown classes.",
            "You just normal classes and normal plant images in the test data set.",
            "So for this particular competition we have to somehow.",
            "First, separately Finetune Googlenet model for a binary classification problem.",
            "For example plan versus non plant images.",
            "For this set up the training data data set contains plant images from life 2015 unknown plant images for the floor scale competition and using the results for results from the binary classifier, we can reject the images that are classified classified as non plant images.",
            "Unassign a low confidence scoring data in the final main plant indication indication system.",
            "So first we are training.",
            "A binary classifier that can distinguish two classes, plant versus non plants.",
            "Then we are using the same setup as previous but we are decreasing the probabilities.",
            "We are signing bonus for for this images that are classified classified as non plant images in the in the final.",
            "In the final result."
        ],
        [
            "It is interesting here that the degree of novelty in the test set is a strong influence on the performance.",
            "For example, in this year, blank left 2016 competition when 25% of the various still belong to a known class.",
            "None of the system region mean average precision greater and greater than.",
            "C Zero point 45 compared to the zero point 83 in the closed world world.",
            "Set up where the classes in the training images are from the.",
            "You may just need the test data set data set are.",
            "With the classes from the training data set, so this is quite quite a problem in a real case scenario this number is much more 'cause if the user has a mobile phone and it goes and.",
            "Take take picture of everything and submitted the queries.",
            "The number, the number of of this number will be will be much lower, so the performance is it is can be decorated even even more so this is this is quite a quite a problem that have to be solved, solved in the plans magnification task.",
            "Additional."
        ],
        [
            "Problems that we have here is that the original net model requires input image of facial size to convert 24 by 224.",
            "The images in the planet left versions are arbitrarily sized so.",
            "Following the specialized restriction in Google Maps, model input images gets to be either copper or.",
            "Formation loss there is."
        ],
        [
            "Solution for this problem?",
            "We haven't tried this yet.",
            "We can use spatial spatial pyramid pooling layer.",
            "The feature we can divide a feature map spatially into one by one 2 by 4 by 4 in total 51 region.",
            "Then each region can be average pulled producing a vector of pick sides.",
            "For example, if we have 5020 generals in the last convolutional litteraire, you're paying a vector of fixed size 1010 thousand 77155.",
            "Um?",
            "55 scalars in that vector.",
            "Um?",
            "This conversion of arbitrary size feature mapping to the into a fixed size vector or allow the model to accept input image obtaining size.",
            "We can skip that step when we are processing the images in the fixed.",
            "Sized"
        ],
        [
            "Make some conclusions and further work.",
            "Mushel neural networks.",
            "Three training on large datasets set and fine tuned on Tao.",
            "Commented datasets to the specific domain to get the best way to get the best results is is our recommendation, but the convolutional neural network is strongly affected by the higher rates of images belonging to unknown class, so we have to find the solution for this.",
            "We are as a further work we are.",
            "We will definitely try different.",
            "Set up soft revolutional neural network.",
            "Somehow we can create an example of convolutional neural network networks with different set up with different convolutional layer and so on.",
            "And then we can combine the tradition to increase the classification performance.",
            "We are also planning to somehow combines a handcrafted features into the feature features obtained into the convolutional neural networks.",
            "We are we have done another application similar to this but in that application we had only lift images and it was quite interesting.",
            "The results were quite interesting.",
            "Some of the classes that are very that were very difficult to be distinguished even looking by I from.",
            "I don't know by some expert were correctly classified by the convolutional neural network and some of the images that were quite distinct.",
            "Were wrongly classified by then convolutional neural network.",
            "In this case, if we have applied standard conventional methods, feature extraction methods.",
            "Location methods them.",
            "These images would be correctly classified so we can somehow combine the hand crafted features and the convolutional neural networking in order to eliminate these problems.",
            "Also we are.",
            "We can also try to use them higher here of the taxonomy into in the convolutional neural networks too.",
            "Do something to somehow boost the overall performance of.",
            "Of this approach."
        ],
        [
            "Let's see."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I will present an application of deep learning for.",
                    "label": 1
                },
                {
                    "sent": "Case of plant identification, so this is.",
                    "label": 0
                },
                {
                    "sent": "Application application that we.",
                    "label": 0
                },
                {
                    "sent": "That we have doing in the last five years first revealed firstly using conventional feature extraction methods and learning methods and anything.",
                    "label": 0
                },
                {
                    "sent": "The last two years deep learning so.",
                    "label": 0
                },
                {
                    "sent": "The outline.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Presentation first, I will give a brief introduction of the problem.",
                    "label": 0
                },
                {
                    "sent": "Then I will explain the data set that we used in this particular research.",
                    "label": 0
                },
                {
                    "sent": "Then I will give an overview of the plant identification approaches before the deep learning.",
                    "label": 1
                },
                {
                    "sent": "The segmentation methods, the feature extraction methods, the classification methods and so on.",
                    "label": 0
                },
                {
                    "sent": "And then I will explain how.",
                    "label": 1
                },
                {
                    "sent": "Explain how we are using deep learning for the purpose of a plant identification.",
                    "label": 0
                },
                {
                    "sent": "Some experiments, results, issues, some problems that we have to solve and some conclusion, conclusions and for the work that we are planning.",
                    "label": 0
                },
                {
                    "sent": "That we are planning for the near future.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If you don't find plant species is usually impossible for the general public, and often it is a very difficult task for even a professional, such as farmers for enthusia, stick with exploiters and so on.",
                    "label": 1
                },
                {
                    "sent": "Typical cycle pass for the botanist themselves, so the image based image based plans in Ification is the most problem.",
                    "label": 0
                },
                {
                    "sent": "Promising solutions solution towards bringing the bridging.",
                    "label": 0
                },
                {
                    "sent": "The botanical taxonomic gap in the recent years there there is an emergence of dedicated mobile applications such as Leaf snap and plant net that can be used for.",
                    "label": 0
                },
                {
                    "sent": "Image classification image identification application.",
                    "label": 0
                },
                {
                    "sent": "These applications are quite promising, but their performance is still far from the requirements of a fully automated ecological surveillance scenario just.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Does the example in 2015 more than two million 2 million square stepping submitted by the users of the plant net mobile applications, the OS version and Android version but only less than 3% of them were finally shared on collaboratively validated?",
                    "label": 1
                },
                {
                    "sent": "This is a very low percentage of them.",
                    "label": 0
                },
                {
                    "sent": "Entire set of queries that have been submitted, so it is crucial.",
                    "label": 1
                },
                {
                    "sent": "To boost the performance of the machine learning algorithms for the purpose of automated identification, notification of these plans, but most only building effective computer vision and machine learning technique.",
                    "label": 1
                },
                {
                    "sent": "This is crucial for for bridging this taxonomical gap problem, it is crucial to have appropriate training data and so collecting computing appropriate training data is becoming one of the most central problems for solving the economic gap problem.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now you search, we're using the plant cube data set for this data set contains more than 100,000 images.",
                    "label": 0
                },
                {
                    "sent": "Some example images are shown on this slide.",
                    "label": 0
                },
                {
                    "sent": "This slide we are using two versions of this data set.",
                    "label": 1
                },
                {
                    "sent": "The version the version from 2014 and 2015 Plant Cliff competition.",
                    "label": 0
                },
                {
                    "sent": "The images from the test data set are from mom classes in this case and for the plant left for 2016.",
                    "label": 1
                },
                {
                    "sent": "We have a open world recognition problem in the test set we have images that are not planned on images that are images with plans that are from different classes that we have in the training set.",
                    "label": 0
                },
                {
                    "sent": "So the plant left 2016 is more and more challenging or data set so more challenging.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Problem some example images from this data set just to see how the images and the plans are diverse.",
                    "label": 0
                },
                {
                    "sent": "Their diverse taking into account the leaf.",
                    "label": 0
                },
                {
                    "sent": "We have coloration, global shape variation.",
                    "label": 0
                },
                {
                    "sent": "We have left margin variation, number of leaflets, variation, leafless relative position variation and so on.",
                    "label": 0
                },
                {
                    "sent": "So it's quite.",
                    "label": 0
                },
                {
                    "sent": "Quite leaf diversity.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If we.",
                    "label": 0
                },
                {
                    "sent": "If we analyze this flower images, we can see that there is also diversity.",
                    "label": 0
                },
                {
                    "sent": "The buffer between the Flowers present in this data set.",
                    "label": 0
                },
                {
                    "sent": "The flower is often the key to identify a specious of the plant, but as I mentioned, there is a great diversity within the Flowers of Flowers.",
                    "label": 0
                },
                {
                    "sent": "For the data set can be categorized according to the color to the Cemetery, to the structure, orientation and the size.",
                    "label": 0
                },
                {
                    "sent": "Also for one same species, the Flowers still have different colors, so this is even more.",
                    "label": 0
                },
                {
                    "sent": "Other, more challenging.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On this slide, slide some.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "What this slide?",
                    "label": 0
                },
                {
                    "sent": "We have some variation in the fruit table stem type, the entire plant in the branch.",
                    "label": 0
                },
                {
                    "sent": "Great diversity of the type of fruits that are better represented throughout the speeches of the plan.",
                    "label": 0
                },
                {
                    "sent": "View data set.",
                    "label": 0
                },
                {
                    "sent": "The stem is generally a difficult plant organ for identifying suspicious, maybe because the visual information is mainly expressed with texture, not color and shape, and because of the age of the plant the stem is changing through time.",
                    "label": 0
                },
                {
                    "sent": "So we have to take this into account also also this the entire view of the tree generally does not contain enough information.",
                    "label": 0
                },
                {
                    "sent": "So we cannot use it.",
                    "label": 0
                },
                {
                    "sent": "First, the purpose of plant identification, but surely can help.",
                    "label": 0
                },
                {
                    "sent": "You can help.",
                    "label": 0
                },
                {
                    "sent": "Combined with the other plant organs, very different appearance depending on the geographical and climatical condition condition.",
                    "label": 0
                },
                {
                    "sent": "This is for the entire plant and for the branch.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "From the images of this data set, we have a rich metadata.",
                    "label": 0
                },
                {
                    "sent": "The metadata is described here.",
                    "label": 0
                },
                {
                    "sent": "The most important part is observation ID.",
                    "label": 1
                },
                {
                    "sent": "The plan operation idea for, from which several picture can be associated with.",
                    "label": 1
                },
                {
                    "sent": "We have also here the species, genus, family, the data vault, the average of the user rating of the image quality locality, and so on.",
                    "label": 1
                },
                {
                    "sent": "Uh.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What is observation over plant is a set of 1 several images depicting the same individual plant observed, observed by the same person the same day.",
                    "label": 1
                },
                {
                    "sent": "We will say in the device there is example.",
                    "label": 0
                },
                {
                    "sent": "Here we have this plant and several images representing leaves and Flowers of these plans.",
                    "label": 0
                },
                {
                    "sent": "So all of these images will have the same observation ID and actually all of these images we can use later too.",
                    "label": 0
                },
                {
                    "sent": "Predict the species for this particular plant.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Some general information of the the two version of the of the data set for the plank left 2015.",
                    "label": 0
                },
                {
                    "sent": "Seven plant organs, 17th image content, flower fruit, fruit leaves.",
                    "label": 1
                },
                {
                    "sent": "Live scan, entire tree branches, theme stem and so on.",
                    "label": 0
                },
                {
                    "sent": "1000 plant classes.",
                    "label": 0
                },
                {
                    "sent": "More than 100,000 images for over 43,000 operation as I mentioned.",
                    "label": 1
                },
                {
                    "sent": "One of the nation 15 images of a plant and this is actually a multi query challenge.",
                    "label": 1
                },
                {
                    "sent": "We have to take into account all the images when classifying.",
                    "label": 0
                },
                {
                    "sent": "Come on observation.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For the blank left 2016, as I mentioned, the test data set is composed of unknown plants, vicious and normal plant objects.",
                    "label": 1
                },
                {
                    "sent": "To create an open world plant data set so we have recognized unknown class features, but also to reject downloading plans and the objects.",
                    "label": 1
                },
                {
                    "sent": "Also example images from this this.",
                    "label": 0
                },
                {
                    "sent": "Except these are the example images from the test set.",
                    "label": 0
                },
                {
                    "sent": "The train step is the same as the lamp class 2015.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "15 So that the.",
                    "label": 0
                },
                {
                    "sent": "Platelets 2016 is open center or open world recognition challenging testing computer vision as well as samples from how long classes could be present so we have to develop algorithm that is robust to unknown and never see an inventories.",
                    "label": 1
                },
                {
                    "sent": "So beyond the brute force classification across the known classes of the training set of big challenge, here is to automatically reject the foldable positive classification hits caused by the unknown classes and unknown object.",
                    "label": 1
                },
                {
                    "sent": "So image is present in the present in the data set.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The test set is composed of 8000 images.",
                    "label": 1
                },
                {
                    "sent": "Some of the images are labeled with one of the 1000 known classes of the training set.",
                    "label": 1
                },
                {
                    "sent": "The rest of the images are from unknown classes or even known plant images.",
                    "label": 0
                },
                {
                    "sent": "Among the first images that are that are labeled with known classes, they are 366 images stacked as invasive, according to a select list of potentially.",
                    "label": 0
                },
                {
                    "sent": "Invasive species",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That is the description of the datasets that we used in our experiments.",
                    "label": 0
                },
                {
                    "sent": "Now briefly overview of the plant edification approaches that were used before deep learning approach.",
                    "label": 1
                },
                {
                    "sent": "I will tell you something about English innovation, feature extraction, classification, and Fusion.",
                    "label": 1
                },
                {
                    "sent": "The image.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Imitation process can be crucial in the plant ification test becausw the image segmentation is trying to segment the main object and extract the regional feed interests and remove the relevant background which could introduce noise to our classifier that we are using different segmentation approaches for the different plan to organize we have to use brief.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Be about these segmentation approaches.",
                    "label": 0
                },
                {
                    "sent": "For example, for the flower and fruit images, if we attempted a flower or fruit is usually more red compared to the lives we can locate the region of which there red channel is larger than the green channels and later on each color image we can convert to a great value in each and the localized red regions are then employed as initial masking.",
                    "label": 1
                },
                {
                    "sent": "Nothing, anything the flower or fruit in the great value me choosing the active contour method.",
                    "label": 1
                },
                {
                    "sent": "Then we can compute the minimum bounding box of the flower or fruit.",
                    "label": 0
                },
                {
                    "sent": "The regional features do example images and the region of interest extracted from these images.",
                    "label": 0
                },
                {
                    "sent": "In so in the classification step we are using these images instead of the.",
                    "label": 0
                },
                {
                    "sent": "We are using this the small images instead of the entire image with the background.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This data set contain contains also release scans, either as simple images.",
                    "label": 0
                },
                {
                    "sent": "The lift is can't usually on the white background, but there is a variation among the background color for the segmentation purpose.",
                    "label": 1
                },
                {
                    "sent": "Here in this scenario we are no normalizing the background with the consistent.",
                    "label": 1
                },
                {
                    "sent": "Why follow later on we are converting the core images to a great value mission applied automatically to computer.",
                    "label": 0
                },
                {
                    "sent": "Shall the pixel values the floors official letter level this big around an old big big round pixel in the personal info images are signed with the white Board to example images images after the simple.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Quotation for the leaf images.",
                    "label": 0
                },
                {
                    "sent": "Because the leaf is usually located in the center area of the picture, there are typically some margin between the leaf boundaries and the picture border.",
                    "label": 1
                },
                {
                    "sent": "So we in this area.",
                    "label": 1
                },
                {
                    "sent": "In this case, we're just extracting the object that is located in the center of the of the pictures.",
                    "label": 0
                },
                {
                    "sent": "To remove them the background.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For the same images.",
                    "label": 0
                },
                {
                    "sent": "See similar as the leaf usually located in the center of language.",
                    "label": 1
                },
                {
                    "sent": "Compared the color image to Gray value image.",
                    "label": 0
                },
                {
                    "sent": "Credit created central Mask of the image by cropping percent from left to right.",
                    "label": 1
                },
                {
                    "sent": "The great value in each using this mask bounding box of the resulting idea to obtain the region of interest for the steam image.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, what we have done.",
                    "label": 0
                },
                {
                    "sent": "The user segmentation then we are proceeding with the next step.",
                    "label": 0
                },
                {
                    "sent": "The feature extraction step.",
                    "label": 0
                },
                {
                    "sent": "In this step we are using basically some of the feature that on the way already mentioning his presentation, we're using her local feature extraction around here, just pointing the segmented images.",
                    "label": 1
                },
                {
                    "sent": "Some example in some example of feature extraction methods that can be used our rotation invariant invariant local band.",
                    "label": 0
                },
                {
                    "sent": "Binary partners still inviting future can storm the speedup fahrion surf full of food at his program.",
                    "label": 0
                },
                {
                    "sent": "Instrumentation histogram.",
                    "label": 1
                },
                {
                    "sent": "Some variants of the histogram in different color spaces and so on when where we have the local features, we can construct a visual index of this local features.",
                    "label": 0
                },
                {
                    "sent": "For example, if you're computing the local features from the training images.",
                    "label": 0
                },
                {
                    "sent": "Then we can compress and index them using for example random maximum margin, fishing, tehnika stables and later on for each local features from feature from the query image we compressed it with this.",
                    "label": 1
                },
                {
                    "sent": "With this caching then approximative K means neighbors or search probing multiple neighboring buckets in the hash tables to obtain the panel list of most relevant images for this query.",
                    "label": 0
                },
                {
                    "sent": "For this query image.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Besides the doing this, we can also construct the standard bag of visual words.",
                    "label": 0
                },
                {
                    "sent": "You can use the standard bag of visual words approach.",
                    "label": 0
                },
                {
                    "sent": "We can construct us.",
                    "label": 0
                },
                {
                    "sent": "We can construct for example visual codebook for each plant organ.",
                    "label": 1
                },
                {
                    "sent": "For doing this we can use.",
                    "label": 0
                },
                {
                    "sent": "For example K means or approximative K means or predicted or even predicted clustering trees if we have many number of local strip clubs and if we are clustering.",
                    "label": 0
                },
                {
                    "sent": "These local distributors seen many clusters or visual words.",
                    "label": 0
                },
                {
                    "sent": "We cannot experience experiments using Approximative Kings.",
                    "label": 1
                },
                {
                    "sent": "Also, predictive clustering trees later on we can use the term frequency inverse document frequency.",
                    "label": 0
                },
                {
                    "sent": "Some normalization normalization to count the similarities between these images.",
                    "label": 1
                },
                {
                    "sent": "Also besides the bag of visual words, we can use the feature parallel feature coding.",
                    "label": 0
                },
                {
                    "sent": "We can compute losing richer models in the SIFT.",
                    "label": 0
                },
                {
                    "sent": "The space that this alternative to the bag of visual words approaching these are the local feature extraction techniques that thing that can be used.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Can also use some feature extraction techniques that are global that they take into account the entire the entire image.",
                    "label": 0
                },
                {
                    "sent": "Entire picture.",
                    "label": 0
                },
                {
                    "sent": "For example, we have the multi scale triangle shape.",
                    "label": 0
                },
                {
                    "sent": "Descriptor that can that is.",
                    "label": 0
                },
                {
                    "sent": "Validated on variously database, very robust and fast to compute.",
                    "label": 1
                },
                {
                    "sent": "It is used for local makes, mention of shapes and that's why it is best for the images with Leafs.",
                    "label": 0
                },
                {
                    "sent": "How it briefly, how it is computed, the shape boundary is represented with a sequence sequence on of sampling points which are uniformly distributed over the contours.",
                    "label": 1
                },
                {
                    "sent": "Another thing the code base in order for example, and then for each point each point actually is represented by a.",
                    "label": 1
                },
                {
                    "sent": "383 angles computed at different different different scales.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The classification algorithms we can use.",
                    "label": 0
                },
                {
                    "sent": "And then classifier we can build for example for example 7 classifier for the seven different plant organs.",
                    "label": 0
                },
                {
                    "sent": "We can use support vector machines.",
                    "label": 1
                },
                {
                    "sent": "We can use different similarity metrics.",
                    "label": 0
                },
                {
                    "sent": "Is crucial to use some sort of Fusion scheme to obtain the final prediction.",
                    "label": 1
                },
                {
                    "sent": "We cause.",
                    "label": 0
                },
                {
                    "sent": "Usually we have many feature descriptors also seven classifiers.",
                    "label": 0
                },
                {
                    "sent": "So somehow to obtain the the classes for the observation we have to fuse these different predictions from the different feature extraction methods and from the different from the different classifiers.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Summary of this approach is.",
                    "label": 1
                },
                {
                    "sent": "As I mentioned, these approaches are before the before the start, before deep learning applied to the planning signification problem.",
                    "label": 0
                },
                {
                    "sent": "If you want to use something that is not declaring the best choice would be Fisher.",
                    "label": 0
                },
                {
                    "sent": "Vector encoding contain state of the art results results.",
                    "label": 0
                },
                {
                    "sent": "Extract benefits and polar moments in the images to produce each local feature to a 60 four dimension dimensions after using PCA.",
                    "label": 1
                },
                {
                    "sent": "Estimated using mixture models, for example with five current until components to produce the Fisher vector representation for the images, and then as a classifier to use them.",
                    "label": 1
                },
                {
                    "sent": "Linear SVM, one for each side of the future.",
                    "label": 0
                },
                {
                    "sent": "Features the seat and the.",
                    "label": 0
                },
                {
                    "sent": "Polar moments this is the paper that describes this.",
                    "label": 0
                },
                {
                    "sent": "This is set up.",
                    "label": 0
                },
                {
                    "sent": "The results are about 40% of miniature precision.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And now something about the deep learning approach.",
                    "label": 0
                },
                {
                    "sent": "You know that thing deep.",
                    "label": 0
                },
                {
                    "sent": "Learning the raw data data is fit into the convolutional neural network in multiple levels.",
                    "label": 1
                },
                {
                    "sent": "Evolution of neural network automatically discover, discover, Skype level features or plant which is recognition.",
                    "label": 1
                },
                {
                    "sent": "The deep learning approaches Sky computational complexity to be trained from scratch, and that's why usually we're using pre trained networks that are fine tuned for plant identification purposes.",
                    "label": 0
                },
                {
                    "sent": "For example, we're using.",
                    "label": 0
                },
                {
                    "sent": "CNET or Google Maps to.",
                    "label": 0
                },
                {
                    "sent": "That are pre trained on the large image set and later on we are fine tuning them for the purpose of plant plant identification purposes.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The first step is that we are going in the deep learning approaches, day termination date of meditation.",
                    "label": 0
                },
                {
                    "sent": "We're applying data augmentation to decrease the chance of overfitting during training and to improve the performance of them of the convolutional neural networks.",
                    "label": 1
                },
                {
                    "sent": "Actually with the with the data innovation, we're increasing the data set size.",
                    "label": 0
                },
                {
                    "sent": "We're doing artificial expansion of the data set.",
                    "label": 0
                },
                {
                    "sent": "Using accommodation by rotation by mirroring quest curing.",
                    "label": 0
                },
                {
                    "sent": "All sorts of different augmentation techniques can be used to artificially expand the the initial data set.",
                    "label": 1
                },
                {
                    "sent": "The white spaces after the mentation or filled with the latest set mean value.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some example image via the initial image and the image obtain after the rotation augmented image.",
                    "label": 0
                },
                {
                    "sent": "The white spaces are filled with the data set mean value.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then augmentation by mirroring.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In augmentation by skewing.",
                    "label": 0
                },
                {
                    "sent": "In this way, we are enlarging the training data set data set that we are.",
                    "label": 0
                },
                {
                    "sent": "We are going to use for training for fine tuning to classify.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is the overall overall.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "System architecture we have the initial training set and test set.",
                    "label": 0
                },
                {
                    "sent": "The training set is.",
                    "label": 0
                },
                {
                    "sent": "Through the application model module.",
                    "label": 0
                },
                {
                    "sent": "To obtain the Elemental train set with artificially added images, we are using the Google Maps Model 3 training on the large set of images, 40,000,000 images from image net.",
                    "label": 0
                },
                {
                    "sent": "If you are fine tuning this model with the elemented.",
                    "label": 0
                },
                {
                    "sent": "Documented datasets from the from the Plant Review.",
                    "label": 0
                },
                {
                    "sent": "We are obtaining the predictions and in the later phase we are using some sort of Fusion to take into account the images in the observation and we're doing some evaluation and presenting that final result.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Results.",
                    "label": 0
                },
                {
                    "sent": "This is the global net model that we used in this application as a nation is pre trained on the image.",
                    "label": 0
                },
                {
                    "sent": "Net data set implemented in the fake convolutional neural network with 27 layers we take into account the inception layers.",
                    "label": 1
                },
                {
                    "sent": "Receptive field is 224 by 224 images that are in the energy color space and as I mentioned we have inception architecture.",
                    "label": 0
                },
                {
                    "sent": "We have accept.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Inception architecture in this model, the inception model in the convolutional neural network are designed to allow for deeper, larger convolutional layers, while at the same time allowing for more efficient computations.",
                    "label": 1
                },
                {
                    "sent": "How is this done?",
                    "label": 1
                },
                {
                    "sent": "This is done by using one by one convolution convolutions with small feature map size example here.",
                    "label": 0
                },
                {
                    "sent": "190 two, 28 by 28 sites feature Maps can be reduced to 6428 by 28 future Max 264 one by one convolution because of the reduced size.",
                    "label": 0
                },
                {
                    "sent": "This one by our convolution can be follow up with larger convolution conclusions for size 3 by 3 or 5 by 5 by 5 in the output of the reception module.",
                    "label": 0
                },
                {
                    "sent": "All the.",
                    "label": 1
                },
                {
                    "sent": "Large convolutions are concatenated into a big feature map, which is then fed into the next layer of the of the convolutional neural net.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The Google Maps layer Sir presented here.",
                    "label": 0
                },
                {
                    "sent": "You can see the convolutional layers.",
                    "label": 0
                },
                {
                    "sent": "The Max pooling layers, the inception layers and in the later the last layer is the softmax layer.",
                    "label": 0
                },
                {
                    "sent": "You can see also here the output size of each layer, also the parameters.",
                    "label": 0
                },
                {
                    "sent": "Oh, did we obtain each of these layers?",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Some experiments first.",
                    "label": 0
                },
                {
                    "sent": "Experiments to see how the data set size and the diversity of the data set data set to impact the classification performance.",
                    "label": 1
                },
                {
                    "sent": "Then we also did some experiments to see how the data argumentation impact the overall performance of of our.",
                    "label": 0
                },
                {
                    "sent": "Approach.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Power system these are the experiments.",
                    "label": 0
                },
                {
                    "sent": "Here we are using the volumes for the 2014 and plan 2015 data set several experiments only using Google, Google Maps, Google Maps, model train from scratch using the plant 2014 data.",
                    "label": 0
                },
                {
                    "sent": "Set up your Google Maps only on the image net not fine tuned on the plan data set Google Net on Image net and.",
                    "label": 0
                },
                {
                    "sent": "Fine Tune complaint 2014 Google Net retrain from image net.",
                    "label": 0
                },
                {
                    "sent": "Fine tuned with the difference.",
                    "label": 0
                },
                {
                    "sent": "Expand Expanded datasets using them, augmentation methods, and in the last the last experiment, experiment with using the Google Net.",
                    "label": 0
                },
                {
                    "sent": "Jeanette, but fine tunes on the plants 2015.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sets the results as I as as to be expected.",
                    "label": 0
                },
                {
                    "sent": "If you're using your Google Maps not fine tune on the planet data set we are obtaining.",
                    "label": 0
                },
                {
                    "sent": "Very low.",
                    "label": 0
                },
                {
                    "sent": "Accuracy very little, very bit resolve.",
                    "label": 0
                },
                {
                    "sent": "These are the results if we are using.",
                    "label": 0
                },
                {
                    "sent": "If you're using convolutional neural network training from scratch using only the plant 2014 data set, the results are between 18%.",
                    "label": 0
                },
                {
                    "sent": "This is the Google net trained on image net training, retraining, Connect and fine tune with the images from.",
                    "label": 0
                },
                {
                    "sent": "Left 2014 you can see that boosting.",
                    "label": 0
                },
                {
                    "sent": "Mercy.",
                    "label": 0
                },
                {
                    "sent": "The first images only take into account.",
                    "label": 0
                },
                {
                    "sent": "If we if we have the correct label for the first image, so we are.",
                    "label": 0
                },
                {
                    "sent": "We are prisoners.",
                    "label": 0
                },
                {
                    "sent": "Google net on the image net pre training and plan 2014.",
                    "label": 0
                },
                {
                    "sent": "See the boosting the performance compared to the Google Maps trained from scratch from this data set.",
                    "label": 0
                },
                {
                    "sent": "If we compare the performance of the augmented data sets sets, we can see that if we augmented the data set then we obtain further improvement of the performance compared to the original original data set.",
                    "label": 0
                },
                {
                    "sent": "If we use them.",
                    "label": 0
                },
                {
                    "sent": "Plant 2015 data set we are obtaining.",
                    "label": 0
                },
                {
                    "sent": "We are the difference between the.",
                    "label": 0
                },
                {
                    "sent": "Then 2014 and plan 2015 is dead.",
                    "label": 0
                },
                {
                    "sent": "The plan 2015 has 1000 classes and the plan 2014 has 500 classes.",
                    "label": 0
                },
                {
                    "sent": "So this data set is actually bigger than this data set.",
                    "label": 0
                },
                {
                    "sent": "We are training on the we are training the fine tuning the network on the these data set, but we are testing on on the plans 2014.",
                    "label": 0
                },
                {
                    "sent": "I wanted to ask so if you have 500,000 plus is so accuracy 45% is quite good.",
                    "label": 0
                },
                {
                    "sent": "Would you check?",
                    "label": 0
                },
                {
                    "sent": "So, did you try measuring the accuracy in North or identifying each individual species, but instead seeing if the genus is correct?",
                    "label": 0
                },
                {
                    "sent": "No, we have not taken into account here here that economy afraid you're only interested in the in the lower.",
                    "label": 0
                },
                {
                    "sent": "I would guess people would be interested in that as well.",
                    "label": 0
                },
                {
                    "sent": "It might be much, much better perhaps.",
                    "label": 0
                },
                {
                    "sent": "Actually, we we we are playing this for the framework we are.",
                    "label": 0
                },
                {
                    "sent": "We are somehow trying to incorporate the hierarchy of the excellent into the learning process.",
                    "label": 0
                },
                {
                    "sent": "Some count, but we haven't done that yet.",
                    "label": 0
                },
                {
                    "sent": "We are planning to do that.",
                    "label": 0
                },
                {
                    "sent": "So when you say you're fine tuning Imagenet.",
                    "label": 0
                },
                {
                    "sent": "You're throwing away the last layer.",
                    "label": 0
                },
                {
                    "sent": "Keeping the weights from Imagemaps very trainable.",
                    "label": 0
                },
                {
                    "sent": "So have you tested how much though?",
                    "label": 0
                },
                {
                    "sent": "The weights of the lower level are actually changing.",
                    "label": 0
                },
                {
                    "sent": "Or is it just that you are just living a different classifier on the representation of engagement?",
                    "label": 0
                },
                {
                    "sent": "And what happens if you run like?",
                    "label": 0
                },
                {
                    "sent": "Super vector machine on the on.",
                    "label": 0
                },
                {
                    "sent": "The representation for measurement if we run without, you know.",
                    "label": 0
                },
                {
                    "sent": "Doing backpropagation and we have done that, but the results are worse, much worse.",
                    "label": 0
                },
                {
                    "sent": "Maybe by I don't know.",
                    "label": 0
                },
                {
                    "sent": "I don't know the exact number, so I think by 50% or maybe worse, OK?",
                    "label": 0
                },
                {
                    "sent": "That's why we decided to use this new setup.",
                    "label": 0
                },
                {
                    "sent": "The results were similar with the the other approaches that I mentioned before.",
                    "label": 0
                },
                {
                    "sent": "The linear SVM instrumentation.",
                    "label": 0
                },
                {
                    "sent": "The whole message as official Victor performed here, sorry.",
                    "label": 0
                },
                {
                    "sent": "You're not deep learning.",
                    "label": 0
                },
                {
                    "sent": "It was interesting in the 2014 competition.",
                    "label": 0
                },
                {
                    "sent": "The Fisher vector encoding using linear SVM's was the best ranked.",
                    "label": 0
                },
                {
                    "sent": "Result it was around 50% I think in the final scoring and the same team applied also deep learning deep learning the results from different learning more about 20 or so percent so.",
                    "label": 0
                },
                {
                    "sent": "But in the next year most of the team started using only deep learning and the results increased quite for this year.",
                    "label": 0
                },
                {
                    "sent": "The best result is.",
                    "label": 0
                },
                {
                    "sent": "80%.",
                    "label": 0
                },
                {
                    "sent": "Quiting increase compared to the previous years.",
                    "label": 0
                },
                {
                    "sent": "We participated in.",
                    "label": 0
                },
                {
                    "sent": "2014 and we did not manage to submit the results for 2015, but if we have submitted we would view rank type thing.",
                    "label": 0
                },
                {
                    "sent": "Second transfer.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is the learning curve.",
                    "label": 0
                },
                {
                    "sent": "Increase of accuracy and the increase of the loss during the training process and want to get into details.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here it was interesting as I mentioned, for the planet left 2016.",
                    "label": 0
                },
                {
                    "sent": "The organizers of this competition includes unknown classes.",
                    "label": 0
                },
                {
                    "sent": "You just normal classes and normal plant images in the test data set.",
                    "label": 0
                },
                {
                    "sent": "So for this particular competition we have to somehow.",
                    "label": 0
                },
                {
                    "sent": "First, separately Finetune Googlenet model for a binary classification problem.",
                    "label": 1
                },
                {
                    "sent": "For example plan versus non plant images.",
                    "label": 0
                },
                {
                    "sent": "For this set up the training data data set contains plant images from life 2015 unknown plant images for the floor scale competition and using the results for results from the binary classifier, we can reject the images that are classified classified as non plant images.",
                    "label": 1
                },
                {
                    "sent": "Unassign a low confidence scoring data in the final main plant indication indication system.",
                    "label": 0
                },
                {
                    "sent": "So first we are training.",
                    "label": 0
                },
                {
                    "sent": "A binary classifier that can distinguish two classes, plant versus non plants.",
                    "label": 0
                },
                {
                    "sent": "Then we are using the same setup as previous but we are decreasing the probabilities.",
                    "label": 0
                },
                {
                    "sent": "We are signing bonus for for this images that are classified classified as non plant images in the in the final.",
                    "label": 0
                },
                {
                    "sent": "In the final result.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It is interesting here that the degree of novelty in the test set is a strong influence on the performance.",
                    "label": 1
                },
                {
                    "sent": "For example, in this year, blank left 2016 competition when 25% of the various still belong to a known class.",
                    "label": 0
                },
                {
                    "sent": "None of the system region mean average precision greater and greater than.",
                    "label": 0
                },
                {
                    "sent": "C Zero point 45 compared to the zero point 83 in the closed world world.",
                    "label": 0
                },
                {
                    "sent": "Set up where the classes in the training images are from the.",
                    "label": 0
                },
                {
                    "sent": "You may just need the test data set data set are.",
                    "label": 0
                },
                {
                    "sent": "With the classes from the training data set, so this is quite quite a problem in a real case scenario this number is much more 'cause if the user has a mobile phone and it goes and.",
                    "label": 0
                },
                {
                    "sent": "Take take picture of everything and submitted the queries.",
                    "label": 0
                },
                {
                    "sent": "The number, the number of of this number will be will be much lower, so the performance is it is can be decorated even even more so this is this is quite a quite a problem that have to be solved, solved in the plans magnification task.",
                    "label": 0
                },
                {
                    "sent": "Additional.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Problems that we have here is that the original net model requires input image of facial size to convert 24 by 224.",
                    "label": 1
                },
                {
                    "sent": "The images in the planet left versions are arbitrarily sized so.",
                    "label": 1
                },
                {
                    "sent": "Following the specialized restriction in Google Maps, model input images gets to be either copper or.",
                    "label": 0
                },
                {
                    "sent": "Formation loss there is.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Solution for this problem?",
                    "label": 0
                },
                {
                    "sent": "We haven't tried this yet.",
                    "label": 0
                },
                {
                    "sent": "We can use spatial spatial pyramid pooling layer.",
                    "label": 1
                },
                {
                    "sent": "The feature we can divide a feature map spatially into one by one 2 by 4 by 4 in total 51 region.",
                    "label": 0
                },
                {
                    "sent": "Then each region can be average pulled producing a vector of pick sides.",
                    "label": 1
                },
                {
                    "sent": "For example, if we have 5020 generals in the last convolutional litteraire, you're paying a vector of fixed size 1010 thousand 77155.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "55 scalars in that vector.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "This conversion of arbitrary size feature mapping to the into a fixed size vector or allow the model to accept input image obtaining size.",
                    "label": 1
                },
                {
                    "sent": "We can skip that step when we are processing the images in the fixed.",
                    "label": 0
                },
                {
                    "sent": "Sized",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Make some conclusions and further work.",
                    "label": 1
                },
                {
                    "sent": "Mushel neural networks.",
                    "label": 1
                },
                {
                    "sent": "Three training on large datasets set and fine tuned on Tao.",
                    "label": 0
                },
                {
                    "sent": "Commented datasets to the specific domain to get the best way to get the best results is is our recommendation, but the convolutional neural network is strongly affected by the higher rates of images belonging to unknown class, so we have to find the solution for this.",
                    "label": 1
                },
                {
                    "sent": "We are as a further work we are.",
                    "label": 0
                },
                {
                    "sent": "We will definitely try different.",
                    "label": 0
                },
                {
                    "sent": "Set up soft revolutional neural network.",
                    "label": 0
                },
                {
                    "sent": "Somehow we can create an example of convolutional neural network networks with different set up with different convolutional layer and so on.",
                    "label": 1
                },
                {
                    "sent": "And then we can combine the tradition to increase the classification performance.",
                    "label": 0
                },
                {
                    "sent": "We are also planning to somehow combines a handcrafted features into the feature features obtained into the convolutional neural networks.",
                    "label": 0
                },
                {
                    "sent": "We are we have done another application similar to this but in that application we had only lift images and it was quite interesting.",
                    "label": 0
                },
                {
                    "sent": "The results were quite interesting.",
                    "label": 0
                },
                {
                    "sent": "Some of the classes that are very that were very difficult to be distinguished even looking by I from.",
                    "label": 0
                },
                {
                    "sent": "I don't know by some expert were correctly classified by the convolutional neural network and some of the images that were quite distinct.",
                    "label": 0
                },
                {
                    "sent": "Were wrongly classified by then convolutional neural network.",
                    "label": 0
                },
                {
                    "sent": "In this case, if we have applied standard conventional methods, feature extraction methods.",
                    "label": 0
                },
                {
                    "sent": "Location methods them.",
                    "label": 0
                },
                {
                    "sent": "These images would be correctly classified so we can somehow combine the hand crafted features and the convolutional neural networking in order to eliminate these problems.",
                    "label": 0
                },
                {
                    "sent": "Also we are.",
                    "label": 0
                },
                {
                    "sent": "We can also try to use them higher here of the taxonomy into in the convolutional neural networks too.",
                    "label": 0
                },
                {
                    "sent": "Do something to somehow boost the overall performance of.",
                    "label": 0
                },
                {
                    "sent": "Of this approach.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's see.",
                    "label": 0
                }
            ]
        }
    }
}