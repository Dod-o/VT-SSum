{
    "id": "bg7noucqxy5o42ngxznzxte7ifuzq5gd",
    "title": "An Overview of Deep Learning and Its Challenges for Technical Computing",
    "info": {
        "author": [
            "Graham Taylor, School of Engineering, University of Guelph"
        ],
        "published": "Oct. 13, 2014",
        "recorded": "September 2014",
        "category": [
            "Top->Computers->Software->Open-Source Software",
            "Top->Computers->Programming->Python",
            "Top->Computer Science->Optimization Methods",
            "Top->Computer Science->Programming Languages",
            "Top->Computer Science->Machine Learning",
            "Top->Mathematics"
        ]
    },
    "url": "http://videolectures.net/tcmm2014_taylor_deep_learning/",
    "segmentation": [
        [
            "This, I guess, begins a day on deep learning and Pascal is going to speak after me and he's going to focus on some of the tools for building deep learning style models, so I'm going to start the day by giving an overview of several of the different deep learning architectures, and this tutorial is aimed at going to cover the grounds for people that don't know anything about deep learning.",
            "So if you're already a deep learning expert, I apologize for.",
            "Going through some of these basic models, but is designed as a tutorial and please feel that feel free to ask questions as I move along."
        ],
        [
            "So."
        ],
        [
            "So the way that I'm going to structure this tutorial this morning is I'm going to start by giving some motivations by deep up deep learning, and I think one of the reasons we're here and we're talking about it is because there's been some tremendous gains in the last few years, so I'll talk about why these gains have happened and put it in context and talk about why it's worth studying.",
            "Deep learning.",
            "Is this just another trend?",
            "Is another sort of peak in the peaks and valleys of neural networks, or is this something we're going to be talking about for awhile?",
            "Next I'm going to go onto."
        ],
        [
            "To specific methods, and so I'm going to spend probably about 60% of the time talking about actual deep learning models.",
            "Anne."
        ],
        [
            "And cover the covering them in both.",
            "The paradigms are supervised and unsupervised learning, and then because it's a technical computing workshop, I'm going to focus on some of the technical challenges that are raised by deep learning and not talk a whole lot about that."
        ],
        [
            "But I'm going to give some pointers to some of the tools, and then Pascoe lamblin after after my talk will actually go through and talk to you about some of the Python based frameworks for building deep learning models.",
            "OK, so let's talk."
        ],
        [
            "Graph about learning, talking about learning representation, representation, learning is something that's.",
            "Underlying deep learning and the idea of learning representations is that we want to extract concepts or abstracts that are present in the data and these make us help us make sense of the variability that exists in data.",
            "So a lot of methods have proposed ways of engineering or handcrafting desirable features for data.",
            "These features are often designed to be sensible or sensitive to variables of interest, but remain insensitive to other factors which explain variability.",
            "So for example, noise in the data.",
            "So what differs representation?",
            "Learning from a lot of the existing feature extraction methods out there is that the features themselves are learned from the data extracted automatically, and I'll talk a little bit more about why we might want to do that."
        ],
        [
            "OK, so it pictured at top here is an architecture called a convolutional neural net and this is essentially the current hammer of deep learning.",
            "Everybody is applying this in particular in the vision community because this is a model that's designed specifically for 2D data.",
            "There are one variations of comments, so they can be applied to, for example, audio data as well, but most of the success has been found in vision, community and.",
            "There's a few motivations here for why we might want to study this model, like why is this not just to try anything that we're talking about now?",
            "Why is it something might consider for the future?",
            "And certainly there's theory out there that tells us there are certain classes of problems and certain functions that are more efficiently expressed as a series of K layers.",
            "An if we would want to represent these functions as just a two layer problem, we could do it, but it would take exponentially more.",
            "Variables to do so, so certain classes of problems are just more efficiently represented by multiple layers.",
            "Of course, as humans, we will often take problems and break them down so we can understand them by studying the smaller pieces.",
            "So composition is something that comes natural to us.",
            "Engineers will take problems and break them into pieces and analyze them individual and individually, and build up abstractions from these concepts.",
            "So it's something that's native to human organization and thought.",
            "And finally, I'm going to make just a very weak link to biology here.",
            "The models that we talk about, and especially the types of models that I'm going to be discussing today, are very, very loosely connected to biology, but certainly the brain is deep and use mostly uses multiple layers of representation, and so there is a biological motivation and you'll see work in the deep learning community.",
            "That's even more motivated by biology and closer, closer connected to biology."
        ],
        [
            "OK, so just to give an overview of what's happened in recent years, I just like to put some major milestones."
        ],
        [
            "In front of you.",
            "So I would say that the current deep learning wave started in sometime around 2006 when people began to pre train and stack restricted Boltzmann machines.",
            "So this was the rise of a model called deep belief networks and people within the Community got very excited about that.",
            "At that time it was it was found that networks could be very deep.",
            "Networks could be trained and optimized more efficiently by first using unsupervised learning procedures.",
            "Learning the layers one at a time and then doing some fine tuning for a discriminative or super supervised task.",
            "This got a lot more people interested in the problem working on neural networks again."
        ],
        [
            "And ideas technical ideas were explored, sort of in the years between 2006 and 2012.",
            "So when I idea that I'll talk about today is the idea of rectifier units, this is an alternative type of non linearity for networks.",
            "Instead instead of the traditional sigmoid style functions are Tan, H is.",
            "There's other ideas like dropout.",
            "Maybe some of you have heard about some of these technical innovations were put forward and used for more efficiently training neural network."
        ],
        [
            "It was actually the speech community that latched on to these models even before the vision community, so in terms of the.",
            "The commercial impact some of the major speech groups like IBM, Microsoft and Google started using some of these deep learning models and actually experienced pretty major gains.",
            "And there's some review papers written where a bunch of these groups from competing companies have come together and talked about the impact that deep learning systems have made on their recognizers.",
            "There was a major breakthrough in 2012 and this is when Alex Kryszewski, who is a student at U of T trained convolutional neural net like the one I just pictured on a data set called Image Net.",
            "And what was significant about that is that image Net was not amnist.",
            "OK so Emnace is a favorite data set of neural Nets.",
            "People been used for many years has about 60,000 examples and the images are very small or 28 by 28.",
            "Image net has much larger images or different sizes, but it's not really even the resolution of the image is.",
            "It's the fact that there's over a million images in image NET.",
            "OK, so so Alex had really scaled up neural Nets and this one over a lot of critics and people that were skeptical of deep learning.",
            "And so he showed that a large scale visual recognition task could be approach using deep learning method and he actually ended up winning this competition.",
            "And winning a lot of people over the image that had a thousand categories as well.",
            "So it was a much more challenging classification task then say digit recognition.",
            "But this got a lot more people working on deep learning problems and excited about it.",
            "And you'll see this in the ensuing years like Google and Baidu and Facebook making talent acquisitions in this area an lot.",
            "Really latching on the deep learning."
        ],
        [
            "Where we are right now is in the midst of a sort of a deep learning wave and a lot of hype being spread at the CPR 2014 conference, which just happened this past June.",
            "There was actually a separate session devoted to compenents, which I'll talk about today in more depth, but that just shows, you know, at a mainstream vision conference people are really believing in these models now and returning to them even though they've been around for a long time.",
            "But we're seeing another wave.",
            "OK, so.",
            "Let's talk about."
        ],
        [
            "So it's traditional visual recognition versions versus deep learning, so typically visual recognition goes like this."
        ],
        [
            "We have some input data we extract."
        ],
        [
            "A bunch of low level vision features so things like sift descriptors, hog descriptors, local binary patterns or so forth, and then we do some operations that are nonlinear.",
            "We may be quantized them, or we pull them and we build a vector representation from that."
        ],
        [
            "And we feed this vector representation to powerful machine learning model like a support vector machine.",
            "And the point here is that all of the learning is placed into the into the third stage here.",
            "OK into the SVM for example so.",
            "What's happening here is in the feature extraction stage, there's no learning at all, and So what deep learning is all about is putting learning into these stages right here.",
            "The."
        ],
        [
            "The computer vision community has worked very hard on engineering different types of feature descriptors.",
            "There's a few popular ones that I mentioned before up here.",
            "There's obviously many more, and feature extraction is indeed very important.",
            "So if you look at some work though."
        ],
        [
            "A few years ago by Debbie Parekh and Larry Zitnik at Microsoft, they have a couple of CPR papers where they've essentially looked at a vision pipeline and tried to judge which part of that is most important.",
            "So what they're doing is they're doing something called an ablation study.",
            "So if you consider the first one, they essentially they look at the amount of training data, the learning algorithm, and the features that are involved in the recognition task.",
            "And here they're looking at multiple recognition tests.",
            "And they essentially take.",
            "The machine out of the picture and insert a human via Amazon Mechanical Turk and when they do this, when they replace each of these stages with with a human, they find that it's actually the feature extraction that's more important than the algorithm itself, or even the amount of training data.",
            "OK, they fold up this with another study where they don't look at sort of a very broadview, but they look at a specific algorithm and in the follow up paper a year later they look at a very specific problem.",
            "Which person detection.",
            "And they look at a specific model, which is a deformable part model.",
            "So this is a very popular vision based architecture and at each stage of this deformable part model again they do the same thing.",
            "They take out the machine learning component and they insert a human and so they do this with feature extraction part based extraction.",
            "The spatial model stage where they assemble the parts into full components and then something called non maximal suppression and what they found here is that.",
            "It was the part extraction of the part detectors, which were most sensitive to taking the machine out and putting the humans in OK.",
            "So in other words, the humans were really able to improve over the machines when we stuck them in as human part detectors and not machine learning based part detectors.",
            "So what does that mean?",
            "So it means."
        ],
        [
            "These part detectors are are very important to visual recognition tests and part detectors represent something called mid level representations, so these can be things like continuations or parallelism or junctions or corners is after the stage of, for example, edge detection at the very bottom of one of these networks and object parts so little bits of bicycles or cellos orbits of human faces.",
            "These are very difficult to describe with.",
            "A program OK so you can write a simple filter, a program to do edge detection, but if you want to write a part of a bicycle wheel detector and get it right and be invariant to all kinds of different makes and models and sizes and views of bicycles, that's very difficult to hand engineer.",
            "Alright, So what we'd like to do is, since part detection is very important part of a visual recognition algorithm, can we improve on just writing programs that describe what a nose or an I?",
            "Should look at and.",
            "This is the motivation to learn not only low level, but mid level representations as well.",
            "OK, so the."
        ],
        [
            "The typical deep learning approach looks something like this.",
            "We have multiple layers of feature extraction.",
            "OK, so down here would be the low level feature extraction component, which typically will extract things like edges.",
            "Here is where mid level and high level parts start to be extracted.",
            "An then after we've fed the output of each layer to the next layer to extract features.",
            "Then we apply a classifier.",
            "But what's happening compared to what we looked at before is we're not just training the classifier.",
            "We're training all of these stages together.",
            "OK, so typically using something called the backpropagation algorithm, which I'll talk about.",
            "We actually compute some errors here, and we update the parameters of all these models at the same time in order to decrease our loss up here.",
            "And this is also called end to end feature learning."
        ],
        [
            "So to get a specific example of what's happening here, let's look at the problem of learning some features on images of peoples faces.",
            "OK, so this data set is purely made up of cropped faces, like the one that you see here.",
            "You take a region of an image you feed it into one of these feature extraction algorithms, and when I said those three stages that we just looked at before, these are the types of filters that emerged.",
            "So these have all emerged automatically.",
            "We haven't had to write any programs for my detectors or noted.",
            "Noise detectors, I'll point out this is actually using a type of learning which is an unsupervised learning architecture, so that's why these look so nice.",
            "OK, so typically when you're when you're learning supervised neural Nets, you don't get very crisp.",
            "Decompositions of the sort that you see here.",
            "But you'll see that this model is actually extracted edges to little bits of faces, and then at the very top.",
            "Here we're seeing full faces, and this is probably at this time got a lot of people excited about.",
            "Unsupervised deep learning just because of the visual quality of these filters, it really represented something close to what humans would describe if they, if they were to describe a face built up of its constituent parts.",
            "OK."
        ],
        [
            "So sure, these features look nice and they align with the decomposition that a human might make of a face.",
            "So what's beyond that?",
            "Beyond extracting some nice looking features, what's the point?",
            "Well, in less few years these deep learning models have actually.",
            "Seated the performance of a lot of traditional architectures, so it's the performance is actually getting a lot of people excited.",
            "Image that is an example of a competition that's been one by one of these feature learning algorithms.",
            "There's an appealing property of these algorithms that it should be easy to extend them to other domains, and people are actually starting to work with RGB plus D data from things like the Connect video.",
            "There's been several methods proposed on working with video I've worked on that myself and.",
            "We're also interested in working with other types of data like multispectral or hyperspectral, and we don't need to design new features for these platforms which is difficult to do.",
            "We can simply apply these strategies directly to them.",
            "The other argument is that if you're using a traditional feature extraction approach in which we're using engineered features, each of those feature extraction stages may take a long time to do OK, so if we're going to run dozens of features and extract them if they're all different, this is going to be prohibitive for large datasets.",
            "Whereas these deep learning models tend to extract the same type of feature even though they're extracting 100 or 1000 features, the way that they're being extracted with the exact same, so they're very amenable to parallelization.",
            "And we'll talk about parallelization strategies a little bit later on.",
            "OK, so."
        ],
        [
            "I'm going to talk about two different paradigms.",
            "You know, for those of you who are here from the machine learning component of the workshop, you obviously know about supervised and unsupervised learning.",
            "So the point here is that we can apply supervised feature learning strategies in cases where there's a lot of labeled data available.",
            "But there's also a number of.",
            "Let's just say maybe less popular, less recognized approaches for doing unsupervised feature extraction, but they're important, especially in cases where there isn't a lot of data.",
            "Available."
        ],
        [
            "OK, so.",
            "That's the beginning, and that's the end of the motivation component of this talk.",
            "The next, the next person be actually talking a bit more about specific architectures for doing deep learning, and so deep learning is really all about neural networks, and I think it was Ronan Colbert who is credited with saying deep learning is just a trendy name for neural networks, and these models have been around for a long, long time.",
            "Neural networks really are a way of building up complicated nonlinear functions from a series of simpler building blocks and.",
            "Each of these simple building blocks we're going to have some parameters that are subject to training OK, and so in what I'm going to talk about when I describe neural networks.",
            "Let's for now assume that the input is just a vector.",
            "OK, so even if we're going to work on an image, we're going to collapse that into a vector, and we're going to ignore the spatial layout of the pixel."
        ],
        [
            "OK, so this like I said is likely going to be reviewed to those of you who are you who are fully aware of neural networks, but I just want to go through the basics so this is a picture of standard neural net where you might if you know about neural Nets, what might be a little bit different.",
            "Here is a type of non linearity that we're using in these two stages, so this is called a rectified linear unit.",
            "You might be used to seeing something like a sigmoid or A10H.",
            "Is it essentially satisfies the same property of sort of inserting a non linearity in here so we don't just have a complete linear collapse and have a fully linear network, but this is just sort of outlining some of the notations, so we're putting in an input.",
            "We're extracting multiple layers of what we call hidden units.",
            "OK, so these are these are just vectors that are representations of the data, and typically these typically are higher dimensional than the data.",
            "And then we have an output coming from our model.",
            "OK, we're going to train this thing using supervised learning, so we're going to train it with matched input to output pairs."
        ],
        [
            "OK, So what happens at the first stage?",
            "First stage we apply a weight matrix, so W. These are the parameters of the model.",
            "OK, these are learned by the learning algorithm.",
            "We apply that to the input and that produces a new description of the data, which is the hidden hidden units.",
            "And then we pass that through a non linearity.",
            "The biases are not shown in this just for simplicity, but typically we have a linear offset term.",
            "So, so we can represent affine transformations instead of just purely linear ones.",
            "So this non linearity called Erelu has been something that's explored.",
            "Like I said since about 2010 and it's actually made a big performance increase as opposed to using saturating type nonlinearities.",
            "After we have."
        ],
        [
            "Corrected the 1st.",
            "Set of hidden units.",
            "We apply the same sort of transformation a linear operation.",
            "Add the bias and then a non linearity.",
            "This Relu again and even though it's the same type of transformation, the parameters in this stage are different.",
            "OK so this is a different type of weight matrix.",
            "We learn those parameters as well and then finally we."
        ],
        [
            "Extract the output again using a linear transformation.",
            "There's no non linearity at this stage, so this produces a vector of real real valued outputs.",
            "OK, so it's a mapping from input output, you may."
        ],
        [
            "See different types of graphical depictions of this sorts of models, so you'll see block diagrams like the one I just discussed, which shows the non linearity.",
            "You can show a little picture of the Relu and the weight matrix, like sort of a signal processing type of set up later in the talk will use this type of picture where we're just showing the units and representing the weight matrix via single link and then also you might see people be more explicit and actually write all the links in the weights.",
            "OK, so this is actually explicitly shows that each.",
            "Hidden units in one layer is connected to all the hidden units in the next layer and this is what we mean by fully connected network people.",
            "Also experiments with different types.",
            "Experiment effective connectivity in these sorts of Nets, but by far this is the most popular.",
            "People also introduce things like Skip Connections where you can connect one layer two layers further down the pipeline, but this is the classical type of setup will be talking about today."
        ],
        [
            "OK, so once you've defined a way to get from input to output, so this is the forward processing step you want to be able to run your model and tell how good it's performing is enabled to be able to train it, you need to come up with something like a loss function.",
            "OK, so assuming that we're going to just do classification style set up here, we're going to match the inputs which we assume are real value.",
            "Something like an image to a class label and the way that we're going to encode our class labels were going to do something called 1 hot encoding.",
            "Where we have a vector of zeros which and the number of elements equal number of classes, and then we're going to insert a one in the place corresponding to the correct class, right?",
            "So we're going to produce something at the end of the day that we need to make it look a little bit more like something like this, and So what we're going to do is we want to.",
            "We also want something smooth and differentiable, so we're going to produce an output that essentially has the probability of each class.",
            "The output being each class.",
            "Given that input.",
            "OK, so we gotta do is where they take the real valued vector coming out, which has a number of elements equal to the number of classes and normalize that so it adds up to one and it can be interpreted as probabilities.",
            "So we're going to use were using nonlinear linear normalization operation called a softmax OK, and that just takes each element and normalizes, normalizes it by the other elements in the output and that will give us a vector of the output.",
            "Which is which.",
            "If you sum over the elements, that will sum to one and can be interpreted as probability of the correct class label.",
            "OK, so then what happens in our loss is a natural loss function for this.",
            "Sort of classification problem is just the negative log likelihood of the correct class given the input.",
            "This is also called cross entropy."
        ],
        [
            "OK, so learning is going to consist of justice.",
            "Minimizing this loss function with respect to the parameters sofita is the notation I'm going to use for the parameters in all stages of this network, so all of the weight matrices are make up this data.",
            "And the question here becomes, how do we actually minimize this complicated function that consists of multiple stages?",
            "And really, the answer is just.",
            "It's an application of the chain rule of all of these blocks are differentiable themselves.",
            "We can just apply the chain rule to the whole, the whole model, and this is called the backpropagation algorithm."
        ],
        [
            "So many of you have probably already aware of backpropagation, but in case this is new just to give a little bit of intuition behind it, a similar strategy you could use is simply by taking each weight in isolation, perturbing that wait a little bit, and.",
            "Looking at the loss and seeing if it decreases or increases OK, So what we're writing here is you take a particular wait, say in the first layer, OK, and there's a particular way IJ so it connects some unit J2 unit I and we're just going to add a very small amount to it.",
            "OK, and we're going to measure the loss without that perturbation, and we're going to measure that loss with this perturbation, so this notation is just take out this weight and replace it by this weight plus epsilon.",
            "OK, so if that little perturbation improves the loss or lowers the loss, then we're going to just keep that change to the weight and move on.",
            "OK, if it actually ends up raising the loss so that little adjustment made things worse, then we're going to just move in the other way.",
            "OK, so this is a way of learning by just wiggling the weights, but it's, uh, it's incredibly inefficient.",
            "OK, So what you would have to do is for each weight, you would have to visit a number of input vectors.",
            "Do this little wiggling operation and then sort of compute the average of this quantity over all of those.",
            "OK, so we want to have something that doesn't scale in terms of the number of weights, which is essentially quadratic in the number of neurons and the number of data examples.",
            "So a better thing to do."
        ],
        [
            "Is actually instead of perturbing each weight, we perturb the hidden unit activities.",
            "OK, so we don't really have an idea of what their hidden, so we don't know what the hidden should should should should be, but we can use the proxy of the air.",
            "How fast the error changes with respect to the hidden activities, as sort of a desired target signal.",
            "OK, so by wiggling these hidden's or computing their derivatives we can.",
            "Compute the change on the loss by the by wiggling this hidden and use this as a signal to drive the learning of the network, and So what we do is we compute error derivatives for all the hidden units in an efficient way at the same time, and then given the error derivatives of the loss with respect to the hiddens, we can easily compute the error derivatives of the loss with respect to the weights.",
            "OK, so it says 2 step procedure, see how each stage of hedons affects the loss.",
            "And then see how those parameters that are computing those hidden's or that are part of the computation of those hands are affected.",
            "That makes up the backpropagation algorithm.",
            "OK, so I'm going to.",
            "Start at the top of the network or the the output stage and I'm going to start computing these error derivatives backward.",
            "OK, so let's start."
        ],
        [
            "With the derivative of the output of the loss function with respect to the output of the network.",
            "So I talked before about this normalization step called the softmax.",
            "So to start off the chain rule we had to take the compute the loss and then take the derivative.",
            "The loss with respect to the output of the network and it just happens to be sort of mathematically convenient that the derivative loss with respect to the output for the softmax ends up being something very simple.",
            "I so it ends up doing just the difference between the.",
            "Prediction of the class and the desired classes.",
            "This guy is either a one or a zero, so if it's the you know, if we're predicting the class label the true class, this driver is going to be just simply a one for the two classes.",
            "This guy is going to be 0 for every other class sets for every other other class, and so once we've computed that loss."
        ],
        [
            "With respect to the output of the network, we start back propagating and so we take this and we use this quantity to compute the derivative of a loss with respect to the weights at this stage, and then the derivative loss with respect to the hidden units going in.",
            "At this stage.",
            "OK, so this is again just application of the chain rule.",
            "We take."
        ],
        [
            "This the second guy that we've just computed derivative loss with respect to the second stage hidden units and again do the exact same thing.",
            "So we compute the derivative loss with respect to the weights at this stage and drive along with respect to the input going into this layer.",
            "So that's this quantity here via chain rule.",
            "And then finally."
        ],
        [
            "We sorry move back."
        ],
        [
            "And we compute the derivative.",
            "The loss with respect to the first stage weights, and that's all we need.",
            "So now we have the error derivatives with respect to each with respect to the parameters at each stage, and that gives us what we need to do to do a parameter update of the whole system.",
            "OK.",
            "So this."
        ],
        [
            "This to our first technical challenge, so these networks, which we've discussed are basically built up of individual building blocks, and they have associated parameters we made have associated architectural settings.",
            "For example, how many hidden units, what kind of non linearity we want to describe these in some convenient way and off to reuse the same sort of modules and build these up and not make errors in our programming.",
            "So this requires us to define both the forward pass in the backwards pass for each module.",
            "But there's Fortunately a number of libraries out there which allow us to assemble these neural networks that can be described as series of building blocks, and the most pop."
        ],
        [
            "Other ones out there are torch cafe and the Python frameworks Theano and Pilot and two.",
            "So Pascal is going to talk about Fiano Pilar into Theano, sort of the backbone of Pilar.",
            "Two, Pilar, two let's you do this high level description of neural Nets cafe and torch also allow you to describe.",
            "Describe neural Nets in their composition in a simple way and assemble them and also allow you to give you access to training algorithms.",
            "They all give you access to GPS and so forth."
        ],
        [
            "OK, so we recently did tutorial at CPR.",
            "This is back in June an we had representatives for each of these open source platforms.",
            "Come and give talks and so these short talks on these on these different frameworks are available on this page and they provide useful information or you can just go to the various GitHub pages and check them out.",
            "Now because Pascal is going to talk about Theano and Pilar and two.",
            "I thought I'd just take a second and give an example of using Cafe cafe and torture.",
            "Actually pretty similar.",
            "But the."
        ],
        [
            "Yeah, is you're going to define using any of these frameworks.",
            "You'll find your network in terms of building blocks, so this is actually a convolution layer.",
            "It's a little bit more complicated than the usual our standard neural network layer that we just talked about.",
            "We will talk about convolution a little bit later on in this talk, but essentially you define some parameters associated with that layer, so filter sizes, number of number of outputs you have to describe what's going in and out of that layer, and then you also have to describe the parameters associated with it.",
            "So I said there's some weights.",
            "And there's some bias is typically a neural net.",
            "Those are what are getting updated.",
            "So how do you write this thing?",
            "You just write it in a structured file like Jason or YAML Cafe ends up using something called Google Proto Buffers.",
            "And."
        ],
        [
            "So once you've described it in terms of the architecture of the structure of the network, you need to tell how to."
        ],
        [
            "Compute the forward pass in the backward pass.",
            "OK, so you gotta write some code for going forward, so the transformation going from input to output and then you gotta write some code that goes back the other way.",
            "So just like we talked about before how to compute derivatives of the output or the loss with respect to the parameters of network and also with respect to the input to that particular module, that gives you enough to be able to assemble these things together.",
            "OK, So what does it actually look like in code?",
            "So when."
        ],
        [
            "Build up these modules in something like Cafe.",
            "This is a very very simple, probably simplest neural net you could possibly have is actually a little bit logistic regression model, and so you define it.",
            "You tell it well.",
            "I'm going to.",
            "I'm going to process some data.",
            "This is the famous MNIST data set.",
            "I'm going to process the examples in batches of 64 and I'm going to scale them and this produces a data.",
            "The scale data and there's also a label associated with each data case.",
            "And then I'm going to take the output and just apply a linear operator to.",
            "This is just the weights times the inputs, so this represents our inner product component.",
            "This type here Xavier.",
            "This is a guy at University of Montreal who's famous for the paper on the rectified linear unit.",
            "So it's just saying that this stage uses Relu type non linearity and and it produces this guy called IP and then we define this softmax loss which is what we talked about before.",
            "This is a classification problem, so this is saying match the output of the network with the true label and apply this softmax locks already already talked about.",
            "That's a very simple network."
        ],
        [
            "Cafe also comes with some reference implementations of very complicated networks, so this is Alex Kraszewski's.",
            "People call Alex net.",
            "This is a network I showed you before which one image net.",
            "If you roll out all of the layers in this you get something like 30 different layers.",
            "So to write something like this just with no framework is actually very tedious.",
            "You could get bugs and so forth, but because this is a number of repeated modules you can write this very efficiently in cafe or torch.",
            "Or piloting too, they all have functionality with to assemble very complex neural networks.",
            "And provide you all of the associated tools with parameterising them and training them and so forth.",
            "OK, so I mentioned before.",
            "At this stage we need to break both forward pass in the backwards pass so the backwards pass obviously."
        ],
        [
            "It involves.",
            "Computing gradients of the loss with respect to the input of a layer with respect to the parameters of a layer, and.",
            "You can imagine once your network is up to 30 layers, that's going to be a little bit tedious to do and error prone.",
            "Of course, if you do this yourself and this is what people have been doing for many years, you should numerically verify your gradients always get this easy to get bugs, but Theano actually gives you a functionality to automatically compute gradients.",
            "You just write your network symbolically assemble the pieces.",
            "And then ask it to do symbolic differentiation for you, and so this is one of the advantage of Theano versus the other.",
            "The other frameworks is the idea that giving giving you this functionality of automatic differentiation.",
            "So while Pascal is going to talk in depth about Theano, I thought I would just give you like a little teaser of what piano looks like.",
            "OK, so the font size OK, maybe.",
            "Little bit bigger.",
            "See.",
            "OK.",
            "So basically here's my pointer.",
            "OK, so theano?",
            "It's essentially mathematical expression compiler, so a lot of people associated with neural Nets, but it's actually much more general than just building deep learning models, so you have to start up.",
            "It's a Python based framework, so you going to do some imports from Theano, so there's a pretty printer in Theano function.",
            "We're going to use.",
            "We're also going to use an object called a piano tensor.",
            "And so when we assemble models in Theano, we're actually going to.",
            "Define these symbolic variables so X is a symbolic variable.",
            "It's a scalar.",
            "OK, so we're giving it a name X.",
            "We're assigning it to X and we're telling you that it's a scalar, and it's a double variable.",
            "We're then defining Y as a function of X. OK, so this is a symbolic expression, so it's just X squared alright, and So what we want to do is compute the symbolically the gradient of Y.",
            "With respect to X, so we use this operator, the grad operator, so we're saying OK, so this is going to be another symbolic variable, and it represents the gradient of Y with respect to X, and then we print it out.",
            "OK, so when we do this, we see that it's some kind of complicated nasty looking thing, but really all this is, it's just saying fill up a block that's the same size as X squared with with ones OK and then multiply that with.",
            "So.",
            "My scrolling is not working very well here, but it is saying essentially.",
            "Multiply this was something that 2 * X to the 2 -- 1 which is just 2 * X OK, so that actually matches out even though it's kind of nasty.",
            "But actually Theano optimizes that to a simpler expression.",
            "Doesn't actually do all this stuff at runtime, but once we have this gradient as a symbolic expression, we can then create what's called Theano function out of it, and Theano function is the map from NUM PY variables to non play inputs and outputs.",
            "OK, so this is the stage at which are symbolic.",
            "Variables get replaced by actual quantities.",
            "OK, so we say I want a function that Maps inputs which is X.",
            "We define that earlier a scalar X to this operation gradient of Y.",
            "And so that creates our map.",
            "We can we can call F of any of any number we can run it, and that actually gives us the gradients of Y with respect to X evaluated at that X.",
            "So that's just a one stage.",
            "Very simple function, but you can do this with a number of variables, change together and take gradients with respect to them and evaluate them.",
            "And you can also do gradients of some.",
            "Function with rate in some variable with respect to a number of different variables, in which case this will return a vector.",
            "So you can also do full Jacobian hessian's what I was going to show at the end here is essentially this simplification that Theano does in terms of reducing that kind of nasty.",
            "Expression at the top here to actually just two 2 * X. OK.",
            "So it does have an optimizer that takes the the graph and reduces it to something that's more efficient.",
            "OK, so.",
            "That's Theano, a very quick taste of it.",
            "You'll see more about Theano this afternoon."
        ],
        [
            "OK, so the next technical challenge you're going to hear more about this at the at the conferences on optimization and historically the deep learning community or neural Nets community has hasn't used very complicated type of optimizers or they've been typically obsessed with stochastic gradient descent, in particular mini batch variants of gradient descent.",
            "Bill often use tricks like momentum.",
            "In recent years people have been experiencing are experimenting with different types of tricks like Nesterov style momentum.",
            "RMS Prof.",
            "Different RMS different types of adaptive learning rates and so forth, but you'll find that there's not a lot of evidence that these models are.",
            "Optimize better using more complicated techniques or batch techniques.",
            "So overwhelmingly you'll see scatter gradient descent applied.",
            "What's more important?",
            "What's more challenging?",
            "I think in this community is not necessarily the parameter optimization, but the hyperparameter optimization.",
            "So these are all in."
        ],
        [
            "Different settings architectural configurations of these networks, their complicated things.",
            "They have many of these hyperparameters associated with them.",
            "Things like the learning rates, the number of layers, the number of hidden's per layer, the type of non linearity, all these different different things.",
            "These have typically been set by just 6P."
        ],
        [
            "Variance OK, so someone being sort of a neural network wizard, you'll see some volumes like the neural Nets, tricks of the trade out there, kind of giving some guidance of how to set some of these parameters, but it's not completely satisfactory just to have this wisdom sort of passed down from advisor to grad student.",
            "So what's been hot in the last couple of years?",
            "Or people applying different types of black box optimizers to do hyperparameter optimization of neural net?",
            "OK, so the two most popular ones that have been used for.",
            "Hyperparameter optimization of deep learning models are two projects that are both on GitHub."
        ],
        [
            "One is called hyperopt.",
            "OK, so this is written by James Berger who who worked on piano and actually hyper up, uses Theano as its back end.",
            "So at the end of the day everything is done symbolically.",
            "It supports real valued quantities, discrete value quantities and it also has this these conditional dimensions.",
            "So for example in the code here, we're defining a hyperparameter optimization of parameter space in which there is choice of a discrete variable, so.",
            "This variable A has two outcomes, right?",
            "It can take case one or case two if we choose case one, then we have a continuous variable which.",
            "Is distributed according to this expression source of 1, plus some lognormal and it has associated range with it.",
            "If we take case 2 for our first variable, then this.",
            "As is other hyperparameter associated with which is C2 and it's just uniformly distributed.",
            "OK, so you can build up fairly complicated parameter spaces and then do this hyperparameter optimization in a distributed way.",
            "And it has ways of plugging in different types of algorithms.",
            "So it's quite flexible.",
            "It's been used on a lot of different deep learning projects and the other one that's out there is is called."
        ],
        [
            "Pierement, which is more focused on a specific class of Bayesian optimization algorithms.",
            "But again it's being used by quite quite a number of people.",
            "It's also on GitHub.",
            "It's been extended to something called Spearmint Solid, which essentially just uses is a way of doing sort of ensembles of meta optimization algorithms.",
            "So all of these make the search over this very complicated parameter space A little bit easier to.",
            "To swallow.",
            "OK, so that's neural networks standard neural networks.",
            "That's sort of the.",
            "Background for deep learning."
        ],
        [
            "Let's talk a little bit more about the limitations of standard neural networks.",
            "For large datasets, I'm going to keep talking about images.",
            "So let's just say we don't have an image Patch anymore.",
            "We have an image that's 200 by 200, so I told you before.",
            "If we want to process image data using a neural net.",
            "Typically what we would do is take all of the pixels in that image.",
            "We flatten it to a vector and then we have a fully connected model, right?",
            "So we've connected every single pixel in that image to every single neuron or hidden unit in the first layer.",
            "So if we do this for 200 by 200 image and we have 40,000 hidden units, the number of weights that need to be learning that model is something like 2 billion parameters.",
            "OK, so there's some problems with this.",
            "One is that we're never going to have enough data to even fit this number of parameters, and also we're doing a lot of wasted work, so typically the correlation images is very local.",
            "OK, so we're not going to be searching for feature detectors that need to consider very wide spatial dependencies.",
            "It makes much more sense."
        ],
        [
            "Actually connect up these hidden units in a very local way.",
            "OK, so let's do that.",
            "So let's take each hidden unit instead of connecting it to all the pixels, we're going to just connect it to 10 by 10 window of pixels OK, and if we do that, we still have 40,000 hidden units, and we use this 10 by 10 window.",
            "We're going to end up going from 2 million to four million parameters, so this is much easier to deal with.",
            "Now the idea of right now the way that we've done this is this is a different set of parameters.",
            "This is different set of parameters.",
            "So is this and so is this.",
            "There's."
        ],
        [
            "Actually, stationarity in this problem and that if we're going to build something like an eye detector, why'd build an eye detector over here and I detector over here and I detector over here.",
            "Why not just build it once?",
            "OK, so that's the motivation for essentially sharing parameters.",
            "So now we're going to have these."
        ],
        [
            "Hidden units that only look at a local region, but the parameters of each hidden unit that looks at a different local region that shared with all the other guys.",
            "OK, so here you have a single set of parameters is 10 by 10, so it's 100 numbers and it gets used everywhere.",
            "So every hidden unit uses the same weight matrix or filter whatever you want to call it.",
            "So this can actually be when you when you want to extract a number of hidden units that look at different patches of the image is this can be implemented efficiently using a convolution.",
            "OK, so this is where we're getting to in terms of convolutional neural net.",
            "Your hidden units are spatially arranged.",
            "They share their parameters and this is computed via convolution so."
        ],
        [
            "A convolutional layer when we actually do a convolution, it's taking an image, convolving it with some filter.",
            "This is a three by three.",
            "We're looking at 10 by 10 region before and this produces some new representation.",
            "We call this a feature map.",
            "OK, so here we just used an edge filter system, extracting horizontal edges.",
            "This produces a new representation of the image.",
            "It's also 2D.",
            "OK, so this is a little bit different than standard neural Nets.",
            "The representations produced by this.",
            "What we're going to call in convolutional neural net are also spatially arranged.",
            "Now the difference between this an what happens in the convolutional net is that this guy, the filter is learned OK, so typically we won't just learn a single."
        ],
        [
            "Filter, but we'll learn multiple filters.",
            "OK, so we see here with the red and the black.",
            "These are different settings of those filters.",
            "Typically will you will learn maybe between 10 and 100 of them at each layer.",
            "OK, so.",
            "When we share the parameters at all locations and we maybe learn 100 of these filters, we've gone from now 4 million to 10,000 parameters.",
            "OK, so what's the math in the convolutional?"
        ],
        [
            "There, So what typically happens is you have a mapping from input feature Maps.",
            "This is at one stage.",
            "This is the.",
            "This is essentially a tuning depiction of hidden units.",
            "And we convolve that with the kernel, and we produce an output map.",
            "And then we convolve the another input map with another kernel.",
            "We produce an output map, and we sum these guys altogether and that produces our final output feature map.",
            "OK, so you see here if this is the first layer of the network, it might be 3 channels representing something like red, green and blue.",
            "Those get convolved with specific parameters and those produce output feature Maps now."
        ],
        [
            "This is a little picture of this, So what we need to do in terms of computing the operations is for each output feature map we need to involve a filter with the respective input map.",
            "Each input map and then sum these guys together in that produces the output map."
        ],
        [
            "Will be a set of three different filters associated with this second output map.",
            "And in terms of the number of output Maps at each stage, this is again one of these hyperparameters that might be optimized via the hyper optimization framework.",
            "OK, so.",
            "The other thing I just want to mention is that there's still a non linearity being performed in the convolutional layer, and this happens after we sum the responses of the convolutions with the individual input feature Maps.",
            "And then there's a number of things that happened later, so let's just recap what we've gone through."
        ],
        [
            "Here if we apply just a fully connected standard neural network to images, it's going to scale quadratically in terms of the number of parameters with the size of the input is also, and it's not going to leverage stationarity, meaning that we're going to have to learn separate feature detectors at all locations of the image, so it makes much more sense to share the parameters, reduce the parameterisation in that network, and this thing is called a convolutional layer.",
            "Any network that contains a convolutional layer is called a convolutional neural network.",
            "OK, so this just happens that convolution is only the first stage of the convolutional neural network."
        ],
        [
            "There's something else called a pooling layer, which is really important.",
            "OK, so let's assume that the filter is that's been learned as an eye detector.",
            "OK, so how can we make the detection detector robust to the exact location of the eye?",
            "So what we mean by that is we want to be able to have this response map fire when there's an eye in a particular location in sort of some local region, but we don't want to care of whether it's shifted one or two pixels over.",
            "We want to get these same response, so this is also called learning invariants.",
            "OK, we're learning shift invariants."
        ],
        [
            "OK, So what we're going to do here is we're going to take the responses of a number of these neurons, and we're going to pull them into a single response.",
            "So typically Max or an average operator is used, but there's a."
        ],
        [
            "Number of different pooling's that have been done and compared in the literature beyond Max is an average is we can do for example L2 pooling in a spatial region.",
            "But we can also do pooling, not just spatially, but we can do pooling in local neighborhoods.",
            "A cross filters as well across features.",
            "OK so we can do a combination of pulling across spatial regions.",
            "Anna Cross features as well.",
            "OK, so."
        ],
        [
            "So apart from pooling in sort of modern day convolutional Nets, another architectural choice that makes a lot of difference is doing normalization at various stages with the network.",
            "So at the input as well as the layers of the network themselves.",
            "So when something called local contrast normalization we take a local neighborhood, we compute the mean and the standard deviation and so for each unit we're going to subtract the mean from the of the responses.",
            "That are in a local region around it and divide by the standard deviation of the responses in a local neighborhood around it."
        ],
        [
            "This allows us to, when we have highly variable feature Maps in terms of the responses, allows us to control the dynamic range and."
        ],
        [
            "So we get out a smooth feature map and this tends to improve in variance.",
            "It makes the optimization more stable because we've controlled the range and it also increases sparsity.",
            "And so compared to the first stage, the convolutional feature extraction this both the pooling and the local contrast normalization steps are really negligible in terms of the amount of computation needed.",
            "OK, so convolutional filtering, rectification, local contrast normalization and pooling."
        ],
        [
            "Those make up this a single stage of a convolutional neural net, so this kind of puts it all together.",
            "Convolutional Nets are made up of multiple stacks of these stages OK, but each of these stages have these three operations which are important to making it work technically, and the main parameters associated with this block are the actual filters in the convolution convolutional layer here.",
            "OK, so this goes.",
            "It shows a little picture of what's happening with the filtering.",
            "The non linearity, the rectification, we contrast, normalize and then we pull the responses down in that produces a smaller output map."
        ],
        [
            "OK.",
            "In terms of building up the whole system, that was a single stage typically will stack multiple stages together and then we'll follow those by a few fully connected layers.",
            "So what happens is we do each of these we're going to produce 2D structures right?",
            "'cause the output of filtering normalization and pooling and so at the top.",
            "Here we're going to have something that's a series of feature Maps and these are two D structures, but we're then going to collapse them down, just flatten them out into vectors and process them with the layers of a standard neural net.",
            "Again, we generally have a number of these, typically something like one to three fully connected layers, and that's connected to something like a class label.",
            "Or if you're doing regression or another task, you can change the output of that model.",
            "But again, we train this thing via."
        ],
        [
            "Back propagation.",
            "So when we created accommodate all these operations that we talked about.",
            "The convolution itself, the rectification, the normalization, the pooling.",
            "These are all differentiable, so each block you can differentiate the output with respect to the input and that allows us apply the backpropagation algorithm.",
            "So the training, these things which are obviously more complicated than standard neural Nets, is the exact same procedure you do a forward pass through the network, go from input to output, you perform backpropagation, and then you do a parameter update convolution."
        ],
        [
            "And that's compared to standard neural Nets.",
            "Is that you can scale them up very easily to larger images, so the convolution operation, as opposed to say sliding window based techniques in the vision literature.",
            "You can reuse the computations involved and very efficiently compute features across a very large image just using the convolution.",
            "You don't need to do separate computations of the net for each window across a larger image.",
            "OK, so."
        ],
        [
            "These convolutional neural Nets are not new, they've existed in some shape and form since the early 80s.",
            "Then Fukushima had something like very similar to modern modern day convolutional neural Nets, and until about 2012 the conventional wisdom was that these things are just hard to train because we end up in local minima.",
            "It's very complicated, model is nonlinear, nonconvex.",
            "We get stuck in local minima.",
            "And that's all we can do.",
            "The thinking has changed to some degree, in that the local minima are not really all that bad.",
            "OK, there's a lot of local minima, but they all are essentially the same in terms of the value of the loss of the performance.",
            "There's a lot of plateaus and it just takes a long time to break symmetry in these networks.",
            "So we could just train them for longer.",
            "And be more patient.",
            "They can actually work, and if we have enough data to train them then they can actually do really amazing things.",
            "So optimization given if we have enough data, we have enough flops to train these things and we make the right architectural settings, like using Relu units, using normalization and so forth.",
            "Optimization is not really the challenges."
        ],
        [
            "Challenges are more the generalization capability, so if we have a ton of parameters in this network, how much data do we really need to be able to train it and not overfit?",
            "And also we want to train very high dimensional training, high dimensional data.",
            "How many parameters would do we need to do?",
            "We need to have and then again how many samples do we need to be able to fit those parameters?",
            "OK, so scalability really is the issue and a lot of us working in this Community believe that it's really been changes in terms of scalability that which have pushed these models forward.",
            "OK, it's not as much the algorithms there have been some architectural discoveries.",
            "But it hasn't really been about the optimization.",
            "People are still using SGD plus momentum as they have been for many years, and that's not to say that.",
            "There may be discoveries on the optimization front, but up till now the main breakthroughs have really been in terms of scalability."
        ],
        [
            "So what's been happening is in people have been sorry this is cut off a little bit.",
            "This is flops per second on the left, so people have been pushing out in terms of the flops.",
            "GPU's have made a huge difference on this front and then we've also been pushing it on the data.",
            "OK, so I said image Net was a big breakthrough because we were training on millions of images instead of 10s of thousands of images.",
            "So as we've pushed out on the FLOPS per second in the data, this is allowed neural networks to be able to.",
            "Expand In terms of the capacity of the number of parameters, so their complexity is going up, but they've been able to generalize because we have more data and we've actually been able to fit these things in a reasonable amount of time because we have the processing power.",
            "So in sum."
        ],
        [
            "Sense convolutional networks, even though they've been around for a while, they were in some sense premature because we just didn't really have the flops and we didn't have the datasets to train them.",
            "OK, so in terms of.",
            "Technical computing challenges.",
            "It's really about."
        ],
        [
            "Scalability.",
            "OK so.",
            "The good news is that deep learning architectures are very amenable to parallelization because of two reasons.",
            "So one of the types of data that are are typically being used by things like common.",
            "These things like image data, video data is made up of pixels, so it's very amenable to data based parallelization.",
            "We're often performing the same operations like these convolutions on a number of pixels.",
            "The other type of parallelization is the model based parallelization.",
            "Based on this task, parallelism, so we have a number of hidden units or a number of units in the feature map.",
            "All of those are being computed in the exact same way.",
            "Those operations can be easily parallelized, so that's why all of these platforms that I mentioned earlier, like Torch and Theano and Cafe all provide transparent GPU support in the form of CUDA.",
            "The deep learning in machine learning community in general has been really attached to CUDA because in the video came out with their hardware really far in advance of anybody else.",
            "You'll see some open CL developments starting in Theano.",
            "People are starting to work on Fpgas.",
            "People are starting to design specialized hardware for deep learning as well.",
            "In the last few years, so we'll start to see these sorts of models be demonstrated on various embedded platforms within the next few years.",
            "It's not just constrained GPS and CUDA, but the bulk of the hardware acceleration is being done on the computer platform.",
            "Oh yeah, so that includes the supervised learning part of the talk.",
            "For the remainder of the session, I'm going to talk about.",
            "Less well known or less recognized, especially in the last few years.",
            "Avenue of Deep Learning, which is unsupervised learning."
        ],
        [
            "So.",
            "Clearly, these impressive results com nights and so forth.",
            "Winning competitions have all been done on supervised learning problems, usually with a lot of data, and typically it's been classification problems like visual recognition.",
            "Progress has been slower on the front of unsupervised learning, but I believe that and many people in the community believe that unsupervised learning will be very important to the advances in deep learning and even though.",
            "We're scaling up the amount of data that we have available to us.",
            "That doesn't mean that we're always going to have labeled data available, so this is really about this sort of next part of the talk is about what do you do when you don't have access to a ton of labeled data, like image that when you have a thousand categories and you don't have 30 or 100 examples per category telling you what that class label is."
        ],
        [
            "So an interesting historical fact is that, as I mentioned earlier on the talk, the unsupervised learning algorithms based on deep techniques were actually the catalyst to a lot of the recent breakthroughs in deep learning.",
            "So people in the last say three 2, three years have totally moved towards supervised learning and comments and so forth.",
            "But what really got all this going was this idea of taking restricted Boltzmann machines.",
            "Training layers greedily by themselves, and then stacking them into things called deep belief networks.",
            "What happened is that as we talked about before, we got better algorithms like and tricks like nonlinearities and normalization and regularization like dropout.",
            "We got more data, we got more GPU's and everybody kind of forgot about unsupervised learning.",
            "But I think we should still care about it.",
            "It's important and it's interesting.",
            "It's fun to work on, so there's a new deep learning book out by."
        ],
        [
            "Yoshua Bengio Aaron Courville Ian Goodfellow.",
            "And there's a book draft available.",
            "It's not out in published form yet, but in that book they talk about the reasoning behind unsupervised learning, and I want to make sort of.",
            "I want to put these points out there, so the first one is that as I said, there's a lot of data out there.",
            "We're getting more and more access to data, but it's not necessarily labeled OK.",
            "So things like Google Glasses, YouTube, Flickr, they're generating a lot of data.",
            "We have access to it, so we want to use it and leverage it.",
            "We need to have unsupervised learning algorithms."
        ],
        [
            "Now unsupervised learning algorithms also allow us to capture enough information about the variables to answer.",
            "Questions that were not necessarily there at training time.",
            "OK, so supervised learning algorithms were trained for specific problem, were able to ask for a very specific answer, which is an input output mapping.",
            "Unsupervised learning algorithms are much more flexible.",
            "OK, we train a model based density model.",
            "We can ask it all kinds of different questions after the fact.",
            "After it's been trained."
        ],
        [
            "The sort of restricted Boltzmann machine, deep belief network break through a number of years ago pointed us towards the fact that unsupervised learning could be an important regularization tool for deep learning.",
            "OK, so it helps us generalize, and this is important to different regimes such as transfer learning, unbalanced classes, and zero shot.",
            "One shot, learning and so forth.",
            "There's been some work analyzing what happens when you do pretraining and you don't do.",
            "Pre training so pre training is this process of unsupervised learning first followed by supervised learning.",
            "And so there's a paper out of the Montreal Group from 2010 that essentially is a visualization of networks.",
            "So each of these dots represents a different neural net.",
            "OK, so as different parameters and these guys over here have been trained just using back propagation, no, pretraining these Nets over here have been trained using an unsupervised learning algorithm first.",
            "Then training them with the supervised learning algorithm.",
            "And So what you see happening over here is that the as we move from blue to green.",
            "That's the training time.",
            "And the network.",
            "So these guys actually end up dispersing and these guys end up sort of converging as they as they train.",
            "OK so again.",
            "Some of the motivations here in terms of generalization and pre training have been eclipsed by the ability to train supervise for a longer amount of time.",
            "But that doesn't mean that you know these results from a few years ago or invalid.",
            "We may return to these sort of pre training strategies in the future."
        ],
        [
            "OK, so another interesting aspect of unsupervised learning compared to supervised learning is that we can train it using local learning strategies.",
            "OK, so there is sort of a credit assignment problem in deep networks, as we as we grow this network out in terms of the number of layers.",
            "We're still stuck with taking some loss computing at computing some some error signal and back propagating it all the way through the network, and so this you may have heard of vanishing gradients.",
            "That's what happens when we try to assign credit a very way along very far back.",
            "In time and propagate this information to the layers and enrich.",
            "It starts to disappear, whereas unsupervised learning algorithms actually just sort of capture layer by layer dependencies.",
            "An patterns at a very local level and this makes them easier to train in that regard.",
            "However, there's still motivations for wanting to train unsupervised learning algorithms.",
            "From end to end, essentially and organizing them so that the upper layers know about representations that have been learned by the lower layers."
        ],
        [
            "And finally, another motivation for unsupervised learning is the parallels between what are called structured prediction problems and the challenges faced by unsupervised learning.",
            "So even though all these successes as of late have been tests like recognition, there are a number of problems.",
            "For example, attribute prediction, segmentation, producing language from images, sequence modeling and so forth that are called structured prediction tasks where the output is not just a single.",
            "Class label, but it's a high dimensional.",
            "Output with a lot of rich structure in it.",
            "OK, and so the instance enforce consistency in that output and the types of computations that are performed in unsupervised learning problems can be leveraged for this sort of structure learning problem."
        ],
        [
            "OK, so as we just discussed, when doing supervised learning, we learn a representation that's very specific for a particular task.",
            "For example, classification the.",
            "It's generally fairly easy to set up the error signal, 'cause it's very specific to the task."
        ],
        [
            "When we come to unsupervised learning, we no longer have an output.",
            "We don't have this input output relationship anymore, and it's also not clear to us what the error signal should be.",
            "We're just giving these inputs and we need to build a model of them.",
            "OK, so what's been proposed?"
        ],
        [
            "Additionally, are things like.",
            "Reconstruction error OK. Can you learn to just?",
            "Produce some sort of representation or code from that input and reconstruct it.",
            "People have proposed probabilistic techniques and just tried to maximize the likelihood of the data, the training data.",
            "And also people like hung likely have looked explicitly at things like disentangle ING factors of variation.",
            "OK, so can you build a hidden representation that is interpretable that takes the lighting and takes the orientation and takes the identity?",
            "Out of these facial images and represents them as elements in a distributed representation.",
            "OK, so the last part of this talk is just going to be talking a little bit more about specific methods for doing unsupervised learning, and so the main ones I was going to cover are autoencoders and restricted Boltzmann machines.",
            "We'll see in terms of I know I have about 15 minutes left, so depending on how that goes we may talk about just one and not the other.",
            "OK, so let's talk about autoencoders first, because there.",
            "Much more closely connected to the supervised neural Nets that we talked about earlier on OK, but to get at them it's useful to motivate them from a point of view of something that everybody most people here are probably familiar with, which is principal components analysis, so it's off."
        ],
        [
            "Often useful to create a lower dimensional representation for some data so you have data and dimensions and you want to represent represent it as.",
            "And M dimensional vector and.",
            "When your data lies on a linear manifold in high dimensions, you can use something called principle components analysis.",
            "You just predict it projected to a lower dimensional subspace and you do this by searching for directions that have the most variance and.",
            "Discarding the other directions right, and so you know, here's an example of some 2D data.",
            "We find the direction of maximal variance, which is this.",
            "This line here, and we take each point and we projected to this line, and so we're we completely lose all information and directions that are orthogonal to the direction we've selected.",
            "OK, and this happens and happens in high dimensional high dimensions as well, but typically that's not a big deal because the dimensions that you're ignoring are the ones that have lower variance.",
            "You can take this PCA model and implement it.",
            "By a neural net.",
            "OK, so typically people use eigenvector based methods to estimate PCA, but you can just take a MoD."
        ],
        [
            "So that's a simple neural network where you have an input vector.",
            "You have a code and then you have an output.",
            "If you encourage the output to be a reconstruction of the input, and you do that through your loss function.",
            "That will implement something very similar to PCA.",
            "OK, so this is just what we talked about before.",
            "As a mapping from input to output, the difference is that we have some sort of loss function that just measures the Fidelity.",
            "So these guys have to be the same dimensionality obviously, and the loss function is just ensuring that these things look similar.",
            "And also it's important that the code here has fewer dimensions, right?",
            "Otherwise we could just copy the input and then copy it again and just perfectly reconstruct it.",
            "OK, so we have to create some sort of bottleneck.",
            "The input gets projected down to some lower dimensional space, just like PCA can do.",
            "And then we reconstruct it.",
            "So it's a little bit different than PCA, because it won't necessarily find orthogonal feature vectors, and they'll have approximately equal variance, unlike the directions found in PCA.",
            "But essentially it's the same, it will span the same subspace.",
            "Now."
        ],
        [
            "Why would we want to fit PCA using backpropagation when we just have spectral methods to do so?",
            "Well, it allows us to be much more flexible in terms of the types of functions we can represent, so we can actually take the.",
            "The mapping from input to code and put extra layers in there OK and then we can also put extra layers between the code and reconstruction, and we generalize it.",
            "This way we have something called an encoder and decoder, so this can use all kinds of fancy nonlinearities, multiple layers, normalization, even.",
            "And these can be very flexible now.",
            "So we just define sort of generic mapping differentiable of course from input to code and then code to reconstruction.",
            "OK, so now we're able to represent data that doesn't necessarily lie on a linear manifold, so something that PCA is not necessarily good at capturing.",
            "We can train this model using all the tools that we've just talked about earlier today, and this can be a very efficient.",
            "A powerful way of discovering representations.",
            "With a very simple training signal."
        ],
        [
            "So when we have this sort of generic PCA like learning architecture, this thing is called an autoencoder.",
            "It's a feedforward network, is trained to minimize reconstruction error between the input and output, but either a bottleneck.",
            "So making the code low dimensional or using some sort of regularization is essential.",
            "Otherwise it can just cheat by copying the."
        ],
        [
            "Put OK."
        ],
        [
            "Now, what if we're not using bottleneck hidden layers?",
            "OK, or code vectors?",
            "We want to actually take an input and produce a higher dimensional representation of it.",
            "What can we do?",
            "So what kind of?"
        ],
        [
            "Regularization, can we?",
            "Can we perform in this case?",
            "We have to somehow restrict the capacity of the model, say by sparsity or some other method, and so there is this predictive opposition taking place between the network wanting to reconstruct the input accurately and also the regularizer tugging it back and keeping it making it very simple and sort of crippling the model in some way.",
            "So what do we mean by simple or what do you mean by crippling it?",
            "It could be making it compact that we talked about before it could be sparsity on the activations of the code layer.",
            "It could be adding noise to the input and forcing the model to reconstruct a noisy version of the input.",
            "This is something called a denoising auto encoder.",
            "Or we could use something called a contractive autoencoder, which forces the hidden layer of the code layer to be insensitive to the input."
        ],
        [
            "OK, so let's just take a little closer look at each of these methods.",
            "So in sparse Arlington coders we have in the loss function this first part of the objective, which is just a Fidelity measure between X, the input an X hat, which is the reconstruction of that input.",
            "OK, so this is the auto encoding part, right?",
            "So give me back something that looks like the input, but then also penalize the KL divergent between two distributions.",
            "One is the observed activation.",
            "Of these code units or hidden units, and one is a target probability, which is just something small.",
            "OK, so these are Bernoulli distributions, single parameter, so in a sense we this is predictive opposition between reconstructing accurately but maintaining a low activation on these units.",
            "In the code on average.",
            "So this is called a sparse autoencoder."
        ],
        [
            "Denoising autoencoder is a little bit different.",
            "There's an extra stage here.",
            "We say we ever input, we corrupt it in some way using, say, a Gaussian distribution.",
            "That's one possible choice without some Gaussian noise to it, map that to a code and then reconstruct the clean thing.",
            "OK, so even though I corrupted it, we need you to get back the clean thing.",
            "So now copying that input directly to the code is not going to help because you're going to copy the noisy input to the code.",
            "So this is a different type of regularizer regularizer."
        ],
        [
            "Contractor autoencoders do something again slightly different, so they again have this measure of Fidelity between the input and the reconstruction here.",
            "But they also have this penalty penalty on the sensitivity of the code with respect to the input.",
            "OK, so really what you're doing is you're kind of shutting it down in all dimensions.",
            "But this guy, the Fidelity term, forces it to to actually do an accurate reconstruction.",
            "So what happens is it is allowed to vary in dimensions that are effective in reconstructing the data, but it doesn't vary in directions that are orthogonal to that.",
            "OK.",
            "I only have a few minutes left, So what I'm going to do is I'm going to jump to.",
            "Deeper models and stacking."
        ],
        [
            "OK, so.",
            "Essentially, an important part of unsupervised learning in building deep learning models is the ability to take these fundamental building blocks like autoencoders and restricted Boltzmann machines, which I didn't really talk too much about, but build deeper models out of them and so.",
            "The most of the work, sort of around the time of 2006, 2007 was focused on stacking these models called restricted Boltzmann machines, which are probabilistic models.",
            "But you can also, they're very similar to autoencoders.",
            "There are two layer model.",
            "There's an input and there's some sort of representation that's been learned that learn from that input and."
        ],
        [
            "The idea is you can think of this as training RBM or training an autoencoder.",
            "OK, so you have an objective.",
            "It could be something like reconstruction.",
            "You learn to extract codes from data.",
            "OK, so then you take the codes that are produced been produced from that model."
        ],
        [
            "And then you train the same model, but instead of on the original data you train it on the codes themselves.",
            "OK, you're going to run your whole training data set through that model, produce a new data set of codes, and then train an identical model on top of it.",
            "And then maybe you're going to do that again."
        ],
        [
            "OK, so this gives you a."
        ],
        [
            "Stack of autoencoders or Stalker restricted Boltzmann machines.",
            "You then compose the two models.",
            "So if you do this for restricted Boltzmann machines you end up with a hybrid model which is sort of.",
            "It has directed connections in the lowermost layers and it has undirected connections in the topmost layers.",
            "This thing is called a deep."
        ],
        [
            "Belief network OK, this weird sort of hybrid between undirected and directed models.",
            "This is sort of the first stacked variant of unsupervised deep learning architecture.",
            "What you can do after stacking this model up where you've trained it layer by layer, as you can train the whole thing either using a generative objective or a discriminative objective.",
            "So if your task at the end of the day is going to be doing classification, you can stick.",
            "On the top some units which are representing the output safe class labels and then you can just train this model using backpropagation that we talked about before.",
            "OK, so you've initialized with the weights.",
            "In this model, your forward weights going up here are now your forward weights and justice, standard neural network and you can train that with the supervised criterion.",
            "You can also train this using.",
            "Like I said, a general objective with something like the Wake sleep algorithm.",
            "But essentially this gives you a more powerful model, so yeah.",
            "So the motivations here is that you know."
        ],
        [
            "And we do this, what's happening well in a probabilistic model, like a DB DBN.",
            "There's several distributions involved, so there's the joint distribution between the input and hidden representation.",
            "There is these.",
            "Conditional distributions sort of doing the inference of the hiddens, or reconstruct into the visibles.",
            "And there's also marginal distributions over the vegetables in the hidden's, and so when we express the PBM joint distribution marginalized over the head ends and we get the marginal over the visibles, we can see it as.",
            "Coming from a joint marginal over the Hidden Zan conditional distribution.",
            "Given the hidden reconstructing the visibles, what we're going to do when we we stack our BMS is at each layer we're going to throw away this marginal distribution over the head ends, and we're going to replace it with another distribution, right?",
            "So this is what happens when we map our inputs to some code vectors, and we now train a model in this code, vectors were throwing away the implicit prior on those hidden's by the original model and replacing it with a new P of H. OK, so if we improve the PMH.",
            "This is improving the the joint model.",
            "OK so.",
            "I."
        ],
        [
            "That's that's all I'm going to talk about today.",
            "I'll just I'll just conclude.",
            "By saying that.",
            "There is.",
            "You know, been a number of advancements in deep learning.",
            "A lot of these architectures are not necessarily new, but we've come up with some architectural improvements.",
            "Reliz normalization types of regularizers like dropout and so forth.",
            "This combined with more data, faster computers.",
            "Has really changed the landscape in terms of the types of problems we can solve.",
            "People are excited about these models and there's solid motivations for them so.",
            "Going forward into the future, I think unsupervised learning is going to be important.",
            "For a number of reasons.",
            "And it's not really just about building better supervised models, it's about dealing with the sheer amount of data that's out there.",
            "That's not necessarily labeled, and also looking at harder problems, not just necessarily classification and regional recognition problems.",
            "But all types of structured output problems and so forth.",
            "And so I hope this is useful to you.",
            "Sort of getting some of the background on deep learning what some of these models, how they operate, what are the motivations, and you'll hear this afternoon more practical details from Pascal.",
            "In terms of building up some of these models in the Python based framework, so with that thank you very much for your attention and look forward to chatting with you later."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This, I guess, begins a day on deep learning and Pascal is going to speak after me and he's going to focus on some of the tools for building deep learning style models, so I'm going to start the day by giving an overview of several of the different deep learning architectures, and this tutorial is aimed at going to cover the grounds for people that don't know anything about deep learning.",
                    "label": 1
                },
                {
                    "sent": "So if you're already a deep learning expert, I apologize for.",
                    "label": 0
                },
                {
                    "sent": "Going through some of these basic models, but is designed as a tutorial and please feel that feel free to ask questions as I move along.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the way that I'm going to structure this tutorial this morning is I'm going to start by giving some motivations by deep up deep learning, and I think one of the reasons we're here and we're talking about it is because there's been some tremendous gains in the last few years, so I'll talk about why these gains have happened and put it in context and talk about why it's worth studying.",
                    "label": 0
                },
                {
                    "sent": "Deep learning.",
                    "label": 0
                },
                {
                    "sent": "Is this just another trend?",
                    "label": 0
                },
                {
                    "sent": "Is another sort of peak in the peaks and valleys of neural networks, or is this something we're going to be talking about for awhile?",
                    "label": 0
                },
                {
                    "sent": "Next I'm going to go onto.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To specific methods, and so I'm going to spend probably about 60% of the time talking about actual deep learning models.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And cover the covering them in both.",
                    "label": 0
                },
                {
                    "sent": "The paradigms are supervised and unsupervised learning, and then because it's a technical computing workshop, I'm going to focus on some of the technical challenges that are raised by deep learning and not talk a whole lot about that.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But I'm going to give some pointers to some of the tools, and then Pascoe lamblin after after my talk will actually go through and talk to you about some of the Python based frameworks for building deep learning models.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's talk.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Graph about learning, talking about learning representation, representation, learning is something that's.",
                    "label": 0
                },
                {
                    "sent": "Underlying deep learning and the idea of learning representations is that we want to extract concepts or abstracts that are present in the data and these make us help us make sense of the variability that exists in data.",
                    "label": 1
                },
                {
                    "sent": "So a lot of methods have proposed ways of engineering or handcrafting desirable features for data.",
                    "label": 1
                },
                {
                    "sent": "These features are often designed to be sensible or sensitive to variables of interest, but remain insensitive to other factors which explain variability.",
                    "label": 0
                },
                {
                    "sent": "So for example, noise in the data.",
                    "label": 0
                },
                {
                    "sent": "So what differs representation?",
                    "label": 0
                },
                {
                    "sent": "Learning from a lot of the existing feature extraction methods out there is that the features themselves are learned from the data extracted automatically, and I'll talk a little bit more about why we might want to do that.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so it pictured at top here is an architecture called a convolutional neural net and this is essentially the current hammer of deep learning.",
                    "label": 0
                },
                {
                    "sent": "Everybody is applying this in particular in the vision community because this is a model that's designed specifically for 2D data.",
                    "label": 0
                },
                {
                    "sent": "There are one variations of comments, so they can be applied to, for example, audio data as well, but most of the success has been found in vision, community and.",
                    "label": 0
                },
                {
                    "sent": "There's a few motivations here for why we might want to study this model, like why is this not just to try anything that we're talking about now?",
                    "label": 0
                },
                {
                    "sent": "Why is it something might consider for the future?",
                    "label": 0
                },
                {
                    "sent": "And certainly there's theory out there that tells us there are certain classes of problems and certain functions that are more efficiently expressed as a series of K layers.",
                    "label": 0
                },
                {
                    "sent": "An if we would want to represent these functions as just a two layer problem, we could do it, but it would take exponentially more.",
                    "label": 0
                },
                {
                    "sent": "Variables to do so, so certain classes of problems are just more efficiently represented by multiple layers.",
                    "label": 0
                },
                {
                    "sent": "Of course, as humans, we will often take problems and break them down so we can understand them by studying the smaller pieces.",
                    "label": 0
                },
                {
                    "sent": "So composition is something that comes natural to us.",
                    "label": 0
                },
                {
                    "sent": "Engineers will take problems and break them into pieces and analyze them individual and individually, and build up abstractions from these concepts.",
                    "label": 0
                },
                {
                    "sent": "So it's something that's native to human organization and thought.",
                    "label": 0
                },
                {
                    "sent": "And finally, I'm going to make just a very weak link to biology here.",
                    "label": 0
                },
                {
                    "sent": "The models that we talk about, and especially the types of models that I'm going to be discussing today, are very, very loosely connected to biology, but certainly the brain is deep and use mostly uses multiple layers of representation, and so there is a biological motivation and you'll see work in the deep learning community.",
                    "label": 0
                },
                {
                    "sent": "That's even more motivated by biology and closer, closer connected to biology.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so just to give an overview of what's happened in recent years, I just like to put some major milestones.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In front of you.",
                    "label": 0
                },
                {
                    "sent": "So I would say that the current deep learning wave started in sometime around 2006 when people began to pre train and stack restricted Boltzmann machines.",
                    "label": 0
                },
                {
                    "sent": "So this was the rise of a model called deep belief networks and people within the Community got very excited about that.",
                    "label": 0
                },
                {
                    "sent": "At that time it was it was found that networks could be very deep.",
                    "label": 0
                },
                {
                    "sent": "Networks could be trained and optimized more efficiently by first using unsupervised learning procedures.",
                    "label": 0
                },
                {
                    "sent": "Learning the layers one at a time and then doing some fine tuning for a discriminative or super supervised task.",
                    "label": 0
                },
                {
                    "sent": "This got a lot more people interested in the problem working on neural networks again.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And ideas technical ideas were explored, sort of in the years between 2006 and 2012.",
                    "label": 0
                },
                {
                    "sent": "So when I idea that I'll talk about today is the idea of rectifier units, this is an alternative type of non linearity for networks.",
                    "label": 0
                },
                {
                    "sent": "Instead instead of the traditional sigmoid style functions are Tan, H is.",
                    "label": 0
                },
                {
                    "sent": "There's other ideas like dropout.",
                    "label": 0
                },
                {
                    "sent": "Maybe some of you have heard about some of these technical innovations were put forward and used for more efficiently training neural network.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It was actually the speech community that latched on to these models even before the vision community, so in terms of the.",
                    "label": 0
                },
                {
                    "sent": "The commercial impact some of the major speech groups like IBM, Microsoft and Google started using some of these deep learning models and actually experienced pretty major gains.",
                    "label": 0
                },
                {
                    "sent": "And there's some review papers written where a bunch of these groups from competing companies have come together and talked about the impact that deep learning systems have made on their recognizers.",
                    "label": 0
                },
                {
                    "sent": "There was a major breakthrough in 2012 and this is when Alex Kryszewski, who is a student at U of T trained convolutional neural net like the one I just pictured on a data set called Image Net.",
                    "label": 0
                },
                {
                    "sent": "And what was significant about that is that image Net was not amnist.",
                    "label": 0
                },
                {
                    "sent": "OK so Emnace is a favorite data set of neural Nets.",
                    "label": 0
                },
                {
                    "sent": "People been used for many years has about 60,000 examples and the images are very small or 28 by 28.",
                    "label": 0
                },
                {
                    "sent": "Image net has much larger images or different sizes, but it's not really even the resolution of the image is.",
                    "label": 0
                },
                {
                    "sent": "It's the fact that there's over a million images in image NET.",
                    "label": 0
                },
                {
                    "sent": "OK, so so Alex had really scaled up neural Nets and this one over a lot of critics and people that were skeptical of deep learning.",
                    "label": 0
                },
                {
                    "sent": "And so he showed that a large scale visual recognition task could be approach using deep learning method and he actually ended up winning this competition.",
                    "label": 0
                },
                {
                    "sent": "And winning a lot of people over the image that had a thousand categories as well.",
                    "label": 0
                },
                {
                    "sent": "So it was a much more challenging classification task then say digit recognition.",
                    "label": 0
                },
                {
                    "sent": "But this got a lot more people working on deep learning problems and excited about it.",
                    "label": 1
                },
                {
                    "sent": "And you'll see this in the ensuing years like Google and Baidu and Facebook making talent acquisitions in this area an lot.",
                    "label": 0
                },
                {
                    "sent": "Really latching on the deep learning.",
                    "label": 1
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Where we are right now is in the midst of a sort of a deep learning wave and a lot of hype being spread at the CPR 2014 conference, which just happened this past June.",
                    "label": 0
                },
                {
                    "sent": "There was actually a separate session devoted to compenents, which I'll talk about today in more depth, but that just shows, you know, at a mainstream vision conference people are really believing in these models now and returning to them even though they've been around for a long time.",
                    "label": 0
                },
                {
                    "sent": "But we're seeing another wave.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Let's talk about.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So it's traditional visual recognition versions versus deep learning, so typically visual recognition goes like this.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We have some input data we extract.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A bunch of low level vision features so things like sift descriptors, hog descriptors, local binary patterns or so forth, and then we do some operations that are nonlinear.",
                    "label": 0
                },
                {
                    "sent": "We may be quantized them, or we pull them and we build a vector representation from that.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we feed this vector representation to powerful machine learning model like a support vector machine.",
                    "label": 0
                },
                {
                    "sent": "And the point here is that all of the learning is placed into the into the third stage here.",
                    "label": 0
                },
                {
                    "sent": "OK into the SVM for example so.",
                    "label": 0
                },
                {
                    "sent": "What's happening here is in the feature extraction stage, there's no learning at all, and So what deep learning is all about is putting learning into these stages right here.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The computer vision community has worked very hard on engineering different types of feature descriptors.",
                    "label": 0
                },
                {
                    "sent": "There's a few popular ones that I mentioned before up here.",
                    "label": 0
                },
                {
                    "sent": "There's obviously many more, and feature extraction is indeed very important.",
                    "label": 0
                },
                {
                    "sent": "So if you look at some work though.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A few years ago by Debbie Parekh and Larry Zitnik at Microsoft, they have a couple of CPR papers where they've essentially looked at a vision pipeline and tried to judge which part of that is most important.",
                    "label": 0
                },
                {
                    "sent": "So what they're doing is they're doing something called an ablation study.",
                    "label": 0
                },
                {
                    "sent": "So if you consider the first one, they essentially they look at the amount of training data, the learning algorithm, and the features that are involved in the recognition task.",
                    "label": 0
                },
                {
                    "sent": "And here they're looking at multiple recognition tests.",
                    "label": 0
                },
                {
                    "sent": "And they essentially take.",
                    "label": 0
                },
                {
                    "sent": "The machine out of the picture and insert a human via Amazon Mechanical Turk and when they do this, when they replace each of these stages with with a human, they find that it's actually the feature extraction that's more important than the algorithm itself, or even the amount of training data.",
                    "label": 0
                },
                {
                    "sent": "OK, they fold up this with another study where they don't look at sort of a very broadview, but they look at a specific algorithm and in the follow up paper a year later they look at a very specific problem.",
                    "label": 0
                },
                {
                    "sent": "Which person detection.",
                    "label": 0
                },
                {
                    "sent": "And they look at a specific model, which is a deformable part model.",
                    "label": 0
                },
                {
                    "sent": "So this is a very popular vision based architecture and at each stage of this deformable part model again they do the same thing.",
                    "label": 0
                },
                {
                    "sent": "They take out the machine learning component and they insert a human and so they do this with feature extraction part based extraction.",
                    "label": 0
                },
                {
                    "sent": "The spatial model stage where they assemble the parts into full components and then something called non maximal suppression and what they found here is that.",
                    "label": 0
                },
                {
                    "sent": "It was the part extraction of the part detectors, which were most sensitive to taking the machine out and putting the humans in OK.",
                    "label": 0
                },
                {
                    "sent": "So in other words, the humans were really able to improve over the machines when we stuck them in as human part detectors and not machine learning based part detectors.",
                    "label": 0
                },
                {
                    "sent": "So what does that mean?",
                    "label": 0
                },
                {
                    "sent": "So it means.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "These part detectors are are very important to visual recognition tests and part detectors represent something called mid level representations, so these can be things like continuations or parallelism or junctions or corners is after the stage of, for example, edge detection at the very bottom of one of these networks and object parts so little bits of bicycles or cellos orbits of human faces.",
                    "label": 0
                },
                {
                    "sent": "These are very difficult to describe with.",
                    "label": 0
                },
                {
                    "sent": "A program OK so you can write a simple filter, a program to do edge detection, but if you want to write a part of a bicycle wheel detector and get it right and be invariant to all kinds of different makes and models and sizes and views of bicycles, that's very difficult to hand engineer.",
                    "label": 0
                },
                {
                    "sent": "Alright, So what we'd like to do is, since part detection is very important part of a visual recognition algorithm, can we improve on just writing programs that describe what a nose or an I?",
                    "label": 0
                },
                {
                    "sent": "Should look at and.",
                    "label": 0
                },
                {
                    "sent": "This is the motivation to learn not only low level, but mid level representations as well.",
                    "label": 0
                },
                {
                    "sent": "OK, so the.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The typical deep learning approach looks something like this.",
                    "label": 1
                },
                {
                    "sent": "We have multiple layers of feature extraction.",
                    "label": 0
                },
                {
                    "sent": "OK, so down here would be the low level feature extraction component, which typically will extract things like edges.",
                    "label": 0
                },
                {
                    "sent": "Here is where mid level and high level parts start to be extracted.",
                    "label": 0
                },
                {
                    "sent": "An then after we've fed the output of each layer to the next layer to extract features.",
                    "label": 1
                },
                {
                    "sent": "Then we apply a classifier.",
                    "label": 0
                },
                {
                    "sent": "But what's happening compared to what we looked at before is we're not just training the classifier.",
                    "label": 0
                },
                {
                    "sent": "We're training all of these stages together.",
                    "label": 0
                },
                {
                    "sent": "OK, so typically using something called the backpropagation algorithm, which I'll talk about.",
                    "label": 0
                },
                {
                    "sent": "We actually compute some errors here, and we update the parameters of all these models at the same time in order to decrease our loss up here.",
                    "label": 0
                },
                {
                    "sent": "And this is also called end to end feature learning.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So to get a specific example of what's happening here, let's look at the problem of learning some features on images of peoples faces.",
                    "label": 0
                },
                {
                    "sent": "OK, so this data set is purely made up of cropped faces, like the one that you see here.",
                    "label": 0
                },
                {
                    "sent": "You take a region of an image you feed it into one of these feature extraction algorithms, and when I said those three stages that we just looked at before, these are the types of filters that emerged.",
                    "label": 0
                },
                {
                    "sent": "So these have all emerged automatically.",
                    "label": 0
                },
                {
                    "sent": "We haven't had to write any programs for my detectors or noted.",
                    "label": 0
                },
                {
                    "sent": "Noise detectors, I'll point out this is actually using a type of learning which is an unsupervised learning architecture, so that's why these look so nice.",
                    "label": 0
                },
                {
                    "sent": "OK, so typically when you're when you're learning supervised neural Nets, you don't get very crisp.",
                    "label": 0
                },
                {
                    "sent": "Decompositions of the sort that you see here.",
                    "label": 0
                },
                {
                    "sent": "But you'll see that this model is actually extracted edges to little bits of faces, and then at the very top.",
                    "label": 0
                },
                {
                    "sent": "Here we're seeing full faces, and this is probably at this time got a lot of people excited about.",
                    "label": 0
                },
                {
                    "sent": "Unsupervised deep learning just because of the visual quality of these filters, it really represented something close to what humans would describe if they, if they were to describe a face built up of its constituent parts.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So sure, these features look nice and they align with the decomposition that a human might make of a face.",
                    "label": 0
                },
                {
                    "sent": "So what's beyond that?",
                    "label": 0
                },
                {
                    "sent": "Beyond extracting some nice looking features, what's the point?",
                    "label": 0
                },
                {
                    "sent": "Well, in less few years these deep learning models have actually.",
                    "label": 1
                },
                {
                    "sent": "Seated the performance of a lot of traditional architectures, so it's the performance is actually getting a lot of people excited.",
                    "label": 0
                },
                {
                    "sent": "Image that is an example of a competition that's been one by one of these feature learning algorithms.",
                    "label": 1
                },
                {
                    "sent": "There's an appealing property of these algorithms that it should be easy to extend them to other domains, and people are actually starting to work with RGB plus D data from things like the Connect video.",
                    "label": 0
                },
                {
                    "sent": "There's been several methods proposed on working with video I've worked on that myself and.",
                    "label": 0
                },
                {
                    "sent": "We're also interested in working with other types of data like multispectral or hyperspectral, and we don't need to design new features for these platforms which is difficult to do.",
                    "label": 0
                },
                {
                    "sent": "We can simply apply these strategies directly to them.",
                    "label": 0
                },
                {
                    "sent": "The other argument is that if you're using a traditional feature extraction approach in which we're using engineered features, each of those feature extraction stages may take a long time to do OK, so if we're going to run dozens of features and extract them if they're all different, this is going to be prohibitive for large datasets.",
                    "label": 1
                },
                {
                    "sent": "Whereas these deep learning models tend to extract the same type of feature even though they're extracting 100 or 1000 features, the way that they're being extracted with the exact same, so they're very amenable to parallelization.",
                    "label": 0
                },
                {
                    "sent": "And we'll talk about parallelization strategies a little bit later on.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm going to talk about two different paradigms.",
                    "label": 0
                },
                {
                    "sent": "You know, for those of you who are here from the machine learning component of the workshop, you obviously know about supervised and unsupervised learning.",
                    "label": 1
                },
                {
                    "sent": "So the point here is that we can apply supervised feature learning strategies in cases where there's a lot of labeled data available.",
                    "label": 1
                },
                {
                    "sent": "But there's also a number of.",
                    "label": 0
                },
                {
                    "sent": "Let's just say maybe less popular, less recognized approaches for doing unsupervised feature extraction, but they're important, especially in cases where there isn't a lot of data.",
                    "label": 0
                },
                {
                    "sent": "Available.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "That's the beginning, and that's the end of the motivation component of this talk.",
                    "label": 0
                },
                {
                    "sent": "The next, the next person be actually talking a bit more about specific architectures for doing deep learning, and so deep learning is really all about neural networks, and I think it was Ronan Colbert who is credited with saying deep learning is just a trendy name for neural networks, and these models have been around for a long, long time.",
                    "label": 0
                },
                {
                    "sent": "Neural networks really are a way of building up complicated nonlinear functions from a series of simpler building blocks and.",
                    "label": 0
                },
                {
                    "sent": "Each of these simple building blocks we're going to have some parameters that are subject to training OK, and so in what I'm going to talk about when I describe neural networks.",
                    "label": 1
                },
                {
                    "sent": "Let's for now assume that the input is just a vector.",
                    "label": 1
                },
                {
                    "sent": "OK, so even if we're going to work on an image, we're going to collapse that into a vector, and we're going to ignore the spatial layout of the pixel.",
                    "label": 1
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so this like I said is likely going to be reviewed to those of you who are you who are fully aware of neural networks, but I just want to go through the basics so this is a picture of standard neural net where you might if you know about neural Nets, what might be a little bit different.",
                    "label": 0
                },
                {
                    "sent": "Here is a type of non linearity that we're using in these two stages, so this is called a rectified linear unit.",
                    "label": 0
                },
                {
                    "sent": "You might be used to seeing something like a sigmoid or A10H.",
                    "label": 0
                },
                {
                    "sent": "Is it essentially satisfies the same property of sort of inserting a non linearity in here so we don't just have a complete linear collapse and have a fully linear network, but this is just sort of outlining some of the notations, so we're putting in an input.",
                    "label": 0
                },
                {
                    "sent": "We're extracting multiple layers of what we call hidden units.",
                    "label": 0
                },
                {
                    "sent": "OK, so these are these are just vectors that are representations of the data, and typically these typically are higher dimensional than the data.",
                    "label": 0
                },
                {
                    "sent": "And then we have an output coming from our model.",
                    "label": 0
                },
                {
                    "sent": "OK, we're going to train this thing using supervised learning, so we're going to train it with matched input to output pairs.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, So what happens at the first stage?",
                    "label": 0
                },
                {
                    "sent": "First stage we apply a weight matrix, so W. These are the parameters of the model.",
                    "label": 0
                },
                {
                    "sent": "OK, these are learned by the learning algorithm.",
                    "label": 0
                },
                {
                    "sent": "We apply that to the input and that produces a new description of the data, which is the hidden hidden units.",
                    "label": 0
                },
                {
                    "sent": "And then we pass that through a non linearity.",
                    "label": 0
                },
                {
                    "sent": "The biases are not shown in this just for simplicity, but typically we have a linear offset term.",
                    "label": 0
                },
                {
                    "sent": "So, so we can represent affine transformations instead of just purely linear ones.",
                    "label": 0
                },
                {
                    "sent": "So this non linearity called Erelu has been something that's explored.",
                    "label": 0
                },
                {
                    "sent": "Like I said since about 2010 and it's actually made a big performance increase as opposed to using saturating type nonlinearities.",
                    "label": 0
                },
                {
                    "sent": "After we have.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Corrected the 1st.",
                    "label": 0
                },
                {
                    "sent": "Set of hidden units.",
                    "label": 0
                },
                {
                    "sent": "We apply the same sort of transformation a linear operation.",
                    "label": 0
                },
                {
                    "sent": "Add the bias and then a non linearity.",
                    "label": 0
                },
                {
                    "sent": "This Relu again and even though it's the same type of transformation, the parameters in this stage are different.",
                    "label": 0
                },
                {
                    "sent": "OK so this is a different type of weight matrix.",
                    "label": 0
                },
                {
                    "sent": "We learn those parameters as well and then finally we.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Extract the output again using a linear transformation.",
                    "label": 0
                },
                {
                    "sent": "There's no non linearity at this stage, so this produces a vector of real real valued outputs.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's a mapping from input output, you may.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "See different types of graphical depictions of this sorts of models, so you'll see block diagrams like the one I just discussed, which shows the non linearity.",
                    "label": 0
                },
                {
                    "sent": "You can show a little picture of the Relu and the weight matrix, like sort of a signal processing type of set up later in the talk will use this type of picture where we're just showing the units and representing the weight matrix via single link and then also you might see people be more explicit and actually write all the links in the weights.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is actually explicitly shows that each.",
                    "label": 0
                },
                {
                    "sent": "Hidden units in one layer is connected to all the hidden units in the next layer and this is what we mean by fully connected network people.",
                    "label": 0
                },
                {
                    "sent": "Also experiments with different types.",
                    "label": 0
                },
                {
                    "sent": "Experiment effective connectivity in these sorts of Nets, but by far this is the most popular.",
                    "label": 0
                },
                {
                    "sent": "People also introduce things like Skip Connections where you can connect one layer two layers further down the pipeline, but this is the classical type of setup will be talking about today.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so once you've defined a way to get from input to output, so this is the forward processing step you want to be able to run your model and tell how good it's performing is enabled to be able to train it, you need to come up with something like a loss function.",
                    "label": 0
                },
                {
                    "sent": "OK, so assuming that we're going to just do classification style set up here, we're going to match the inputs which we assume are real value.",
                    "label": 0
                },
                {
                    "sent": "Something like an image to a class label and the way that we're going to encode our class labels were going to do something called 1 hot encoding.",
                    "label": 0
                },
                {
                    "sent": "Where we have a vector of zeros which and the number of elements equal number of classes, and then we're going to insert a one in the place corresponding to the correct class, right?",
                    "label": 1
                },
                {
                    "sent": "So we're going to produce something at the end of the day that we need to make it look a little bit more like something like this, and So what we're going to do is we want to.",
                    "label": 1
                },
                {
                    "sent": "We also want something smooth and differentiable, so we're going to produce an output that essentially has the probability of each class.",
                    "label": 0
                },
                {
                    "sent": "The output being each class.",
                    "label": 0
                },
                {
                    "sent": "Given that input.",
                    "label": 0
                },
                {
                    "sent": "OK, so we gotta do is where they take the real valued vector coming out, which has a number of elements equal to the number of classes and normalize that so it adds up to one and it can be interpreted as probabilities.",
                    "label": 0
                },
                {
                    "sent": "So we're going to use were using nonlinear linear normalization operation called a softmax OK, and that just takes each element and normalizes, normalizes it by the other elements in the output and that will give us a vector of the output.",
                    "label": 0
                },
                {
                    "sent": "Which is which.",
                    "label": 0
                },
                {
                    "sent": "If you sum over the elements, that will sum to one and can be interpreted as probability of the correct class label.",
                    "label": 1
                },
                {
                    "sent": "OK, so then what happens in our loss is a natural loss function for this.",
                    "label": 0
                },
                {
                    "sent": "Sort of classification problem is just the negative log likelihood of the correct class given the input.",
                    "label": 0
                },
                {
                    "sent": "This is also called cross entropy.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so learning is going to consist of justice.",
                    "label": 0
                },
                {
                    "sent": "Minimizing this loss function with respect to the parameters sofita is the notation I'm going to use for the parameters in all stages of this network, so all of the weight matrices are make up this data.",
                    "label": 1
                },
                {
                    "sent": "And the question here becomes, how do we actually minimize this complicated function that consists of multiple stages?",
                    "label": 1
                },
                {
                    "sent": "And really, the answer is just.",
                    "label": 0
                },
                {
                    "sent": "It's an application of the chain rule of all of these blocks are differentiable themselves.",
                    "label": 1
                },
                {
                    "sent": "We can just apply the chain rule to the whole, the whole model, and this is called the backpropagation algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So many of you have probably already aware of backpropagation, but in case this is new just to give a little bit of intuition behind it, a similar strategy you could use is simply by taking each weight in isolation, perturbing that wait a little bit, and.",
                    "label": 0
                },
                {
                    "sent": "Looking at the loss and seeing if it decreases or increases OK, So what we're writing here is you take a particular wait, say in the first layer, OK, and there's a particular way IJ so it connects some unit J2 unit I and we're just going to add a very small amount to it.",
                    "label": 1
                },
                {
                    "sent": "OK, and we're going to measure the loss without that perturbation, and we're going to measure that loss with this perturbation, so this notation is just take out this weight and replace it by this weight plus epsilon.",
                    "label": 0
                },
                {
                    "sent": "OK, so if that little perturbation improves the loss or lowers the loss, then we're going to just keep that change to the weight and move on.",
                    "label": 0
                },
                {
                    "sent": "OK, if it actually ends up raising the loss so that little adjustment made things worse, then we're going to just move in the other way.",
                    "label": 1
                },
                {
                    "sent": "OK, so this is a way of learning by just wiggling the weights, but it's, uh, it's incredibly inefficient.",
                    "label": 0
                },
                {
                    "sent": "OK, So what you would have to do is for each weight, you would have to visit a number of input vectors.",
                    "label": 0
                },
                {
                    "sent": "Do this little wiggling operation and then sort of compute the average of this quantity over all of those.",
                    "label": 1
                },
                {
                    "sent": "OK, so we want to have something that doesn't scale in terms of the number of weights, which is essentially quadratic in the number of neurons and the number of data examples.",
                    "label": 0
                },
                {
                    "sent": "So a better thing to do.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is actually instead of perturbing each weight, we perturb the hidden unit activities.",
                    "label": 1
                },
                {
                    "sent": "OK, so we don't really have an idea of what their hidden, so we don't know what the hidden should should should should be, but we can use the proxy of the air.",
                    "label": 1
                },
                {
                    "sent": "How fast the error changes with respect to the hidden activities, as sort of a desired target signal.",
                    "label": 1
                },
                {
                    "sent": "OK, so by wiggling these hidden's or computing their derivatives we can.",
                    "label": 0
                },
                {
                    "sent": "Compute the change on the loss by the by wiggling this hidden and use this as a signal to drive the learning of the network, and So what we do is we compute error derivatives for all the hidden units in an efficient way at the same time, and then given the error derivatives of the loss with respect to the hiddens, we can easily compute the error derivatives of the loss with respect to the weights.",
                    "label": 1
                },
                {
                    "sent": "OK, so it says 2 step procedure, see how each stage of hedons affects the loss.",
                    "label": 0
                },
                {
                    "sent": "And then see how those parameters that are computing those hidden's or that are part of the computation of those hands are affected.",
                    "label": 0
                },
                {
                    "sent": "That makes up the backpropagation algorithm.",
                    "label": 0
                },
                {
                    "sent": "OK, so I'm going to.",
                    "label": 0
                },
                {
                    "sent": "Start at the top of the network or the the output stage and I'm going to start computing these error derivatives backward.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's start.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With the derivative of the output of the loss function with respect to the output of the network.",
                    "label": 0
                },
                {
                    "sent": "So I talked before about this normalization step called the softmax.",
                    "label": 0
                },
                {
                    "sent": "So to start off the chain rule we had to take the compute the loss and then take the derivative.",
                    "label": 0
                },
                {
                    "sent": "The loss with respect to the output of the network and it just happens to be sort of mathematically convenient that the derivative loss with respect to the output for the softmax ends up being something very simple.",
                    "label": 0
                },
                {
                    "sent": "I so it ends up doing just the difference between the.",
                    "label": 0
                },
                {
                    "sent": "Prediction of the class and the desired classes.",
                    "label": 0
                },
                {
                    "sent": "This guy is either a one or a zero, so if it's the you know, if we're predicting the class label the true class, this driver is going to be just simply a one for the two classes.",
                    "label": 0
                },
                {
                    "sent": "This guy is going to be 0 for every other class sets for every other other class, and so once we've computed that loss.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With respect to the output of the network, we start back propagating and so we take this and we use this quantity to compute the derivative of a loss with respect to the weights at this stage, and then the derivative loss with respect to the hidden units going in.",
                    "label": 0
                },
                {
                    "sent": "At this stage.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is again just application of the chain rule.",
                    "label": 0
                },
                {
                    "sent": "We take.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This the second guy that we've just computed derivative loss with respect to the second stage hidden units and again do the exact same thing.",
                    "label": 0
                },
                {
                    "sent": "So we compute the derivative loss with respect to the weights at this stage and drive along with respect to the input going into this layer.",
                    "label": 0
                },
                {
                    "sent": "So that's this quantity here via chain rule.",
                    "label": 0
                },
                {
                    "sent": "And then finally.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We sorry move back.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we compute the derivative.",
                    "label": 0
                },
                {
                    "sent": "The loss with respect to the first stage weights, and that's all we need.",
                    "label": 0
                },
                {
                    "sent": "So now we have the error derivatives with respect to each with respect to the parameters at each stage, and that gives us what we need to do to do a parameter update of the whole system.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So this.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This to our first technical challenge, so these networks, which we've discussed are basically built up of individual building blocks, and they have associated parameters we made have associated architectural settings.",
                    "label": 0
                },
                {
                    "sent": "For example, how many hidden units, what kind of non linearity we want to describe these in some convenient way and off to reuse the same sort of modules and build these up and not make errors in our programming.",
                    "label": 0
                },
                {
                    "sent": "So this requires us to define both the forward pass in the backwards pass for each module.",
                    "label": 1
                },
                {
                    "sent": "But there's Fortunately a number of libraries out there which allow us to assemble these neural networks that can be described as series of building blocks, and the most pop.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Other ones out there are torch cafe and the Python frameworks Theano and Pilot and two.",
                    "label": 0
                },
                {
                    "sent": "So Pascal is going to talk about Fiano Pilar into Theano, sort of the backbone of Pilar.",
                    "label": 0
                },
                {
                    "sent": "Two, Pilar, two let's you do this high level description of neural Nets cafe and torch also allow you to describe.",
                    "label": 0
                },
                {
                    "sent": "Describe neural Nets in their composition in a simple way and assemble them and also allow you to give you access to training algorithms.",
                    "label": 0
                },
                {
                    "sent": "They all give you access to GPS and so forth.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so we recently did tutorial at CPR.",
                    "label": 0
                },
                {
                    "sent": "This is back in June an we had representatives for each of these open source platforms.",
                    "label": 0
                },
                {
                    "sent": "Come and give talks and so these short talks on these on these different frameworks are available on this page and they provide useful information or you can just go to the various GitHub pages and check them out.",
                    "label": 0
                },
                {
                    "sent": "Now because Pascal is going to talk about Theano and Pilar and two.",
                    "label": 0
                },
                {
                    "sent": "I thought I'd just take a second and give an example of using Cafe cafe and torture.",
                    "label": 0
                },
                {
                    "sent": "Actually pretty similar.",
                    "label": 0
                },
                {
                    "sent": "But the.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, is you're going to define using any of these frameworks.",
                    "label": 0
                },
                {
                    "sent": "You'll find your network in terms of building blocks, so this is actually a convolution layer.",
                    "label": 0
                },
                {
                    "sent": "It's a little bit more complicated than the usual our standard neural network layer that we just talked about.",
                    "label": 0
                },
                {
                    "sent": "We will talk about convolution a little bit later on in this talk, but essentially you define some parameters associated with that layer, so filter sizes, number of number of outputs you have to describe what's going in and out of that layer, and then you also have to describe the parameters associated with it.",
                    "label": 0
                },
                {
                    "sent": "So I said there's some weights.",
                    "label": 0
                },
                {
                    "sent": "And there's some bias is typically a neural net.",
                    "label": 0
                },
                {
                    "sent": "Those are what are getting updated.",
                    "label": 0
                },
                {
                    "sent": "So how do you write this thing?",
                    "label": 0
                },
                {
                    "sent": "You just write it in a structured file like Jason or YAML Cafe ends up using something called Google Proto Buffers.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So once you've described it in terms of the architecture of the structure of the network, you need to tell how to.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Compute the forward pass in the backward pass.",
                    "label": 0
                },
                {
                    "sent": "OK, so you gotta write some code for going forward, so the transformation going from input to output and then you gotta write some code that goes back the other way.",
                    "label": 0
                },
                {
                    "sent": "So just like we talked about before how to compute derivatives of the output or the loss with respect to the parameters of network and also with respect to the input to that particular module, that gives you enough to be able to assemble these things together.",
                    "label": 0
                },
                {
                    "sent": "OK, So what does it actually look like in code?",
                    "label": 0
                },
                {
                    "sent": "So when.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Build up these modules in something like Cafe.",
                    "label": 0
                },
                {
                    "sent": "This is a very very simple, probably simplest neural net you could possibly have is actually a little bit logistic regression model, and so you define it.",
                    "label": 0
                },
                {
                    "sent": "You tell it well.",
                    "label": 0
                },
                {
                    "sent": "I'm going to.",
                    "label": 0
                },
                {
                    "sent": "I'm going to process some data.",
                    "label": 0
                },
                {
                    "sent": "This is the famous MNIST data set.",
                    "label": 0
                },
                {
                    "sent": "I'm going to process the examples in batches of 64 and I'm going to scale them and this produces a data.",
                    "label": 0
                },
                {
                    "sent": "The scale data and there's also a label associated with each data case.",
                    "label": 0
                },
                {
                    "sent": "And then I'm going to take the output and just apply a linear operator to.",
                    "label": 0
                },
                {
                    "sent": "This is just the weights times the inputs, so this represents our inner product component.",
                    "label": 0
                },
                {
                    "sent": "This type here Xavier.",
                    "label": 0
                },
                {
                    "sent": "This is a guy at University of Montreal who's famous for the paper on the rectified linear unit.",
                    "label": 0
                },
                {
                    "sent": "So it's just saying that this stage uses Relu type non linearity and and it produces this guy called IP and then we define this softmax loss which is what we talked about before.",
                    "label": 0
                },
                {
                    "sent": "This is a classification problem, so this is saying match the output of the network with the true label and apply this softmax locks already already talked about.",
                    "label": 0
                },
                {
                    "sent": "That's a very simple network.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Cafe also comes with some reference implementations of very complicated networks, so this is Alex Kraszewski's.",
                    "label": 0
                },
                {
                    "sent": "People call Alex net.",
                    "label": 0
                },
                {
                    "sent": "This is a network I showed you before which one image net.",
                    "label": 0
                },
                {
                    "sent": "If you roll out all of the layers in this you get something like 30 different layers.",
                    "label": 0
                },
                {
                    "sent": "So to write something like this just with no framework is actually very tedious.",
                    "label": 0
                },
                {
                    "sent": "You could get bugs and so forth, but because this is a number of repeated modules you can write this very efficiently in cafe or torch.",
                    "label": 0
                },
                {
                    "sent": "Or piloting too, they all have functionality with to assemble very complex neural networks.",
                    "label": 0
                },
                {
                    "sent": "And provide you all of the associated tools with parameterising them and training them and so forth.",
                    "label": 0
                },
                {
                    "sent": "OK, so I mentioned before.",
                    "label": 0
                },
                {
                    "sent": "At this stage we need to break both forward pass in the backwards pass so the backwards pass obviously.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It involves.",
                    "label": 0
                },
                {
                    "sent": "Computing gradients of the loss with respect to the input of a layer with respect to the parameters of a layer, and.",
                    "label": 0
                },
                {
                    "sent": "You can imagine once your network is up to 30 layers, that's going to be a little bit tedious to do and error prone.",
                    "label": 1
                },
                {
                    "sent": "Of course, if you do this yourself and this is what people have been doing for many years, you should numerically verify your gradients always get this easy to get bugs, but Theano actually gives you a functionality to automatically compute gradients.",
                    "label": 0
                },
                {
                    "sent": "You just write your network symbolically assemble the pieces.",
                    "label": 0
                },
                {
                    "sent": "And then ask it to do symbolic differentiation for you, and so this is one of the advantage of Theano versus the other.",
                    "label": 1
                },
                {
                    "sent": "The other frameworks is the idea that giving giving you this functionality of automatic differentiation.",
                    "label": 0
                },
                {
                    "sent": "So while Pascal is going to talk in depth about Theano, I thought I would just give you like a little teaser of what piano looks like.",
                    "label": 0
                },
                {
                    "sent": "OK, so the font size OK, maybe.",
                    "label": 0
                },
                {
                    "sent": "Little bit bigger.",
                    "label": 0
                },
                {
                    "sent": "See.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So basically here's my pointer.",
                    "label": 0
                },
                {
                    "sent": "OK, so theano?",
                    "label": 0
                },
                {
                    "sent": "It's essentially mathematical expression compiler, so a lot of people associated with neural Nets, but it's actually much more general than just building deep learning models, so you have to start up.",
                    "label": 0
                },
                {
                    "sent": "It's a Python based framework, so you going to do some imports from Theano, so there's a pretty printer in Theano function.",
                    "label": 0
                },
                {
                    "sent": "We're going to use.",
                    "label": 0
                },
                {
                    "sent": "We're also going to use an object called a piano tensor.",
                    "label": 0
                },
                {
                    "sent": "And so when we assemble models in Theano, we're actually going to.",
                    "label": 0
                },
                {
                    "sent": "Define these symbolic variables so X is a symbolic variable.",
                    "label": 1
                },
                {
                    "sent": "It's a scalar.",
                    "label": 0
                },
                {
                    "sent": "OK, so we're giving it a name X.",
                    "label": 0
                },
                {
                    "sent": "We're assigning it to X and we're telling you that it's a scalar, and it's a double variable.",
                    "label": 0
                },
                {
                    "sent": "We're then defining Y as a function of X. OK, so this is a symbolic expression, so it's just X squared alright, and So what we want to do is compute the symbolically the gradient of Y.",
                    "label": 0
                },
                {
                    "sent": "With respect to X, so we use this operator, the grad operator, so we're saying OK, so this is going to be another symbolic variable, and it represents the gradient of Y with respect to X, and then we print it out.",
                    "label": 0
                },
                {
                    "sent": "OK, so when we do this, we see that it's some kind of complicated nasty looking thing, but really all this is, it's just saying fill up a block that's the same size as X squared with with ones OK and then multiply that with.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "My scrolling is not working very well here, but it is saying essentially.",
                    "label": 0
                },
                {
                    "sent": "Multiply this was something that 2 * X to the 2 -- 1 which is just 2 * X OK, so that actually matches out even though it's kind of nasty.",
                    "label": 0
                },
                {
                    "sent": "But actually Theano optimizes that to a simpler expression.",
                    "label": 0
                },
                {
                    "sent": "Doesn't actually do all this stuff at runtime, but once we have this gradient as a symbolic expression, we can then create what's called Theano function out of it, and Theano function is the map from NUM PY variables to non play inputs and outputs.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is the stage at which are symbolic.",
                    "label": 0
                },
                {
                    "sent": "Variables get replaced by actual quantities.",
                    "label": 0
                },
                {
                    "sent": "OK, so we say I want a function that Maps inputs which is X.",
                    "label": 0
                },
                {
                    "sent": "We define that earlier a scalar X to this operation gradient of Y.",
                    "label": 0
                },
                {
                    "sent": "And so that creates our map.",
                    "label": 0
                },
                {
                    "sent": "We can we can call F of any of any number we can run it, and that actually gives us the gradients of Y with respect to X evaluated at that X.",
                    "label": 0
                },
                {
                    "sent": "So that's just a one stage.",
                    "label": 0
                },
                {
                    "sent": "Very simple function, but you can do this with a number of variables, change together and take gradients with respect to them and evaluate them.",
                    "label": 0
                },
                {
                    "sent": "And you can also do gradients of some.",
                    "label": 0
                },
                {
                    "sent": "Function with rate in some variable with respect to a number of different variables, in which case this will return a vector.",
                    "label": 0
                },
                {
                    "sent": "So you can also do full Jacobian hessian's what I was going to show at the end here is essentially this simplification that Theano does in terms of reducing that kind of nasty.",
                    "label": 0
                },
                {
                    "sent": "Expression at the top here to actually just two 2 * X. OK.",
                    "label": 0
                },
                {
                    "sent": "So it does have an optimizer that takes the the graph and reduces it to something that's more efficient.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "That's Theano, a very quick taste of it.",
                    "label": 0
                },
                {
                    "sent": "You'll see more about Theano this afternoon.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_49": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so the next technical challenge you're going to hear more about this at the at the conferences on optimization and historically the deep learning community or neural Nets community has hasn't used very complicated type of optimizers or they've been typically obsessed with stochastic gradient descent, in particular mini batch variants of gradient descent.",
                    "label": 1
                },
                {
                    "sent": "Bill often use tricks like momentum.",
                    "label": 0
                },
                {
                    "sent": "In recent years people have been experiencing are experimenting with different types of tricks like Nesterov style momentum.",
                    "label": 0
                },
                {
                    "sent": "RMS Prof.",
                    "label": 1
                },
                {
                    "sent": "Different RMS different types of adaptive learning rates and so forth, but you'll find that there's not a lot of evidence that these models are.",
                    "label": 0
                },
                {
                    "sent": "Optimize better using more complicated techniques or batch techniques.",
                    "label": 0
                },
                {
                    "sent": "So overwhelmingly you'll see scatter gradient descent applied.",
                    "label": 0
                },
                {
                    "sent": "What's more important?",
                    "label": 0
                },
                {
                    "sent": "What's more challenging?",
                    "label": 0
                },
                {
                    "sent": "I think in this community is not necessarily the parameter optimization, but the hyperparameter optimization.",
                    "label": 0
                },
                {
                    "sent": "So these are all in.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Different settings architectural configurations of these networks, their complicated things.",
                    "label": 0
                },
                {
                    "sent": "They have many of these hyperparameters associated with them.",
                    "label": 1
                },
                {
                    "sent": "Things like the learning rates, the number of layers, the number of hidden's per layer, the type of non linearity, all these different different things.",
                    "label": 1
                },
                {
                    "sent": "These have typically been set by just 6P.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Variance OK, so someone being sort of a neural network wizard, you'll see some volumes like the neural Nets, tricks of the trade out there, kind of giving some guidance of how to set some of these parameters, but it's not completely satisfactory just to have this wisdom sort of passed down from advisor to grad student.",
                    "label": 1
                },
                {
                    "sent": "So what's been hot in the last couple of years?",
                    "label": 0
                },
                {
                    "sent": "Or people applying different types of black box optimizers to do hyperparameter optimization of neural net?",
                    "label": 0
                },
                {
                    "sent": "OK, so the two most popular ones that have been used for.",
                    "label": 0
                },
                {
                    "sent": "Hyperparameter optimization of deep learning models are two projects that are both on GitHub.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One is called hyperopt.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is written by James Berger who who worked on piano and actually hyper up, uses Theano as its back end.",
                    "label": 0
                },
                {
                    "sent": "So at the end of the day everything is done symbolically.",
                    "label": 0
                },
                {
                    "sent": "It supports real valued quantities, discrete value quantities and it also has this these conditional dimensions.",
                    "label": 0
                },
                {
                    "sent": "So for example in the code here, we're defining a hyperparameter optimization of parameter space in which there is choice of a discrete variable, so.",
                    "label": 0
                },
                {
                    "sent": "This variable A has two outcomes, right?",
                    "label": 0
                },
                {
                    "sent": "It can take case one or case two if we choose case one, then we have a continuous variable which.",
                    "label": 0
                },
                {
                    "sent": "Is distributed according to this expression source of 1, plus some lognormal and it has associated range with it.",
                    "label": 0
                },
                {
                    "sent": "If we take case 2 for our first variable, then this.",
                    "label": 0
                },
                {
                    "sent": "As is other hyperparameter associated with which is C2 and it's just uniformly distributed.",
                    "label": 0
                },
                {
                    "sent": "OK, so you can build up fairly complicated parameter spaces and then do this hyperparameter optimization in a distributed way.",
                    "label": 0
                },
                {
                    "sent": "And it has ways of plugging in different types of algorithms.",
                    "label": 0
                },
                {
                    "sent": "So it's quite flexible.",
                    "label": 0
                },
                {
                    "sent": "It's been used on a lot of different deep learning projects and the other one that's out there is is called.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Pierement, which is more focused on a specific class of Bayesian optimization algorithms.",
                    "label": 0
                },
                {
                    "sent": "But again it's being used by quite quite a number of people.",
                    "label": 0
                },
                {
                    "sent": "It's also on GitHub.",
                    "label": 0
                },
                {
                    "sent": "It's been extended to something called Spearmint Solid, which essentially just uses is a way of doing sort of ensembles of meta optimization algorithms.",
                    "label": 0
                },
                {
                    "sent": "So all of these make the search over this very complicated parameter space A little bit easier to.",
                    "label": 0
                },
                {
                    "sent": "To swallow.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's neural networks standard neural networks.",
                    "label": 0
                },
                {
                    "sent": "That's sort of the.",
                    "label": 0
                },
                {
                    "sent": "Background for deep learning.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let's talk a little bit more about the limitations of standard neural networks.",
                    "label": 0
                },
                {
                    "sent": "For large datasets, I'm going to keep talking about images.",
                    "label": 0
                },
                {
                    "sent": "So let's just say we don't have an image Patch anymore.",
                    "label": 1
                },
                {
                    "sent": "We have an image that's 200 by 200, so I told you before.",
                    "label": 0
                },
                {
                    "sent": "If we want to process image data using a neural net.",
                    "label": 0
                },
                {
                    "sent": "Typically what we would do is take all of the pixels in that image.",
                    "label": 0
                },
                {
                    "sent": "We flatten it to a vector and then we have a fully connected model, right?",
                    "label": 0
                },
                {
                    "sent": "So we've connected every single pixel in that image to every single neuron or hidden unit in the first layer.",
                    "label": 1
                },
                {
                    "sent": "So if we do this for 200 by 200 image and we have 40,000 hidden units, the number of weights that need to be learning that model is something like 2 billion parameters.",
                    "label": 0
                },
                {
                    "sent": "OK, so there's some problems with this.",
                    "label": 0
                },
                {
                    "sent": "One is that we're never going to have enough data to even fit this number of parameters, and also we're doing a lot of wasted work, so typically the correlation images is very local.",
                    "label": 0
                },
                {
                    "sent": "OK, so we're not going to be searching for feature detectors that need to consider very wide spatial dependencies.",
                    "label": 0
                },
                {
                    "sent": "It makes much more sense.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Actually connect up these hidden units in a very local way.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's do that.",
                    "label": 0
                },
                {
                    "sent": "So let's take each hidden unit instead of connecting it to all the pixels, we're going to just connect it to 10 by 10 window of pixels OK, and if we do that, we still have 40,000 hidden units, and we use this 10 by 10 window.",
                    "label": 0
                },
                {
                    "sent": "We're going to end up going from 2 million to four million parameters, so this is much easier to deal with.",
                    "label": 0
                },
                {
                    "sent": "Now the idea of right now the way that we've done this is this is a different set of parameters.",
                    "label": 0
                },
                {
                    "sent": "This is different set of parameters.",
                    "label": 0
                },
                {
                    "sent": "So is this and so is this.",
                    "label": 0
                },
                {
                    "sent": "There's.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Actually, stationarity in this problem and that if we're going to build something like an eye detector, why'd build an eye detector over here and I detector over here and I detector over here.",
                    "label": 0
                },
                {
                    "sent": "Why not just build it once?",
                    "label": 0
                },
                {
                    "sent": "OK, so that's the motivation for essentially sharing parameters.",
                    "label": 0
                },
                {
                    "sent": "So now we're going to have these.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hidden units that only look at a local region, but the parameters of each hidden unit that looks at a different local region that shared with all the other guys.",
                    "label": 0
                },
                {
                    "sent": "OK, so here you have a single set of parameters is 10 by 10, so it's 100 numbers and it gets used everywhere.",
                    "label": 0
                },
                {
                    "sent": "So every hidden unit uses the same weight matrix or filter whatever you want to call it.",
                    "label": 0
                },
                {
                    "sent": "So this can actually be when you when you want to extract a number of hidden units that look at different patches of the image is this can be implemented efficiently using a convolution.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is where we're getting to in terms of convolutional neural net.",
                    "label": 0
                },
                {
                    "sent": "Your hidden units are spatially arranged.",
                    "label": 0
                },
                {
                    "sent": "They share their parameters and this is computed via convolution so.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A convolutional layer when we actually do a convolution, it's taking an image, convolving it with some filter.",
                    "label": 0
                },
                {
                    "sent": "This is a three by three.",
                    "label": 0
                },
                {
                    "sent": "We're looking at 10 by 10 region before and this produces some new representation.",
                    "label": 0
                },
                {
                    "sent": "We call this a feature map.",
                    "label": 0
                },
                {
                    "sent": "OK, so here we just used an edge filter system, extracting horizontal edges.",
                    "label": 0
                },
                {
                    "sent": "This produces a new representation of the image.",
                    "label": 0
                },
                {
                    "sent": "It's also 2D.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is a little bit different than standard neural Nets.",
                    "label": 0
                },
                {
                    "sent": "The representations produced by this.",
                    "label": 0
                },
                {
                    "sent": "What we're going to call in convolutional neural net are also spatially arranged.",
                    "label": 0
                },
                {
                    "sent": "Now the difference between this an what happens in the convolutional net is that this guy, the filter is learned OK, so typically we won't just learn a single.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Filter, but we'll learn multiple filters.",
                    "label": 1
                },
                {
                    "sent": "OK, so we see here with the red and the black.",
                    "label": 0
                },
                {
                    "sent": "These are different settings of those filters.",
                    "label": 0
                },
                {
                    "sent": "Typically will you will learn maybe between 10 and 100 of them at each layer.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "When we share the parameters at all locations and we maybe learn 100 of these filters, we've gone from now 4 million to 10,000 parameters.",
                    "label": 0
                },
                {
                    "sent": "OK, so what's the math in the convolutional?",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There, So what typically happens is you have a mapping from input feature Maps.",
                    "label": 1
                },
                {
                    "sent": "This is at one stage.",
                    "label": 0
                },
                {
                    "sent": "This is the.",
                    "label": 0
                },
                {
                    "sent": "This is essentially a tuning depiction of hidden units.",
                    "label": 0
                },
                {
                    "sent": "And we convolve that with the kernel, and we produce an output map.",
                    "label": 0
                },
                {
                    "sent": "And then we convolve the another input map with another kernel.",
                    "label": 0
                },
                {
                    "sent": "We produce an output map, and we sum these guys altogether and that produces our final output feature map.",
                    "label": 1
                },
                {
                    "sent": "OK, so you see here if this is the first layer of the network, it might be 3 channels representing something like red, green and blue.",
                    "label": 0
                },
                {
                    "sent": "Those get convolved with specific parameters and those produce output feature Maps now.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is a little picture of this, So what we need to do in terms of computing the operations is for each output feature map we need to involve a filter with the respective input map.",
                    "label": 0
                },
                {
                    "sent": "Each input map and then sum these guys together in that produces the output map.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Will be a set of three different filters associated with this second output map.",
                    "label": 0
                },
                {
                    "sent": "And in terms of the number of output Maps at each stage, this is again one of these hyperparameters that might be optimized via the hyper optimization framework.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "The other thing I just want to mention is that there's still a non linearity being performed in the convolutional layer, and this happens after we sum the responses of the convolutions with the individual input feature Maps.",
                    "label": 0
                },
                {
                    "sent": "And then there's a number of things that happened later, so let's just recap what we've gone through.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here if we apply just a fully connected standard neural network to images, it's going to scale quadratically in terms of the number of parameters with the size of the input is also, and it's not going to leverage stationarity, meaning that we're going to have to learn separate feature detectors at all locations of the image, so it makes much more sense to share the parameters, reduce the parameterisation in that network, and this thing is called a convolutional layer.",
                    "label": 1
                },
                {
                    "sent": "Any network that contains a convolutional layer is called a convolutional neural network.",
                    "label": 0
                },
                {
                    "sent": "OK, so this just happens that convolution is only the first stage of the convolutional neural network.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There's something else called a pooling layer, which is really important.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's assume that the filter is that's been learned as an eye detector.",
                    "label": 1
                },
                {
                    "sent": "OK, so how can we make the detection detector robust to the exact location of the eye?",
                    "label": 1
                },
                {
                    "sent": "So what we mean by that is we want to be able to have this response map fire when there's an eye in a particular location in sort of some local region, but we don't want to care of whether it's shifted one or two pixels over.",
                    "label": 0
                },
                {
                    "sent": "We want to get these same response, so this is also called learning invariants.",
                    "label": 0
                },
                {
                    "sent": "OK, we're learning shift invariants.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, So what we're going to do here is we're going to take the responses of a number of these neurons, and we're going to pull them into a single response.",
                    "label": 0
                },
                {
                    "sent": "So typically Max or an average operator is used, but there's a.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Number of different pooling's that have been done and compared in the literature beyond Max is an average is we can do for example L2 pooling in a spatial region.",
                    "label": 0
                },
                {
                    "sent": "But we can also do pooling, not just spatially, but we can do pooling in local neighborhoods.",
                    "label": 0
                },
                {
                    "sent": "A cross filters as well across features.",
                    "label": 0
                },
                {
                    "sent": "OK so we can do a combination of pulling across spatial regions.",
                    "label": 0
                },
                {
                    "sent": "Anna Cross features as well.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So apart from pooling in sort of modern day convolutional Nets, another architectural choice that makes a lot of difference is doing normalization at various stages with the network.",
                    "label": 0
                },
                {
                    "sent": "So at the input as well as the layers of the network themselves.",
                    "label": 0
                },
                {
                    "sent": "So when something called local contrast normalization we take a local neighborhood, we compute the mean and the standard deviation and so for each unit we're going to subtract the mean from the of the responses.",
                    "label": 1
                },
                {
                    "sent": "That are in a local region around it and divide by the standard deviation of the responses in a local neighborhood around it.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This allows us to, when we have highly variable feature Maps in terms of the responses, allows us to control the dynamic range and.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we get out a smooth feature map and this tends to improve in variance.",
                    "label": 0
                },
                {
                    "sent": "It makes the optimization more stable because we've controlled the range and it also increases sparsity.",
                    "label": 0
                },
                {
                    "sent": "And so compared to the first stage, the convolutional feature extraction this both the pooling and the local contrast normalization steps are really negligible in terms of the amount of computation needed.",
                    "label": 0
                },
                {
                    "sent": "OK, so convolutional filtering, rectification, local contrast normalization and pooling.",
                    "label": 1
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Those make up this a single stage of a convolutional neural net, so this kind of puts it all together.",
                    "label": 0
                },
                {
                    "sent": "Convolutional Nets are made up of multiple stacks of these stages OK, but each of these stages have these three operations which are important to making it work technically, and the main parameters associated with this block are the actual filters in the convolution convolutional layer here.",
                    "label": 0
                },
                {
                    "sent": "OK, so this goes.",
                    "label": 0
                },
                {
                    "sent": "It shows a little picture of what's happening with the filtering.",
                    "label": 0
                },
                {
                    "sent": "The non linearity, the rectification, we contrast, normalize and then we pull the responses down in that produces a smaller output map.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "In terms of building up the whole system, that was a single stage typically will stack multiple stages together and then we'll follow those by a few fully connected layers.",
                    "label": 1
                },
                {
                    "sent": "So what happens is we do each of these we're going to produce 2D structures right?",
                    "label": 0
                },
                {
                    "sent": "'cause the output of filtering normalization and pooling and so at the top.",
                    "label": 0
                },
                {
                    "sent": "Here we're going to have something that's a series of feature Maps and these are two D structures, but we're then going to collapse them down, just flatten them out into vectors and process them with the layers of a standard neural net.",
                    "label": 0
                },
                {
                    "sent": "Again, we generally have a number of these, typically something like one to three fully connected layers, and that's connected to something like a class label.",
                    "label": 0
                },
                {
                    "sent": "Or if you're doing regression or another task, you can change the output of that model.",
                    "label": 0
                },
                {
                    "sent": "But again, we train this thing via.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Back propagation.",
                    "label": 0
                },
                {
                    "sent": "So when we created accommodate all these operations that we talked about.",
                    "label": 0
                },
                {
                    "sent": "The convolution itself, the rectification, the normalization, the pooling.",
                    "label": 0
                },
                {
                    "sent": "These are all differentiable, so each block you can differentiate the output with respect to the input and that allows us apply the backpropagation algorithm.",
                    "label": 0
                },
                {
                    "sent": "So the training, these things which are obviously more complicated than standard neural Nets, is the exact same procedure you do a forward pass through the network, go from input to output, you perform backpropagation, and then you do a parameter update convolution.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And that's compared to standard neural Nets.",
                    "label": 0
                },
                {
                    "sent": "Is that you can scale them up very easily to larger images, so the convolution operation, as opposed to say sliding window based techniques in the vision literature.",
                    "label": 0
                },
                {
                    "sent": "You can reuse the computations involved and very efficiently compute features across a very large image just using the convolution.",
                    "label": 0
                },
                {
                    "sent": "You don't need to do separate computations of the net for each window across a larger image.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "These convolutional neural Nets are not new, they've existed in some shape and form since the early 80s.",
                    "label": 0
                },
                {
                    "sent": "Then Fukushima had something like very similar to modern modern day convolutional neural Nets, and until about 2012 the conventional wisdom was that these things are just hard to train because we end up in local minima.",
                    "label": 0
                },
                {
                    "sent": "It's very complicated, model is nonlinear, nonconvex.",
                    "label": 0
                },
                {
                    "sent": "We get stuck in local minima.",
                    "label": 1
                },
                {
                    "sent": "And that's all we can do.",
                    "label": 0
                },
                {
                    "sent": "The thinking has changed to some degree, in that the local minima are not really all that bad.",
                    "label": 0
                },
                {
                    "sent": "OK, there's a lot of local minima, but they all are essentially the same in terms of the value of the loss of the performance.",
                    "label": 0
                },
                {
                    "sent": "There's a lot of plateaus and it just takes a long time to break symmetry in these networks.",
                    "label": 1
                },
                {
                    "sent": "So we could just train them for longer.",
                    "label": 0
                },
                {
                    "sent": "And be more patient.",
                    "label": 0
                },
                {
                    "sent": "They can actually work, and if we have enough data to train them then they can actually do really amazing things.",
                    "label": 1
                },
                {
                    "sent": "So optimization given if we have enough data, we have enough flops to train these things and we make the right architectural settings, like using Relu units, using normalization and so forth.",
                    "label": 0
                },
                {
                    "sent": "Optimization is not really the challenges.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Challenges are more the generalization capability, so if we have a ton of parameters in this network, how much data do we really need to be able to train it and not overfit?",
                    "label": 0
                },
                {
                    "sent": "And also we want to train very high dimensional training, high dimensional data.",
                    "label": 0
                },
                {
                    "sent": "How many parameters would do we need to do?",
                    "label": 1
                },
                {
                    "sent": "We need to have and then again how many samples do we need to be able to fit those parameters?",
                    "label": 1
                },
                {
                    "sent": "OK, so scalability really is the issue and a lot of us working in this Community believe that it's really been changes in terms of scalability that which have pushed these models forward.",
                    "label": 0
                },
                {
                    "sent": "OK, it's not as much the algorithms there have been some architectural discoveries.",
                    "label": 0
                },
                {
                    "sent": "But it hasn't really been about the optimization.",
                    "label": 0
                },
                {
                    "sent": "People are still using SGD plus momentum as they have been for many years, and that's not to say that.",
                    "label": 0
                },
                {
                    "sent": "There may be discoveries on the optimization front, but up till now the main breakthroughs have really been in terms of scalability.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what's been happening is in people have been sorry this is cut off a little bit.",
                    "label": 0
                },
                {
                    "sent": "This is flops per second on the left, so people have been pushing out in terms of the flops.",
                    "label": 0
                },
                {
                    "sent": "GPU's have made a huge difference on this front and then we've also been pushing it on the data.",
                    "label": 0
                },
                {
                    "sent": "OK, so I said image Net was a big breakthrough because we were training on millions of images instead of 10s of thousands of images.",
                    "label": 0
                },
                {
                    "sent": "So as we've pushed out on the FLOPS per second in the data, this is allowed neural networks to be able to.",
                    "label": 0
                },
                {
                    "sent": "Expand In terms of the capacity of the number of parameters, so their complexity is going up, but they've been able to generalize because we have more data and we've actually been able to fit these things in a reasonable amount of time because we have the processing power.",
                    "label": 1
                },
                {
                    "sent": "So in sum.",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sense convolutional networks, even though they've been around for a while, they were in some sense premature because we just didn't really have the flops and we didn't have the datasets to train them.",
                    "label": 1
                },
                {
                    "sent": "OK, so in terms of.",
                    "label": 0
                },
                {
                    "sent": "Technical computing challenges.",
                    "label": 0
                },
                {
                    "sent": "It's really about.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Scalability.",
                    "label": 0
                },
                {
                    "sent": "OK so.",
                    "label": 0
                },
                {
                    "sent": "The good news is that deep learning architectures are very amenable to parallelization because of two reasons.",
                    "label": 0
                },
                {
                    "sent": "So one of the types of data that are are typically being used by things like common.",
                    "label": 0
                },
                {
                    "sent": "These things like image data, video data is made up of pixels, so it's very amenable to data based parallelization.",
                    "label": 0
                },
                {
                    "sent": "We're often performing the same operations like these convolutions on a number of pixels.",
                    "label": 0
                },
                {
                    "sent": "The other type of parallelization is the model based parallelization.",
                    "label": 0
                },
                {
                    "sent": "Based on this task, parallelism, so we have a number of hidden units or a number of units in the feature map.",
                    "label": 0
                },
                {
                    "sent": "All of those are being computed in the exact same way.",
                    "label": 0
                },
                {
                    "sent": "Those operations can be easily parallelized, so that's why all of these platforms that I mentioned earlier, like Torch and Theano and Cafe all provide transparent GPU support in the form of CUDA.",
                    "label": 1
                },
                {
                    "sent": "The deep learning in machine learning community in general has been really attached to CUDA because in the video came out with their hardware really far in advance of anybody else.",
                    "label": 0
                },
                {
                    "sent": "You'll see some open CL developments starting in Theano.",
                    "label": 0
                },
                {
                    "sent": "People are starting to work on Fpgas.",
                    "label": 0
                },
                {
                    "sent": "People are starting to design specialized hardware for deep learning as well.",
                    "label": 0
                },
                {
                    "sent": "In the last few years, so we'll start to see these sorts of models be demonstrated on various embedded platforms within the next few years.",
                    "label": 0
                },
                {
                    "sent": "It's not just constrained GPS and CUDA, but the bulk of the hardware acceleration is being done on the computer platform.",
                    "label": 0
                },
                {
                    "sent": "Oh yeah, so that includes the supervised learning part of the talk.",
                    "label": 0
                },
                {
                    "sent": "For the remainder of the session, I'm going to talk about.",
                    "label": 0
                },
                {
                    "sent": "Less well known or less recognized, especially in the last few years.",
                    "label": 0
                },
                {
                    "sent": "Avenue of Deep Learning, which is unsupervised learning.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Clearly, these impressive results com nights and so forth.",
                    "label": 0
                },
                {
                    "sent": "Winning competitions have all been done on supervised learning problems, usually with a lot of data, and typically it's been classification problems like visual recognition.",
                    "label": 0
                },
                {
                    "sent": "Progress has been slower on the front of unsupervised learning, but I believe that and many people in the community believe that unsupervised learning will be very important to the advances in deep learning and even though.",
                    "label": 1
                },
                {
                    "sent": "We're scaling up the amount of data that we have available to us.",
                    "label": 0
                },
                {
                    "sent": "That doesn't mean that we're always going to have labeled data available, so this is really about this sort of next part of the talk is about what do you do when you don't have access to a ton of labeled data, like image that when you have a thousand categories and you don't have 30 or 100 examples per category telling you what that class label is.",
                    "label": 0
                }
            ]
        },
        "clip_80": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So an interesting historical fact is that, as I mentioned earlier on the talk, the unsupervised learning algorithms based on deep techniques were actually the catalyst to a lot of the recent breakthroughs in deep learning.",
                    "label": 1
                },
                {
                    "sent": "So people in the last say three 2, three years have totally moved towards supervised learning and comments and so forth.",
                    "label": 0
                },
                {
                    "sent": "But what really got all this going was this idea of taking restricted Boltzmann machines.",
                    "label": 0
                },
                {
                    "sent": "Training layers greedily by themselves, and then stacking them into things called deep belief networks.",
                    "label": 0
                },
                {
                    "sent": "What happened is that as we talked about before, we got better algorithms like and tricks like nonlinearities and normalization and regularization like dropout.",
                    "label": 1
                },
                {
                    "sent": "We got more data, we got more GPU's and everybody kind of forgot about unsupervised learning.",
                    "label": 0
                },
                {
                    "sent": "But I think we should still care about it.",
                    "label": 0
                },
                {
                    "sent": "It's important and it's interesting.",
                    "label": 0
                },
                {
                    "sent": "It's fun to work on, so there's a new deep learning book out by.",
                    "label": 0
                }
            ]
        },
        "clip_81": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yoshua Bengio Aaron Courville Ian Goodfellow.",
                    "label": 0
                },
                {
                    "sent": "And there's a book draft available.",
                    "label": 0
                },
                {
                    "sent": "It's not out in published form yet, but in that book they talk about the reasoning behind unsupervised learning, and I want to make sort of.",
                    "label": 0
                },
                {
                    "sent": "I want to put these points out there, so the first one is that as I said, there's a lot of data out there.",
                    "label": 0
                },
                {
                    "sent": "We're getting more and more access to data, but it's not necessarily labeled OK.",
                    "label": 0
                },
                {
                    "sent": "So things like Google Glasses, YouTube, Flickr, they're generating a lot of data.",
                    "label": 0
                },
                {
                    "sent": "We have access to it, so we want to use it and leverage it.",
                    "label": 0
                },
                {
                    "sent": "We need to have unsupervised learning algorithms.",
                    "label": 1
                }
            ]
        },
        "clip_82": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now unsupervised learning algorithms also allow us to capture enough information about the variables to answer.",
                    "label": 1
                },
                {
                    "sent": "Questions that were not necessarily there at training time.",
                    "label": 1
                },
                {
                    "sent": "OK, so supervised learning algorithms were trained for specific problem, were able to ask for a very specific answer, which is an input output mapping.",
                    "label": 1
                },
                {
                    "sent": "Unsupervised learning algorithms are much more flexible.",
                    "label": 0
                },
                {
                    "sent": "OK, we train a model based density model.",
                    "label": 0
                },
                {
                    "sent": "We can ask it all kinds of different questions after the fact.",
                    "label": 0
                },
                {
                    "sent": "After it's been trained.",
                    "label": 0
                }
            ]
        },
        "clip_83": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The sort of restricted Boltzmann machine, deep belief network break through a number of years ago pointed us towards the fact that unsupervised learning could be an important regularization tool for deep learning.",
                    "label": 1
                },
                {
                    "sent": "OK, so it helps us generalize, and this is important to different regimes such as transfer learning, unbalanced classes, and zero shot.",
                    "label": 0
                },
                {
                    "sent": "One shot, learning and so forth.",
                    "label": 0
                },
                {
                    "sent": "There's been some work analyzing what happens when you do pretraining and you don't do.",
                    "label": 0
                },
                {
                    "sent": "Pre training so pre training is this process of unsupervised learning first followed by supervised learning.",
                    "label": 0
                },
                {
                    "sent": "And so there's a paper out of the Montreal Group from 2010 that essentially is a visualization of networks.",
                    "label": 0
                },
                {
                    "sent": "So each of these dots represents a different neural net.",
                    "label": 0
                },
                {
                    "sent": "OK, so as different parameters and these guys over here have been trained just using back propagation, no, pretraining these Nets over here have been trained using an unsupervised learning algorithm first.",
                    "label": 0
                },
                {
                    "sent": "Then training them with the supervised learning algorithm.",
                    "label": 0
                },
                {
                    "sent": "And So what you see happening over here is that the as we move from blue to green.",
                    "label": 0
                },
                {
                    "sent": "That's the training time.",
                    "label": 0
                },
                {
                    "sent": "And the network.",
                    "label": 0
                },
                {
                    "sent": "So these guys actually end up dispersing and these guys end up sort of converging as they as they train.",
                    "label": 0
                },
                {
                    "sent": "OK so again.",
                    "label": 0
                },
                {
                    "sent": "Some of the motivations here in terms of generalization and pre training have been eclipsed by the ability to train supervise for a longer amount of time.",
                    "label": 0
                },
                {
                    "sent": "But that doesn't mean that you know these results from a few years ago or invalid.",
                    "label": 0
                },
                {
                    "sent": "We may return to these sort of pre training strategies in the future.",
                    "label": 0
                }
            ]
        },
        "clip_84": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so another interesting aspect of unsupervised learning compared to supervised learning is that we can train it using local learning strategies.",
                    "label": 1
                },
                {
                    "sent": "OK, so there is sort of a credit assignment problem in deep networks, as we as we grow this network out in terms of the number of layers.",
                    "label": 0
                },
                {
                    "sent": "We're still stuck with taking some loss computing at computing some some error signal and back propagating it all the way through the network, and so this you may have heard of vanishing gradients.",
                    "label": 0
                },
                {
                    "sent": "That's what happens when we try to assign credit a very way along very far back.",
                    "label": 0
                },
                {
                    "sent": "In time and propagate this information to the layers and enrich.",
                    "label": 0
                },
                {
                    "sent": "It starts to disappear, whereas unsupervised learning algorithms actually just sort of capture layer by layer dependencies.",
                    "label": 0
                },
                {
                    "sent": "An patterns at a very local level and this makes them easier to train in that regard.",
                    "label": 1
                },
                {
                    "sent": "However, there's still motivations for wanting to train unsupervised learning algorithms.",
                    "label": 0
                },
                {
                    "sent": "From end to end, essentially and organizing them so that the upper layers know about representations that have been learned by the lower layers.",
                    "label": 0
                }
            ]
        },
        "clip_85": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And finally, another motivation for unsupervised learning is the parallels between what are called structured prediction problems and the challenges faced by unsupervised learning.",
                    "label": 1
                },
                {
                    "sent": "So even though all these successes as of late have been tests like recognition, there are a number of problems.",
                    "label": 0
                },
                {
                    "sent": "For example, attribute prediction, segmentation, producing language from images, sequence modeling and so forth that are called structured prediction tasks where the output is not just a single.",
                    "label": 1
                },
                {
                    "sent": "Class label, but it's a high dimensional.",
                    "label": 0
                },
                {
                    "sent": "Output with a lot of rich structure in it.",
                    "label": 0
                },
                {
                    "sent": "OK, and so the instance enforce consistency in that output and the types of computations that are performed in unsupervised learning problems can be leveraged for this sort of structure learning problem.",
                    "label": 0
                }
            ]
        },
        "clip_86": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so as we just discussed, when doing supervised learning, we learn a representation that's very specific for a particular task.",
                    "label": 0
                },
                {
                    "sent": "For example, classification the.",
                    "label": 0
                },
                {
                    "sent": "It's generally fairly easy to set up the error signal, 'cause it's very specific to the task.",
                    "label": 0
                }
            ]
        },
        "clip_87": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "When we come to unsupervised learning, we no longer have an output.",
                    "label": 0
                },
                {
                    "sent": "We don't have this input output relationship anymore, and it's also not clear to us what the error signal should be.",
                    "label": 0
                },
                {
                    "sent": "We're just giving these inputs and we need to build a model of them.",
                    "label": 0
                },
                {
                    "sent": "OK, so what's been proposed?",
                    "label": 0
                }
            ]
        },
        "clip_88": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Additionally, are things like.",
                    "label": 0
                },
                {
                    "sent": "Reconstruction error OK. Can you learn to just?",
                    "label": 0
                },
                {
                    "sent": "Produce some sort of representation or code from that input and reconstruct it.",
                    "label": 0
                },
                {
                    "sent": "People have proposed probabilistic techniques and just tried to maximize the likelihood of the data, the training data.",
                    "label": 0
                },
                {
                    "sent": "And also people like hung likely have looked explicitly at things like disentangle ING factors of variation.",
                    "label": 0
                },
                {
                    "sent": "OK, so can you build a hidden representation that is interpretable that takes the lighting and takes the orientation and takes the identity?",
                    "label": 0
                },
                {
                    "sent": "Out of these facial images and represents them as elements in a distributed representation.",
                    "label": 0
                },
                {
                    "sent": "OK, so the last part of this talk is just going to be talking a little bit more about specific methods for doing unsupervised learning, and so the main ones I was going to cover are autoencoders and restricted Boltzmann machines.",
                    "label": 0
                },
                {
                    "sent": "We'll see in terms of I know I have about 15 minutes left, so depending on how that goes we may talk about just one and not the other.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's talk about autoencoders first, because there.",
                    "label": 0
                },
                {
                    "sent": "Much more closely connected to the supervised neural Nets that we talked about earlier on OK, but to get at them it's useful to motivate them from a point of view of something that everybody most people here are probably familiar with, which is principal components analysis, so it's off.",
                    "label": 0
                }
            ]
        },
        "clip_89": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Often useful to create a lower dimensional representation for some data so you have data and dimensions and you want to represent represent it as.",
                    "label": 0
                },
                {
                    "sent": "And M dimensional vector and.",
                    "label": 0
                },
                {
                    "sent": "When your data lies on a linear manifold in high dimensions, you can use something called principle components analysis.",
                    "label": 1
                },
                {
                    "sent": "You just predict it projected to a lower dimensional subspace and you do this by searching for directions that have the most variance and.",
                    "label": 0
                },
                {
                    "sent": "Discarding the other directions right, and so you know, here's an example of some 2D data.",
                    "label": 1
                },
                {
                    "sent": "We find the direction of maximal variance, which is this.",
                    "label": 0
                },
                {
                    "sent": "This line here, and we take each point and we projected to this line, and so we're we completely lose all information and directions that are orthogonal to the direction we've selected.",
                    "label": 0
                },
                {
                    "sent": "OK, and this happens and happens in high dimensional high dimensions as well, but typically that's not a big deal because the dimensions that you're ignoring are the ones that have lower variance.",
                    "label": 0
                },
                {
                    "sent": "You can take this PCA model and implement it.",
                    "label": 0
                },
                {
                    "sent": "By a neural net.",
                    "label": 0
                },
                {
                    "sent": "OK, so typically people use eigenvector based methods to estimate PCA, but you can just take a MoD.",
                    "label": 0
                }
            ]
        },
        "clip_90": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that's a simple neural network where you have an input vector.",
                    "label": 1
                },
                {
                    "sent": "You have a code and then you have an output.",
                    "label": 0
                },
                {
                    "sent": "If you encourage the output to be a reconstruction of the input, and you do that through your loss function.",
                    "label": 1
                },
                {
                    "sent": "That will implement something very similar to PCA.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is just what we talked about before.",
                    "label": 0
                },
                {
                    "sent": "As a mapping from input to output, the difference is that we have some sort of loss function that just measures the Fidelity.",
                    "label": 0
                },
                {
                    "sent": "So these guys have to be the same dimensionality obviously, and the loss function is just ensuring that these things look similar.",
                    "label": 0
                },
                {
                    "sent": "And also it's important that the code here has fewer dimensions, right?",
                    "label": 0
                },
                {
                    "sent": "Otherwise we could just copy the input and then copy it again and just perfectly reconstruct it.",
                    "label": 0
                },
                {
                    "sent": "OK, so we have to create some sort of bottleneck.",
                    "label": 0
                },
                {
                    "sent": "The input gets projected down to some lower dimensional space, just like PCA can do.",
                    "label": 0
                },
                {
                    "sent": "And then we reconstruct it.",
                    "label": 0
                },
                {
                    "sent": "So it's a little bit different than PCA, because it won't necessarily find orthogonal feature vectors, and they'll have approximately equal variance, unlike the directions found in PCA.",
                    "label": 1
                },
                {
                    "sent": "But essentially it's the same, it will span the same subspace.",
                    "label": 1
                },
                {
                    "sent": "Now.",
                    "label": 0
                }
            ]
        },
        "clip_91": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Why would we want to fit PCA using backpropagation when we just have spectral methods to do so?",
                    "label": 1
                },
                {
                    "sent": "Well, it allows us to be much more flexible in terms of the types of functions we can represent, so we can actually take the.",
                    "label": 0
                },
                {
                    "sent": "The mapping from input to code and put extra layers in there OK and then we can also put extra layers between the code and reconstruction, and we generalize it.",
                    "label": 0
                },
                {
                    "sent": "This way we have something called an encoder and decoder, so this can use all kinds of fancy nonlinearities, multiple layers, normalization, even.",
                    "label": 0
                },
                {
                    "sent": "And these can be very flexible now.",
                    "label": 1
                },
                {
                    "sent": "So we just define sort of generic mapping differentiable of course from input to code and then code to reconstruction.",
                    "label": 0
                },
                {
                    "sent": "OK, so now we're able to represent data that doesn't necessarily lie on a linear manifold, so something that PCA is not necessarily good at capturing.",
                    "label": 1
                },
                {
                    "sent": "We can train this model using all the tools that we've just talked about earlier today, and this can be a very efficient.",
                    "label": 0
                },
                {
                    "sent": "A powerful way of discovering representations.",
                    "label": 0
                },
                {
                    "sent": "With a very simple training signal.",
                    "label": 0
                }
            ]
        },
        "clip_92": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So when we have this sort of generic PCA like learning architecture, this thing is called an autoencoder.",
                    "label": 0
                },
                {
                    "sent": "It's a feedforward network, is trained to minimize reconstruction error between the input and output, but either a bottleneck.",
                    "label": 1
                },
                {
                    "sent": "So making the code low dimensional or using some sort of regularization is essential.",
                    "label": 0
                },
                {
                    "sent": "Otherwise it can just cheat by copying the.",
                    "label": 0
                }
            ]
        },
        "clip_93": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Put OK.",
                    "label": 0
                }
            ]
        },
        "clip_94": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now, what if we're not using bottleneck hidden layers?",
                    "label": 0
                },
                {
                    "sent": "OK, or code vectors?",
                    "label": 0
                },
                {
                    "sent": "We want to actually take an input and produce a higher dimensional representation of it.",
                    "label": 0
                },
                {
                    "sent": "What can we do?",
                    "label": 0
                },
                {
                    "sent": "So what kind of?",
                    "label": 0
                }
            ]
        },
        "clip_95": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Regularization, can we?",
                    "label": 0
                },
                {
                    "sent": "Can we perform in this case?",
                    "label": 0
                },
                {
                    "sent": "We have to somehow restrict the capacity of the model, say by sparsity or some other method, and so there is this predictive opposition taking place between the network wanting to reconstruct the input accurately and also the regularizer tugging it back and keeping it making it very simple and sort of crippling the model in some way.",
                    "label": 0
                },
                {
                    "sent": "So what do we mean by simple or what do you mean by crippling it?",
                    "label": 0
                },
                {
                    "sent": "It could be making it compact that we talked about before it could be sparsity on the activations of the code layer.",
                    "label": 1
                },
                {
                    "sent": "It could be adding noise to the input and forcing the model to reconstruct a noisy version of the input.",
                    "label": 0
                },
                {
                    "sent": "This is something called a denoising auto encoder.",
                    "label": 0
                },
                {
                    "sent": "Or we could use something called a contractive autoencoder, which forces the hidden layer of the code layer to be insensitive to the input.",
                    "label": 1
                }
            ]
        },
        "clip_96": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so let's just take a little closer look at each of these methods.",
                    "label": 0
                },
                {
                    "sent": "So in sparse Arlington coders we have in the loss function this first part of the objective, which is just a Fidelity measure between X, the input an X hat, which is the reconstruction of that input.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is the auto encoding part, right?",
                    "label": 0
                },
                {
                    "sent": "So give me back something that looks like the input, but then also penalize the KL divergent between two distributions.",
                    "label": 0
                },
                {
                    "sent": "One is the observed activation.",
                    "label": 0
                },
                {
                    "sent": "Of these code units or hidden units, and one is a target probability, which is just something small.",
                    "label": 0
                },
                {
                    "sent": "OK, so these are Bernoulli distributions, single parameter, so in a sense we this is predictive opposition between reconstructing accurately but maintaining a low activation on these units.",
                    "label": 0
                },
                {
                    "sent": "In the code on average.",
                    "label": 0
                },
                {
                    "sent": "So this is called a sparse autoencoder.",
                    "label": 0
                }
            ]
        },
        "clip_97": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Denoising autoencoder is a little bit different.",
                    "label": 0
                },
                {
                    "sent": "There's an extra stage here.",
                    "label": 0
                },
                {
                    "sent": "We say we ever input, we corrupt it in some way using, say, a Gaussian distribution.",
                    "label": 0
                },
                {
                    "sent": "That's one possible choice without some Gaussian noise to it, map that to a code and then reconstruct the clean thing.",
                    "label": 1
                },
                {
                    "sent": "OK, so even though I corrupted it, we need you to get back the clean thing.",
                    "label": 1
                },
                {
                    "sent": "So now copying that input directly to the code is not going to help because you're going to copy the noisy input to the code.",
                    "label": 0
                },
                {
                    "sent": "So this is a different type of regularizer regularizer.",
                    "label": 0
                }
            ]
        },
        "clip_98": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Contractor autoencoders do something again slightly different, so they again have this measure of Fidelity between the input and the reconstruction here.",
                    "label": 0
                },
                {
                    "sent": "But they also have this penalty penalty on the sensitivity of the code with respect to the input.",
                    "label": 0
                },
                {
                    "sent": "OK, so really what you're doing is you're kind of shutting it down in all dimensions.",
                    "label": 0
                },
                {
                    "sent": "But this guy, the Fidelity term, forces it to to actually do an accurate reconstruction.",
                    "label": 0
                },
                {
                    "sent": "So what happens is it is allowed to vary in dimensions that are effective in reconstructing the data, but it doesn't vary in directions that are orthogonal to that.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "I only have a few minutes left, So what I'm going to do is I'm going to jump to.",
                    "label": 0
                },
                {
                    "sent": "Deeper models and stacking.",
                    "label": 0
                }
            ]
        },
        "clip_99": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Essentially, an important part of unsupervised learning in building deep learning models is the ability to take these fundamental building blocks like autoencoders and restricted Boltzmann machines, which I didn't really talk too much about, but build deeper models out of them and so.",
                    "label": 0
                },
                {
                    "sent": "The most of the work, sort of around the time of 2006, 2007 was focused on stacking these models called restricted Boltzmann machines, which are probabilistic models.",
                    "label": 0
                },
                {
                    "sent": "But you can also, they're very similar to autoencoders.",
                    "label": 0
                },
                {
                    "sent": "There are two layer model.",
                    "label": 0
                },
                {
                    "sent": "There's an input and there's some sort of representation that's been learned that learn from that input and.",
                    "label": 0
                }
            ]
        },
        "clip_100": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The idea is you can think of this as training RBM or training an autoencoder.",
                    "label": 0
                },
                {
                    "sent": "OK, so you have an objective.",
                    "label": 0
                },
                {
                    "sent": "It could be something like reconstruction.",
                    "label": 0
                },
                {
                    "sent": "You learn to extract codes from data.",
                    "label": 0
                },
                {
                    "sent": "OK, so then you take the codes that are produced been produced from that model.",
                    "label": 0
                }
            ]
        },
        "clip_101": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then you train the same model, but instead of on the original data you train it on the codes themselves.",
                    "label": 0
                },
                {
                    "sent": "OK, you're going to run your whole training data set through that model, produce a new data set of codes, and then train an identical model on top of it.",
                    "label": 1
                },
                {
                    "sent": "And then maybe you're going to do that again.",
                    "label": 0
                }
            ]
        },
        "clip_102": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so this gives you a.",
                    "label": 0
                }
            ]
        },
        "clip_103": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Stack of autoencoders or Stalker restricted Boltzmann machines.",
                    "label": 0
                },
                {
                    "sent": "You then compose the two models.",
                    "label": 0
                },
                {
                    "sent": "So if you do this for restricted Boltzmann machines you end up with a hybrid model which is sort of.",
                    "label": 0
                },
                {
                    "sent": "It has directed connections in the lowermost layers and it has undirected connections in the topmost layers.",
                    "label": 0
                },
                {
                    "sent": "This thing is called a deep.",
                    "label": 0
                }
            ]
        },
        "clip_104": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Belief network OK, this weird sort of hybrid between undirected and directed models.",
                    "label": 1
                },
                {
                    "sent": "This is sort of the first stacked variant of unsupervised deep learning architecture.",
                    "label": 1
                },
                {
                    "sent": "What you can do after stacking this model up where you've trained it layer by layer, as you can train the whole thing either using a generative objective or a discriminative objective.",
                    "label": 0
                },
                {
                    "sent": "So if your task at the end of the day is going to be doing classification, you can stick.",
                    "label": 0
                },
                {
                    "sent": "On the top some units which are representing the output safe class labels and then you can just train this model using backpropagation that we talked about before.",
                    "label": 0
                },
                {
                    "sent": "OK, so you've initialized with the weights.",
                    "label": 0
                },
                {
                    "sent": "In this model, your forward weights going up here are now your forward weights and justice, standard neural network and you can train that with the supervised criterion.",
                    "label": 0
                },
                {
                    "sent": "You can also train this using.",
                    "label": 0
                },
                {
                    "sent": "Like I said, a general objective with something like the Wake sleep algorithm.",
                    "label": 0
                },
                {
                    "sent": "But essentially this gives you a more powerful model, so yeah.",
                    "label": 0
                },
                {
                    "sent": "So the motivations here is that you know.",
                    "label": 0
                }
            ]
        },
        "clip_105": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we do this, what's happening well in a probabilistic model, like a DB DBN.",
                    "label": 0
                },
                {
                    "sent": "There's several distributions involved, so there's the joint distribution between the input and hidden representation.",
                    "label": 0
                },
                {
                    "sent": "There is these.",
                    "label": 0
                },
                {
                    "sent": "Conditional distributions sort of doing the inference of the hiddens, or reconstruct into the visibles.",
                    "label": 0
                },
                {
                    "sent": "And there's also marginal distributions over the vegetables in the hidden's, and so when we express the PBM joint distribution marginalized over the head ends and we get the marginal over the visibles, we can see it as.",
                    "label": 1
                },
                {
                    "sent": "Coming from a joint marginal over the Hidden Zan conditional distribution.",
                    "label": 0
                },
                {
                    "sent": "Given the hidden reconstructing the visibles, what we're going to do when we we stack our BMS is at each layer we're going to throw away this marginal distribution over the head ends, and we're going to replace it with another distribution, right?",
                    "label": 1
                },
                {
                    "sent": "So this is what happens when we map our inputs to some code vectors, and we now train a model in this code, vectors were throwing away the implicit prior on those hidden's by the original model and replacing it with a new P of H. OK, so if we improve the PMH.",
                    "label": 0
                },
                {
                    "sent": "This is improving the the joint model.",
                    "label": 0
                },
                {
                    "sent": "OK so.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                }
            ]
        },
        "clip_106": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That's that's all I'm going to talk about today.",
                    "label": 0
                },
                {
                    "sent": "I'll just I'll just conclude.",
                    "label": 0
                },
                {
                    "sent": "By saying that.",
                    "label": 0
                },
                {
                    "sent": "There is.",
                    "label": 0
                },
                {
                    "sent": "You know, been a number of advancements in deep learning.",
                    "label": 0
                },
                {
                    "sent": "A lot of these architectures are not necessarily new, but we've come up with some architectural improvements.",
                    "label": 0
                },
                {
                    "sent": "Reliz normalization types of regularizers like dropout and so forth.",
                    "label": 0
                },
                {
                    "sent": "This combined with more data, faster computers.",
                    "label": 0
                },
                {
                    "sent": "Has really changed the landscape in terms of the types of problems we can solve.",
                    "label": 0
                },
                {
                    "sent": "People are excited about these models and there's solid motivations for them so.",
                    "label": 0
                },
                {
                    "sent": "Going forward into the future, I think unsupervised learning is going to be important.",
                    "label": 1
                },
                {
                    "sent": "For a number of reasons.",
                    "label": 0
                },
                {
                    "sent": "And it's not really just about building better supervised models, it's about dealing with the sheer amount of data that's out there.",
                    "label": 0
                },
                {
                    "sent": "That's not necessarily labeled, and also looking at harder problems, not just necessarily classification and regional recognition problems.",
                    "label": 0
                },
                {
                    "sent": "But all types of structured output problems and so forth.",
                    "label": 1
                },
                {
                    "sent": "And so I hope this is useful to you.",
                    "label": 0
                },
                {
                    "sent": "Sort of getting some of the background on deep learning what some of these models, how they operate, what are the motivations, and you'll hear this afternoon more practical details from Pascal.",
                    "label": 1
                },
                {
                    "sent": "In terms of building up some of these models in the Python based framework, so with that thank you very much for your attention and look forward to chatting with you later.",
                    "label": 0
                }
            ]
        }
    }
}