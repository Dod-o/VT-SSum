{
    "id": "4yqmzuqtoh6otqiazg7d6yrswvvxajmi",
    "title": "Close-Range Human Detection and Tracking for Head-Mounted Cameras",
    "info": {
        "author": [
            "Dennis Mitzel, RWTH Aachen University"
        ],
        "published": "Oct. 9, 2012",
        "recorded": "September 2012",
        "category": [
            "Top->Computer Science->Computer Vision"
        ]
    },
    "url": "http://videolectures.net/bmvc2012_mitzel_human_detection/",
    "segmentation": [
        [
            "My name is Dennis Smith said, and this is joint work with Passion Library.",
            "And in this work we consider a problem of multi person detection from head mounted cameras, so before."
        ],
        [
            "Going into digital first show what I mean by head mounted camera."
        ],
        [
            "So you see, here is the setup we were using.",
            "So we have mounted the stereo camera bumblebee on the head on a helmet.",
            "In the corner above you will see.",
            "A theory estimation where we have used the algorithm from Andreas Geiger which was presented at ACC 2010.",
            "And So what is important to notice to notice in these sequences?",
            "As a pedestrian gets highly included, as soon as they come really close to the camera so we can have highly occlusions here on the image photos especially.",
            "And this makes of course as a problem of object detection, much more complex.",
            "So."
        ],
        [
            "As most of you might know.",
            "Robust multi person detection and tracking.",
            "It's important prerequisite for several applications, so speech for example in mobile robotics applications.",
            "As a position and.",
            "Also, velocity of moving obstacles.",
            "Could be really supportive for the past planning algorithms, especially the problem."
        ],
        [
            "We need to be able also to detect the pedestrians which are also here.",
            "So in order to avoid collisions because they are also very close to the camera.",
            "The problem is of course sets the standard full body object detectors, which are available.",
            "For example, Hawk are not really well suited for this problem.",
            "So for the Standard Hawk dispositions are basically invisible, so."
        ],
        [
            "Also part based approaches as one from Felton Schwab for example, have some difficulties in detect this pedestrians which are really close to the boundaries and in addition it's also computationally expensive.",
            "So the most related approach to our work is work from Choi at all, which was presented in ICT workshop in 2011.",
            "So there in they have introduced basically are manually generated tips template which they used on a smooth Kinnick data, so it performs surprisingly well on the Connect data, but on its own on our noisy steering stereo data, it doesn't perform so well, so."
        ],
        [
            "That's why we propose a extremely simple.",
            "It's really extremely simple and fast detector for close range pedestrians, which is based on the depth and we are exploiting the region of interest processing in order to reduce the search space of the detector.",
            "And so despite this is despite its simplicity.",
            "It works surprisingly well on very complex, very complex, crowded scenarios.",
            "And basically."
        ],
        [
            "The main contribution here what we wanted to show is that the problem, the problem becomes much simpler if we have the three data available.",
            "So not only the image data but also the 3D data stereo data."
        ],
        [
            "So Furthermore, we perform system systematic evolution of all parameters of the detector and we show how we can integrate the detections also in the tracking framework."
        ],
        [
            "So in all.",
            "Detection and tracking pipeline consists basically of three major steps.",
            "So first of all we extract region of interest which are basically areas in the image that I likely to contain target objects and then this region of interest are passed to the detector where we slide the depth template over each region of interest and compute the distance between the template.",
            "And so over later and the overlap area of the region of interest and basically the position with the minimum distance as detections, which are then passed through tracking framework.",
            "Where we simply associate them to long-term long-term trajectories by using extended camel filter and some specific pedestrian motion model."
        ],
        [
            "So let's look in more details for."
        ],
        [
            "For each part, so starting with region of interest generation.",
            "So in order to get region of interest standard approach.",
            "So we just take the 3D points and projects into the ground plane.",
            "So this procedure basically forms a 2D histogram.",
            "Very needs also to weight each bin.",
            "Of the histogram.",
            "By the distance of the camera in order to compensate for the fact that the closer objects is much more image supports in the objects which are farther away from the camera.",
            "So then this region of interest."
        ],
        [
            "Are can be simply projected to the image to the image plane and the width of the bounding boxes in the image plane.",
            "Basically, corresponds to the width of the 3D region of interest and for the height we take the point which is enclosed by each region of interest in 3D.",
            "So we take basically the highest point in order to compute the height, so the height would be the distance between the highest point of each region of interest and the distance between the highest point of interest to the ground.",
            "So it's important to notice here that the height of the bounding box basically gives us already a very precise prior for the template, which we then will slide over each region of interest."
        ],
        [
            "So now, given this to the regions of interest we pass through the detector."
        ],
        [
            "Where we have learned to normalize steps template which will then slide over each region of interest in the depth image.",
            "And compute always the distance for each position between the template and over that region of."
        ],
        [
            "Of the region of interest.",
            "So the output of this procedure is basically a distance distance matrix.",
            "You see here.",
            "So for each position you get the distance between the template and the overlap region.",
            "So we have seen before.",
            "Since the objects are working, usually in groups in our scenario.",
            "So the region of interest we obtain are basically containing several objects, so we don't get region of interest for individual objects, but also for groups of objects, and so we need also to downsample the template and also to compensate for different Heights, different size of pedestrians.",
            "So that's why we get several distance matrixes for each scale.",
            "So we downsample the template and run it again it again.",
            "That's why we get for each.",
            "Basically, for each object to get several positive detection, since the scale stride we're using this quite usually small.",
            "And then we perform some standards, non minimal suppression based off based on intersection over Union in order to obtain final detections."
        ],
        [
            "So in order to generate this depth template, we just have annotated 6000 pedestrian upper bodies in the depths images and so each."
        ],
        [
            "Patient is in normalized with the median depth.",
            "And pixels which are not within this medium depth with a fixed on certainty.",
            "I'll just set as invalid.",
            "This procedure basically removes all the background, so we're not interesting in the background, but we want is just the pixels or release of the pixels on the object itself.",
            "And in order to obtain the final depth template, we just average them by excluding the invalid pixels."
        ],
        [
            "For the distance measurement, we use the occasion the truncated in distance and.",
            "As already mentioned before, we perform automotive scaling in order to compensate for varying pedestrian Heights.",
            "And in order to obtain local local minima in each distance matrix, we just use a very simple minimal filters free by streaming filter."
        ],
        [
            "So by as you see here, for example, this on the left, this is output if you several scales, so several scales in order to run our template.",
            "But we of course interesting in our just final detections.",
            "And in order to do this we have used a greedy approach where iteratively selected bounding box or detection box with the lowest distance and just reject it.",
            "All the bounding box is a certain overlap.",
            "So the problem here is there two different techniques how we can see how we can measure this overlap.",
            "So the one would be just using bounding box intersection values, the simplest one?",
            "What we have seen this in this case that in many cases where pedestrians are walking behind each other.",
            "So in this case as the correct detection, for example, for this woman would be also rejected.",
            "So that's why we propose a template based intersection, Virginia, which is more suited for our scenarios where OK."
        ],
        [
            "So in this scenario.",
            "If you're using intersection of our union bounding box space, we will keep only one if we use as a template based will keep also the correct detection for the for the person working behind."
        ],
        [
            "So now this detections are basically passed to the tracking system."
        ],
        [
            "Where tracking system we have employed an extended version of work from lab at all from 2008.",
            "So the tracking system works as follows.",
            "So given ours detections and the structure for motion in the ground plane estimation, so then we place the detection in the from the image plane in a 3D World coordinate system by simply projecting each bounding box.",
            "So the bottom point of the bounding box to the ground plate, and then we're using.",
            "Extended Kalman filter in order to associate the detections into long-term trajectories.",
            "And so basically in each frame extent existing projector is but also for each detection we start new new trajectories backwards in time.",
            "So this obviously gives us an overcomplete set of trajectories.",
            "What we're interested in are of course the final set, so we don't want to have all the trajectories.",
            "That's why we didn't perform.",
            "Kind of pruning using model selection in MDF framework which was also proposed by lie but also physically.",
            "For more details refer to the original paper.",
            "So this is not a contribution from my side."
        ],
        [
            "So what you see here now is some qualitative result on one part of the secret of the sequence.",
            "So here we have fixed the range from zero to 7 meters, so we explained in our also why.",
            "So you will see that also in the quantity.",
            "For relation.",
            "Why we have this ranges from the camera?",
            "So as you can see here, we can track.",
            "So we detect most pedestrian correctly.",
            "We have also some false positives.",
            "Also some false negatives as you'll see here for example for for this woman, because she's here slower to your head, and so in the depth image.",
            "Basically we see only the shoulder area and most ahead area, so it's as soon as we get closer.",
            "So inside the head.",
            "We get also this detectors.",
            "So now also some tracking results.",
            "So as you can see here can also track all the pedestrians.",
            "And especially the interesting part is of course here for the tracking is that, for example, these two persons are tracked over the entire time, so if we're using our object detector full body object detector will not get them at all, so.",
            "It's kind of shaky because it's also because I mean we're moving ahead.",
            "So if you are working and it's also gets a little bit difficult to extract the structure for motion.",
            "If there are so many pedestrians also close to the camera because we don't get features on the static objects."
        ],
        [
            "In order to assess the performance, so is a quantitative performance of our detector.",
            "We have noted over 2500 frames.",
            "It was not fun with 19 thousand other pedestrians, and so we perform their relation.",
            "Basically four different distance ranges so the distance ranges were from zero to five, so it's red curve, zero to 7 and zero to 10 meters.",
            "So this is distance from the camera we were using.",
            "And as you can see, this is a performance for Father away pedestrians.",
            "Drop significantly, it can be simply explained by the fact that we get much more false positives in this area because the depth information gets much much more noisy.",
            "Here we have in the same plot we have also run the French file on our data, also for different different ranges as we see here perform significantly worse.",
            "It's basically underlines against the difficulties, so the complexity of the data, because really there are 40 to 50% of pedestrians are high, low clouded by the image borders."
        ],
        [
            "On the right side you see the evaluation where we have use a binary template, so we didn't use the original binary template with, which was basically in the original paper, so it was generated manually.",
            "But we have just used our approach where we switch all the pixel which is above 0 to one.",
            "So it performs so our perform significantly better for the close range pedestrians, so it's up to 5% more equal, but here it is not as serious.",
            "Also, it's important that this binary approach also profits from the region of interest extraction that we perform.",
            "It's also."
        ],
        [
            "Underlined in this plot.",
            "So what we have done is also in order to relate how the region of interest extraction affects the performance of our detector.",
            "I've also run so slightly.",
            "The template over the entire depth image using 100 scales.",
            "And it's performance, of course, significantly worse.",
            "So it's we get much more false positives.",
            "Also on the buildings and everywhere so."
        ],
        [
            "On the right side you see here's the difference between using this different minimum separation, which I have mentioned before.",
            "So you see here we get up to 3% more Rico if we use this template based.",
            "Let me know suppression.",
            "It's not that much, but it's basically if you look at the data, its output of the detector, you'll see that the pedestrians which are walking behind each other.",
            "So we get much more detections for this position which are also included from other pedestrians."
        ],
        [
            "Furthermore, we have also related how many skills required and also which scale straight we should use.",
            "So in the in the left plot you basically see that already 123 scales are already sufficient.",
            "So which means that the initial scale estimation which is based on the height of of of the bounding box.",
            "We extract this already really precise enough, so we don't need to go to have more skills.",
            "And it's also basically corroborated by the right plot, where it shows it's the lower the scales tried, so there's a bit of performance 15, so increasing the scale set basically gives us more false positives, but not increasing the recall."
        ],
        [
            "So regarding the computing computational performance approach runs now with more than 25 frames per second on a single disk CPU without any parallelization.",
            "But there's still considerable optimization potential because the region of interest evaluation can be done completely independent, so and also the computation for each scale can be done completely independent.",
            "So basically there are no reason why this algorithm should not run at much higher speeds.",
            "The bottleneck right now.",
            "So for the entire tracking system, so the tracking itself runs also with 60 frames per second, so the bottleneck right now is the depth estimation.",
            "So we're using algorithms from Andreas Krieger which runs on a 640 * 480 image with 10 frames per second on a single CPU.",
            "But we also now investigating if we can also work with half resolution of the image.",
            "Because then we can still get more than 25 frames per second for the depth estimation."
        ],
        [
            "So in conclusion, we have presented very fast and robust test that template based.",
            "Object detector.",
            "But we basically exploit also the region of interest in processing in order to read user search space.",
            "So this also reduces the false positive false positive significantly.",
            "And we have shown that even though their approach is really simple and fast, apply its reach is really superior performance.",
            "And so we have also shown that it can be also integrated in the multi hypothesis tracking framework.",
            "And for the future, what we plan is to perform some kind of combination between this upper body detector for the close range pedestrians and some full body detector for for father away pedestrians in order to close this gap between closer and farther pedestrians.",
            "OK."
        ],
        [
            "That's it, thank you very much for your attention.",
            "So any questions?"
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "My name is Dennis Smith said, and this is joint work with Passion Library.",
                    "label": 0
                },
                {
                    "sent": "And in this work we consider a problem of multi person detection from head mounted cameras, so before.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Going into digital first show what I mean by head mounted camera.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So you see, here is the setup we were using.",
                    "label": 0
                },
                {
                    "sent": "So we have mounted the stereo camera bumblebee on the head on a helmet.",
                    "label": 0
                },
                {
                    "sent": "In the corner above you will see.",
                    "label": 0
                },
                {
                    "sent": "A theory estimation where we have used the algorithm from Andreas Geiger which was presented at ACC 2010.",
                    "label": 0
                },
                {
                    "sent": "And So what is important to notice to notice in these sequences?",
                    "label": 0
                },
                {
                    "sent": "As a pedestrian gets highly included, as soon as they come really close to the camera so we can have highly occlusions here on the image photos especially.",
                    "label": 0
                },
                {
                    "sent": "And this makes of course as a problem of object detection, much more complex.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As most of you might know.",
                    "label": 0
                },
                {
                    "sent": "Robust multi person detection and tracking.",
                    "label": 0
                },
                {
                    "sent": "It's important prerequisite for several applications, so speech for example in mobile robotics applications.",
                    "label": 0
                },
                {
                    "sent": "As a position and.",
                    "label": 0
                },
                {
                    "sent": "Also, velocity of moving obstacles.",
                    "label": 0
                },
                {
                    "sent": "Could be really supportive for the past planning algorithms, especially the problem.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We need to be able also to detect the pedestrians which are also here.",
                    "label": 0
                },
                {
                    "sent": "So in order to avoid collisions because they are also very close to the camera.",
                    "label": 0
                },
                {
                    "sent": "The problem is of course sets the standard full body object detectors, which are available.",
                    "label": 1
                },
                {
                    "sent": "For example, Hawk are not really well suited for this problem.",
                    "label": 1
                },
                {
                    "sent": "So for the Standard Hawk dispositions are basically invisible, so.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Also part based approaches as one from Felton Schwab for example, have some difficulties in detect this pedestrians which are really close to the boundaries and in addition it's also computationally expensive.",
                    "label": 0
                },
                {
                    "sent": "So the most related approach to our work is work from Choi at all, which was presented in ICT workshop in 2011.",
                    "label": 0
                },
                {
                    "sent": "So there in they have introduced basically are manually generated tips template which they used on a smooth Kinnick data, so it performs surprisingly well on the Connect data, but on its own on our noisy steering stereo data, it doesn't perform so well, so.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That's why we propose a extremely simple.",
                    "label": 0
                },
                {
                    "sent": "It's really extremely simple and fast detector for close range pedestrians, which is based on the depth and we are exploiting the region of interest processing in order to reduce the search space of the detector.",
                    "label": 1
                },
                {
                    "sent": "And so despite this is despite its simplicity.",
                    "label": 1
                },
                {
                    "sent": "It works surprisingly well on very complex, very complex, crowded scenarios.",
                    "label": 0
                },
                {
                    "sent": "And basically.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The main contribution here what we wanted to show is that the problem, the problem becomes much simpler if we have the three data available.",
                    "label": 0
                },
                {
                    "sent": "So not only the image data but also the 3D data stereo data.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So Furthermore, we perform system systematic evolution of all parameters of the detector and we show how we can integrate the detections also in the tracking framework.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in all.",
                    "label": 0
                },
                {
                    "sent": "Detection and tracking pipeline consists basically of three major steps.",
                    "label": 0
                },
                {
                    "sent": "So first of all we extract region of interest which are basically areas in the image that I likely to contain target objects and then this region of interest are passed to the detector where we slide the depth template over each region of interest and compute the distance between the template.",
                    "label": 0
                },
                {
                    "sent": "And so over later and the overlap area of the region of interest and basically the position with the minimum distance as detections, which are then passed through tracking framework.",
                    "label": 0
                },
                {
                    "sent": "Where we simply associate them to long-term long-term trajectories by using extended camel filter and some specific pedestrian motion model.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's look in more details for.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For each part, so starting with region of interest generation.",
                    "label": 0
                },
                {
                    "sent": "So in order to get region of interest standard approach.",
                    "label": 0
                },
                {
                    "sent": "So we just take the 3D points and projects into the ground plane.",
                    "label": 0
                },
                {
                    "sent": "So this procedure basically forms a 2D histogram.",
                    "label": 1
                },
                {
                    "sent": "Very needs also to weight each bin.",
                    "label": 0
                },
                {
                    "sent": "Of the histogram.",
                    "label": 0
                },
                {
                    "sent": "By the distance of the camera in order to compensate for the fact that the closer objects is much more image supports in the objects which are farther away from the camera.",
                    "label": 0
                },
                {
                    "sent": "So then this region of interest.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Are can be simply projected to the image to the image plane and the width of the bounding boxes in the image plane.",
                    "label": 1
                },
                {
                    "sent": "Basically, corresponds to the width of the 3D region of interest and for the height we take the point which is enclosed by each region of interest in 3D.",
                    "label": 0
                },
                {
                    "sent": "So we take basically the highest point in order to compute the height, so the height would be the distance between the highest point of each region of interest and the distance between the highest point of interest to the ground.",
                    "label": 0
                },
                {
                    "sent": "So it's important to notice here that the height of the bounding box basically gives us already a very precise prior for the template, which we then will slide over each region of interest.",
                    "label": 1
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now, given this to the regions of interest we pass through the detector.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Where we have learned to normalize steps template which will then slide over each region of interest in the depth image.",
                    "label": 0
                },
                {
                    "sent": "And compute always the distance for each position between the template and over that region of.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Of the region of interest.",
                    "label": 0
                },
                {
                    "sent": "So the output of this procedure is basically a distance distance matrix.",
                    "label": 1
                },
                {
                    "sent": "You see here.",
                    "label": 0
                },
                {
                    "sent": "So for each position you get the distance between the template and the overlap region.",
                    "label": 0
                },
                {
                    "sent": "So we have seen before.",
                    "label": 0
                },
                {
                    "sent": "Since the objects are working, usually in groups in our scenario.",
                    "label": 0
                },
                {
                    "sent": "So the region of interest we obtain are basically containing several objects, so we don't get region of interest for individual objects, but also for groups of objects, and so we need also to downsample the template and also to compensate for different Heights, different size of pedestrians.",
                    "label": 0
                },
                {
                    "sent": "So that's why we get several distance matrixes for each scale.",
                    "label": 1
                },
                {
                    "sent": "So we downsample the template and run it again it again.",
                    "label": 0
                },
                {
                    "sent": "That's why we get for each.",
                    "label": 0
                },
                {
                    "sent": "Basically, for each object to get several positive detection, since the scale stride we're using this quite usually small.",
                    "label": 0
                },
                {
                    "sent": "And then we perform some standards, non minimal suppression based off based on intersection over Union in order to obtain final detections.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in order to generate this depth template, we just have annotated 6000 pedestrian upper bodies in the depths images and so each.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Patient is in normalized with the median depth.",
                    "label": 1
                },
                {
                    "sent": "And pixels which are not within this medium depth with a fixed on certainty.",
                    "label": 1
                },
                {
                    "sent": "I'll just set as invalid.",
                    "label": 0
                },
                {
                    "sent": "This procedure basically removes all the background, so we're not interesting in the background, but we want is just the pixels or release of the pixels on the object itself.",
                    "label": 0
                },
                {
                    "sent": "And in order to obtain the final depth template, we just average them by excluding the invalid pixels.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For the distance measurement, we use the occasion the truncated in distance and.",
                    "label": 0
                },
                {
                    "sent": "As already mentioned before, we perform automotive scaling in order to compensate for varying pedestrian Heights.",
                    "label": 1
                },
                {
                    "sent": "And in order to obtain local local minima in each distance matrix, we just use a very simple minimal filters free by streaming filter.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So by as you see here, for example, this on the left, this is output if you several scales, so several scales in order to run our template.",
                    "label": 0
                },
                {
                    "sent": "But we of course interesting in our just final detections.",
                    "label": 0
                },
                {
                    "sent": "And in order to do this we have used a greedy approach where iteratively selected bounding box or detection box with the lowest distance and just reject it.",
                    "label": 0
                },
                {
                    "sent": "All the bounding box is a certain overlap.",
                    "label": 1
                },
                {
                    "sent": "So the problem here is there two different techniques how we can see how we can measure this overlap.",
                    "label": 1
                },
                {
                    "sent": "So the one would be just using bounding box intersection values, the simplest one?",
                    "label": 0
                },
                {
                    "sent": "What we have seen this in this case that in many cases where pedestrians are walking behind each other.",
                    "label": 1
                },
                {
                    "sent": "So in this case as the correct detection, for example, for this woman would be also rejected.",
                    "label": 0
                },
                {
                    "sent": "So that's why we propose a template based intersection, Virginia, which is more suited for our scenarios where OK.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in this scenario.",
                    "label": 0
                },
                {
                    "sent": "If you're using intersection of our union bounding box space, we will keep only one if we use as a template based will keep also the correct detection for the for the person working behind.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now this detections are basically passed to the tracking system.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Where tracking system we have employed an extended version of work from lab at all from 2008.",
                    "label": 0
                },
                {
                    "sent": "So the tracking system works as follows.",
                    "label": 0
                },
                {
                    "sent": "So given ours detections and the structure for motion in the ground plane estimation, so then we place the detection in the from the image plane in a 3D World coordinate system by simply projecting each bounding box.",
                    "label": 1
                },
                {
                    "sent": "So the bottom point of the bounding box to the ground plate, and then we're using.",
                    "label": 0
                },
                {
                    "sent": "Extended Kalman filter in order to associate the detections into long-term trajectories.",
                    "label": 0
                },
                {
                    "sent": "And so basically in each frame extent existing projector is but also for each detection we start new new trajectories backwards in time.",
                    "label": 1
                },
                {
                    "sent": "So this obviously gives us an overcomplete set of trajectories.",
                    "label": 1
                },
                {
                    "sent": "What we're interested in are of course the final set, so we don't want to have all the trajectories.",
                    "label": 0
                },
                {
                    "sent": "That's why we didn't perform.",
                    "label": 1
                },
                {
                    "sent": "Kind of pruning using model selection in MDF framework which was also proposed by lie but also physically.",
                    "label": 0
                },
                {
                    "sent": "For more details refer to the original paper.",
                    "label": 0
                },
                {
                    "sent": "So this is not a contribution from my side.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what you see here now is some qualitative result on one part of the secret of the sequence.",
                    "label": 0
                },
                {
                    "sent": "So here we have fixed the range from zero to 7 meters, so we explained in our also why.",
                    "label": 0
                },
                {
                    "sent": "So you will see that also in the quantity.",
                    "label": 0
                },
                {
                    "sent": "For relation.",
                    "label": 0
                },
                {
                    "sent": "Why we have this ranges from the camera?",
                    "label": 0
                },
                {
                    "sent": "So as you can see here, we can track.",
                    "label": 0
                },
                {
                    "sent": "So we detect most pedestrian correctly.",
                    "label": 0
                },
                {
                    "sent": "We have also some false positives.",
                    "label": 0
                },
                {
                    "sent": "Also some false negatives as you'll see here for example for for this woman, because she's here slower to your head, and so in the depth image.",
                    "label": 0
                },
                {
                    "sent": "Basically we see only the shoulder area and most ahead area, so it's as soon as we get closer.",
                    "label": 0
                },
                {
                    "sent": "So inside the head.",
                    "label": 0
                },
                {
                    "sent": "We get also this detectors.",
                    "label": 0
                },
                {
                    "sent": "So now also some tracking results.",
                    "label": 0
                },
                {
                    "sent": "So as you can see here can also track all the pedestrians.",
                    "label": 0
                },
                {
                    "sent": "And especially the interesting part is of course here for the tracking is that, for example, these two persons are tracked over the entire time, so if we're using our object detector full body object detector will not get them at all, so.",
                    "label": 0
                },
                {
                    "sent": "It's kind of shaky because it's also because I mean we're moving ahead.",
                    "label": 0
                },
                {
                    "sent": "So if you are working and it's also gets a little bit difficult to extract the structure for motion.",
                    "label": 0
                },
                {
                    "sent": "If there are so many pedestrians also close to the camera because we don't get features on the static objects.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In order to assess the performance, so is a quantitative performance of our detector.",
                    "label": 0
                },
                {
                    "sent": "We have noted over 2500 frames.",
                    "label": 0
                },
                {
                    "sent": "It was not fun with 19 thousand other pedestrians, and so we perform their relation.",
                    "label": 0
                },
                {
                    "sent": "Basically four different distance ranges so the distance ranges were from zero to five, so it's red curve, zero to 7 and zero to 10 meters.",
                    "label": 0
                },
                {
                    "sent": "So this is distance from the camera we were using.",
                    "label": 0
                },
                {
                    "sent": "And as you can see, this is a performance for Father away pedestrians.",
                    "label": 0
                },
                {
                    "sent": "Drop significantly, it can be simply explained by the fact that we get much more false positives in this area because the depth information gets much much more noisy.",
                    "label": 0
                },
                {
                    "sent": "Here we have in the same plot we have also run the French file on our data, also for different different ranges as we see here perform significantly worse.",
                    "label": 0
                },
                {
                    "sent": "It's basically underlines against the difficulties, so the complexity of the data, because really there are 40 to 50% of pedestrians are high, low clouded by the image borders.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On the right side you see the evaluation where we have use a binary template, so we didn't use the original binary template with, which was basically in the original paper, so it was generated manually.",
                    "label": 0
                },
                {
                    "sent": "But we have just used our approach where we switch all the pixel which is above 0 to one.",
                    "label": 0
                },
                {
                    "sent": "So it performs so our perform significantly better for the close range pedestrians, so it's up to 5% more equal, but here it is not as serious.",
                    "label": 0
                },
                {
                    "sent": "Also, it's important that this binary approach also profits from the region of interest extraction that we perform.",
                    "label": 0
                },
                {
                    "sent": "It's also.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Underlined in this plot.",
                    "label": 0
                },
                {
                    "sent": "So what we have done is also in order to relate how the region of interest extraction affects the performance of our detector.",
                    "label": 0
                },
                {
                    "sent": "I've also run so slightly.",
                    "label": 0
                },
                {
                    "sent": "The template over the entire depth image using 100 scales.",
                    "label": 0
                },
                {
                    "sent": "And it's performance, of course, significantly worse.",
                    "label": 0
                },
                {
                    "sent": "So it's we get much more false positives.",
                    "label": 0
                },
                {
                    "sent": "Also on the buildings and everywhere so.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "On the right side you see here's the difference between using this different minimum separation, which I have mentioned before.",
                    "label": 0
                },
                {
                    "sent": "So you see here we get up to 3% more Rico if we use this template based.",
                    "label": 1
                },
                {
                    "sent": "Let me know suppression.",
                    "label": 0
                },
                {
                    "sent": "It's not that much, but it's basically if you look at the data, its output of the detector, you'll see that the pedestrians which are walking behind each other.",
                    "label": 0
                },
                {
                    "sent": "So we get much more detections for this position which are also included from other pedestrians.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Furthermore, we have also related how many skills required and also which scale straight we should use.",
                    "label": 1
                },
                {
                    "sent": "So in the in the left plot you basically see that already 123 scales are already sufficient.",
                    "label": 0
                },
                {
                    "sent": "So which means that the initial scale estimation which is based on the height of of of the bounding box.",
                    "label": 1
                },
                {
                    "sent": "We extract this already really precise enough, so we don't need to go to have more skills.",
                    "label": 0
                },
                {
                    "sent": "And it's also basically corroborated by the right plot, where it shows it's the lower the scales tried, so there's a bit of performance 15, so increasing the scale set basically gives us more false positives, but not increasing the recall.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So regarding the computing computational performance approach runs now with more than 25 frames per second on a single disk CPU without any parallelization.",
                    "label": 1
                },
                {
                    "sent": "But there's still considerable optimization potential because the region of interest evaluation can be done completely independent, so and also the computation for each scale can be done completely independent.",
                    "label": 0
                },
                {
                    "sent": "So basically there are no reason why this algorithm should not run at much higher speeds.",
                    "label": 1
                },
                {
                    "sent": "The bottleneck right now.",
                    "label": 0
                },
                {
                    "sent": "So for the entire tracking system, so the tracking itself runs also with 60 frames per second, so the bottleneck right now is the depth estimation.",
                    "label": 0
                },
                {
                    "sent": "So we're using algorithms from Andreas Krieger which runs on a 640 * 480 image with 10 frames per second on a single CPU.",
                    "label": 0
                },
                {
                    "sent": "But we also now investigating if we can also work with half resolution of the image.",
                    "label": 0
                },
                {
                    "sent": "Because then we can still get more than 25 frames per second for the depth estimation.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in conclusion, we have presented very fast and robust test that template based.",
                    "label": 1
                },
                {
                    "sent": "Object detector.",
                    "label": 1
                },
                {
                    "sent": "But we basically exploit also the region of interest in processing in order to read user search space.",
                    "label": 0
                },
                {
                    "sent": "So this also reduces the false positive false positive significantly.",
                    "label": 1
                },
                {
                    "sent": "And we have shown that even though their approach is really simple and fast, apply its reach is really superior performance.",
                    "label": 0
                },
                {
                    "sent": "And so we have also shown that it can be also integrated in the multi hypothesis tracking framework.",
                    "label": 0
                },
                {
                    "sent": "And for the future, what we plan is to perform some kind of combination between this upper body detector for the close range pedestrians and some full body detector for for father away pedestrians in order to close this gap between closer and farther pedestrians.",
                    "label": 1
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's it, thank you very much for your attention.",
                    "label": 0
                },
                {
                    "sent": "So any questions?",
                    "label": 0
                }
            ]
        }
    }
}