{
    "id": "y2sshb6hwonxdtdycrnwyoxf43usl3zr",
    "title": "Generative and Discriminative Image Models",
    "info": {
        "author": [
            "John Winn, Microsoft Research, Cambridge, Microsoft Research"
        ],
        "published": "March 26, 2010",
        "recorded": "December 2009",
        "category": [
            "Top->Computer Science->Computer Vision->Object Recognition",
            "Top->Computer Science->Computer Vision->Motion and Tracking"
        ]
    },
    "url": "http://videolectures.net/nipsworkshops09_winn_gdim/",
    "segmentation": [
        [
            "You had a nice break for today.",
            "We're pleased to have John win with us today.",
            "John Dubinsky HD, Cambridge, where he worked on graphical model and friends and have inside my research does vision applications at all suppliers in attics.",
            "So I actually met John five years going out in at MSR and back then I was into it, scared models and I was kind of getting into general models and global skeptical Delta Dawn hasn't timeless.",
            "Model and look at this.",
            "Discussion.",
            "So it's appropriate that you know Johnny here five years later has done a lot of good work, combining the best of both.",
            "Worldswhichshows.com, thank you busy so.",
            "The talk this talk is is not going to be deeply mathematical talk.",
            "It's going to be a little bit of a whirlwind tour of some probabilistic models of vision applications, but I will be pulling my own personal journey through generative and discriminative approaches to vision before looking at some some hybrid.",
            "Ideas, so I quite like the yin and Yang sort of concept for generative and discriminative have complementary ideas that bring both which bring something to the table.",
            "So that's the theme here."
        ],
        [
            "Yes, but one of the things I would like to sort of emphasizes is the problem of understanding and automatically interpreting an image has its own special characteristics that perhaps differ from some of the other applications will be hearing about in the workshop today, so I particularly want to sort of start off just by setting the scene, do what the real challenges with understanding images.",
            "And the really big thing about a measured pixel intensity or or RGB value is that the sheer number of things that led to that measurement.",
            "So there's a huge number of sources of image variability.",
            "That lead or can influence the measurement that you get when you take your camera out into the world and take a picture.",
            "And this is just an attempt to try and enumerate some of those.",
            "Sources of variability.",
            "So the first thing that influences what pixels you're actually going to get is where you take your camera.",
            "What sort of rough?"
        ],
        [
            "Seen the indoors outdoor.",
            "What kind of things we're going to see.",
            "So this is the same type and the geometry of the scene.",
            "So, for example, we might have a street scene with this kind of geometry outdoor.",
            "The horizon is visible and so forth.",
            "And then on top of that, it's going to be what objects are present in the scene.",
            "So one of the classes of the objects that we have within the scene structure."
        ],
        [
            "And so for a street scene, you might expect to see something like this set of objects present in the image.",
            "Now if we want to work out which pixels are affected by the presence of these objects in the scene."
        ],
        [
            "Then we're going to first of all, we have to workout the position and orientation of each of these objects.",
            "So we can move those objects into the appropriate location, but we're going to need a little more than that.",
            "We will need to know about their shape and."
        ],
        [
            "So if we now now we can start to see exactly which pixel measurements going to be influenced by to these objects that are actually out there in the world.",
            "But objects aren't transparent like they're here.",
            "In fact, they have this depth ordering 'cause we're talking about image in a 3 dimensional world, so I don't really have the steps that that's going to lead to occlusion effect, so the actual."
        ],
        [
            "Pixels influenced by each object are going to look something more like that.",
            "And then on top of that we have to say how does the presence of an object in the scene influence the pixels?",
            "And that's going to mean some."
        ],
        [
            "Thing about encoding the appearance of an object, and so if we bring that into the image, we now have something that's pretty close to the kind of image that you might be capturing.",
            "But on top of that there are effects that are not object specific where one object influences the appearance of another, for example earlier."
        ],
        [
            "Nation effects and shadows, which are to do with interactions between objects and therefore inches.",
            "Further complexity in the statistical dependence between the pixels, so we can bring in the shadows into our scene and then fine."
        ],
        [
            "So we have a whole other bunch of such smaller lower impact sources of variability like motion blur and camera."
        ],
        [
            "Next, we're going to have relatively small effects on the pixels that might be like what resolution are we?",
            "Are we going to be sampling the light field at?",
            "And so this leads us to the actual image that we want to measure.",
            "So when we're talking about building a probabilistic model, the main thing that you have to bear in mind is there's a huge number of sources of variability that we're going to have to be able to represent.",
            "And so."
        ],
        [
            "Let's talk firstly, then, if we were talking about building a generative model of an image.",
            "So you will come into this workshop.",
            "You know what generative model is.",
            "Then here we have a prescription as I see it for a generative approaches, which is going to select some set of these variables or sources of variability that affect the image as latent variables and describe attractable generative process.",
            "So a stochastic process by which those variables will lead to the generation of a natural image.",
            "And then we're going to apply that to some unlabeled data to infer these latent variables.",
            "Now, a key thing that we have to bear in mind here is that if we don't include one of these sources of variability in our generative model, then we're going to pair price for it.",
            "So we either have to restrict the domain in which we're going to apply the model by saying.",
            "The objects must not be included or they must be affixed.",
            "Seen structure of a fixed class or a fixed orientation.",
            "We're going to have to hope that they are captured by some.",
            "Noise or outline process, and if that's not the case, it's going to distort the inference of the model, so this is going to be a sort of model mismatch issue.",
            "If we don't build a rich enough model and building a rich enough model is going to be very challenging.",
            "So I'm building up my little comparison score."
        ],
        [
            "The table between the generative and discriminative approaches here, and what this tells us is that we've seen as a huge number of sources of variability, so we're going to have to build a complex model if we don't want to be suffering from a limited domain in which we can apply our generative model.",
            "And that's going to be slow to do inferencing.",
            "So this suggests that in.",
            "In understanding images, generative model is going to be both complicated and somewhat slow to process."
        ],
        [
            "So we look at an example, so I'm going to take a number of examples at the talk.",
            "On the left hand side, I'm going to keep around the list of sources of variability and highlight the ones that the model is actually representing within itself, and so all the other ones are going to actually have to be fixed or just going to ignore them and cross our fingers.",
            "And on the right hand side we have the actual generative model that we are using in this case.",
            "So here this is the layered sprites model of UA Confrey from 2001.",
            "This is one of the first generative image models that.",
            "That really sort of was able to generate a entire video, for example, and you see that we have latent variables for the appearance of the object, which in this case is just a Sprite or a bitmap.",
            "For the shape, which is just a binary bitmap and then we just going to have a position which rips in the position of the object in the scene, and then there's going to be composited together so we have a number of those objects are going to be composited together to form the image, and that's the assumed generative process here.",
            "So here is a picture of that."
        ],
        [
            "Generative model in play so.",
            "What's happened is they've taken some video.",
            "Anne.",
            "Where we have someone walking along very, very carefully from left to right and.",
            "It's learned about these sprites for both the background layer.",
            "Which has a fixed appearance in a mask which is or shape which is the entire image and a foreground layer where the appearance is the appearance of a guy looking from the side and the mask is is the shape of that person and then the position of the background is fixed in the middle and the position of the person is moving from left to right.",
            "Another example of this model."
        ],
        [
            "Is.",
            "So in here this is with two layers and the background, and so we have the two authors rendered in the brochure, walking very carefully in front of each other.",
            "And then we can take that video and decompose it into layers under the generative model.",
            "So I think.",
            "While this model has been very successful in decomposing this video, a criticism that was leveled at it from the vision community at least is that this is, yeah, this is set up right.",
            "You had people working very, very carefully, but that was because they had to keep within the domain of the generative model.",
            "Keep within the assumptions of the generative model, which only allowed very limited domain of application for this model.",
            "So just to continue then."
        ],
        [
            "With because it's complicated to build these models to represent the rich variability of images, we're going to have to often limit the domain in which generative model can be applied.",
            "But on the plus side, within that domain, and assuming we can solve the inference problem accurately.",
            "Then it's going to give us accurate interpretable results for that model."
        ],
        [
            "So let's switch to the second approach that's mentioned in this workshop, which is discriminative modeling.",
            "So again, we're going to need to look at some of these sources of variability, but now they're going to be targets, and we're going to be modeling the conditional probability.",
            "This is my view for the discriminative model is a conditional model I guess is people were mentioning earlier those target variables given the image, and now we have to actually use some manual annotation.",
            "But once again, if we're not explicitly representing a source of variability in the model.",
            "It either has to be fixed or it has to be thoroughly explored in the training set so you can learn to compensate for that source of variability.",
            "So this is kind of the ability to cope with model mismatch that discriminative models have.",
            "But you still need to make sure that that's the source of variability, are thoroughly explored in your labeled data and envision.",
            "That's extremely hard, because if you made a very simple discriminative model, that's a huge number of of.",
            "Other variables that you're going to have to explore thoroughly, which suggests you need a combinatorially large training set, but I will say something about discriminative models, which is this ability to.",
            "Cope with model mismatch.",
            "Means that 'cause no one can build models complicated enough to accurately represent the imaging process.",
            "These are the ones that currently work best.",
            "And in fact, if you look at the Pascal VC challenge for this year, all of the winning competitors is a challenge for detecting, segmenting, and classifying objects in images.",
            "All of the winning systems are predominantly discriminative.",
            "This is different we've seen in other domains today where generative models are competitive in vision at the moment.",
            "They are predominantly not competitive with discriminative models, and that's I think.",
            "Mainly because of the complexity of the imaging task, Percy.",
            "So that's why I said predominantly discriminative.",
            "So these are vision systems which are often not new, have algorithmic components and so forth.",
            "And there are certain components of these systems which you could see as generative.",
            "For example, Pat clustering and that kind of thing.",
            "Some of them use Constellation models which are learning the generative type way.",
            "But I would say that by far the dominant paradigm is discriminative."
        ],
        [
            "So.",
            "We build up a table.",
            "They can be relatively simple models in comparison to the generative ones, because there simply have fewer variable variabilities in them, they're going to be faster to execute.",
            "Ann and their robust to model mismatch.",
            "The downside is of course that you need labeled data, and if you believe what I said just now, you need a lot of labeled data.",
            "And in the Pascal challenge, for example, we do provide a lot of labeled data, but maybe not.",
            "An infinite amount."
        ],
        [
            "So let's look at a common example of discriminative models used in vision.",
            "So here the only thing that's basically inside this model is which class it is, where it's a face or not, and the position of that face within the image.",
            "And we're just going to slide a window across the image, extract some features.",
            "From that window and then feed it into a standard classifier of some sort, and in this case it was a boosted cascade.",
            "And that's going to tell us whether or not we have a face within our window at this particular point in time.",
            "As you can see, it works absolutely pretty well at explaining faces, and I think this is one of the first times in vision where people really appreciated the power of machine learning.",
            "So it's a great and Seminole paper, but it's also particularly recommend recognizing footballs which are not faces lost.",
            "I checked.",
            "So why is that?",
            "And this is a.",
            "It's not like it's hard for us to tell that.",
            "Thing at the bottom is not a face, and it's because it's only seeing this tiny window.",
            "There's enormous amount of information that this model is ignoring.",
            "And of course discriminative models are completely free to do that because they're not required to explain everything that you're seeing in the image.",
            "And so negative on the discriminative front is that there are helpful."
        ],
        [
            "Use in modeling all of these other sources of variability, like the context, for example, which is very, very quick.",
            "Very easy to ignore if you're just merging to pick what you think are going to be useful features.",
            "The other thing is that it will be inaccurate if you have two few labeled examples and in most cases you have too few labeled examples."
        ],
        [
            "A common approach or common sort of understanding is that these discriminative models we mean a standard classifier.",
            "But of course you can put a lot of rich prior information into a discriminative model.",
            "We've seen some of that earlier today in vision at a very common approach is the conditional random field for segmentation.",
            "Here what we do is we take a sliding window, but rather than trying to use the sliding window to recognize the whole object, we're going to get to recognize parts of the object like the car.",
            "Here we're going to say.",
            "Each color is a part of sliding window and predict what the parts are and if we do that then we get a complete mess that looks like this because trying to predict which part of a car you're seeing from a little sliding window is a very ambiguous task.",
            "But if we then introduce some structure into the model which says that I expect the front of the car to be next to the middle of the car.",
            "Introducing conditional random field structure in place.",
            "That's putting a lot of prior knowledge about how parts go together and also how occluding objects interact with each other.",
            "Now if we run the same model again, then we get a result like this."
        ],
        [
            "Where the only coherent part labels are those which accurately represents the car, and they can also cope with occlusion and tell you which part of the car that you're actually seeing.",
            "So we can identify the cars in the image."
        ],
        [
            "So to continue, these discriminative models need not be black box models.",
            "We can put a lot of rich information in them.",
            "However, if the model goes wrong, the only measure we have of the performance of a discriminative model is some some sense, whether it succeeds or not.",
            "Because the internals are not necessarily.",
            "That interpretable.",
            "Sometimes extremely hard to diagnose why discriminative model doesn't work well for the generative model.",
            "We have a well defined definition of what each of our latent variables is.",
            "I think this is a really big weakness of discriminative models.",
            "It's like if it doesn't work.",
            "You don't know how to modify the model or or the inference procedure often to workout, why?"
        ],
        [
            "OK, second generative example is.",
            "Here we're trying to go beyond the restricted set we saw earlier.",
            "And.",
            "Build a richer model that has many more aspects of the image in process in there.",
            "So we got position, shape, appearance and illumination.",
            "I'm not going to go into too much detail about the object, but the only thing to say is it's basically segmenting out a set of objects of the same class in a bunch of images under the assumption of the same class, but without knowing what the classes and the only thing common between all of the images is.",
            "This shared sort of shape template."
        ],
        [
            "So well defined generative model of the image.",
            "Anne Anne.",
            "What you can get from that is completely unsupervised segmentation, so you give it.",
            "In this case, there were twenty images of horses.",
            "I'm just showing four of them.",
            "And we can get out of that both completely unsupervised segmentation and a model of the horse.",
            "That is being used to segment all of these images, and this is actually one of the generative models which is come closer to the performance of discriminative models in vision.",
            "So when I did this paper back in 2005, the accuracy of segmentation in this data set was about 93%.",
            "For discriminative methods, it was about 9095% for discount methods.",
            "It was 94%.",
            "That's since gone to 95%.",
            "So here we have an example of a generative model that's coming pretty close.",
            "To discriminative model in performance, but it's not better."
        ],
        [
            "So what we can do then is deal with unlabeled data and we can diagnose flows more easily.",
            "So for example, where that model tended to go wrong, it was because one of the generative modeling assumptions was violated and it was very easy to tell which that it was."
        ],
        [
            "You can then go along that path even more and build even even more.",
            "Hackling even more variables into the model.",
            "This is a great piece of work by.",
            "Pound Kumar in 2005 when they threw in an awful lot of variables.",
            "But the inference here was very, very difficult.",
            "Including that motion blur illumination, all different parts of the zebra and so forth, but it was able to use every single one of these cues to help improve the accuracy of the inference and and builder.",
            "As zebra model from."
        ],
        [
            "There in this case, so it was using all available queues and the other thing was you could do it for all kinds of different applications.",
            "It would track segment diebler.",
            "It was doing all of these different vision applications using exactly the same model.",
            "Because all these different latent variables are being represented within the model.",
            "OK, this is a lightning tour.",
            "I'm going through this very quickly so I apologize for that.",
            "Say that the."
        ],
        [
            "5 minutes great so that the.",
            "You can, so we see that there's lots of advantages of both generative and discriminative models in vision.",
            "And so we want to try and take.",
            "The best of both worlds.",
            "So we need to develop some hybrid methods.",
            "And.",
            "Which is obviously what this workshop is about, and we've seen some various methods presented today so far.",
            "Anne.",
            "What I want to talk about probably going to talk about one application and this is to do with.",
            "At slightly different approach than what we've seen, it's about using a hybrid approach to speed up inference in a generative model, so here."
        ],
        [
            "So we have another image model.",
            "This is called the jigsaw model and the idea is that you have a set of images and you want to try and find a latent image that we call the jigsaw that you can use pieces of to explain a number of real images.",
            "So here we have a cartoon of that where we have.",
            "One face here, but imagine you have a set of these faces, and then we're going to learn a bunch of pieces that we can use to build up all the faces out of an example result.",
            "Is if we have some faces you can't quite see them, they're showing the pieces as well.",
            "So here we have 20 faces.",
            "Then the kind of jigsaw that you did look something like this.",
            "But something slightly out of a horror movie.",
            "But you can use this to construct photo fits of.",
            "All kinds of people's faces.",
            "The problem with the jigsaw model.",
            "Is that we're trying to infer for every single pixel of each training image or test image where it Maps 2 into the jigsaw, and this is a high cardinality problem.",
            "There's maybe in this case 10,000 pixels in the jigsaw, so we're going to have to have a 10,000 state variable for every single pixel in every single training image.",
            "And that's a very slow operation."
        ],
        [
            "We'd like to be able to speed that up, and here's a hybrid approach for doing that.",
            "So we compute.",
            "The likelihood of each pixel affected pixel coming from every possible jigsaw location that we find.",
            "If we have a red pixel.",
            "Excuse me, it will match well to all the red locations in the jigsaw and it won't match very well anywhere else and so you'll tend to get a likelihood that looks something like this.",
            "It will have a few peaks and then it will have a lot of very flat.",
            "Regions for most of most of the places it doesn't match well too.",
            "But it's not very informative.",
            "It can't tell.",
            "They can't tell which red pixel it should map to because it's not able to use any context, so we can use a discriminative approach, which is very much like what you seen earlier.",
            "Where you take a Patch and try to make a prediction for the part in the car case so we can take a Patch and trying to prediction for where we go into the jigsaw in this case.",
            "And that's going to make a prediction here.",
            "Rather than just linearly combine this in some way, what we're going to do is we're going to take a family of approximating distributions such that we're saying that family is the set of distributions which has K well defined values, and all remaining values are exactly the same a uniform.",
            "Then we can take So what we can do normally is we can just say let's suppose K is 10, we can use KL divergent, say and minimize kelder vengeance to pick the Member of that family.",
            "We're going to use for message passing.",
            "But now we can take the prediction for the classifier and say the location is predicted by the classifier are going to be where we're going to represent explicitly the values in this message.",
            "So you can think of it as training a discriminative classifier to tell you where to spend computational effort to solve your generative model.",
            "And that's kind of a very nice."
        ],
        [
            "Framework.",
            "And so the results we're getting for that things like this.",
            "So here we have the amount of memory required to solve the jigsaw model.",
            "This is a measure of the quality of the resultant solution and this is showing how as we train that classifier on more and more.",
            "Training images how we're getting better and better, better performance and just doing inference in the generative model.",
            "So we can get up to a 10 times speedup over the original image by using this technique.",
            "So this hybrid methods for speeding up inference.",
            "This is called hybrid belief propagation."
        ],
        [
            "So the idea and the goal line of machine vision, I would say, is to represent all of these sources of variability in a single image Ng model so that we can get a complete understanding of the image.",
            "And I think it's very encouraging that these hybrid methods are able to take the best of both generative and discriminative worlds.",
            "I think that we will probably see something in the next few years that is capable of doing this, and in fact this is a project that's going on in Microsoft Cambridge at the moment is to try and build a single model that.",
            "No, we're not quite handling all of these.",
            "Is handling the."
        ],
        [
            "The bulk of them using a hybrid deep segmentation network, which I don't have any time left to talk about, unfortunately, so you'll have to watch this space and thank you."
        ],
        [
            "So much for your attention.",
            "Questions for the speaker.",
            "Do you think you can generalize the idea?",
            "I'm using discriminative model to sort of ruined the model space absolutely.",
            "Absolutely, I think.",
            "I think a lot of approximate inference techniques are about choosing the family, choosing your approximating family at the family, approximating distribution.",
            "At the moment we tend to do that once by hand, right?",
            "And it's not in a data driven way, and I think there's a huge amount of scope for for it's going to matter.",
            "Inference is for using features of the data to predict how we can efficiently run that inference.",
            "I think this is a very exciting area because.",
            "You know currently are meta inference things.",
            "A meta inference method is grad students, right?",
            "They watch the inference procedure progressing and see what's working and what isn't, and then modify it, and it seems to make sense that you know if a grad student can do it, then we can automate it.",
            "My phone number.",
            "Any other questions?",
            "You're showing the footballer went wrong instead of teacher in generative models can incorporate things that go wrong with season.",
            "Spin pole is close to very easy because all you do is just kind of.",
            "People trained in this kind of model looking like that, so it again in the training set, so it's more highly weighted.",
            "And then you keep repeating until they get the maximum performance like that.",
            "Something as simple as well.",
            "I mean if you take a discriminative model like a booster, it's already got something like that built in and then it's going to make mistakes.",
            "Still at the end.",
            "So assuming you've already done all the tricks that you know how to do to update or download different parts of your training set, then what do you do next, right?",
            "Why's your discriminative model failing at that point?",
            "Which in a sense?",
            "This control is lossy.",
            "It's computing some features of the data, which means that there's potentially things being lossed about the data and you don't know what they are, and so the only way to sort of explore that space is to try and dream up new features and you don't know you have no means of saying how.",
            "Well, it's not obvious how these features are orthogonal to existing features and so on, whereas a generative model that's forced to explain all of the image is non lossy in that sense.",
            "So, and also if you're trying to interpret it as a forward running generative stochastic process of creating the image and you can see either way the inference is going wrong or whether you're making a false assumption in the model.",
            "So I would say it's much easier to diagnose failure.",
            "Let's thank the speaker again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You had a nice break for today.",
                    "label": 0
                },
                {
                    "sent": "We're pleased to have John win with us today.",
                    "label": 0
                },
                {
                    "sent": "John Dubinsky HD, Cambridge, where he worked on graphical model and friends and have inside my research does vision applications at all suppliers in attics.",
                    "label": 0
                },
                {
                    "sent": "So I actually met John five years going out in at MSR and back then I was into it, scared models and I was kind of getting into general models and global skeptical Delta Dawn hasn't timeless.",
                    "label": 0
                },
                {
                    "sent": "Model and look at this.",
                    "label": 0
                },
                {
                    "sent": "Discussion.",
                    "label": 0
                },
                {
                    "sent": "So it's appropriate that you know Johnny here five years later has done a lot of good work, combining the best of both.",
                    "label": 0
                },
                {
                    "sent": "Worldswhichshows.com, thank you busy so.",
                    "label": 0
                },
                {
                    "sent": "The talk this talk is is not going to be deeply mathematical talk.",
                    "label": 0
                },
                {
                    "sent": "It's going to be a little bit of a whirlwind tour of some probabilistic models of vision applications, but I will be pulling my own personal journey through generative and discriminative approaches to vision before looking at some some hybrid.",
                    "label": 0
                },
                {
                    "sent": "Ideas, so I quite like the yin and Yang sort of concept for generative and discriminative have complementary ideas that bring both which bring something to the table.",
                    "label": 1
                },
                {
                    "sent": "So that's the theme here.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yes, but one of the things I would like to sort of emphasizes is the problem of understanding and automatically interpreting an image has its own special characteristics that perhaps differ from some of the other applications will be hearing about in the workshop today, so I particularly want to sort of start off just by setting the scene, do what the real challenges with understanding images.",
                    "label": 0
                },
                {
                    "sent": "And the really big thing about a measured pixel intensity or or RGB value is that the sheer number of things that led to that measurement.",
                    "label": 0
                },
                {
                    "sent": "So there's a huge number of sources of image variability.",
                    "label": 1
                },
                {
                    "sent": "That lead or can influence the measurement that you get when you take your camera out into the world and take a picture.",
                    "label": 0
                },
                {
                    "sent": "And this is just an attempt to try and enumerate some of those.",
                    "label": 0
                },
                {
                    "sent": "Sources of variability.",
                    "label": 0
                },
                {
                    "sent": "So the first thing that influences what pixels you're actually going to get is where you take your camera.",
                    "label": 0
                },
                {
                    "sent": "What sort of rough?",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Seen the indoors outdoor.",
                    "label": 0
                },
                {
                    "sent": "What kind of things we're going to see.",
                    "label": 0
                },
                {
                    "sent": "So this is the same type and the geometry of the scene.",
                    "label": 0
                },
                {
                    "sent": "So, for example, we might have a street scene with this kind of geometry outdoor.",
                    "label": 1
                },
                {
                    "sent": "The horizon is visible and so forth.",
                    "label": 0
                },
                {
                    "sent": "And then on top of that, it's going to be what objects are present in the scene.",
                    "label": 0
                },
                {
                    "sent": "So one of the classes of the objects that we have within the scene structure.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so for a street scene, you might expect to see something like this set of objects present in the image.",
                    "label": 0
                },
                {
                    "sent": "Now if we want to work out which pixels are affected by the presence of these objects in the scene.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then we're going to first of all, we have to workout the position and orientation of each of these objects.",
                    "label": 0
                },
                {
                    "sent": "So we can move those objects into the appropriate location, but we're going to need a little more than that.",
                    "label": 0
                },
                {
                    "sent": "We will need to know about their shape and.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if we now now we can start to see exactly which pixel measurements going to be influenced by to these objects that are actually out there in the world.",
                    "label": 0
                },
                {
                    "sent": "But objects aren't transparent like they're here.",
                    "label": 0
                },
                {
                    "sent": "In fact, they have this depth ordering 'cause we're talking about image in a 3 dimensional world, so I don't really have the steps that that's going to lead to occlusion effect, so the actual.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Pixels influenced by each object are going to look something more like that.",
                    "label": 0
                },
                {
                    "sent": "And then on top of that we have to say how does the presence of an object in the scene influence the pixels?",
                    "label": 0
                },
                {
                    "sent": "And that's going to mean some.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thing about encoding the appearance of an object, and so if we bring that into the image, we now have something that's pretty close to the kind of image that you might be capturing.",
                    "label": 0
                },
                {
                    "sent": "But on top of that there are effects that are not object specific where one object influences the appearance of another, for example earlier.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Nation effects and shadows, which are to do with interactions between objects and therefore inches.",
                    "label": 0
                },
                {
                    "sent": "Further complexity in the statistical dependence between the pixels, so we can bring in the shadows into our scene and then fine.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we have a whole other bunch of such smaller lower impact sources of variability like motion blur and camera.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Next, we're going to have relatively small effects on the pixels that might be like what resolution are we?",
                    "label": 0
                },
                {
                    "sent": "Are we going to be sampling the light field at?",
                    "label": 0
                },
                {
                    "sent": "And so this leads us to the actual image that we want to measure.",
                    "label": 0
                },
                {
                    "sent": "So when we're talking about building a probabilistic model, the main thing that you have to bear in mind is there's a huge number of sources of variability that we're going to have to be able to represent.",
                    "label": 0
                },
                {
                    "sent": "And so.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let's talk firstly, then, if we were talking about building a generative model of an image.",
                    "label": 0
                },
                {
                    "sent": "So you will come into this workshop.",
                    "label": 0
                },
                {
                    "sent": "You know what generative model is.",
                    "label": 0
                },
                {
                    "sent": "Then here we have a prescription as I see it for a generative approaches, which is going to select some set of these variables or sources of variability that affect the image as latent variables and describe attractable generative process.",
                    "label": 1
                },
                {
                    "sent": "So a stochastic process by which those variables will lead to the generation of a natural image.",
                    "label": 0
                },
                {
                    "sent": "And then we're going to apply that to some unlabeled data to infer these latent variables.",
                    "label": 0
                },
                {
                    "sent": "Now, a key thing that we have to bear in mind here is that if we don't include one of these sources of variability in our generative model, then we're going to pair price for it.",
                    "label": 0
                },
                {
                    "sent": "So we either have to restrict the domain in which we're going to apply the model by saying.",
                    "label": 0
                },
                {
                    "sent": "The objects must not be included or they must be affixed.",
                    "label": 0
                },
                {
                    "sent": "Seen structure of a fixed class or a fixed orientation.",
                    "label": 0
                },
                {
                    "sent": "We're going to have to hope that they are captured by some.",
                    "label": 1
                },
                {
                    "sent": "Noise or outline process, and if that's not the case, it's going to distort the inference of the model, so this is going to be a sort of model mismatch issue.",
                    "label": 0
                },
                {
                    "sent": "If we don't build a rich enough model and building a rich enough model is going to be very challenging.",
                    "label": 0
                },
                {
                    "sent": "So I'm building up my little comparison score.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The table between the generative and discriminative approaches here, and what this tells us is that we've seen as a huge number of sources of variability, so we're going to have to build a complex model if we don't want to be suffering from a limited domain in which we can apply our generative model.",
                    "label": 0
                },
                {
                    "sent": "And that's going to be slow to do inferencing.",
                    "label": 0
                },
                {
                    "sent": "So this suggests that in.",
                    "label": 0
                },
                {
                    "sent": "In understanding images, generative model is going to be both complicated and somewhat slow to process.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we look at an example, so I'm going to take a number of examples at the talk.",
                    "label": 0
                },
                {
                    "sent": "On the left hand side, I'm going to keep around the list of sources of variability and highlight the ones that the model is actually representing within itself, and so all the other ones are going to actually have to be fixed or just going to ignore them and cross our fingers.",
                    "label": 0
                },
                {
                    "sent": "And on the right hand side we have the actual generative model that we are using in this case.",
                    "label": 0
                },
                {
                    "sent": "So here this is the layered sprites model of UA Confrey from 2001.",
                    "label": 0
                },
                {
                    "sent": "This is one of the first generative image models that.",
                    "label": 0
                },
                {
                    "sent": "That really sort of was able to generate a entire video, for example, and you see that we have latent variables for the appearance of the object, which in this case is just a Sprite or a bitmap.",
                    "label": 0
                },
                {
                    "sent": "For the shape, which is just a binary bitmap and then we just going to have a position which rips in the position of the object in the scene, and then there's going to be composited together so we have a number of those objects are going to be composited together to form the image, and that's the assumed generative process here.",
                    "label": 0
                },
                {
                    "sent": "So here is a picture of that.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Generative model in play so.",
                    "label": 0
                },
                {
                    "sent": "What's happened is they've taken some video.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "Where we have someone walking along very, very carefully from left to right and.",
                    "label": 0
                },
                {
                    "sent": "It's learned about these sprites for both the background layer.",
                    "label": 0
                },
                {
                    "sent": "Which has a fixed appearance in a mask which is or shape which is the entire image and a foreground layer where the appearance is the appearance of a guy looking from the side and the mask is is the shape of that person and then the position of the background is fixed in the middle and the position of the person is moving from left to right.",
                    "label": 0
                },
                {
                    "sent": "Another example of this model.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is.",
                    "label": 0
                },
                {
                    "sent": "So in here this is with two layers and the background, and so we have the two authors rendered in the brochure, walking very carefully in front of each other.",
                    "label": 0
                },
                {
                    "sent": "And then we can take that video and decompose it into layers under the generative model.",
                    "label": 0
                },
                {
                    "sent": "So I think.",
                    "label": 0
                },
                {
                    "sent": "While this model has been very successful in decomposing this video, a criticism that was leveled at it from the vision community at least is that this is, yeah, this is set up right.",
                    "label": 0
                },
                {
                    "sent": "You had people working very, very carefully, but that was because they had to keep within the domain of the generative model.",
                    "label": 0
                },
                {
                    "sent": "Keep within the assumptions of the generative model, which only allowed very limited domain of application for this model.",
                    "label": 0
                },
                {
                    "sent": "So just to continue then.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With because it's complicated to build these models to represent the rich variability of images, we're going to have to often limit the domain in which generative model can be applied.",
                    "label": 0
                },
                {
                    "sent": "But on the plus side, within that domain, and assuming we can solve the inference problem accurately.",
                    "label": 0
                },
                {
                    "sent": "Then it's going to give us accurate interpretable results for that model.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's switch to the second approach that's mentioned in this workshop, which is discriminative modeling.",
                    "label": 0
                },
                {
                    "sent": "So again, we're going to need to look at some of these sources of variability, but now they're going to be targets, and we're going to be modeling the conditional probability.",
                    "label": 0
                },
                {
                    "sent": "This is my view for the discriminative model is a conditional model I guess is people were mentioning earlier those target variables given the image, and now we have to actually use some manual annotation.",
                    "label": 1
                },
                {
                    "sent": "But once again, if we're not explicitly representing a source of variability in the model.",
                    "label": 1
                },
                {
                    "sent": "It either has to be fixed or it has to be thoroughly explored in the training set so you can learn to compensate for that source of variability.",
                    "label": 1
                },
                {
                    "sent": "So this is kind of the ability to cope with model mismatch that discriminative models have.",
                    "label": 0
                },
                {
                    "sent": "But you still need to make sure that that's the source of variability, are thoroughly explored in your labeled data and envision.",
                    "label": 0
                },
                {
                    "sent": "That's extremely hard, because if you made a very simple discriminative model, that's a huge number of of.",
                    "label": 0
                },
                {
                    "sent": "Other variables that you're going to have to explore thoroughly, which suggests you need a combinatorially large training set, but I will say something about discriminative models, which is this ability to.",
                    "label": 0
                },
                {
                    "sent": "Cope with model mismatch.",
                    "label": 0
                },
                {
                    "sent": "Means that 'cause no one can build models complicated enough to accurately represent the imaging process.",
                    "label": 0
                },
                {
                    "sent": "These are the ones that currently work best.",
                    "label": 1
                },
                {
                    "sent": "And in fact, if you look at the Pascal VC challenge for this year, all of the winning competitors is a challenge for detecting, segmenting, and classifying objects in images.",
                    "label": 0
                },
                {
                    "sent": "All of the winning systems are predominantly discriminative.",
                    "label": 0
                },
                {
                    "sent": "This is different we've seen in other domains today where generative models are competitive in vision at the moment.",
                    "label": 0
                },
                {
                    "sent": "They are predominantly not competitive with discriminative models, and that's I think.",
                    "label": 0
                },
                {
                    "sent": "Mainly because of the complexity of the imaging task, Percy.",
                    "label": 0
                },
                {
                    "sent": "So that's why I said predominantly discriminative.",
                    "label": 0
                },
                {
                    "sent": "So these are vision systems which are often not new, have algorithmic components and so forth.",
                    "label": 0
                },
                {
                    "sent": "And there are certain components of these systems which you could see as generative.",
                    "label": 0
                },
                {
                    "sent": "For example, Pat clustering and that kind of thing.",
                    "label": 0
                },
                {
                    "sent": "Some of them use Constellation models which are learning the generative type way.",
                    "label": 0
                },
                {
                    "sent": "But I would say that by far the dominant paradigm is discriminative.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We build up a table.",
                    "label": 0
                },
                {
                    "sent": "They can be relatively simple models in comparison to the generative ones, because there simply have fewer variable variabilities in them, they're going to be faster to execute.",
                    "label": 0
                },
                {
                    "sent": "Ann and their robust to model mismatch.",
                    "label": 1
                },
                {
                    "sent": "The downside is of course that you need labeled data, and if you believe what I said just now, you need a lot of labeled data.",
                    "label": 0
                },
                {
                    "sent": "And in the Pascal challenge, for example, we do provide a lot of labeled data, but maybe not.",
                    "label": 0
                },
                {
                    "sent": "An infinite amount.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's look at a common example of discriminative models used in vision.",
                    "label": 0
                },
                {
                    "sent": "So here the only thing that's basically inside this model is which class it is, where it's a face or not, and the position of that face within the image.",
                    "label": 0
                },
                {
                    "sent": "And we're just going to slide a window across the image, extract some features.",
                    "label": 0
                },
                {
                    "sent": "From that window and then feed it into a standard classifier of some sort, and in this case it was a boosted cascade.",
                    "label": 0
                },
                {
                    "sent": "And that's going to tell us whether or not we have a face within our window at this particular point in time.",
                    "label": 0
                },
                {
                    "sent": "As you can see, it works absolutely pretty well at explaining faces, and I think this is one of the first times in vision where people really appreciated the power of machine learning.",
                    "label": 0
                },
                {
                    "sent": "So it's a great and Seminole paper, but it's also particularly recommend recognizing footballs which are not faces lost.",
                    "label": 0
                },
                {
                    "sent": "I checked.",
                    "label": 0
                },
                {
                    "sent": "So why is that?",
                    "label": 0
                },
                {
                    "sent": "And this is a.",
                    "label": 0
                },
                {
                    "sent": "It's not like it's hard for us to tell that.",
                    "label": 0
                },
                {
                    "sent": "Thing at the bottom is not a face, and it's because it's only seeing this tiny window.",
                    "label": 0
                },
                {
                    "sent": "There's enormous amount of information that this model is ignoring.",
                    "label": 0
                },
                {
                    "sent": "And of course discriminative models are completely free to do that because they're not required to explain everything that you're seeing in the image.",
                    "label": 0
                },
                {
                    "sent": "And so negative on the discriminative front is that there are helpful.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Use in modeling all of these other sources of variability, like the context, for example, which is very, very quick.",
                    "label": 0
                },
                {
                    "sent": "Very easy to ignore if you're just merging to pick what you think are going to be useful features.",
                    "label": 0
                },
                {
                    "sent": "The other thing is that it will be inaccurate if you have two few labeled examples and in most cases you have too few labeled examples.",
                    "label": 1
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A common approach or common sort of understanding is that these discriminative models we mean a standard classifier.",
                    "label": 0
                },
                {
                    "sent": "But of course you can put a lot of rich prior information into a discriminative model.",
                    "label": 0
                },
                {
                    "sent": "We've seen some of that earlier today in vision at a very common approach is the conditional random field for segmentation.",
                    "label": 0
                },
                {
                    "sent": "Here what we do is we take a sliding window, but rather than trying to use the sliding window to recognize the whole object, we're going to get to recognize parts of the object like the car.",
                    "label": 0
                },
                {
                    "sent": "Here we're going to say.",
                    "label": 0
                },
                {
                    "sent": "Each color is a part of sliding window and predict what the parts are and if we do that then we get a complete mess that looks like this because trying to predict which part of a car you're seeing from a little sliding window is a very ambiguous task.",
                    "label": 0
                },
                {
                    "sent": "But if we then introduce some structure into the model which says that I expect the front of the car to be next to the middle of the car.",
                    "label": 0
                },
                {
                    "sent": "Introducing conditional random field structure in place.",
                    "label": 0
                },
                {
                    "sent": "That's putting a lot of prior knowledge about how parts go together and also how occluding objects interact with each other.",
                    "label": 0
                },
                {
                    "sent": "Now if we run the same model again, then we get a result like this.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Where the only coherent part labels are those which accurately represents the car, and they can also cope with occlusion and tell you which part of the car that you're actually seeing.",
                    "label": 0
                },
                {
                    "sent": "So we can identify the cars in the image.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to continue, these discriminative models need not be black box models.",
                    "label": 1
                },
                {
                    "sent": "We can put a lot of rich information in them.",
                    "label": 0
                },
                {
                    "sent": "However, if the model goes wrong, the only measure we have of the performance of a discriminative model is some some sense, whether it succeeds or not.",
                    "label": 0
                },
                {
                    "sent": "Because the internals are not necessarily.",
                    "label": 0
                },
                {
                    "sent": "That interpretable.",
                    "label": 1
                },
                {
                    "sent": "Sometimes extremely hard to diagnose why discriminative model doesn't work well for the generative model.",
                    "label": 0
                },
                {
                    "sent": "We have a well defined definition of what each of our latent variables is.",
                    "label": 0
                },
                {
                    "sent": "I think this is a really big weakness of discriminative models.",
                    "label": 0
                },
                {
                    "sent": "It's like if it doesn't work.",
                    "label": 0
                },
                {
                    "sent": "You don't know how to modify the model or or the inference procedure often to workout, why?",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, second generative example is.",
                    "label": 0
                },
                {
                    "sent": "Here we're trying to go beyond the restricted set we saw earlier.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Build a richer model that has many more aspects of the image in process in there.",
                    "label": 0
                },
                {
                    "sent": "So we got position, shape, appearance and illumination.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to go into too much detail about the object, but the only thing to say is it's basically segmenting out a set of objects of the same class in a bunch of images under the assumption of the same class, but without knowing what the classes and the only thing common between all of the images is.",
                    "label": 0
                },
                {
                    "sent": "This shared sort of shape template.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So well defined generative model of the image.",
                    "label": 0
                },
                {
                    "sent": "Anne Anne.",
                    "label": 0
                },
                {
                    "sent": "What you can get from that is completely unsupervised segmentation, so you give it.",
                    "label": 0
                },
                {
                    "sent": "In this case, there were twenty images of horses.",
                    "label": 0
                },
                {
                    "sent": "I'm just showing four of them.",
                    "label": 0
                },
                {
                    "sent": "And we can get out of that both completely unsupervised segmentation and a model of the horse.",
                    "label": 0
                },
                {
                    "sent": "That is being used to segment all of these images, and this is actually one of the generative models which is come closer to the performance of discriminative models in vision.",
                    "label": 0
                },
                {
                    "sent": "So when I did this paper back in 2005, the accuracy of segmentation in this data set was about 93%.",
                    "label": 0
                },
                {
                    "sent": "For discriminative methods, it was about 9095% for discount methods.",
                    "label": 0
                },
                {
                    "sent": "It was 94%.",
                    "label": 0
                },
                {
                    "sent": "That's since gone to 95%.",
                    "label": 0
                },
                {
                    "sent": "So here we have an example of a generative model that's coming pretty close.",
                    "label": 0
                },
                {
                    "sent": "To discriminative model in performance, but it's not better.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what we can do then is deal with unlabeled data and we can diagnose flows more easily.",
                    "label": 0
                },
                {
                    "sent": "So for example, where that model tended to go wrong, it was because one of the generative modeling assumptions was violated and it was very easy to tell which that it was.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can then go along that path even more and build even even more.",
                    "label": 0
                },
                {
                    "sent": "Hackling even more variables into the model.",
                    "label": 0
                },
                {
                    "sent": "This is a great piece of work by.",
                    "label": 0
                },
                {
                    "sent": "Pound Kumar in 2005 when they threw in an awful lot of variables.",
                    "label": 0
                },
                {
                    "sent": "But the inference here was very, very difficult.",
                    "label": 0
                },
                {
                    "sent": "Including that motion blur illumination, all different parts of the zebra and so forth, but it was able to use every single one of these cues to help improve the accuracy of the inference and and builder.",
                    "label": 0
                },
                {
                    "sent": "As zebra model from.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There in this case, so it was using all available queues and the other thing was you could do it for all kinds of different applications.",
                    "label": 0
                },
                {
                    "sent": "It would track segment diebler.",
                    "label": 0
                },
                {
                    "sent": "It was doing all of these different vision applications using exactly the same model.",
                    "label": 0
                },
                {
                    "sent": "Because all these different latent variables are being represented within the model.",
                    "label": 0
                },
                {
                    "sent": "OK, this is a lightning tour.",
                    "label": 0
                },
                {
                    "sent": "I'm going through this very quickly so I apologize for that.",
                    "label": 0
                },
                {
                    "sent": "Say that the.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "5 minutes great so that the.",
                    "label": 0
                },
                {
                    "sent": "You can, so we see that there's lots of advantages of both generative and discriminative models in vision.",
                    "label": 0
                },
                {
                    "sent": "And so we want to try and take.",
                    "label": 0
                },
                {
                    "sent": "The best of both worlds.",
                    "label": 0
                },
                {
                    "sent": "So we need to develop some hybrid methods.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Which is obviously what this workshop is about, and we've seen some various methods presented today so far.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "What I want to talk about probably going to talk about one application and this is to do with.",
                    "label": 0
                },
                {
                    "sent": "At slightly different approach than what we've seen, it's about using a hybrid approach to speed up inference in a generative model, so here.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we have another image model.",
                    "label": 0
                },
                {
                    "sent": "This is called the jigsaw model and the idea is that you have a set of images and you want to try and find a latent image that we call the jigsaw that you can use pieces of to explain a number of real images.",
                    "label": 0
                },
                {
                    "sent": "So here we have a cartoon of that where we have.",
                    "label": 0
                },
                {
                    "sent": "One face here, but imagine you have a set of these faces, and then we're going to learn a bunch of pieces that we can use to build up all the faces out of an example result.",
                    "label": 0
                },
                {
                    "sent": "Is if we have some faces you can't quite see them, they're showing the pieces as well.",
                    "label": 0
                },
                {
                    "sent": "So here we have 20 faces.",
                    "label": 0
                },
                {
                    "sent": "Then the kind of jigsaw that you did look something like this.",
                    "label": 0
                },
                {
                    "sent": "But something slightly out of a horror movie.",
                    "label": 0
                },
                {
                    "sent": "But you can use this to construct photo fits of.",
                    "label": 0
                },
                {
                    "sent": "All kinds of people's faces.",
                    "label": 0
                },
                {
                    "sent": "The problem with the jigsaw model.",
                    "label": 0
                },
                {
                    "sent": "Is that we're trying to infer for every single pixel of each training image or test image where it Maps 2 into the jigsaw, and this is a high cardinality problem.",
                    "label": 0
                },
                {
                    "sent": "There's maybe in this case 10,000 pixels in the jigsaw, so we're going to have to have a 10,000 state variable for every single pixel in every single training image.",
                    "label": 0
                },
                {
                    "sent": "And that's a very slow operation.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We'd like to be able to speed that up, and here's a hybrid approach for doing that.",
                    "label": 0
                },
                {
                    "sent": "So we compute.",
                    "label": 0
                },
                {
                    "sent": "The likelihood of each pixel affected pixel coming from every possible jigsaw location that we find.",
                    "label": 0
                },
                {
                    "sent": "If we have a red pixel.",
                    "label": 0
                },
                {
                    "sent": "Excuse me, it will match well to all the red locations in the jigsaw and it won't match very well anywhere else and so you'll tend to get a likelihood that looks something like this.",
                    "label": 0
                },
                {
                    "sent": "It will have a few peaks and then it will have a lot of very flat.",
                    "label": 0
                },
                {
                    "sent": "Regions for most of most of the places it doesn't match well too.",
                    "label": 0
                },
                {
                    "sent": "But it's not very informative.",
                    "label": 0
                },
                {
                    "sent": "It can't tell.",
                    "label": 0
                },
                {
                    "sent": "They can't tell which red pixel it should map to because it's not able to use any context, so we can use a discriminative approach, which is very much like what you seen earlier.",
                    "label": 0
                },
                {
                    "sent": "Where you take a Patch and try to make a prediction for the part in the car case so we can take a Patch and trying to prediction for where we go into the jigsaw in this case.",
                    "label": 0
                },
                {
                    "sent": "And that's going to make a prediction here.",
                    "label": 0
                },
                {
                    "sent": "Rather than just linearly combine this in some way, what we're going to do is we're going to take a family of approximating distributions such that we're saying that family is the set of distributions which has K well defined values, and all remaining values are exactly the same a uniform.",
                    "label": 0
                },
                {
                    "sent": "Then we can take So what we can do normally is we can just say let's suppose K is 10, we can use KL divergent, say and minimize kelder vengeance to pick the Member of that family.",
                    "label": 0
                },
                {
                    "sent": "We're going to use for message passing.",
                    "label": 0
                },
                {
                    "sent": "But now we can take the prediction for the classifier and say the location is predicted by the classifier are going to be where we're going to represent explicitly the values in this message.",
                    "label": 0
                },
                {
                    "sent": "So you can think of it as training a discriminative classifier to tell you where to spend computational effort to solve your generative model.",
                    "label": 0
                },
                {
                    "sent": "And that's kind of a very nice.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Framework.",
                    "label": 0
                },
                {
                    "sent": "And so the results we're getting for that things like this.",
                    "label": 0
                },
                {
                    "sent": "So here we have the amount of memory required to solve the jigsaw model.",
                    "label": 0
                },
                {
                    "sent": "This is a measure of the quality of the resultant solution and this is showing how as we train that classifier on more and more.",
                    "label": 0
                },
                {
                    "sent": "Training images how we're getting better and better, better performance and just doing inference in the generative model.",
                    "label": 0
                },
                {
                    "sent": "So we can get up to a 10 times speedup over the original image by using this technique.",
                    "label": 0
                },
                {
                    "sent": "So this hybrid methods for speeding up inference.",
                    "label": 0
                },
                {
                    "sent": "This is called hybrid belief propagation.",
                    "label": 1
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the idea and the goal line of machine vision, I would say, is to represent all of these sources of variability in a single image Ng model so that we can get a complete understanding of the image.",
                    "label": 1
                },
                {
                    "sent": "And I think it's very encouraging that these hybrid methods are able to take the best of both generative and discriminative worlds.",
                    "label": 0
                },
                {
                    "sent": "I think that we will probably see something in the next few years that is capable of doing this, and in fact this is a project that's going on in Microsoft Cambridge at the moment is to try and build a single model that.",
                    "label": 0
                },
                {
                    "sent": "No, we're not quite handling all of these.",
                    "label": 0
                },
                {
                    "sent": "Is handling the.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The bulk of them using a hybrid deep segmentation network, which I don't have any time left to talk about, unfortunately, so you'll have to watch this space and thank you.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So much for your attention.",
                    "label": 0
                },
                {
                    "sent": "Questions for the speaker.",
                    "label": 0
                },
                {
                    "sent": "Do you think you can generalize the idea?",
                    "label": 0
                },
                {
                    "sent": "I'm using discriminative model to sort of ruined the model space absolutely.",
                    "label": 0
                },
                {
                    "sent": "Absolutely, I think.",
                    "label": 0
                },
                {
                    "sent": "I think a lot of approximate inference techniques are about choosing the family, choosing your approximating family at the family, approximating distribution.",
                    "label": 0
                },
                {
                    "sent": "At the moment we tend to do that once by hand, right?",
                    "label": 0
                },
                {
                    "sent": "And it's not in a data driven way, and I think there's a huge amount of scope for for it's going to matter.",
                    "label": 0
                },
                {
                    "sent": "Inference is for using features of the data to predict how we can efficiently run that inference.",
                    "label": 0
                },
                {
                    "sent": "I think this is a very exciting area because.",
                    "label": 0
                },
                {
                    "sent": "You know currently are meta inference things.",
                    "label": 0
                },
                {
                    "sent": "A meta inference method is grad students, right?",
                    "label": 0
                },
                {
                    "sent": "They watch the inference procedure progressing and see what's working and what isn't, and then modify it, and it seems to make sense that you know if a grad student can do it, then we can automate it.",
                    "label": 0
                },
                {
                    "sent": "My phone number.",
                    "label": 0
                },
                {
                    "sent": "Any other questions?",
                    "label": 0
                },
                {
                    "sent": "You're showing the footballer went wrong instead of teacher in generative models can incorporate things that go wrong with season.",
                    "label": 0
                },
                {
                    "sent": "Spin pole is close to very easy because all you do is just kind of.",
                    "label": 0
                },
                {
                    "sent": "People trained in this kind of model looking like that, so it again in the training set, so it's more highly weighted.",
                    "label": 0
                },
                {
                    "sent": "And then you keep repeating until they get the maximum performance like that.",
                    "label": 0
                },
                {
                    "sent": "Something as simple as well.",
                    "label": 0
                },
                {
                    "sent": "I mean if you take a discriminative model like a booster, it's already got something like that built in and then it's going to make mistakes.",
                    "label": 0
                },
                {
                    "sent": "Still at the end.",
                    "label": 0
                },
                {
                    "sent": "So assuming you've already done all the tricks that you know how to do to update or download different parts of your training set, then what do you do next, right?",
                    "label": 0
                },
                {
                    "sent": "Why's your discriminative model failing at that point?",
                    "label": 0
                },
                {
                    "sent": "Which in a sense?",
                    "label": 0
                },
                {
                    "sent": "This control is lossy.",
                    "label": 0
                },
                {
                    "sent": "It's computing some features of the data, which means that there's potentially things being lossed about the data and you don't know what they are, and so the only way to sort of explore that space is to try and dream up new features and you don't know you have no means of saying how.",
                    "label": 0
                },
                {
                    "sent": "Well, it's not obvious how these features are orthogonal to existing features and so on, whereas a generative model that's forced to explain all of the image is non lossy in that sense.",
                    "label": 0
                },
                {
                    "sent": "So, and also if you're trying to interpret it as a forward running generative stochastic process of creating the image and you can see either way the inference is going wrong or whether you're making a false assumption in the model.",
                    "label": 0
                },
                {
                    "sent": "So I would say it's much easier to diagnose failure.",
                    "label": 0
                },
                {
                    "sent": "Let's thank the speaker again.",
                    "label": 0
                }
            ]
        }
    }
}