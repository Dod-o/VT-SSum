{
    "id": "mbrreds7vudfvzoevcbrhmdft5qcenw4",
    "title": "Online Learning of Music Preference",
    "info": {
        "author": [
            "Peter Orbanz, Institute of Computational Science, ETH Zurich"
        ],
        "published": "Dec. 29, 2007",
        "recorded": "December 2007",
        "category": [
            "Top->Computer Science->Machine Learning->On-line Learning"
        ]
    },
    "url": "http://videolectures.net/mbc07_orbanz_olm/",
    "segmentation": [
        [
            "Good morning, so my name is Peter Robbins and I'm working at Zurich Ath with young woman and most of the work that I'm presenting here was done by my colleague in one more.",
            "But you could make it."
        ],
        [
            "So we are.",
            "Yeah, I'm sorry.",
            "So we are interested in music classification, but somewhat in a somewhat different sense than most people here, I suppose because we're not trying to do general classification.",
            "We are interested in in classifying music data, but in a sense that the classifier is capable of incorporating user feedback.",
            "And and adjust to that even if the user has a lousy idea of music.",
            "Yeah, he should still be satisfied.",
            "So the reason why we are interested in such a problem is that we are working with a hearing aid company and they would like to build.",
            "Hearing aids which?",
            "Which apply different kind of amplification programs to different kinds of data, and a classifier should decide which amplification program is to be used.",
            "So when we're talking about classes here then that means amplification settings.",
            "OK, so and the classifier behavior should in some way be influenced by the user.",
            "The user should provide feedback and it's important that that feedback is simple.",
            "You can't sell hearing aid to someone and try to explain the support vector machine.",
            "You have to very simple button press kind of feedback.",
            "So the algorithmic requirements that we have is.",
            "One is online adaptation, of course, so that means if the.",
            "If new data comes in that hasn't been seen previously, or if the user contradicts himself in one, is that the feedback provided by the user has to be expected to be very, very sparse.",
            "So we can't expect the user to be hitting buttons all the time.",
            "Yeah, we have to expect that every once in awhile we get some feedback label and the feedback is for the classification purposes.",
            "Labels are feedback.",
            "Yeah, so we have few labels in the data.",
            "Then there is something which I have called passivity here.",
            "So what that is about is.",
            "Um?",
            "We would not like to have a setting where the user has to.",
            "To tell us that the current setting is nice.",
            "What people would rather do is that the user just reacts.",
            "If something is wrong.",
            "So if the current setting is not good, the user hits a button that's a setting.",
            "And that means that as long as there is no feedback, we have to assume that everything is fine and the classifier should not continuously adapt its settings.",
            "We want to have an online learning algorithm, but it should not continuously try to adapt.",
            "Becaused if the user is satisfied, then whatever, whatever machine learning theory sets, we should not adapt further, OK?",
            "And last but not least, of course they're sufficiency becausw in the long term goal is to at some point implement that on on a portable device, and sound data accumulates lots of gigabytes very quickly.",
            "And you can't store that backwards indefinitely.",
            "So."
        ],
        [
            "Our approach is a combination of.",
            "Of online and semi supervised learning strategies.",
            "So to address this online problem that the classifier has to adapt.",
            "We we use what's called an additive expert ensemble, so that's a very classic online learning algorithm.",
            "For those of you not familiar with that, it's basically a combination of very simple classifiers and these classifiers are fixed and they are combined into an aggregate classifier by a weighted sum.",
            "And what is actually changed are the weights of the sum of the individual classifiers, which ends setting are called the experts.",
            "They are kept fixed.",
            "The only thing that we adapt is that every once in awhile, if a classifier performance very poorly, we will evict it and train one new classifier.",
            "But we don't train the whole set of classifiers and you in every adaptation step.",
            "OK, and this this system adapts only when feedback is received to make it passive.",
            "Yeah.",
            "OK, and we have to address the partial label problem.",
            "We use a method that is called label propagation, so that's a direct graph based method.",
            "What you do is you look at your data.",
            "Part of that is labeled.",
            "Most of it is unlabeled and you construct a graph between the data points and then you put edge weights on the graph and the weights tell you how far or how similar data points are.",
            "Usually you just take something like exponential, negative Euclidean distance or something like that.",
            "So the point is only influenced by points which are very close.",
            "And then you propagate the label information from the points which are labeled along the graph edges by a discretized diffusion process.",
            "So I admit that discretized diffusion is that sounds kind of too fancy for something that works well, but it actually works pretty well.",
            "And so by this message we use, we use the labels that we have to hypothesize labels on the other data points.",
            "And then pass those back to the classifier.",
            "And we have some reason to believe that that works that works rather well or music data.",
            "So what I'm showing here is some of our data and it's colored according to composers.",
            "This mostly classical music color according to composer, so that's a much finer granularity then we actually considering.",
            "Our setting is hyperplane somewhere in between.",
            "Here one class the other class.",
            "And.",
            "Um?",
            "As you can see, there is something of a spatial coherence.",
            "Yeah, so it's it's.",
            "These classes are spatially more or less coherent, and that is very important for semi supervised learning, because this idea that you can spread one label to neighboring points that requires a certain amount of regularity.",
            "OK, what you can also see is that we have to expect.",
            "Certain certain error rate is of maybe 10% or something is something that we really have to live with because the classes here are really mixed up.",
            "So this is this is an LDA projection.",
            "It already takes into account the labels."
        ],
        [
            "OK, and very briefly.",
            "Um?",
            "About the results.",
            "I'm we have a poster over there and I would like to discuss the results in more detail there, but.",
            "What you see here is the performance of the green curves that a classifier that adept based only on the labels that we have.",
            "The blue curve is was a semi supervised information, but the label propagation and what you see here on the X is are not time steps, it's the ratio of label information.",
            "So 100% here is a fully supervised case.",
            "We have all the labels, zero percent is unsupervised and what you can see here is what's kind of interesting is that the performance when we get more labels first gets worse.",
            "For the green curve, which is kind of counterintuitive, right, it should get better.",
            "But what happens here is here we have a factory setting and restart to adapt that, and the reason why this first gets worse served with several steps is that more labels mean more adaptation steps.",
            "But when we have very few labels, adaptation is a bad thing because it overfits.",
            "Yeah, so more steps, more overfitting performance gets worse and then it starts to get better again.",
            "So what we're interested in is actually the break even point it would be over here.",
            "So this is where you can really start to use your adaptive classifier.",
            "And you can see that with the green curve, this is something that happens for maybe 30% of the labels.",
            "And when we use the semi supervised information we can really switch to the other classifier at maybe 5% of the labels, so it's still not as good as we would like to be.",
            "Would like to get down to something like 1% maybe.",
            "And we are chiefly here to collect feedback.",
            "From a different community and what we are particularly interested in is.",
            "We're currently using MFC features and these are pretty bad.",
            "So currently we need about 20 seconds of a piece of music to get a reliable classification.",
            "And I mean that is intuitively that's ridiculous.",
            "Human least needs much less than 20 seconds, right?",
            "So we probably should use something else.",
            "So if you if you have anything, any anything to say about that, any suggestions or criticism?",
            "I would like to hear about it.",
            "Around after that for the post session, thank you very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Good morning, so my name is Peter Robbins and I'm working at Zurich Ath with young woman and most of the work that I'm presenting here was done by my colleague in one more.",
                    "label": 0
                },
                {
                    "sent": "But you could make it.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we are.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I'm sorry.",
                    "label": 0
                },
                {
                    "sent": "So we are interested in music classification, but somewhat in a somewhat different sense than most people here, I suppose because we're not trying to do general classification.",
                    "label": 0
                },
                {
                    "sent": "We are interested in in classifying music data, but in a sense that the classifier is capable of incorporating user feedback.",
                    "label": 0
                },
                {
                    "sent": "And and adjust to that even if the user has a lousy idea of music.",
                    "label": 1
                },
                {
                    "sent": "Yeah, he should still be satisfied.",
                    "label": 0
                },
                {
                    "sent": "So the reason why we are interested in such a problem is that we are working with a hearing aid company and they would like to build.",
                    "label": 0
                },
                {
                    "sent": "Hearing aids which?",
                    "label": 1
                },
                {
                    "sent": "Which apply different kind of amplification programs to different kinds of data, and a classifier should decide which amplification program is to be used.",
                    "label": 0
                },
                {
                    "sent": "So when we're talking about classes here then that means amplification settings.",
                    "label": 0
                },
                {
                    "sent": "OK, so and the classifier behavior should in some way be influenced by the user.",
                    "label": 0
                },
                {
                    "sent": "The user should provide feedback and it's important that that feedback is simple.",
                    "label": 1
                },
                {
                    "sent": "You can't sell hearing aid to someone and try to explain the support vector machine.",
                    "label": 0
                },
                {
                    "sent": "You have to very simple button press kind of feedback.",
                    "label": 0
                },
                {
                    "sent": "So the algorithmic requirements that we have is.",
                    "label": 0
                },
                {
                    "sent": "One is online adaptation, of course, so that means if the.",
                    "label": 1
                },
                {
                    "sent": "If new data comes in that hasn't been seen previously, or if the user contradicts himself in one, is that the feedback provided by the user has to be expected to be very, very sparse.",
                    "label": 0
                },
                {
                    "sent": "So we can't expect the user to be hitting buttons all the time.",
                    "label": 0
                },
                {
                    "sent": "Yeah, we have to expect that every once in awhile we get some feedback label and the feedback is for the classification purposes.",
                    "label": 0
                },
                {
                    "sent": "Labels are feedback.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so we have few labels in the data.",
                    "label": 0
                },
                {
                    "sent": "Then there is something which I have called passivity here.",
                    "label": 0
                },
                {
                    "sent": "So what that is about is.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "We would not like to have a setting where the user has to.",
                    "label": 0
                },
                {
                    "sent": "To tell us that the current setting is nice.",
                    "label": 0
                },
                {
                    "sent": "What people would rather do is that the user just reacts.",
                    "label": 0
                },
                {
                    "sent": "If something is wrong.",
                    "label": 1
                },
                {
                    "sent": "So if the current setting is not good, the user hits a button that's a setting.",
                    "label": 0
                },
                {
                    "sent": "And that means that as long as there is no feedback, we have to assume that everything is fine and the classifier should not continuously adapt its settings.",
                    "label": 0
                },
                {
                    "sent": "We want to have an online learning algorithm, but it should not continuously try to adapt.",
                    "label": 0
                },
                {
                    "sent": "Becaused if the user is satisfied, then whatever, whatever machine learning theory sets, we should not adapt further, OK?",
                    "label": 0
                },
                {
                    "sent": "And last but not least, of course they're sufficiency becausw in the long term goal is to at some point implement that on on a portable device, and sound data accumulates lots of gigabytes very quickly.",
                    "label": 0
                },
                {
                    "sent": "And you can't store that backwards indefinitely.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our approach is a combination of.",
                    "label": 0
                },
                {
                    "sent": "Of online and semi supervised learning strategies.",
                    "label": 1
                },
                {
                    "sent": "So to address this online problem that the classifier has to adapt.",
                    "label": 0
                },
                {
                    "sent": "We we use what's called an additive expert ensemble, so that's a very classic online learning algorithm.",
                    "label": 1
                },
                {
                    "sent": "For those of you not familiar with that, it's basically a combination of very simple classifiers and these classifiers are fixed and they are combined into an aggregate classifier by a weighted sum.",
                    "label": 0
                },
                {
                    "sent": "And what is actually changed are the weights of the sum of the individual classifiers, which ends setting are called the experts.",
                    "label": 0
                },
                {
                    "sent": "They are kept fixed.",
                    "label": 0
                },
                {
                    "sent": "The only thing that we adapt is that every once in awhile, if a classifier performance very poorly, we will evict it and train one new classifier.",
                    "label": 0
                },
                {
                    "sent": "But we don't train the whole set of classifiers and you in every adaptation step.",
                    "label": 0
                },
                {
                    "sent": "OK, and this this system adapts only when feedback is received to make it passive.",
                    "label": 1
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "OK, and we have to address the partial label problem.",
                    "label": 0
                },
                {
                    "sent": "We use a method that is called label propagation, so that's a direct graph based method.",
                    "label": 0
                },
                {
                    "sent": "What you do is you look at your data.",
                    "label": 0
                },
                {
                    "sent": "Part of that is labeled.",
                    "label": 0
                },
                {
                    "sent": "Most of it is unlabeled and you construct a graph between the data points and then you put edge weights on the graph and the weights tell you how far or how similar data points are.",
                    "label": 0
                },
                {
                    "sent": "Usually you just take something like exponential, negative Euclidean distance or something like that.",
                    "label": 0
                },
                {
                    "sent": "So the point is only influenced by points which are very close.",
                    "label": 0
                },
                {
                    "sent": "And then you propagate the label information from the points which are labeled along the graph edges by a discretized diffusion process.",
                    "label": 0
                },
                {
                    "sent": "So I admit that discretized diffusion is that sounds kind of too fancy for something that works well, but it actually works pretty well.",
                    "label": 0
                },
                {
                    "sent": "And so by this message we use, we use the labels that we have to hypothesize labels on the other data points.",
                    "label": 0
                },
                {
                    "sent": "And then pass those back to the classifier.",
                    "label": 0
                },
                {
                    "sent": "And we have some reason to believe that that works that works rather well or music data.",
                    "label": 0
                },
                {
                    "sent": "So what I'm showing here is some of our data and it's colored according to composers.",
                    "label": 0
                },
                {
                    "sent": "This mostly classical music color according to composer, so that's a much finer granularity then we actually considering.",
                    "label": 0
                },
                {
                    "sent": "Our setting is hyperplane somewhere in between.",
                    "label": 0
                },
                {
                    "sent": "Here one class the other class.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "As you can see, there is something of a spatial coherence.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so it's it's.",
                    "label": 0
                },
                {
                    "sent": "These classes are spatially more or less coherent, and that is very important for semi supervised learning, because this idea that you can spread one label to neighboring points that requires a certain amount of regularity.",
                    "label": 0
                },
                {
                    "sent": "OK, what you can also see is that we have to expect.",
                    "label": 0
                },
                {
                    "sent": "Certain certain error rate is of maybe 10% or something is something that we really have to live with because the classes here are really mixed up.",
                    "label": 0
                },
                {
                    "sent": "So this is this is an LDA projection.",
                    "label": 0
                },
                {
                    "sent": "It already takes into account the labels.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, and very briefly.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "About the results.",
                    "label": 0
                },
                {
                    "sent": "I'm we have a poster over there and I would like to discuss the results in more detail there, but.",
                    "label": 0
                },
                {
                    "sent": "What you see here is the performance of the green curves that a classifier that adept based only on the labels that we have.",
                    "label": 0
                },
                {
                    "sent": "The blue curve is was a semi supervised information, but the label propagation and what you see here on the X is are not time steps, it's the ratio of label information.",
                    "label": 0
                },
                {
                    "sent": "So 100% here is a fully supervised case.",
                    "label": 0
                },
                {
                    "sent": "We have all the labels, zero percent is unsupervised and what you can see here is what's kind of interesting is that the performance when we get more labels first gets worse.",
                    "label": 0
                },
                {
                    "sent": "For the green curve, which is kind of counterintuitive, right, it should get better.",
                    "label": 0
                },
                {
                    "sent": "But what happens here is here we have a factory setting and restart to adapt that, and the reason why this first gets worse served with several steps is that more labels mean more adaptation steps.",
                    "label": 0
                },
                {
                    "sent": "But when we have very few labels, adaptation is a bad thing because it overfits.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so more steps, more overfitting performance gets worse and then it starts to get better again.",
                    "label": 0
                },
                {
                    "sent": "So what we're interested in is actually the break even point it would be over here.",
                    "label": 0
                },
                {
                    "sent": "So this is where you can really start to use your adaptive classifier.",
                    "label": 0
                },
                {
                    "sent": "And you can see that with the green curve, this is something that happens for maybe 30% of the labels.",
                    "label": 0
                },
                {
                    "sent": "And when we use the semi supervised information we can really switch to the other classifier at maybe 5% of the labels, so it's still not as good as we would like to be.",
                    "label": 0
                },
                {
                    "sent": "Would like to get down to something like 1% maybe.",
                    "label": 0
                },
                {
                    "sent": "And we are chiefly here to collect feedback.",
                    "label": 0
                },
                {
                    "sent": "From a different community and what we are particularly interested in is.",
                    "label": 0
                },
                {
                    "sent": "We're currently using MFC features and these are pretty bad.",
                    "label": 0
                },
                {
                    "sent": "So currently we need about 20 seconds of a piece of music to get a reliable classification.",
                    "label": 1
                },
                {
                    "sent": "And I mean that is intuitively that's ridiculous.",
                    "label": 0
                },
                {
                    "sent": "Human least needs much less than 20 seconds, right?",
                    "label": 0
                },
                {
                    "sent": "So we probably should use something else.",
                    "label": 0
                },
                {
                    "sent": "So if you if you have anything, any anything to say about that, any suggestions or criticism?",
                    "label": 0
                },
                {
                    "sent": "I would like to hear about it.",
                    "label": 0
                },
                {
                    "sent": "Around after that for the post session, thank you very much.",
                    "label": 0
                }
            ]
        }
    }
}