{
    "id": "2xgfeapp25a2vkytfp6hdrtc3m5kquyz",
    "title": "Common Substructure Learning of Multiple Graphical Gaussian Models",
    "info": {
        "author": [
            "Satoshi Hara, Graduate School of Engineering, Osaka University"
        ],
        "published": "Oct. 3, 2011",
        "recorded": "September 2011",
        "category": [
            "Top->Computer Science->Machine Learning->Graphical Models",
            "Top->Computer Science->Machine Learning->Gaussian Processes"
        ]
    },
    "url": "http://videolectures.net/ecmlpkdd2011_hara_common/",
    "segmentation": [
        [
            "So today I'd like to introduce our work titled Common Substructure Learning on multiple graphical Gaussian models that I'm suppose harder from also University and it's joint work with my supervisor."
        ],
        [
            "So the target of my work this time is kind of the dynamics of a graphical model.",
            "So it is natural to assume if the data generating mechanism has some non stationarity.",
            "Or that it had some.",
            "Affect from the surrounding environment that are changing, then that what we observe also changes so that like here we.",
            "Usually have also that underlying the graphical model for each time point or each environment are different.",
            "But this time we also assume that this kind of change occurs only partially.",
            "This is the case that, for example, in the engineering system that usually the system error occurs in only on this subsystem, so the remaining parts remain are healthy.",
            "Or also in the if we analyze a short time change in the series, then we can separate the series to the dynamical changing part on the very slow gradual change part, which can be assumed as a common part."
        ],
        [
            "So the goal of my research is here, so we have the data set from each time point or from the each environment.",
            "Then that of course that they have some underlying graphical models.",
            "So that.",
            "Now that we want to know this one, of course, but we further want to know which part of the edges are common and which parts are dynamically changing.",
            "This is the target of my work."
        ],
        [
            "Time.",
            "So this is a brief.",
            "Abstract on my."
        ],
        [
            "I first talk about the graphical Gaussian model.",
            "This is the model we treating this time.",
            "So.",
            "OK, this is just a general fact that if a random variable X is generated from Gaussian, then we know that the two variables XJ and XJ prime are conditionally independent.",
            "This is equivalent that this question matrix Lambda has a zero entry on it's JJ Primes.",
            "So we can so that it's just a Gaussian model, but then that learning the structure of graphical model it can now is turned to the identification of the Reporter in the pressure matrix.",
            "So.",
            "Data, most naive approaches just use a maximum likelihood estimate, but which is of course in practice for impractical for this case because it gives only the dense estimate for the final sample case.",
            "So that's why that the recent techniques that sparse methods have been introduced in this field."
        ],
        [
            "So this is some structured learning methods recently provided using the regularization technique.",
            "OK, the most fundamental one is our Air unregularized maximum likelihood, so it's OK. We maximize the likelihood function here.",
            "Then that data, additional L1 regularization term which makes the result sparse.",
            "Fortunately, this program is convex and there are several efficient algorithm it's existing.",
            "And.",
            "Once we can write down the problem in this regularization form that it is natural to extend this L1 regularization to the regularization commonly used in the group lasso.",
            "So this is a problem that treated in the.",
            "This paper that they estimate not the one pression matrix, but rather the set of the pressure matrices in one time with the underlying assumption that all has the same zero pattern.",
            "So they replace this error on regularization with kind of the Max.",
            "Maximum normal.",
            "OK, so.",
            "As I mentioned before, the target work is the three.",
            "This kind of a set of data sets, so the problem can be in this framework.",
            "Kind of this framework.",
            "So this is a basic part of our work."
        ],
        [
            "Now I moved onto that work, so of course that we first need to define what is a common substructure in our program.",
            "So this is a definition I treated in this case.",
            "So OK, we have pressure matrices and some corresponding entries are all the same, then we treat it as a common part.",
            "And if if if.",
            "One of them, or more of them, are different than that we treated as non common part, so it's just a very naive definition, but it can be seen as a extension of the weak stationarity notion to the partial covariance.",
            "And what's more, better for this definition is that we can write down this definition in this formula.",
            "So if the corresponding element is common, then actually we see that this kind of the maximal variation is 0.",
            "This is equivalent condition.",
            "So now that the basic idea is to use this property."
        ],
        [
            "To make a new regularization term.",
            "OK, So what we solve is again the maximum likelihood.",
            "And we impose the same joint structure from the previous.",
            "Structure learning method.",
            "And we further imposed additional regularization term which comes from this property of the commonness.",
            "So we regularly to joint structure as well as the maximum variation.",
            "So this is our proposed part.",
            "And.",
            "Even though we do this kind of the complicated stuff, the problem still remains convex, so we can.",
            "Now later I introduce a way to solve this optimization problem.",
            "But"
        ],
        [
            "Before that I have to mention that there is one existing prior works related to this problem.",
            "So what they did this paper treated is they treated the problem of the structural changes between two datasets.",
            "They used a bit different approach, but.",
            "The contrast can be summarized as this table so.",
            "We use the regularizer, maximum likelihood and their work can be seen at the kind of approximation of this formulation.",
            "And the father that they treated as I said, two datasets.",
            "So their problem formulation and also the algorithm are.",
            "Very specific to the case of the N = 2.",
            "So that it cannot be actually generalized more than N = 3 then, so that which we can treat.",
            "So our work can be understood as a more general framework involving this one."
        ],
        [
            "OK, so now I explain that how to do this.",
            "How to solve this optimization problem?"
        ],
        [
            "So the technique we treat here is a block coding dissent, which is commonly used in the prior works like graphical lasso or the multitask structure learning.",
            "So because of that, we have that D * D matrix.",
            "Times N. Number of datasets, so it's a very big.",
            "Parameters, but what we do is not optimize all stuff in one time, but rather we pick up the one element from each matrix and make the N dimensional vector.",
            "And we optimize only this N dimensional vectors while others remaining part of the parameters to be fixed.",
            "And what good is that?",
            "There is some theoretical analytics saying this approach converging to global Optima?",
            "And OK, we pick up 1 one element from each matrix, but there are two cases at the target element is on the diagonal an or in the non diagonal.",
            "So that we derive two different problems for each case."
        ],
        [
            "The first case, that target is on the diagonal.",
            "The what we do is very simple, just.",
            "OK, this is a target entry.",
            "We want to optimize and.",
            "Divide matrices into the remaining parts, like here.",
            "Then the optimal value is given in this analytic form, so we don't really need the any difficult thing.",
            "Furthermore, that this approach guarantees that if we initialize, each pressure matrix is positive definite, then that this property is preserved for any updating step, so that we don't really need to care of the positive definite.",
            "This because it's automatically counted in this approach."
        ],
        [
            "The problem on the non diagonal entries it's more tricky.",
            "So what we want to optimize is a set of variables B.",
            "But here we solve the dual problem because it's more easier.",
            "OK, I omit the detail, but there are some parameters AB come from the fixed parameters and sample covariances.",
            "And the problem is the optimization on the quadratic.",
            "Problem with these two constraint.",
            "So this is a convex program, so we can use any kind of general convex solvers.",
            "But we wanted to solve it more efficiently.",
            "So looking at more detail on this constraint, the constraint term, then we see that OK this.",
            "This term corresponds to this Blue Square the.",
            "This one corresponds to these red lines.",
            "And people, the region is discolored part.",
            "And we actually classify the solution to four cases.",
            "The solution is inside this colored region, or on this blue line or on this red line or on the intersection of two hyper spaces.",
            "So what we do here is the not to solve this problem directly, but solve for each case."
        ],
        [
            "And again with the detail, but for example, if the solution is on this blue line, it can be solved so called continuous quadratic knapsack problem.",
            "This is very, very efficient algorithm, so we can solve it easily and exactly.",
            "The solution is on the red line.",
            "OK, there is analytic solution, so we don't really need to do anything difficult.",
            "And the solution is on this intersection.",
            "Again, this is kind of this kind of problem, so we can solve it exactly and efficiently.",
            "So what we have to do is OK.",
            "So this solve this.",
            "Solve this and OK the final solution."
        ],
        [
            "This target program."
        ],
        [
            "It's one of these threes or just a inside."
        ],
        [
            "Here, which is just a B."
        ],
        [
            "So."
        ],
        [
            "Instead of solving this problem directly."
        ],
        [
            "We factorize a problem to four parts and just pick up one of these solutions.",
            "This is the optimal.",
            "And now we have."
        ],
        [
            "The way to optimize the our target program.",
            "Sorry.",
            "So I now introduce a simulation."
        ],
        [
            "Old.",
            "I generated data artificially.",
            "OK, this is a graph showing that the X1 to X8 these variables has a common edges.",
            "And so their structure and also the weights of edges are common while the remaining 12 variables there edge weights and also the connecting structures are changing.",
            "And I generated 20 times.",
            "So under 5 datasets and each from each data set that we generated, 100 IID data points."
        ],
        [
            "And also for the comparison purpose we adopted 2 baseline methods.",
            "So what I did is the.",
            "Just first estimate pressure matrices using the existing methods like glosso under multitask structure learning so they don't count anything commonness in their problem.",
            "So at the post press processing we extracted a seemingly common substructure just by thresholding the maximal variation with some parameter epsilon."
        ],
        [
            "So this is a result.",
            "Then by changing the hyper prime, the load and this is a RC car.",
            "And it is clear that the proposed method, this blue line, is on the left upper side.",
            "It means that it is the best.",
            "We further tell that this.",
            "Thresholding on the maximum variation on this heuristic, we set epsilon to one.",
            "But actually that epsilon to one is very optimistic.",
            "'cause that already does 74% of the estimated non zero entries are under the threshold.",
            "But still that actually this part involves only 38% of the true common substructure.",
            "So what we find here is almost nothing.",
            "But the proposed method could avoid this kind of the estimation variance problem and.",
            "And so so the best result."
        ],
        [
            "Now that last part of my talk, I introduced the application part.",
            "I applied proposal method."
        ],
        [
            "Anomaly detection problem.",
            "So this is a description of the data set I used.",
            "So this is an automobile data and there it has 42 sensor values from real car.",
            "And this data set.",
            "So there are 79 datasets samples from the normal states.",
            "And other 20 samples from 40 states where the fault is caused by the miswiring of the 24th and 25th sensors.",
            "So what we find what we want to find is that this rich sensor is faulty.",
            "So the previous work.",
            "And this STM paper they pointed out that we can capture this kind of the anomaly by using these graphical model.",
            "And further that using this anomaly score, which is actually just a clear divergences, we can find such errors and efficiently point out OK for 2420 fifth sensors are.",
            "Faulty but as I said in the beginning that.",
            "We assume in our program that some parts of the graphical model is common and some parts are dynamically changing, which can intuitively corresponds to the healthy parts of the sensors and the faulty parts of the sensors."
        ],
        [
            "OK, so this is a simulation setting.",
            "We used 25 datasets, 20 from normal state on five from 40 States and again I adopted baseline methods of dealer.",
            "So under MSL.",
            "And after I estimated pressure methods for each of these methods, then I.",
            "Calculated this score for each case is an just detect the sensors by thresholding rolled up."
        ],
        [
            "Under my score.",
            "Say this is a result of resulting the RC car and also the corresponding the AUC value.",
            "We first see OK the proposed method, our method and also the model task structure.",
            "Learning approaches provide the best AUC, so they're performing.",
            "Almost the same in the detection performance.",
            "However, we can't."
        ],
        [
            "Others see their differences on the resulting the animal scores.",
            "So OK, these two black lines are the faulty sensors.",
            "And OK, any method?",
            "Each method has more or less giving the good result that they are very enhanced.",
            "But still that for remaining this of.",
            "Healthy sensors so we can see that the proposed method has lower significance on these healthy fats, like for example here that is almost zero saying that it's perfectly healthy.",
            "And also that I.",
            "Roads on the.",
            "75% and 25% points, which also shows that this graph shows that proposed methods much stable for the.",
            "The fraction of the data set.",
            "So OK, the detection performance is almost the same, but still we can see the advantage of the proposed method in this graph."
        ],
        [
            "OK, so this is a summary of my talk.",
            "I treated a common substructure learning problem, which is the identified a common parts in the dynamic dependency structure.",
            "And I proposed the optimization problem using the block coordinate descent and we also provided.",
            "Very simple strategy to solve the subproblem, we just factorizing the solution to four cases and just pick up one of them.",
            "And on the numerical evaluation, or both on synthetic and real world data, we can see the validity of the proposed method.",
            "Especially that we observe that naive approaches are not very good for this context because they suffer from the estimation variance, that's all, thank you.",
            "The time for questions from the floor.",
            "Questions.",
            "Maybe the.",
            "Dependence structure.",
            "In your presentation is the dependency of which variables are directly related to which other variables, right?",
            "It's a conditional dependency, yeah, so it doesn't necessarily tell the causality among the variables, not it undirected graph.",
            "It's not causal deal OK. Q.",
            "If there is no other.",
            "Questions or comments from the floor?",
            "I think we should close this session an let's close this session by thanking all the speakers."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So today I'd like to introduce our work titled Common Substructure Learning on multiple graphical Gaussian models that I'm suppose harder from also University and it's joint work with my supervisor.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the target of my work this time is kind of the dynamics of a graphical model.",
                    "label": 1
                },
                {
                    "sent": "So it is natural to assume if the data generating mechanism has some non stationarity.",
                    "label": 0
                },
                {
                    "sent": "Or that it had some.",
                    "label": 0
                },
                {
                    "sent": "Affect from the surrounding environment that are changing, then that what we observe also changes so that like here we.",
                    "label": 1
                },
                {
                    "sent": "Usually have also that underlying the graphical model for each time point or each environment are different.",
                    "label": 0
                },
                {
                    "sent": "But this time we also assume that this kind of change occurs only partially.",
                    "label": 0
                },
                {
                    "sent": "This is the case that, for example, in the engineering system that usually the system error occurs in only on this subsystem, so the remaining parts remain are healthy.",
                    "label": 0
                },
                {
                    "sent": "Or also in the if we analyze a short time change in the series, then we can separate the series to the dynamical changing part on the very slow gradual change part, which can be assumed as a common part.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the goal of my research is here, so we have the data set from each time point or from the each environment.",
                    "label": 1
                },
                {
                    "sent": "Then that of course that they have some underlying graphical models.",
                    "label": 1
                },
                {
                    "sent": "So that.",
                    "label": 0
                },
                {
                    "sent": "Now that we want to know this one, of course, but we further want to know which part of the edges are common and which parts are dynamically changing.",
                    "label": 0
                },
                {
                    "sent": "This is the target of my work.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Time.",
                    "label": 0
                },
                {
                    "sent": "So this is a brief.",
                    "label": 0
                },
                {
                    "sent": "Abstract on my.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I first talk about the graphical Gaussian model.",
                    "label": 0
                },
                {
                    "sent": "This is the model we treating this time.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "OK, this is just a general fact that if a random variable X is generated from Gaussian, then we know that the two variables XJ and XJ prime are conditionally independent.",
                    "label": 1
                },
                {
                    "sent": "This is equivalent that this question matrix Lambda has a zero entry on it's JJ Primes.",
                    "label": 0
                },
                {
                    "sent": "So we can so that it's just a Gaussian model, but then that learning the structure of graphical model it can now is turned to the identification of the Reporter in the pressure matrix.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Data, most naive approaches just use a maximum likelihood estimate, but which is of course in practice for impractical for this case because it gives only the dense estimate for the final sample case.",
                    "label": 0
                },
                {
                    "sent": "So that's why that the recent techniques that sparse methods have been introduced in this field.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is some structured learning methods recently provided using the regularization technique.",
                    "label": 0
                },
                {
                    "sent": "OK, the most fundamental one is our Air unregularized maximum likelihood, so it's OK. We maximize the likelihood function here.",
                    "label": 1
                },
                {
                    "sent": "Then that data, additional L1 regularization term which makes the result sparse.",
                    "label": 0
                },
                {
                    "sent": "Fortunately, this program is convex and there are several efficient algorithm it's existing.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Once we can write down the problem in this regularization form that it is natural to extend this L1 regularization to the regularization commonly used in the group lasso.",
                    "label": 0
                },
                {
                    "sent": "So this is a problem that treated in the.",
                    "label": 1
                },
                {
                    "sent": "This paper that they estimate not the one pression matrix, but rather the set of the pressure matrices in one time with the underlying assumption that all has the same zero pattern.",
                    "label": 0
                },
                {
                    "sent": "So they replace this error on regularization with kind of the Max.",
                    "label": 0
                },
                {
                    "sent": "Maximum normal.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "As I mentioned before, the target work is the three.",
                    "label": 0
                },
                {
                    "sent": "This kind of a set of data sets, so the problem can be in this framework.",
                    "label": 0
                },
                {
                    "sent": "Kind of this framework.",
                    "label": 0
                },
                {
                    "sent": "So this is a basic part of our work.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now I moved onto that work, so of course that we first need to define what is a common substructure in our program.",
                    "label": 0
                },
                {
                    "sent": "So this is a definition I treated in this case.",
                    "label": 0
                },
                {
                    "sent": "So OK, we have pressure matrices and some corresponding entries are all the same, then we treat it as a common part.",
                    "label": 0
                },
                {
                    "sent": "And if if if.",
                    "label": 0
                },
                {
                    "sent": "One of them, or more of them, are different than that we treated as non common part, so it's just a very naive definition, but it can be seen as a extension of the weak stationarity notion to the partial covariance.",
                    "label": 0
                },
                {
                    "sent": "And what's more, better for this definition is that we can write down this definition in this formula.",
                    "label": 0
                },
                {
                    "sent": "So if the corresponding element is common, then actually we see that this kind of the maximal variation is 0.",
                    "label": 1
                },
                {
                    "sent": "This is equivalent condition.",
                    "label": 0
                },
                {
                    "sent": "So now that the basic idea is to use this property.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To make a new regularization term.",
                    "label": 0
                },
                {
                    "sent": "OK, So what we solve is again the maximum likelihood.",
                    "label": 0
                },
                {
                    "sent": "And we impose the same joint structure from the previous.",
                    "label": 1
                },
                {
                    "sent": "Structure learning method.",
                    "label": 0
                },
                {
                    "sent": "And we further imposed additional regularization term which comes from this property of the commonness.",
                    "label": 1
                },
                {
                    "sent": "So we regularly to joint structure as well as the maximum variation.",
                    "label": 0
                },
                {
                    "sent": "So this is our proposed part.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Even though we do this kind of the complicated stuff, the problem still remains convex, so we can.",
                    "label": 1
                },
                {
                    "sent": "Now later I introduce a way to solve this optimization problem.",
                    "label": 0
                },
                {
                    "sent": "But",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Before that I have to mention that there is one existing prior works related to this problem.",
                    "label": 0
                },
                {
                    "sent": "So what they did this paper treated is they treated the problem of the structural changes between two datasets.",
                    "label": 1
                },
                {
                    "sent": "They used a bit different approach, but.",
                    "label": 0
                },
                {
                    "sent": "The contrast can be summarized as this table so.",
                    "label": 0
                },
                {
                    "sent": "We use the regularizer, maximum likelihood and their work can be seen at the kind of approximation of this formulation.",
                    "label": 0
                },
                {
                    "sent": "And the father that they treated as I said, two datasets.",
                    "label": 0
                },
                {
                    "sent": "So their problem formulation and also the algorithm are.",
                    "label": 1
                },
                {
                    "sent": "Very specific to the case of the N = 2.",
                    "label": 0
                },
                {
                    "sent": "So that it cannot be actually generalized more than N = 3 then, so that which we can treat.",
                    "label": 1
                },
                {
                    "sent": "So our work can be understood as a more general framework involving this one.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so now I explain that how to do this.",
                    "label": 0
                },
                {
                    "sent": "How to solve this optimization problem?",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the technique we treat here is a block coding dissent, which is commonly used in the prior works like graphical lasso or the multitask structure learning.",
                    "label": 0
                },
                {
                    "sent": "So because of that, we have that D * D matrix.",
                    "label": 0
                },
                {
                    "sent": "Times N. Number of datasets, so it's a very big.",
                    "label": 0
                },
                {
                    "sent": "Parameters, but what we do is not optimize all stuff in one time, but rather we pick up the one element from each matrix and make the N dimensional vector.",
                    "label": 0
                },
                {
                    "sent": "And we optimize only this N dimensional vectors while others remaining part of the parameters to be fixed.",
                    "label": 0
                },
                {
                    "sent": "And what good is that?",
                    "label": 0
                },
                {
                    "sent": "There is some theoretical analytics saying this approach converging to global Optima?",
                    "label": 0
                },
                {
                    "sent": "And OK, we pick up 1 one element from each matrix, but there are two cases at the target element is on the diagonal an or in the non diagonal.",
                    "label": 0
                },
                {
                    "sent": "So that we derive two different problems for each case.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The first case, that target is on the diagonal.",
                    "label": 0
                },
                {
                    "sent": "The what we do is very simple, just.",
                    "label": 0
                },
                {
                    "sent": "OK, this is a target entry.",
                    "label": 0
                },
                {
                    "sent": "We want to optimize and.",
                    "label": 0
                },
                {
                    "sent": "Divide matrices into the remaining parts, like here.",
                    "label": 0
                },
                {
                    "sent": "Then the optimal value is given in this analytic form, so we don't really need the any difficult thing.",
                    "label": 0
                },
                {
                    "sent": "Furthermore, that this approach guarantees that if we initialize, each pressure matrix is positive definite, then that this property is preserved for any updating step, so that we don't really need to care of the positive definite.",
                    "label": 1
                },
                {
                    "sent": "This because it's automatically counted in this approach.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The problem on the non diagonal entries it's more tricky.",
                    "label": 0
                },
                {
                    "sent": "So what we want to optimize is a set of variables B.",
                    "label": 0
                },
                {
                    "sent": "But here we solve the dual problem because it's more easier.",
                    "label": 1
                },
                {
                    "sent": "OK, I omit the detail, but there are some parameters AB come from the fixed parameters and sample covariances.",
                    "label": 0
                },
                {
                    "sent": "And the problem is the optimization on the quadratic.",
                    "label": 0
                },
                {
                    "sent": "Problem with these two constraint.",
                    "label": 0
                },
                {
                    "sent": "So this is a convex program, so we can use any kind of general convex solvers.",
                    "label": 0
                },
                {
                    "sent": "But we wanted to solve it more efficiently.",
                    "label": 0
                },
                {
                    "sent": "So looking at more detail on this constraint, the constraint term, then we see that OK this.",
                    "label": 0
                },
                {
                    "sent": "This term corresponds to this Blue Square the.",
                    "label": 0
                },
                {
                    "sent": "This one corresponds to these red lines.",
                    "label": 0
                },
                {
                    "sent": "And people, the region is discolored part.",
                    "label": 0
                },
                {
                    "sent": "And we actually classify the solution to four cases.",
                    "label": 0
                },
                {
                    "sent": "The solution is inside this colored region, or on this blue line or on this red line or on the intersection of two hyper spaces.",
                    "label": 0
                },
                {
                    "sent": "So what we do here is the not to solve this problem directly, but solve for each case.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And again with the detail, but for example, if the solution is on this blue line, it can be solved so called continuous quadratic knapsack problem.",
                    "label": 1
                },
                {
                    "sent": "This is very, very efficient algorithm, so we can solve it easily and exactly.",
                    "label": 0
                },
                {
                    "sent": "The solution is on the red line.",
                    "label": 0
                },
                {
                    "sent": "OK, there is analytic solution, so we don't really need to do anything difficult.",
                    "label": 0
                },
                {
                    "sent": "And the solution is on this intersection.",
                    "label": 0
                },
                {
                    "sent": "Again, this is kind of this kind of problem, so we can solve it exactly and efficiently.",
                    "label": 0
                },
                {
                    "sent": "So what we have to do is OK.",
                    "label": 0
                },
                {
                    "sent": "So this solve this.",
                    "label": 0
                },
                {
                    "sent": "Solve this and OK the final solution.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This target program.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's one of these threes or just a inside.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here, which is just a B.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Instead of solving this problem directly.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We factorize a problem to four parts and just pick up one of these solutions.",
                    "label": 1
                },
                {
                    "sent": "This is the optimal.",
                    "label": 0
                },
                {
                    "sent": "And now we have.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The way to optimize the our target program.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "So I now introduce a simulation.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Old.",
                    "label": 0
                },
                {
                    "sent": "I generated data artificially.",
                    "label": 0
                },
                {
                    "sent": "OK, this is a graph showing that the X1 to X8 these variables has a common edges.",
                    "label": 0
                },
                {
                    "sent": "And so their structure and also the weights of edges are common while the remaining 12 variables there edge weights and also the connecting structures are changing.",
                    "label": 0
                },
                {
                    "sent": "And I generated 20 times.",
                    "label": 0
                },
                {
                    "sent": "So under 5 datasets and each from each data set that we generated, 100 IID data points.",
                    "label": 1
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And also for the comparison purpose we adopted 2 baseline methods.",
                    "label": 1
                },
                {
                    "sent": "So what I did is the.",
                    "label": 0
                },
                {
                    "sent": "Just first estimate pressure matrices using the existing methods like glosso under multitask structure learning so they don't count anything commonness in their problem.",
                    "label": 1
                },
                {
                    "sent": "So at the post press processing we extracted a seemingly common substructure just by thresholding the maximal variation with some parameter epsilon.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is a result.",
                    "label": 0
                },
                {
                    "sent": "Then by changing the hyper prime, the load and this is a RC car.",
                    "label": 0
                },
                {
                    "sent": "And it is clear that the proposed method, this blue line, is on the left upper side.",
                    "label": 0
                },
                {
                    "sent": "It means that it is the best.",
                    "label": 1
                },
                {
                    "sent": "We further tell that this.",
                    "label": 0
                },
                {
                    "sent": "Thresholding on the maximum variation on this heuristic, we set epsilon to one.",
                    "label": 0
                },
                {
                    "sent": "But actually that epsilon to one is very optimistic.",
                    "label": 1
                },
                {
                    "sent": "'cause that already does 74% of the estimated non zero entries are under the threshold.",
                    "label": 1
                },
                {
                    "sent": "But still that actually this part involves only 38% of the true common substructure.",
                    "label": 0
                },
                {
                    "sent": "So what we find here is almost nothing.",
                    "label": 0
                },
                {
                    "sent": "But the proposed method could avoid this kind of the estimation variance problem and.",
                    "label": 1
                },
                {
                    "sent": "And so so the best result.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now that last part of my talk, I introduced the application part.",
                    "label": 0
                },
                {
                    "sent": "I applied proposal method.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Anomaly detection problem.",
                    "label": 0
                },
                {
                    "sent": "So this is a description of the data set I used.",
                    "label": 0
                },
                {
                    "sent": "So this is an automobile data and there it has 42 sensor values from real car.",
                    "label": 1
                },
                {
                    "sent": "And this data set.",
                    "label": 1
                },
                {
                    "sent": "So there are 79 datasets samples from the normal states.",
                    "label": 1
                },
                {
                    "sent": "And other 20 samples from 40 states where the fault is caused by the miswiring of the 24th and 25th sensors.",
                    "label": 0
                },
                {
                    "sent": "So what we find what we want to find is that this rich sensor is faulty.",
                    "label": 0
                },
                {
                    "sent": "So the previous work.",
                    "label": 0
                },
                {
                    "sent": "And this STM paper they pointed out that we can capture this kind of the anomaly by using these graphical model.",
                    "label": 0
                },
                {
                    "sent": "And further that using this anomaly score, which is actually just a clear divergences, we can find such errors and efficiently point out OK for 2420 fifth sensors are.",
                    "label": 0
                },
                {
                    "sent": "Faulty but as I said in the beginning that.",
                    "label": 0
                },
                {
                    "sent": "We assume in our program that some parts of the graphical model is common and some parts are dynamically changing, which can intuitively corresponds to the healthy parts of the sensors and the faulty parts of the sensors.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so this is a simulation setting.",
                    "label": 1
                },
                {
                    "sent": "We used 25 datasets, 20 from normal state on five from 40 States and again I adopted baseline methods of dealer.",
                    "label": 1
                },
                {
                    "sent": "So under MSL.",
                    "label": 0
                },
                {
                    "sent": "And after I estimated pressure methods for each of these methods, then I.",
                    "label": 0
                },
                {
                    "sent": "Calculated this score for each case is an just detect the sensors by thresholding rolled up.",
                    "label": 1
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Under my score.",
                    "label": 0
                },
                {
                    "sent": "Say this is a result of resulting the RC car and also the corresponding the AUC value.",
                    "label": 0
                },
                {
                    "sent": "We first see OK the proposed method, our method and also the model task structure.",
                    "label": 0
                },
                {
                    "sent": "Learning approaches provide the best AUC, so they're performing.",
                    "label": 1
                },
                {
                    "sent": "Almost the same in the detection performance.",
                    "label": 1
                },
                {
                    "sent": "However, we can't.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Others see their differences on the resulting the animal scores.",
                    "label": 0
                },
                {
                    "sent": "So OK, these two black lines are the faulty sensors.",
                    "label": 0
                },
                {
                    "sent": "And OK, any method?",
                    "label": 0
                },
                {
                    "sent": "Each method has more or less giving the good result that they are very enhanced.",
                    "label": 0
                },
                {
                    "sent": "But still that for remaining this of.",
                    "label": 0
                },
                {
                    "sent": "Healthy sensors so we can see that the proposed method has lower significance on these healthy fats, like for example here that is almost zero saying that it's perfectly healthy.",
                    "label": 1
                },
                {
                    "sent": "And also that I.",
                    "label": 0
                },
                {
                    "sent": "Roads on the.",
                    "label": 0
                },
                {
                    "sent": "75% and 25% points, which also shows that this graph shows that proposed methods much stable for the.",
                    "label": 0
                },
                {
                    "sent": "The fraction of the data set.",
                    "label": 0
                },
                {
                    "sent": "So OK, the detection performance is almost the same, but still we can see the advantage of the proposed method in this graph.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so this is a summary of my talk.",
                    "label": 0
                },
                {
                    "sent": "I treated a common substructure learning problem, which is the identified a common parts in the dynamic dependency structure.",
                    "label": 1
                },
                {
                    "sent": "And I proposed the optimization problem using the block coordinate descent and we also provided.",
                    "label": 0
                },
                {
                    "sent": "Very simple strategy to solve the subproblem, we just factorizing the solution to four cases and just pick up one of them.",
                    "label": 0
                },
                {
                    "sent": "And on the numerical evaluation, or both on synthetic and real world data, we can see the validity of the proposed method.",
                    "label": 1
                },
                {
                    "sent": "Especially that we observe that naive approaches are not very good for this context because they suffer from the estimation variance, that's all, thank you.",
                    "label": 0
                },
                {
                    "sent": "The time for questions from the floor.",
                    "label": 0
                },
                {
                    "sent": "Questions.",
                    "label": 0
                },
                {
                    "sent": "Maybe the.",
                    "label": 0
                },
                {
                    "sent": "Dependence structure.",
                    "label": 0
                },
                {
                    "sent": "In your presentation is the dependency of which variables are directly related to which other variables, right?",
                    "label": 0
                },
                {
                    "sent": "It's a conditional dependency, yeah, so it doesn't necessarily tell the causality among the variables, not it undirected graph.",
                    "label": 0
                },
                {
                    "sent": "It's not causal deal OK. Q.",
                    "label": 0
                },
                {
                    "sent": "If there is no other.",
                    "label": 0
                },
                {
                    "sent": "Questions or comments from the floor?",
                    "label": 0
                },
                {
                    "sent": "I think we should close this session an let's close this session by thanking all the speakers.",
                    "label": 0
                }
            ]
        }
    }
}