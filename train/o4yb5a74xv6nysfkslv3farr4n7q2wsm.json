{
    "id": "o4yb5a74xv6nysfkslv3farr4n7q2wsm",
    "title": "Getting the Meaning Right: A Complementary Distributional Layer for the Web Semantics",
    "info": {
        "author": [
            "Vit Novacek, DERI Galway, National University of Ireland, Galway"
        ],
        "published": "Nov. 25, 2011",
        "recorded": "October 2011",
        "category": [
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/iswc2011_novacek_semantics/",
    "segmentation": [
        [
            "The talk is not essentially providing an additional layer to disseminate through web semantics.",
            "A bottom up layer, in addition to what currently is more like topdown salmon."
        ],
        [
            "Six the talk is separated into four main blocks.",
            "First of all, I will tell you what bothers us and why it should bother you and what are we going to do about that.",
            "Then, in the solution I just go through the essentials and I tried to explain the technical core of the paper using a couple of simple examples.",
            "You can find the technical details in the paper here.",
            "If you are interested in the evaluation, I will show you.",
            "I will tell you what data we used for the evaluation, what kind of methods did we do?",
            "Did we apply and what results did we get?",
            "And conclusion section is just obligatory.",
            "Summing up of the paper and summary of the few."
        ],
        [
            "Work.",
            "So what's wrong with the meaning like?",
            "What, what, what, why should we bother the current semantic web is concerned mainly with expressions which are composed of some basic symbols.",
            "Your eyes, the meaning of the expressions is quite well researched.",
            "We we know how to combine your eyes and expressions or just store them in already have stores.",
            "How to query the stored statements, how to reason with the statements out to visualize the statements.",
            "But the meaning of the basic symbols is kind of atomic.",
            "Still like the machines don't really care.",
            "What do you, what the meaning of your eyes.",
            "As you could replace the Euros with any arbitrary symbols and the machines would proceed as happily as before, just manipulating the statements composed of these symbols.",
            "So what does this mean?",
            "This means essentially that the semantic web is not really linked to reality like there is like a gap between the semantic web expressions and between their possible grounding in the real world, like people maybe are able to link the statements to some entities in the real world, but for the machines there is no no formal link.",
            "Between the statements to your eyes, in the statements, and the things that these statements are supposed to describe, like I mean the things in the real world.",
            "And this is plenty of consequences.",
            "It's very hard to make the semantic Web descriptions accountable like people can describe things in real world, but different people can descrip exactly the same thing in totally different way.",
            "And there is no formal way how you can tell like you are wrong and you're right.",
            "Probably no one is wrong.",
            "No one is right.",
            "The truth is somewhere in between.",
            "That's totally fine.",
            "It's like it works like like it works like that, like when people represent the meaning.",
            "But in semantic web we would like to have this link.",
            "We would like to cap be able to capture this link for the machine so that the machines can deal with that so that the machines are really able to anchor their similar descriptions in the real world.",
            "But real world I should emphasize that I mean like obviously the machines are not able to perceive the real world as we do so by real world like anchoring in reality I mean like the closest approximation of reality that is available to the machines.",
            "Essentially, the web of data.",
            "The vast amount of data the machines have at their disposal on the web, or the semantic web.",
            "And when we will able to, when we will be able to do this, we will be able to do also like more empirical analysis of the semantic web data.",
            "This is kind of related to the invited talk which all of you heard in the morning of Franklin Harmelin.",
            "He was concerned about making the semantic web more signs like more more theorie.",
            "This is this is kind of fitting into this vision because if you're able to empirically prove that some semantic web descriptions.",
            "Actually describe something.",
            "Then you're one step closer to real science.",
            "You have a hypothesis which in our case is semantic Web description.",
            "Semantic web already have resource or whatever else, or an ontology.",
            "And then you empirically prove if you have the link between the expressions and the reality that your description actually really describes something that your hypothesis about the describing the world is valid.",
            "So that's what we would like to do with this approach.",
            "And how are we going to do that?",
            "Well, simply by adding a bottom up layer to the web semantics.",
            "That means that we slightly change the perspective.",
            "We look at.",
            "Semantic web is not something that is supposed to assert the meanings that do things, but we look at the semantic web as something that is able to infer the meaning of things from the data we have on the web."
        ],
        [
            "So this is the outline of the solution of the main contribution of the paper.",
            "Adding the bottom up layer.",
            "This is based on distributional semantics distribution.",
            "Semantics is an approach from computational linguistics which studies meaning of words as a function of their meaning in large natural language corpora.",
            "So we take this inspiration.",
            "This has been proven to work like since over decades ago.",
            "It's used in information retrieval in many commercially successful applications, so it's really proven to work.",
            "It's based on simple representation.",
            "A lot of really well founded mathematical methods based on linear algebra, statistical data analysts, so there is a lot of Arsenal theoretical original we can directly apply, so it's all just about changing the perspective to changing our view on how to look at the semantic Web data and how to analyze them so we can see the meaning of your eyes based on some corcorans analytics we we define the meaning as patterns that the symbols that your eyes can occur in by patterns like we mean for example, groups of related.",
            "Entities related you rise of entities or properties, or some rules.",
            "Some emergent emergently extracted rules and analogies that provide some.",
            "You know more specific specification of particular you Rice top this is this is this bottom up later.",
            "This is kind of an you think like curtain you view on the semantic web, but we still have to be able to combine this with the top down layer with the bunch of the extant ontologies, which can very often be converted to rules.",
            "Then we can do some rule based reasoning.",
            "You know this is all like.",
            "There are well known techniques for that, but the contribution of this approach is in combination of this top down techniques.",
            "With something that has been anchored into reality, using this bottom, a player that has been empirically grounded in the reality and then, like the symbolic reasoning, is not meaningless anymore.",
            "It operates with well grounded meaning of the your eyes.",
            "In the paper.",
            "We also show we've also shown promising promise of the approach by applying these principles to consolidation of entities and properties, grouping them into related groups, and we evaluated this in a using Bio Med."
        ],
        [
            "Pulling data."
        ],
        [
            "Let's move on to the solution.",
            "The essential notions regarding the representation are tensors, like everything is organized in as labeled tensors in the representation, tenders, or just generalization of the notion of vector metric, source colors color as just a number as a tensor with zero dimensionality.",
            "Vector is a tensor of dimension one.",
            "Just one line of numbers, metrics Field 2 dimensional field of numbers.",
            "So that's a dynamic 3 dimensional tensor at cetera, etc.",
            "So we have three layers of representation.",
            "First of all, we have source.",
            "These are just RDF graph, so RDF statements with their provenance represented as a four dimensional tensor.",
            "You'll see it in the example in a little while, then additional level is corpus is a 3 dimensional tensor which is sort of more compact, more comprehensive view on the resources and just groups together all the statements possibly occurring multiple resources computes sum, sum.",
            "Additional values and creates a kind of comprehensive view of the sources.",
            "Perspectives are then 2 dimensional matrices which are essentially still the corpus tensors only, represented in a slightly different way and converted to a metrics which then provides us with vector spaces.",
            "We can we can analyze later on the computation requires some statistiques when you want to compute this comprehensive view on the sources in the form of tenzer corpus tensor.",
            "Tensar Metra station.",
            "Converting higher dimensional tensors into 2 dimensional matrices.",
            "Linear algebra methods for analyzing of the metrics perspectives of the corpus and then a little bit of growth, era fuzzy logics and fixed point mathematics for evaluating the rule."
        ],
        [
            "This.",
            "This is an example of source and corpus representation.",
            "Like I I wrote down that answers to a more convenient tabular notation is because it's kind of tricky to display 4 dimensional tensors, for instance, so the rightmost column always contains, like numerical values.",
            "These are the elements of the tensors, whereas all the other columns represent the indices.",
            "The labeled indices of the tensor.",
            "So when you take the first line and the source representation, that's a statement like protein domain is the subject.",
            "Different is the predicate protein as the object and the one is an identifier of a document.",
            "This statement occurs in and the value of that is the frequency of the statement occurrence in the particular document.",
            "It's one for all the statements, then from this source tenzer, you just create a comprehensive corpus representation as follows, like here.",
            "Use relative frequencies of the statements in the full source.",
            "So for all the statements is 1 / 7 because there is like 7 statements.",
            "In total only for one statement for protein domain is a type of domain which occurs in two sources.",
            "In D1, the first line, sorry, the second line and E4 the last line.",
            "So it occurs in two documents or relative frequencies 2 /.",
            "7 It's quite simple in practice.",
            "Of course you may want to use some more sophisticated measures like mutual information of the subject and objects, for instance like modified by the frequency of predicates, but it doesn't matter for the purposes of this example.",
            "Now when you want to analyze the corpora, you can use these different perspectives here.",
            "Here are examples of 2 three different perspectives.",
            "The first 2 perspectives relate to entities.",
            "Representation is basically, you know, no numbers are changed, so is just converting the 10s or the three dimensional tensor into metrics and we can just go through."
        ],
        [
            "First line of the first table there.",
            "This is a representation of the protein domain subject, so you know that that's what the S divided by PO means.",
            "We define.",
            "We analyze the subjects as vectors, where the features are actually the predicate and objects which Co occur with the subject in the corpus.",
            "So for protein domain, which."
        ],
        [
            "Is different, you know if you go one slide back protein domain is different from protein in document one protein domain is type of domain and document one."
        ],
        [
            "Document four with different values.",
            "So these two statements actually constitute these non zero values.",
            "1 / 7 for this is abbreviation for the different from protein and 2 / 7 four type of domain.",
            "There are no other statements which which the protein domain would occur in.",
            "So all all the other wall is R0 and exactly in the same way you proceed with the other lines.",
            "The other table is very similar, only you take the perspective of objects so.",
            "Actually, the labels of the rows are the objects as occurring in the corpus and the features are this time predicate and subjects that Coker with these objects, so otherwise, it's pretty much the same, and for the properties again, property names are the labels of the vectors and the features are the subject.",
            "An object that Coker with."
        ],
        [
            "So if you have these, these representations of the different perspective, you can do various types of analysts.",
            "You can try to infer more complex empirically grounded patterns, and one example of a pattern is groups of similar things, like you know implicitly related based based on their context, and you can compute these groups using similarity between corresponding row vectors.",
            "For this similarity you can use well known techniques like cosine similarity of two vectors.",
            "And when you applied this on the example which we had in the previous slide, you will find out that protein, domain and gene in the subject perspective are somehow related.",
            "There is non zero similarity but not exactly similarity one.",
            "This kind of confirms intuition, but like we are not life scientists.",
            "But you know I can disclose here that protein domain is a part of the protein which can be isolated which can evolve independently whereas gene as most of you may know is supportive.",
            "DNA which can be isolated can be studied in an isolated manner and can can evolve independently.",
            "Yet protein domain is part of protein and gene is a part of genome power of the DNA, so they are not exactly the same, but there sure are a lot of similarities.",
            "So you know the intuitive intuition is kind of confirmed by the analysis.",
            "Similarly, you know in the corpus according to the object perspective, juxta membrane and extracellular domains are considered to be equal.",
            "To have similarity one.",
            "This is also like.",
            "Responding to the intuition because Jackson membrane is something that is attached to a cellular membrane whereas extracellular domain is support of a recipe which goes on the outer side of a cellular membrane.",
            "So you know according to the data available, we can decide that these two things are the same.",
            "Of course, like if you had more data in more realistic settings, you would find out that these things are not exactly the same, but still they would be quite similar.",
            "There is no clear pattern among properties though in this little."
        ],
        [
            "Dataset.",
            "The last example is about a topdown layer.",
            "It's about rule based inference on the top of this bottom up statistical or empirical layer.",
            "So how do we do the rule based inference?",
            "It's quite similar to RTI algorithm, for instance, like the matching of possible instances is done by traversing all the possible assignments of instances, two variables which creates kind of trees where you test like the statements occurring in the rule antecedents when you when you fully instantiate.",
            "A path in this tree you can use fuzzy conjunction to determine a degree of the corresponding consequences.",
            "This is this is usually computed using teeners.",
            "Again like classical representation of conjunction for uncertain values and then closure you achieve a closure when you cannot add anymore new statements by applying the rules on your data set when the data set becomes table.",
            "So just to give an example on on our sample data set, imagine 2 rules which are actually.",
            "These are these are two rules from our DFS entailment rules.",
            "The first rule rule one expresses the transitivity of subclass of relationship and the other rule tells you that if.",
            "A class is a subclass of a more general class, and you have a type of the more specific class.",
            "Then this is also a type of the more general class.",
            "When you add some more statements just to add the subclass of relationship and when you take the type relationship which we saw before, as already have type relationship, you can apply the rules on on on the sample corpus as follows, like in the first iteration you will find out that the domain is also a subclass of building block because of the subclass of transitivity rule.",
            "And you just pick the lowest lowest value, like when he used minimum T norm, you just keep the lowest value of all the values that occur in the conjunction.",
            "This is kind of like intuitively.",
            "Conforming to the intuition of conjunction, so you always pick like the minimal, the minimal value of all the possible ones.",
            "If you have the crisp case, you know when you have a bunch of ones, an AN-10.",
            "The result is 0 like as with the natural crisp conjunction the the other line in the iteration.",
            "One is a result of application of Rule 2, so you just assert that protein domain is a type of molecule structure as well, because molecular structure as a subclass.",
            "Sorry, domain is A is a subclass of molecular structure and when you apply the rules once more on the extended data set, you just add one more statement that protein domain is a type of building block which uses like before.",
            "It used the subclass of transitivity and now it uses the second rule and after that there is no other thing to add.",
            "So so you have a closure of the day."
        ],
        [
            "Just said so.",
            "This was like basically illustrating Cody Approach works again as I said, like the more technical details are provided in the paper or I'm happy to explain them offline later on."
        ],
        [
            "If you prefer that way, let's go to the evaluation.",
            "The data we used for the evaluation was coming from the linked open data set link on open Cloud.",
            "We took four for resources from the linked Open data cloud related to pharmacology and diseases.",
            "These are DailyMed disease home, Truck bank, and cider.",
            "We basically analyzed four different datasets in the evaluation.",
            "First of all, we distinguish between RDF just taken from the linked data.",
            "And then we also extracted some additional RDF resources from textual literal objects in those linked datasets.",
            "Like, you know there are properties like drug, description or adverse effects which which have object.",
            "Basically an excerpt of text from Encyclopedia.",
            "So you can use that to get additional information about the data set.",
            "So we use some simple natural language processing pipeline to extract some RDF statements from these textual descriptions which are available in these linked datasets.",
            "The other the other dimension like we used for distinguishing between between data we used also the part of the original datasets like the RDF datasets we used also their flat and versions.",
            "We were curious what happens if you disregard all the properties.",
            "If you just instead of all the specific properties in the datasets you take this generic link, just you know subjects and objects Co occurring together with no information whatsoever about the actual relationship between them.",
            "We were curious what happens after that and something curious.",
            "Happened indeed, as you will see later, the method for evaluation was that we computed groups of related entities and properties using exactly the same method I described in the example before we compared the results against the random randomly computed groups as a baseline and for the entity group evaluation we use the gold standard.",
            "There is a medical subject headings mesh, Caesars, which is a very big resource covering life Sciences in general.",
            "It's basically hierarchy of taxonomy of terms.",
            "Used in life Sciences, we define some kind of edge based distance between between entries in the mesh Caesars and then we use this distance as a measure of quality of the cluster.",
            "So essentially the lower the mesh distance between members in a cluster that we computed, the better the group quality because the better it it confirmed it conforms to what humans think about the domain for property was not that easy because there is no such comprehensive gold standard which we could use for the evaluation.",
            "So for the time being.",
            "We just invited two domain experts to life scientists and we did some some manual evaluation.",
            "We were loyal waiting two para meters accuracy.",
            "Basically number of properties that are not noise in a cluster when compared to all the properties that were extracted and adequate.",
            "Still like how many of the properties are actually related to the property that served as a seed for.",
            "For computing of agree."
        ],
        [
            "Of the properties, so let's briefly go through the analysis of the results.",
            "First start with properties.",
            "Good thing was that all the measure terminators were significantly better than in the case of the random baseline.",
            "In All in all the cases for all the different datasets for the linked open data, obviously the accuracy was one because the properties were defined manually.",
            "The other question was best 0.874875 for small groups groups of less than 10 properties grouped together, then it was getting lower, like when we increase the size of the.",
            "Of the groups.",
            "Extract for the extracted data said the accuracy was around half of the things were considered to be correct in the clusters and and slightly less than half of the things was considered to be adequate to the clusters like these numbers are not that impressive.",
            "Like for you, if you wanted to use it for linking things or for displaying the stuff in some industrial strength application.",
            "Probably this is not enough, but it already serves for kind of a nice abstraction.",
            "An reduction of the space of all the extracted properties because in the extracted data there were.",
            "Around 35,000 of different properties, many of them occurring just in one statement, so you know by grouping the properties together, we could actually increase the user experience by offering them properties like you know, user puts one name of the property into a search.",
            "For instance search engine, and then we can offer like additional properties like you might be interested also in this data and this is something the users wouldn't be able to get if we didn't group the things together.",
            "Examples of cluster of groups of properties are like the first cluster.",
            "Secreted and excreted and eliminated in this is related to production or consumption of some substances like hormones in different parts of human body.",
            "The second cluster is apparently related to some kind of origin of stuff in some location, and the third cluster increase increased by diminishes related to changing of quantities.",
            "So this is for the properties like you know it was found interesting.",
            "It was found, you know, applicable by by the domain."
        ],
        [
            "Users, but let's get to the analysis of the entity evaluation results.",
            "I hope you can see it like the green dotted line is the random baseline and the graph basically expresses the dependence of the quality of the clusters on the cluster sizes so.",
            "The other lines are for the four testing datasets.",
            "The red lines are for the extracted data.",
            "The black lines are for the original link data and the full lines are for the data with actual properties and the dashed lines are for the data which were flat and which were just, you know, links no with no specific types.",
            "So the good thing is that for the small clusters up to size of let's say 50, all the datasets, all the testing data.",
            "Perform better than the baseline.",
            "Then for a bigger, bigger clusters, some of them tend to.",
            "You know, it usually goes down or it tends to oscillate around the random baseline.",
            "So like the good thing is that it's better.",
            "It's better than the baseline, but maybe some of you can notice something funny like the flat and the flat and datasets perform much better than the datasets with the actual properties.",
            "Moreover, like the datasets with the actual properties are worse than the extracted data set.",
            "The more noisy data set for for clustering.",
            "And they are also for bigger clusters below the random baseline, which is something really suspicious.",
            "So like one conclusion could be that perhaps the properties are not useful at all, like they don't bring anything to the empirical semantics which might be true in this case, but probably it's not true in millions of other possible use cases, so we were thinking that another possible and more plausible interpretation for that could be that the type of similarity induced by the data is actually different in the cases of the datasets with the properties.",
            "And for today, just without the property, since you know dissimilarity defined on the gold standard is kind of based on the Theodore, so it's kind of like subsumption based similarity, which can be more close to the similarity.",
            "The simple the flat similarity induced by the flatten datasets, so you know the fact that these originally full flight status is performed worse is not necessarily bad, it only may mean that the similarity, the empirical similar to induce by them, is kind of more structure.",
            "And therefore note that conforming to the gold standard similarity we used, so this kind of, you know, triggers a lot of nice, interesting research questions for later."
        ],
        [
            "I will just briefly conclude just one minutes.",
            "OK, yeah.",
            "So what you should remember?",
            "Like, you know, we really need additional layer of disadvantage because the the web semantic is not complete like we're not able to anchor the descriptions on the summary within the reality, which can lead to a lot of possible problems.",
            "So we need to provide some kind of bottom up layer of the semantics before we can claim that semantic web is really assigned that we can do some empirical analysis of the data or.",
            "We can, you know, then be used for kind of more more reality based, more dynamic because like you don't really need to design the resources all the time, the data changes.",
            "You can just apply some techniques for extracting the complex patterns and you can.",
            "You can in much easier way design ontologies in a semi automatic way.",
            "For instance.",
            "Yeah for future work we want to analyze some additional patterns we want to evaluate.",
            "The top down approach as well.",
            "And yeah we want to explore more use cases.",
            "Actually working with some domain users so.",
            "Not just formally evaluating that, but finding out what it can be used for in practical use cases.",
            "OK, that's all.",
            "Thanks yeah, let's think so speakers.",
            "So first of all I am in this field of semantic search.",
            "We're actually.",
            "We always have to argue with the distribution of semantics is or not enough that just taking the word occurrences is there not enough and This is why we would like to making use of more, richer structure, richer semantics in order to improve task.",
            "We will talk about the task later.",
            "We talk about your the evaluation later.",
            "So my question here is.",
            "Now.",
            "D. This more explicit semantics can be considered an additional features and in the evaluation you have this random baseline.",
            "Now if you wouldn't use the structure of the properties, let's say the task is to to find related entities or two.",
            "More specifically, like entity matching, could you consider this that this kind of approach would provide any added value?",
            "Well, I'm not sure if I got you correctly, but you know I never said it.",
            "It distributional semantics is just, you know, one part of the solution and you know this is.",
            "This is very initial result and if you have like more structured background knowledge in the form of an ontology or of a rule set, then of course it can help a lot for defining a better you know better structural similarity.",
            "For instance you can explain how to do how to, how to deal with that with this approach would be.",
            "Just to apply to Rooster computer closure of the data set.",
            "Then create like the distributional representation of debt, which will however already include the more, the more specific, the more refined semantics provided by people like the more more structured background knowledge, more precise background knowledge, and this is something I would like to do in the very near future to see actually how this can contribute, and you know, like.",
            "From the technical point of view, it's really free.",
            "It's very full free, you just you, just, you know, applied it and I would be really curious to see where my point is.",
            "Where is this makes sense if you don't have the structure, the semantics at Aden you could apply this, but in case there is already structured semantics that is represented in this cases are therefore in some ontologies even for the task of finding the topics, finding clusters of similar entities.",
            "Maybe the counter argument is that instead of taking only word.",
            "Convinces or instead of taking word occurrences at all.",
            "You should news the more fine grained structure in order to do any kind of task about what exactly do you mean by the finer grained structure.",
            "And instead of not taking the semantic of the edges into account the labels.",
            "So what the distribution of semantics in this case just say that you have some word that Coco but some other word right now.",
            "It's not really in this case like this is applied already on the link on the link data set, so.",
            "It takes all the statements so it's not operating at the text level, it's operating at the statement level, so we can you include the structural information when you have it in the link.",
            "Datasets like these were just datasets, just RDF taken from the link data cloud.",
            "You don't have the specific semantic of the edge labels, and if you take even longer path into account does not would not be presented right.",
            "It would be represented if you know that you know like.",
            "That some relation is transitive, for instance.",
            "So if you have the rules, you can apply them and then then you have it in the context representation.",
            "So OK, I would like to discuss this maybe later offline, and if you have any further questions.",
            "So I think with Slide 13 he shows some examples of your property clusters.",
            "Maybe it was 12 S 1.",
            "One thing I noticed looking at this is that it seems like they're grouping on the very common words like in an from an, such as learning to what extent theaters visiting on the RDS labels in terms of finding similarities.",
            "And if so, when that some use of TF IDF can help you better group things on the more interesting terms as opposed to these really common ones.",
            "Well, yeah, well, that's of course related to one limitation of the extraction pipeline, which, well, like it was a result of two afternoons of coding.",
            "So it's not really something groundbreaking, so you have, like, you know, these things occurring together like one way.",
            "How to make this more interesting would be to actually take these groups.",
            "These these really simple groups.",
            "And either you know manually, maybe bootstrap it manually, provide labels like with the domain experts to these two.",
            "These two, these properties and which would create some kind of like more general, more more abstract level representation.",
            "And then you could define like more refined semantics of debt and then you would have something really, you know something much more refined which you could use actually to bootstrap.",
            "Maybe you could be would be able to add some more properties into the clusters from EULA coming data.",
            "You could use it for doing some other inferences when this you know more refined properties occur in.",
            "And some other relationship between some.",
            "You know abstract clusters.",
            "So this is all about, you know basic levels.",
            "So I totally agree with you that it would make much more sense to do something more.",
            "You know more complex than just these simple words, but all are already.",
            "Dislike is providing you some kind of more general view on the basic data, so it's like the first step, like the starting point for looking into what we can do more with that, so you don't think something like TF IDF could be used on these words to kind of help.",
            "Do a better job of clustering.",
            "Extra user input.",
            "You could you could use that for reducing.",
            "Maybe some of the you know less.",
            "Well there is.",
            "There is some TF IDF like already.",
            "Already applies like a during the extraction process, so this is already filter out, but fairly we need to play more with the filtering and it might make sense to introduce some ranking methods based on the statements actually.",
            "So when the property is not linking anything interesting, then probably doesn't make sense to bother with that at all, so this could help us well I think."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The talk is not essentially providing an additional layer to disseminate through web semantics.",
                    "label": 0
                },
                {
                    "sent": "A bottom up layer, in addition to what currently is more like topdown salmon.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Six the talk is separated into four main blocks.",
                    "label": 0
                },
                {
                    "sent": "First of all, I will tell you what bothers us and why it should bother you and what are we going to do about that.",
                    "label": 0
                },
                {
                    "sent": "Then, in the solution I just go through the essentials and I tried to explain the technical core of the paper using a couple of simple examples.",
                    "label": 0
                },
                {
                    "sent": "You can find the technical details in the paper here.",
                    "label": 0
                },
                {
                    "sent": "If you are interested in the evaluation, I will show you.",
                    "label": 0
                },
                {
                    "sent": "I will tell you what data we used for the evaluation, what kind of methods did we do?",
                    "label": 0
                },
                {
                    "sent": "Did we apply and what results did we get?",
                    "label": 0
                },
                {
                    "sent": "And conclusion section is just obligatory.",
                    "label": 0
                },
                {
                    "sent": "Summing up of the paper and summary of the few.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Work.",
                    "label": 0
                },
                {
                    "sent": "So what's wrong with the meaning like?",
                    "label": 1
                },
                {
                    "sent": "What, what, what, why should we bother the current semantic web is concerned mainly with expressions which are composed of some basic symbols.",
                    "label": 0
                },
                {
                    "sent": "Your eyes, the meaning of the expressions is quite well researched.",
                    "label": 0
                },
                {
                    "sent": "We we know how to combine your eyes and expressions or just store them in already have stores.",
                    "label": 0
                },
                {
                    "sent": "How to query the stored statements, how to reason with the statements out to visualize the statements.",
                    "label": 1
                },
                {
                    "sent": "But the meaning of the basic symbols is kind of atomic.",
                    "label": 0
                },
                {
                    "sent": "Still like the machines don't really care.",
                    "label": 0
                },
                {
                    "sent": "What do you, what the meaning of your eyes.",
                    "label": 1
                },
                {
                    "sent": "As you could replace the Euros with any arbitrary symbols and the machines would proceed as happily as before, just manipulating the statements composed of these symbols.",
                    "label": 0
                },
                {
                    "sent": "So what does this mean?",
                    "label": 0
                },
                {
                    "sent": "This means essentially that the semantic web is not really linked to reality like there is like a gap between the semantic web expressions and between their possible grounding in the real world, like people maybe are able to link the statements to some entities in the real world, but for the machines there is no no formal link.",
                    "label": 1
                },
                {
                    "sent": "Between the statements to your eyes, in the statements, and the things that these statements are supposed to describe, like I mean the things in the real world.",
                    "label": 0
                },
                {
                    "sent": "And this is plenty of consequences.",
                    "label": 0
                },
                {
                    "sent": "It's very hard to make the semantic Web descriptions accountable like people can describe things in real world, but different people can descrip exactly the same thing in totally different way.",
                    "label": 0
                },
                {
                    "sent": "And there is no formal way how you can tell like you are wrong and you're right.",
                    "label": 0
                },
                {
                    "sent": "Probably no one is wrong.",
                    "label": 0
                },
                {
                    "sent": "No one is right.",
                    "label": 0
                },
                {
                    "sent": "The truth is somewhere in between.",
                    "label": 0
                },
                {
                    "sent": "That's totally fine.",
                    "label": 0
                },
                {
                    "sent": "It's like it works like like it works like that, like when people represent the meaning.",
                    "label": 0
                },
                {
                    "sent": "But in semantic web we would like to have this link.",
                    "label": 0
                },
                {
                    "sent": "We would like to cap be able to capture this link for the machine so that the machines can deal with that so that the machines are really able to anchor their similar descriptions in the real world.",
                    "label": 0
                },
                {
                    "sent": "But real world I should emphasize that I mean like obviously the machines are not able to perceive the real world as we do so by real world like anchoring in reality I mean like the closest approximation of reality that is available to the machines.",
                    "label": 0
                },
                {
                    "sent": "Essentially, the web of data.",
                    "label": 0
                },
                {
                    "sent": "The vast amount of data the machines have at their disposal on the web, or the semantic web.",
                    "label": 0
                },
                {
                    "sent": "And when we will able to, when we will be able to do this, we will be able to do also like more empirical analysis of the semantic web data.",
                    "label": 0
                },
                {
                    "sent": "This is kind of related to the invited talk which all of you heard in the morning of Franklin Harmelin.",
                    "label": 0
                },
                {
                    "sent": "He was concerned about making the semantic web more signs like more more theorie.",
                    "label": 0
                },
                {
                    "sent": "This is this is kind of fitting into this vision because if you're able to empirically prove that some semantic web descriptions.",
                    "label": 1
                },
                {
                    "sent": "Actually describe something.",
                    "label": 0
                },
                {
                    "sent": "Then you're one step closer to real science.",
                    "label": 0
                },
                {
                    "sent": "You have a hypothesis which in our case is semantic Web description.",
                    "label": 0
                },
                {
                    "sent": "Semantic web already have resource or whatever else, or an ontology.",
                    "label": 0
                },
                {
                    "sent": "And then you empirically prove if you have the link between the expressions and the reality that your description actually really describes something that your hypothesis about the describing the world is valid.",
                    "label": 1
                },
                {
                    "sent": "So that's what we would like to do with this approach.",
                    "label": 0
                },
                {
                    "sent": "And how are we going to do that?",
                    "label": 0
                },
                {
                    "sent": "Well, simply by adding a bottom up layer to the web semantics.",
                    "label": 0
                },
                {
                    "sent": "That means that we slightly change the perspective.",
                    "label": 0
                },
                {
                    "sent": "We look at.",
                    "label": 0
                },
                {
                    "sent": "Semantic web is not something that is supposed to assert the meanings that do things, but we look at the semantic web as something that is able to infer the meaning of things from the data we have on the web.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is the outline of the solution of the main contribution of the paper.",
                    "label": 0
                },
                {
                    "sent": "Adding the bottom up layer.",
                    "label": 0
                },
                {
                    "sent": "This is based on distributional semantics distribution.",
                    "label": 0
                },
                {
                    "sent": "Semantics is an approach from computational linguistics which studies meaning of words as a function of their meaning in large natural language corpora.",
                    "label": 0
                },
                {
                    "sent": "So we take this inspiration.",
                    "label": 0
                },
                {
                    "sent": "This has been proven to work like since over decades ago.",
                    "label": 0
                },
                {
                    "sent": "It's used in information retrieval in many commercially successful applications, so it's really proven to work.",
                    "label": 0
                },
                {
                    "sent": "It's based on simple representation.",
                    "label": 0
                },
                {
                    "sent": "A lot of really well founded mathematical methods based on linear algebra, statistical data analysts, so there is a lot of Arsenal theoretical original we can directly apply, so it's all just about changing the perspective to changing our view on how to look at the semantic Web data and how to analyze them so we can see the meaning of your eyes based on some corcorans analytics we we define the meaning as patterns that the symbols that your eyes can occur in by patterns like we mean for example, groups of related.",
                    "label": 0
                },
                {
                    "sent": "Entities related you rise of entities or properties, or some rules.",
                    "label": 1
                },
                {
                    "sent": "Some emergent emergently extracted rules and analogies that provide some.",
                    "label": 1
                },
                {
                    "sent": "You know more specific specification of particular you Rice top this is this is this bottom up later.",
                    "label": 0
                },
                {
                    "sent": "This is kind of an you think like curtain you view on the semantic web, but we still have to be able to combine this with the top down layer with the bunch of the extant ontologies, which can very often be converted to rules.",
                    "label": 0
                },
                {
                    "sent": "Then we can do some rule based reasoning.",
                    "label": 0
                },
                {
                    "sent": "You know this is all like.",
                    "label": 0
                },
                {
                    "sent": "There are well known techniques for that, but the contribution of this approach is in combination of this top down techniques.",
                    "label": 0
                },
                {
                    "sent": "With something that has been anchored into reality, using this bottom, a player that has been empirically grounded in the reality and then, like the symbolic reasoning, is not meaningless anymore.",
                    "label": 1
                },
                {
                    "sent": "It operates with well grounded meaning of the your eyes.",
                    "label": 0
                },
                {
                    "sent": "In the paper.",
                    "label": 0
                },
                {
                    "sent": "We also show we've also shown promising promise of the approach by applying these principles to consolidation of entities and properties, grouping them into related groups, and we evaluated this in a using Bio Med.",
                    "label": 1
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Pulling data.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let's move on to the solution.",
                    "label": 0
                },
                {
                    "sent": "The essential notions regarding the representation are tensors, like everything is organized in as labeled tensors in the representation, tenders, or just generalization of the notion of vector metric, source colors color as just a number as a tensor with zero dimensionality.",
                    "label": 0
                },
                {
                    "sent": "Vector is a tensor of dimension one.",
                    "label": 0
                },
                {
                    "sent": "Just one line of numbers, metrics Field 2 dimensional field of numbers.",
                    "label": 0
                },
                {
                    "sent": "So that's a dynamic 3 dimensional tensor at cetera, etc.",
                    "label": 0
                },
                {
                    "sent": "So we have three layers of representation.",
                    "label": 0
                },
                {
                    "sent": "First of all, we have source.",
                    "label": 0
                },
                {
                    "sent": "These are just RDF graph, so RDF statements with their provenance represented as a four dimensional tensor.",
                    "label": 0
                },
                {
                    "sent": "You'll see it in the example in a little while, then additional level is corpus is a 3 dimensional tensor which is sort of more compact, more comprehensive view on the resources and just groups together all the statements possibly occurring multiple resources computes sum, sum.",
                    "label": 0
                },
                {
                    "sent": "Additional values and creates a kind of comprehensive view of the sources.",
                    "label": 0
                },
                {
                    "sent": "Perspectives are then 2 dimensional matrices which are essentially still the corpus tensors only, represented in a slightly different way and converted to a metrics which then provides us with vector spaces.",
                    "label": 0
                },
                {
                    "sent": "We can we can analyze later on the computation requires some statistiques when you want to compute this comprehensive view on the sources in the form of tenzer corpus tensor.",
                    "label": 0
                },
                {
                    "sent": "Tensar Metra station.",
                    "label": 0
                },
                {
                    "sent": "Converting higher dimensional tensors into 2 dimensional matrices.",
                    "label": 0
                },
                {
                    "sent": "Linear algebra methods for analyzing of the metrics perspectives of the corpus and then a little bit of growth, era fuzzy logics and fixed point mathematics for evaluating the rule.",
                    "label": 1
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This.",
                    "label": 0
                },
                {
                    "sent": "This is an example of source and corpus representation.",
                    "label": 1
                },
                {
                    "sent": "Like I I wrote down that answers to a more convenient tabular notation is because it's kind of tricky to display 4 dimensional tensors, for instance, so the rightmost column always contains, like numerical values.",
                    "label": 0
                },
                {
                    "sent": "These are the elements of the tensors, whereas all the other columns represent the indices.",
                    "label": 0
                },
                {
                    "sent": "The labeled indices of the tensor.",
                    "label": 1
                },
                {
                    "sent": "So when you take the first line and the source representation, that's a statement like protein domain is the subject.",
                    "label": 0
                },
                {
                    "sent": "Different is the predicate protein as the object and the one is an identifier of a document.",
                    "label": 0
                },
                {
                    "sent": "This statement occurs in and the value of that is the frequency of the statement occurrence in the particular document.",
                    "label": 0
                },
                {
                    "sent": "It's one for all the statements, then from this source tenzer, you just create a comprehensive corpus representation as follows, like here.",
                    "label": 0
                },
                {
                    "sent": "Use relative frequencies of the statements in the full source.",
                    "label": 1
                },
                {
                    "sent": "So for all the statements is 1 / 7 because there is like 7 statements.",
                    "label": 0
                },
                {
                    "sent": "In total only for one statement for protein domain is a type of domain which occurs in two sources.",
                    "label": 0
                },
                {
                    "sent": "In D1, the first line, sorry, the second line and E4 the last line.",
                    "label": 0
                },
                {
                    "sent": "So it occurs in two documents or relative frequencies 2 /.",
                    "label": 0
                },
                {
                    "sent": "7 It's quite simple in practice.",
                    "label": 0
                },
                {
                    "sent": "Of course you may want to use some more sophisticated measures like mutual information of the subject and objects, for instance like modified by the frequency of predicates, but it doesn't matter for the purposes of this example.",
                    "label": 0
                },
                {
                    "sent": "Now when you want to analyze the corpora, you can use these different perspectives here.",
                    "label": 0
                },
                {
                    "sent": "Here are examples of 2 three different perspectives.",
                    "label": 0
                },
                {
                    "sent": "The first 2 perspectives relate to entities.",
                    "label": 0
                },
                {
                    "sent": "Representation is basically, you know, no numbers are changed, so is just converting the 10s or the three dimensional tensor into metrics and we can just go through.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "First line of the first table there.",
                    "label": 0
                },
                {
                    "sent": "This is a representation of the protein domain subject, so you know that that's what the S divided by PO means.",
                    "label": 0
                },
                {
                    "sent": "We define.",
                    "label": 0
                },
                {
                    "sent": "We analyze the subjects as vectors, where the features are actually the predicate and objects which Co occur with the subject in the corpus.",
                    "label": 0
                },
                {
                    "sent": "So for protein domain, which.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is different, you know if you go one slide back protein domain is different from protein in document one protein domain is type of domain and document one.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Document four with different values.",
                    "label": 0
                },
                {
                    "sent": "So these two statements actually constitute these non zero values.",
                    "label": 0
                },
                {
                    "sent": "1 / 7 for this is abbreviation for the different from protein and 2 / 7 four type of domain.",
                    "label": 0
                },
                {
                    "sent": "There are no other statements which which the protein domain would occur in.",
                    "label": 0
                },
                {
                    "sent": "So all all the other wall is R0 and exactly in the same way you proceed with the other lines.",
                    "label": 0
                },
                {
                    "sent": "The other table is very similar, only you take the perspective of objects so.",
                    "label": 0
                },
                {
                    "sent": "Actually, the labels of the rows are the objects as occurring in the corpus and the features are this time predicate and subjects that Coker with these objects, so otherwise, it's pretty much the same, and for the properties again, property names are the labels of the vectors and the features are the subject.",
                    "label": 0
                },
                {
                    "sent": "An object that Coker with.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So if you have these, these representations of the different perspective, you can do various types of analysts.",
                    "label": 0
                },
                {
                    "sent": "You can try to infer more complex empirically grounded patterns, and one example of a pattern is groups of similar things, like you know implicitly related based based on their context, and you can compute these groups using similarity between corresponding row vectors.",
                    "label": 1
                },
                {
                    "sent": "For this similarity you can use well known techniques like cosine similarity of two vectors.",
                    "label": 0
                },
                {
                    "sent": "And when you applied this on the example which we had in the previous slide, you will find out that protein, domain and gene in the subject perspective are somehow related.",
                    "label": 0
                },
                {
                    "sent": "There is non zero similarity but not exactly similarity one.",
                    "label": 0
                },
                {
                    "sent": "This kind of confirms intuition, but like we are not life scientists.",
                    "label": 0
                },
                {
                    "sent": "But you know I can disclose here that protein domain is a part of the protein which can be isolated which can evolve independently whereas gene as most of you may know is supportive.",
                    "label": 0
                },
                {
                    "sent": "DNA which can be isolated can be studied in an isolated manner and can can evolve independently.",
                    "label": 0
                },
                {
                    "sent": "Yet protein domain is part of protein and gene is a part of genome power of the DNA, so they are not exactly the same, but there sure are a lot of similarities.",
                    "label": 0
                },
                {
                    "sent": "So you know the intuitive intuition is kind of confirmed by the analysis.",
                    "label": 0
                },
                {
                    "sent": "Similarly, you know in the corpus according to the object perspective, juxta membrane and extracellular domains are considered to be equal.",
                    "label": 0
                },
                {
                    "sent": "To have similarity one.",
                    "label": 0
                },
                {
                    "sent": "This is also like.",
                    "label": 0
                },
                {
                    "sent": "Responding to the intuition because Jackson membrane is something that is attached to a cellular membrane whereas extracellular domain is support of a recipe which goes on the outer side of a cellular membrane.",
                    "label": 0
                },
                {
                    "sent": "So you know according to the data available, we can decide that these two things are the same.",
                    "label": 0
                },
                {
                    "sent": "Of course, like if you had more data in more realistic settings, you would find out that these things are not exactly the same, but still they would be quite similar.",
                    "label": 1
                },
                {
                    "sent": "There is no clear pattern among properties though in this little.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Dataset.",
                    "label": 0
                },
                {
                    "sent": "The last example is about a topdown layer.",
                    "label": 0
                },
                {
                    "sent": "It's about rule based inference on the top of this bottom up statistical or empirical layer.",
                    "label": 0
                },
                {
                    "sent": "So how do we do the rule based inference?",
                    "label": 0
                },
                {
                    "sent": "It's quite similar to RTI algorithm, for instance, like the matching of possible instances is done by traversing all the possible assignments of instances, two variables which creates kind of trees where you test like the statements occurring in the rule antecedents when you when you fully instantiate.",
                    "label": 0
                },
                {
                    "sent": "A path in this tree you can use fuzzy conjunction to determine a degree of the corresponding consequences.",
                    "label": 1
                },
                {
                    "sent": "This is this is usually computed using teeners.",
                    "label": 0
                },
                {
                    "sent": "Again like classical representation of conjunction for uncertain values and then closure you achieve a closure when you cannot add anymore new statements by applying the rules on your data set when the data set becomes table.",
                    "label": 0
                },
                {
                    "sent": "So just to give an example on on our sample data set, imagine 2 rules which are actually.",
                    "label": 0
                },
                {
                    "sent": "These are these are two rules from our DFS entailment rules.",
                    "label": 0
                },
                {
                    "sent": "The first rule rule one expresses the transitivity of subclass of relationship and the other rule tells you that if.",
                    "label": 0
                },
                {
                    "sent": "A class is a subclass of a more general class, and you have a type of the more specific class.",
                    "label": 0
                },
                {
                    "sent": "Then this is also a type of the more general class.",
                    "label": 0
                },
                {
                    "sent": "When you add some more statements just to add the subclass of relationship and when you take the type relationship which we saw before, as already have type relationship, you can apply the rules on on on the sample corpus as follows, like in the first iteration you will find out that the domain is also a subclass of building block because of the subclass of transitivity rule.",
                    "label": 0
                },
                {
                    "sent": "And you just pick the lowest lowest value, like when he used minimum T norm, you just keep the lowest value of all the values that occur in the conjunction.",
                    "label": 0
                },
                {
                    "sent": "This is kind of like intuitively.",
                    "label": 0
                },
                {
                    "sent": "Conforming to the intuition of conjunction, so you always pick like the minimal, the minimal value of all the possible ones.",
                    "label": 0
                },
                {
                    "sent": "If you have the crisp case, you know when you have a bunch of ones, an AN-10.",
                    "label": 0
                },
                {
                    "sent": "The result is 0 like as with the natural crisp conjunction the the other line in the iteration.",
                    "label": 0
                },
                {
                    "sent": "One is a result of application of Rule 2, so you just assert that protein domain is a type of molecule structure as well, because molecular structure as a subclass.",
                    "label": 1
                },
                {
                    "sent": "Sorry, domain is A is a subclass of molecular structure and when you apply the rules once more on the extended data set, you just add one more statement that protein domain is a type of building block which uses like before.",
                    "label": 1
                },
                {
                    "sent": "It used the subclass of transitivity and now it uses the second rule and after that there is no other thing to add.",
                    "label": 0
                },
                {
                    "sent": "So so you have a closure of the day.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just said so.",
                    "label": 0
                },
                {
                    "sent": "This was like basically illustrating Cody Approach works again as I said, like the more technical details are provided in the paper or I'm happy to explain them offline later on.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If you prefer that way, let's go to the evaluation.",
                    "label": 0
                },
                {
                    "sent": "The data we used for the evaluation was coming from the linked open data set link on open Cloud.",
                    "label": 0
                },
                {
                    "sent": "We took four for resources from the linked Open data cloud related to pharmacology and diseases.",
                    "label": 0
                },
                {
                    "sent": "These are DailyMed disease home, Truck bank, and cider.",
                    "label": 0
                },
                {
                    "sent": "We basically analyzed four different datasets in the evaluation.",
                    "label": 0
                },
                {
                    "sent": "First of all, we distinguish between RDF just taken from the linked data.",
                    "label": 0
                },
                {
                    "sent": "And then we also extracted some additional RDF resources from textual literal objects in those linked datasets.",
                    "label": 0
                },
                {
                    "sent": "Like, you know there are properties like drug, description or adverse effects which which have object.",
                    "label": 0
                },
                {
                    "sent": "Basically an excerpt of text from Encyclopedia.",
                    "label": 0
                },
                {
                    "sent": "So you can use that to get additional information about the data set.",
                    "label": 0
                },
                {
                    "sent": "So we use some simple natural language processing pipeline to extract some RDF statements from these textual descriptions which are available in these linked datasets.",
                    "label": 0
                },
                {
                    "sent": "The other the other dimension like we used for distinguishing between between data we used also the part of the original datasets like the RDF datasets we used also their flat and versions.",
                    "label": 0
                },
                {
                    "sent": "We were curious what happens if you disregard all the properties.",
                    "label": 0
                },
                {
                    "sent": "If you just instead of all the specific properties in the datasets you take this generic link, just you know subjects and objects Co occurring together with no information whatsoever about the actual relationship between them.",
                    "label": 0
                },
                {
                    "sent": "We were curious what happens after that and something curious.",
                    "label": 0
                },
                {
                    "sent": "Happened indeed, as you will see later, the method for evaluation was that we computed groups of related entities and properties using exactly the same method I described in the example before we compared the results against the random randomly computed groups as a baseline and for the entity group evaluation we use the gold standard.",
                    "label": 1
                },
                {
                    "sent": "There is a medical subject headings mesh, Caesars, which is a very big resource covering life Sciences in general.",
                    "label": 0
                },
                {
                    "sent": "It's basically hierarchy of taxonomy of terms.",
                    "label": 0
                },
                {
                    "sent": "Used in life Sciences, we define some kind of edge based distance between between entries in the mesh Caesars and then we use this distance as a measure of quality of the cluster.",
                    "label": 1
                },
                {
                    "sent": "So essentially the lower the mesh distance between members in a cluster that we computed, the better the group quality because the better it it confirmed it conforms to what humans think about the domain for property was not that easy because there is no such comprehensive gold standard which we could use for the evaluation.",
                    "label": 1
                },
                {
                    "sent": "So for the time being.",
                    "label": 0
                },
                {
                    "sent": "We just invited two domain experts to life scientists and we did some some manual evaluation.",
                    "label": 1
                },
                {
                    "sent": "We were loyal waiting two para meters accuracy.",
                    "label": 0
                },
                {
                    "sent": "Basically number of properties that are not noise in a cluster when compared to all the properties that were extracted and adequate.",
                    "label": 0
                },
                {
                    "sent": "Still like how many of the properties are actually related to the property that served as a seed for.",
                    "label": 0
                },
                {
                    "sent": "For computing of agree.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Of the properties, so let's briefly go through the analysis of the results.",
                    "label": 0
                },
                {
                    "sent": "First start with properties.",
                    "label": 0
                },
                {
                    "sent": "Good thing was that all the measure terminators were significantly better than in the case of the random baseline.",
                    "label": 1
                },
                {
                    "sent": "In All in all the cases for all the different datasets for the linked open data, obviously the accuracy was one because the properties were defined manually.",
                    "label": 0
                },
                {
                    "sent": "The other question was best 0.874875 for small groups groups of less than 10 properties grouped together, then it was getting lower, like when we increase the size of the.",
                    "label": 0
                },
                {
                    "sent": "Of the groups.",
                    "label": 0
                },
                {
                    "sent": "Extract for the extracted data said the accuracy was around half of the things were considered to be correct in the clusters and and slightly less than half of the things was considered to be adequate to the clusters like these numbers are not that impressive.",
                    "label": 0
                },
                {
                    "sent": "Like for you, if you wanted to use it for linking things or for displaying the stuff in some industrial strength application.",
                    "label": 0
                },
                {
                    "sent": "Probably this is not enough, but it already serves for kind of a nice abstraction.",
                    "label": 0
                },
                {
                    "sent": "An reduction of the space of all the extracted properties because in the extracted data there were.",
                    "label": 1
                },
                {
                    "sent": "Around 35,000 of different properties, many of them occurring just in one statement, so you know by grouping the properties together, we could actually increase the user experience by offering them properties like you know, user puts one name of the property into a search.",
                    "label": 0
                },
                {
                    "sent": "For instance search engine, and then we can offer like additional properties like you might be interested also in this data and this is something the users wouldn't be able to get if we didn't group the things together.",
                    "label": 0
                },
                {
                    "sent": "Examples of cluster of groups of properties are like the first cluster.",
                    "label": 0
                },
                {
                    "sent": "Secreted and excreted and eliminated in this is related to production or consumption of some substances like hormones in different parts of human body.",
                    "label": 0
                },
                {
                    "sent": "The second cluster is apparently related to some kind of origin of stuff in some location, and the third cluster increase increased by diminishes related to changing of quantities.",
                    "label": 0
                },
                {
                    "sent": "So this is for the properties like you know it was found interesting.",
                    "label": 0
                },
                {
                    "sent": "It was found, you know, applicable by by the domain.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Users, but let's get to the analysis of the entity evaluation results.",
                    "label": 0
                },
                {
                    "sent": "I hope you can see it like the green dotted line is the random baseline and the graph basically expresses the dependence of the quality of the clusters on the cluster sizes so.",
                    "label": 0
                },
                {
                    "sent": "The other lines are for the four testing datasets.",
                    "label": 0
                },
                {
                    "sent": "The red lines are for the extracted data.",
                    "label": 0
                },
                {
                    "sent": "The black lines are for the original link data and the full lines are for the data with actual properties and the dashed lines are for the data which were flat and which were just, you know, links no with no specific types.",
                    "label": 0
                },
                {
                    "sent": "So the good thing is that for the small clusters up to size of let's say 50, all the datasets, all the testing data.",
                    "label": 0
                },
                {
                    "sent": "Perform better than the baseline.",
                    "label": 0
                },
                {
                    "sent": "Then for a bigger, bigger clusters, some of them tend to.",
                    "label": 0
                },
                {
                    "sent": "You know, it usually goes down or it tends to oscillate around the random baseline.",
                    "label": 0
                },
                {
                    "sent": "So like the good thing is that it's better.",
                    "label": 0
                },
                {
                    "sent": "It's better than the baseline, but maybe some of you can notice something funny like the flat and the flat and datasets perform much better than the datasets with the actual properties.",
                    "label": 0
                },
                {
                    "sent": "Moreover, like the datasets with the actual properties are worse than the extracted data set.",
                    "label": 0
                },
                {
                    "sent": "The more noisy data set for for clustering.",
                    "label": 0
                },
                {
                    "sent": "And they are also for bigger clusters below the random baseline, which is something really suspicious.",
                    "label": 0
                },
                {
                    "sent": "So like one conclusion could be that perhaps the properties are not useful at all, like they don't bring anything to the empirical semantics which might be true in this case, but probably it's not true in millions of other possible use cases, so we were thinking that another possible and more plausible interpretation for that could be that the type of similarity induced by the data is actually different in the cases of the datasets with the properties.",
                    "label": 0
                },
                {
                    "sent": "And for today, just without the property, since you know dissimilarity defined on the gold standard is kind of based on the Theodore, so it's kind of like subsumption based similarity, which can be more close to the similarity.",
                    "label": 0
                },
                {
                    "sent": "The simple the flat similarity induced by the flatten datasets, so you know the fact that these originally full flight status is performed worse is not necessarily bad, it only may mean that the similarity, the empirical similar to induce by them, is kind of more structure.",
                    "label": 0
                },
                {
                    "sent": "And therefore note that conforming to the gold standard similarity we used, so this kind of, you know, triggers a lot of nice, interesting research questions for later.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I will just briefly conclude just one minutes.",
                    "label": 0
                },
                {
                    "sent": "OK, yeah.",
                    "label": 0
                },
                {
                    "sent": "So what you should remember?",
                    "label": 0
                },
                {
                    "sent": "Like, you know, we really need additional layer of disadvantage because the the web semantic is not complete like we're not able to anchor the descriptions on the summary within the reality, which can lead to a lot of possible problems.",
                    "label": 0
                },
                {
                    "sent": "So we need to provide some kind of bottom up layer of the semantics before we can claim that semantic web is really assigned that we can do some empirical analysis of the data or.",
                    "label": 0
                },
                {
                    "sent": "We can, you know, then be used for kind of more more reality based, more dynamic because like you don't really need to design the resources all the time, the data changes.",
                    "label": 0
                },
                {
                    "sent": "You can just apply some techniques for extracting the complex patterns and you can.",
                    "label": 0
                },
                {
                    "sent": "You can in much easier way design ontologies in a semi automatic way.",
                    "label": 0
                },
                {
                    "sent": "For instance.",
                    "label": 0
                },
                {
                    "sent": "Yeah for future work we want to analyze some additional patterns we want to evaluate.",
                    "label": 0
                },
                {
                    "sent": "The top down approach as well.",
                    "label": 0
                },
                {
                    "sent": "And yeah we want to explore more use cases.",
                    "label": 0
                },
                {
                    "sent": "Actually working with some domain users so.",
                    "label": 0
                },
                {
                    "sent": "Not just formally evaluating that, but finding out what it can be used for in practical use cases.",
                    "label": 0
                },
                {
                    "sent": "OK, that's all.",
                    "label": 0
                },
                {
                    "sent": "Thanks yeah, let's think so speakers.",
                    "label": 0
                },
                {
                    "sent": "So first of all I am in this field of semantic search.",
                    "label": 0
                },
                {
                    "sent": "We're actually.",
                    "label": 0
                },
                {
                    "sent": "We always have to argue with the distribution of semantics is or not enough that just taking the word occurrences is there not enough and This is why we would like to making use of more, richer structure, richer semantics in order to improve task.",
                    "label": 0
                },
                {
                    "sent": "We will talk about the task later.",
                    "label": 0
                },
                {
                    "sent": "We talk about your the evaluation later.",
                    "label": 0
                },
                {
                    "sent": "So my question here is.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "D. This more explicit semantics can be considered an additional features and in the evaluation you have this random baseline.",
                    "label": 0
                },
                {
                    "sent": "Now if you wouldn't use the structure of the properties, let's say the task is to to find related entities or two.",
                    "label": 0
                },
                {
                    "sent": "More specifically, like entity matching, could you consider this that this kind of approach would provide any added value?",
                    "label": 0
                },
                {
                    "sent": "Well, I'm not sure if I got you correctly, but you know I never said it.",
                    "label": 0
                },
                {
                    "sent": "It distributional semantics is just, you know, one part of the solution and you know this is.",
                    "label": 0
                },
                {
                    "sent": "This is very initial result and if you have like more structured background knowledge in the form of an ontology or of a rule set, then of course it can help a lot for defining a better you know better structural similarity.",
                    "label": 0
                },
                {
                    "sent": "For instance you can explain how to do how to, how to deal with that with this approach would be.",
                    "label": 0
                },
                {
                    "sent": "Just to apply to Rooster computer closure of the data set.",
                    "label": 0
                },
                {
                    "sent": "Then create like the distributional representation of debt, which will however already include the more, the more specific, the more refined semantics provided by people like the more more structured background knowledge, more precise background knowledge, and this is something I would like to do in the very near future to see actually how this can contribute, and you know, like.",
                    "label": 0
                },
                {
                    "sent": "From the technical point of view, it's really free.",
                    "label": 0
                },
                {
                    "sent": "It's very full free, you just you, just, you know, applied it and I would be really curious to see where my point is.",
                    "label": 0
                },
                {
                    "sent": "Where is this makes sense if you don't have the structure, the semantics at Aden you could apply this, but in case there is already structured semantics that is represented in this cases are therefore in some ontologies even for the task of finding the topics, finding clusters of similar entities.",
                    "label": 0
                },
                {
                    "sent": "Maybe the counter argument is that instead of taking only word.",
                    "label": 0
                },
                {
                    "sent": "Convinces or instead of taking word occurrences at all.",
                    "label": 0
                },
                {
                    "sent": "You should news the more fine grained structure in order to do any kind of task about what exactly do you mean by the finer grained structure.",
                    "label": 0
                },
                {
                    "sent": "And instead of not taking the semantic of the edges into account the labels.",
                    "label": 0
                },
                {
                    "sent": "So what the distribution of semantics in this case just say that you have some word that Coco but some other word right now.",
                    "label": 0
                },
                {
                    "sent": "It's not really in this case like this is applied already on the link on the link data set, so.",
                    "label": 0
                },
                {
                    "sent": "It takes all the statements so it's not operating at the text level, it's operating at the statement level, so we can you include the structural information when you have it in the link.",
                    "label": 0
                },
                {
                    "sent": "Datasets like these were just datasets, just RDF taken from the link data cloud.",
                    "label": 0
                },
                {
                    "sent": "You don't have the specific semantic of the edge labels, and if you take even longer path into account does not would not be presented right.",
                    "label": 0
                },
                {
                    "sent": "It would be represented if you know that you know like.",
                    "label": 0
                },
                {
                    "sent": "That some relation is transitive, for instance.",
                    "label": 0
                },
                {
                    "sent": "So if you have the rules, you can apply them and then then you have it in the context representation.",
                    "label": 0
                },
                {
                    "sent": "So OK, I would like to discuss this maybe later offline, and if you have any further questions.",
                    "label": 0
                },
                {
                    "sent": "So I think with Slide 13 he shows some examples of your property clusters.",
                    "label": 0
                },
                {
                    "sent": "Maybe it was 12 S 1.",
                    "label": 0
                },
                {
                    "sent": "One thing I noticed looking at this is that it seems like they're grouping on the very common words like in an from an, such as learning to what extent theaters visiting on the RDS labels in terms of finding similarities.",
                    "label": 0
                },
                {
                    "sent": "And if so, when that some use of TF IDF can help you better group things on the more interesting terms as opposed to these really common ones.",
                    "label": 0
                },
                {
                    "sent": "Well, yeah, well, that's of course related to one limitation of the extraction pipeline, which, well, like it was a result of two afternoons of coding.",
                    "label": 0
                },
                {
                    "sent": "So it's not really something groundbreaking, so you have, like, you know, these things occurring together like one way.",
                    "label": 0
                },
                {
                    "sent": "How to make this more interesting would be to actually take these groups.",
                    "label": 0
                },
                {
                    "sent": "These these really simple groups.",
                    "label": 0
                },
                {
                    "sent": "And either you know manually, maybe bootstrap it manually, provide labels like with the domain experts to these two.",
                    "label": 0
                },
                {
                    "sent": "These two, these properties and which would create some kind of like more general, more more abstract level representation.",
                    "label": 0
                },
                {
                    "sent": "And then you could define like more refined semantics of debt and then you would have something really, you know something much more refined which you could use actually to bootstrap.",
                    "label": 0
                },
                {
                    "sent": "Maybe you could be would be able to add some more properties into the clusters from EULA coming data.",
                    "label": 0
                },
                {
                    "sent": "You could use it for doing some other inferences when this you know more refined properties occur in.",
                    "label": 0
                },
                {
                    "sent": "And some other relationship between some.",
                    "label": 0
                },
                {
                    "sent": "You know abstract clusters.",
                    "label": 0
                },
                {
                    "sent": "So this is all about, you know basic levels.",
                    "label": 0
                },
                {
                    "sent": "So I totally agree with you that it would make much more sense to do something more.",
                    "label": 0
                },
                {
                    "sent": "You know more complex than just these simple words, but all are already.",
                    "label": 0
                },
                {
                    "sent": "Dislike is providing you some kind of more general view on the basic data, so it's like the first step, like the starting point for looking into what we can do more with that, so you don't think something like TF IDF could be used on these words to kind of help.",
                    "label": 0
                },
                {
                    "sent": "Do a better job of clustering.",
                    "label": 0
                },
                {
                    "sent": "Extra user input.",
                    "label": 0
                },
                {
                    "sent": "You could you could use that for reducing.",
                    "label": 0
                },
                {
                    "sent": "Maybe some of the you know less.",
                    "label": 0
                },
                {
                    "sent": "Well there is.",
                    "label": 0
                },
                {
                    "sent": "There is some TF IDF like already.",
                    "label": 0
                },
                {
                    "sent": "Already applies like a during the extraction process, so this is already filter out, but fairly we need to play more with the filtering and it might make sense to introduce some ranking methods based on the statements actually.",
                    "label": 0
                },
                {
                    "sent": "So when the property is not linking anything interesting, then probably doesn't make sense to bother with that at all, so this could help us well I think.",
                    "label": 0
                }
            ]
        }
    }
}