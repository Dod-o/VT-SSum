{
    "id": "kdopiubxzil2wubghqnpk54e72vl3deo",
    "title": "Large-Scale Graph Mining Using Backbone Refinement Classes",
    "info": {
        "author": [
            "Andreas Maunz, Institute for Computer Science, University of Freiburg"
        ],
        "published": "Sept. 14, 2009",
        "recorded": "June 2009",
        "category": [
            "Top->Computer Science->Data Mining->Graph Mining"
        ]
    },
    "url": "http://videolectures.net/kdd09_maunz_lsgmubrc/",
    "segmentation": [
        [
            "Thank you, my name is Andreas mounts from Freiburg University and this is a joint work with Crystal, Thelma and Steven, from Munich.",
            "The approach I'm going to present is concerned with mining substructures from a class labeled graph database.",
            "Meaning every graph has a binary target classification attached."
        ],
        [
            "Thanks.",
            "We discovered a new class of subgraphs.",
            "That enable us to specifically mine very large databases.",
            "Um, they may disclose enabled us to mine the largest correlated graph data set that has been used so far.",
            "A lot of graph mining algorithms with minimum frequency and possibly target correlation constraints have been proposed.",
            "Our contribution is structural criterium that guarantees diversity of features as well as time efficiency.",
            "Let me first motivate the topic."
        ],
        [
            "By the example of the chemical domain that we use, structural features are widely used for similarity and distance measures, and as instantiation descriptors for classification and regression purposes, to bigger frequencies for substructures of different type in a chemical database, such as the carcinogenicity database shown above.",
            "Trees are the most frequent type, yet they may be might efficiently.",
            "However, current methods with minimum frequency and correlation thresholds have large running time and return excessively large solution sets that make post processing necessary, and that is the problem that we want to tackle."
        ],
        [
            "Customers are graph mining algorithm that we use as a basis for our approach in order to introduce you to the basic concepts.",
            "I will start with the concept of a backbone.",
            "The backbone of a tree is defined as the longest path with the lowest sequence.",
            "Assuming Canonical sequence ordering.",
            "Here you can see an example tree with a backbone Mark Gray.",
            "I hope this is visible.",
            "And an attached branch black.",
            "Since every tree has exactly 1 backbone, the backbones partition the partial order of trees disjointly.",
            "We use depth first traversal in each such partition to refine the structures.",
            "And the core concept.",
            "To our approach, namely the backbone refinement class is defined as all three refinements that grow from a specific backbone.",
            "I will show you an example."
        ],
        [
            "In the upper part you can see the pattern.",
            "We just looked at.",
            "The lower part features a slightly different pattern.",
            "Both patterns share the same backbone, but are not refinements of each other.",
            "So this is the backbone.",
            "And you have a branch here and you have a branch here, but they are in different locations.",
            "Both trees can be refined to 1/3 tree, featuring still the same backbone, but both branches from that backbone instead of just one.",
            "So we have two backbone refinement classes here.",
            "The reason is that although all structures share the same backbone, the two left structures are not refinements of each."
        ],
        [
            "Other.",
            "If you have two backbone refinement classes then two settings are possible.",
            "Either both correspond to the same backbone, in which case they are not disjoint.",
            "This is the setting we just saw in the example, or they do, in which case they are disjoint.",
            "The first setting is also.",
            "Depicted on the left in the schema.",
            "Well, two classes start at the backbone, then branch in different directions.",
            "However.",
            "They Unite again at the maximum tree that this backbone is able to spend, where it is not possible to refine further without changing the backbone.",
            "So backbone refinement classes partitioned the search base structurally as opposed to for example, open or closed features.",
            "Meaning the most general or the most specific patterns."
        ],
        [
            "For each level of occurrence.",
            "We use paths as candidate backbones, as in Gaston, and the idea is to mine backbone refinement classes and represent each backbone refinement class by the most significant member."
        ],
        [
            "In case of several most significant members, we used the most general one.",
            "And casquette thresholds cannot be used for anti monotonic pruning directly.",
            "However an upper bound.",
            "Forecast square values of refinements of a pattern exists.",
            "This technique is called statistical metric pruning."
        ],
        [
            "The threshold may be increased during depths."
        ],
        [
            "Search if the pattern if a pattern with casquette value greater than the user defined minimum has been seen.",
            "Since we only search for the maximum element of each class.",
            "So if the not for all significant patterns.",
            "So if the upper bound falls below what we have already seen, we're able to increase.",
            "The threshold and we call this method.",
            "And sorry, dynamic upper bound pruning to contrast it to using a static upper bound."
        ],
        [
            "Now for the experiments.",
            "We compared different types of descriptors.",
            "First, type are all significant.",
            "All trees that are so frequent and significant.",
            "I'm second type are open trees.",
            "Most general significant trees with the same occurrences and the third type.",
            "Our backbone refinement classes.",
            "For the calculation of the open trees, we used the original algorithm by beyond Bringman and colleagues.",
            "Who provided us with the binary and we then compared all those descriptors regarding time efficiency, feature, set size and expressiveness on those four class balanced carcinogenicity datasets.",
            "Which we obtained from the World Wide Web.",
            "The feature."
        ],
        [
            "Set size analysis shows that open trees compete with backbone refinement class features for the best compression.",
            "However, median values over the four datasets then revealed smaller set sizes for the backbone refinement class features.",
            "About 10% of the complete reset size.",
            "Hurry."
        ],
        [
            "Guarding time efficiency, it turned out that the dynamic upper bound method applicable to backbone refinement classes yields a large running time difference.",
            "On the other hand, static upper bound thresholds do not seem to contribute much to the pruning process.",
            "Median values over the four datasets make this clearer."
        ],
        [
            "We then investigated accuracy, sensitivity and specificity of the different descriptors in the leaf.",
            "One out cross validation approach.",
            "The complete results are given in the table on the right and the Roc plot for the MC data set multi.",
            "Socalled data set is shown on the left.",
            "As an example, the complete set of talks of significant trees compete with backbone refinement class features.",
            "Am as can clearly be seen from the table.",
            "Namely, the right and the left column, whereas the open trees fall behind.",
            "Significance tests revealed that the backbone refinement class features perform significantly better than the open trees.",
            "So in summary, we have less features, much faster computation and a better productivity compared to open trees."
        ],
        [
            "In view of the favorable properties we just saw, we then applied our method to very large datasets to investigate the scalability and robustness of the approach.",
            "We used parts of the NCI database featuring two datasets with nearly 90,000 labeled compounds."
        ],
        [
            "We assess the effect of minimum frequency on data set coverage for the largest stage zero data set, we increase the minimum frequency stepwise.",
            "For example, the step from 100 to 200 did not significantly degrees coverage.",
            "That is, the number of features per compound.",
            "Similar results were also obtained for combinations of the other datasets and other thresholds.",
            "This indicates robustness towards minimum frequency and is very favorable for time efficiency reasons.",
            "As you can see from the table.",
            "The reason for robustness lies in the backbone refinement class features being most discriminative patterns, which tend to be found somewhere in the middle in the light region of the search space.",
            "That is above the minimum frequency border, since casquette values are low for low and high frequencies."
        ],
        [
            "To compare feature set sizes, we class balanced the datasets by randomly downsampling to 23,000 and 10,500 samples.",
            "We then compared all significant open and maximal trees, which consists of the positive border as applied by our as implied by our constraints, to our backbone refinement class features and the compression on this large scale data is much greater than on the carcinogenicity data set.",
            "You can see the barplots over the two datasets.",
            "Finally, with our algorithms."
        ],
        [
            "Mining times were reduced to less than five minutes for the data sets of 23,000 and 10,500 compounds.",
            "Whereas open trees took about four to 12 hours to calculate.",
            "We then tried leave one out cross validation as using a K nearest neighbor technique that is, the neighbors are calculated for every prediction based on the instantiating features.",
            "The only usable feature type in this setting where the backbone refinement class features that demand for resources was just too high for been using the other types of descriptors.",
            "In summary, the backbone refined with class features turned out to be practically usable for large scale datasets in terms of time and space efficiency.",
            "They enable both mining and modeling and key features are the robustness towards minimum frequency and their space space representation.",
            "For the latter aspect, I have something that I will now show you."
        ],
        [
            "It is an archadian embedding of the data.",
            "And as you can see.",
            "The data consists of.",
            "Features and instances and the features are the green and the red dots, whereas the instances are blue and salmen respectively.",
            "The blue instances are the active ones and the green instances are the fragments that are most activating.",
            "This is from one of the carcinogenicity data sets.",
            "And I think the embedding visualizes that well.",
            "The features are quite nicely distributed and also clearly separated when you draw the diagonal from top left to bottom right, you will mainly find the red at the green ones down to the left, and also the compounds follow this separation."
        ],
        [
            "So in summary."
        ],
        [
            "With the backbone refinement class features, we obtain descriptors that are heterogeneous through a structural invariant which is used to compress the search space.",
            "Oops, we are relatively robust against minimum frequency, yielding a good data set coverage and the technique is also applicable.",
            "Scalable enough to be applicable to large scale data in terms of time efficiency and feature set size, data set coverage and model performance."
        ],
        [
            "We achieved the compression.",
            "Significant performance gain compared to open or closed features in terms of compression, but especially in time efficiency through the use of dynamic upper bound pruning.",
            "The discriminative ability in typical classification tasks was similar to the complete set of trees, but significantly better than open trees."
        ],
        [
            "Finally, there is a C++ library implementation available.",
            "If anyone is interested and.",
            "Thanks for your attention.",
            "The next speaker setting up this.",
            "Recommend.",
            "OK."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you, my name is Andreas mounts from Freiburg University and this is a joint work with Crystal, Thelma and Steven, from Munich.",
                    "label": 0
                },
                {
                    "sent": "The approach I'm going to present is concerned with mining substructures from a class labeled graph database.",
                    "label": 0
                },
                {
                    "sent": "Meaning every graph has a binary target classification attached.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thanks.",
                    "label": 0
                },
                {
                    "sent": "We discovered a new class of subgraphs.",
                    "label": 0
                },
                {
                    "sent": "That enable us to specifically mine very large databases.",
                    "label": 0
                },
                {
                    "sent": "Um, they may disclose enabled us to mine the largest correlated graph data set that has been used so far.",
                    "label": 0
                },
                {
                    "sent": "A lot of graph mining algorithms with minimum frequency and possibly target correlation constraints have been proposed.",
                    "label": 0
                },
                {
                    "sent": "Our contribution is structural criterium that guarantees diversity of features as well as time efficiency.",
                    "label": 0
                },
                {
                    "sent": "Let me first motivate the topic.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "By the example of the chemical domain that we use, structural features are widely used for similarity and distance measures, and as instantiation descriptors for classification and regression purposes, to bigger frequencies for substructures of different type in a chemical database, such as the carcinogenicity database shown above.",
                    "label": 0
                },
                {
                    "sent": "Trees are the most frequent type, yet they may be might efficiently.",
                    "label": 1
                },
                {
                    "sent": "However, current methods with minimum frequency and correlation thresholds have large running time and return excessively large solution sets that make post processing necessary, and that is the problem that we want to tackle.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Customers are graph mining algorithm that we use as a basis for our approach in order to introduce you to the basic concepts.",
                    "label": 0
                },
                {
                    "sent": "I will start with the concept of a backbone.",
                    "label": 0
                },
                {
                    "sent": "The backbone of a tree is defined as the longest path with the lowest sequence.",
                    "label": 1
                },
                {
                    "sent": "Assuming Canonical sequence ordering.",
                    "label": 0
                },
                {
                    "sent": "Here you can see an example tree with a backbone Mark Gray.",
                    "label": 0
                },
                {
                    "sent": "I hope this is visible.",
                    "label": 0
                },
                {
                    "sent": "And an attached branch black.",
                    "label": 1
                },
                {
                    "sent": "Since every tree has exactly 1 backbone, the backbones partition the partial order of trees disjointly.",
                    "label": 1
                },
                {
                    "sent": "We use depth first traversal in each such partition to refine the structures.",
                    "label": 1
                },
                {
                    "sent": "And the core concept.",
                    "label": 0
                },
                {
                    "sent": "To our approach, namely the backbone refinement class is defined as all three refinements that grow from a specific backbone.",
                    "label": 0
                },
                {
                    "sent": "I will show you an example.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In the upper part you can see the pattern.",
                    "label": 0
                },
                {
                    "sent": "We just looked at.",
                    "label": 0
                },
                {
                    "sent": "The lower part features a slightly different pattern.",
                    "label": 0
                },
                {
                    "sent": "Both patterns share the same backbone, but are not refinements of each other.",
                    "label": 0
                },
                {
                    "sent": "So this is the backbone.",
                    "label": 0
                },
                {
                    "sent": "And you have a branch here and you have a branch here, but they are in different locations.",
                    "label": 0
                },
                {
                    "sent": "Both trees can be refined to 1/3 tree, featuring still the same backbone, but both branches from that backbone instead of just one.",
                    "label": 0
                },
                {
                    "sent": "So we have two backbone refinement classes here.",
                    "label": 1
                },
                {
                    "sent": "The reason is that although all structures share the same backbone, the two left structures are not refinements of each.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Other.",
                    "label": 0
                },
                {
                    "sent": "If you have two backbone refinement classes then two settings are possible.",
                    "label": 0
                },
                {
                    "sent": "Either both correspond to the same backbone, in which case they are not disjoint.",
                    "label": 1
                },
                {
                    "sent": "This is the setting we just saw in the example, or they do, in which case they are disjoint.",
                    "label": 0
                },
                {
                    "sent": "The first setting is also.",
                    "label": 1
                },
                {
                    "sent": "Depicted on the left in the schema.",
                    "label": 0
                },
                {
                    "sent": "Well, two classes start at the backbone, then branch in different directions.",
                    "label": 1
                },
                {
                    "sent": "However.",
                    "label": 0
                },
                {
                    "sent": "They Unite again at the maximum tree that this backbone is able to spend, where it is not possible to refine further without changing the backbone.",
                    "label": 0
                },
                {
                    "sent": "So backbone refinement classes partitioned the search base structurally as opposed to for example, open or closed features.",
                    "label": 1
                },
                {
                    "sent": "Meaning the most general or the most specific patterns.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For each level of occurrence.",
                    "label": 0
                },
                {
                    "sent": "We use paths as candidate backbones, as in Gaston, and the idea is to mine backbone refinement classes and represent each backbone refinement class by the most significant member.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In case of several most significant members, we used the most general one.",
                    "label": 0
                },
                {
                    "sent": "And casquette thresholds cannot be used for anti monotonic pruning directly.",
                    "label": 0
                },
                {
                    "sent": "However an upper bound.",
                    "label": 0
                },
                {
                    "sent": "Forecast square values of refinements of a pattern exists.",
                    "label": 0
                },
                {
                    "sent": "This technique is called statistical metric pruning.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The threshold may be increased during depths.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Search if the pattern if a pattern with casquette value greater than the user defined minimum has been seen.",
                    "label": 0
                },
                {
                    "sent": "Since we only search for the maximum element of each class.",
                    "label": 1
                },
                {
                    "sent": "So if the not for all significant patterns.",
                    "label": 0
                },
                {
                    "sent": "So if the upper bound falls below what we have already seen, we're able to increase.",
                    "label": 0
                },
                {
                    "sent": "The threshold and we call this method.",
                    "label": 1
                },
                {
                    "sent": "And sorry, dynamic upper bound pruning to contrast it to using a static upper bound.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now for the experiments.",
                    "label": 0
                },
                {
                    "sent": "We compared different types of descriptors.",
                    "label": 0
                },
                {
                    "sent": "First, type are all significant.",
                    "label": 0
                },
                {
                    "sent": "All trees that are so frequent and significant.",
                    "label": 1
                },
                {
                    "sent": "I'm second type are open trees.",
                    "label": 0
                },
                {
                    "sent": "Most general significant trees with the same occurrences and the third type.",
                    "label": 1
                },
                {
                    "sent": "Our backbone refinement classes.",
                    "label": 1
                },
                {
                    "sent": "For the calculation of the open trees, we used the original algorithm by beyond Bringman and colleagues.",
                    "label": 0
                },
                {
                    "sent": "Who provided us with the binary and we then compared all those descriptors regarding time efficiency, feature, set size and expressiveness on those four class balanced carcinogenicity datasets.",
                    "label": 0
                },
                {
                    "sent": "Which we obtained from the World Wide Web.",
                    "label": 0
                },
                {
                    "sent": "The feature.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Set size analysis shows that open trees compete with backbone refinement class features for the best compression.",
                    "label": 1
                },
                {
                    "sent": "However, median values over the four datasets then revealed smaller set sizes for the backbone refinement class features.",
                    "label": 0
                },
                {
                    "sent": "About 10% of the complete reset size.",
                    "label": 0
                },
                {
                    "sent": "Hurry.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Guarding time efficiency, it turned out that the dynamic upper bound method applicable to backbone refinement classes yields a large running time difference.",
                    "label": 1
                },
                {
                    "sent": "On the other hand, static upper bound thresholds do not seem to contribute much to the pruning process.",
                    "label": 0
                },
                {
                    "sent": "Median values over the four datasets make this clearer.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We then investigated accuracy, sensitivity and specificity of the different descriptors in the leaf.",
                    "label": 0
                },
                {
                    "sent": "One out cross validation approach.",
                    "label": 0
                },
                {
                    "sent": "The complete results are given in the table on the right and the Roc plot for the MC data set multi.",
                    "label": 0
                },
                {
                    "sent": "Socalled data set is shown on the left.",
                    "label": 0
                },
                {
                    "sent": "As an example, the complete set of talks of significant trees compete with backbone refinement class features.",
                    "label": 0
                },
                {
                    "sent": "Am as can clearly be seen from the table.",
                    "label": 0
                },
                {
                    "sent": "Namely, the right and the left column, whereas the open trees fall behind.",
                    "label": 0
                },
                {
                    "sent": "Significance tests revealed that the backbone refinement class features perform significantly better than the open trees.",
                    "label": 0
                },
                {
                    "sent": "So in summary, we have less features, much faster computation and a better productivity compared to open trees.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In view of the favorable properties we just saw, we then applied our method to very large datasets to investigate the scalability and robustness of the approach.",
                    "label": 0
                },
                {
                    "sent": "We used parts of the NCI database featuring two datasets with nearly 90,000 labeled compounds.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We assess the effect of minimum frequency on data set coverage for the largest stage zero data set, we increase the minimum frequency stepwise.",
                    "label": 1
                },
                {
                    "sent": "For example, the step from 100 to 200 did not significantly degrees coverage.",
                    "label": 0
                },
                {
                    "sent": "That is, the number of features per compound.",
                    "label": 1
                },
                {
                    "sent": "Similar results were also obtained for combinations of the other datasets and other thresholds.",
                    "label": 1
                },
                {
                    "sent": "This indicates robustness towards minimum frequency and is very favorable for time efficiency reasons.",
                    "label": 0
                },
                {
                    "sent": "As you can see from the table.",
                    "label": 0
                },
                {
                    "sent": "The reason for robustness lies in the backbone refinement class features being most discriminative patterns, which tend to be found somewhere in the middle in the light region of the search space.",
                    "label": 0
                },
                {
                    "sent": "That is above the minimum frequency border, since casquette values are low for low and high frequencies.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To compare feature set sizes, we class balanced the datasets by randomly downsampling to 23,000 and 10,500 samples.",
                    "label": 0
                },
                {
                    "sent": "We then compared all significant open and maximal trees, which consists of the positive border as applied by our as implied by our constraints, to our backbone refinement class features and the compression on this large scale data is much greater than on the carcinogenicity data set.",
                    "label": 1
                },
                {
                    "sent": "You can see the barplots over the two datasets.",
                    "label": 0
                },
                {
                    "sent": "Finally, with our algorithms.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Mining times were reduced to less than five minutes for the data sets of 23,000 and 10,500 compounds.",
                    "label": 0
                },
                {
                    "sent": "Whereas open trees took about four to 12 hours to calculate.",
                    "label": 0
                },
                {
                    "sent": "We then tried leave one out cross validation as using a K nearest neighbor technique that is, the neighbors are calculated for every prediction based on the instantiating features.",
                    "label": 0
                },
                {
                    "sent": "The only usable feature type in this setting where the backbone refinement class features that demand for resources was just too high for been using the other types of descriptors.",
                    "label": 0
                },
                {
                    "sent": "In summary, the backbone refined with class features turned out to be practically usable for large scale datasets in terms of time and space efficiency.",
                    "label": 0
                },
                {
                    "sent": "They enable both mining and modeling and key features are the robustness towards minimum frequency and their space space representation.",
                    "label": 0
                },
                {
                    "sent": "For the latter aspect, I have something that I will now show you.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It is an archadian embedding of the data.",
                    "label": 1
                },
                {
                    "sent": "And as you can see.",
                    "label": 0
                },
                {
                    "sent": "The data consists of.",
                    "label": 1
                },
                {
                    "sent": "Features and instances and the features are the green and the red dots, whereas the instances are blue and salmen respectively.",
                    "label": 0
                },
                {
                    "sent": "The blue instances are the active ones and the green instances are the fragments that are most activating.",
                    "label": 0
                },
                {
                    "sent": "This is from one of the carcinogenicity data sets.",
                    "label": 0
                },
                {
                    "sent": "And I think the embedding visualizes that well.",
                    "label": 0
                },
                {
                    "sent": "The features are quite nicely distributed and also clearly separated when you draw the diagonal from top left to bottom right, you will mainly find the red at the green ones down to the left, and also the compounds follow this separation.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in summary.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "With the backbone refinement class features, we obtain descriptors that are heterogeneous through a structural invariant which is used to compress the search space.",
                    "label": 1
                },
                {
                    "sent": "Oops, we are relatively robust against minimum frequency, yielding a good data set coverage and the technique is also applicable.",
                    "label": 0
                },
                {
                    "sent": "Scalable enough to be applicable to large scale data in terms of time efficiency and feature set size, data set coverage and model performance.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We achieved the compression.",
                    "label": 0
                },
                {
                    "sent": "Significant performance gain compared to open or closed features in terms of compression, but especially in time efficiency through the use of dynamic upper bound pruning.",
                    "label": 1
                },
                {
                    "sent": "The discriminative ability in typical classification tasks was similar to the complete set of trees, but significantly better than open trees.",
                    "label": 1
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Finally, there is a C++ library implementation available.",
                    "label": 0
                },
                {
                    "sent": "If anyone is interested and.",
                    "label": 0
                },
                {
                    "sent": "Thanks for your attention.",
                    "label": 0
                },
                {
                    "sent": "The next speaker setting up this.",
                    "label": 0
                },
                {
                    "sent": "Recommend.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        }
    }
}