{
    "id": "5fajq6js5v6dsddiu2abwxwqxefppms4",
    "title": "Information evolution of optimal learning",
    "info": {
        "author": [
            "Roman V. Belavkin, School of Computing Science, Middlesex University"
        ],
        "published": "Sept. 4, 2008",
        "recorded": "May 2008",
        "category": [
            "Top->Computer Science->Machine Learning",
            "Top->Computer Science->Optimization Methods"
        ]
    },
    "url": "http://videolectures.net/aispds08_belavkin_ieol/",
    "segmentation": [
        [
            "Good morning everybody.",
            "My name is Roman Bill Atkin and I'm based in London and Middlesex University.",
            "It's very nice morning and.",
            "I would like to talk today about slightly.",
            "Probably unusual approach to these problems.",
            "I will not talk about time evolution of of learning systems, but I will talk about information evolution.",
            "And later, of course, we'll try to translate this to time evolution and.",
            "So that's pro."
        ],
        [
            "The forward is."
        ],
        [
            "This work, of course, is related to all that you use, as well as a Bayesian estimation and choice under uncertainty, which has been largely developed in the beginning of 40s and 50s.",
            "As a theory of statistical statistical decision, decision making, and."
        ],
        [
            "Of course, optimization is related to variational analysis, and optimal control has developed as a subfield of that, with the maximum principle of Pendragon, which is a trajectory methods for estimating the optimal solution.",
            "So if you imagine immediamente that you're trying to.",
            "In this medium, compute the optimal trajectory which is connected to points."
        ],
        [
            "Of course, that approach turned out to be quite difficult for stochastic control where.",
            "Trajectory is or not so useful.",
            "Not not.",
            "Didn't seem to be so obvious and Bellman approach which is similar to propagation of disturbances of light and Fermat theory.",
            "It's away so called Wavefront approach which is solved by partial differential equations and of course the discrete version of that is Bellman difference equation."
        ],
        [
            "And the significant development in this area was the theory of conditional Markov processes, which was developed by certain notion.",
            "The end of 50s.",
            "With essentially, any process can be represented as a conditional Markov process in the higher dimensional phase space.",
            "And because it's a Markov process, it's very easy to translate it's partial differential equations.",
            "And then you can achieve stochastic optimal control.",
            "The problem problem of optimal nonlinear filtering was solved.",
            "An particular case of that was a linear filter, which you know is a common VC, but in fact you total story says that common attended conference in Moscow in 1960 where Stratonovich reported his results of 1959, where as an example of linear case he showed Kalman filter equations but.",
            "Of course.",
            "Doesn't produce contribution of common we see, and it's a very popular in engineering.",
            "Another important development, something that I'm typically interested in.",
            "Of course.",
            "Information theory."
        ],
        [
            "And that's in fact the area where the variational approaches that you're talking about.",
            "Quite often here were first applied.",
            "They were applied to estimate the maximum channel capacity, and Kolmogorov Giants holes define the maximum entropy principle and certain knowledge also use them to estimate the maximum useful value of information.",
            "So the problem is this.",
            "If you suppose you try to estimate your development of your system based on probability and using dynamic programming method.",
            "For example, you of course know that on each step you estimating the expectation.",
            "Of course on the last step you estimating expectation given that the previous steps was estimated.",
            "And of course on that last step, our estimation is a linear function.",
            "Of course, if you do a second estimation, your function already becomes nonlinear.",
            "So of course, that's why dynamic programming problems there.",
            "Nonlinearly, they describe nonlinear processes, but the problem is this, if I know that probability Markov transition probability is anything to learn for me, anifah compute, let's say 1000 steps ahead.",
            "What will happen on the next step when I find out that my probability estimation was actually wrong, do I have to recompute all that expensive computations?",
            "So.",
            "It."
        ],
        [
            "These are that learning and adaptation is only related to situations when you don't know these probabilities exactly, so optimal control is about predicting what happens to the system like a missile when you know your system.",
            "But if you don't know if you have a model free system.",
            "These equations actually do not describe my situation.",
            "So here's a couple."
        ],
        [
            "Propositions first.",
            "Of all is there is no need to learn if there is nothing to optimize.",
            "Why do you have to?",
            "And that's quite extreme extreme, of course."
        ],
        [
            "Next proposition that there is nothing new to learn if you know if your information is complete.",
            "So you can then predict what will happen to the system.",
            "But if you know the probability it's not, there's no learning there because you know the information."
        ],
        [
            "Now I will start now a little bit overview of theory of optimization and it actually related to the theory of choice.",
            "The most fundamental concept in theory of choices, prefer insulation.",
            "We work with functions here, but in fact we don't eat probabilities.",
            "We don't eat values of utility functions.",
            "We eat apples, which these utilities are defined on.",
            "So preference relation is a binary relation which is total and transitive.",
            "And total means it's also reflective.",
            "So in fact it is a preorder preorder which is total.",
            "This is a very nice object, in fact, because."
        ],
        [
            "It gives you immediately at apology.",
            "It's Alexander topology, which in which open set is a system of upper sets plus empty set, and the set itself."
        ],
        [
            "In fact, the finest topology is also discrete topology, and because we have a topology, it means your set is measurable.",
            "You have a board of Sigma algebra.",
            "A lot of the series I'm telling you today will tell you.",
            "In fact, I have developed in category of preorders not even going to functions because I decided to stay at the levels of apples."
        ],
        [
            "And there are many interesting results which I'm not going to tell you here, but one of them is for example.",
            "Describing the arrows in this category and function is monotone with respect to pre orders means it's continuous with respect to apologies.",
            "Continue to means immeasurable and measurable means it's monotone.",
            "So you have everything in some in some sense.",
            "So many things I can develop can be developed on these errors, but of course."
        ],
        [
            "Applications, especially when the sets are very large.",
            "When I have many apples, I cannot really put all apples into pairs, is quite convenient to create tables.",
            "Numerical tables representing these preferences which are called functions, and these utility functions is a monotone functions which embed my pre order into the order on real line.",
            "It turns out that not all prefer insulations can be embedded like this, but we will talk about about this, but in fact everything will talk today about this particular class.",
            "Or prefer installations because we'll talk about functions now.",
            "What type of?"
        ],
        [
            "Functions will talk about.",
            "All discuss dual spaces of functions.",
            "And these two functions will be defined on the same set."
        ],
        [
            "The spaces cover can have different structure.",
            "They in fact, yeah.",
            "Into the example reference relationship, which cannot be included in lexicographic continuous continuous lexicographic preference solution.",
            "For example, and you arrange so basically to make prefer insulation represent by real function, you must have in this preferred solution or the dense countable subset.",
            "And if you I can give you more precise definition.",
            "Looks a little bit, but that's technicality.",
            "But the interesting thing that real numbers is the only completely ordered field.",
            "So.",
            "It makes his question, do you really need preference relations which are not representable?",
            "OK so I will be coupling functions in these two spaces through a Hilbert space.",
            "This is a Gelfand triple.",
            "And these functions of these spaces can have different metrics.",
            "They I hope they're reflexive, but I need linear bilinear form.",
            "The coupling function is be linear, which is for example example is the inner product and why I'm interested in the product.",
            "Is this of course, because we expect."
        ],
        [
            "Value that all we tried to maximize easily in the product.",
            "Function wise supposed to function which is added to additive to one and X is my utility of course.",
            "Now I will when when I don't have uncertainty, I just optimize my function, but if I have uncertainties here then in fact my choice set is the choice of probability functions parameter parameterized by some values which I don't know and in fact."
        ],
        [
            "You have to consider space of all functions like that.",
            "Here is an example that I will use quite often.",
            "It's a simplex or probability triangle.",
            "So suppose you have a set of three elements, so you have three probabilities.",
            "Of course, the one probability can be computed from two others.",
            "So by XI represent one probability by wire, present third probability and the second probability somewhere there.",
            "So the totality of all probabilities, the triangle.",
            "For example, the constant uniform probability is the point in the middle here.",
            "White expected value is useful becausw it coincides with my utility in the Delta functions.",
            "And in fact, by Norman Morganstein proved that the only function that satisfies the continuous in the other assumptions is.",
            "In fact there are fine function or linear function on probabilities.",
            "However, there is a paradox.",
            "If your choice set includes the Delta functions.",
            "Do you really have uncertainties?",
            "I can just choose this the most the best.",
            "In real problems we choose from a subset of these probabilities and I will talk today about this subset."
        ],
        [
            "I will need to something a little bit refreshing your memory or maybe give some definitions about convex functions, because I will concentrate on convex subsets.",
            "And of course, if it's not convex, you can always convexified it and after first or second Legendre transform you know it becomes convex anyway.",
            "So convex function, that's the definition.",
            "Of course the the point on the middle of the interval gives you smaller value than the mixture of the.",
            "On the right side, and it's important that these functions can go to Infinity, so these are convex functions which can go into Infinity, but the area on which they are not infinite is called affective domain, and if it's nonempty, I call these functions proper."
        ],
        [
            "Example information divergent, so could make that Libya diversions that we've all considered.",
            "For example, it's a lab rhythmic deviation of 1 function from another, which is a cool initial or reference.",
            "And in fact, this is a convex functional of Y.",
            "In fact, it's also very nice because it's strictly convex.",
            "It means it has unique minimum.",
            "You don't need to have this.",
            "In fact, functions normalized.",
            "So in probability theory we have normalized, but there are many examples.",
            "When, for example, this measure is a lebec measure which is not normalized to one.",
            "In that case, this becomes minus entropy.",
            "If of course, for example here you have joint probability and this is product of marginals, then this becomes Shannon information.",
            "OK, so that's just an example of quality functions, but I'm not going to just concentrate."
        ],
        [
            "Him.",
            "Something's about 1X functions is for or there for some conditions that can be shown to be continuous on the on the interior of this domain."
        ],
        [
            "Strictly convex functions, I repeat, has unique minimum global minimum.",
            "And that's the proof."
        ],
        [
            "And I will also use notion of sub differential is slightly generalization of differential.",
            "The things that I don't need really that my functions to be differential, that every point.",
            "It's not that I have continues, but if they're not differential, some points that I will consider a set of all support hyperplanes, hyperplanes.",
            "So it means in some sense derivative differential is not uniquely defined on some points, so you have an angle and then you can have some several hyperplanes of supports if its differentiable then my subdifferential let's say at this point is a Singleton."
        ],
        [
            "A set of one in it.",
            "OK so I remember reminding you of memory that I will be interested in subsets of functions.",
            "So it is interesting to talk about so called polar subsets of sets.",
            "So Quantics Boyer phonics set is a set that two for two points appoint on the segment belongs to the."
        ],
        [
            "To this voting.",
            "First of all, I would each convex set is characterized by unique support function.",
            "Which is defined as follows.",
            "Suppose we have a subset convex subset in SpaceX.",
            "So now given the function in the conjugate space Y, the support is a maximum of inner product over X which belong to this subset.",
            "And basically, if you imagine the ball, then you in the product is maximized.",
            "You move as close as possible to the surface, and that's a hyperplane of support.",
            "This function is called mixed and it's first order homogeneous."
        ],
        [
            "You can also define something called the distance function in this context set.",
            "That's a function.",
            "That's a function that gives you a scale parameter by which you have to increase your context set to approach a point from the center.",
            "So for example, if you're convex set is a unit ball and there is a point somewhere, the distance from the center at this point is the factor by which you have to increase this ball to reach this point."
        ],
        [
            "Now two sets are called polar.",
            "If support of one is the distance of another.",
            "What it means is that in fact you can relate these two functions to support of two polar sets by genre transform."
        ],
        [
            "So for the moment I will forget about the condition.",
            "Remember I defined support as a supremum, where X belong to myself.",
            "But now what I do in fact I just constrain the distance of the dual set.",
            "And the.",
            "That's already better."
        ],
        [
            "Finds us some problems in convex optimization.",
            "I also have a can represent them as a dual problems.",
            "In fact, here X that satisfies the supremum can be found using this problem by minimizing this convex function with the constraint on the linear functional."
        ],
        [
            "And you can re late.",
            "As I mentioned, these two convex functions through legions form which looks like this.",
            "And of course, the condition of extremely satisfied on X belongs to subdifferential one function and why belongs to sub differential of another.",
            "That means that in fact sub differentials are inverse functions of each other.",
            "In fact, it's in these Murphys."
        ],
        [
            "Among these, your context function is monotone, strictly more convex then your sub differential will always be strictly monotone function.",
            "Now what is the condition of the extreme right?",
            "So in my subset I want to find that point which gives me the maximum of my linear functional, which if you remember, gives me maximum expected value.",
            "It's very straightforward.",
            "That's a generalization of contactor theorem.",
            "So basically you're you define LaGrange multiplier, which is related to your constraint.",
            "Now, beta X belongs to sub differential of your context function at your extremum than other condition condition of extreme that your functional must reach.",
            "So basically you can strain your context functional, but obviously linear functional achieves the maximum on the boundary.",
            "It will never achieve maximum linear because it's linear.",
            "It will never achieve the maximum.",
            "In theory it's always on the boundary, so that represents the boundary and in fact your LaGrange multipliers determined as a derivative of 1 constraint.",
            "With respect to another."
        ],
        [
            "To prove it.",
            "You have to write Lagrangian function.",
            "Take this sub differential over Y that gives you first condition zero must belong to this sub differential.",
            "Another condition is differentiated by beta that gives a second constraint.",
            "And thinking about this function as G of C. Differentiating this Lagrangian by C gives you the last relation.",
            "So now I know how my optimal Huawei which in fact.",
            "Will be a probability distribution.",
            "Is characterized."
        ],
        [
            "Here's an example.",
            "If my convex function is the entropy or relative entropy.",
            "Then I can very quickly write the following.",
            "By the way, this this thing appears.",
            "Here is additional constraint that my function is additive to one.",
            "It's just normalization.",
            "And let's give you this equation.",
            "If Y is constant, this is in fact the Gibbs distribution.",
            "Now.",
            "You know now that this in fact appears as a solution of this extreme external problem.",
            "Now, if for example, my utility function is minus Euclidean distance, then it is a Gaussian distribution.",
            "If it's something else, like for example number of events, but I'm that become persona everything.",
            "So all distributions we have in fact just appear by substituting different utility functions."
        ],
        [
            "He rose again, returning to this triangle so that circle here represents a level of constant entropy, and they are extremely here that I mentioned that there are extreme and it turns out that linear functional in fact has two extreme ones that correspond to maximum.",
            "Another response to minimum.",
            "And they correspond to positive and negative values of this parameter beta.",
            "By the way, beta inverse is the temperature that just heard on the previous talk.",
            "And temperature can be negative in this problems."
        ],
        [
            "Now.",
            "We I would like now the the most important thing I would like to tell you today is this characterization of this solution.",
            "An understanding of this comes when you in fact forget about that.",
            "It's a probability or anything else.",
            "If you constrain your convex functional by somewhere by some value, it's clear that your linear functional your.",
            "In the product cannot have infinite value.",
            "If it does, it means that your hyperplane dissect your domain.",
            "OK, So what I would but The thing is that my.",
            "I want to use functions like utility functions which can have infinite values on some measure non 0.",
            "So what will happen with my optimal solution in the case?"
        ],
        [
            "First theorem my linear function will not have infinite values, even only if everywhere where my utility function or this function is infinite.",
            "The other is 0.",
            "That means that non zero values imply finite values of utility.",
            "How to prove it?"
        ],
        [
            "Of course, you just use convention that Infinity by zero is 0 and then you just split your linear functional into parts where you have none.",
            "Listen where you have inflated together 0 so the result is a finite value.",
            "Conversely, by convention that the sum of infringes gives you minus Infinity.",
            "You end up with infinite value.",
            "So what it means in translating into language of probability, it means the optimal solution is such when non zero probabilities correspond.",
            "All need to find values of utility.",
            "Now there is a stronger current."
        ],
        [
            "Azatian suppose that you are convex.",
            "Functional, has unique minimum.",
            "That means, for example, that that's true for strictly convex function.",
            "So and for for any function X, if your optimal solution has zero.",
            "That means that your X that you have chosen at that point is proportional to the minimum.",
            "The unique minimum of the value of of your unique minimum minimum function in that on that element."
        ],
        [
            "The proof is quite simple.",
            "It basically just show that you're you have a local minimum and then on that particular coordinate.",
            "And."
        ],
        [
            "Example.",
            "Why's it important?",
            "So I returning back to probability.",
            "So now I have again my.",
            "Cool big divergance as a one functional its conjugate.",
            "Is has this form and in fact it is the.",
            "This is the partition function.",
            "This is locked partition function.",
            "It's minimum global minimum is constant minus Infinity.",
            "So what this theorem tells you that in your optimal solution zero probabilities.",
            "Imply infinite values of your utility function.",
            "That means zeros and infinities are in one to one correspondence.",
            "The important consequences that, for example, if your ex your function is defined on the space of say, let's say observations and controls, that means that your controls none of your controls can have a zero probability.",
            "That means a completely stochastic process.",
            "I mean, you can have zero probability for some controller for some estimation, But then it will not be optimal.",
            "And I remember Peter's nugget that he put into his estimations and they become better.",
            "That's just why it happens."
        ],
        [
            "Now.",
            "Now, if I know my optimal solution, I can in fact straightaway forget about all non optimal solutions and given my utility functions I know how the optimal looks.",
            "I will now define characteristics potentials which are not now functions defined on the vector spaces, but there are functions defined on this color on the real value they just parameterized by better, so I only now work in the space of my optimal solutions."
        ],
        [
            "I defined two characteristic potentials there with defined with respect to my convex functionals which can be anything.",
            "But"
        ],
        [
            "What what, what the heck?"
        ],
        [
            "To do is the following, in fact, as illusions form, I can now define what is my maximum value, for example of 1 function with respect to constraint to another.",
            "And it is basically given by derivative of one of these.",
            "Potentials and this is just is just a function you can find and.",
            "In fact you can find the inverse.",
            "So to destroy this I will now show."
        ],
        [
            "Examples.",
            "Using probability, so my first function will be again my cool big Libya diversions.",
            "And its conjugate, as I mentioned, this has this form.",
            "I will consider the divergent with respect to the back measure.",
            "So in fact my divergences now minus entropy.",
            "So just to simplify things in that setting, the second potential is in fact this free energy that you talked about here quite often."
        ],
        [
            "So let's consider first case.",
            "We have a finite set of two elements.",
            "Hourly back measure is just accounting measure 1.",
            "An it means our utility function can have at most two values and I define them C -- D, C plus D just to have it.",
            "Symmetric sees the center.",
            "And then.",
            "And I write all these functions immediately and I define how my maximum value of my expected value depends on parameter beta.",
            "That means I can invert it and compute better from the constraint on the expected value."
        ],
        [
            "Example, Now let's say AB Continuum.",
            "Now these days is lebec measure and now my utility functions has various in the interval or which is subset of real line.",
            "Doesn't matter, I just write new equations, just slightly different.",
            "And that's my egg in my final function.",
            "And here is the graph."
        ],
        [
            "So these two functions.",
            "So here you can see this parameter beta, which I'm only care about.",
            "That's the LaGrange multiplier and that's the maximum value of your extreme value of your expectation.",
            "This line represents a case of final set of two elements.",
            "This case represents.",
            "This function is a case of uncountable set which corresponds to infinite dimensional space.",
            "So everything else in between is there so you can see, but it's very nice functions I can also.",
            "Means that if I give a constraint on my let's say average error.",
            "I know immediately what my optimal parameter is."
        ],
        [
            "The temperature.",
            "You can also have the same functions for the information, so that's again better and that's information in the first case, and that's information in the second case information information."
        ],
        [
            "Let's not mention the dynamics.",
            "So I assume now that I now actually care about time.",
            "And as I learn, let's say my constraints change as some monotonic function of time.",
            "Let's say my information increases C or my my performance increases.",
            "My average utility increases.",
            "It took."
        ],
        [
            "Without that, the sum of your utilities has the following upper bound.",
            "It's a difference of your courtesy potentials on the endpoints, which characterized by bitter.",
            "Determine from this constraints also your information."
        ],
        [
            "Communitive information has the following lower bound.",
            "So that means that's the maximum.",
            "The best you can do, and that's the smallest information you need to learn to do that.",
            "Of course, better here is determined from the function that I should just show you on the previous slide.",
            "The."
        ],
        [
            "All this, of course, you know an integral integral is maximized when each of the integrators maximized, and it's a function of better.",
            "But I showed you before and it's a derivative of microchips potential, which gives me.",
            "Immediately the gradient theorem."
        ],
        [
            "Same happens for the second case."
        ],
        [
            "Now I would like like to explain this on my triangle again, so that's my space of probabilities and these are now level sets of my expected utility.",
            "They are linear because it's a linear function of probability, remember.",
            "So the point is that I want to move in this space somehow and if I move in some direction it means I change my information changes.",
            "So equivalent of change with information gives me different change of expected utility.",
            "So I want to maximize the change of my expected utility, but.",
            "You know that by gradient it doesn't matter how I move, because it's only matters what are the difference on the on the.",
            "Starting points, so what's the deal?",
            "Why do I need to choose a trajectory?"
        ],
        [
            "Because I also want to optimize the other thing.",
            "The other thing is information.",
            "I want to move.",
            "In such a way that I don't learn as much as possible, so I want to achieve my change of utility with the smallest amount of information."
        ],
        [
            "And that is achieved by the exponential family, and in that case this is in fact analogy offer brackets thrown problem in variation calculus where you want to achieve.",
            "You want to compute the trajectory where a ball is falling between two points as fast as possible.",
            "Here I want to achieve.",
            "Trajectory that goes from one level of expected to another with the smallest information possible.",
            "And that's control."
        ],
        [
            "This equation.",
            "How much time do I have?",
            "About four minutes.",
            "OK, I probably can mention this why algorithm in exponentials are so important?",
            "I mentioned I derive the this results without going for general convex sets and functions, but I also mentioned The thing is that functions such as utility functions or probabilities in fact they're not really if they just consider only that they do not formally in space.",
            "If you for example, multiply utility function by negative number, this function falls out of its place.",
            "So understand that algebra of plus and plus and multiplication, they don't form linear space."
        ],
        [
            "But it turns out that they form linear space in other algebras.",
            "These are algebras over independent semirings and these are some rings where the addition is it important here to examples are Max is when you consider real functions and the operation of addition is a maximum.",
            "An multiplication is plus constant zero is minus Infinity and 01.",
            "Another it's important.",
            "Simmering is positive functions with the operations Marks and multiplication.",
            "These simmering, which in this algebra probabilities are linear space, and here utility functions are linear space.",
            "By the way, in this semi algebra.",
            "So in this in this algebra Max Plus bailment equation is linear."
        ],
        [
            "And it turns out that the only is a morphism between these two semirings.",
            "Is the exponent and the inverse is of course the logarithm.",
            "That's why we have them so often these functions."
        ],
        [
            "The applications of this I will just slightly mention that I'm quite interested in learning and I do a lot of cognitive modeling and I look into data of subjects or people or animals, how they learn, and in fact most of the ideas that I mentioned today, they come from data that is modeled by these models and important phenomena.",
            "That's when we learn we have something called the probability matching.",
            "So for example, we try to adapt towards high probability of rewards and low probability of punishments or something.",
            "But it turns out this function is not identity.",
            "So low probabilities are overmatched.",
            "High probability of people under matched an to model this we introduce noise and in fact cognitive models use this.",
            "Softmax gives distribution.",
            "The question is what is the value of this noise parameter, the temperature?"
        ],
        [
            "And if you consider, for example, how people learn in different stages as they go on, you will notice that this noise decreases with time.",
            "So I propose that something along time ago to add the dynamic noise into models and what is the dynamics."
        ],
        [
            "From equations we've seen, it's related to two things to information, and you expected utility, but here's an experiment where I applied this.",
            "This is experimental, very famous model, very famous experiment.",
            "Yorkies Dotson experimented 100 years ago with mice and they trained them to exit.",
            "Suggest particular door and they train them is different strengths of stimuli.",
            "What they found was that the performance was not linear function of strength of stimuli, it was the called inverted U shape so it achieves the maximum performance at some point.",
            "The fastest learning, but then as you increase the stimulate improvement performance drop that shows you that in fact your action selection algorithm depends on the values with which you reward.",
            "And there's a relation to of my algorithm to the not only to information here is the graph of the."
        ],
        [
            "Entropy.",
            "As the mouse learns what I did I just attached this entropy directly to control noise temperature.",
            "So the higher the uncertainty, the higher the noise.",
            "The lower density is lower than us, so related information, but also it is related to these values of rewards.",
            "To model this speak like this you need also the other relation."
        ],
        [
            "And you have very nice correspondence with the data, not data from samples or it's actually data from real experiments with animals."
        ],
        [
            "I also applied this to optimal action selection of agents.",
            "Here I compare three agents, greedy Agent Maxim like maximum expected value, slightly noisy agent, but not the optimal and the one which I control by optimal trajectory strategy.",
            "Here's the number of cycles.",
            "And as they learn, the optimal agent is better, but what?"
        ],
        [
            "Important is that.",
            "You may, for example, the difference in the number of rewards this color is collected has the following order optimal has the highest number of rewards.",
            "Then smaller and smaller, but then if you can look at what amount of information they learn."
        ],
        [
            "You will see that the order is reversed.",
            "The optimal learns the smallest amount of information, and the worst one has the highest amount of information loop.",
            "So that's exactly illustration of result."
        ],
        [
            "I showed that there in theory I also we also apply this to learning in neural cell assemblies and let's experiment with report in the conference this summer, but I'm not going to tell you about that, so that's it."
        ],
        [
            "Any questions?",
            "Quick question.",
            "Was wondering.",
            "This information anything to do with exploration and see that there's.",
            "Yeah, of course, explore exploration is controlled by noise that's remember.",
            "If you don't have full information, you have to explore and that represents that.",
            "All your actions have non zero probabilities in the optimal distribution.",
            "The question is how random are they?",
            "And of course the answer is given by this critic potentials.",
            "So your constraint define your optimal temperature and these are constraints on information or constraints on your expected value.",
            "So would you say that that your approach is an answer to the exploration exploitation?",
            "Yes, yes it is.",
            "It's a kind of similar to you know they disjecta algorithm, which is locally optimal and globally optimal.",
            "So to answer your question here."
        ],
        [
            "Here is the graph that defines.",
            "So remember I mentioned about trajectory approach and wavefront approach to optimization, so this is very similar to punch wagons.",
            "Trajectory approach but now in the space of probabilities.",
            "So my my state space is a space of probabilities overtime.",
            "Well this call it was published quite a long time ago, but it's not.",
            "We have to convince people because they reviews very often mentioned you.",
            "Some git.",
            "An index on exploration, exploitation and strategies which are parametric.",
            "And if you try to say this is not parametric, there's parameters determines from your experience.",
            "It's of course not.",
            "Requires a little bit of overcoming traditional I think constraints, but of course it's these solutions are they?",
            "Have they become more complex as you start considering specific examples.",
            "So for example, this is a gift distribution for the entropy, but if you start, for example, optimizing Shannon information.",
            "The problem is the Shannon information has a reference as the reference of Shannon.",
            "So the distribution which include diversions refer to is the independent.",
            "So independent distributions and diversions from independent.",
            "So in fact, you kind of minimize two entropies there, so it's not as straightforward.",
            "But the results of information value theory say that asymptotically, in fact, these approaches are the same.",
            "So there are theorems on hardly Boltzmann Shannon information value an asymptomatically they're the same.",
            "Of course, we want to.",
            "I would.",
            "I'm interested in a simplistic theory.",
            "I want to be locally optimal.",
            "Of course, a simplistic theory is interesting, but.",
            "North when I have to do to snow.",
            "Sorry, yeah, thank you, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Good morning everybody.",
                    "label": 0
                },
                {
                    "sent": "My name is Roman Bill Atkin and I'm based in London and Middlesex University.",
                    "label": 1
                },
                {
                    "sent": "It's very nice morning and.",
                    "label": 0
                },
                {
                    "sent": "I would like to talk today about slightly.",
                    "label": 0
                },
                {
                    "sent": "Probably unusual approach to these problems.",
                    "label": 0
                },
                {
                    "sent": "I will not talk about time evolution of of learning systems, but I will talk about information evolution.",
                    "label": 1
                },
                {
                    "sent": "And later, of course, we'll try to translate this to time evolution and.",
                    "label": 0
                },
                {
                    "sent": "So that's pro.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The forward is.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This work, of course, is related to all that you use, as well as a Bayesian estimation and choice under uncertainty, which has been largely developed in the beginning of 40s and 50s.",
                    "label": 0
                },
                {
                    "sent": "As a theory of statistical statistical decision, decision making, and.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Of course, optimization is related to variational analysis, and optimal control has developed as a subfield of that, with the maximum principle of Pendragon, which is a trajectory methods for estimating the optimal solution.",
                    "label": 1
                },
                {
                    "sent": "So if you imagine immediamente that you're trying to.",
                    "label": 0
                },
                {
                    "sent": "In this medium, compute the optimal trajectory which is connected to points.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of course, that approach turned out to be quite difficult for stochastic control where.",
                    "label": 0
                },
                {
                    "sent": "Trajectory is or not so useful.",
                    "label": 0
                },
                {
                    "sent": "Not not.",
                    "label": 0
                },
                {
                    "sent": "Didn't seem to be so obvious and Bellman approach which is similar to propagation of disturbances of light and Fermat theory.",
                    "label": 0
                },
                {
                    "sent": "It's away so called Wavefront approach which is solved by partial differential equations and of course the discrete version of that is Bellman difference equation.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the significant development in this area was the theory of conditional Markov processes, which was developed by certain notion.",
                    "label": 1
                },
                {
                    "sent": "The end of 50s.",
                    "label": 0
                },
                {
                    "sent": "With essentially, any process can be represented as a conditional Markov process in the higher dimensional phase space.",
                    "label": 0
                },
                {
                    "sent": "And because it's a Markov process, it's very easy to translate it's partial differential equations.",
                    "label": 0
                },
                {
                    "sent": "And then you can achieve stochastic optimal control.",
                    "label": 1
                },
                {
                    "sent": "The problem problem of optimal nonlinear filtering was solved.",
                    "label": 1
                },
                {
                    "sent": "An particular case of that was a linear filter, which you know is a common VC, but in fact you total story says that common attended conference in Moscow in 1960 where Stratonovich reported his results of 1959, where as an example of linear case he showed Kalman filter equations but.",
                    "label": 0
                },
                {
                    "sent": "Of course.",
                    "label": 0
                },
                {
                    "sent": "Doesn't produce contribution of common we see, and it's a very popular in engineering.",
                    "label": 0
                },
                {
                    "sent": "Another important development, something that I'm typically interested in.",
                    "label": 0
                },
                {
                    "sent": "Of course.",
                    "label": 0
                },
                {
                    "sent": "Information theory.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And that's in fact the area where the variational approaches that you're talking about.",
                    "label": 0
                },
                {
                    "sent": "Quite often here were first applied.",
                    "label": 0
                },
                {
                    "sent": "They were applied to estimate the maximum channel capacity, and Kolmogorov Giants holes define the maximum entropy principle and certain knowledge also use them to estimate the maximum useful value of information.",
                    "label": 0
                },
                {
                    "sent": "So the problem is this.",
                    "label": 0
                },
                {
                    "sent": "If you suppose you try to estimate your development of your system based on probability and using dynamic programming method.",
                    "label": 0
                },
                {
                    "sent": "For example, you of course know that on each step you estimating the expectation.",
                    "label": 0
                },
                {
                    "sent": "Of course on the last step you estimating expectation given that the previous steps was estimated.",
                    "label": 0
                },
                {
                    "sent": "And of course on that last step, our estimation is a linear function.",
                    "label": 0
                },
                {
                    "sent": "Of course, if you do a second estimation, your function already becomes nonlinear.",
                    "label": 0
                },
                {
                    "sent": "So of course, that's why dynamic programming problems there.",
                    "label": 0
                },
                {
                    "sent": "Nonlinearly, they describe nonlinear processes, but the problem is this, if I know that probability Markov transition probability is anything to learn for me, anifah compute, let's say 1000 steps ahead.",
                    "label": 0
                },
                {
                    "sent": "What will happen on the next step when I find out that my probability estimation was actually wrong, do I have to recompute all that expensive computations?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "It.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "These are that learning and adaptation is only related to situations when you don't know these probabilities exactly, so optimal control is about predicting what happens to the system like a missile when you know your system.",
                    "label": 0
                },
                {
                    "sent": "But if you don't know if you have a model free system.",
                    "label": 0
                },
                {
                    "sent": "These equations actually do not describe my situation.",
                    "label": 0
                },
                {
                    "sent": "So here's a couple.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Propositions first.",
                    "label": 0
                },
                {
                    "sent": "Of all is there is no need to learn if there is nothing to optimize.",
                    "label": 1
                },
                {
                    "sent": "Why do you have to?",
                    "label": 0
                },
                {
                    "sent": "And that's quite extreme extreme, of course.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Next proposition that there is nothing new to learn if you know if your information is complete.",
                    "label": 1
                },
                {
                    "sent": "So you can then predict what will happen to the system.",
                    "label": 0
                },
                {
                    "sent": "But if you know the probability it's not, there's no learning there because you know the information.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now I will start now a little bit overview of theory of optimization and it actually related to the theory of choice.",
                    "label": 0
                },
                {
                    "sent": "The most fundamental concept in theory of choices, prefer insulation.",
                    "label": 0
                },
                {
                    "sent": "We work with functions here, but in fact we don't eat probabilities.",
                    "label": 0
                },
                {
                    "sent": "We don't eat values of utility functions.",
                    "label": 0
                },
                {
                    "sent": "We eat apples, which these utilities are defined on.",
                    "label": 0
                },
                {
                    "sent": "So preference relation is a binary relation which is total and transitive.",
                    "label": 1
                },
                {
                    "sent": "And total means it's also reflective.",
                    "label": 0
                },
                {
                    "sent": "So in fact it is a preorder preorder which is total.",
                    "label": 0
                },
                {
                    "sent": "This is a very nice object, in fact, because.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It gives you immediately at apology.",
                    "label": 0
                },
                {
                    "sent": "It's Alexander topology, which in which open set is a system of upper sets plus empty set, and the set itself.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In fact, the finest topology is also discrete topology, and because we have a topology, it means your set is measurable.",
                    "label": 0
                },
                {
                    "sent": "You have a board of Sigma algebra.",
                    "label": 0
                },
                {
                    "sent": "A lot of the series I'm telling you today will tell you.",
                    "label": 0
                },
                {
                    "sent": "In fact, I have developed in category of preorders not even going to functions because I decided to stay at the levels of apples.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And there are many interesting results which I'm not going to tell you here, but one of them is for example.",
                    "label": 0
                },
                {
                    "sent": "Describing the arrows in this category and function is monotone with respect to pre orders means it's continuous with respect to apologies.",
                    "label": 0
                },
                {
                    "sent": "Continue to means immeasurable and measurable means it's monotone.",
                    "label": 0
                },
                {
                    "sent": "So you have everything in some in some sense.",
                    "label": 0
                },
                {
                    "sent": "So many things I can develop can be developed on these errors, but of course.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Applications, especially when the sets are very large.",
                    "label": 0
                },
                {
                    "sent": "When I have many apples, I cannot really put all apples into pairs, is quite convenient to create tables.",
                    "label": 0
                },
                {
                    "sent": "Numerical tables representing these preferences which are called functions, and these utility functions is a monotone functions which embed my pre order into the order on real line.",
                    "label": 0
                },
                {
                    "sent": "It turns out that not all prefer insulations can be embedded like this, but we will talk about about this, but in fact everything will talk today about this particular class.",
                    "label": 0
                },
                {
                    "sent": "Or prefer installations because we'll talk about functions now.",
                    "label": 0
                },
                {
                    "sent": "What type of?",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Functions will talk about.",
                    "label": 0
                },
                {
                    "sent": "All discuss dual spaces of functions.",
                    "label": 1
                },
                {
                    "sent": "And these two functions will be defined on the same set.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The spaces cover can have different structure.",
                    "label": 0
                },
                {
                    "sent": "They in fact, yeah.",
                    "label": 0
                },
                {
                    "sent": "Into the example reference relationship, which cannot be included in lexicographic continuous continuous lexicographic preference solution.",
                    "label": 0
                },
                {
                    "sent": "For example, and you arrange so basically to make prefer insulation represent by real function, you must have in this preferred solution or the dense countable subset.",
                    "label": 0
                },
                {
                    "sent": "And if you I can give you more precise definition.",
                    "label": 0
                },
                {
                    "sent": "Looks a little bit, but that's technicality.",
                    "label": 0
                },
                {
                    "sent": "But the interesting thing that real numbers is the only completely ordered field.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "It makes his question, do you really need preference relations which are not representable?",
                    "label": 0
                },
                {
                    "sent": "OK so I will be coupling functions in these two spaces through a Hilbert space.",
                    "label": 0
                },
                {
                    "sent": "This is a Gelfand triple.",
                    "label": 0
                },
                {
                    "sent": "And these functions of these spaces can have different metrics.",
                    "label": 0
                },
                {
                    "sent": "They I hope they're reflexive, but I need linear bilinear form.",
                    "label": 1
                },
                {
                    "sent": "The coupling function is be linear, which is for example example is the inner product and why I'm interested in the product.",
                    "label": 1
                },
                {
                    "sent": "Is this of course, because we expect.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Value that all we tried to maximize easily in the product.",
                    "label": 0
                },
                {
                    "sent": "Function wise supposed to function which is added to additive to one and X is my utility of course.",
                    "label": 0
                },
                {
                    "sent": "Now I will when when I don't have uncertainty, I just optimize my function, but if I have uncertainties here then in fact my choice set is the choice of probability functions parameter parameterized by some values which I don't know and in fact.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You have to consider space of all functions like that.",
                    "label": 0
                },
                {
                    "sent": "Here is an example that I will use quite often.",
                    "label": 0
                },
                {
                    "sent": "It's a simplex or probability triangle.",
                    "label": 1
                },
                {
                    "sent": "So suppose you have a set of three elements, so you have three probabilities.",
                    "label": 0
                },
                {
                    "sent": "Of course, the one probability can be computed from two others.",
                    "label": 0
                },
                {
                    "sent": "So by XI represent one probability by wire, present third probability and the second probability somewhere there.",
                    "label": 1
                },
                {
                    "sent": "So the totality of all probabilities, the triangle.",
                    "label": 0
                },
                {
                    "sent": "For example, the constant uniform probability is the point in the middle here.",
                    "label": 0
                },
                {
                    "sent": "White expected value is useful becausw it coincides with my utility in the Delta functions.",
                    "label": 0
                },
                {
                    "sent": "And in fact, by Norman Morganstein proved that the only function that satisfies the continuous in the other assumptions is.",
                    "label": 0
                },
                {
                    "sent": "In fact there are fine function or linear function on probabilities.",
                    "label": 0
                },
                {
                    "sent": "However, there is a paradox.",
                    "label": 1
                },
                {
                    "sent": "If your choice set includes the Delta functions.",
                    "label": 0
                },
                {
                    "sent": "Do you really have uncertainties?",
                    "label": 0
                },
                {
                    "sent": "I can just choose this the most the best.",
                    "label": 0
                },
                {
                    "sent": "In real problems we choose from a subset of these probabilities and I will talk today about this subset.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I will need to something a little bit refreshing your memory or maybe give some definitions about convex functions, because I will concentrate on convex subsets.",
                    "label": 0
                },
                {
                    "sent": "And of course, if it's not convex, you can always convexified it and after first or second Legendre transform you know it becomes convex anyway.",
                    "label": 0
                },
                {
                    "sent": "So convex function, that's the definition.",
                    "label": 0
                },
                {
                    "sent": "Of course the the point on the middle of the interval gives you smaller value than the mixture of the.",
                    "label": 0
                },
                {
                    "sent": "On the right side, and it's important that these functions can go to Infinity, so these are convex functions which can go into Infinity, but the area on which they are not infinite is called affective domain, and if it's nonempty, I call these functions proper.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Example information divergent, so could make that Libya diversions that we've all considered.",
                    "label": 0
                },
                {
                    "sent": "For example, it's a lab rhythmic deviation of 1 function from another, which is a cool initial or reference.",
                    "label": 0
                },
                {
                    "sent": "And in fact, this is a convex functional of Y.",
                    "label": 0
                },
                {
                    "sent": "In fact, it's also very nice because it's strictly convex.",
                    "label": 0
                },
                {
                    "sent": "It means it has unique minimum.",
                    "label": 0
                },
                {
                    "sent": "You don't need to have this.",
                    "label": 0
                },
                {
                    "sent": "In fact, functions normalized.",
                    "label": 0
                },
                {
                    "sent": "So in probability theory we have normalized, but there are many examples.",
                    "label": 0
                },
                {
                    "sent": "When, for example, this measure is a lebec measure which is not normalized to one.",
                    "label": 0
                },
                {
                    "sent": "In that case, this becomes minus entropy.",
                    "label": 0
                },
                {
                    "sent": "If of course, for example here you have joint probability and this is product of marginals, then this becomes Shannon information.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's just an example of quality functions, but I'm not going to just concentrate.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Him.",
                    "label": 0
                },
                {
                    "sent": "Something's about 1X functions is for or there for some conditions that can be shown to be continuous on the on the interior of this domain.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Strictly convex functions, I repeat, has unique minimum global minimum.",
                    "label": 0
                },
                {
                    "sent": "And that's the proof.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And I will also use notion of sub differential is slightly generalization of differential.",
                    "label": 0
                },
                {
                    "sent": "The things that I don't need really that my functions to be differential, that every point.",
                    "label": 0
                },
                {
                    "sent": "It's not that I have continues, but if they're not differential, some points that I will consider a set of all support hyperplanes, hyperplanes.",
                    "label": 0
                },
                {
                    "sent": "So it means in some sense derivative differential is not uniquely defined on some points, so you have an angle and then you can have some several hyperplanes of supports if its differentiable then my subdifferential let's say at this point is a Singleton.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A set of one in it.",
                    "label": 0
                },
                {
                    "sent": "OK so I remember reminding you of memory that I will be interested in subsets of functions.",
                    "label": 0
                },
                {
                    "sent": "So it is interesting to talk about so called polar subsets of sets.",
                    "label": 0
                },
                {
                    "sent": "So Quantics Boyer phonics set is a set that two for two points appoint on the segment belongs to the.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To this voting.",
                    "label": 0
                },
                {
                    "sent": "First of all, I would each convex set is characterized by unique support function.",
                    "label": 0
                },
                {
                    "sent": "Which is defined as follows.",
                    "label": 0
                },
                {
                    "sent": "Suppose we have a subset convex subset in SpaceX.",
                    "label": 0
                },
                {
                    "sent": "So now given the function in the conjugate space Y, the support is a maximum of inner product over X which belong to this subset.",
                    "label": 0
                },
                {
                    "sent": "And basically, if you imagine the ball, then you in the product is maximized.",
                    "label": 0
                },
                {
                    "sent": "You move as close as possible to the surface, and that's a hyperplane of support.",
                    "label": 0
                },
                {
                    "sent": "This function is called mixed and it's first order homogeneous.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can also define something called the distance function in this context set.",
                    "label": 0
                },
                {
                    "sent": "That's a function.",
                    "label": 0
                },
                {
                    "sent": "That's a function that gives you a scale parameter by which you have to increase your context set to approach a point from the center.",
                    "label": 0
                },
                {
                    "sent": "So for example, if you're convex set is a unit ball and there is a point somewhere, the distance from the center at this point is the factor by which you have to increase this ball to reach this point.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now two sets are called polar.",
                    "label": 0
                },
                {
                    "sent": "If support of one is the distance of another.",
                    "label": 1
                },
                {
                    "sent": "What it means is that in fact you can relate these two functions to support of two polar sets by genre transform.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for the moment I will forget about the condition.",
                    "label": 0
                },
                {
                    "sent": "Remember I defined support as a supremum, where X belong to myself.",
                    "label": 0
                },
                {
                    "sent": "But now what I do in fact I just constrain the distance of the dual set.",
                    "label": 0
                },
                {
                    "sent": "And the.",
                    "label": 0
                },
                {
                    "sent": "That's already better.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Finds us some problems in convex optimization.",
                    "label": 0
                },
                {
                    "sent": "I also have a can represent them as a dual problems.",
                    "label": 0
                },
                {
                    "sent": "In fact, here X that satisfies the supremum can be found using this problem by minimizing this convex function with the constraint on the linear functional.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And you can re late.",
                    "label": 0
                },
                {
                    "sent": "As I mentioned, these two convex functions through legions form which looks like this.",
                    "label": 0
                },
                {
                    "sent": "And of course, the condition of extremely satisfied on X belongs to subdifferential one function and why belongs to sub differential of another.",
                    "label": 0
                },
                {
                    "sent": "That means that in fact sub differentials are inverse functions of each other.",
                    "label": 0
                },
                {
                    "sent": "In fact, it's in these Murphys.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Among these, your context function is monotone, strictly more convex then your sub differential will always be strictly monotone function.",
                    "label": 0
                },
                {
                    "sent": "Now what is the condition of the extreme right?",
                    "label": 0
                },
                {
                    "sent": "So in my subset I want to find that point which gives me the maximum of my linear functional, which if you remember, gives me maximum expected value.",
                    "label": 0
                },
                {
                    "sent": "It's very straightforward.",
                    "label": 0
                },
                {
                    "sent": "That's a generalization of contactor theorem.",
                    "label": 0
                },
                {
                    "sent": "So basically you're you define LaGrange multiplier, which is related to your constraint.",
                    "label": 0
                },
                {
                    "sent": "Now, beta X belongs to sub differential of your context function at your extremum than other condition condition of extreme that your functional must reach.",
                    "label": 0
                },
                {
                    "sent": "So basically you can strain your context functional, but obviously linear functional achieves the maximum on the boundary.",
                    "label": 0
                },
                {
                    "sent": "It will never achieve maximum linear because it's linear.",
                    "label": 0
                },
                {
                    "sent": "It will never achieve the maximum.",
                    "label": 0
                },
                {
                    "sent": "In theory it's always on the boundary, so that represents the boundary and in fact your LaGrange multipliers determined as a derivative of 1 constraint.",
                    "label": 0
                },
                {
                    "sent": "With respect to another.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To prove it.",
                    "label": 0
                },
                {
                    "sent": "You have to write Lagrangian function.",
                    "label": 0
                },
                {
                    "sent": "Take this sub differential over Y that gives you first condition zero must belong to this sub differential.",
                    "label": 0
                },
                {
                    "sent": "Another condition is differentiated by beta that gives a second constraint.",
                    "label": 0
                },
                {
                    "sent": "And thinking about this function as G of C. Differentiating this Lagrangian by C gives you the last relation.",
                    "label": 0
                },
                {
                    "sent": "So now I know how my optimal Huawei which in fact.",
                    "label": 0
                },
                {
                    "sent": "Will be a probability distribution.",
                    "label": 0
                },
                {
                    "sent": "Is characterized.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here's an example.",
                    "label": 0
                },
                {
                    "sent": "If my convex function is the entropy or relative entropy.",
                    "label": 0
                },
                {
                    "sent": "Then I can very quickly write the following.",
                    "label": 0
                },
                {
                    "sent": "By the way, this this thing appears.",
                    "label": 0
                },
                {
                    "sent": "Here is additional constraint that my function is additive to one.",
                    "label": 0
                },
                {
                    "sent": "It's just normalization.",
                    "label": 0
                },
                {
                    "sent": "And let's give you this equation.",
                    "label": 0
                },
                {
                    "sent": "If Y is constant, this is in fact the Gibbs distribution.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "You know now that this in fact appears as a solution of this extreme external problem.",
                    "label": 0
                },
                {
                    "sent": "Now, if for example, my utility function is minus Euclidean distance, then it is a Gaussian distribution.",
                    "label": 0
                },
                {
                    "sent": "If it's something else, like for example number of events, but I'm that become persona everything.",
                    "label": 0
                },
                {
                    "sent": "So all distributions we have in fact just appear by substituting different utility functions.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "He rose again, returning to this triangle so that circle here represents a level of constant entropy, and they are extremely here that I mentioned that there are extreme and it turns out that linear functional in fact has two extreme ones that correspond to maximum.",
                    "label": 0
                },
                {
                    "sent": "Another response to minimum.",
                    "label": 0
                },
                {
                    "sent": "And they correspond to positive and negative values of this parameter beta.",
                    "label": 0
                },
                {
                    "sent": "By the way, beta inverse is the temperature that just heard on the previous talk.",
                    "label": 0
                },
                {
                    "sent": "And temperature can be negative in this problems.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "We I would like now the the most important thing I would like to tell you today is this characterization of this solution.",
                    "label": 0
                },
                {
                    "sent": "An understanding of this comes when you in fact forget about that.",
                    "label": 0
                },
                {
                    "sent": "It's a probability or anything else.",
                    "label": 0
                },
                {
                    "sent": "If you constrain your convex functional by somewhere by some value, it's clear that your linear functional your.",
                    "label": 0
                },
                {
                    "sent": "In the product cannot have infinite value.",
                    "label": 0
                },
                {
                    "sent": "If it does, it means that your hyperplane dissect your domain.",
                    "label": 0
                },
                {
                    "sent": "OK, So what I would but The thing is that my.",
                    "label": 0
                },
                {
                    "sent": "I want to use functions like utility functions which can have infinite values on some measure non 0.",
                    "label": 0
                },
                {
                    "sent": "So what will happen with my optimal solution in the case?",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "First theorem my linear function will not have infinite values, even only if everywhere where my utility function or this function is infinite.",
                    "label": 0
                },
                {
                    "sent": "The other is 0.",
                    "label": 0
                },
                {
                    "sent": "That means that non zero values imply finite values of utility.",
                    "label": 0
                },
                {
                    "sent": "How to prove it?",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of course, you just use convention that Infinity by zero is 0 and then you just split your linear functional into parts where you have none.",
                    "label": 0
                },
                {
                    "sent": "Listen where you have inflated together 0 so the result is a finite value.",
                    "label": 0
                },
                {
                    "sent": "Conversely, by convention that the sum of infringes gives you minus Infinity.",
                    "label": 0
                },
                {
                    "sent": "You end up with infinite value.",
                    "label": 0
                },
                {
                    "sent": "So what it means in translating into language of probability, it means the optimal solution is such when non zero probabilities correspond.",
                    "label": 0
                },
                {
                    "sent": "All need to find values of utility.",
                    "label": 0
                },
                {
                    "sent": "Now there is a stronger current.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Azatian suppose that you are convex.",
                    "label": 0
                },
                {
                    "sent": "Functional, has unique minimum.",
                    "label": 0
                },
                {
                    "sent": "That means, for example, that that's true for strictly convex function.",
                    "label": 0
                },
                {
                    "sent": "So and for for any function X, if your optimal solution has zero.",
                    "label": 0
                },
                {
                    "sent": "That means that your X that you have chosen at that point is proportional to the minimum.",
                    "label": 0
                },
                {
                    "sent": "The unique minimum of the value of of your unique minimum minimum function in that on that element.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The proof is quite simple.",
                    "label": 0
                },
                {
                    "sent": "It basically just show that you're you have a local minimum and then on that particular coordinate.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Example.",
                    "label": 0
                },
                {
                    "sent": "Why's it important?",
                    "label": 0
                },
                {
                    "sent": "So I returning back to probability.",
                    "label": 0
                },
                {
                    "sent": "So now I have again my.",
                    "label": 0
                },
                {
                    "sent": "Cool big divergance as a one functional its conjugate.",
                    "label": 0
                },
                {
                    "sent": "Is has this form and in fact it is the.",
                    "label": 0
                },
                {
                    "sent": "This is the partition function.",
                    "label": 0
                },
                {
                    "sent": "This is locked partition function.",
                    "label": 0
                },
                {
                    "sent": "It's minimum global minimum is constant minus Infinity.",
                    "label": 0
                },
                {
                    "sent": "So what this theorem tells you that in your optimal solution zero probabilities.",
                    "label": 0
                },
                {
                    "sent": "Imply infinite values of your utility function.",
                    "label": 0
                },
                {
                    "sent": "That means zeros and infinities are in one to one correspondence.",
                    "label": 0
                },
                {
                    "sent": "The important consequences that, for example, if your ex your function is defined on the space of say, let's say observations and controls, that means that your controls none of your controls can have a zero probability.",
                    "label": 0
                },
                {
                    "sent": "That means a completely stochastic process.",
                    "label": 0
                },
                {
                    "sent": "I mean, you can have zero probability for some controller for some estimation, But then it will not be optimal.",
                    "label": 0
                },
                {
                    "sent": "And I remember Peter's nugget that he put into his estimations and they become better.",
                    "label": 0
                },
                {
                    "sent": "That's just why it happens.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "Now, if I know my optimal solution, I can in fact straightaway forget about all non optimal solutions and given my utility functions I know how the optimal looks.",
                    "label": 0
                },
                {
                    "sent": "I will now define characteristics potentials which are not now functions defined on the vector spaces, but there are functions defined on this color on the real value they just parameterized by better, so I only now work in the space of my optimal solutions.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I defined two characteristic potentials there with defined with respect to my convex functionals which can be anything.",
                    "label": 0
                },
                {
                    "sent": "But",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What what, what the heck?",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To do is the following, in fact, as illusions form, I can now define what is my maximum value, for example of 1 function with respect to constraint to another.",
                    "label": 0
                },
                {
                    "sent": "And it is basically given by derivative of one of these.",
                    "label": 0
                },
                {
                    "sent": "Potentials and this is just is just a function you can find and.",
                    "label": 0
                },
                {
                    "sent": "In fact you can find the inverse.",
                    "label": 0
                },
                {
                    "sent": "So to destroy this I will now show.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Examples.",
                    "label": 0
                },
                {
                    "sent": "Using probability, so my first function will be again my cool big Libya diversions.",
                    "label": 0
                },
                {
                    "sent": "And its conjugate, as I mentioned, this has this form.",
                    "label": 0
                },
                {
                    "sent": "I will consider the divergent with respect to the back measure.",
                    "label": 0
                },
                {
                    "sent": "So in fact my divergences now minus entropy.",
                    "label": 0
                },
                {
                    "sent": "So just to simplify things in that setting, the second potential is in fact this free energy that you talked about here quite often.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's consider first case.",
                    "label": 0
                },
                {
                    "sent": "We have a finite set of two elements.",
                    "label": 0
                },
                {
                    "sent": "Hourly back measure is just accounting measure 1.",
                    "label": 0
                },
                {
                    "sent": "An it means our utility function can have at most two values and I define them C -- D, C plus D just to have it.",
                    "label": 0
                },
                {
                    "sent": "Symmetric sees the center.",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                },
                {
                    "sent": "And I write all these functions immediately and I define how my maximum value of my expected value depends on parameter beta.",
                    "label": 0
                },
                {
                    "sent": "That means I can invert it and compute better from the constraint on the expected value.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Example, Now let's say AB Continuum.",
                    "label": 0
                },
                {
                    "sent": "Now these days is lebec measure and now my utility functions has various in the interval or which is subset of real line.",
                    "label": 0
                },
                {
                    "sent": "Doesn't matter, I just write new equations, just slightly different.",
                    "label": 0
                },
                {
                    "sent": "And that's my egg in my final function.",
                    "label": 0
                },
                {
                    "sent": "And here is the graph.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So these two functions.",
                    "label": 0
                },
                {
                    "sent": "So here you can see this parameter beta, which I'm only care about.",
                    "label": 0
                },
                {
                    "sent": "That's the LaGrange multiplier and that's the maximum value of your extreme value of your expectation.",
                    "label": 0
                },
                {
                    "sent": "This line represents a case of final set of two elements.",
                    "label": 0
                },
                {
                    "sent": "This case represents.",
                    "label": 0
                },
                {
                    "sent": "This function is a case of uncountable set which corresponds to infinite dimensional space.",
                    "label": 0
                },
                {
                    "sent": "So everything else in between is there so you can see, but it's very nice functions I can also.",
                    "label": 0
                },
                {
                    "sent": "Means that if I give a constraint on my let's say average error.",
                    "label": 0
                },
                {
                    "sent": "I know immediately what my optimal parameter is.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The temperature.",
                    "label": 0
                },
                {
                    "sent": "You can also have the same functions for the information, so that's again better and that's information in the first case, and that's information in the second case information information.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's not mention the dynamics.",
                    "label": 0
                },
                {
                    "sent": "So I assume now that I now actually care about time.",
                    "label": 0
                },
                {
                    "sent": "And as I learn, let's say my constraints change as some monotonic function of time.",
                    "label": 0
                },
                {
                    "sent": "Let's say my information increases C or my my performance increases.",
                    "label": 0
                },
                {
                    "sent": "My average utility increases.",
                    "label": 0
                },
                {
                    "sent": "It took.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Without that, the sum of your utilities has the following upper bound.",
                    "label": 0
                },
                {
                    "sent": "It's a difference of your courtesy potentials on the endpoints, which characterized by bitter.",
                    "label": 0
                },
                {
                    "sent": "Determine from this constraints also your information.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Communitive information has the following lower bound.",
                    "label": 0
                },
                {
                    "sent": "So that means that's the maximum.",
                    "label": 0
                },
                {
                    "sent": "The best you can do, and that's the smallest information you need to learn to do that.",
                    "label": 0
                },
                {
                    "sent": "Of course, better here is determined from the function that I should just show you on the previous slide.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "All this, of course, you know an integral integral is maximized when each of the integrators maximized, and it's a function of better.",
                    "label": 1
                },
                {
                    "sent": "But I showed you before and it's a derivative of microchips potential, which gives me.",
                    "label": 0
                },
                {
                    "sent": "Immediately the gradient theorem.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Same happens for the second case.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now I would like like to explain this on my triangle again, so that's my space of probabilities and these are now level sets of my expected utility.",
                    "label": 0
                },
                {
                    "sent": "They are linear because it's a linear function of probability, remember.",
                    "label": 0
                },
                {
                    "sent": "So the point is that I want to move in this space somehow and if I move in some direction it means I change my information changes.",
                    "label": 0
                },
                {
                    "sent": "So equivalent of change with information gives me different change of expected utility.",
                    "label": 0
                },
                {
                    "sent": "So I want to maximize the change of my expected utility, but.",
                    "label": 0
                },
                {
                    "sent": "You know that by gradient it doesn't matter how I move, because it's only matters what are the difference on the on the.",
                    "label": 0
                },
                {
                    "sent": "Starting points, so what's the deal?",
                    "label": 0
                },
                {
                    "sent": "Why do I need to choose a trajectory?",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Because I also want to optimize the other thing.",
                    "label": 0
                },
                {
                    "sent": "The other thing is information.",
                    "label": 0
                },
                {
                    "sent": "I want to move.",
                    "label": 0
                },
                {
                    "sent": "In such a way that I don't learn as much as possible, so I want to achieve my change of utility with the smallest amount of information.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And that is achieved by the exponential family, and in that case this is in fact analogy offer brackets thrown problem in variation calculus where you want to achieve.",
                    "label": 0
                },
                {
                    "sent": "You want to compute the trajectory where a ball is falling between two points as fast as possible.",
                    "label": 0
                },
                {
                    "sent": "Here I want to achieve.",
                    "label": 0
                },
                {
                    "sent": "Trajectory that goes from one level of expected to another with the smallest information possible.",
                    "label": 0
                },
                {
                    "sent": "And that's control.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This equation.",
                    "label": 0
                },
                {
                    "sent": "How much time do I have?",
                    "label": 0
                },
                {
                    "sent": "About four minutes.",
                    "label": 0
                },
                {
                    "sent": "OK, I probably can mention this why algorithm in exponentials are so important?",
                    "label": 0
                },
                {
                    "sent": "I mentioned I derive the this results without going for general convex sets and functions, but I also mentioned The thing is that functions such as utility functions or probabilities in fact they're not really if they just consider only that they do not formally in space.",
                    "label": 1
                },
                {
                    "sent": "If you for example, multiply utility function by negative number, this function falls out of its place.",
                    "label": 0
                },
                {
                    "sent": "So understand that algebra of plus and plus and multiplication, they don't form linear space.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But it turns out that they form linear space in other algebras.",
                    "label": 1
                },
                {
                    "sent": "These are algebras over independent semirings and these are some rings where the addition is it important here to examples are Max is when you consider real functions and the operation of addition is a maximum.",
                    "label": 1
                },
                {
                    "sent": "An multiplication is plus constant zero is minus Infinity and 01.",
                    "label": 0
                },
                {
                    "sent": "Another it's important.",
                    "label": 1
                },
                {
                    "sent": "Simmering is positive functions with the operations Marks and multiplication.",
                    "label": 0
                },
                {
                    "sent": "These simmering, which in this algebra probabilities are linear space, and here utility functions are linear space.",
                    "label": 0
                },
                {
                    "sent": "By the way, in this semi algebra.",
                    "label": 0
                },
                {
                    "sent": "So in this in this algebra Max Plus bailment equation is linear.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And it turns out that the only is a morphism between these two semirings.",
                    "label": 0
                },
                {
                    "sent": "Is the exponent and the inverse is of course the logarithm.",
                    "label": 0
                },
                {
                    "sent": "That's why we have them so often these functions.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The applications of this I will just slightly mention that I'm quite interested in learning and I do a lot of cognitive modeling and I look into data of subjects or people or animals, how they learn, and in fact most of the ideas that I mentioned today, they come from data that is modeled by these models and important phenomena.",
                    "label": 0
                },
                {
                    "sent": "That's when we learn we have something called the probability matching.",
                    "label": 1
                },
                {
                    "sent": "So for example, we try to adapt towards high probability of rewards and low probability of punishments or something.",
                    "label": 0
                },
                {
                    "sent": "But it turns out this function is not identity.",
                    "label": 0
                },
                {
                    "sent": "So low probabilities are overmatched.",
                    "label": 0
                },
                {
                    "sent": "High probability of people under matched an to model this we introduce noise and in fact cognitive models use this.",
                    "label": 0
                },
                {
                    "sent": "Softmax gives distribution.",
                    "label": 1
                },
                {
                    "sent": "The question is what is the value of this noise parameter, the temperature?",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And if you consider, for example, how people learn in different stages as they go on, you will notice that this noise decreases with time.",
                    "label": 0
                },
                {
                    "sent": "So I propose that something along time ago to add the dynamic noise into models and what is the dynamics.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "From equations we've seen, it's related to two things to information, and you expected utility, but here's an experiment where I applied this.",
                    "label": 0
                },
                {
                    "sent": "This is experimental, very famous model, very famous experiment.",
                    "label": 0
                },
                {
                    "sent": "Yorkies Dotson experimented 100 years ago with mice and they trained them to exit.",
                    "label": 0
                },
                {
                    "sent": "Suggest particular door and they train them is different strengths of stimuli.",
                    "label": 0
                },
                {
                    "sent": "What they found was that the performance was not linear function of strength of stimuli, it was the called inverted U shape so it achieves the maximum performance at some point.",
                    "label": 0
                },
                {
                    "sent": "The fastest learning, but then as you increase the stimulate improvement performance drop that shows you that in fact your action selection algorithm depends on the values with which you reward.",
                    "label": 0
                },
                {
                    "sent": "And there's a relation to of my algorithm to the not only to information here is the graph of the.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Entropy.",
                    "label": 0
                },
                {
                    "sent": "As the mouse learns what I did I just attached this entropy directly to control noise temperature.",
                    "label": 0
                },
                {
                    "sent": "So the higher the uncertainty, the higher the noise.",
                    "label": 0
                },
                {
                    "sent": "The lower density is lower than us, so related information, but also it is related to these values of rewards.",
                    "label": 0
                },
                {
                    "sent": "To model this speak like this you need also the other relation.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And you have very nice correspondence with the data, not data from samples or it's actually data from real experiments with animals.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I also applied this to optimal action selection of agents.",
                    "label": 1
                },
                {
                    "sent": "Here I compare three agents, greedy Agent Maxim like maximum expected value, slightly noisy agent, but not the optimal and the one which I control by optimal trajectory strategy.",
                    "label": 0
                },
                {
                    "sent": "Here's the number of cycles.",
                    "label": 0
                },
                {
                    "sent": "And as they learn, the optimal agent is better, but what?",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Important is that.",
                    "label": 0
                },
                {
                    "sent": "You may, for example, the difference in the number of rewards this color is collected has the following order optimal has the highest number of rewards.",
                    "label": 0
                },
                {
                    "sent": "Then smaller and smaller, but then if you can look at what amount of information they learn.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You will see that the order is reversed.",
                    "label": 0
                },
                {
                    "sent": "The optimal learns the smallest amount of information, and the worst one has the highest amount of information loop.",
                    "label": 0
                },
                {
                    "sent": "So that's exactly illustration of result.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I showed that there in theory I also we also apply this to learning in neural cell assemblies and let's experiment with report in the conference this summer, but I'm not going to tell you about that, so that's it.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Any questions?",
                    "label": 0
                },
                {
                    "sent": "Quick question.",
                    "label": 0
                },
                {
                    "sent": "Was wondering.",
                    "label": 0
                },
                {
                    "sent": "This information anything to do with exploration and see that there's.",
                    "label": 0
                },
                {
                    "sent": "Yeah, of course, explore exploration is controlled by noise that's remember.",
                    "label": 0
                },
                {
                    "sent": "If you don't have full information, you have to explore and that represents that.",
                    "label": 0
                },
                {
                    "sent": "All your actions have non zero probabilities in the optimal distribution.",
                    "label": 0
                },
                {
                    "sent": "The question is how random are they?",
                    "label": 0
                },
                {
                    "sent": "And of course the answer is given by this critic potentials.",
                    "label": 0
                },
                {
                    "sent": "So your constraint define your optimal temperature and these are constraints on information or constraints on your expected value.",
                    "label": 0
                },
                {
                    "sent": "So would you say that that your approach is an answer to the exploration exploitation?",
                    "label": 0
                },
                {
                    "sent": "Yes, yes it is.",
                    "label": 0
                },
                {
                    "sent": "It's a kind of similar to you know they disjecta algorithm, which is locally optimal and globally optimal.",
                    "label": 0
                },
                {
                    "sent": "So to answer your question here.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here is the graph that defines.",
                    "label": 0
                },
                {
                    "sent": "So remember I mentioned about trajectory approach and wavefront approach to optimization, so this is very similar to punch wagons.",
                    "label": 0
                },
                {
                    "sent": "Trajectory approach but now in the space of probabilities.",
                    "label": 0
                },
                {
                    "sent": "So my my state space is a space of probabilities overtime.",
                    "label": 0
                },
                {
                    "sent": "Well this call it was published quite a long time ago, but it's not.",
                    "label": 0
                },
                {
                    "sent": "We have to convince people because they reviews very often mentioned you.",
                    "label": 0
                },
                {
                    "sent": "Some git.",
                    "label": 0
                },
                {
                    "sent": "An index on exploration, exploitation and strategies which are parametric.",
                    "label": 0
                },
                {
                    "sent": "And if you try to say this is not parametric, there's parameters determines from your experience.",
                    "label": 0
                },
                {
                    "sent": "It's of course not.",
                    "label": 0
                },
                {
                    "sent": "Requires a little bit of overcoming traditional I think constraints, but of course it's these solutions are they?",
                    "label": 0
                },
                {
                    "sent": "Have they become more complex as you start considering specific examples.",
                    "label": 0
                },
                {
                    "sent": "So for example, this is a gift distribution for the entropy, but if you start, for example, optimizing Shannon information.",
                    "label": 0
                },
                {
                    "sent": "The problem is the Shannon information has a reference as the reference of Shannon.",
                    "label": 0
                },
                {
                    "sent": "So the distribution which include diversions refer to is the independent.",
                    "label": 0
                },
                {
                    "sent": "So independent distributions and diversions from independent.",
                    "label": 0
                },
                {
                    "sent": "So in fact, you kind of minimize two entropies there, so it's not as straightforward.",
                    "label": 0
                },
                {
                    "sent": "But the results of information value theory say that asymptotically, in fact, these approaches are the same.",
                    "label": 0
                },
                {
                    "sent": "So there are theorems on hardly Boltzmann Shannon information value an asymptomatically they're the same.",
                    "label": 0
                },
                {
                    "sent": "Of course, we want to.",
                    "label": 0
                },
                {
                    "sent": "I would.",
                    "label": 0
                },
                {
                    "sent": "I'm interested in a simplistic theory.",
                    "label": 0
                },
                {
                    "sent": "I want to be locally optimal.",
                    "label": 0
                },
                {
                    "sent": "Of course, a simplistic theory is interesting, but.",
                    "label": 0
                },
                {
                    "sent": "North when I have to do to snow.",
                    "label": 0
                },
                {
                    "sent": "Sorry, yeah, thank you, thank you.",
                    "label": 0
                }
            ]
        }
    }
}