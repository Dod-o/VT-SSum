{
    "id": "dn75nx2tlxsbumxlnrg2szvitcvwtlyl",
    "title": "Dopamine type 2 receptors control inverse temperature beta for transition from perceptual inference to reinforcement learning",
    "info": {
        "author": [
            "Eunjeong Lee, National Institute of Mental Health (NIMH)"
        ],
        "published": "July 28, 2015",
        "recorded": "June 2015",
        "category": [
            "Top->Computer Science->Machine Learning",
            "Top->Computer Science->Artificial Intelligence",
            "Top->Social Sciences->Psychology",
            "Top->Social Sciences->Economics",
            "Top->Medicine->Neuroscience",
            "Top->Technology->Engineering->Electrical Engineering->Control Engineering"
        ]
    },
    "url": "http://videolectures.net/rldm2015_lee_reinforcement_learning/",
    "segmentation": [
        [
            "My name is Unjung.",
            "I'm walking in at Bruno back, slap in an IMHO.",
            "So today I'm going to talk about injection of dopamine type 2 antagonists, decrease inverse temperature in reinforcement learning."
        ],
        [
            "So just."
        ],
        [
            "Amazing during lunch time.",
            "You are used to it burger and chips but when you go to the restaurant there is long queue to wait.",
            "Then you need to choose an alternative option as like pizza here."
        ],
        [
            "So, is it like the example when we make a decision, in many situations we use both?",
            "Perceptual information an."
        ],
        [
            "Memory information gained through the reinforcement learning so."
        ],
        [
            "Today in this talk I'm going to focus on the role of dopamine in these two processes.",
            "In these two processes."
        ],
        [
            "So we use oculomotor sequential decision-making task.",
            "So first I'm going to simulate.",
            "1."
        ],
        [
            "One movement in a sequence.",
            "So if you look the green circle here.",
            "Nice.",
            "OK, very weak Chris Tucker here.",
            "After 500 millisecond later, two target with one stimulus will present.",
            "So just decide which one is more dominant."
        ],
        [
            "OK."
        ],
        [
            "So.",
            "If you select read as a dominant color, you are right.",
            "So we applied.",
            "Also, we varied the stimulus from 5050 to 65 to 65.",
            "Verse 35."
        ],
        [
            "Is easy choice."
        ],
        [
            "As you did anyone also decide One Direction at each stage of the sequence in a triangle.",
            "So here the.",
            "Anymore pics save the green circle for 500 milliseconds."
        ],
        [
            "Later, the stimulus with two target presented to the animal as well as you did just before then.",
            "Based on the dominant color here among."
        ],
        [
            "He can make suckered to the direction so if the monkey makes a car to the blue, that's correct, so.",
            "Anymore."
        ],
        [
            "Repeat three times."
        ],
        [
            "So if they make a three times correct movement at the end of the."
        ],
        [
            "Fire up the animal get viewer.",
            "Just as a reward.",
            "So each point anymore repeat the binomial distribution.",
            "Binomial decision-making which is right or left or up or down.",
            "So.",
            "If you, if they choose the wrong target at any point in the sequence, they were forced to back to the previous just previous fixation point, and they were shown a mix the color stimulus and then two choice target again.",
            "So this was repeated until they select the correct target.",
            "Maximum time movement.",
            "They can do that."
        ],
        [
            "So we also use here 8 possible sequences, so each panel shows each sequence.",
            "So one sequence contains 3 movement.",
            "Does an animal goes three different steps in each sequence at any moment anymore makes a decision based on either mix of the two colors or if the animal knows which is sequences in, then the animal can utilize knowledge of sequence to make a correct direction."
        ],
        [
            "So the task was carried out on the two conditions.",
            "First fixed condition, which is the stimulus of eye movement.",
            "So fixed for a correct, right?"
        ],
        [
            "Others then switch to new sequence and remains."
        ],
        [
            "Fixed again second condition."
        ],
        [
            "It is the random condition which is the sequence changes.",
            "Every trial."
        ],
        [
            "So in the random condition, the animal is forced to rely on the fixed fixation stimulus, which is here mixture of two colors to determine movement direction.",
            "So here the decision is based on immediately available perceptual information.",
            "In the fixed the condition after fuel consecutive trials of a Cuban sequence, the animal can utilize knowledge of sequence to determine the correct movement direction.",
            "So direction this season.",
            "Here is the based on the lawn sequence movement sequence information."
        ],
        [
            "So we are interested in the printers theater circuit because it it plays an important role in selecting appropriate action and optimizing the action.",
            "So this is a drawing of the nonhuman primate brain.",
            "So here left side is anterior portion right sided.",
            "Posterior portion of the stores are and venture down."
        ],
        [
            "Center so if we cut corners section the pinkish area shows the latter part of the prefrontal cortex.",
            "Yellowish area shows the lower part of the striatum.",
            "So."
        ],
        [
            "People we place the Chamber of of just over the lateral prefrontal cortex.",
            "So by that way we can access prefrontal uncertain at the same time."
        ],
        [
            "You not understand our data in detail.",
            "We applied reinforcement learning modern so here action value, current action value is equal the previous action Bella Plus learning rate times.",
            "We were the prediction error.",
            "So here the reward is if the monkey makes correct action is 1.",
            "If the monkey makes incorrect actions, then it's general."
        ],
        [
            "So the animal choice or curious is depend on the past outcomes and color bias, so here better.",
            "Music.",
            "So the action value.",
            "Yeah.",
            "Better and then color buyers multiplied by weight of the color buyers.",
            "So the parameter beta is the inverse temperature, which is a specified choice.",
            "Consistent deflect on the respond variability, thus if better is increased, which means that response variability is decreased if better.",
            "Which is not response variability increased.",
            "If data is decreased, which means response variability is increased.",
            "Decrease so here the C is chosen.",
            "Chosen action so if action is 1, which is correct one, then the C is 1 if the action is.",
            "If the monkey makes incorrect action then C is 0 action 2.",
            "So we."
        ],
        [
            "We extract the upper meters by minimizing the log likelihood equation.",
            "So how the how does Triton neurons represented the decision-making processes?"
        ],
        [
            "So I'm going to show you the result.",
            "Electrophysiological result, so here the general line.",
            "It's X axis shows the time.",
            "So general line here is synchronized with the stimulus onset.",
            "So Blue line show I showed the data from striatum and redline I showed here data is from prefrontal cortex.",
            "So actually in random condition the.",
            "Higher portion of the structure neurons actually correlated with a mixture of the two colors, then prefrontal cortex in our test."
        ],
        [
            "And in fix the condition.",
            "The higher the here Girellini synchronized with the movement onset, so the higher portion that the higher portion of the striatum neurons actually correlated with learned action value, then prefrontal cortex.",
            "So those are part of the striatum actually represent the value of actions driven by immediately available perceptor information or past the reinforcement."
        ],
        [
            "Values.",
            "So we are interesting.",
            "What's the role of dopamine in these two decision making processes?",
            "So we have in the.",
            "In the experiment, we have three steps, so first inject first let them let the monkey allow the behavior task and then injected drugs and then record.",
            "After injection so we compare pre injection.",
            "And post injection.",
            "Within the session.",
            "Also we compare the drug data first sailing data."
        ],
        [
            "So.",
            "1st I'm going to start with the data from random condition.",
            "So here X axis shows color bias which which is mix of the color two colors.",
            "So as you expected, 5050% of mixture means it's ambiguous stimulus.",
            "So monkeys performance shows translate that behavior.",
            "However, the if the color dominant colors more dominant colors, more dominant to One Direction than the monkey's performance was increased.",
            "In random condition."
        ],
        [
            "In the fixed condition.",
            "When the monkey knows which is sequences in the performance rate and increased.",
            "And also the reaction time getting faster then faster then the monkey knows the sequence.",
            "And also, although the stimulus itself is ambiguous, the monkeys performance shows higher.",
            "Correct rate.",
            "When so, thus, the monkey utilize a reinforcement learning from previous trials and immediately available information in the fixation stimulus."
        ],
        [
            "So when we inject dopamine type 2 antagonists into the lower part of the striatum.",
            "Actually.",
            "The when the monkey.",
            "Previously, the monkeys performances get higher, however, when you blocked the permit type 2 receptors, monkeys performance was decreased.",
            "Also, the reaction time couldn't be faster than before.",
            "Injection is like before injection.",
            "Interestingly, there is no changes.",
            "This is there are two lines.",
            "Suppose each other here, so in random condition there's no changes.",
            "When you apply to permit type 2 receptors.",
            "When we."
        ],
        [
            "Inject dopamine type 1.",
            "When we inject sale, when we inject Saline, there is no changes in random condition or so there is no changes in fixed condition."
        ],
        [
            "And also when we injected Obama, Taiwan and progress into the stores are part of stratum is like a sale in there is no changes in fixed condition and also in random condition."
        ],
        [
            "So.",
            "We want to understand what kind of parameters in this process are involved in.",
            "So as I previously showed you, we applied the reinforcement learning model.",
            "So better actually here.",
            "When we blocked the public type 2 receptors, actually better words decrease, which means noise level or reaction response variability actually increased."
        ],
        [
            "However.",
            "They will come now come out, which is the color by way of color buyers.",
            "There is no Chinese compare prior pre and post and running rate.",
            "Pre and post there were any changes so no changes in running, wait and wait or mixture of two colors.",
            "When we apply dopamine type 2 receptors.",
            "The Type 2 antagonist."
        ],
        [
            "So."
        ],
        [
            "The conclusion is.",
            "The plumbing pipe to antagonist injection impact performance.",
            "Accuracy and reaction times only when we, when the animal makes a decision based on the previous reinforcement."
        ],
        [
            "Reinforcement, which is in our case fixed condition.",
            "Also, there are no behavior effects with dopamine type one receptor antagonist or sale in administration, nor in the random condition with Obama Type 2 antagonists."
        ],
        [
            "And then we apply the reinforcement learning model, or effectors of the deployment Type 2 Antonius were on inverse temperature, which means the response variability actually increased.",
            "I."
        ],
        [
            "I would like to thank you thanks too.",
            "My mental Bruno and order two PhD student and then our steps scientist Andy.",
            "Thank you for your attention.",
            "Hi.",
            "For in your renforcement learning framework, it runs with current stimulus for the action, and so the sequence depends on this.",
            "The only comes through the prediction error.",
            "But the other case is actually I have done something similar in a different context, but in other cases based upon past sequence, what passed a transition that the monkey or subject could might make the prediction?",
            "So in other words, have you ever also tried to expand the states?",
            "Uh, including that the past sequence.",
            "Do you understand what I'm asking?",
            "So state means past sequence, so for instance, or that sometime in our daily life, based upon what you did, you kind of possibly to predict what you might do before the next things coming.",
            "So you're learning framework.",
            "You are including sort of a sequence dependencies through the value.",
            "But in other cases in other possibility is you could also make your states at somewhat expanded like a.",
            "Two step model.",
            "For instance you can spend so just curious.",
            "We didn't apply the state model like the kind of previous two step or three steps further.",
            "But that actually emitted into the action value.",
            "Heindl yeah maybe I guess yeah.",
            "I mean come to my poster, we can talk more detail Stacy pendency.",
            "Do the effect of the reaction times in the in the random case from the D2 antagonists.",
            "You only showed the reaction times in the in the in the fixed case random condition, so reaction time in random condition using the higher than pixel condition.",
            "Was it affected by the drugs?",
            "There is no effect in random.",
            "There is no significant effect in the reaction time.",
            "In random condition."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "My name is Unjung.",
                    "label": 0
                },
                {
                    "sent": "I'm walking in at Bruno back, slap in an IMHO.",
                    "label": 0
                },
                {
                    "sent": "So today I'm going to talk about injection of dopamine type 2 antagonists, decrease inverse temperature in reinforcement learning.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So just.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Amazing during lunch time.",
                    "label": 0
                },
                {
                    "sent": "You are used to it burger and chips but when you go to the restaurant there is long queue to wait.",
                    "label": 0
                },
                {
                    "sent": "Then you need to choose an alternative option as like pizza here.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So, is it like the example when we make a decision, in many situations we use both?",
                    "label": 0
                },
                {
                    "sent": "Perceptual information an.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Memory information gained through the reinforcement learning so.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Today in this talk I'm going to focus on the role of dopamine in these two processes.",
                    "label": 0
                },
                {
                    "sent": "In these two processes.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we use oculomotor sequential decision-making task.",
                    "label": 1
                },
                {
                    "sent": "So first I'm going to simulate.",
                    "label": 0
                },
                {
                    "sent": "1.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One movement in a sequence.",
                    "label": 0
                },
                {
                    "sent": "So if you look the green circle here.",
                    "label": 0
                },
                {
                    "sent": "Nice.",
                    "label": 0
                },
                {
                    "sent": "OK, very weak Chris Tucker here.",
                    "label": 0
                },
                {
                    "sent": "After 500 millisecond later, two target with one stimulus will present.",
                    "label": 0
                },
                {
                    "sent": "So just decide which one is more dominant.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "If you select read as a dominant color, you are right.",
                    "label": 0
                },
                {
                    "sent": "So we applied.",
                    "label": 0
                },
                {
                    "sent": "Also, we varied the stimulus from 5050 to 65 to 65.",
                    "label": 0
                },
                {
                    "sent": "Verse 35.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is easy choice.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As you did anyone also decide One Direction at each stage of the sequence in a triangle.",
                    "label": 1
                },
                {
                    "sent": "So here the.",
                    "label": 0
                },
                {
                    "sent": "Anymore pics save the green circle for 500 milliseconds.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Later, the stimulus with two target presented to the animal as well as you did just before then.",
                    "label": 0
                },
                {
                    "sent": "Based on the dominant color here among.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "He can make suckered to the direction so if the monkey makes a car to the blue, that's correct, so.",
                    "label": 0
                },
                {
                    "sent": "Anymore.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Repeat three times.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if they make a three times correct movement at the end of the.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Fire up the animal get viewer.",
                    "label": 0
                },
                {
                    "sent": "Just as a reward.",
                    "label": 0
                },
                {
                    "sent": "So each point anymore repeat the binomial distribution.",
                    "label": 0
                },
                {
                    "sent": "Binomial decision-making which is right or left or up or down.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "If you, if they choose the wrong target at any point in the sequence, they were forced to back to the previous just previous fixation point, and they were shown a mix the color stimulus and then two choice target again.",
                    "label": 0
                },
                {
                    "sent": "So this was repeated until they select the correct target.",
                    "label": 0
                },
                {
                    "sent": "Maximum time movement.",
                    "label": 0
                },
                {
                    "sent": "They can do that.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we also use here 8 possible sequences, so each panel shows each sequence.",
                    "label": 1
                },
                {
                    "sent": "So one sequence contains 3 movement.",
                    "label": 0
                },
                {
                    "sent": "Does an animal goes three different steps in each sequence at any moment anymore makes a decision based on either mix of the two colors or if the animal knows which is sequences in, then the animal can utilize knowledge of sequence to make a correct direction.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the task was carried out on the two conditions.",
                    "label": 0
                },
                {
                    "sent": "First fixed condition, which is the stimulus of eye movement.",
                    "label": 1
                },
                {
                    "sent": "So fixed for a correct, right?",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Others then switch to new sequence and remains.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Fixed again second condition.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It is the random condition which is the sequence changes.",
                    "label": 0
                },
                {
                    "sent": "Every trial.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in the random condition, the animal is forced to rely on the fixed fixation stimulus, which is here mixture of two colors to determine movement direction.",
                    "label": 1
                },
                {
                    "sent": "So here the decision is based on immediately available perceptual information.",
                    "label": 1
                },
                {
                    "sent": "In the fixed the condition after fuel consecutive trials of a Cuban sequence, the animal can utilize knowledge of sequence to determine the correct movement direction.",
                    "label": 0
                },
                {
                    "sent": "So direction this season.",
                    "label": 0
                },
                {
                    "sent": "Here is the based on the lawn sequence movement sequence information.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we are interested in the printers theater circuit because it it plays an important role in selecting appropriate action and optimizing the action.",
                    "label": 0
                },
                {
                    "sent": "So this is a drawing of the nonhuman primate brain.",
                    "label": 0
                },
                {
                    "sent": "So here left side is anterior portion right sided.",
                    "label": 0
                },
                {
                    "sent": "Posterior portion of the stores are and venture down.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Center so if we cut corners section the pinkish area shows the latter part of the prefrontal cortex.",
                    "label": 1
                },
                {
                    "sent": "Yellowish area shows the lower part of the striatum.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "People we place the Chamber of of just over the lateral prefrontal cortex.",
                    "label": 0
                },
                {
                    "sent": "So by that way we can access prefrontal uncertain at the same time.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You not understand our data in detail.",
                    "label": 0
                },
                {
                    "sent": "We applied reinforcement learning modern so here action value, current action value is equal the previous action Bella Plus learning rate times.",
                    "label": 1
                },
                {
                    "sent": "We were the prediction error.",
                    "label": 0
                },
                {
                    "sent": "So here the reward is if the monkey makes correct action is 1.",
                    "label": 1
                },
                {
                    "sent": "If the monkey makes incorrect actions, then it's general.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the animal choice or curious is depend on the past outcomes and color bias, so here better.",
                    "label": 1
                },
                {
                    "sent": "Music.",
                    "label": 0
                },
                {
                    "sent": "So the action value.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 1
                },
                {
                    "sent": "Better and then color buyers multiplied by weight of the color buyers.",
                    "label": 0
                },
                {
                    "sent": "So the parameter beta is the inverse temperature, which is a specified choice.",
                    "label": 1
                },
                {
                    "sent": "Consistent deflect on the respond variability, thus if better is increased, which means that response variability is decreased if better.",
                    "label": 0
                },
                {
                    "sent": "Which is not response variability increased.",
                    "label": 1
                },
                {
                    "sent": "If data is decreased, which means response variability is increased.",
                    "label": 0
                },
                {
                    "sent": "Decrease so here the C is chosen.",
                    "label": 0
                },
                {
                    "sent": "Chosen action so if action is 1, which is correct one, then the C is 1 if the action is.",
                    "label": 0
                },
                {
                    "sent": "If the monkey makes incorrect action then C is 0 action 2.",
                    "label": 0
                },
                {
                    "sent": "So we.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We extract the upper meters by minimizing the log likelihood equation.",
                    "label": 0
                },
                {
                    "sent": "So how the how does Triton neurons represented the decision-making processes?",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I'm going to show you the result.",
                    "label": 0
                },
                {
                    "sent": "Electrophysiological result, so here the general line.",
                    "label": 0
                },
                {
                    "sent": "It's X axis shows the time.",
                    "label": 0
                },
                {
                    "sent": "So general line here is synchronized with the stimulus onset.",
                    "label": 1
                },
                {
                    "sent": "So Blue line show I showed the data from striatum and redline I showed here data is from prefrontal cortex.",
                    "label": 0
                },
                {
                    "sent": "So actually in random condition the.",
                    "label": 1
                },
                {
                    "sent": "Higher portion of the structure neurons actually correlated with a mixture of the two colors, then prefrontal cortex in our test.",
                    "label": 1
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And in fix the condition.",
                    "label": 0
                },
                {
                    "sent": "The higher the here Girellini synchronized with the movement onset, so the higher portion that the higher portion of the striatum neurons actually correlated with learned action value, then prefrontal cortex.",
                    "label": 0
                },
                {
                    "sent": "So those are part of the striatum actually represent the value of actions driven by immediately available perceptor information or past the reinforcement.",
                    "label": 1
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Values.",
                    "label": 0
                },
                {
                    "sent": "So we are interesting.",
                    "label": 0
                },
                {
                    "sent": "What's the role of dopamine in these two decision making processes?",
                    "label": 0
                },
                {
                    "sent": "So we have in the.",
                    "label": 0
                },
                {
                    "sent": "In the experiment, we have three steps, so first inject first let them let the monkey allow the behavior task and then injected drugs and then record.",
                    "label": 0
                },
                {
                    "sent": "After injection so we compare pre injection.",
                    "label": 0
                },
                {
                    "sent": "And post injection.",
                    "label": 0
                },
                {
                    "sent": "Within the session.",
                    "label": 0
                },
                {
                    "sent": "Also we compare the drug data first sailing data.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "1st I'm going to start with the data from random condition.",
                    "label": 0
                },
                {
                    "sent": "So here X axis shows color bias which which is mix of the color two colors.",
                    "label": 0
                },
                {
                    "sent": "So as you expected, 5050% of mixture means it's ambiguous stimulus.",
                    "label": 0
                },
                {
                    "sent": "So monkeys performance shows translate that behavior.",
                    "label": 0
                },
                {
                    "sent": "However, the if the color dominant colors more dominant colors, more dominant to One Direction than the monkey's performance was increased.",
                    "label": 0
                },
                {
                    "sent": "In random condition.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In the fixed condition.",
                    "label": 0
                },
                {
                    "sent": "When the monkey knows which is sequences in the performance rate and increased.",
                    "label": 0
                },
                {
                    "sent": "And also the reaction time getting faster then faster then the monkey knows the sequence.",
                    "label": 0
                },
                {
                    "sent": "And also, although the stimulus itself is ambiguous, the monkeys performance shows higher.",
                    "label": 0
                },
                {
                    "sent": "Correct rate.",
                    "label": 0
                },
                {
                    "sent": "When so, thus, the monkey utilize a reinforcement learning from previous trials and immediately available information in the fixation stimulus.",
                    "label": 1
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So when we inject dopamine type 2 antagonists into the lower part of the striatum.",
                    "label": 0
                },
                {
                    "sent": "Actually.",
                    "label": 0
                },
                {
                    "sent": "The when the monkey.",
                    "label": 0
                },
                {
                    "sent": "Previously, the monkeys performances get higher, however, when you blocked the permit type 2 receptors, monkeys performance was decreased.",
                    "label": 0
                },
                {
                    "sent": "Also, the reaction time couldn't be faster than before.",
                    "label": 0
                },
                {
                    "sent": "Injection is like before injection.",
                    "label": 0
                },
                {
                    "sent": "Interestingly, there is no changes.",
                    "label": 0
                },
                {
                    "sent": "This is there are two lines.",
                    "label": 0
                },
                {
                    "sent": "Suppose each other here, so in random condition there's no changes.",
                    "label": 0
                },
                {
                    "sent": "When you apply to permit type 2 receptors.",
                    "label": 0
                },
                {
                    "sent": "When we.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Inject dopamine type 1.",
                    "label": 0
                },
                {
                    "sent": "When we inject sale, when we inject Saline, there is no changes in random condition or so there is no changes in fixed condition.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And also when we injected Obama, Taiwan and progress into the stores are part of stratum is like a sale in there is no changes in fixed condition and also in random condition.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We want to understand what kind of parameters in this process are involved in.",
                    "label": 0
                },
                {
                    "sent": "So as I previously showed you, we applied the reinforcement learning model.",
                    "label": 0
                },
                {
                    "sent": "So better actually here.",
                    "label": 0
                },
                {
                    "sent": "When we blocked the public type 2 receptors, actually better words decrease, which means noise level or reaction response variability actually increased.",
                    "label": 1
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "However.",
                    "label": 0
                },
                {
                    "sent": "They will come now come out, which is the color by way of color buyers.",
                    "label": 0
                },
                {
                    "sent": "There is no Chinese compare prior pre and post and running rate.",
                    "label": 0
                },
                {
                    "sent": "Pre and post there were any changes so no changes in running, wait and wait or mixture of two colors.",
                    "label": 1
                },
                {
                    "sent": "When we apply dopamine type 2 receptors.",
                    "label": 0
                },
                {
                    "sent": "The Type 2 antagonist.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The conclusion is.",
                    "label": 0
                },
                {
                    "sent": "The plumbing pipe to antagonist injection impact performance.",
                    "label": 0
                },
                {
                    "sent": "Accuracy and reaction times only when we, when the animal makes a decision based on the previous reinforcement.",
                    "label": 1
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Reinforcement, which is in our case fixed condition.",
                    "label": 0
                },
                {
                    "sent": "Also, there are no behavior effects with dopamine type one receptor antagonist or sale in administration, nor in the random condition with Obama Type 2 antagonists.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we apply the reinforcement learning model, or effectors of the deployment Type 2 Antonius were on inverse temperature, which means the response variability actually increased.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I would like to thank you thanks too.",
                    "label": 0
                },
                {
                    "sent": "My mental Bruno and order two PhD student and then our steps scientist Andy.",
                    "label": 0
                },
                {
                    "sent": "Thank you for your attention.",
                    "label": 0
                },
                {
                    "sent": "Hi.",
                    "label": 0
                },
                {
                    "sent": "For in your renforcement learning framework, it runs with current stimulus for the action, and so the sequence depends on this.",
                    "label": 0
                },
                {
                    "sent": "The only comes through the prediction error.",
                    "label": 0
                },
                {
                    "sent": "But the other case is actually I have done something similar in a different context, but in other cases based upon past sequence, what passed a transition that the monkey or subject could might make the prediction?",
                    "label": 0
                },
                {
                    "sent": "So in other words, have you ever also tried to expand the states?",
                    "label": 0
                },
                {
                    "sent": "Uh, including that the past sequence.",
                    "label": 0
                },
                {
                    "sent": "Do you understand what I'm asking?",
                    "label": 0
                },
                {
                    "sent": "So state means past sequence, so for instance, or that sometime in our daily life, based upon what you did, you kind of possibly to predict what you might do before the next things coming.",
                    "label": 0
                },
                {
                    "sent": "So you're learning framework.",
                    "label": 0
                },
                {
                    "sent": "You are including sort of a sequence dependencies through the value.",
                    "label": 0
                },
                {
                    "sent": "But in other cases in other possibility is you could also make your states at somewhat expanded like a.",
                    "label": 0
                },
                {
                    "sent": "Two step model.",
                    "label": 0
                },
                {
                    "sent": "For instance you can spend so just curious.",
                    "label": 0
                },
                {
                    "sent": "We didn't apply the state model like the kind of previous two step or three steps further.",
                    "label": 0
                },
                {
                    "sent": "But that actually emitted into the action value.",
                    "label": 0
                },
                {
                    "sent": "Heindl yeah maybe I guess yeah.",
                    "label": 0
                },
                {
                    "sent": "I mean come to my poster, we can talk more detail Stacy pendency.",
                    "label": 0
                },
                {
                    "sent": "Do the effect of the reaction times in the in the random case from the D2 antagonists.",
                    "label": 0
                },
                {
                    "sent": "You only showed the reaction times in the in the in the fixed case random condition, so reaction time in random condition using the higher than pixel condition.",
                    "label": 0
                },
                {
                    "sent": "Was it affected by the drugs?",
                    "label": 0
                },
                {
                    "sent": "There is no effect in random.",
                    "label": 0
                },
                {
                    "sent": "There is no significant effect in the reaction time.",
                    "label": 0
                },
                {
                    "sent": "In random condition.",
                    "label": 0
                }
            ]
        }
    }
}