{
    "id": "k5oncpcmitm4bbvdywntjqbqczsl2abg",
    "title": "3D-assisted Facial Texture Super-Resolution",
    "info": {
        "author": [
            "Pouria Mortazavian, University of Surrey"
        ],
        "published": "Dec. 1, 2009",
        "recorded": "September 2009",
        "category": [
            "Top->Computer Science->Computer Vision"
        ]
    },
    "url": "http://videolectures.net/bmvc09_mortazavian_3dft/",
    "segmentation": [
        [
            "I'm going to talk about superresolution of faces.",
            "What?"
        ],
        [
            "Let's start by defining the problem.",
            "Well, given one or more low resolution observations of a face, what we want to do is to estimate a high resolution image of that face.",
            "Well, super resolution is is a very well defined problem."
        ],
        [
            "And there's been many methods used, and they can largely be categorized into rare reconstruction based methods and example example based methods.",
            "Well reconstruction based methods try to.",
            "Well, the the main source of information for reconstruction based methods is the so called reconstruction constraints, with which is simply that when you.",
            "Warp and downsample the high resolution image appropriately.",
            "You should be able to obtain your low resolution initial images.",
            "Example based methods add another additional source of information which is a set of examples of.",
            "And a scene or an object.",
            "And.",
            "A sub category of those is object specific methods, which is which you know the object.",
            "I mean for example, and this method is a face super resolution, so we know we have a face image, so it's an object specific approach very."
        ],
        [
            "Our way to do this is map estimation, where we try to maximize the posterior probability of the high resolution phase given the low resolution face or faces.",
            "And while we have a likelihood and a private time."
        ],
        [
            "Likelihood is usually defined so that it would satisfy the certain there super resolution constraint, which is simply that the low resolution images should be obtainable from the high resolution image which we're looking for by warping blaring and downsampling the high resolution image plus some pixel noise time by assuming iid Gaussian distribution for this pixel noise we.",
            "Can come up with a residual error of this form for the negative look look like likelihood."
        ],
        [
            "OK, and for the prior there's been there's been many different methods used with different priors.",
            "One very well known one is the face of hallucination work of Baker and Canadian.",
            "They use their sample set to predict what the gradient of the high resolution phase should look like, and then they define the prior so that the gradient of the final result is encouraged to.",
            "Actually look like their prediction.",
            "OK, as long as you have frontal faces and you have frontal faces in your sample set and your input is also frontal, everything works works fine.",
            "You can see here."
        ],
        [
            "And the picture and left at the front of face is super resolved very well with this, with the face hallucination method.",
            "But if you have a non frontal pose then everything breaks down and this is always a problem with faces as soon as pose changes then you're very likely to lose everything.",
            "A very powerful tool to deal with poses and shape different shapes in different lightings and everything."
        ],
        [
            "Is a 3D model model.",
            "Now I'm not going to go through this because you're probably familiar with it, but it's a vector space.",
            "Representation of 3D faces and using parameters of the shape and texture of the face which are Alpha and beta respectively.",
            "Here we can use this model to represent generic faces.",
            "Now you."
        ],
        [
            "In a 2D image of a phase, you can fit the 3D model on the on the the image by finding the optimal set of model parameters are from beta and a set of rendering parameters and roll.",
            "That's wood.",
            "Make the appearance of the model be very similar to the given image.",
            "Once you've done that, you can we can use the."
        ],
        [
            "Fitted model to extract texture from the input image and map it to a predefined.",
            "Coordinate frame.",
            "The way we do this is that trust we flatten the surface of the 3D face like this and then each triangle of this flatten surface is projected to the input image and then we copy the texture from that specific location to this high resolution coordinate frame.",
            "So this gives us a shape, normalized and opposed normalized texture map of the face.",
            "So no matter what the post is, you get the same texture.",
            "Now we're going to use this for super resolution instead of the initial image.",
            "And before."
        ],
        [
            "Edit This as a map estimation.",
            "Again, we're trying to well here T is the texture map.",
            "MU is the model parameters, so Alpha and beta together and roll is the rendering parameters.",
            "An SM F is the low resolution image, so.",
            "If we marginalized the posterior probability of the model parameters, rendering prompters and texture map over the model and rendering parameters and then the T value that gives us the maximum of this probability is actually the high resolution texture map that we're looking for.",
            "So we can just simply write this this term like this an.",
            "Here we have."
        ],
        [
            "Two terms which the first time is essentially a texture superresolution term because you're looking for a optimal capital T given all the parameters of the model and image and the second term is a model fitting.",
            "To.",
            "Now to make things easier to make.",
            "We assume that."
        ],
        [
            "The model parameters and the rendering parameters have a dense distribution which peaks at their optimal value.",
            "So effectively they can be estimated by Dirac function so that marginalized probability is.",
            "Simplified to this form."
        ],
        [
            "Next, we're going to assume that."
        ],
        [
            "All the information that was available in the initial image is also available in the.",
            "In a texture map extracted from that image.",
            "So instead of maximizing this probability, we're going to use these parameters to extract the texture from that from our image or low resolution input, which we will call smalti because it's a low resolution texture, and then we're going to maximize the posterior probability of capital T given salty.",
            "So to summarize things this."
        ],
        [
            "Is what we are trying to do given a low resolution face, we first fit a 3D model to it.",
            "And then we use the parameters of the model to extract texture and obtain a low resolution texture map.",
            "And then we super resolve this texture map and obtain a high resolution texture map.",
            "Now once we have this high resolution texture map we can use."
        ],
        [
            "Together with the model parameters obtained in the fitting to render a high resolution face and not only the same pose as we started with, but we can.",
            "Change the row parameters to arbitrary values and obtain new."
        ],
        [
            "Poses or new views of the facts?",
            "OK, here you can see that the texture on these parts does not look correct.",
            "This is because this texture was not originally available in the low resolution image and it was estimated by the 3D model.",
            "Now what this difference in texture means is that the model is not doing a very fine job in being fitted to a low resolution phase.",
            "Because there is an error in the texture estimate.",
            "So we."
        ],
        [
            "So the way we do this texture is super resolution here.",
            "The.",
            "Is similar to the Baker cannot approach.",
            "We have a similar likelihood term, except that this a here doesn't include anymore warping because we're doing this in a normalized rate in a geometrically normalized coordinate frame."
        ],
        [
            "And for the prior, we predict the gradients.",
            "So to do this, assume that we have a set of low resolution and high resolution samples.",
            "Given a."
        ],
        [
            "Low resolution input.",
            "We compare each Patch of this input which all the patches and the low resolution sample set by comparing the parent structure vectors of the pixels and in that."
        ],
        [
            "Patch and the winner.",
            "We will we find the closest match and we take the."
        ],
        [
            "Much in the.",
            "And the high resolution image that corresponds to that winner."
        ],
        [
            "And we take the gradient of that Patch, and we assume that the gradient in the Super resolved image should look like the gradient of that particular Patch.",
            "So we're so in the end we have this."
        ],
        [
            "Predicted gradient map.",
            "And then we define."
        ],
        [
            "The prior to.",
            "To encourage the gradients of the final result to look like our predicted grade."
        ],
        [
            "So here's some results, but these are not the actual sizes of the images because they've been rescheduled to fit in the slide.",
            "But it can give you an idea of the enlarged factor, which is 8 times in each direction.",
            "Here.",
            "This is the low resolution image.",
            "B is bilinear interpolation of the low resolution input, C is the result of applying our approach.",
            "D is bacon, others face hallucination for comparison and E is the ground truth.",
            "High resolution image."
        ],
        [
            "And this is 2 novel views of the face, so these were generated using that low resolution image and a sample set which only contains frontal faces.",
            "Some more results though."
        ],
        [
            "Top role is bilinear interpolation, 2nd row is bacon on these results.",
            "Well, our results by by implementing their approach.",
            "Maybe they should.",
            "They could get better results.",
            "The 3rd row is our method and the 4th row is the high resolution faces so.",
            "Well, visually comparing sometimes our method works better, sometimes it.",
            "Theirs is outperforming us but they have more or less the same quality.",
            "But the added value of our approach is, as I said that."
        ],
        [
            "It can handle different poses as well.",
            "This is an example.",
            "A is the low resolution image.",
            "Again, B is bilinear interpolation and see as the results of our super resolution.",
            "This is something that couldn't be done with, but by just applying Bacon's method too.",
            "The initial image.",
            "Now have a."
        ],
        [
            "Well, an application of superresolution faces in face recognition.",
            "It has been shown that the recognition performance drops when you go below some certain resolution."
        ],
        [
            "The recognition we compared our results against Baker Kenada for recognition.",
            "The recognition method we used was about, well, LBP histograms in different patches of the image.",
            "And Maps to earlier space and then we use normalized correlation for comparison, we had three samples for training and three foot tests and views as subset of the exam to BTS database.",
            "On the high resolution images which are roughly 240 pixels by 190 pixels.",
            "This method gives 99.28% recognition, but if you downsample those images 8 times in each direction for recognition rate drops to 78%.",
            "So this shows that we're losing a lot of information here by super resolving that low resolution image with Baker Canada we can get 96% and by our method we get 95 which is.",
            "Quite well, abit less, but not very significantly, but our approach is also able to handle different poses so you can also do recognition and pose correction at the same time.",
            "So."
        ],
        [
            "In conclusion, we showed a framework for pose independent face recognition face sorry, super resolution.",
            "And the results obtained are visually compatible with the hallucination method.",
            "And we showed that this method can provide additional information which is useful for recognition, which means that the information with we're adding to the image is not just random information and it's actually plausable information, but.",
            "For future work, the model fitting is not doing a fine job on low resolutions, so we're going to try to improve the model fitting on lower resolution images, because the model fitting process assumes that you already have a very good resolution phase."
        ],
        [
            "OK, thank you so.",
            "The Gallery is images of the recognition.",
            "Module or the superresolution model?",
            "Because it's two different lists.",
            "You need a picture of the same face, not necessarily to fight the same face.",
            "You just need a set of samples or faces.",
            "Yeah.",
            "Yes, and things get much worse when you go to lower resolutions.",
            "But while the database we used was.",
            "Well, it has nice illumination, so that's just in our favor.",
            "And we do get some errors in the fitting as well, but they don't tend to be very deteriorating deteriorating on the final results of the Super resolution.",
            "Thank you, let's make expression on no.",
            "No, we haven't tried that yet, but there's been.",
            "Attempts to also normalize expressions using more for models.",
            "So if we can work on that, which I can imagine gets really difficult in low resolutions, then the same framework should work for expressions as well."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm going to talk about superresolution of faces.",
                    "label": 0
                },
                {
                    "sent": "What?",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let's start by defining the problem.",
                    "label": 0
                },
                {
                    "sent": "Well, given one or more low resolution observations of a face, what we want to do is to estimate a high resolution image of that face.",
                    "label": 1
                },
                {
                    "sent": "Well, super resolution is is a very well defined problem.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And there's been many methods used, and they can largely be categorized into rare reconstruction based methods and example example based methods.",
                    "label": 0
                },
                {
                    "sent": "Well reconstruction based methods try to.",
                    "label": 0
                },
                {
                    "sent": "Well, the the main source of information for reconstruction based methods is the so called reconstruction constraints, with which is simply that when you.",
                    "label": 0
                },
                {
                    "sent": "Warp and downsample the high resolution image appropriately.",
                    "label": 1
                },
                {
                    "sent": "You should be able to obtain your low resolution initial images.",
                    "label": 0
                },
                {
                    "sent": "Example based methods add another additional source of information which is a set of examples of.",
                    "label": 0
                },
                {
                    "sent": "And a scene or an object.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "A sub category of those is object specific methods, which is which you know the object.",
                    "label": 0
                },
                {
                    "sent": "I mean for example, and this method is a face super resolution, so we know we have a face image, so it's an object specific approach very.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Our way to do this is map estimation, where we try to maximize the posterior probability of the high resolution phase given the low resolution face or faces.",
                    "label": 0
                },
                {
                    "sent": "And while we have a likelihood and a private time.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Likelihood is usually defined so that it would satisfy the certain there super resolution constraint, which is simply that the low resolution images should be obtainable from the high resolution image which we're looking for by warping blaring and downsampling the high resolution image plus some pixel noise time by assuming iid Gaussian distribution for this pixel noise we.",
                    "label": 0
                },
                {
                    "sent": "Can come up with a residual error of this form for the negative look look like likelihood.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, and for the prior there's been there's been many different methods used with different priors.",
                    "label": 0
                },
                {
                    "sent": "One very well known one is the face of hallucination work of Baker and Canadian.",
                    "label": 1
                },
                {
                    "sent": "They use their sample set to predict what the gradient of the high resolution phase should look like, and then they define the prior so that the gradient of the final result is encouraged to.",
                    "label": 0
                },
                {
                    "sent": "Actually look like their prediction.",
                    "label": 0
                },
                {
                    "sent": "OK, as long as you have frontal faces and you have frontal faces in your sample set and your input is also frontal, everything works works fine.",
                    "label": 0
                },
                {
                    "sent": "You can see here.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the picture and left at the front of face is super resolved very well with this, with the face hallucination method.",
                    "label": 1
                },
                {
                    "sent": "But if you have a non frontal pose then everything breaks down and this is always a problem with faces as soon as pose changes then you're very likely to lose everything.",
                    "label": 0
                },
                {
                    "sent": "A very powerful tool to deal with poses and shape different shapes in different lightings and everything.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is a 3D model model.",
                    "label": 1
                },
                {
                    "sent": "Now I'm not going to go through this because you're probably familiar with it, but it's a vector space.",
                    "label": 0
                },
                {
                    "sent": "Representation of 3D faces and using parameters of the shape and texture of the face which are Alpha and beta respectively.",
                    "label": 1
                },
                {
                    "sent": "Here we can use this model to represent generic faces.",
                    "label": 0
                },
                {
                    "sent": "Now you.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In a 2D image of a phase, you can fit the 3D model on the on the the image by finding the optimal set of model parameters are from beta and a set of rendering parameters and roll.",
                    "label": 0
                },
                {
                    "sent": "That's wood.",
                    "label": 0
                },
                {
                    "sent": "Make the appearance of the model be very similar to the given image.",
                    "label": 1
                },
                {
                    "sent": "Once you've done that, you can we can use the.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Fitted model to extract texture from the input image and map it to a predefined.",
                    "label": 1
                },
                {
                    "sent": "Coordinate frame.",
                    "label": 0
                },
                {
                    "sent": "The way we do this is that trust we flatten the surface of the 3D face like this and then each triangle of this flatten surface is projected to the input image and then we copy the texture from that specific location to this high resolution coordinate frame.",
                    "label": 0
                },
                {
                    "sent": "So this gives us a shape, normalized and opposed normalized texture map of the face.",
                    "label": 0
                },
                {
                    "sent": "So no matter what the post is, you get the same texture.",
                    "label": 0
                },
                {
                    "sent": "Now we're going to use this for super resolution instead of the initial image.",
                    "label": 0
                },
                {
                    "sent": "And before.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Edit This as a map estimation.",
                    "label": 0
                },
                {
                    "sent": "Again, we're trying to well here T is the texture map.",
                    "label": 0
                },
                {
                    "sent": "MU is the model parameters, so Alpha and beta together and roll is the rendering parameters.",
                    "label": 0
                },
                {
                    "sent": "An SM F is the low resolution image, so.",
                    "label": 0
                },
                {
                    "sent": "If we marginalized the posterior probability of the model parameters, rendering prompters and texture map over the model and rendering parameters and then the T value that gives us the maximum of this probability is actually the high resolution texture map that we're looking for.",
                    "label": 0
                },
                {
                    "sent": "So we can just simply write this this term like this an.",
                    "label": 0
                },
                {
                    "sent": "Here we have.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Two terms which the first time is essentially a texture superresolution term because you're looking for a optimal capital T given all the parameters of the model and image and the second term is a model fitting.",
                    "label": 0
                },
                {
                    "sent": "To.",
                    "label": 0
                },
                {
                    "sent": "Now to make things easier to make.",
                    "label": 0
                },
                {
                    "sent": "We assume that.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The model parameters and the rendering parameters have a dense distribution which peaks at their optimal value.",
                    "label": 1
                },
                {
                    "sent": "So effectively they can be estimated by Dirac function so that marginalized probability is.",
                    "label": 0
                },
                {
                    "sent": "Simplified to this form.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Next, we're going to assume that.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "All the information that was available in the initial image is also available in the.",
                    "label": 0
                },
                {
                    "sent": "In a texture map extracted from that image.",
                    "label": 0
                },
                {
                    "sent": "So instead of maximizing this probability, we're going to use these parameters to extract the texture from that from our image or low resolution input, which we will call smalti because it's a low resolution texture, and then we're going to maximize the posterior probability of capital T given salty.",
                    "label": 0
                },
                {
                    "sent": "So to summarize things this.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is what we are trying to do given a low resolution face, we first fit a 3D model to it.",
                    "label": 0
                },
                {
                    "sent": "And then we use the parameters of the model to extract texture and obtain a low resolution texture map.",
                    "label": 0
                },
                {
                    "sent": "And then we super resolve this texture map and obtain a high resolution texture map.",
                    "label": 0
                },
                {
                    "sent": "Now once we have this high resolution texture map we can use.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Together with the model parameters obtained in the fitting to render a high resolution face and not only the same pose as we started with, but we can.",
                    "label": 0
                },
                {
                    "sent": "Change the row parameters to arbitrary values and obtain new.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Poses or new views of the facts?",
                    "label": 0
                },
                {
                    "sent": "OK, here you can see that the texture on these parts does not look correct.",
                    "label": 0
                },
                {
                    "sent": "This is because this texture was not originally available in the low resolution image and it was estimated by the 3D model.",
                    "label": 0
                },
                {
                    "sent": "Now what this difference in texture means is that the model is not doing a very fine job in being fitted to a low resolution phase.",
                    "label": 0
                },
                {
                    "sent": "Because there is an error in the texture estimate.",
                    "label": 0
                },
                {
                    "sent": "So we.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the way we do this texture is super resolution here.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "Is similar to the Baker cannot approach.",
                    "label": 0
                },
                {
                    "sent": "We have a similar likelihood term, except that this a here doesn't include anymore warping because we're doing this in a normalized rate in a geometrically normalized coordinate frame.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And for the prior, we predict the gradients.",
                    "label": 0
                },
                {
                    "sent": "So to do this, assume that we have a set of low resolution and high resolution samples.",
                    "label": 0
                },
                {
                    "sent": "Given a.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Low resolution input.",
                    "label": 0
                },
                {
                    "sent": "We compare each Patch of this input which all the patches and the low resolution sample set by comparing the parent structure vectors of the pixels and in that.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Patch and the winner.",
                    "label": 0
                },
                {
                    "sent": "We will we find the closest match and we take the.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Much in the.",
                    "label": 0
                },
                {
                    "sent": "And the high resolution image that corresponds to that winner.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we take the gradient of that Patch, and we assume that the gradient in the Super resolved image should look like the gradient of that particular Patch.",
                    "label": 0
                },
                {
                    "sent": "So we're so in the end we have this.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Predicted gradient map.",
                    "label": 0
                },
                {
                    "sent": "And then we define.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The prior to.",
                    "label": 0
                },
                {
                    "sent": "To encourage the gradients of the final result to look like our predicted grade.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's some results, but these are not the actual sizes of the images because they've been rescheduled to fit in the slide.",
                    "label": 0
                },
                {
                    "sent": "But it can give you an idea of the enlarged factor, which is 8 times in each direction.",
                    "label": 0
                },
                {
                    "sent": "Here.",
                    "label": 0
                },
                {
                    "sent": "This is the low resolution image.",
                    "label": 0
                },
                {
                    "sent": "B is bilinear interpolation of the low resolution input, C is the result of applying our approach.",
                    "label": 0
                },
                {
                    "sent": "D is bacon, others face hallucination for comparison and E is the ground truth.",
                    "label": 0
                },
                {
                    "sent": "High resolution image.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is 2 novel views of the face, so these were generated using that low resolution image and a sample set which only contains frontal faces.",
                    "label": 0
                },
                {
                    "sent": "Some more results though.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Top role is bilinear interpolation, 2nd row is bacon on these results.",
                    "label": 0
                },
                {
                    "sent": "Well, our results by by implementing their approach.",
                    "label": 0
                },
                {
                    "sent": "Maybe they should.",
                    "label": 0
                },
                {
                    "sent": "They could get better results.",
                    "label": 0
                },
                {
                    "sent": "The 3rd row is our method and the 4th row is the high resolution faces so.",
                    "label": 0
                },
                {
                    "sent": "Well, visually comparing sometimes our method works better, sometimes it.",
                    "label": 0
                },
                {
                    "sent": "Theirs is outperforming us but they have more or less the same quality.",
                    "label": 0
                },
                {
                    "sent": "But the added value of our approach is, as I said that.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It can handle different poses as well.",
                    "label": 0
                },
                {
                    "sent": "This is an example.",
                    "label": 0
                },
                {
                    "sent": "A is the low resolution image.",
                    "label": 0
                },
                {
                    "sent": "Again, B is bilinear interpolation and see as the results of our super resolution.",
                    "label": 0
                },
                {
                    "sent": "This is something that couldn't be done with, but by just applying Bacon's method too.",
                    "label": 0
                },
                {
                    "sent": "The initial image.",
                    "label": 0
                },
                {
                    "sent": "Now have a.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, an application of superresolution faces in face recognition.",
                    "label": 0
                },
                {
                    "sent": "It has been shown that the recognition performance drops when you go below some certain resolution.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The recognition we compared our results against Baker Kenada for recognition.",
                    "label": 0
                },
                {
                    "sent": "The recognition method we used was about, well, LBP histograms in different patches of the image.",
                    "label": 1
                },
                {
                    "sent": "And Maps to earlier space and then we use normalized correlation for comparison, we had three samples for training and three foot tests and views as subset of the exam to BTS database.",
                    "label": 1
                },
                {
                    "sent": "On the high resolution images which are roughly 240 pixels by 190 pixels.",
                    "label": 0
                },
                {
                    "sent": "This method gives 99.28% recognition, but if you downsample those images 8 times in each direction for recognition rate drops to 78%.",
                    "label": 0
                },
                {
                    "sent": "So this shows that we're losing a lot of information here by super resolving that low resolution image with Baker Canada we can get 96% and by our method we get 95 which is.",
                    "label": 0
                },
                {
                    "sent": "Quite well, abit less, but not very significantly, but our approach is also able to handle different poses so you can also do recognition and pose correction at the same time.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In conclusion, we showed a framework for pose independent face recognition face sorry, super resolution.",
                    "label": 1
                },
                {
                    "sent": "And the results obtained are visually compatible with the hallucination method.",
                    "label": 1
                },
                {
                    "sent": "And we showed that this method can provide additional information which is useful for recognition, which means that the information with we're adding to the image is not just random information and it's actually plausable information, but.",
                    "label": 1
                },
                {
                    "sent": "For future work, the model fitting is not doing a fine job on low resolutions, so we're going to try to improve the model fitting on lower resolution images, because the model fitting process assumes that you already have a very good resolution phase.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, thank you so.",
                    "label": 0
                },
                {
                    "sent": "The Gallery is images of the recognition.",
                    "label": 0
                },
                {
                    "sent": "Module or the superresolution model?",
                    "label": 0
                },
                {
                    "sent": "Because it's two different lists.",
                    "label": 0
                },
                {
                    "sent": "You need a picture of the same face, not necessarily to fight the same face.",
                    "label": 0
                },
                {
                    "sent": "You just need a set of samples or faces.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Yes, and things get much worse when you go to lower resolutions.",
                    "label": 0
                },
                {
                    "sent": "But while the database we used was.",
                    "label": 0
                },
                {
                    "sent": "Well, it has nice illumination, so that's just in our favor.",
                    "label": 0
                },
                {
                    "sent": "And we do get some errors in the fitting as well, but they don't tend to be very deteriorating deteriorating on the final results of the Super resolution.",
                    "label": 0
                },
                {
                    "sent": "Thank you, let's make expression on no.",
                    "label": 0
                },
                {
                    "sent": "No, we haven't tried that yet, but there's been.",
                    "label": 0
                },
                {
                    "sent": "Attempts to also normalize expressions using more for models.",
                    "label": 0
                },
                {
                    "sent": "So if we can work on that, which I can imagine gets really difficult in low resolutions, then the same framework should work for expressions as well.",
                    "label": 0
                }
            ]
        }
    }
}