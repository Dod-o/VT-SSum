{
    "id": "mvxuj5sns2r626u3tm2zqaca2mvvd5cc",
    "title": "Arbitrage of Forecasting Experts",
    "info": {
        "author": [
            "Luis Torgo, University of Porto"
        ],
        "published": "Feb. 14, 2018",
        "recorded": "January 2018",
        "category": [
            "Top->Computer Science",
            "Top->Data Science"
        ]
    },
    "url": "http://videolectures.net/solomon_torgo_forecasting_experts/",
    "segmentation": [
        [
            "So it's a pleasure to be here again, so as Eagle was mentioning, this is an extension of work with my student Twitter and also my colleagues back in Porto five you and Carlos.",
            "And so this is a kind of follow up of the work that we presented at in sculpture last September.",
            "OK, so."
        ],
        [
            "Before client, so I'll talk a bit about, you know the motivation for this work, and then we'll go into the methodology an described experiments.",
            "You know, the standard outline alright?"
        ],
        [
            "So."
        ],
        [
            "The motivation for this sort of methods is more or less obvious, so we all know that time series are around in many application domains.",
            "We also know that frequently in most real world problems, this time series are collected from very complex and dynamic environments where the things that we are measured, the time series that we're trying to approximate somehow depends on many external factors that frequently are not.",
            "Stored or measured.",
            "So there is all these complex dynamics that makes this task slightly more challenging for real world problems.",
            "OK, so examples of this abound.",
            "You know like things like financial analysis, forecasts for stock prices, and also things like you know, intelligent transportation systems an where we try to forecast the shore traffic, short term traffic flow to try to plan in advance.",
            "The road networks OK, so these are two simple examples of very complex dynamic systems where you have interesting somehow forecasting some variables, But the problems are very complex, OK Now."
        ],
        [
            "Of course, time series analysis is, you know, it's a long time since people are working on this on these areas.",
            "Really many communities, many research communities approach this problem from different perspectives, and that's nice because you can somehow reuse ideas and adapt ideas, which is a nice thing to do.",
            "And typically most methods are designed to try to somehow model the temporal dependencies among the observations that we that we store in our database is OK.",
            "However, you know most time series I have.",
            "Very clear nonstationarity's and also you know sometime evolving data, complex structures that may require slightly more sophisticated approaches.",
            "Things like recurring structures due to things like seasonality may become an issue on several real world applications.",
            "OK, so some of these kind of state of the art, or more standard models end up suffering a bit on this more challenging tasks.",
            "Although of course any community tries to provide solutions for these things.",
            "OK, so our setting is basically this sort of complex and you know very dynamic time series and that's what we are trying to handle here."
        ],
        [
            "OK, now.",
            "Whenever we have this complex situations, we within machine learning all know that you know combining different models is usually a very good idea or a very good way of trying to include somehow diversity that can cope with this extra complexity.",
            "OK, so that's one of the things that you can do with this combination.",
            "So typically here questions involve like selecting the weights of each individual model, which may be challenging, particularly in a.",
            "Time dependent domains where?",
            "What is the best model can change very rapidly because of these dynamics of the time series.",
            "OK, so.",
            "Of course, the idea is that recent observations will tend to give you a hint on which models are more adjusted to the current dynamics of the series.",
            "But of course you need to adjust to things like concept drift and things like effects like that, where different models which were performing very very well suddenly start to perform not so well, OK, and so the idea of using a combination of experts or an assemble if you prefer for this sort of.",
            "Uh, tasks is that you need to be very careful with the way that you combine these experts.",
            "That is the way that you reach or select the weights with which each model will have will enter the aggregated procedure prediction of the ensemble OK, and so that's the main challenge.",
            "Because of these dynamics of the time series.",
            "OK, so meta learning is also commonly used.",
            "With, you know approach is similar to stacking where you try to somehow learn a meta model that tried to four tries to forecast the behavior of the different models on different settings OK, and so that's actually one approach that they're going to follow here.",
            "We're going to use try to use meta learning to come up with.",
            "You know these weights for the aggregation of the experts.",
            "OK so."
        ],
        [
            "Just to try to give you a some motivation motivating example.",
            "So what you see here is in black real World Time series and what you see here is somehow the prediction of two different models.",
            "These red and blue lines OK and you can observe that at some periods, for instance, the red seems to be, you know better a better fit for this series, but on other regions than the blue becomes.",
            "Better performing OK, so that's the challenge that you face on these very complex dynamic systems.",
            "Not a single model will most probably not behave very well on all settings.",
            "OK, and then you may have.",
            "You may try to gain from this diversity of among the different models and somehow combine them in a clever way such that you can take advantage of this thing OK?"
        ],
        [
            "So the main goal then is to dynamically combine these models across the time series in a real time.",
            "You know setting where you try to guess what is the best combination for the next forecast.",
            "OK, so."
        ],
        [
            "The idea then is to use a meta learning method that can handle this sort of dynamic environments and that can select a.",
            "Some stages give more importance.",
            "One of the models at some stages, it gives more important to the other, and so on and so forth so that we can have a prediction that is a combination.",
            "Of course is a simplistic example with only two models we are not going to combine two models, of course, but the idea is to try to take advantage of the the places or the times or the time regions where each model behaves better than the others OK?",
            "So that's the idea, right?",
            "So this meta learning method will try to perform a dynamic weighing of the models that she sighs timestep.",
            "So these weights are dynamic in the sense that they change change through time.",
            "They are not fixed.",
            "And then of course we will also try to handle the interdependency among experts because we may have different models which are somehow correlated their performance, and so we don't want to.",
            "Put them together in the ensemble decisions OK?"
        ],
        [
            "Alright, so let's try to give a bit more detail on the methodology of proposing here, so it's called arbitrating forecasters and."
        ],
        [
            "So the idea is that we have.",
            "A set of base models that try to approximate a time series.",
            "OK, so these are our base models that will form this ensemble.",
            "OK, so this based models essentially they try to forecast the next value of the time series using the previous values, or eventually some further features that we think are important to try to forecast the future behavior of the time series.",
            "OK between the simplistic way we essentially use the recent past values.",
            "And we tried to forecast the next one OK, But we can enrich somehow these features to try to improve the performance of the models.",
            "OK, and then what we need given that we have this set of models, each of them making a forecast for the next value of the time series.",
            "And we need a way to combine them using some criteria."
        ],
        [
            "So.",
            "Arbitrating this models essentially consists of trying to learn associated with each of these based models.",
            "Learn a kind of meta model and that's the idea of arbitrating.",
            "We tried to learn a model that tries to forecast what will be the error of each of these models.",
            "OK, so this meta models here tried to forecast what will be the error of each of these models.",
            "OK, so that."
        ],
        [
            "The idea so this meta models their predictions is the estimated error of the respective based model OK, and so they again they use some features that describe the current state of the time series and then based on this current state they try to forecast what will be the error of the model.",
            "OK now.",
            "These models again are learn using the training data that we have.",
            "That is, the past performance of the models and so they somehow learn how the model behaves for each different dynamics of the time series OK?"
        ],
        [
            "Now.",
            "An alternative to arbitrating is something which is more of.",
            "Frequent to do on this time series and samples, which is win doing OK.",
            "So in windway you basically look for the recent performance of the models of the base models, and then using these recent performance you somehow reach the weight of each of these models.",
            "OK, arbitrating is different because what we learn we don't look only to the recent performance.",
            "We learn a meta model that learn that is learned using all the performance during all history, OK?",
            "So if you have things like a recurrent events because at some stage with some dynamics this was the best model and now we are at a different dynamics.",
            "But suddenly we are moving to this same dynamics then this meta models no because they have this history and they know that within this context this model is going to be better than the other ones.",
            "OK, so there are slightly more interesting in terms of long range modeling than win doing because we doing just look at looks at the very recent performance OK?",
            "And it takes time to adjust to a new setting.",
            "OK, so that's what we expect to gain from windowing, which is a more frequent way of combining time series models within these tasks, OK?"
        ],
        [
            "Alright, so arbitrating is not a new concept of course, so this was actually proposed in the context of classification tasks.",
            "For, you know, for arbitrating ensembles of classifiers.",
            "So essentially the original idea of arbitrating was to use these meta models to select one model.",
            "One of the base classifiers as the one that is going to prevail OK. And so we somehow rework this idea.",
            "And try to apply to this time series forecasting an we are going to make a few adjustments but the original concept of arbitrating is not ours, it's something which was done before for classification.",
            "Things OK. Also related are these concepts of mixture of experts which is somehow similar to arbitrating but mixture of experts do not try to model the error of the of the base models.",
            "OK so they use this gating networks.",
            "That tried to compute directly the weights of the experts and the way that the diversity of the models is handle is also very different from from arbitrating experts.",
            "OK now."
        ],
        [
            "So at each time step, our proposal essentially tries to come up with a prediction of the ensemble that is based on a weighted combination of the predictions of the base models.",
            "OK, but these weights with which each of the models enters the final prediction depends on the opinion of this method.",
            "Learners OK, so these metal learners will estimate the error of these.",
            "Each of these models.",
            "Then based on these errors we do some.",
            "Scaling to come up with some weights for each of the models, and then it's these weights that are used to reach the final combined prediction.",
            "OK, now we."
        ],
        [
            "Made a small change to this process by eliminating at each time step we may kind of suspend some of the models of the ensemble OK and the motivation for that again is to try to adjust better.",
            "A better adjust to the different dynamics throughout time.",
            "OK, because maybe some models at some stages at some dynamics are two batch OK and even if their weight is too low they end up having some impact.",
            "OK, if we have like 10 models which are.",
            "All very bad, even if they have a low weight, they somehow influenced the predictors.",
            "OK, So what we do is that at each time step we suspend, we may decide to suspend or reactivate some of the models that form the base learners OK, and so they can.",
            "They are not thrown away, but they are kind of put to sleep because at this stage they are not performing very well and this is always always controlled by the opinion of this metal learners OK?",
            "If the metal is expected model to be to have very low error even if he was asleep before then, is waken and then it enters the den symbol.",
            "OK so basically in terms of an implementation we at each time step with the top Lambda percent models.",
            "And this.",
            "Top is calculated looking at some past performance, not only the last one like the past.",
            "Looking at the performance in the last, let's say two weeks, these are the top Alpha performance or top Lambda performance.",
            "OK, and so these are the ones which entered the final combined prediction of the ensemble.",
            "OK, so that's another feature that we use not only using meta learning, but then in the dynamic ensemble composition.",
            "We use this trick of eventually.",
            "Putting asleep temporally.",
            "Some of the models OK."
        ],
        [
            "Then another thing that we have.",
            "Change compared to the original arbitrating is the way that the metal learning approaches are somehow used.",
            "OK, so the standard meta learning approaches.",
            "Typically they start model selection at deployment time.",
            "OK, so in order to try and because of that then the meta learners take some time before they perform well, because here we have a time evolving scenario.",
            "We said.",
            "Well maybe it's good that.",
            "During training time with user kind of prick, when shall strategy to start to learn already the metal learners so that when we reach finally the test set, we already have a good meta learner which was trained during all these periods OK and so we use a kind of out of the bag process where the metal learner is somehow checked against this test set and so that the meta learner is improved.",
            "Throughout the training period, OK, so that's another if you want kind of trick that we have added to the standard arbitrating so that we could take advantage of the fact that we have a time series so we can kind of follow this time flow OK?"
        ],
        [
            "Now.",
            "The other issue that I mentioned, which is important that we have started on, actually that's the main one of the main changes compared to the XML paper that I mentioned that this work is well.",
            "This is one of the most recent extensions that we have made is to try to handle interdependency among the base models.",
            "OK, so we may have based models which are very correlated with each other, and so then what we do.",
            "A standard arbitrating model analyzes each expert separatedly OK an so this can be somehow dangerous or can be a limitation if there are interdependencies among these based learners.",
            "OK, so.",
            "So we somehow try to encourage this diversity not only by having different based models with different techniques, but also the way that we aggregate their opinions should try to cope with this interdependency.",
            "OK, so"
        ],
        [
            "How do we do that?",
            "So we basically tackle the first issue of trying to have diversity by employing eater genius and sample.",
            "So that means that our base models are very different from each other in terms of algorithms that are used to build each base model.",
            "OK, so we don't have an homogeneous and somehow we have a very pure genius and sampled that uses different techniques that I'm going to tell you later on.",
            "OK, so regarding the second issue of this.",
            "Interdependency.",
            "What we do is that we explicitly re wait.",
            "The experts teach predictions, step according to their recent correlation.",
            "OK, so we we come up with these weights that I've explained before, but then these weights are changed according to the correlation of the predictions of the experts.",
            "OK, so how do we do?"
        ],
        [
            "But we basically took this idea.",
            "If you want this inspiration from information retrieval literature.",
            "So whenever you do some query you come up with the ranking of related documents, but then you know you somehow adjust this thing because if you have like the second most relevant document, if it is very related with the first one that you already suggested, you somehow want to decrease, it's important.",
            "OK, so you want to take care of this.",
            "Correlation between the things and provide the ranking OK, and so we kind of follow the same idea and so we have.",
            "We rank our models by their weights, but then we select the first one for the combined prediction.",
            "But then the second one before we select it, we check if it is very correlated to this first one.",
            "If it is very correlated recently their predictions then we decrease its weight.",
            "So it goes down in the rank.",
            "OK, so we kind of re weight the weights.",
            "Of the experts with which they entered this combined prediction based on this idea based on the correlation to the models that are already included on the combination.",
            "OK, so that's more or less what we."
        ],
        [
            "Do we use the person correlation coefficient to try to adjust these weights based on our correlated R?",
            "The predictions recently on a recent time window OK?",
            "So that's the final thing that we have adjusted.",
            "OK so yeah, yeah.",
            "Airbook correlated actually.",
            "I want them to have higher.",
            "Yeah.",
            "Yeah, they are inversely correlated, you mean.",
            "They have the same multiple first one over should stick around other ships OK. Take the average of both.",
            "You get the the correct prediction.",
            "Use the weight of one of them.",
            "Actually, you're losing a lot of information.",
            "That's actually a.",
            "A possibility I think, although outside I'm not completely sure if the meta learner model will not somehow provide that information on the error.",
            "That person at the end.",
            "The little one, yeah, but what I mean is that.",
            "What I mean is that the original weights are based on the estimated error by the metal metal model, yeah?",
            "Yeah yeah, maybe maybe.",
            "Maybe you have a point.",
            "There maybe should be something that we should check.",
            "If that is not happening.",
            "Yeah, thank you.",
            "A.",
            "To understand it.",
            "No correlated models can help, right?",
            "Situations where they would reinforce right?",
            "Yeah yeah, but but going back to your question so it doesn't mean that they get out of the ensemble, they just get their weight slightly decreased, OK?",
            "So they will still help.",
            "It's not like 01, but they will get.",
            "Maybe it's instead of being on the 2nd place.",
            "Maybe it is on the 4th or something like that, so they will have their impact slightly reduced.",
            "So in this extreme situation where summing up them that will be the perfect perfect prediction.",
            "Then of course we are losing something.",
            "Please contact.",
            "Actually.",
            "The kids can have some.",
            "Many situations can happen like that because yeah.",
            "Perfect.",
            "I mean definitely something that that we should check.",
            "Yeah, definitely that's.",
            "I'm not, I'm not completely sure whether Victor didn't check that because we did lots of plots where we were seeing the, but I don't recall that.",
            "But I mean definitely, that's something that we should check.",
            "Thank you.",
            "OK, so."
        ],
        [
            "Now let's move into the kind of experiments that we have carried out with this idea so."
        ],
        [
            "Essentially, we have played with 62 real World Time series from very different domains.",
            "They also rank their ranges vary a lot.",
            "Just out of comparison, there is this famous time series competitions this M1234.",
            "Before, as roughly one 100,000 time series on, you know, only three and a half percent of this.",
            "I have more than seven 750 observations, so we somehow have slightly larger time series because I think this, you know nowadays is very easy to get.",
            "Very big time series, so I think it's important to have slightly larger time series so that you can capture you know different regimes across time.",
            "OK, so that's something that we have tried to.",
            "Increase the size compared to these more standard benchmarks, OK?",
            "5% of 100,000, what is?",
            "So this is one kind of benchmark competition that exists on time series forecasting this M1 and two and they have like 100,000 time series in the competition.",
            "OK and only three 100% of this are larger than 750 but I think.",
            "That somehow is not realistic, I think because most of the time series nowadays are relatively big, so we try to.",
            "Do you slightly bigger the time series?",
            "OK, that's kind of an explanation.",
            "Why haven't we use this kind of benchmark?",
            "Because we could, of course applied our sync to this 100,000.",
            "OK, of course it would take a bit more time, but anyway it would.",
            "Yeah, yeah I would say it's pretty short, but comparing to some of the benchmarks used in this area, it's not short.",
            "That's why I'm trying to."
        ],
        [
            "Alright, so in terms of modeling the construction of the base models, we have used the standard strategy of using the embedding of the recent observations of the time series.",
            "That is, the wrist and recent K values of the time series, and we have used.",
            "You know, these false nearest neighbor method to estimate the size of this embedding.",
            "OK, but on top of that we have also added as features as input features to the models, afew summary statistics whose idea is to try to.",
            "You know illustrates some of the recent dynamics of the time series.",
            "OK, so things like the trend, you know, the skewness, you know long term, long range dependence.",
            "You know things like that.",
            "We have tried to create features to put, to add to the models, to add to this embedding, which is the more standard sink.",
            "OK, so in order to try to improve the quality of the base models, OK?"
        ],
        [
            "Now, in terms of evaluation, we were.",
            "We compared all the approaches that I'm going to show the results using out of the sample in multiple testing periods, which you know some of our recent work together also with vigor.",
            "And we were just complaining.",
            "No, this one.",
            "This one is still not somehow, although it is from October, it's still not in the proceedings.",
            "I don't know why we were just commenting that, but we did.",
            "You know, study where we compare different evaluation methods for time series forecasting method strategies and we are using what from this study we conclude it was the best or the more adequate way of comparing these alternatives, OK?",
            "Anne."
        ],
        [
            "So in terms of assemble at your agility, as I mentioned before, we try to build better genius and samples.",
            "OK, so the assumption or the motivation here is that using different models will increase the capability of the ensemble to cope with different regimes or different types of dynamics of the time series.",
            "OK, so we try to increase this capability by using different models.",
            "OK, so namely the base models use either PHMSA or multilayer perception ghosting.",
            "Forces you know we increased.",
            "We included many different learning techniques to obtain the different based models that form our ensemble just to try to increase these.",
            "You know, diversity.",
            "OK, so so in the end the symbol is formed by 58 based models.",
            "OK, and of course then we'll have 50 metal learners.",
            "OK, because if you remember the initial figure for each based model, we have one meta learner.",
            "So we have 5050 based models, each of them obtained with different techniques to increase diversity and then we have 50 also metal learners that in this case all of them are random forest.",
            "So the meta learners are all random forest.",
            "We tried other models but you know the best results we were getting was with random for us.",
            "OK so of course you may wonder why.",
            "Why only 50?",
            "It seems very small ensemble.",
            "We actually analyzed that later on, and the effect was not.",
            "Significant the the sensitivity of the ensemble to the increase of this number was not relevant.",
            "OK, so that's why we end up selecting this number.",
            "Yeah.",
            "Most cases.",
            "So they yeah on the and and arbiters also.",
            "Yeah yeah.",
            "OK, so the idea of these features is that they somehow captured the recent dynamics of the time series, and so they include not only the recent values, but to try to provide some more information.",
            "They include information on the trend and things like that, OK?"
        ],
        [
            "Of course, many things you can add over there I'm we are not claiming that's the best way, but it's just a way to provide information on the status, the current status of the series.",
            "OK, so in terms of similar composition, so at each time step as I mentioned, some of the models will be shut down.",
            "OK, put to sleep OK and namely we select 50% of the models according to their performance in the last 50% fifty observations, OK?",
            "So we use the last 50 observations and we select the top 50 models 50% model.",
            "Sorry, which if the sample is formed by 50 then it will be 25.",
            "So 50% of the models will be selected for the combination and this will be based on observing their performance on a recently on the last 50 observations.",
            "OK again in the end I'll present some experiments where we try to vary these parameters just for you to have an idea of the sensitivity.",
            "Two of the.",
            "The technique to these parameters.",
            "OK so.",
            "So experts are fit on the training data and then they are dynamically combined at runtime.",
            "So during the test period we make a prediction for the next one and then you know we dynamically adjust the weights at each timestep OK?",
            "So arbiters so the metal models are fit using these out of bag out of the bag.",
            "Observations based on this prick Wenczel idea that I mentioned already from the training data, so that when we start the test period the meta models are already reasonably well tuned OK. We tuned every every point or at yeah came K block.",
            "You know I don't remember the exact value of K But you know yes some sometime.",
            "Yeah not at every time step.",
            "Yeah it's probably a parameter of the method but I don't recall much we have used."
        ],
        [
            "So let's have a look at the results.",
            "So the first thing here is to compare these arbitrary dynamic and samples that we are proposing against some state of the art approaches.",
            "OK, so here it's just, you know, some of the state of the art models that we have compared against.",
            "What you see here is that the average rank of our model over this 60 something time series is clearly the best.",
            "This most similar one is this windowing idea, which is similar to our model, probably the most similar one, but the way that things are combined is different.",
            "OK, and then we have here a different other other different standard approaches.",
            "Most of them are ensembles with the exception of Arima.",
            "On this naive, naive is basically trying to make us the forecast for the next value, the last one, the last observed one.",
            "OK, so this is of course the worst model OK, and then we compare against other.",
            "Other standard existing state of the art approach is OK here."
        ],
        [
            "Slightly more extended version of this comparison comparison.",
            "So this is again the average rank, but here we have a kind of standard deviation across the old.",
            "The time series datasets that we have tried on.",
            "You know a few more models that we didn't include on this graph, otherwise it will be a big mess.",
            "OK, but again, we observe that generally our approach achieves the best rank average rank.",
            "And also the variation is slightly smaller OK. No, no it's not.",
            "We didn't use the 100,000, we only use 64 or something.",
            "Something real data sets OK."
        ],
        [
            "OK, so the next thing that we have tried is to try to check what were the advantages of each of the contributions that we had to the standard arbitrating.",
            "OK, so the first one is the question whether it is beneficial to use this wagging schema in the arbitrating approach.",
            "Instead of selecting the best forecaster, OK, instead of using the standard arbitrating which is like I look at the meta models, the meta model say well this is the one that is going to have lowest error so I just use it.",
            "For making the prediction OK, so instead we use this waiting schema.",
            "OK, so is that beneficial so that selecting the best and that's our model and as you see this is somehow beneficial.",
            "By the way this this one is the result publishing XML, so this is already the contribution which is not very big, but the contribution of this redundancy that we have added since the SML paper.",
            "OK, so the original thing that was public.",
            "Is this?",
            "I think this is version zero OK.",
            "Right, so the next."
        ],
        [
            "Thing is that to check if it is beneficial to use out of the back predictions to train the arbiters.",
            "OK, so in this idea of using this prick when shall sing to train the models the meta models.",
            "Is it leading us to gain something and this is the alternative of not using that compared to our models.",
            "And again as you see, this statistically significant advantage of using these this approach of trying to improve the meta models during the training stage already.",
            "OK.",
            "So I I'm not sure I can check, but it's either 5 or 1%.",
            "I'm not sure, but it's something like that.",
            "Yeah, probably I don't know.",
            "I can check that later on the paper.",
            "So."
        ],
        [
            "The next question is whether the performance of our proposal varies or not by the introduction of a committee.",
            "That is this thing of shutting off some models temporarily versus always using them OK, and so this is the our model when we always use all of them, even if with less weights.",
            "OK, compared to our proposal.",
            "So you see, you know a very big gain on this.",
            "This part of our strategy.",
            "OK, so that's where we got to the largest boost in terms of the initial step."
        ],
        [
            "Then we also checked the impact of this reweighting based on this correlation.",
            "OK, so although I will check the suggestion of over there.",
            "But what we have observed all, although not statistically significant, is that over this you know 60 something time series.",
            "We gain something when we introduced this reweighting based on correlation.",
            "OK, which doesn't mean that maybe we can improve this by checking the sort of correlation that we have.",
            "OK?",
            "Actually, I'm not.",
            "Well, we can talk later about that and still thinking about your suggestion."
        ],
        [
            "OK, so the next thing that we have tried to think about is the deployement.",
            "That is how to use this ensemble at runtime when we are getting you a observations and we are trying to use them sample so over there there are also a few alternatives that we could try.",
            "So for instance we could make both the experts an arbiters, the meta models static.",
            "OK so we learn it.",
            "During the training period and then we just keep it like that forever.",
            "OK, and that's this first version.",
            "OK, so both of them are static.",
            "Then we could eventually make the arbiters the meta models every certain amount of observations, retrain them OK. Or we could just retrain the base models, or we could retrain both.",
            "OK, so we tried all these variants to check if something was statistically significant or not."
        ],
        [
            "So this is a summary of the result.",
            "Somehow we are not able to explain why, but apparently not retraining the meta models somehow gives a slight advantage.",
            "We are still exploring why that can be.",
            "Why is that?",
            "So?",
            "Updating the base models is giving us something.",
            "But updating them the base models are not updating the.",
            "The metamodel, somehow it's currently giving us the best results, but we still don't.",
            "Don't know why, but it's not a big difference, but it's you know some difference OK?"
        ],
        [
            "Now then we start to try to study the sensitivity of the ensemble to these two parameters.",
            "OK, so this gamma is the size of the committee.",
            "If you remember, I use 50% of the top models OK. And also I checked the top models using the 50 last predictions.",
            "OK, so we looked.",
            "We estimated the performance using some window back OK, and so we studied.",
            "Somehow the sensitivity of the model.",
            "With this, with respect to these two parameters and you know of course all of this.",
            "This is the average performance overall, datasets OK. And of course this is not true for all datasets.",
            "This is the average performance.",
            "Of course there is some dependent dependencies on the data set, but generally we can observe that as some regions where these parameters provide us the best performance overall.",
            "So that somehow helps on setting the defaults of our method when we provide this as a software we have.",
            "This defaults based on these experiments OK."
        ],
        [
            "Then we also tried to check the issue of the size of the committee.",
            "I told you that we have 50 base models.",
            "Why not more so we try to increase the size of the dens of the base ensembles.",
            "But really, we didn't.",
            "We didn't observe any significant or worthwhile experiment and of course, as you improve the size of the base of the assembled, then you increase the running time and you know on this real time time series that may be an issue so.",
            "There are some tradeoffs and overall we sticked on this 50 based models OK, so and that's actually one of the things that we are currently worded about is the."
        ],
        [
            "The runtime OK. Our model compared to things like standard ARIMA model or even compared to window windowing is computationally more requiring.",
            "OK, it requires more computation time.",
            "OK, because of these meta models that they do not exist on the windowing.",
            "Basically we just look at the past performance, we don't have any extra models that we need to learn.",
            "OK, so that's the only negative side of our approach currently that we see.",
            "It is computationally more demanding than the current state of the art.",
            "OK, so that's our current focus of trying to improve that, but that's the situation currently, OK. OK, so it scales worse than this state of the art."
        ],
        [
            "Alright, so very brief."
        ],
        [
            "Only the main.",
            "If you want scientific contributions of this work is that we have proposed a dynamic arbitrated Anet Originals ensemble for Time series forecasting that you know the results are encouraging in terms of performance.",
            "At least we have proposed an approach for generating data for meta learning using this prick.",
            "When shall, in blocks strategy, and we also have proposed recently this approach for trying to control the redundancy among the experts by using this person correlation to try to, you know.",
            "Handle their eventual interdependency.",
            "OK, so future work.",
            "As I mentioned, we are trying to address this issue of the scalability eventually, instead of having one meta model for each of the base models, maybe we can have a single regression tool which is a multi target regression.",
            "OK, so which will have, you know, will forecast?",
            "The performance but having a multi target regression, so it's a single model instead of several models, but with a multi target regression.",
            "That's something that we want eventually to try OK and then of course we want to study the data space spaces where the model doesn't perform so well to try to understand why and try to somehow cope with these limitations OK?",
            "Alright, so."
        ],
        [
            "The.",
            "All this is available as in our package that you can install and try and play, and you know provide feedback if you want so it's the name is TS ensemble so you can install it for free and you know just play around with it and if you have any feedback and Gino just contact us.",
            "OK, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So it's a pleasure to be here again, so as Eagle was mentioning, this is an extension of work with my student Twitter and also my colleagues back in Porto five you and Carlos.",
                    "label": 0
                },
                {
                    "sent": "And so this is a kind of follow up of the work that we presented at in sculpture last September.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Before client, so I'll talk a bit about, you know the motivation for this work, and then we'll go into the methodology an described experiments.",
                    "label": 0
                },
                {
                    "sent": "You know, the standard outline alright?",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The motivation for this sort of methods is more or less obvious, so we all know that time series are around in many application domains.",
                    "label": 0
                },
                {
                    "sent": "We also know that frequently in most real world problems, this time series are collected from very complex and dynamic environments where the things that we are measured, the time series that we're trying to approximate somehow depends on many external factors that frequently are not.",
                    "label": 0
                },
                {
                    "sent": "Stored or measured.",
                    "label": 0
                },
                {
                    "sent": "So there is all these complex dynamics that makes this task slightly more challenging for real world problems.",
                    "label": 0
                },
                {
                    "sent": "OK, so examples of this abound.",
                    "label": 0
                },
                {
                    "sent": "You know like things like financial analysis, forecasts for stock prices, and also things like you know, intelligent transportation systems an where we try to forecast the shore traffic, short term traffic flow to try to plan in advance.",
                    "label": 0
                },
                {
                    "sent": "The road networks OK, so these are two simple examples of very complex dynamic systems where you have interesting somehow forecasting some variables, But the problems are very complex, OK Now.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Of course, time series analysis is, you know, it's a long time since people are working on this on these areas.",
                    "label": 1
                },
                {
                    "sent": "Really many communities, many research communities approach this problem from different perspectives, and that's nice because you can somehow reuse ideas and adapt ideas, which is a nice thing to do.",
                    "label": 0
                },
                {
                    "sent": "And typically most methods are designed to try to somehow model the temporal dependencies among the observations that we that we store in our database is OK.",
                    "label": 0
                },
                {
                    "sent": "However, you know most time series I have.",
                    "label": 1
                },
                {
                    "sent": "Very clear nonstationarity's and also you know sometime evolving data, complex structures that may require slightly more sophisticated approaches.",
                    "label": 1
                },
                {
                    "sent": "Things like recurring structures due to things like seasonality may become an issue on several real world applications.",
                    "label": 0
                },
                {
                    "sent": "OK, so some of these kind of state of the art, or more standard models end up suffering a bit on this more challenging tasks.",
                    "label": 0
                },
                {
                    "sent": "Although of course any community tries to provide solutions for these things.",
                    "label": 0
                },
                {
                    "sent": "OK, so our setting is basically this sort of complex and you know very dynamic time series and that's what we are trying to handle here.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, now.",
                    "label": 0
                },
                {
                    "sent": "Whenever we have this complex situations, we within machine learning all know that you know combining different models is usually a very good idea or a very good way of trying to include somehow diversity that can cope with this extra complexity.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's one of the things that you can do with this combination.",
                    "label": 0
                },
                {
                    "sent": "So typically here questions involve like selecting the weights of each individual model, which may be challenging, particularly in a.",
                    "label": 0
                },
                {
                    "sent": "Time dependent domains where?",
                    "label": 0
                },
                {
                    "sent": "What is the best model can change very rapidly because of these dynamics of the time series.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Of course, the idea is that recent observations will tend to give you a hint on which models are more adjusted to the current dynamics of the series.",
                    "label": 0
                },
                {
                    "sent": "But of course you need to adjust to things like concept drift and things like effects like that, where different models which were performing very very well suddenly start to perform not so well, OK, and so the idea of using a combination of experts or an assemble if you prefer for this sort of.",
                    "label": 0
                },
                {
                    "sent": "Uh, tasks is that you need to be very careful with the way that you combine these experts.",
                    "label": 0
                },
                {
                    "sent": "That is the way that you reach or select the weights with which each model will have will enter the aggregated procedure prediction of the ensemble OK, and so that's the main challenge.",
                    "label": 0
                },
                {
                    "sent": "Because of these dynamics of the time series.",
                    "label": 0
                },
                {
                    "sent": "OK, so meta learning is also commonly used.",
                    "label": 0
                },
                {
                    "sent": "With, you know approach is similar to stacking where you try to somehow learn a meta model that tried to four tries to forecast the behavior of the different models on different settings OK, and so that's actually one approach that they're going to follow here.",
                    "label": 0
                },
                {
                    "sent": "We're going to use try to use meta learning to come up with.",
                    "label": 0
                },
                {
                    "sent": "You know these weights for the aggregation of the experts.",
                    "label": 0
                },
                {
                    "sent": "OK so.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Just to try to give you a some motivation motivating example.",
                    "label": 0
                },
                {
                    "sent": "So what you see here is in black real World Time series and what you see here is somehow the prediction of two different models.",
                    "label": 0
                },
                {
                    "sent": "These red and blue lines OK and you can observe that at some periods, for instance, the red seems to be, you know better a better fit for this series, but on other regions than the blue becomes.",
                    "label": 1
                },
                {
                    "sent": "Better performing OK, so that's the challenge that you face on these very complex dynamic systems.",
                    "label": 0
                },
                {
                    "sent": "Not a single model will most probably not behave very well on all settings.",
                    "label": 0
                },
                {
                    "sent": "OK, and then you may have.",
                    "label": 0
                },
                {
                    "sent": "You may try to gain from this diversity of among the different models and somehow combine them in a clever way such that you can take advantage of this thing OK?",
                    "label": 1
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the main goal then is to dynamically combine these models across the time series in a real time.",
                    "label": 1
                },
                {
                    "sent": "You know setting where you try to guess what is the best combination for the next forecast.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The idea then is to use a meta learning method that can handle this sort of dynamic environments and that can select a.",
                    "label": 0
                },
                {
                    "sent": "Some stages give more importance.",
                    "label": 0
                },
                {
                    "sent": "One of the models at some stages, it gives more important to the other, and so on and so forth so that we can have a prediction that is a combination.",
                    "label": 0
                },
                {
                    "sent": "Of course is a simplistic example with only two models we are not going to combine two models, of course, but the idea is to try to take advantage of the the places or the times or the time regions where each model behaves better than the others OK?",
                    "label": 0
                },
                {
                    "sent": "So that's the idea, right?",
                    "label": 0
                },
                {
                    "sent": "So this meta learning method will try to perform a dynamic weighing of the models that she sighs timestep.",
                    "label": 0
                },
                {
                    "sent": "So these weights are dynamic in the sense that they change change through time.",
                    "label": 0
                },
                {
                    "sent": "They are not fixed.",
                    "label": 0
                },
                {
                    "sent": "And then of course we will also try to handle the interdependency among experts because we may have different models which are somehow correlated their performance, and so we don't want to.",
                    "label": 0
                },
                {
                    "sent": "Put them together in the ensemble decisions OK?",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so let's try to give a bit more detail on the methodology of proposing here, so it's called arbitrating forecasters and.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the idea is that we have.",
                    "label": 0
                },
                {
                    "sent": "A set of base models that try to approximate a time series.",
                    "label": 0
                },
                {
                    "sent": "OK, so these are our base models that will form this ensemble.",
                    "label": 0
                },
                {
                    "sent": "OK, so this based models essentially they try to forecast the next value of the time series using the previous values, or eventually some further features that we think are important to try to forecast the future behavior of the time series.",
                    "label": 0
                },
                {
                    "sent": "OK between the simplistic way we essentially use the recent past values.",
                    "label": 0
                },
                {
                    "sent": "And we tried to forecast the next one OK, But we can enrich somehow these features to try to improve the performance of the models.",
                    "label": 0
                },
                {
                    "sent": "OK, and then what we need given that we have this set of models, each of them making a forecast for the next value of the time series.",
                    "label": 0
                },
                {
                    "sent": "And we need a way to combine them using some criteria.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Arbitrating this models essentially consists of trying to learn associated with each of these based models.",
                    "label": 0
                },
                {
                    "sent": "Learn a kind of meta model and that's the idea of arbitrating.",
                    "label": 0
                },
                {
                    "sent": "We tried to learn a model that tries to forecast what will be the error of each of these models.",
                    "label": 0
                },
                {
                    "sent": "OK, so this meta models here tried to forecast what will be the error of each of these models.",
                    "label": 0
                },
                {
                    "sent": "OK, so that.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The idea so this meta models their predictions is the estimated error of the respective based model OK, and so they again they use some features that describe the current state of the time series and then based on this current state they try to forecast what will be the error of the model.",
                    "label": 0
                },
                {
                    "sent": "OK now.",
                    "label": 0
                },
                {
                    "sent": "These models again are learn using the training data that we have.",
                    "label": 0
                },
                {
                    "sent": "That is, the past performance of the models and so they somehow learn how the model behaves for each different dynamics of the time series OK?",
                    "label": 1
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "An alternative to arbitrating is something which is more of.",
                    "label": 0
                },
                {
                    "sent": "Frequent to do on this time series and samples, which is win doing OK.",
                    "label": 1
                },
                {
                    "sent": "So in windway you basically look for the recent performance of the models of the base models, and then using these recent performance you somehow reach the weight of each of these models.",
                    "label": 1
                },
                {
                    "sent": "OK, arbitrating is different because what we learn we don't look only to the recent performance.",
                    "label": 1
                },
                {
                    "sent": "We learn a meta model that learn that is learned using all the performance during all history, OK?",
                    "label": 0
                },
                {
                    "sent": "So if you have things like a recurrent events because at some stage with some dynamics this was the best model and now we are at a different dynamics.",
                    "label": 0
                },
                {
                    "sent": "But suddenly we are moving to this same dynamics then this meta models no because they have this history and they know that within this context this model is going to be better than the other ones.",
                    "label": 0
                },
                {
                    "sent": "OK, so there are slightly more interesting in terms of long range modeling than win doing because we doing just look at looks at the very recent performance OK?",
                    "label": 0
                },
                {
                    "sent": "And it takes time to adjust to a new setting.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's what we expect to gain from windowing, which is a more frequent way of combining time series models within these tasks, OK?",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so arbitrating is not a new concept of course, so this was actually proposed in the context of classification tasks.",
                    "label": 0
                },
                {
                    "sent": "For, you know, for arbitrating ensembles of classifiers.",
                    "label": 0
                },
                {
                    "sent": "So essentially the original idea of arbitrating was to use these meta models to select one model.",
                    "label": 0
                },
                {
                    "sent": "One of the base classifiers as the one that is going to prevail OK. And so we somehow rework this idea.",
                    "label": 0
                },
                {
                    "sent": "And try to apply to this time series forecasting an we are going to make a few adjustments but the original concept of arbitrating is not ours, it's something which was done before for classification.",
                    "label": 0
                },
                {
                    "sent": "Things OK. Also related are these concepts of mixture of experts which is somehow similar to arbitrating but mixture of experts do not try to model the error of the of the base models.",
                    "label": 0
                },
                {
                    "sent": "OK so they use this gating networks.",
                    "label": 0
                },
                {
                    "sent": "That tried to compute directly the weights of the experts and the way that the diversity of the models is handle is also very different from from arbitrating experts.",
                    "label": 0
                },
                {
                    "sent": "OK now.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So at each time step, our proposal essentially tries to come up with a prediction of the ensemble that is based on a weighted combination of the predictions of the base models.",
                    "label": 0
                },
                {
                    "sent": "OK, but these weights with which each of the models enters the final prediction depends on the opinion of this method.",
                    "label": 0
                },
                {
                    "sent": "Learners OK, so these metal learners will estimate the error of these.",
                    "label": 0
                },
                {
                    "sent": "Each of these models.",
                    "label": 0
                },
                {
                    "sent": "Then based on these errors we do some.",
                    "label": 0
                },
                {
                    "sent": "Scaling to come up with some weights for each of the models, and then it's these weights that are used to reach the final combined prediction.",
                    "label": 0
                },
                {
                    "sent": "OK, now we.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Made a small change to this process by eliminating at each time step we may kind of suspend some of the models of the ensemble OK and the motivation for that again is to try to adjust better.",
                    "label": 0
                },
                {
                    "sent": "A better adjust to the different dynamics throughout time.",
                    "label": 0
                },
                {
                    "sent": "OK, because maybe some models at some stages at some dynamics are two batch OK and even if their weight is too low they end up having some impact.",
                    "label": 0
                },
                {
                    "sent": "OK, if we have like 10 models which are.",
                    "label": 0
                },
                {
                    "sent": "All very bad, even if they have a low weight, they somehow influenced the predictors.",
                    "label": 0
                },
                {
                    "sent": "OK, So what we do is that at each time step we suspend, we may decide to suspend or reactivate some of the models that form the base learners OK, and so they can.",
                    "label": 0
                },
                {
                    "sent": "They are not thrown away, but they are kind of put to sleep because at this stage they are not performing very well and this is always always controlled by the opinion of this metal learners OK?",
                    "label": 0
                },
                {
                    "sent": "If the metal is expected model to be to have very low error even if he was asleep before then, is waken and then it enters the den symbol.",
                    "label": 1
                },
                {
                    "sent": "OK so basically in terms of an implementation we at each time step with the top Lambda percent models.",
                    "label": 1
                },
                {
                    "sent": "And this.",
                    "label": 0
                },
                {
                    "sent": "Top is calculated looking at some past performance, not only the last one like the past.",
                    "label": 0
                },
                {
                    "sent": "Looking at the performance in the last, let's say two weeks, these are the top Alpha performance or top Lambda performance.",
                    "label": 0
                },
                {
                    "sent": "OK, and so these are the ones which entered the final combined prediction of the ensemble.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's another feature that we use not only using meta learning, but then in the dynamic ensemble composition.",
                    "label": 0
                },
                {
                    "sent": "We use this trick of eventually.",
                    "label": 0
                },
                {
                    "sent": "Putting asleep temporally.",
                    "label": 0
                },
                {
                    "sent": "Some of the models OK.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then another thing that we have.",
                    "label": 0
                },
                {
                    "sent": "Change compared to the original arbitrating is the way that the metal learning approaches are somehow used.",
                    "label": 0
                },
                {
                    "sent": "OK, so the standard meta learning approaches.",
                    "label": 0
                },
                {
                    "sent": "Typically they start model selection at deployment time.",
                    "label": 0
                },
                {
                    "sent": "OK, so in order to try and because of that then the meta learners take some time before they perform well, because here we have a time evolving scenario.",
                    "label": 0
                },
                {
                    "sent": "We said.",
                    "label": 0
                },
                {
                    "sent": "Well maybe it's good that.",
                    "label": 0
                },
                {
                    "sent": "During training time with user kind of prick, when shall strategy to start to learn already the metal learners so that when we reach finally the test set, we already have a good meta learner which was trained during all these periods OK and so we use a kind of out of the bag process where the metal learner is somehow checked against this test set and so that the meta learner is improved.",
                    "label": 0
                },
                {
                    "sent": "Throughout the training period, OK, so that's another if you want kind of trick that we have added to the standard arbitrating so that we could take advantage of the fact that we have a time series so we can kind of follow this time flow OK?",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "The other issue that I mentioned, which is important that we have started on, actually that's the main one of the main changes compared to the XML paper that I mentioned that this work is well.",
                    "label": 0
                },
                {
                    "sent": "This is one of the most recent extensions that we have made is to try to handle interdependency among the base models.",
                    "label": 1
                },
                {
                    "sent": "OK, so we may have based models which are very correlated with each other, and so then what we do.",
                    "label": 0
                },
                {
                    "sent": "A standard arbitrating model analyzes each expert separatedly OK an so this can be somehow dangerous or can be a limitation if there are interdependencies among these based learners.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "So we somehow try to encourage this diversity not only by having different based models with different techniques, but also the way that we aggregate their opinions should try to cope with this interdependency.",
                    "label": 0
                },
                {
                    "sent": "OK, so",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "How do we do that?",
                    "label": 0
                },
                {
                    "sent": "So we basically tackle the first issue of trying to have diversity by employing eater genius and sample.",
                    "label": 0
                },
                {
                    "sent": "So that means that our base models are very different from each other in terms of algorithms that are used to build each base model.",
                    "label": 1
                },
                {
                    "sent": "OK, so we don't have an homogeneous and somehow we have a very pure genius and sampled that uses different techniques that I'm going to tell you later on.",
                    "label": 0
                },
                {
                    "sent": "OK, so regarding the second issue of this.",
                    "label": 0
                },
                {
                    "sent": "Interdependency.",
                    "label": 0
                },
                {
                    "sent": "What we do is that we explicitly re wait.",
                    "label": 1
                },
                {
                    "sent": "The experts teach predictions, step according to their recent correlation.",
                    "label": 0
                },
                {
                    "sent": "OK, so we we come up with these weights that I've explained before, but then these weights are changed according to the correlation of the predictions of the experts.",
                    "label": 0
                },
                {
                    "sent": "OK, so how do we do?",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But we basically took this idea.",
                    "label": 0
                },
                {
                    "sent": "If you want this inspiration from information retrieval literature.",
                    "label": 0
                },
                {
                    "sent": "So whenever you do some query you come up with the ranking of related documents, but then you know you somehow adjust this thing because if you have like the second most relevant document, if it is very related with the first one that you already suggested, you somehow want to decrease, it's important.",
                    "label": 0
                },
                {
                    "sent": "OK, so you want to take care of this.",
                    "label": 0
                },
                {
                    "sent": "Correlation between the things and provide the ranking OK, and so we kind of follow the same idea and so we have.",
                    "label": 0
                },
                {
                    "sent": "We rank our models by their weights, but then we select the first one for the combined prediction.",
                    "label": 0
                },
                {
                    "sent": "But then the second one before we select it, we check if it is very correlated to this first one.",
                    "label": 0
                },
                {
                    "sent": "If it is very correlated recently their predictions then we decrease its weight.",
                    "label": 0
                },
                {
                    "sent": "So it goes down in the rank.",
                    "label": 0
                },
                {
                    "sent": "OK, so we kind of re weight the weights.",
                    "label": 0
                },
                {
                    "sent": "Of the experts with which they entered this combined prediction based on this idea based on the correlation to the models that are already included on the combination.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's more or less what we.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Do we use the person correlation coefficient to try to adjust these weights based on our correlated R?",
                    "label": 0
                },
                {
                    "sent": "The predictions recently on a recent time window OK?",
                    "label": 0
                },
                {
                    "sent": "So that's the final thing that we have adjusted.",
                    "label": 0
                },
                {
                    "sent": "OK so yeah, yeah.",
                    "label": 0
                },
                {
                    "sent": "Airbook correlated actually.",
                    "label": 0
                },
                {
                    "sent": "I want them to have higher.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah, they are inversely correlated, you mean.",
                    "label": 0
                },
                {
                    "sent": "They have the same multiple first one over should stick around other ships OK. Take the average of both.",
                    "label": 0
                },
                {
                    "sent": "You get the the correct prediction.",
                    "label": 0
                },
                {
                    "sent": "Use the weight of one of them.",
                    "label": 0
                },
                {
                    "sent": "Actually, you're losing a lot of information.",
                    "label": 0
                },
                {
                    "sent": "That's actually a.",
                    "label": 0
                },
                {
                    "sent": "A possibility I think, although outside I'm not completely sure if the meta learner model will not somehow provide that information on the error.",
                    "label": 0
                },
                {
                    "sent": "That person at the end.",
                    "label": 0
                },
                {
                    "sent": "The little one, yeah, but what I mean is that.",
                    "label": 0
                },
                {
                    "sent": "What I mean is that the original weights are based on the estimated error by the metal metal model, yeah?",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah, maybe maybe.",
                    "label": 0
                },
                {
                    "sent": "Maybe you have a point.",
                    "label": 0
                },
                {
                    "sent": "There maybe should be something that we should check.",
                    "label": 0
                },
                {
                    "sent": "If that is not happening.",
                    "label": 0
                },
                {
                    "sent": "Yeah, thank you.",
                    "label": 0
                },
                {
                    "sent": "A.",
                    "label": 0
                },
                {
                    "sent": "To understand it.",
                    "label": 0
                },
                {
                    "sent": "No correlated models can help, right?",
                    "label": 0
                },
                {
                    "sent": "Situations where they would reinforce right?",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah, but but going back to your question so it doesn't mean that they get out of the ensemble, they just get their weight slightly decreased, OK?",
                    "label": 0
                },
                {
                    "sent": "So they will still help.",
                    "label": 0
                },
                {
                    "sent": "It's not like 01, but they will get.",
                    "label": 0
                },
                {
                    "sent": "Maybe it's instead of being on the 2nd place.",
                    "label": 0
                },
                {
                    "sent": "Maybe it is on the 4th or something like that, so they will have their impact slightly reduced.",
                    "label": 0
                },
                {
                    "sent": "So in this extreme situation where summing up them that will be the perfect perfect prediction.",
                    "label": 0
                },
                {
                    "sent": "Then of course we are losing something.",
                    "label": 0
                },
                {
                    "sent": "Please contact.",
                    "label": 0
                },
                {
                    "sent": "Actually.",
                    "label": 0
                },
                {
                    "sent": "The kids can have some.",
                    "label": 0
                },
                {
                    "sent": "Many situations can happen like that because yeah.",
                    "label": 0
                },
                {
                    "sent": "Perfect.",
                    "label": 0
                },
                {
                    "sent": "I mean definitely something that that we should check.",
                    "label": 0
                },
                {
                    "sent": "Yeah, definitely that's.",
                    "label": 0
                },
                {
                    "sent": "I'm not, I'm not completely sure whether Victor didn't check that because we did lots of plots where we were seeing the, but I don't recall that.",
                    "label": 0
                },
                {
                    "sent": "But I mean definitely, that's something that we should check.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now let's move into the kind of experiments that we have carried out with this idea so.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Essentially, we have played with 62 real World Time series from very different domains.",
                    "label": 0
                },
                {
                    "sent": "They also rank their ranges vary a lot.",
                    "label": 0
                },
                {
                    "sent": "Just out of comparison, there is this famous time series competitions this M1234.",
                    "label": 0
                },
                {
                    "sent": "Before, as roughly one 100,000 time series on, you know, only three and a half percent of this.",
                    "label": 0
                },
                {
                    "sent": "I have more than seven 750 observations, so we somehow have slightly larger time series because I think this, you know nowadays is very easy to get.",
                    "label": 0
                },
                {
                    "sent": "Very big time series, so I think it's important to have slightly larger time series so that you can capture you know different regimes across time.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's something that we have tried to.",
                    "label": 0
                },
                {
                    "sent": "Increase the size compared to these more standard benchmarks, OK?",
                    "label": 0
                },
                {
                    "sent": "5% of 100,000, what is?",
                    "label": 0
                },
                {
                    "sent": "So this is one kind of benchmark competition that exists on time series forecasting this M1 and two and they have like 100,000 time series in the competition.",
                    "label": 0
                },
                {
                    "sent": "OK and only three 100% of this are larger than 750 but I think.",
                    "label": 0
                },
                {
                    "sent": "That somehow is not realistic, I think because most of the time series nowadays are relatively big, so we try to.",
                    "label": 0
                },
                {
                    "sent": "Do you slightly bigger the time series?",
                    "label": 0
                },
                {
                    "sent": "OK, that's kind of an explanation.",
                    "label": 0
                },
                {
                    "sent": "Why haven't we use this kind of benchmark?",
                    "label": 0
                },
                {
                    "sent": "Because we could, of course applied our sync to this 100,000.",
                    "label": 0
                },
                {
                    "sent": "OK, of course it would take a bit more time, but anyway it would.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah I would say it's pretty short, but comparing to some of the benchmarks used in this area, it's not short.",
                    "label": 0
                },
                {
                    "sent": "That's why I'm trying to.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, so in terms of modeling the construction of the base models, we have used the standard strategy of using the embedding of the recent observations of the time series.",
                    "label": 0
                },
                {
                    "sent": "That is, the wrist and recent K values of the time series, and we have used.",
                    "label": 1
                },
                {
                    "sent": "You know, these false nearest neighbor method to estimate the size of this embedding.",
                    "label": 0
                },
                {
                    "sent": "OK, but on top of that we have also added as features as input features to the models, afew summary statistics whose idea is to try to.",
                    "label": 0
                },
                {
                    "sent": "You know illustrates some of the recent dynamics of the time series.",
                    "label": 1
                },
                {
                    "sent": "OK, so things like the trend, you know, the skewness, you know long term, long range dependence.",
                    "label": 0
                },
                {
                    "sent": "You know things like that.",
                    "label": 0
                },
                {
                    "sent": "We have tried to create features to put, to add to the models, to add to this embedding, which is the more standard sink.",
                    "label": 0
                },
                {
                    "sent": "OK, so in order to try to improve the quality of the base models, OK?",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now, in terms of evaluation, we were.",
                    "label": 0
                },
                {
                    "sent": "We compared all the approaches that I'm going to show the results using out of the sample in multiple testing periods, which you know some of our recent work together also with vigor.",
                    "label": 0
                },
                {
                    "sent": "And we were just complaining.",
                    "label": 0
                },
                {
                    "sent": "No, this one.",
                    "label": 0
                },
                {
                    "sent": "This one is still not somehow, although it is from October, it's still not in the proceedings.",
                    "label": 0
                },
                {
                    "sent": "I don't know why we were just commenting that, but we did.",
                    "label": 0
                },
                {
                    "sent": "You know, study where we compare different evaluation methods for time series forecasting method strategies and we are using what from this study we conclude it was the best or the more adequate way of comparing these alternatives, OK?",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in terms of assemble at your agility, as I mentioned before, we try to build better genius and samples.",
                    "label": 0
                },
                {
                    "sent": "OK, so the assumption or the motivation here is that using different models will increase the capability of the ensemble to cope with different regimes or different types of dynamics of the time series.",
                    "label": 0
                },
                {
                    "sent": "OK, so we try to increase this capability by using different models.",
                    "label": 0
                },
                {
                    "sent": "OK, so namely the base models use either PHMSA or multilayer perception ghosting.",
                    "label": 0
                },
                {
                    "sent": "Forces you know we increased.",
                    "label": 0
                },
                {
                    "sent": "We included many different learning techniques to obtain the different based models that form our ensemble just to try to increase these.",
                    "label": 0
                },
                {
                    "sent": "You know, diversity.",
                    "label": 0
                },
                {
                    "sent": "OK, so so in the end the symbol is formed by 58 based models.",
                    "label": 0
                },
                {
                    "sent": "OK, and of course then we'll have 50 metal learners.",
                    "label": 0
                },
                {
                    "sent": "OK, because if you remember the initial figure for each based model, we have one meta learner.",
                    "label": 0
                },
                {
                    "sent": "So we have 5050 based models, each of them obtained with different techniques to increase diversity and then we have 50 also metal learners that in this case all of them are random forest.",
                    "label": 0
                },
                {
                    "sent": "So the meta learners are all random forest.",
                    "label": 0
                },
                {
                    "sent": "We tried other models but you know the best results we were getting was with random for us.",
                    "label": 0
                },
                {
                    "sent": "OK so of course you may wonder why.",
                    "label": 0
                },
                {
                    "sent": "Why only 50?",
                    "label": 0
                },
                {
                    "sent": "It seems very small ensemble.",
                    "label": 0
                },
                {
                    "sent": "We actually analyzed that later on, and the effect was not.",
                    "label": 0
                },
                {
                    "sent": "Significant the the sensitivity of the ensemble to the increase of this number was not relevant.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's why we end up selecting this number.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Most cases.",
                    "label": 0
                },
                {
                    "sent": "So they yeah on the and and arbiters also.",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah.",
                    "label": 0
                },
                {
                    "sent": "OK, so the idea of these features is that they somehow captured the recent dynamics of the time series, and so they include not only the recent values, but to try to provide some more information.",
                    "label": 0
                },
                {
                    "sent": "They include information on the trend and things like that, OK?",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of course, many things you can add over there I'm we are not claiming that's the best way, but it's just a way to provide information on the status, the current status of the series.",
                    "label": 0
                },
                {
                    "sent": "OK, so in terms of similar composition, so at each time step as I mentioned, some of the models will be shut down.",
                    "label": 0
                },
                {
                    "sent": "OK, put to sleep OK and namely we select 50% of the models according to their performance in the last 50% fifty observations, OK?",
                    "label": 0
                },
                {
                    "sent": "So we use the last 50 observations and we select the top 50 models 50% model.",
                    "label": 0
                },
                {
                    "sent": "Sorry, which if the sample is formed by 50 then it will be 25.",
                    "label": 0
                },
                {
                    "sent": "So 50% of the models will be selected for the combination and this will be based on observing their performance on a recently on the last 50 observations.",
                    "label": 0
                },
                {
                    "sent": "OK again in the end I'll present some experiments where we try to vary these parameters just for you to have an idea of the sensitivity.",
                    "label": 0
                },
                {
                    "sent": "Two of the.",
                    "label": 0
                },
                {
                    "sent": "The technique to these parameters.",
                    "label": 0
                },
                {
                    "sent": "OK so.",
                    "label": 0
                },
                {
                    "sent": "So experts are fit on the training data and then they are dynamically combined at runtime.",
                    "label": 0
                },
                {
                    "sent": "So during the test period we make a prediction for the next one and then you know we dynamically adjust the weights at each timestep OK?",
                    "label": 0
                },
                {
                    "sent": "So arbiters so the metal models are fit using these out of bag out of the bag.",
                    "label": 0
                },
                {
                    "sent": "Observations based on this prick Wenczel idea that I mentioned already from the training data, so that when we start the test period the meta models are already reasonably well tuned OK. We tuned every every point or at yeah came K block.",
                    "label": 0
                },
                {
                    "sent": "You know I don't remember the exact value of K But you know yes some sometime.",
                    "label": 0
                },
                {
                    "sent": "Yeah not at every time step.",
                    "label": 0
                },
                {
                    "sent": "Yeah it's probably a parameter of the method but I don't recall much we have used.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's have a look at the results.",
                    "label": 0
                },
                {
                    "sent": "So the first thing here is to compare these arbitrary dynamic and samples that we are proposing against some state of the art approaches.",
                    "label": 0
                },
                {
                    "sent": "OK, so here it's just, you know, some of the state of the art models that we have compared against.",
                    "label": 0
                },
                {
                    "sent": "What you see here is that the average rank of our model over this 60 something time series is clearly the best.",
                    "label": 0
                },
                {
                    "sent": "This most similar one is this windowing idea, which is similar to our model, probably the most similar one, but the way that things are combined is different.",
                    "label": 0
                },
                {
                    "sent": "OK, and then we have here a different other other different standard approaches.",
                    "label": 0
                },
                {
                    "sent": "Most of them are ensembles with the exception of Arima.",
                    "label": 0
                },
                {
                    "sent": "On this naive, naive is basically trying to make us the forecast for the next value, the last one, the last observed one.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is of course the worst model OK, and then we compare against other.",
                    "label": 0
                },
                {
                    "sent": "Other standard existing state of the art approach is OK here.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Slightly more extended version of this comparison comparison.",
                    "label": 0
                },
                {
                    "sent": "So this is again the average rank, but here we have a kind of standard deviation across the old.",
                    "label": 0
                },
                {
                    "sent": "The time series datasets that we have tried on.",
                    "label": 0
                },
                {
                    "sent": "You know a few more models that we didn't include on this graph, otherwise it will be a big mess.",
                    "label": 0
                },
                {
                    "sent": "OK, but again, we observe that generally our approach achieves the best rank average rank.",
                    "label": 0
                },
                {
                    "sent": "And also the variation is slightly smaller OK. No, no it's not.",
                    "label": 0
                },
                {
                    "sent": "We didn't use the 100,000, we only use 64 or something.",
                    "label": 0
                },
                {
                    "sent": "Something real data sets OK.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so the next thing that we have tried is to try to check what were the advantages of each of the contributions that we had to the standard arbitrating.",
                    "label": 0
                },
                {
                    "sent": "OK, so the first one is the question whether it is beneficial to use this wagging schema in the arbitrating approach.",
                    "label": 0
                },
                {
                    "sent": "Instead of selecting the best forecaster, OK, instead of using the standard arbitrating which is like I look at the meta models, the meta model say well this is the one that is going to have lowest error so I just use it.",
                    "label": 0
                },
                {
                    "sent": "For making the prediction OK, so instead we use this waiting schema.",
                    "label": 0
                },
                {
                    "sent": "OK, so is that beneficial so that selecting the best and that's our model and as you see this is somehow beneficial.",
                    "label": 0
                },
                {
                    "sent": "By the way this this one is the result publishing XML, so this is already the contribution which is not very big, but the contribution of this redundancy that we have added since the SML paper.",
                    "label": 0
                },
                {
                    "sent": "OK, so the original thing that was public.",
                    "label": 0
                },
                {
                    "sent": "Is this?",
                    "label": 0
                },
                {
                    "sent": "I think this is version zero OK.",
                    "label": 0
                },
                {
                    "sent": "Right, so the next.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Thing is that to check if it is beneficial to use out of the back predictions to train the arbiters.",
                    "label": 1
                },
                {
                    "sent": "OK, so in this idea of using this prick when shall sing to train the models the meta models.",
                    "label": 1
                },
                {
                    "sent": "Is it leading us to gain something and this is the alternative of not using that compared to our models.",
                    "label": 0
                },
                {
                    "sent": "And again as you see, this statistically significant advantage of using these this approach of trying to improve the meta models during the training stage already.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So I I'm not sure I can check, but it's either 5 or 1%.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure, but it's something like that.",
                    "label": 0
                },
                {
                    "sent": "Yeah, probably I don't know.",
                    "label": 0
                },
                {
                    "sent": "I can check that later on the paper.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The next question is whether the performance of our proposal varies or not by the introduction of a committee.",
                    "label": 0
                },
                {
                    "sent": "That is this thing of shutting off some models temporarily versus always using them OK, and so this is the our model when we always use all of them, even if with less weights.",
                    "label": 0
                },
                {
                    "sent": "OK, compared to our proposal.",
                    "label": 0
                },
                {
                    "sent": "So you see, you know a very big gain on this.",
                    "label": 0
                },
                {
                    "sent": "This part of our strategy.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's where we got to the largest boost in terms of the initial step.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then we also checked the impact of this reweighting based on this correlation.",
                    "label": 0
                },
                {
                    "sent": "OK, so although I will check the suggestion of over there.",
                    "label": 0
                },
                {
                    "sent": "But what we have observed all, although not statistically significant, is that over this you know 60 something time series.",
                    "label": 0
                },
                {
                    "sent": "We gain something when we introduced this reweighting based on correlation.",
                    "label": 0
                },
                {
                    "sent": "OK, which doesn't mean that maybe we can improve this by checking the sort of correlation that we have.",
                    "label": 0
                },
                {
                    "sent": "OK?",
                    "label": 0
                },
                {
                    "sent": "Actually, I'm not.",
                    "label": 0
                },
                {
                    "sent": "Well, we can talk later about that and still thinking about your suggestion.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so the next thing that we have tried to think about is the deployement.",
                    "label": 0
                },
                {
                    "sent": "That is how to use this ensemble at runtime when we are getting you a observations and we are trying to use them sample so over there there are also a few alternatives that we could try.",
                    "label": 0
                },
                {
                    "sent": "So for instance we could make both the experts an arbiters, the meta models static.",
                    "label": 0
                },
                {
                    "sent": "OK so we learn it.",
                    "label": 0
                },
                {
                    "sent": "During the training period and then we just keep it like that forever.",
                    "label": 0
                },
                {
                    "sent": "OK, and that's this first version.",
                    "label": 0
                },
                {
                    "sent": "OK, so both of them are static.",
                    "label": 0
                },
                {
                    "sent": "Then we could eventually make the arbiters the meta models every certain amount of observations, retrain them OK. Or we could just retrain the base models, or we could retrain both.",
                    "label": 0
                },
                {
                    "sent": "OK, so we tried all these variants to check if something was statistically significant or not.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is a summary of the result.",
                    "label": 0
                },
                {
                    "sent": "Somehow we are not able to explain why, but apparently not retraining the meta models somehow gives a slight advantage.",
                    "label": 0
                },
                {
                    "sent": "We are still exploring why that can be.",
                    "label": 0
                },
                {
                    "sent": "Why is that?",
                    "label": 0
                },
                {
                    "sent": "So?",
                    "label": 0
                },
                {
                    "sent": "Updating the base models is giving us something.",
                    "label": 0
                },
                {
                    "sent": "But updating them the base models are not updating the.",
                    "label": 0
                },
                {
                    "sent": "The metamodel, somehow it's currently giving us the best results, but we still don't.",
                    "label": 0
                },
                {
                    "sent": "Don't know why, but it's not a big difference, but it's you know some difference OK?",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now then we start to try to study the sensitivity of the ensemble to these two parameters.",
                    "label": 0
                },
                {
                    "sent": "OK, so this gamma is the size of the committee.",
                    "label": 1
                },
                {
                    "sent": "If you remember, I use 50% of the top models OK. And also I checked the top models using the 50 last predictions.",
                    "label": 0
                },
                {
                    "sent": "OK, so we looked.",
                    "label": 0
                },
                {
                    "sent": "We estimated the performance using some window back OK, and so we studied.",
                    "label": 0
                },
                {
                    "sent": "Somehow the sensitivity of the model.",
                    "label": 1
                },
                {
                    "sent": "With this, with respect to these two parameters and you know of course all of this.",
                    "label": 0
                },
                {
                    "sent": "This is the average performance overall, datasets OK. And of course this is not true for all datasets.",
                    "label": 0
                },
                {
                    "sent": "This is the average performance.",
                    "label": 0
                },
                {
                    "sent": "Of course there is some dependent dependencies on the data set, but generally we can observe that as some regions where these parameters provide us the best performance overall.",
                    "label": 0
                },
                {
                    "sent": "So that somehow helps on setting the defaults of our method when we provide this as a software we have.",
                    "label": 0
                },
                {
                    "sent": "This defaults based on these experiments OK.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then we also tried to check the issue of the size of the committee.",
                    "label": 0
                },
                {
                    "sent": "I told you that we have 50 base models.",
                    "label": 0
                },
                {
                    "sent": "Why not more so we try to increase the size of the dens of the base ensembles.",
                    "label": 0
                },
                {
                    "sent": "But really, we didn't.",
                    "label": 0
                },
                {
                    "sent": "We didn't observe any significant or worthwhile experiment and of course, as you improve the size of the base of the assembled, then you increase the running time and you know on this real time time series that may be an issue so.",
                    "label": 0
                },
                {
                    "sent": "There are some tradeoffs and overall we sticked on this 50 based models OK, so and that's actually one of the things that we are currently worded about is the.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The runtime OK. Our model compared to things like standard ARIMA model or even compared to window windowing is computationally more requiring.",
                    "label": 0
                },
                {
                    "sent": "OK, it requires more computation time.",
                    "label": 0
                },
                {
                    "sent": "OK, because of these meta models that they do not exist on the windowing.",
                    "label": 0
                },
                {
                    "sent": "Basically we just look at the past performance, we don't have any extra models that we need to learn.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's the only negative side of our approach currently that we see.",
                    "label": 0
                },
                {
                    "sent": "It is computationally more demanding than the current state of the art.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's our current focus of trying to improve that, but that's the situation currently, OK. OK, so it scales worse than this state of the art.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so very brief.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Only the main.",
                    "label": 0
                },
                {
                    "sent": "If you want scientific contributions of this work is that we have proposed a dynamic arbitrated Anet Originals ensemble for Time series forecasting that you know the results are encouraging in terms of performance.",
                    "label": 0
                },
                {
                    "sent": "At least we have proposed an approach for generating data for meta learning using this prick.",
                    "label": 0
                },
                {
                    "sent": "When shall, in blocks strategy, and we also have proposed recently this approach for trying to control the redundancy among the experts by using this person correlation to try to, you know.",
                    "label": 0
                },
                {
                    "sent": "Handle their eventual interdependency.",
                    "label": 0
                },
                {
                    "sent": "OK, so future work.",
                    "label": 0
                },
                {
                    "sent": "As I mentioned, we are trying to address this issue of the scalability eventually, instead of having one meta model for each of the base models, maybe we can have a single regression tool which is a multi target regression.",
                    "label": 0
                },
                {
                    "sent": "OK, so which will have, you know, will forecast?",
                    "label": 0
                },
                {
                    "sent": "The performance but having a multi target regression, so it's a single model instead of several models, but with a multi target regression.",
                    "label": 0
                },
                {
                    "sent": "That's something that we want eventually to try OK and then of course we want to study the data space spaces where the model doesn't perform so well to try to understand why and try to somehow cope with these limitations OK?",
                    "label": 0
                },
                {
                    "sent": "Alright, so.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "All this is available as in our package that you can install and try and play, and you know provide feedback if you want so it's the name is TS ensemble so you can install it for free and you know just play around with it and if you have any feedback and Gino just contact us.",
                    "label": 0
                },
                {
                    "sent": "OK, thank you.",
                    "label": 0
                }
            ]
        }
    }
}