{
    "id": "sbfq4m76phznmkbrkyti7pi2onig7nug",
    "title": "Combining Truth Discovery and RDF Knowledge Bases to their mutual advantage",
    "info": {
        "author": [
            "Valentina Beretta, IMT Mines Ales"
        ],
        "published": "Nov. 22, 2018",
        "recorded": "October 2018",
        "category": [
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/iswc2018_beretta_combinin_truth_discovery/",
    "segmentation": [
        [
            "Hello to everyone and Valentina and today I will present this study conducted in collaboration with Sebastian Aries, Person Villanueva and Isabella Motional.",
            "You"
        ],
        [
            "In this presentation we see the intuition behind this study, how to discovery can benefit from the user of the Knowledge Express said into RDF knowledge basis and whichever some.",
            "Then we will formalize the true discovery problem and we will see the model.",
            "We propose a in order to incorporate the knowledge Express into RDF knowledge basis into through discovery.",
            "Ask A we will see the experiment we conducted and the main findings resulting from them.",
            "So what is the intuition?"
        ],
        [
            "Behind the our study.",
            "On one side we have through discovery that aims to identify in the factor among a set of conflicting claims that are provided by multiple sources.",
            "On the other side we have MTF knowledge bases that already contain facts about the world.",
            "So in both cases we spoke about factor and our idea."
        ],
        [
            "Was to use the Factor Express in RDF knowledge basis to improve through discovery model and we conducted our first preliminary preliminary study when we use knowledge related to the partial order relation."
        ],
        [
            "And that may exist some all values.",
            "Our idea is that if we had to discover the exact location of Pablo Picasso and we have two people that told us that Pablo Picasso was born in Malaga, and another person that told us that Pablo Picasso was born in Spain existing to Discovery Model, considered this to answer as conflicting.",
            "Our idea was used.",
            "The knowledge we have on the.",
            "Different location to say that the source that explicitly say that Pablo Picasso was born in Malaga also implicitly supported that Pablo Picasso was also born in Spain, in Europe, and so on.",
            "And we obtain a good results and therefore we decide to user."
        ],
        [
            "Other kind of knowledge that we can identify we can derive from her DF knowledge basis.",
            "And body sensor we can identifying recurrent pattern that can help us to increase the confidence about some information.",
            "And that if we are able to improve through discovery model, we will be able to obtain a larger set of facts that."
        ],
        [
            "Can be used to improve the completeness of existing RDF knowledge bases.",
            "Indeed, nowadays, at Jeff Knowledge basis, I have an important every chat, an important site, but they are still far from being complete.",
            "For instance, half of the instances of type person in DB pedia have not the board location, for instance."
        ],
        [
            "So now we will formalize a little bit are the true Discovery Pro."
        ],
        [
            "Lemme through Discovery is a a set of model that given as input a set of data items that are subject predicate.",
            "Not that in this study we focus on the analysis of functional predicate for which only a single true value exist given a set of sources that can be website, people and so on.",
            "These sources can provide claim associated."
        ],
        [
            "With each data item of value and the name of the discovery is.",
            "To identify the factor among these set of completing claims and the additional that the user is the following true information is provided by reliable sources.",
            "Are reliable sources provide true information?",
            "And in order to implement these rational, they assume."
        ],
        [
            "Date with each claim a confidence and with each source a trustworthiness.",
            "And then they iteratively compute this."
        ],
        [
            "Quantities since one depends on the other.",
            "Given the rational I just stated and then won the convergence."
        ],
        [
            "It's been Richard that is the truth prediction faith that select for each data item at the value having the highest confidence as true value."
        ],
        [
            "And.",
            "No, I don't have a."
        ],
        [
            "Approaches have been proposed over the year.",
            "And we can distinguish a first class of approaches that.",
            "That do not use any additional information to compute transporting's and confidence and an example."
        ],
        [
            "Of this kind of approach is a summer.",
            "That is what that was proposal in 2010 by Pasternak wrote, and this approach on computer, the trustworthiness of the source of a source, summing up all the confidence of the claim that this source provide.",
            "And for instance, if we have to compute the trustworthiness of suce."
        ],
        [
            "We consider the confidence associated with with the claim Pablo Picasso, born in Malaga and the confidence associated with Claude Monet, born in Paris.",
            "Then, to compute the confidence of a value.",
            "The same approach sum up all the trustworthiness of the sources that provided the value under examiner."
        ],
        [
            "And for instance, to compute the transport, the confidence associated with Pablo Picasso born in Malaga, we will consider the trustworthiness of Suce Andy."
        ],
        [
            "So also a lot of more complex approach where proposal and among them we can distinguish model that user dependencies that may exist among values among sources or among data item to improve the final results and for instance the approaches that use the dependencies that exist among that item.",
            "Assume that similar data item subjects should have similar data item values.",
            "And $0.40 a study that right a dent ifying the actual gas price of different gas station.",
            "Assume that the gas station in the same area should have similar gas price.",
            "In this case, the data independency is identifying by the location of the different gas station.",
            "And you similarly we decided to take advantage of the titim dependency in order to improve through discovery model."
        ],
        [
            "And we decide to identifying the dependencies using the knowledge is present in every F."
        ],
        [
            "Knowledge bases and our idea was the following.",
            "Given our knowledge base, we use me a third party tool are well known in the literature as rule mining system to extract a recurrent pattern in the form of rules in order to increase the confidence about value associated with some properties and rules are really useful because.",
            "Suggest other which are there that items object that are similar based on the set of properties and values that are contained in the body of a ruler and then yet of a ruler."
        ],
        [
            "So just as the value we should expect for the properties container in it a.",
            "And $0.40 if we know that Pablo Picasso speaks Spanish and we know that Spanish is spoken in Spain, we should increase our confidence in the claim that Pablo Picasso was born in Spain."
        ],
        [
            "And in practice, what we have done is to other boosting factor to the confidence formula of summer and is boosting factor in should represent the confidence that our knowledge base is associated with the value we are analyzing and the idea is that this boosting factor represent the proportion of rule that support our claim among all the rule we consider.",
            "And since we are on the open world assumption.",
            "We cannot consider all the rules that do not support our value has."
        ],
        [
            "The counter example, and therefore we define a set of eligible rules that are a set of rules that concern only similar data item subject.",
            "What?"
        ],
        [
            "Does it mean when he says that if you have to evaluate the confidence of the claims Pablo Picasso born in Spain and we have the factor represented in this slide and the ruler introduced previously?"
        ],
        [
            "This ruler is an eligible rule since if we instantiate the body of this ruler considering the subject Pablo Picasso, this ruler this body also.",
            "But if we remove from the factor of our in container, the in our knowledge base."
        ],
        [
            "The first factor, this ruler is still not an eligible ruler since the body of the ruler does not hold anymore, and if this body does not hold anymore, we cannot say anything about the value we should expect for the property's burning.",
            "Since there may be some information or would be missing."
        ],
        [
            "And we perform several experiment to test our approach now."
        ],
        [
            "And we perform experiment both on synthetics and real world data set and based on the preliminary results we obtain on synthetic data, set them.",
            "We perform we test the real world data using the same approach and some approach that take into account both kind of knowledge.",
            "We can derive from RDF knowledge basis, therefore the partial order of value and the rules are we derive from our knowledge base and we also test another model that use both partial ordering knowledge rules and had a post processing phase.",
            "Data removed from the set of possible true value.",
            "All the value that were provided only by a single source.",
            "Since we assume that in that case there was an extraction error.",
            "And to collect our real world data, we imagine a lot filling scenario where.",
            "The weather Howard Tax Collection was the web and given a set of data item whose value was missing.",
            "We generate a set of query that we submitted."
        ],
        [
            "Search engine in order to collect a set of web pages that talk about the data item and then we find 2 extraction procedure in order to extract suffer from each webpage a value.",
            "And these are exceptional procedure was very were very naive aand Baeza on in crafted ruler.",
            "So no training phase was required and once we collect hold the pair that item value we use them as input to power through discovery model.",
            "And we identify the fact."
        ],
        [
            "And the results show that we were able to improve our of around 5018%.",
            "Then the results obtained by the Origonal some models but.",
            "We were not able to improve a further.",
            "There is also since a."
        ],
        [
            "The same approach are has a limitation that is related to the fact of penalizing a lot, this user having low coverage.",
            "This means the source that.",
            "That a lot of schools in the data set talked about only a few data item.",
            "And these are was the reason because we were not able to."
        ],
        [
            "To further improve the results and there is that we obtain at the end where compatible to the results obtained by harder to discovery model.",
            "But This is why we are trying to incorporate how we're approaching our rational also to other through discovery model.",
            "They take into account of the power law phenomena of the real world data."
        ],
        [
            "So summarizing."
        ],
        [
            "What we have learned, we have found that using the Knowledge Express it into RDF knowledge base allow enable us to obtain a larger set of factor that can be used to populate her DF, knowledge basis or whatever.",
            "A lot of interesting direction needs to be explored.",
            "And first of all, as I your anticipated, we need to to test how oracional also adapting other through discovery model to see if we are able to obtain even better results and then we would like to propose model that we deal with non functional and dynamic properties in order to cover a larger set of cases.",
            "And then we would like also to propose a new model that take into account the problem of power low phenomena that in the real world data is overexpressed."
        ],
        [
            "So all the source code and data set we use in this experiment are available online and thank you for your attention.",
            "I said already you put your directions.",
            "Are you going for non functional properties to how we expect there?",
            "Just based on intuition or the expected behavior?",
            "The problem is that.",
            "Yeah when you have non functional properties you have a lot of value.",
            "That can be true and when you use a.",
            "Knowledge are related now.",
            "There are models that try to deal with the non functional predicate and they try to infer the number of expected true value.",
            "The problem is that when you use knowledge related to value dependencies and so on.",
            "You can have the cases in which a general generalization.",
            "Should the can imply several specification?",
            "And so this is the tricky part.",
            "So.",
            "The last this was the last.",
            "So.",
            "Morning that.",
            "Aspects.",
            "We know about this problem and This is why we should also deal with the dynamic predicate, but for the moment we don't have a.",
            "We don't sever.",
            "Considering enough the problem.",
            "Questions.",
            "How is this one?",
            "Depend of how many different time you would have.",
            "From the from affecting the ruler is the part that require more time, but then it really depends on the claim you ever on.",
            "The sources are on the number of sources.",
            "It takes an author.",
            "I don't remember exactly should amount of time, but for the real world.",
            "It was a. Poser.",
            "Not so big as in the case of synthetic data at the time was reading.",
            "Short"
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hello to everyone and Valentina and today I will present this study conducted in collaboration with Sebastian Aries, Person Villanueva and Isabella Motional.",
                    "label": 0
                },
                {
                    "sent": "You",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In this presentation we see the intuition behind this study, how to discovery can benefit from the user of the Knowledge Express said into RDF knowledge basis and whichever some.",
                    "label": 1
                },
                {
                    "sent": "Then we will formalize the true discovery problem and we will see the model.",
                    "label": 0
                },
                {
                    "sent": "We propose a in order to incorporate the knowledge Express into RDF knowledge basis into through discovery.",
                    "label": 0
                },
                {
                    "sent": "Ask A we will see the experiment we conducted and the main findings resulting from them.",
                    "label": 0
                },
                {
                    "sent": "So what is the intuition?",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Behind the our study.",
                    "label": 0
                },
                {
                    "sent": "On one side we have through discovery that aims to identify in the factor among a set of conflicting claims that are provided by multiple sources.",
                    "label": 1
                },
                {
                    "sent": "On the other side we have MTF knowledge bases that already contain facts about the world.",
                    "label": 0
                },
                {
                    "sent": "So in both cases we spoke about factor and our idea.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Was to use the Factor Express in RDF knowledge basis to improve through discovery model and we conducted our first preliminary preliminary study when we use knowledge related to the partial order relation.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And that may exist some all values.",
                    "label": 0
                },
                {
                    "sent": "Our idea is that if we had to discover the exact location of Pablo Picasso and we have two people that told us that Pablo Picasso was born in Malaga, and another person that told us that Pablo Picasso was born in Spain existing to Discovery Model, considered this to answer as conflicting.",
                    "label": 0
                },
                {
                    "sent": "Our idea was used.",
                    "label": 0
                },
                {
                    "sent": "The knowledge we have on the.",
                    "label": 0
                },
                {
                    "sent": "Different location to say that the source that explicitly say that Pablo Picasso was born in Malaga also implicitly supported that Pablo Picasso was also born in Spain, in Europe, and so on.",
                    "label": 0
                },
                {
                    "sent": "And we obtain a good results and therefore we decide to user.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Other kind of knowledge that we can identify we can derive from her DF knowledge basis.",
                    "label": 0
                },
                {
                    "sent": "And body sensor we can identifying recurrent pattern that can help us to increase the confidence about some information.",
                    "label": 1
                },
                {
                    "sent": "And that if we are able to improve through discovery model, we will be able to obtain a larger set of facts that.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Can be used to improve the completeness of existing RDF knowledge bases.",
                    "label": 0
                },
                {
                    "sent": "Indeed, nowadays, at Jeff Knowledge basis, I have an important every chat, an important site, but they are still far from being complete.",
                    "label": 1
                },
                {
                    "sent": "For instance, half of the instances of type person in DB pedia have not the board location, for instance.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now we will formalize a little bit are the true Discovery Pro.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Lemme through Discovery is a a set of model that given as input a set of data items that are subject predicate.",
                    "label": 0
                },
                {
                    "sent": "Not that in this study we focus on the analysis of functional predicate for which only a single true value exist given a set of sources that can be website, people and so on.",
                    "label": 0
                },
                {
                    "sent": "These sources can provide claim associated.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "With each data item of value and the name of the discovery is.",
                    "label": 0
                },
                {
                    "sent": "To identify the factor among these set of completing claims and the additional that the user is the following true information is provided by reliable sources.",
                    "label": 1
                },
                {
                    "sent": "Are reliable sources provide true information?",
                    "label": 0
                },
                {
                    "sent": "And in order to implement these rational, they assume.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Date with each claim a confidence and with each source a trustworthiness.",
                    "label": 0
                },
                {
                    "sent": "And then they iteratively compute this.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Quantities since one depends on the other.",
                    "label": 0
                },
                {
                    "sent": "Given the rational I just stated and then won the convergence.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's been Richard that is the truth prediction faith that select for each data item at the value having the highest confidence as true value.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "No, I don't have a.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Approaches have been proposed over the year.",
                    "label": 0
                },
                {
                    "sent": "And we can distinguish a first class of approaches that.",
                    "label": 0
                },
                {
                    "sent": "That do not use any additional information to compute transporting's and confidence and an example.",
                    "label": 1
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of this kind of approach is a summer.",
                    "label": 0
                },
                {
                    "sent": "That is what that was proposal in 2010 by Pasternak wrote, and this approach on computer, the trustworthiness of the source of a source, summing up all the confidence of the claim that this source provide.",
                    "label": 0
                },
                {
                    "sent": "And for instance, if we have to compute the trustworthiness of suce.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We consider the confidence associated with with the claim Pablo Picasso, born in Malaga and the confidence associated with Claude Monet, born in Paris.",
                    "label": 0
                },
                {
                    "sent": "Then, to compute the confidence of a value.",
                    "label": 0
                },
                {
                    "sent": "The same approach sum up all the trustworthiness of the sources that provided the value under examiner.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And for instance, to compute the transport, the confidence associated with Pablo Picasso born in Malaga, we will consider the trustworthiness of Suce Andy.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So also a lot of more complex approach where proposal and among them we can distinguish model that user dependencies that may exist among values among sources or among data item to improve the final results and for instance the approaches that use the dependencies that exist among that item.",
                    "label": 0
                },
                {
                    "sent": "Assume that similar data item subjects should have similar data item values.",
                    "label": 0
                },
                {
                    "sent": "And $0.40 a study that right a dent ifying the actual gas price of different gas station.",
                    "label": 0
                },
                {
                    "sent": "Assume that the gas station in the same area should have similar gas price.",
                    "label": 0
                },
                {
                    "sent": "In this case, the data independency is identifying by the location of the different gas station.",
                    "label": 0
                },
                {
                    "sent": "And you similarly we decided to take advantage of the titim dependency in order to improve through discovery model.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we decide to identifying the dependencies using the knowledge is present in every F.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Knowledge bases and our idea was the following.",
                    "label": 0
                },
                {
                    "sent": "Given our knowledge base, we use me a third party tool are well known in the literature as rule mining system to extract a recurrent pattern in the form of rules in order to increase the confidence about value associated with some properties and rules are really useful because.",
                    "label": 0
                },
                {
                    "sent": "Suggest other which are there that items object that are similar based on the set of properties and values that are contained in the body of a ruler and then yet of a ruler.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So just as the value we should expect for the properties container in it a.",
                    "label": 0
                },
                {
                    "sent": "And $0.40 if we know that Pablo Picasso speaks Spanish and we know that Spanish is spoken in Spain, we should increase our confidence in the claim that Pablo Picasso was born in Spain.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in practice, what we have done is to other boosting factor to the confidence formula of summer and is boosting factor in should represent the confidence that our knowledge base is associated with the value we are analyzing and the idea is that this boosting factor represent the proportion of rule that support our claim among all the rule we consider.",
                    "label": 0
                },
                {
                    "sent": "And since we are on the open world assumption.",
                    "label": 0
                },
                {
                    "sent": "We cannot consider all the rules that do not support our value has.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The counter example, and therefore we define a set of eligible rules that are a set of rules that concern only similar data item subject.",
                    "label": 0
                },
                {
                    "sent": "What?",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Does it mean when he says that if you have to evaluate the confidence of the claims Pablo Picasso born in Spain and we have the factor represented in this slide and the ruler introduced previously?",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This ruler is an eligible rule since if we instantiate the body of this ruler considering the subject Pablo Picasso, this ruler this body also.",
                    "label": 0
                },
                {
                    "sent": "But if we remove from the factor of our in container, the in our knowledge base.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The first factor, this ruler is still not an eligible ruler since the body of the ruler does not hold anymore, and if this body does not hold anymore, we cannot say anything about the value we should expect for the property's burning.",
                    "label": 0
                },
                {
                    "sent": "Since there may be some information or would be missing.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we perform several experiment to test our approach now.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we perform experiment both on synthetics and real world data set and based on the preliminary results we obtain on synthetic data, set them.",
                    "label": 0
                },
                {
                    "sent": "We perform we test the real world data using the same approach and some approach that take into account both kind of knowledge.",
                    "label": 0
                },
                {
                    "sent": "We can derive from RDF knowledge basis, therefore the partial order of value and the rules are we derive from our knowledge base and we also test another model that use both partial ordering knowledge rules and had a post processing phase.",
                    "label": 0
                },
                {
                    "sent": "Data removed from the set of possible true value.",
                    "label": 0
                },
                {
                    "sent": "All the value that were provided only by a single source.",
                    "label": 0
                },
                {
                    "sent": "Since we assume that in that case there was an extraction error.",
                    "label": 0
                },
                {
                    "sent": "And to collect our real world data, we imagine a lot filling scenario where.",
                    "label": 0
                },
                {
                    "sent": "The weather Howard Tax Collection was the web and given a set of data item whose value was missing.",
                    "label": 0
                },
                {
                    "sent": "We generate a set of query that we submitted.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Search engine in order to collect a set of web pages that talk about the data item and then we find 2 extraction procedure in order to extract suffer from each webpage a value.",
                    "label": 1
                },
                {
                    "sent": "And these are exceptional procedure was very were very naive aand Baeza on in crafted ruler.",
                    "label": 0
                },
                {
                    "sent": "So no training phase was required and once we collect hold the pair that item value we use them as input to power through discovery model.",
                    "label": 0
                },
                {
                    "sent": "And we identify the fact.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the results show that we were able to improve our of around 5018%.",
                    "label": 0
                },
                {
                    "sent": "Then the results obtained by the Origonal some models but.",
                    "label": 0
                },
                {
                    "sent": "We were not able to improve a further.",
                    "label": 0
                },
                {
                    "sent": "There is also since a.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The same approach are has a limitation that is related to the fact of penalizing a lot, this user having low coverage.",
                    "label": 0
                },
                {
                    "sent": "This means the source that.",
                    "label": 0
                },
                {
                    "sent": "That a lot of schools in the data set talked about only a few data item.",
                    "label": 0
                },
                {
                    "sent": "And these are was the reason because we were not able to.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To further improve the results and there is that we obtain at the end where compatible to the results obtained by harder to discovery model.",
                    "label": 0
                },
                {
                    "sent": "But This is why we are trying to incorporate how we're approaching our rational also to other through discovery model.",
                    "label": 0
                },
                {
                    "sent": "They take into account of the power law phenomena of the real world data.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So summarizing.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What we have learned, we have found that using the Knowledge Express it into RDF knowledge base allow enable us to obtain a larger set of factor that can be used to populate her DF, knowledge basis or whatever.",
                    "label": 1
                },
                {
                    "sent": "A lot of interesting direction needs to be explored.",
                    "label": 0
                },
                {
                    "sent": "And first of all, as I your anticipated, we need to to test how oracional also adapting other through discovery model to see if we are able to obtain even better results and then we would like to propose model that we deal with non functional and dynamic properties in order to cover a larger set of cases.",
                    "label": 1
                },
                {
                    "sent": "And then we would like also to propose a new model that take into account the problem of power low phenomena that in the real world data is overexpressed.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So all the source code and data set we use in this experiment are available online and thank you for your attention.",
                    "label": 0
                },
                {
                    "sent": "I said already you put your directions.",
                    "label": 0
                },
                {
                    "sent": "Are you going for non functional properties to how we expect there?",
                    "label": 0
                },
                {
                    "sent": "Just based on intuition or the expected behavior?",
                    "label": 0
                },
                {
                    "sent": "The problem is that.",
                    "label": 0
                },
                {
                    "sent": "Yeah when you have non functional properties you have a lot of value.",
                    "label": 0
                },
                {
                    "sent": "That can be true and when you use a.",
                    "label": 0
                },
                {
                    "sent": "Knowledge are related now.",
                    "label": 0
                },
                {
                    "sent": "There are models that try to deal with the non functional predicate and they try to infer the number of expected true value.",
                    "label": 0
                },
                {
                    "sent": "The problem is that when you use knowledge related to value dependencies and so on.",
                    "label": 0
                },
                {
                    "sent": "You can have the cases in which a general generalization.",
                    "label": 0
                },
                {
                    "sent": "Should the can imply several specification?",
                    "label": 0
                },
                {
                    "sent": "And so this is the tricky part.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The last this was the last.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Morning that.",
                    "label": 0
                },
                {
                    "sent": "Aspects.",
                    "label": 0
                },
                {
                    "sent": "We know about this problem and This is why we should also deal with the dynamic predicate, but for the moment we don't have a.",
                    "label": 0
                },
                {
                    "sent": "We don't sever.",
                    "label": 0
                },
                {
                    "sent": "Considering enough the problem.",
                    "label": 0
                },
                {
                    "sent": "Questions.",
                    "label": 0
                },
                {
                    "sent": "How is this one?",
                    "label": 0
                },
                {
                    "sent": "Depend of how many different time you would have.",
                    "label": 0
                },
                {
                    "sent": "From the from affecting the ruler is the part that require more time, but then it really depends on the claim you ever on.",
                    "label": 0
                },
                {
                    "sent": "The sources are on the number of sources.",
                    "label": 0
                },
                {
                    "sent": "It takes an author.",
                    "label": 0
                },
                {
                    "sent": "I don't remember exactly should amount of time, but for the real world.",
                    "label": 0
                },
                {
                    "sent": "It was a. Poser.",
                    "label": 0
                },
                {
                    "sent": "Not so big as in the case of synthetic data at the time was reading.",
                    "label": 0
                },
                {
                    "sent": "Short",
                    "label": 0
                }
            ]
        }
    }
}