{
    "id": "m3gktsffg3rnjbdqiuodjafuunpexrdm",
    "title": "LogMap: Logic-based and Scalable Ontology Matching",
    "info": {
        "author": [
            "Ernesto Jimenez-Ruiz, University of Oxford"
        ],
        "published": "Nov. 25, 2011",
        "recorded": "October 2011",
        "category": [
            "Top->Computer Science->Logic",
            "Top->Computer Science->Semantic Web->Ontologies"
        ]
    },
    "url": "http://videolectures.net/iswc2011_jimenez_ruiz_ontology/",
    "segmentation": [
        [
            "Hi everyone, thank you for attending this session.",
            "So I'm presenting our tool log map and this tends to be a scalable and using logic based technique, foreign trade."
        ],
        [
            "And also you try to be.",
            "Highly scalable and in order to face with big ontologies like FMA, NCI, under Snow Medcity.",
            "So we tried to provide like some facilities to clean them up in history."
        ],
        [
            "So well, yes, I fast motivation like why we integrate ontologies.",
            "So in the end we in the future we need to integrate and great data between applications or databases.",
            "So why we need to re integration?",
            "But the problem is this ontologies have been developed by different rules, different people that you're different schemas naming convention.",
            "So that's why we need tools to facilitate the."
        ],
        [
            "Imaging process.",
            "So the talented we were trying to address and face was like.",
            "Or we have big ontologies.",
            "They are not easy even to to load.",
            "So if you have several of these ontologies, we try to work with them is not easy.",
            "So we were trying to face this problem and I'm trying to provide the indexing an optimizer structures to deal with these ontologies as we wanted to.",
            "To provide kind of logic based techniques for controlling matching process.",
            "But the problem is if we use completely research for example, and we recently with the two input ontologies plus the mappings is going to be costly and text consuming, and in some of the cases we cannot even better result because there is some other reasons that they don't get that kind of deal with this be controlled.",
            "This plus the mappings.",
            "So yeah, then we try to probably kind of logic based techniques, but escarole techniques.",
            "So this is one of the key points of the."
        ],
        [
            "Or the tool?",
            "So this is more or less, how are anatomy of our tool, so we'll start with our first step is as I commented, like how to deal with this week ontology.",
            "So we tried to index, but the lexical part eventually plus the structure.",
            "So this is going to be one of the key points of the of the scalability of log Maps.",
            "I told this if you are faster at indexing the lexical and the structure of the ontology.",
            "Also it will be faster computing there at least the first set of candidate mappings.",
            "So another key point of their order, not to me or the architecture of Rd Maps if they're in the mapping repair facility.",
            "Also be trying to be logic based, but also scalable and.",
            "Here we have a kind of iteration of them all in the process, so we just not only provided a way of.",
            "Object computing a set of mapping data.",
            "So we also try to iterate in the process, like trying to discover new mappings from starting from the prior mapping we discover and also involving the repairs always discover new mappings and repair discovered.",
            "So this is one of the keys and after all lots of computer kind of estimation of the overlapping odontologist, because it's not only interesting to provide a set of mapping, but also well this fragment of their own 31 is the one that is going to be mapped without this functionality.",
            "To anthonys something useful.",
            "In the future, if either domain expert wants to to work further with this ontologies plus the mapping so they can focus in in just this compute fragment."
        ],
        [
            "So well, our index section is quite simple, is not nothing different of what in other areas like information retrieval they use.",
            "So we index the lexical like we create like this inverted file and the entry of link or the inverted color is the set of words die represent the labels that occur in different concepts.",
            "And yet, this entry is pointed to the set of ideas or or concept that they label occurs.",
            "So The thing is the same entry could point to different to several concepts and several.",
            "The same concept could appear in different entries, like if they have different synonym for example.",
            "So these are a fragment of our inverted file for FMA on NCI.",
            "And you can see what they would have been like if someone then did.",
            "You have different?",
            "Different ideas this is going to be I will go for the lighter to that again because it won't be for the computational day on the initial map."
        ],
        [
            "So we also in English the error code ontology.",
            "I said classify year key because not always, we're using the reasoner, or at least not a complete regional.",
            "So because some other time we couldn't get an output from the region.",
            "So we also have the option of just perform like an instructional reasoning over the Rocky."
        ],
        [
            "On the thing will be, our representation is based off an index index in interval labeling index.",
            "So each concept is annotated with our pre order number and also with an interval and interval represent a set of of kids that have the concept.",
            "So this allows us to perform really in a fast way.",
            "Typical taxonomical queries.",
            "How will they have the relationship between cultures like for example in?",
            "In the sample you have existed to compute, if BP stands for biological process an.",
            "Entities dance tournament transport.",
            "So it's easy to compute like just computing operation between integral to say like it is.",
            "If this concept is a subclass of this one just because the pre order of TT is 3 and then three is in the interval of BP.",
            "So it's quite easy also to compute if two classes like for example PT is disjoint or not of PS.",
            "So it's quite easy to compute like they have disjoint intervals, so the concepts are going to be busy and so.",
            "These will not help us to be more scalable in the sense.",
            "So."
        ],
        [
            "So just go to the important part like the map."
        ],
        [
            "The mapping instruction.",
            "So as I told you, start from this lexical in the exception.",
            "So the first set of mappings are easily computed just by intersecting the."
        ],
        [
            "Inverted files."
        ],
        [
            "In the end, for example, we have like correction, trapezoid, episode volume and is magma.",
            "Are there are entries from the inverted files that they could in both of them?"
        ],
        [
            "Just by intersecting we have like a set of.",
            "Candidate mappings like.",
            "At least they in the beginning they look like correct or a little less likely.",
            "They are representing things that are really close.",
            "But we are not happy only with that.",
            "Now we have in a fast way that they are big set of candidate that is really good."
        ],
        [
            "I want to do something else with them like we want to assess if the set of initial mappings are good or not.",
            "So on the one hand we compute a confidence for those mappings, so one of the countries that one of the parts of the confidence is how close are the streams represented those concepts?",
            "Because they are coming from this inverted file, the lexical similarity is going to be higher, but on the other hand we also compute the.",
            "How close are semantically in the sense?",
            "Are they sharing the same neighborhoods and scope?",
            "So for example, we applied this principle of locality, are like they are good mappings.",
            "The scope of these concepts in the in the toilets are going to represent or going to have similar scopes.",
            "So for example we have this."
        ],
        [
            "Is one of the samples we usually use, like for example trapezoid.",
            "Is mapped to database and it's like lexically.",
            "It looks like he looks like it's correct answer to this is going, but obviously this one.",
            "This mapping is not correct.",
            "If they are representing much really different realities.",
            "So in that in that case we classify like this mapping has lexical would lexical similarity, but it's not.",
            "It has no scope, so it's it's going to be quite likely that is not going to be a correct.",
            "These are nice example in some of the other examples like is not easy to decide if the concept is representing the same thing or not.",
            "So from the beginning we don't discard this mapping, but if the kosher conflict or so probably in the future running there in the repair facility is going to be discarded from the beginning.",
            "We're going to consider like a dangerous map."
        ],
        [
            "So this mapping discovery and it's going to be explained in this in sequential part.",
            "Well.",
            "So this is going to be involved in this iterative process.",
            "But the key to display just put it as a part of the mapping restriction."
        ],
        [
            "So.",
            "I said as I was using for the confidence in the mapping is currently going to have like similar neighborhood so we can use this to start new mappings.",
            "So.",
            "This mapping view we can see that it could be correct, so probably the balance could be also representing potential mappings for we try to exploit this principle of locality and trying to expand the scope iteratively.",
            "To discover new ones and in the enemy if bond organum bonded representing mapping, we also will expand the scope of these concepts, so it's like kind of trying to help us to discover new new information."
        ],
        [
            "So yeah, let's go to the mapping report.",
            "So I think we wanted to propose something logic based.",
            "As I told you, but also scalable.",
            "So the key of love math is representing the Don tollages under mappings as a whole propositional.",
            "So we represent distended guitar keys, so not only their elections like subclass of but also the disjointness and the intersection when the intersection occurs in the left hand side.",
            "So these are something like a fragment of FMA, NCI, and their mappings.",
            "That's why it's important to note like the mappings are split because we discover or we can do everything that we discovered we represented, like an equivalence mapping, but for the our propositional representation we represent them well.",
            "We applied the mappings in.",
            "In the two sides, so this is important because in the end the repair process may involve the letting only one of the sides another complete mapping.",
            "So it would be something useful."
        ],
        [
            "So our first step in in the report is just checking for errors.",
            "So does the mapping leading the tallest person mapping leading to errors.",
            "So we implemented this down in Angular algorithm for horn satisfiability.",
            "The finish is well.",
            "I think I will explain it with the four.",
            "With this algorithm we check for every class, so we ask every class it is satisfied satisfied."
        ],
        [
            "For example, can you see to understand with this example?",
            "Click on the graph representation of all the horn clauses.",
            "So I want to check if his magma is consistent or not.",
            "So The thing is, we.",
            "We see then that I falls from different parts of the same way like."
        ],
        [
            "You see here anatomy.",
            "And biological processes are disjoint."
        ],
        [
            "So they brought me.",
            "If you from exactly make anatomy through and also biological process through, we're going to have another error.",
            "So.",
            "With the mappings we have this problem stuff from his magma below to NCIS, Magma and then we go up, up up and we got fault probably half well.",
            "We have arrived from one post but also from Shaq racism, bigotry with mapping four to NCI celebration up, up up and then folds.",
            "So we got an error.",
            "So the thing with this algorithm is quite easy to compute these things or is linear and is quite fast.",
            "After how explain later we also contract them which mappings are involving the error?",
            "In this case you have."
        ],
        [
            "This for.",
            "So without the characteristic of this algorithm, flow is how?",
            "So it's good because we were expecting at least if you say if you report that something is an error, so margin error.",
            "It was case linear, so if the characteristic of the algorithms and in that case we didn't do anything.",
            "Obviously sing complete with something like we were expecting.",
            "So if you want something completely that we are not going to be available in the end.",
            "But we're not that bad in the sense of in terms of incompleteness, because we're classifying ontologies, so it's something we're getting some information.",
            "Also, mappings in the end there representing Horn clauses.",
            "Also, as we will see later in the in the valuation, we only fail to report one error between NCI and effect one interacting nsima so well, even if you're in complete for this scenario is working.",
            "So is something really important too?",
            "But well, it's important also to know that for some cases we can be getting some errors in the end after the cleaning process."
        ],
        [
            "So well, I think to deal with and we extended our lingering to report the set of mappings that they are involved in.",
            "There are so for the previous example we have this for mappings.",
            "Um?",
            "Oh yeah, so this explained before like we split them up in space, why we have two equivalence mappings are having a splitting for subclass mappings.",
            "So the thing also for the repair algorithm we try to use something fast and if not really a complete repair algorithm we're not proposing we're not giving all the possibles subsets of mappings that they may repair the error.",
            "So the idea is like we create.",
            "Subsets offer small size and then we invite."
        ],
        [
            "Incrementally.",
            "For example, we're starting from subsets of size 1.",
            "If we found a plan to repair the error, we're done.",
            "If we don't find a Plan B, go for subsets of size 2 and then incrementally until we in this example, and until the red berries, for example, for mappings and they were the size of all the completed mappings.",
            "This will give us some scalability facilities because if we try to compute all possible plans, another potential.",
            "So if you have four plants is OK, but when I have to for mappings to repair is OK, but sometimes we will get in like 100 conflicted mapping.",
            "So computing all possible repairs will be relating consuming.",
            "I'll tell you this greedy algorithm is to our for all the possible classes that could be inconsistent.",
            "We start from top to down, so sometimes even when we repair the subclass, the top class we are repairing also the subclasses or something that it helps."
        ],
        [
            "Well, this repair of property angle wasn't initially in the paper, but in the end because we wanted to participate in the ontology matching initiative.",
            "We decided to include like a facility to discover mapping between properties and also to repair them.",
            "The mapping instruction also relies only interested in the intersection of the inverted files, but the repair process is not yet included.",
            "Normal angle here, but we have some eristic Stew at least to report if a mapping between two properties could be dangerous, might be reported in the sense like if you analyze the domains, the respective domains of the properties under ranges and we know that they are not compatible, so the property is not considered.",
            "And will allow for.",
            "For the valuation in the disorderly matching initiative, we were able to not to provide any dangerous property I any dangerous mapping."
        ],
        [
            "Properties.",
            "So this is the last step of our.",
            "Of log Maps, we also perform like an overlapping."
        ],
        [
            "Any estimation?",
            "So we provide two fragments of their ontologies based on the mappings we discover and also based on the lexical.",
            "Leslie County maletis So we have to establish."
        ],
        [
            "Fairly we implement like while we extend the inverted files, because before we invented fireworks lighting.",
            "Kind of the exact exact label of the order of the other entities, and then we extended in the sand like we don't require the each entry of the inverted file to have like an exact correspondence with the label of the entity.",
            "We also give some flexibility like only consider like 3 words out of four, three out of out of five to give like more flexibility.",
            "In that sense, each entry of the inverted file in the other half, like more candidate concepts that they somehow they shared.",
            "Part of the label, but not the complete label."
        ],
        [
            "This.",
            "Candidate mappings are dangerous to consider as a mapping, but very interesting to consider them to start this.",
            "This estimation of the overlapping so we use this week anchors like a like the input signature.",
            "For those"
        ],
        [
            "This fragment, so I think it would.",
            "The entities involved in this week anchors.",
            "There will be like the input signature to stack a fragment memorial and completely we are using this locality model extractor to form the final.",
            "The final word."
        ],
        [
            "So this is the last part of the auditory canal.",
            "This is probably the most interesting."
        ],
        [
            "Then we can literally take that.",
            "What we implementing is working in practice.",
            "So we use this set of ontologies as Nomad and CI FMA, and also the group of ontologies that there in the ontology.",
            "Matching initiative values like is a fragment of NCI with 3000 classes, mouse anatomy, ontology, and the set of conference and benchmark."
        ],
        [
            "So in the end we we had like 4 main tasks for the valuation, like on the one hand we were rated only the mapping the mapping repair facility of log map to repair gold.",
            "All set of mappings there supposed to be gold standard.",
            "We also met this large ontologies FMA NCI under Snow map.",
            "Uh, another location where these overlapping estimation so are we extracting a meaningful, meaningful fragmented ontologies.",
            "And finally I will present our results of the participating participation is getting in the entity matching."
        ],
        [
            "So for the cleaning of the standards we use the gold standard of the anatomy track of the recently matching initiative and also Umm Azure reference to Inter FM NCI.",
            "And we have like the mappings, because this ontologies are integrated in numerous and, well, you know it's a big mass hours that interacts.",
            "Not only ontologies but also discovery.",
            "So The thing is, we discover taking into account the logic based information and ontologies plus those mappings we got like a huge number of errors.",
            "So our first time was like trying to with the lock Mac repair facility, try to repair these mappings and provide like a clean mappings set.",
            "So in the end we were kind of successful because we clean some of the mapping we were not too aggressive so again we provide like a subset of the original mappings, but it's really a big subset and so we were."
        ],
        [
            "Faster than that.",
            "The unit plan, as I told you, we we fail at reporting 11 error.",
            "But it makes sense because this error is involving existential anniversary quantification, so so it's something we're not representing in our scenario, but there still is much easier today."
        ],
        [
            "To the user to try to rip."
        ],
        [
            "Only one."
        ],
        [
            "Error and not not 655.",
            "So in the end we are providing something helpful."
        ],
        [
            "The mappings computer backlog map.",
            "So now before we started from less, now we're starting from scratch, so we take ncma and NCI and we start trying to get the all possible mappings.",
            "So I think the important thing is we are able to deal with this week ontologies in a quite reasonable time, and we also provide a set of mappings.",
            "And what this table, at least for the time perspective?",
            "Well for the time."
        ],
        [
            "Toby was good, but also we we consider that the results were not about comparing with.",
            "Now I'm comparing again with you.",
            "Melissa called Standard and these are the results that log must produce.",
            "So for FMA on NCI after the cleaning process we got an F score of theodote.",
            "So is something really important because they are big ontologies?",
            "We didn't get as nice as nice actual results results for FMA, and there's no mid so that the position was not too bad, but the recall was really really low.",
            "I'm slightly better than yourself or is normal on NCI.",
            "So the good thing of daddy, like we are able to process these ontologies.",
            "But still we are a bit far away from the ideal results while getting really better record results.",
            "But this has an explanation why we are not getting better FS columns."
        ],
        [
            "It's like a currently looking at realize in the lexical similarity of the ontologists.",
            "So FMA, FMA, and NCI.",
            "They have like quite commonalities, but for example a family I don't know, but they are quite this part so it's like.",
            "The subset of mappings from the gold standard that they have, like a lexical similarity of 95.",
            "Is for any feminine CIS acting 88% but foreign FML is nomad is only 21.",
            "Why we fail to discover?",
            "A huge set of mapping is why our goal was more or less said not to.",
            "But then again there are like 9 results from from the first approximation and you know we have had plenty of."
        ],
        [
            "Improvement.",
            "So I think the overlapping also was a nice output outlook map.",
            "Look like we're mapping this joint ologist, but even if you are not able to produce that complete set of mappings, we are able to produce like uninteresting map fragmente.",
            "And then you can try to discover more mappings so.",
            "Summer or more specialized mountry matching tools.",
            "They could get this output Verilog output and try to discover new mappings and now without much smaller fragmente.",
            "So it's something like.",
            "I know it's not logged in at the end, it could be like used in combination with other until imagine."
        ],
        [
            "Yeah, and I guess too.",
            "To conclude this, these are the results of the entry imaginal campaign.",
            "In the end we decided to participate because then it was good to get some feedback from the community and also to compare with other tools so forth.",
            "Anatomy track we got really interesting results.",
            "We were the second tool in terms of F score.",
            "An yeah, I could make it worse for away from the other tools that the recall was amazing with almost 0.9.",
            "But the interesting thing is like the.",
            "A little of my previous colorful and work the fastest, fastest one and also my was pretty fast, but comparing the results so we were fast and also the product really meaningful, meaningful set of mappings.",
            "Uh, the last column, it means like the incurrence, so they are not official results for the entity matching campaign.",
            "But well, we use a completely as owner.",
            "In that case I think was Hermit and we didn't get any unsatisfiable classes this morning with ontologies on the mappings.",
            "But I don't know the other tools, so the other 2 sided, the percentage of in currencies zero or more, but probably we will get some results."
        ],
        [
            "So far there is another track in the in the campaign is about a small ontologies dealing with conference and in the in the track we were the first of all.",
            "So we got some good results.",
            "However, more or less in line with the with the best too.",
            "Again, the results were."
        ],
        [
            "Wait from using.",
            "For the third track of the OR the campaign, we didn't get a good results, but we were expecting that, so this struck what they they try to create like benchmark test like automatically.",
            "Well, they start from a real ontology and automatically remove some labels.",
            "They put random strings so you might log mass and that doesn't perform well because we rely on the lexical similarities and when they when the labels are are missing or they are not labeled.",
            "We just not provide mappings and why we didn't.",
            "What are really nicely called.",
            "For example, this if I'm not wrong with, it works.",
            "The best tool has much better result than us, but it's something we were expecting, so probably in the future we try to.",
            "Try to improve.",
            "That is mapping discovery like if there are no labels trying to apply some other new lipsticks."
        ],
        [
            "Well, just to conclude, so these words log mob while we started working with low magnesium from January, trying to create a new scalable an nice tool.",
            "I think we got it, but well, we're still working on the other.",
            "I see plenty of room for improvement now we have a second version of Lock Box is kind of more stable and robust and we plan to.",
            "Well now look like this about global name from the sales platform, but we plan to put it also the source code and everything available in the future."
        ],
        [
            "So thank you very much and you have any questions.",
            "I will be more than happy."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi everyone, thank you for attending this session.",
                    "label": 0
                },
                {
                    "sent": "So I'm presenting our tool log map and this tends to be a scalable and using logic based technique, foreign trade.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And also you try to be.",
                    "label": 0
                },
                {
                    "sent": "Highly scalable and in order to face with big ontologies like FMA, NCI, under Snow Medcity.",
                    "label": 0
                },
                {
                    "sent": "So we tried to provide like some facilities to clean them up in history.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So well, yes, I fast motivation like why we integrate ontologies.",
                    "label": 0
                },
                {
                    "sent": "So in the end we in the future we need to integrate and great data between applications or databases.",
                    "label": 0
                },
                {
                    "sent": "So why we need to re integration?",
                    "label": 0
                },
                {
                    "sent": "But the problem is this ontologies have been developed by different rules, different people that you're different schemas naming convention.",
                    "label": 0
                },
                {
                    "sent": "So that's why we need tools to facilitate the.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Imaging process.",
                    "label": 0
                },
                {
                    "sent": "So the talented we were trying to address and face was like.",
                    "label": 0
                },
                {
                    "sent": "Or we have big ontologies.",
                    "label": 0
                },
                {
                    "sent": "They are not easy even to to load.",
                    "label": 0
                },
                {
                    "sent": "So if you have several of these ontologies, we try to work with them is not easy.",
                    "label": 0
                },
                {
                    "sent": "So we were trying to face this problem and I'm trying to provide the indexing an optimizer structures to deal with these ontologies as we wanted to.",
                    "label": 0
                },
                {
                    "sent": "To provide kind of logic based techniques for controlling matching process.",
                    "label": 0
                },
                {
                    "sent": "But the problem is if we use completely research for example, and we recently with the two input ontologies plus the mappings is going to be costly and text consuming, and in some of the cases we cannot even better result because there is some other reasons that they don't get that kind of deal with this be controlled.",
                    "label": 0
                },
                {
                    "sent": "This plus the mappings.",
                    "label": 0
                },
                {
                    "sent": "So yeah, then we try to probably kind of logic based techniques, but escarole techniques.",
                    "label": 0
                },
                {
                    "sent": "So this is one of the key points of the.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Or the tool?",
                    "label": 0
                },
                {
                    "sent": "So this is more or less, how are anatomy of our tool, so we'll start with our first step is as I commented, like how to deal with this week ontology.",
                    "label": 1
                },
                {
                    "sent": "So we tried to index, but the lexical part eventually plus the structure.",
                    "label": 0
                },
                {
                    "sent": "So this is going to be one of the key points of the of the scalability of log Maps.",
                    "label": 0
                },
                {
                    "sent": "I told this if you are faster at indexing the lexical and the structure of the ontology.",
                    "label": 0
                },
                {
                    "sent": "Also it will be faster computing there at least the first set of candidate mappings.",
                    "label": 0
                },
                {
                    "sent": "So another key point of their order, not to me or the architecture of Rd Maps if they're in the mapping repair facility.",
                    "label": 1
                },
                {
                    "sent": "Also be trying to be logic based, but also scalable and.",
                    "label": 0
                },
                {
                    "sent": "Here we have a kind of iteration of them all in the process, so we just not only provided a way of.",
                    "label": 0
                },
                {
                    "sent": "Object computing a set of mapping data.",
                    "label": 0
                },
                {
                    "sent": "So we also try to iterate in the process, like trying to discover new mappings from starting from the prior mapping we discover and also involving the repairs always discover new mappings and repair discovered.",
                    "label": 0
                },
                {
                    "sent": "So this is one of the keys and after all lots of computer kind of estimation of the overlapping odontologist, because it's not only interesting to provide a set of mapping, but also well this fragment of their own 31 is the one that is going to be mapped without this functionality.",
                    "label": 0
                },
                {
                    "sent": "To anthonys something useful.",
                    "label": 0
                },
                {
                    "sent": "In the future, if either domain expert wants to to work further with this ontologies plus the mapping so they can focus in in just this compute fragment.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So well, our index section is quite simple, is not nothing different of what in other areas like information retrieval they use.",
                    "label": 0
                },
                {
                    "sent": "So we index the lexical like we create like this inverted file and the entry of link or the inverted color is the set of words die represent the labels that occur in different concepts.",
                    "label": 0
                },
                {
                    "sent": "And yet, this entry is pointed to the set of ideas or or concept that they label occurs.",
                    "label": 0
                },
                {
                    "sent": "So The thing is the same entry could point to different to several concepts and several.",
                    "label": 0
                },
                {
                    "sent": "The same concept could appear in different entries, like if they have different synonym for example.",
                    "label": 0
                },
                {
                    "sent": "So these are a fragment of our inverted file for FMA on NCI.",
                    "label": 0
                },
                {
                    "sent": "And you can see what they would have been like if someone then did.",
                    "label": 0
                },
                {
                    "sent": "You have different?",
                    "label": 0
                },
                {
                    "sent": "Different ideas this is going to be I will go for the lighter to that again because it won't be for the computational day on the initial map.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we also in English the error code ontology.",
                    "label": 0
                },
                {
                    "sent": "I said classify year key because not always, we're using the reasoner, or at least not a complete regional.",
                    "label": 0
                },
                {
                    "sent": "So because some other time we couldn't get an output from the region.",
                    "label": 0
                },
                {
                    "sent": "So we also have the option of just perform like an instructional reasoning over the Rocky.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "On the thing will be, our representation is based off an index index in interval labeling index.",
                    "label": 0
                },
                {
                    "sent": "So each concept is annotated with our pre order number and also with an interval and interval represent a set of of kids that have the concept.",
                    "label": 1
                },
                {
                    "sent": "So this allows us to perform really in a fast way.",
                    "label": 0
                },
                {
                    "sent": "Typical taxonomical queries.",
                    "label": 0
                },
                {
                    "sent": "How will they have the relationship between cultures like for example in?",
                    "label": 0
                },
                {
                    "sent": "In the sample you have existed to compute, if BP stands for biological process an.",
                    "label": 0
                },
                {
                    "sent": "Entities dance tournament transport.",
                    "label": 0
                },
                {
                    "sent": "So it's easy to compute like just computing operation between integral to say like it is.",
                    "label": 0
                },
                {
                    "sent": "If this concept is a subclass of this one just because the pre order of TT is 3 and then three is in the interval of BP.",
                    "label": 0
                },
                {
                    "sent": "So it's quite easy also to compute if two classes like for example PT is disjoint or not of PS.",
                    "label": 0
                },
                {
                    "sent": "So it's quite easy to compute like they have disjoint intervals, so the concepts are going to be busy and so.",
                    "label": 0
                },
                {
                    "sent": "These will not help us to be more scalable in the sense.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So just go to the important part like the map.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The mapping instruction.",
                    "label": 0
                },
                {
                    "sent": "So as I told you, start from this lexical in the exception.",
                    "label": 0
                },
                {
                    "sent": "So the first set of mappings are easily computed just by intersecting the.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Inverted files.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the end, for example, we have like correction, trapezoid, episode volume and is magma.",
                    "label": 0
                },
                {
                    "sent": "Are there are entries from the inverted files that they could in both of them?",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just by intersecting we have like a set of.",
                    "label": 0
                },
                {
                    "sent": "Candidate mappings like.",
                    "label": 0
                },
                {
                    "sent": "At least they in the beginning they look like correct or a little less likely.",
                    "label": 0
                },
                {
                    "sent": "They are representing things that are really close.",
                    "label": 0
                },
                {
                    "sent": "But we are not happy only with that.",
                    "label": 0
                },
                {
                    "sent": "Now we have in a fast way that they are big set of candidate that is really good.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I want to do something else with them like we want to assess if the set of initial mappings are good or not.",
                    "label": 0
                },
                {
                    "sent": "So on the one hand we compute a confidence for those mappings, so one of the countries that one of the parts of the confidence is how close are the streams represented those concepts?",
                    "label": 0
                },
                {
                    "sent": "Because they are coming from this inverted file, the lexical similarity is going to be higher, but on the other hand we also compute the.",
                    "label": 0
                },
                {
                    "sent": "How close are semantically in the sense?",
                    "label": 0
                },
                {
                    "sent": "Are they sharing the same neighborhoods and scope?",
                    "label": 0
                },
                {
                    "sent": "So for example, we applied this principle of locality, are like they are good mappings.",
                    "label": 0
                },
                {
                    "sent": "The scope of these concepts in the in the toilets are going to represent or going to have similar scopes.",
                    "label": 0
                },
                {
                    "sent": "So for example we have this.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is one of the samples we usually use, like for example trapezoid.",
                    "label": 0
                },
                {
                    "sent": "Is mapped to database and it's like lexically.",
                    "label": 0
                },
                {
                    "sent": "It looks like he looks like it's correct answer to this is going, but obviously this one.",
                    "label": 0
                },
                {
                    "sent": "This mapping is not correct.",
                    "label": 0
                },
                {
                    "sent": "If they are representing much really different realities.",
                    "label": 0
                },
                {
                    "sent": "So in that in that case we classify like this mapping has lexical would lexical similarity, but it's not.",
                    "label": 0
                },
                {
                    "sent": "It has no scope, so it's it's going to be quite likely that is not going to be a correct.",
                    "label": 0
                },
                {
                    "sent": "These are nice example in some of the other examples like is not easy to decide if the concept is representing the same thing or not.",
                    "label": 0
                },
                {
                    "sent": "So from the beginning we don't discard this mapping, but if the kosher conflict or so probably in the future running there in the repair facility is going to be discarded from the beginning.",
                    "label": 0
                },
                {
                    "sent": "We're going to consider like a dangerous map.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this mapping discovery and it's going to be explained in this in sequential part.",
                    "label": 0
                },
                {
                    "sent": "Well.",
                    "label": 0
                },
                {
                    "sent": "So this is going to be involved in this iterative process.",
                    "label": 0
                },
                {
                    "sent": "But the key to display just put it as a part of the mapping restriction.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "I said as I was using for the confidence in the mapping is currently going to have like similar neighborhood so we can use this to start new mappings.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 1
                },
                {
                    "sent": "This mapping view we can see that it could be correct, so probably the balance could be also representing potential mappings for we try to exploit this principle of locality and trying to expand the scope iteratively.",
                    "label": 0
                },
                {
                    "sent": "To discover new ones and in the enemy if bond organum bonded representing mapping, we also will expand the scope of these concepts, so it's like kind of trying to help us to discover new new information.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So yeah, let's go to the mapping report.",
                    "label": 0
                },
                {
                    "sent": "So I think we wanted to propose something logic based.",
                    "label": 0
                },
                {
                    "sent": "As I told you, but also scalable.",
                    "label": 0
                },
                {
                    "sent": "So the key of love math is representing the Don tollages under mappings as a whole propositional.",
                    "label": 0
                },
                {
                    "sent": "So we represent distended guitar keys, so not only their elections like subclass of but also the disjointness and the intersection when the intersection occurs in the left hand side.",
                    "label": 0
                },
                {
                    "sent": "So these are something like a fragment of FMA, NCI, and their mappings.",
                    "label": 0
                },
                {
                    "sent": "That's why it's important to note like the mappings are split because we discover or we can do everything that we discovered we represented, like an equivalence mapping, but for the our propositional representation we represent them well.",
                    "label": 0
                },
                {
                    "sent": "We applied the mappings in.",
                    "label": 0
                },
                {
                    "sent": "In the two sides, so this is important because in the end the repair process may involve the letting only one of the sides another complete mapping.",
                    "label": 0
                },
                {
                    "sent": "So it would be something useful.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So our first step in in the report is just checking for errors.",
                    "label": 0
                },
                {
                    "sent": "So does the mapping leading the tallest person mapping leading to errors.",
                    "label": 0
                },
                {
                    "sent": "So we implemented this down in Angular algorithm for horn satisfiability.",
                    "label": 0
                },
                {
                    "sent": "The finish is well.",
                    "label": 0
                },
                {
                    "sent": "I think I will explain it with the four.",
                    "label": 0
                },
                {
                    "sent": "With this algorithm we check for every class, so we ask every class it is satisfied satisfied.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For example, can you see to understand with this example?",
                    "label": 0
                },
                {
                    "sent": "Click on the graph representation of all the horn clauses.",
                    "label": 0
                },
                {
                    "sent": "So I want to check if his magma is consistent or not.",
                    "label": 0
                },
                {
                    "sent": "So The thing is, we.",
                    "label": 0
                },
                {
                    "sent": "We see then that I falls from different parts of the same way like.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You see here anatomy.",
                    "label": 0
                },
                {
                    "sent": "And biological processes are disjoint.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So they brought me.",
                    "label": 0
                },
                {
                    "sent": "If you from exactly make anatomy through and also biological process through, we're going to have another error.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "With the mappings we have this problem stuff from his magma below to NCIS, Magma and then we go up, up up and we got fault probably half well.",
                    "label": 0
                },
                {
                    "sent": "We have arrived from one post but also from Shaq racism, bigotry with mapping four to NCI celebration up, up up and then folds.",
                    "label": 0
                },
                {
                    "sent": "So we got an error.",
                    "label": 0
                },
                {
                    "sent": "So the thing with this algorithm is quite easy to compute these things or is linear and is quite fast.",
                    "label": 0
                },
                {
                    "sent": "After how explain later we also contract them which mappings are involving the error?",
                    "label": 0
                },
                {
                    "sent": "In this case you have.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This for.",
                    "label": 0
                },
                {
                    "sent": "So without the characteristic of this algorithm, flow is how?",
                    "label": 0
                },
                {
                    "sent": "So it's good because we were expecting at least if you say if you report that something is an error, so margin error.",
                    "label": 0
                },
                {
                    "sent": "It was case linear, so if the characteristic of the algorithms and in that case we didn't do anything.",
                    "label": 0
                },
                {
                    "sent": "Obviously sing complete with something like we were expecting.",
                    "label": 0
                },
                {
                    "sent": "So if you want something completely that we are not going to be available in the end.",
                    "label": 0
                },
                {
                    "sent": "But we're not that bad in the sense of in terms of incompleteness, because we're classifying ontologies, so it's something we're getting some information.",
                    "label": 0
                },
                {
                    "sent": "Also, mappings in the end there representing Horn clauses.",
                    "label": 0
                },
                {
                    "sent": "Also, as we will see later in the in the valuation, we only fail to report one error between NCI and effect one interacting nsima so well, even if you're in complete for this scenario is working.",
                    "label": 0
                },
                {
                    "sent": "So is something really important too?",
                    "label": 0
                },
                {
                    "sent": "But well, it's important also to know that for some cases we can be getting some errors in the end after the cleaning process.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So well, I think to deal with and we extended our lingering to report the set of mappings that they are involved in.",
                    "label": 0
                },
                {
                    "sent": "There are so for the previous example we have this for mappings.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Oh yeah, so this explained before like we split them up in space, why we have two equivalence mappings are having a splitting for subclass mappings.",
                    "label": 0
                },
                {
                    "sent": "So the thing also for the repair algorithm we try to use something fast and if not really a complete repair algorithm we're not proposing we're not giving all the possibles subsets of mappings that they may repair the error.",
                    "label": 0
                },
                {
                    "sent": "So the idea is like we create.",
                    "label": 0
                },
                {
                    "sent": "Subsets offer small size and then we invite.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Incrementally.",
                    "label": 0
                },
                {
                    "sent": "For example, we're starting from subsets of size 1.",
                    "label": 0
                },
                {
                    "sent": "If we found a plan to repair the error, we're done.",
                    "label": 0
                },
                {
                    "sent": "If we don't find a Plan B, go for subsets of size 2 and then incrementally until we in this example, and until the red berries, for example, for mappings and they were the size of all the completed mappings.",
                    "label": 0
                },
                {
                    "sent": "This will give us some scalability facilities because if we try to compute all possible plans, another potential.",
                    "label": 0
                },
                {
                    "sent": "So if you have four plants is OK, but when I have to for mappings to repair is OK, but sometimes we will get in like 100 conflicted mapping.",
                    "label": 0
                },
                {
                    "sent": "So computing all possible repairs will be relating consuming.",
                    "label": 0
                },
                {
                    "sent": "I'll tell you this greedy algorithm is to our for all the possible classes that could be inconsistent.",
                    "label": 0
                },
                {
                    "sent": "We start from top to down, so sometimes even when we repair the subclass, the top class we are repairing also the subclasses or something that it helps.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, this repair of property angle wasn't initially in the paper, but in the end because we wanted to participate in the ontology matching initiative.",
                    "label": 0
                },
                {
                    "sent": "We decided to include like a facility to discover mapping between properties and also to repair them.",
                    "label": 0
                },
                {
                    "sent": "The mapping instruction also relies only interested in the intersection of the inverted files, but the repair process is not yet included.",
                    "label": 0
                },
                {
                    "sent": "Normal angle here, but we have some eristic Stew at least to report if a mapping between two properties could be dangerous, might be reported in the sense like if you analyze the domains, the respective domains of the properties under ranges and we know that they are not compatible, so the property is not considered.",
                    "label": 0
                },
                {
                    "sent": "And will allow for.",
                    "label": 0
                },
                {
                    "sent": "For the valuation in the disorderly matching initiative, we were able to not to provide any dangerous property I any dangerous mapping.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Properties.",
                    "label": 0
                },
                {
                    "sent": "So this is the last step of our.",
                    "label": 0
                },
                {
                    "sent": "Of log Maps, we also perform like an overlapping.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Any estimation?",
                    "label": 0
                },
                {
                    "sent": "So we provide two fragments of their ontologies based on the mappings we discover and also based on the lexical.",
                    "label": 0
                },
                {
                    "sent": "Leslie County maletis So we have to establish.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Fairly we implement like while we extend the inverted files, because before we invented fireworks lighting.",
                    "label": 0
                },
                {
                    "sent": "Kind of the exact exact label of the order of the other entities, and then we extended in the sand like we don't require the each entry of the inverted file to have like an exact correspondence with the label of the entity.",
                    "label": 0
                },
                {
                    "sent": "We also give some flexibility like only consider like 3 words out of four, three out of out of five to give like more flexibility.",
                    "label": 0
                },
                {
                    "sent": "In that sense, each entry of the inverted file in the other half, like more candidate concepts that they somehow they shared.",
                    "label": 0
                },
                {
                    "sent": "Part of the label, but not the complete label.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This.",
                    "label": 0
                },
                {
                    "sent": "Candidate mappings are dangerous to consider as a mapping, but very interesting to consider them to start this.",
                    "label": 0
                },
                {
                    "sent": "This estimation of the overlapping so we use this week anchors like a like the input signature.",
                    "label": 0
                },
                {
                    "sent": "For those",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This fragment, so I think it would.",
                    "label": 0
                },
                {
                    "sent": "The entities involved in this week anchors.",
                    "label": 0
                },
                {
                    "sent": "There will be like the input signature to stack a fragment memorial and completely we are using this locality model extractor to form the final.",
                    "label": 0
                },
                {
                    "sent": "The final word.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is the last part of the auditory canal.",
                    "label": 0
                },
                {
                    "sent": "This is probably the most interesting.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then we can literally take that.",
                    "label": 0
                },
                {
                    "sent": "What we implementing is working in practice.",
                    "label": 0
                },
                {
                    "sent": "So we use this set of ontologies as Nomad and CI FMA, and also the group of ontologies that there in the ontology.",
                    "label": 0
                },
                {
                    "sent": "Matching initiative values like is a fragment of NCI with 3000 classes, mouse anatomy, ontology, and the set of conference and benchmark.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in the end we we had like 4 main tasks for the valuation, like on the one hand we were rated only the mapping the mapping repair facility of log map to repair gold.",
                    "label": 0
                },
                {
                    "sent": "All set of mappings there supposed to be gold standard.",
                    "label": 0
                },
                {
                    "sent": "We also met this large ontologies FMA NCI under Snow map.",
                    "label": 0
                },
                {
                    "sent": "Uh, another location where these overlapping estimation so are we extracting a meaningful, meaningful fragmented ontologies.",
                    "label": 0
                },
                {
                    "sent": "And finally I will present our results of the participating participation is getting in the entity matching.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for the cleaning of the standards we use the gold standard of the anatomy track of the recently matching initiative and also Umm Azure reference to Inter FM NCI.",
                    "label": 0
                },
                {
                    "sent": "And we have like the mappings, because this ontologies are integrated in numerous and, well, you know it's a big mass hours that interacts.",
                    "label": 0
                },
                {
                    "sent": "Not only ontologies but also discovery.",
                    "label": 0
                },
                {
                    "sent": "So The thing is, we discover taking into account the logic based information and ontologies plus those mappings we got like a huge number of errors.",
                    "label": 0
                },
                {
                    "sent": "So our first time was like trying to with the lock Mac repair facility, try to repair these mappings and provide like a clean mappings set.",
                    "label": 0
                },
                {
                    "sent": "So in the end we were kind of successful because we clean some of the mapping we were not too aggressive so again we provide like a subset of the original mappings, but it's really a big subset and so we were.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Faster than that.",
                    "label": 0
                },
                {
                    "sent": "The unit plan, as I told you, we we fail at reporting 11 error.",
                    "label": 0
                },
                {
                    "sent": "But it makes sense because this error is involving existential anniversary quantification, so so it's something we're not representing in our scenario, but there still is much easier today.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To the user to try to rip.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Only one.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Error and not not 655.",
                    "label": 0
                },
                {
                    "sent": "So in the end we are providing something helpful.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The mappings computer backlog map.",
                    "label": 0
                },
                {
                    "sent": "So now before we started from less, now we're starting from scratch, so we take ncma and NCI and we start trying to get the all possible mappings.",
                    "label": 0
                },
                {
                    "sent": "So I think the important thing is we are able to deal with this week ontologies in a quite reasonable time, and we also provide a set of mappings.",
                    "label": 0
                },
                {
                    "sent": "And what this table, at least for the time perspective?",
                    "label": 0
                },
                {
                    "sent": "Well for the time.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Toby was good, but also we we consider that the results were not about comparing with.",
                    "label": 0
                },
                {
                    "sent": "Now I'm comparing again with you.",
                    "label": 0
                },
                {
                    "sent": "Melissa called Standard and these are the results that log must produce.",
                    "label": 0
                },
                {
                    "sent": "So for FMA on NCI after the cleaning process we got an F score of theodote.",
                    "label": 0
                },
                {
                    "sent": "So is something really important because they are big ontologies?",
                    "label": 0
                },
                {
                    "sent": "We didn't get as nice as nice actual results results for FMA, and there's no mid so that the position was not too bad, but the recall was really really low.",
                    "label": 0
                },
                {
                    "sent": "I'm slightly better than yourself or is normal on NCI.",
                    "label": 0
                },
                {
                    "sent": "So the good thing of daddy, like we are able to process these ontologies.",
                    "label": 0
                },
                {
                    "sent": "But still we are a bit far away from the ideal results while getting really better record results.",
                    "label": 0
                },
                {
                    "sent": "But this has an explanation why we are not getting better FS columns.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's like a currently looking at realize in the lexical similarity of the ontologists.",
                    "label": 0
                },
                {
                    "sent": "So FMA, FMA, and NCI.",
                    "label": 0
                },
                {
                    "sent": "They have like quite commonalities, but for example a family I don't know, but they are quite this part so it's like.",
                    "label": 0
                },
                {
                    "sent": "The subset of mappings from the gold standard that they have, like a lexical similarity of 95.",
                    "label": 0
                },
                {
                    "sent": "Is for any feminine CIS acting 88% but foreign FML is nomad is only 21.",
                    "label": 0
                },
                {
                    "sent": "Why we fail to discover?",
                    "label": 0
                },
                {
                    "sent": "A huge set of mapping is why our goal was more or less said not to.",
                    "label": 0
                },
                {
                    "sent": "But then again there are like 9 results from from the first approximation and you know we have had plenty of.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Improvement.",
                    "label": 0
                },
                {
                    "sent": "So I think the overlapping also was a nice output outlook map.",
                    "label": 0
                },
                {
                    "sent": "Look like we're mapping this joint ologist, but even if you are not able to produce that complete set of mappings, we are able to produce like uninteresting map fragmente.",
                    "label": 0
                },
                {
                    "sent": "And then you can try to discover more mappings so.",
                    "label": 0
                },
                {
                    "sent": "Summer or more specialized mountry matching tools.",
                    "label": 0
                },
                {
                    "sent": "They could get this output Verilog output and try to discover new mappings and now without much smaller fragmente.",
                    "label": 0
                },
                {
                    "sent": "So it's something like.",
                    "label": 0
                },
                {
                    "sent": "I know it's not logged in at the end, it could be like used in combination with other until imagine.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, and I guess too.",
                    "label": 0
                },
                {
                    "sent": "To conclude this, these are the results of the entry imaginal campaign.",
                    "label": 0
                },
                {
                    "sent": "In the end we decided to participate because then it was good to get some feedback from the community and also to compare with other tools so forth.",
                    "label": 0
                },
                {
                    "sent": "Anatomy track we got really interesting results.",
                    "label": 0
                },
                {
                    "sent": "We were the second tool in terms of F score.",
                    "label": 0
                },
                {
                    "sent": "An yeah, I could make it worse for away from the other tools that the recall was amazing with almost 0.9.",
                    "label": 0
                },
                {
                    "sent": "But the interesting thing is like the.",
                    "label": 0
                },
                {
                    "sent": "A little of my previous colorful and work the fastest, fastest one and also my was pretty fast, but comparing the results so we were fast and also the product really meaningful, meaningful set of mappings.",
                    "label": 0
                },
                {
                    "sent": "Uh, the last column, it means like the incurrence, so they are not official results for the entity matching campaign.",
                    "label": 0
                },
                {
                    "sent": "But well, we use a completely as owner.",
                    "label": 0
                },
                {
                    "sent": "In that case I think was Hermit and we didn't get any unsatisfiable classes this morning with ontologies on the mappings.",
                    "label": 0
                },
                {
                    "sent": "But I don't know the other tools, so the other 2 sided, the percentage of in currencies zero or more, but probably we will get some results.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So far there is another track in the in the campaign is about a small ontologies dealing with conference and in the in the track we were the first of all.",
                    "label": 0
                },
                {
                    "sent": "So we got some good results.",
                    "label": 0
                },
                {
                    "sent": "However, more or less in line with the with the best too.",
                    "label": 0
                },
                {
                    "sent": "Again, the results were.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Wait from using.",
                    "label": 0
                },
                {
                    "sent": "For the third track of the OR the campaign, we didn't get a good results, but we were expecting that, so this struck what they they try to create like benchmark test like automatically.",
                    "label": 0
                },
                {
                    "sent": "Well, they start from a real ontology and automatically remove some labels.",
                    "label": 0
                },
                {
                    "sent": "They put random strings so you might log mass and that doesn't perform well because we rely on the lexical similarities and when they when the labels are are missing or they are not labeled.",
                    "label": 0
                },
                {
                    "sent": "We just not provide mappings and why we didn't.",
                    "label": 0
                },
                {
                    "sent": "What are really nicely called.",
                    "label": 0
                },
                {
                    "sent": "For example, this if I'm not wrong with, it works.",
                    "label": 0
                },
                {
                    "sent": "The best tool has much better result than us, but it's something we were expecting, so probably in the future we try to.",
                    "label": 0
                },
                {
                    "sent": "Try to improve.",
                    "label": 0
                },
                {
                    "sent": "That is mapping discovery like if there are no labels trying to apply some other new lipsticks.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, just to conclude, so these words log mob while we started working with low magnesium from January, trying to create a new scalable an nice tool.",
                    "label": 0
                },
                {
                    "sent": "I think we got it, but well, we're still working on the other.",
                    "label": 0
                },
                {
                    "sent": "I see plenty of room for improvement now we have a second version of Lock Box is kind of more stable and robust and we plan to.",
                    "label": 0
                },
                {
                    "sent": "Well now look like this about global name from the sales platform, but we plan to put it also the source code and everything available in the future.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So thank you very much and you have any questions.",
                    "label": 0
                },
                {
                    "sent": "I will be more than happy.",
                    "label": 0
                }
            ]
        }
    }
}