{
    "id": "65y2ca37newh25hylyhu6vtfjusdr2fc",
    "title": "Analysis of the Multi-Dimensional Scale Saliency Algorithm and its Application to Texture Categorization",
    "info": {
        "author": [
            "Francisco Escolano, Department of Science of the Computation and Artificial Intelligence, University of Alicante"
        ],
        "published": "Sept. 13, 2010",
        "recorded": "August 2010",
        "category": [
            "Top->Computer Science->Pattern Recognition"
        ]
    },
    "url": "http://videolectures.net/ssspr2010_escolano_amd/",
    "segmentation": [
        [
            "How to extend well known scale saliency detector?",
            "To multidimensional to the multidimensional case, and in particular how to.",
            "How is behavior for categorisation of Texas?",
            "So."
        ],
        [
            "So we shift shift has established landmark in the in the in the emergence of order.",
            "In the appearance of a lot of different detectors and descriptors for capturing parts of the images in the which turn out to be fundamental in some application for object recognition.",
            "And one is one of them is the is the silence."
        ],
        [
            "Which is basically just.",
            "Based on the concept of local salience, which means that the region is supposed to be a scale invariant.",
            "Or this.",
            "Particularly interesting locali."
        ],
        [
            "And this one of these were this detectors is the cuddle buddy detector that everybody detector is not.",
            "Consider it a good detector in terms of repeatability for matching application that is considered a good detector for in categorization tasks.",
            "So basically the behind the detector is that.",
            "Scale is space analysis.",
            "Just come on too many of the detectors in this case is looking for a pick of entropy in the scaling space.",
            "Um?"
        ],
        [
            "Basic idea is that if you extend you are in a pixel an extent the neighborhood you are in Virginia region.",
            "You will have a given entropy in the in the pixel domain in the intensity domain and.",
            "We will be maximol.",
            "Because you have nothing is everything is the same color but but you are out of the of the object of the block.",
            "This entropy is start to decrease.",
            "So you can say that this is the localization.",
            "The optimal localization and optimal scale.",
            "So you can extend this concept to not to isotropic object, but to a fine object to find detection.",
            "But the problem is that.",
            "The escapist solution.",
            "The scale skill values is the bottleneck of the process."
        ],
        [
            "So before entering the part of explaining how to generalize this detector for multi dimensional cases, it is good too.",
            "I think it's timely to introduce previous.",
            "Approach we have to filter some points in the image because many points many pixels in the image are not going to be silent.",
            "If you know that in advance this is the basic idea.",
            "You are not condition to apply scale analysis.",
            "To every pixel in the image so bad for doing that task you need the statistics of the image class.",
            "For instance, if you are considering the statistics of the Caltech database.",
            "For a given class I would place for instance.",
            "It is possible to get the statistics of the image.",
            "To design A filter to avoid a lot of time.",
            "And save and save time in doing a scalar space so."
        ],
        [
            "The basic."
        ],
        [
            "Media."
        ],
        [
            "Is that?",
            "Have to consider the true positives and the first positive false positive distribution is a learning problem.",
            "So imagine you have several categories and you have the inline category.",
            "When the detector in what pixel detector is is working and what pixel detector says nothing.",
            "So if you learn this.",
            "Distribution is the P on distribution, is the the true positive distribution at you also learned for this distribution.",
            "With this the false positive distribution.",
            "For this class.",
            "A good filter could be possible if this good separation between both distribution Bayesian terms.",
            "So if this distributions are overlap.",
            "You are not able of reducing.",
            "The analysis of.",
            "Many points in the image, which is the base."
        ],
        [
            "Radian so.",
            "Method for quantification of that is the channel information.",
            "Internal information is measuring.",
            "This overlapping is something like the product there is a.",
            "Is the minimum about all choices of.",
            "Be on two Lambda times P of.",
            "21 minus Lambda and particular case is the Bachelor distance, which is when Lambda is.",
            "15 OK."
        ],
        [
            "So while the Chairman of Information, the Chairman of Information, provides us with very useful thing which is the channel bound, the Journal bounds bounds depends on the code by labor divisions between P&P off and how they have this this shape.",
            "So any threshold?",
            "For instance, imagine that the salience of your your pixel.",
            "You make analysis and of this region and if you one of the bad things is that is finding a good threshold to decide the pixel is silent or not, so general information gives you range where this threshold is valid statistically.",
            "So you can take a conservative approach like going to the low number of aggressive approach to going.",
            "Close to the upper bound, or Simply put, set this as zero."
        ],
        [
            "So these are some cases where in different classes when we use T = 0 and this is the original image and these are different.",
            "OK, this O for this hold and in black you can see the pixels that are not investigated by the algorithm because the basic hypothesis is the hypothesis is that the entropy is lower at higher scales is.",
            "Likely to be below lowest calories.",
            "So this for this threshold we analyze internal.",
            "It turns out that we analyze only the part of the image which has some interesting points.",
            "Which is a good thing for when you are dealing with a scale scale saliency detectors?",
            "And this can be applied to every scale saliency texture you can consider."
        ],
        [
            "So these are these.",
            "Are this safe time of points on time dependence on some categories, 40% of time depending on the threshold?",
            "But there also some little error in the localization of the of the of the of the point, But anyway.",
            "If you are within these bounds.",
            "The the error is now."
        ],
        [
            "So hey, so this was happening with the filter in the Caltech 101 database.",
            "That is, this is the number of you know.",
            "Does the.",
            "The the error and with T is the minimum base and T0 when D = 0.",
            "Many categories has lower or some of them has a lot bigger or not."
        ],
        [
            "So what is behind the channel of information is because the channel information is the exponent following the son of cerium is the exponent of the probability of error that is, the larger the Chairman of information is, the lower will be the error.",
            "And this is important because if you have a very low churn of information, you have a very high overlap, so the probability of error is growing."
        ],
        [
            "So with that kind of instrument at hand, we can apply this to localization problems with different thresholds and and see that depending on the class it has more texture or less test.",
            "Or you can save a lot of a lot of time.",
            "OK, looking for you there.",
            "Your silence that."
        ],
        [
            "Vectors OK so, but there are some applications where you need to have.",
            "This is able to have no precise if you are working here in RGB.",
            "All images multispectral approaches.",
            "When you have a multi spectral.",
            "Database and you want to find some salience in that context that is that region given region with many dimensions.",
            "We just saw him in the image, so if you want to do."
        ],
        [
            "That if you are one way of doing that is extra to extend the this the same detector and then apply the methodology of filtering.",
            "I told you before.",
            "Due to this kind of images.",
            "Because here where you have multi dimensional data, the scaling space analysis is harder."
        ],
        [
            "So in order to do that, you need an entropy estimator because you.",
            "Remember that you are detecting peaks of entropy, so if you are, if it's pixel is a multidimensional variable instead of 1 dimensional.",
            "You need.",
            "By passenger Vista Mater you are not able for instance, in that case, not other basis for 31 spectral bands.",
            "This is not a very critical case of a circle back there.",
            "Images of thousands of bands or something like that.",
            "So if you have that.",
            "Units for sure has to avoid for sure.",
            "The estimation of the PDF.",
            "To calculate the entropy."
        ],
        [
            "There among the estimators, some of them are the learning quite talkin.",
            "Talk about it in late later.",
            "And.",
            "And we use."
        ],
        [
            "Frequently, but there are others.",
            "Recently proposed are more efficient.",
            "One of them is the the estimators based on data partition.",
            "So the basic idea of the data partition are going to give you."
        ],
        [
            "An image is to partition this space.",
            "Like you know, in a country or here is a 2 dimensional case.",
            "But imagine that you select one dimension an find the median and make a partition and then.",
            "Seek for another dimension and find the median of that dimension and take a partition at that, and so on until.",
            "Homogeneous majority criterion inside this.",
            "These cells is is declared is found in this case.",
            "In this particular case with the detector of of."
        ],
        [
            "The.",
            "The stolen plumbea.",
            "They used the.",
            "Normal normality test that is the late take a statistics and the statistics are saying that this is smooth.",
            "And they take a normalized variable, an standardized variable, an OK, we can say that this is smooth.",
            "So following that, the entropy is given by the probability basically."
        ],
        [
            "By the density of the cells that this, considering that this point divided by the number of total points.",
            "It's an approximation of the probability that the density of the point all these three."
        ],
        [
            "Mission, but in this partition we may have points of different distributions.",
            "Imagine that we are comparing in the scale saliency case.",
            "We have a neighborhood of radius 10, which is the blue dots, and then we extend our neighborhood to radius 15.",
            "Which are the blue points, so we have to.",
            "The topic and to adapt entropy peak, we have to compare them.",
            "If there's all we have also to do another thing which is to compute self similarity, measure that.",
            "Means that whether there's a significant chance between the change between the two distributions.",
            "So in order to do that, we propose us very simple total variation distance, which is something like the probability of X, the sum of.",
            "Absolutely, when differences between probability of obtaining one dimension one in one of the.",
            "The distributions minus the probability of being in the other distribution, and this can be simply approximated by what is the probability of this cell and the.",
            "The cells of this in this cell with this ability of the red points and the proportion of good points, and the proportion of blue points.",
            "So imagine that in a context of 31 dimensions."
        ],
        [
            "OK, so here we have divergences of .24.",
            "And here were you have very different distributions.",
            "We have our divergences of .92.",
            "So.",
            "This modified.",
            "This gives a color body algorithm where the entropy is estimated using this approach.",
            "The Divergents, the local divergance is that is a self similarity is computed using total variation and the waiting is given by this little variation.",
            "So finally find peak of entropy.",
            "OK, there are several approaches to to compute entropy.",
            "One of them is based off.",
            "MS3 is or gain and graphs the problem of KNN graphs is that the complexity is is as you are increasing the neighborhood.",
            "You cannot reuse the previous MST or or update it for the next neighborhood, so the complexity is grows a lot.",
            "This is the complexity of the color algorithm when you when you go 402.",
            "71 dimensions and this ingredient is in the complexity of our proposal.",
            "Without considering the filter in only the algorithm.",
            "And OK.",
            "Here is the comparison, but with this depends the number of bins you consider and also the range of scales.",
            "For instance, you won't go from 5 to 8.",
            "This cost and if you want to 5 to 20 our our method.",
            "Of course this is the scale is larger and the number of bins, although the number of diseases lower so they have.",
            "This complexity is not growing.",
            "2 faster or too fast and at least 431 dimensions."
        ],
        [
            "So in terms of deviation of the entropy estimator, sometimes this in comparison with other interesting later, like the Lorenco at all another entropy standby passenger based emitters.",
            "Sometimes we overestimate, sometimes we underestimate the distribution, but as we are comparing we're maximizing, we're finding a pic of entropy.",
            "That is not important because we don't need exactly to estimate the coded value of entropy, only a relative value of entropy.",
            "Anyway, this analysis has has to be done."
        ],
        [
            "One thing we have, what color we have in several dimensions is that if you increase the number of dimensions, imagine the number of bands in your in your spectral image.",
            "The number of pics of entropy start to decrease.",
            "The reason of that is.",
            "Imagine that I'm looking into space with the same range of scales.",
            "An individual scale, a space.",
            "Points tend to be sparser and sparser, and you grow the dimensions.",
            "So if you are trying to find that pic of entropy is very difficult if you don't adapt the range of scale is very difficult to get that that feature, so you are losing features in that rate with the same even Similarly, if you use one of the estimators or the other estimators of entropy is quite similar.",
            "Anyway, it's not a very high loss.",
            "Best, but if you want beyond 100 feet of features, issue."
        ],
        [
            "Maybe so.",
            "Using that for text to so our proposed now is too OK to get textures from the given database and tattoo cataract make categorization.",
            "Taking first the their salience but using this multidimensional approach.",
            "That is not not Gray level.",
            "This is the difference between grade level saliency, which is OK. Let's you know less uniform 'cause it's based on grey.",
            "Not not on statistics.",
            "For instance, coming from our filters.",
            "So here we are, we are using only one scale or our filters jazz for for bounding the features to 15 or so.",
            "The number of filters we have.",
            "So and then after detecting, you characterize that that is used as a script or like Rift of Soul for whatever you want.",
            "I make experiments or will happens.",
            "Always find out our method is slightly better than than Khedira Brady in each case but not so so good.",
            "Not so good.",
            "The results are highly influenced by the type of descriptor.",
            "Finally, you use for categorization.",
            "For the same detector you changed the script or this is a combination of descriptors and.",
            "This is the our performance is the performance of career in Dustin Gray level.",
            "In that case."
        ],
        [
            "OK, it is better our results back.",
            "We are not investigated yet the.",
            "The effect of finding the optimal set of features in a previous lecture I'll talk about how to find the optimal set of features."
        ],
        [
            "So here we are working now in use.",
            "More rich, richer Gabor filter bank and then finding the features that add more discriminative, which will probably increase this.",
            "You know, this difference between between multidimensional and low dimensional, a saliency"
        ],
        [
            "So the conclusion we propose a motivational salience method.",
            "Applications for respect, perspective, image of the textual categorisation.",
            "Kidney partition system estimators are very efficient.",
            "And also so precise, but it is enough for for this task at least have to be aware that the number of entropy picks decreases when increasing the dimensions.",
            "So you have to make to improve that in terms of adapting also the scale.",
            "But if you extend the scale you will have a computational problem.",
            "So it's also convenient to find the optimal number of features if you if the performance is degrading with the number of features.",
            "It should be good to have a good number of features.",
            "Yeah, that is the most informative one.",
            "So this is the.",
            "I work for the future so and that's all.",
            "Thank you very much.",
            "Thank you very much.",
            "The floor is open for one or more questions.",
            "Well, I would like to know.",
            "So I may be aware of the approach, but there's a saliency detection approach by Bruce and sort source.",
            "While one trick they apply to overcome difficulties with higher dimensions is that they first try to do an ICA on the features, and then that they try to assume some sort of independence with something like this.",
            "Also be helpful in your so that you then, separately.",
            "Yeah, yes, for sure you have to have to go to the features in advance.",
            "You mean that?",
            "But if you so if you would know what kind of if you would could assume some sort of independence between the features cultured and exploit that in making it making the estimate estimation more simple.",
            "So then you only would maybe have to estimate the entropy in lower dimensions and so compile from that entropy is higher dimensions.",
            "Something like that makes sense in your setting, or is it just not applicable?",
            "Interesting, I don't know the approach about.",
            "OK, OK, I can give you the review.",
            "Russians from the audience.",
            "Nobody, well, let's thank the speaker again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "How to extend well known scale saliency detector?",
                    "label": 1
                },
                {
                    "sent": "To multidimensional to the multidimensional case, and in particular how to.",
                    "label": 0
                },
                {
                    "sent": "How is behavior for categorisation of Texas?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we shift shift has established landmark in the in the in the emergence of order.",
                    "label": 0
                },
                {
                    "sent": "In the appearance of a lot of different detectors and descriptors for capturing parts of the images in the which turn out to be fundamental in some application for object recognition.",
                    "label": 1
                },
                {
                    "sent": "And one is one of them is the is the silence.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which is basically just.",
                    "label": 0
                },
                {
                    "sent": "Based on the concept of local salience, which means that the region is supposed to be a scale invariant.",
                    "label": 0
                },
                {
                    "sent": "Or this.",
                    "label": 0
                },
                {
                    "sent": "Particularly interesting locali.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this one of these were this detectors is the cuddle buddy detector that everybody detector is not.",
                    "label": 0
                },
                {
                    "sent": "Consider it a good detector in terms of repeatability for matching application that is considered a good detector for in categorization tasks.",
                    "label": 0
                },
                {
                    "sent": "So basically the behind the detector is that.",
                    "label": 0
                },
                {
                    "sent": "Scale is space analysis.",
                    "label": 0
                },
                {
                    "sent": "Just come on too many of the detectors in this case is looking for a pick of entropy in the scaling space.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Basic idea is that if you extend you are in a pixel an extent the neighborhood you are in Virginia region.",
                    "label": 0
                },
                {
                    "sent": "You will have a given entropy in the in the pixel domain in the intensity domain and.",
                    "label": 0
                },
                {
                    "sent": "We will be maximol.",
                    "label": 0
                },
                {
                    "sent": "Because you have nothing is everything is the same color but but you are out of the of the object of the block.",
                    "label": 0
                },
                {
                    "sent": "This entropy is start to decrease.",
                    "label": 0
                },
                {
                    "sent": "So you can say that this is the localization.",
                    "label": 0
                },
                {
                    "sent": "The optimal localization and optimal scale.",
                    "label": 0
                },
                {
                    "sent": "So you can extend this concept to not to isotropic object, but to a fine object to find detection.",
                    "label": 0
                },
                {
                    "sent": "But the problem is that.",
                    "label": 0
                },
                {
                    "sent": "The escapist solution.",
                    "label": 0
                },
                {
                    "sent": "The scale skill values is the bottleneck of the process.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So before entering the part of explaining how to generalize this detector for multi dimensional cases, it is good too.",
                    "label": 0
                },
                {
                    "sent": "I think it's timely to introduce previous.",
                    "label": 0
                },
                {
                    "sent": "Approach we have to filter some points in the image because many points many pixels in the image are not going to be silent.",
                    "label": 0
                },
                {
                    "sent": "If you know that in advance this is the basic idea.",
                    "label": 0
                },
                {
                    "sent": "You are not condition to apply scale analysis.",
                    "label": 0
                },
                {
                    "sent": "To every pixel in the image so bad for doing that task you need the statistics of the image class.",
                    "label": 0
                },
                {
                    "sent": "For instance, if you are considering the statistics of the Caltech database.",
                    "label": 0
                },
                {
                    "sent": "For a given class I would place for instance.",
                    "label": 0
                },
                {
                    "sent": "It is possible to get the statistics of the image.",
                    "label": 1
                },
                {
                    "sent": "To design A filter to avoid a lot of time.",
                    "label": 0
                },
                {
                    "sent": "And save and save time in doing a scalar space so.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The basic.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Media.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is that?",
                    "label": 0
                },
                {
                    "sent": "Have to consider the true positives and the first positive false positive distribution is a learning problem.",
                    "label": 0
                },
                {
                    "sent": "So imagine you have several categories and you have the inline category.",
                    "label": 0
                },
                {
                    "sent": "When the detector in what pixel detector is is working and what pixel detector says nothing.",
                    "label": 0
                },
                {
                    "sent": "So if you learn this.",
                    "label": 0
                },
                {
                    "sent": "Distribution is the P on distribution, is the the true positive distribution at you also learned for this distribution.",
                    "label": 0
                },
                {
                    "sent": "With this the false positive distribution.",
                    "label": 0
                },
                {
                    "sent": "For this class.",
                    "label": 0
                },
                {
                    "sent": "A good filter could be possible if this good separation between both distribution Bayesian terms.",
                    "label": 0
                },
                {
                    "sent": "So if this distributions are overlap.",
                    "label": 0
                },
                {
                    "sent": "You are not able of reducing.",
                    "label": 0
                },
                {
                    "sent": "The analysis of.",
                    "label": 0
                },
                {
                    "sent": "Many points in the image, which is the base.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Radian so.",
                    "label": 0
                },
                {
                    "sent": "Method for quantification of that is the channel information.",
                    "label": 0
                },
                {
                    "sent": "Internal information is measuring.",
                    "label": 0
                },
                {
                    "sent": "This overlapping is something like the product there is a.",
                    "label": 0
                },
                {
                    "sent": "Is the minimum about all choices of.",
                    "label": 0
                },
                {
                    "sent": "Be on two Lambda times P of.",
                    "label": 0
                },
                {
                    "sent": "21 minus Lambda and particular case is the Bachelor distance, which is when Lambda is.",
                    "label": 0
                },
                {
                    "sent": "15 OK.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So while the Chairman of Information, the Chairman of Information, provides us with very useful thing which is the channel bound, the Journal bounds bounds depends on the code by labor divisions between P&P off and how they have this this shape.",
                    "label": 0
                },
                {
                    "sent": "So any threshold?",
                    "label": 0
                },
                {
                    "sent": "For instance, imagine that the salience of your your pixel.",
                    "label": 0
                },
                {
                    "sent": "You make analysis and of this region and if you one of the bad things is that is finding a good threshold to decide the pixel is silent or not, so general information gives you range where this threshold is valid statistically.",
                    "label": 0
                },
                {
                    "sent": "So you can take a conservative approach like going to the low number of aggressive approach to going.",
                    "label": 0
                },
                {
                    "sent": "Close to the upper bound, or Simply put, set this as zero.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So these are some cases where in different classes when we use T = 0 and this is the original image and these are different.",
                    "label": 1
                },
                {
                    "sent": "OK, this O for this hold and in black you can see the pixels that are not investigated by the algorithm because the basic hypothesis is the hypothesis is that the entropy is lower at higher scales is.",
                    "label": 0
                },
                {
                    "sent": "Likely to be below lowest calories.",
                    "label": 0
                },
                {
                    "sent": "So this for this threshold we analyze internal.",
                    "label": 0
                },
                {
                    "sent": "It turns out that we analyze only the part of the image which has some interesting points.",
                    "label": 0
                },
                {
                    "sent": "Which is a good thing for when you are dealing with a scale scale saliency detectors?",
                    "label": 0
                },
                {
                    "sent": "And this can be applied to every scale saliency texture you can consider.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So these are these.",
                    "label": 0
                },
                {
                    "sent": "Are this safe time of points on time dependence on some categories, 40% of time depending on the threshold?",
                    "label": 0
                },
                {
                    "sent": "But there also some little error in the localization of the of the of the of the point, But anyway.",
                    "label": 0
                },
                {
                    "sent": "If you are within these bounds.",
                    "label": 0
                },
                {
                    "sent": "The the error is now.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So hey, so this was happening with the filter in the Caltech 101 database.",
                    "label": 1
                },
                {
                    "sent": "That is, this is the number of you know.",
                    "label": 0
                },
                {
                    "sent": "Does the.",
                    "label": 0
                },
                {
                    "sent": "The the error and with T is the minimum base and T0 when D = 0.",
                    "label": 0
                },
                {
                    "sent": "Many categories has lower or some of them has a lot bigger or not.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what is behind the channel of information is because the channel information is the exponent following the son of cerium is the exponent of the probability of error that is, the larger the Chairman of information is, the lower will be the error.",
                    "label": 0
                },
                {
                    "sent": "And this is important because if you have a very low churn of information, you have a very high overlap, so the probability of error is growing.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So with that kind of instrument at hand, we can apply this to localization problems with different thresholds and and see that depending on the class it has more texture or less test.",
                    "label": 0
                },
                {
                    "sent": "Or you can save a lot of a lot of time.",
                    "label": 0
                },
                {
                    "sent": "OK, looking for you there.",
                    "label": 0
                },
                {
                    "sent": "Your silence that.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Vectors OK so, but there are some applications where you need to have.",
                    "label": 0
                },
                {
                    "sent": "This is able to have no precise if you are working here in RGB.",
                    "label": 0
                },
                {
                    "sent": "All images multispectral approaches.",
                    "label": 0
                },
                {
                    "sent": "When you have a multi spectral.",
                    "label": 0
                },
                {
                    "sent": "Database and you want to find some salience in that context that is that region given region with many dimensions.",
                    "label": 0
                },
                {
                    "sent": "We just saw him in the image, so if you want to do.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That if you are one way of doing that is extra to extend the this the same detector and then apply the methodology of filtering.",
                    "label": 0
                },
                {
                    "sent": "I told you before.",
                    "label": 0
                },
                {
                    "sent": "Due to this kind of images.",
                    "label": 0
                },
                {
                    "sent": "Because here where you have multi dimensional data, the scaling space analysis is harder.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in order to do that, you need an entropy estimator because you.",
                    "label": 0
                },
                {
                    "sent": "Remember that you are detecting peaks of entropy, so if you are, if it's pixel is a multidimensional variable instead of 1 dimensional.",
                    "label": 0
                },
                {
                    "sent": "You need.",
                    "label": 0
                },
                {
                    "sent": "By passenger Vista Mater you are not able for instance, in that case, not other basis for 31 spectral bands.",
                    "label": 0
                },
                {
                    "sent": "This is not a very critical case of a circle back there.",
                    "label": 0
                },
                {
                    "sent": "Images of thousands of bands or something like that.",
                    "label": 0
                },
                {
                    "sent": "So if you have that.",
                    "label": 0
                },
                {
                    "sent": "Units for sure has to avoid for sure.",
                    "label": 0
                },
                {
                    "sent": "The estimation of the PDF.",
                    "label": 0
                },
                {
                    "sent": "To calculate the entropy.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There among the estimators, some of them are the learning quite talkin.",
                    "label": 0
                },
                {
                    "sent": "Talk about it in late later.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "And we use.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Frequently, but there are others.",
                    "label": 0
                },
                {
                    "sent": "Recently proposed are more efficient.",
                    "label": 0
                },
                {
                    "sent": "One of them is the the estimators based on data partition.",
                    "label": 0
                },
                {
                    "sent": "So the basic idea of the data partition are going to give you.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "An image is to partition this space.",
                    "label": 0
                },
                {
                    "sent": "Like you know, in a country or here is a 2 dimensional case.",
                    "label": 0
                },
                {
                    "sent": "But imagine that you select one dimension an find the median and make a partition and then.",
                    "label": 0
                },
                {
                    "sent": "Seek for another dimension and find the median of that dimension and take a partition at that, and so on until.",
                    "label": 0
                },
                {
                    "sent": "Homogeneous majority criterion inside this.",
                    "label": 0
                },
                {
                    "sent": "These cells is is declared is found in this case.",
                    "label": 0
                },
                {
                    "sent": "In this particular case with the detector of of.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "The stolen plumbea.",
                    "label": 0
                },
                {
                    "sent": "They used the.",
                    "label": 0
                },
                {
                    "sent": "Normal normality test that is the late take a statistics and the statistics are saying that this is smooth.",
                    "label": 0
                },
                {
                    "sent": "And they take a normalized variable, an standardized variable, an OK, we can say that this is smooth.",
                    "label": 0
                },
                {
                    "sent": "So following that, the entropy is given by the probability basically.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "By the density of the cells that this, considering that this point divided by the number of total points.",
                    "label": 0
                },
                {
                    "sent": "It's an approximation of the probability that the density of the point all these three.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Mission, but in this partition we may have points of different distributions.",
                    "label": 0
                },
                {
                    "sent": "Imagine that we are comparing in the scale saliency case.",
                    "label": 0
                },
                {
                    "sent": "We have a neighborhood of radius 10, which is the blue dots, and then we extend our neighborhood to radius 15.",
                    "label": 0
                },
                {
                    "sent": "Which are the blue points, so we have to.",
                    "label": 0
                },
                {
                    "sent": "The topic and to adapt entropy peak, we have to compare them.",
                    "label": 0
                },
                {
                    "sent": "If there's all we have also to do another thing which is to compute self similarity, measure that.",
                    "label": 0
                },
                {
                    "sent": "Means that whether there's a significant chance between the change between the two distributions.",
                    "label": 0
                },
                {
                    "sent": "So in order to do that, we propose us very simple total variation distance, which is something like the probability of X, the sum of.",
                    "label": 0
                },
                {
                    "sent": "Absolutely, when differences between probability of obtaining one dimension one in one of the.",
                    "label": 0
                },
                {
                    "sent": "The distributions minus the probability of being in the other distribution, and this can be simply approximated by what is the probability of this cell and the.",
                    "label": 0
                },
                {
                    "sent": "The cells of this in this cell with this ability of the red points and the proportion of good points, and the proportion of blue points.",
                    "label": 0
                },
                {
                    "sent": "So imagine that in a context of 31 dimensions.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so here we have divergences of .24.",
                    "label": 0
                },
                {
                    "sent": "And here were you have very different distributions.",
                    "label": 0
                },
                {
                    "sent": "We have our divergences of .92.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "This modified.",
                    "label": 0
                },
                {
                    "sent": "This gives a color body algorithm where the entropy is estimated using this approach.",
                    "label": 0
                },
                {
                    "sent": "The Divergents, the local divergance is that is a self similarity is computed using total variation and the waiting is given by this little variation.",
                    "label": 0
                },
                {
                    "sent": "So finally find peak of entropy.",
                    "label": 0
                },
                {
                    "sent": "OK, there are several approaches to to compute entropy.",
                    "label": 0
                },
                {
                    "sent": "One of them is based off.",
                    "label": 0
                },
                {
                    "sent": "MS3 is or gain and graphs the problem of KNN graphs is that the complexity is is as you are increasing the neighborhood.",
                    "label": 0
                },
                {
                    "sent": "You cannot reuse the previous MST or or update it for the next neighborhood, so the complexity is grows a lot.",
                    "label": 0
                },
                {
                    "sent": "This is the complexity of the color algorithm when you when you go 402.",
                    "label": 0
                },
                {
                    "sent": "71 dimensions and this ingredient is in the complexity of our proposal.",
                    "label": 0
                },
                {
                    "sent": "Without considering the filter in only the algorithm.",
                    "label": 0
                },
                {
                    "sent": "And OK.",
                    "label": 0
                },
                {
                    "sent": "Here is the comparison, but with this depends the number of bins you consider and also the range of scales.",
                    "label": 0
                },
                {
                    "sent": "For instance, you won't go from 5 to 8.",
                    "label": 0
                },
                {
                    "sent": "This cost and if you want to 5 to 20 our our method.",
                    "label": 0
                },
                {
                    "sent": "Of course this is the scale is larger and the number of bins, although the number of diseases lower so they have.",
                    "label": 0
                },
                {
                    "sent": "This complexity is not growing.",
                    "label": 0
                },
                {
                    "sent": "2 faster or too fast and at least 431 dimensions.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in terms of deviation of the entropy estimator, sometimes this in comparison with other interesting later, like the Lorenco at all another entropy standby passenger based emitters.",
                    "label": 1
                },
                {
                    "sent": "Sometimes we overestimate, sometimes we underestimate the distribution, but as we are comparing we're maximizing, we're finding a pic of entropy.",
                    "label": 0
                },
                {
                    "sent": "That is not important because we don't need exactly to estimate the coded value of entropy, only a relative value of entropy.",
                    "label": 0
                },
                {
                    "sent": "Anyway, this analysis has has to be done.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "One thing we have, what color we have in several dimensions is that if you increase the number of dimensions, imagine the number of bands in your in your spectral image.",
                    "label": 0
                },
                {
                    "sent": "The number of pics of entropy start to decrease.",
                    "label": 1
                },
                {
                    "sent": "The reason of that is.",
                    "label": 0
                },
                {
                    "sent": "Imagine that I'm looking into space with the same range of scales.",
                    "label": 0
                },
                {
                    "sent": "An individual scale, a space.",
                    "label": 0
                },
                {
                    "sent": "Points tend to be sparser and sparser, and you grow the dimensions.",
                    "label": 0
                },
                {
                    "sent": "So if you are trying to find that pic of entropy is very difficult if you don't adapt the range of scale is very difficult to get that that feature, so you are losing features in that rate with the same even Similarly, if you use one of the estimators or the other estimators of entropy is quite similar.",
                    "label": 0
                },
                {
                    "sent": "Anyway, it's not a very high loss.",
                    "label": 0
                },
                {
                    "sent": "Best, but if you want beyond 100 feet of features, issue.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Maybe so.",
                    "label": 0
                },
                {
                    "sent": "Using that for text to so our proposed now is too OK to get textures from the given database and tattoo cataract make categorization.",
                    "label": 0
                },
                {
                    "sent": "Taking first the their salience but using this multidimensional approach.",
                    "label": 0
                },
                {
                    "sent": "That is not not Gray level.",
                    "label": 0
                },
                {
                    "sent": "This is the difference between grade level saliency, which is OK. Let's you know less uniform 'cause it's based on grey.",
                    "label": 0
                },
                {
                    "sent": "Not not on statistics.",
                    "label": 0
                },
                {
                    "sent": "For instance, coming from our filters.",
                    "label": 0
                },
                {
                    "sent": "So here we are, we are using only one scale or our filters jazz for for bounding the features to 15 or so.",
                    "label": 0
                },
                {
                    "sent": "The number of filters we have.",
                    "label": 0
                },
                {
                    "sent": "So and then after detecting, you characterize that that is used as a script or like Rift of Soul for whatever you want.",
                    "label": 0
                },
                {
                    "sent": "I make experiments or will happens.",
                    "label": 0
                },
                {
                    "sent": "Always find out our method is slightly better than than Khedira Brady in each case but not so so good.",
                    "label": 0
                },
                {
                    "sent": "Not so good.",
                    "label": 0
                },
                {
                    "sent": "The results are highly influenced by the type of descriptor.",
                    "label": 1
                },
                {
                    "sent": "Finally, you use for categorization.",
                    "label": 0
                },
                {
                    "sent": "For the same detector you changed the script or this is a combination of descriptors and.",
                    "label": 0
                },
                {
                    "sent": "This is the our performance is the performance of career in Dustin Gray level.",
                    "label": 0
                },
                {
                    "sent": "In that case.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, it is better our results back.",
                    "label": 0
                },
                {
                    "sent": "We are not investigated yet the.",
                    "label": 0
                },
                {
                    "sent": "The effect of finding the optimal set of features in a previous lecture I'll talk about how to find the optimal set of features.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here we are working now in use.",
                    "label": 0
                },
                {
                    "sent": "More rich, richer Gabor filter bank and then finding the features that add more discriminative, which will probably increase this.",
                    "label": 0
                },
                {
                    "sent": "You know, this difference between between multidimensional and low dimensional, a saliency",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the conclusion we propose a motivational salience method.",
                    "label": 1
                },
                {
                    "sent": "Applications for respect, perspective, image of the textual categorisation.",
                    "label": 0
                },
                {
                    "sent": "Kidney partition system estimators are very efficient.",
                    "label": 1
                },
                {
                    "sent": "And also so precise, but it is enough for for this task at least have to be aware that the number of entropy picks decreases when increasing the dimensions.",
                    "label": 1
                },
                {
                    "sent": "So you have to make to improve that in terms of adapting also the scale.",
                    "label": 0
                },
                {
                    "sent": "But if you extend the scale you will have a computational problem.",
                    "label": 1
                },
                {
                    "sent": "So it's also convenient to find the optimal number of features if you if the performance is degrading with the number of features.",
                    "label": 1
                },
                {
                    "sent": "It should be good to have a good number of features.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that is the most informative one.",
                    "label": 0
                },
                {
                    "sent": "So this is the.",
                    "label": 0
                },
                {
                    "sent": "I work for the future so and that's all.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                },
                {
                    "sent": "The floor is open for one or more questions.",
                    "label": 0
                },
                {
                    "sent": "Well, I would like to know.",
                    "label": 0
                },
                {
                    "sent": "So I may be aware of the approach, but there's a saliency detection approach by Bruce and sort source.",
                    "label": 0
                },
                {
                    "sent": "While one trick they apply to overcome difficulties with higher dimensions is that they first try to do an ICA on the features, and then that they try to assume some sort of independence with something like this.",
                    "label": 1
                },
                {
                    "sent": "Also be helpful in your so that you then, separately.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yes, for sure you have to have to go to the features in advance.",
                    "label": 0
                },
                {
                    "sent": "You mean that?",
                    "label": 0
                },
                {
                    "sent": "But if you so if you would know what kind of if you would could assume some sort of independence between the features cultured and exploit that in making it making the estimate estimation more simple.",
                    "label": 0
                },
                {
                    "sent": "So then you only would maybe have to estimate the entropy in lower dimensions and so compile from that entropy is higher dimensions.",
                    "label": 0
                },
                {
                    "sent": "Something like that makes sense in your setting, or is it just not applicable?",
                    "label": 0
                },
                {
                    "sent": "Interesting, I don't know the approach about.",
                    "label": 0
                },
                {
                    "sent": "OK, OK, I can give you the review.",
                    "label": 0
                },
                {
                    "sent": "Russians from the audience.",
                    "label": 0
                },
                {
                    "sent": "Nobody, well, let's thank the speaker again.",
                    "label": 0
                }
            ]
        }
    }
}