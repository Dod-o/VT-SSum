{
    "id": "yp2fommng5njlzhkzeaveh7qhwqiavpd",
    "title": "Covariate Shift by Kernel Mean Matching",
    "info": {
        "author": [
            "Arthur Gretton, Centre for Computational Statistics and Machine Learning, University College London"
        ],
        "published": "Jan. 19, 2010",
        "recorded": "December 2009",
        "category": [
            "Top->Computer Science->Machine Learning->Structured Data"
        ]
    },
    "url": "http://videolectures.net/nipsworkshops09_gretton_cskm/",
    "segmentation": [
        [
            "Can approaches because.",
            "I also do structured data, so I think this is relevant.",
            "The talk will be more by nature.",
            "They toiled and somewhat informal.",
            "In particular, I'll talk about some things.",
            "From an earlier work I did in fact discussed in another.",
            "Subsequent to our paper on this.",
            "And in particular some findings about."
        ],
        [
            "Festival guests able to.",
            "We have a input system in a pattern which makes something like ideal might be something like.",
            "We have a training set which we receive.",
            "NPR is right here.",
            "I'ma need that attributed according to a.",
            "And likewise.",
            "And now go.",
            "Training distribution might be when the users my focus to test one when the user is messed up.",
            "Gene expression profiles.",
            "We might want to use a classifier.",
            "Provided with one another in this case.",
            "Again, differences in the procedure might mean.",
            "So this is just sort of, yeah.",
            "Examples of.",
            "Convention.",
            "A person question to ask is, does it make sense?"
        ],
        [
            "This is actually not.",
            "An unreasonable question in the sense that if you have two completely unlike distributions, then learning from one Microsoft you nothing about the other.",
            "I'm going to reduce my rate."
        ],
        [
            "Nicola headset any problem?",
            "For which additional dependent of the labels given the data remains unchanged, and the probability distributions of the patterns alone or another change.",
            "And this is the setting of."
        ],
        [
            "So classic examples.",
            "Went by there 1000.",
            "You're appending distribution.",
            "In this case is a Gaussian of a high variance.",
            "Well, that's right.",
            "A label, in this case of your values there is function, polynomial function of input.",
            "An update by Grace that is annoying.",
            "The.",
            "We are doing here.",
            "It is linear regression to making prediction of Y given."
        ],
        [
            "So here is the painting and test data.",
            "The technique.",
            "Lucian if we were tentative.",
            "I'm painting and test it out.",
            "We can see this in 950 on the training data is a portrait."
        ],
        [
            "I'll be test prediction and so you might think that you can do better than this because you know actually where the data are.",
            "You should be able to predict.",
            "So this is."
        ],
        [
            "Example for now.",
            "About the set up.",
            "So in practical learning what you might want to do is to minimize a regularizer connected with.",
            "Which I have yeah.",
            "Two times the expectation of sunblock.",
            "I regularising help.",
            "So the last time, yeah, might be something like a log likelihood.",
            "Either parameter parameter where optimizing over so this could be the parameter of the models.",
            "I could be the direction you project on it and support vector machine and so on, and you're tasked with minimizing the expression in math."
        ],
        [
            "In the very setting, as I said, you have a pair of distribution rather than a single one.",
            "So you're starting with a distribution.",
            "You're trying to minimize the major, right?",
            "You expressed it as a dumb.",
            "But then we want to replace the expectation over the test distribution with an expectation over the.",
            "We waited for the painting and somehow rating data is going to allow us to recover this.",
            "There's a way."
        ],
        [
            "We do this.",
            "This is actually very straightforward simple algebra.",
            "You get the correct way to use it.",
            "You get exactly.",
            "So this.",
            "Which seems to help the problem.",
            "I've open there in mind.",
            "Happy denominated in the numerator 0.",
            "Sing on this condition here with David, wherever the.",
            "Just distribution has support declining distribution.",
            "So that."
        ],
        [
            "So where you get problems might arise in practice.",
            "Can be seen when you look at the variance of this expression.",
            "And so here I've written the variance of the last function related by the ratio of the testis training and distribution.",
            "I expected that out.",
            "Vacation.",
            "I."
        ],
        [
            "In expectation of the last function.",
            "Type my despacio yeah.",
            "So in the West."
        ],
        [
            "ID.",
            "Then you're very nice.",
            "Rises processes largest ratio of the tester training distribution.",
            "And if you think about it, this makes sense, because if you're training distribution has over to support in the event distribution, then quite likely this event.",
            "Hi.",
            "So when you.",
            "Or when when should have at least obtaining distribution?"
        ],
        [
            "Appointment in this case I'm just driving in very general terms.",
            "So what did you have in mind?",
            "Oh yeah, yeah, absolutely.",
            "OK, you know it's in a couple of slides.",
            "Yeah.",
            "Um?",
            "So OK, the next slide is just given these.",
            "Wait how do you go about scoping?",
            "Um?"
        ],
        [
            "So the example I used yeah is kind of recognition.",
            "So assuming that somehow or other you have access to the correct solution, correct?",
            "Important place you want to know.",
            "These weights in that problem.",
            "So yeah, yeah.",
            "So why yeah?",
            "Which is your prediction?",
            "This is some feature of your input.",
            "Can you talk more about that later?"
        ],
        [
            "Minimize this expression.",
            "Here you have again regularization term.",
            "Here we have the weight which we've been given.",
            "And you can see the victim out to in amazing this following expression.",
            "K meeting is amazing.",
            "Connected the difference with respect to standard Ridge regression is that you now have these leaders basically diagonal matrix in the middle of your inner product yet, but you can see that everything follows through and.",
            "Again, I will protect the machines with many learning methods.",
            "Be waiting in this way is just a simple result problems that you can solve as easily."
        ],
        [
            "So in the example and the trade up with the V team, if we use the correct training ratio, you can see that the prediction of the test data has improved.",
            "In this case closest to the idea living with one.",
            "Prediction paint on their distribution."
        ],
        [
            "OK, so I didn't look it up.",
            "If you're using density estimation to try and get this ratio, you're gonna run into trouble, so there are a few reasons.",
            "When the workshop is about complex instruction data might be possible even to meaningfully define distributions over, for instance, graft or things of that one.",
            "Higher because.",
            "Audi distributions on that domain and not well understood.",
            "Another issue that arises is even if you do have a means of finding density estimate.",
            "Window estimate.",
            "You can end up with very high variance.",
            "So again, going back a couple of sites.",
            "Do you remember this is this capital D parameter, which depends on the ratio of the training?",
            "If you are empirical estimate for whatever reason, it makes that major large, then you could have a terribly hydrant.",
            "But you might also have variances because of the nature of the problem, because the training in his introductions at somewhat far away.",
            "So the ratio just because there's nothing you can do about it."
        ],
        [
            "So there are a number of other ways that people go about computing this ratio in a sort of indirectly.",
            "And the advantages of these.",
            "Each of them told the problem, which I did certain conditions will converge eventually to the right ratio.",
            "Of course, assuming that.",
            "Problems were able to paint it another way.",
            "But they basically make different regularising assumption that my team is that the estimate of the ratio, even though it might not be as immediate.",
            "Might have various properties might have fired, which is.",
            "I have much reduces variance.",
            "The estimate that you get when you've done on the freeway today.",
            "So just to go down to this.",
            "1.",
            "Did you actually?",
            "And as a byproduct of that, you get an answer that isn't ratio.",
            "Another way is to minimize the KL divergent between training and test.",
            "That was done my Yama.",
            "Another way I minimize two norm of the difference between the testing ratio added value.",
            "That's kind of worrying health.",
            "These ones I won't talk about too much.",
            "He message that I'll focus on.",
            "If you think a measure of distance between distribution mappings closing maximum these discrepancies.",
            "So this is defined on features of the distribution.",
            "I am a reproducing kernel Hilbert space and its advantages that it can be applied on the data.",
            "Dad please."
        ],
        [
            "So to describe how we do.",
            "Using.",
            "I need this done by describing the next."
        ],
        [
            "Service is a.",
            "Well, this one is actually a very old.",
            "Defining differences on distribution.",
            "Look at the ever a set of witness function.",
            "I hope the difference in expectations.",
            "So this is a nice illustration here.",
            "When you have a Gaussian in laptop.",
            "You have a witness function F. And you can see that it has a large amplitude where the difference in probability Massachusetts allusion is large.",
            "Yeah.",
            "OK I have it.",
            "But you can see that this is a function that would make.",
            "Lunch."
        ],
        [
            "So now I have defining this function.",
            "So what we might want to do is find a custom function such that this quantity here is a metric.",
            "Today very classical problem.",
            "There are many solutions to it.",
            "I've listed a few hears about it functions, functions of bounded variation, which metric election function, which give you the approval popular.",
            "And then all of these rich enough.",
            "So that means it 0 only went in to coincide.",
            "Oh"
        ],
        [
            "I mean, this is what she meant for the purposes of.",
            "Have changing like.",
            "Yeah, for the purposes of comparing distributions, you might actually.",
            "Loaded.",
            "One can impose conditions for it, but.",
            "One knows something about the cost.",
            "Yeah.",
            "It is a metric on the characteristic.",
            "I can extend it.",
            "I have some company tonight.",
            "Time for them by the end of the talk.",
            "For the moment, I'll just say that they're not.",
            "So OK.",
            "So using a Gaussian kernel will cause this."
        ],
        [
            "So I talked about beautiful tonight.",
            "So for this I'm gonna 50 to find some Hilbert space, knology, so that's what I'm gonna stay on the next time next time.",
            "The reproducing kernel Hilbert spaces at this place is a function that can be written in this book.",
            "Basically, linear combinations of positive definite kernel function and the limits of these sequences reproducing kernel."
        ],
        [
            "Now, the positive definite kernel is an inner product between each of those coming back to this idea.",
            "That is regression."
        ],
        [
            "And in particular.",
            "I can't function at X.",
            "Shut up.",
            "So these are my locations that I'm going to be using."
        ],
        [
            "So we find.",
            "P&Q expectations.",
            "Then we make the following replacement.",
            "The expectation of F inner product feature map index.",
            "We then take the expectation of this feature.",
            "I think about this time it's a feature map of the distribution team.",
            "So just if we invented a point in an arcade.",
            "Our Hostess tradition.",
            "New event.",
            "And that's something you detect now."
        ],
        [
            "Have connected F. Now we."
        ],
        [
            "Find F to be a unit all in the reproducing kernel Hilbert space.",
            "What this means is that we can replace over this unit hold.",
            "As just a note.",
            "Now the norm of the differences mean.",
            "And."
        ],
        [
            "Then you can extend it, no doubt, and the inner product and then make a reverse argument that the inner product of UX and UX is the expectation of the inner product feature Maps event.",
            "And the inner product key of X.",
            "We have a simple expression in terms of kernel function of the distance between P&Q.",
            "So."
        ],
        [
            "Just to I guess we calculate the feature map.",
            "The expectation of the.",
            "The distribution is the implementation of the feature map of a point.",
            "You can also think of it as a convolution of signals.",
            "So this is how we represent distributions in me.",
            "I can't get.",
            "The difference between these representations is the maximum."
        ],
        [
            "So it's fine now measure distance between distributions that I'm going to use.",
            "After now how do you do covariant shift using this?"
        ],
        [
            "The algorithm I'm going to use is going to be called tunneling matching."
        ],
        [
            "For the following reason, what you want to do?",
            "Anyway, your training.",
            "Back such a way.",
            "Sending message so if you can do that, then you're making the representations of the distributions in a new producing kernel Hilbert space.",
            "And it is like a way of doing this, be waiting.",
            "So the change that we put here I just to ensure that this is a legitimate backing up a probability distribution.",
            "Now, if the only characteristic.",
            "And if he would have the testing solution is contained in this part of the training distribution, then the solution of this optimization problem is just it.",
            "You get back doing something great, which as we defined, if you'd like to go are the best.",
            "Population.",
            "So what about non characteristic?"
        ],
        [
            "So.",
            "Again, you.",
            "Might wish well.",
            "One of which is that they might not.",
            "So characteristic panels on graph.",
            "Computationally too expensive.",
            "Another reason you might not want to it because you might not care about asking distributions, but you might care only about matching certain moments of the distribution.",
            "So for instance.",
            "If you use it, your classifier that you were going to use relied only on the 1st 3 minutes, then it doesn't make sense to match or to try to match distributions using a general metric.",
            "So basically, yeah, if you consider some classes of distribution.",
            "It would make more sense to choose a feature space which concentrates on those properties and sometimes is not a general."
        ],
        [
            "So apparently this problem can be solved straightforwardly.",
            "I paint clear the population expectations.",
            "Head.",
            "I computed with solution here is to be weighted painting, minimizing the distance.",
            "Quadratic function here.",
            "Type terms are not important."
        ],
        [
            "Readily.",
            "Since the first of all we know the ratio of distributions is on some interval.",
            "Obviously, 0 ND largest saturation and capital D. Now we also have this constraint.",
            "Changes that somewhat with activation of that one.",
            "Where we allow a little bit of pain around the eatery."
        ],
        [
            "The reason that we did that is because if we were given.",
            "The important sampling ratios is something.",
            "Then the sample distance between Trump and his target isn't like.",
            "Yeah, this time doesn't change the target perfectly distributed around the timing acting normal way so it doesn't make sense to include exactly, but I need to import it with increasing precision as you see more samples."
        ],
        [
            "OK, so I've described away distribution.",
            "If you remember from the important something we ran into this.",
            "Difficulties in the variance depends on the legislation of the tests to training distribution.",
            "So again, I'm going to sit here and we run into the same problem as you would expect when you're using this mean matching procedure instead."
        ],
        [
            "So I will give an incorrect put in something data comes to you and sleep.",
            "Then the distance computed empirically between the reweighting training map and the head snap.",
            "I had this down here.",
            "So it converging to 0, but converting it to read.",
            "The important thing to note here is Capital D time comes back again.",
            "So again, if your test distribution is very different from obtaining distribution then even though this converges, it rates one and then it might converge from somewhere very far away from where you would like it to be.",
            "I'm going to just make an inside here.",
            "Have shown convergence of the kernel.",
            "We must be weighted painting etc.",
            "To the expected list on the test distribution.",
            "I mean it.",
            "Oh I.",
            "It might be nothing, but when actually.",
            "No, no I don't.",
            "I mean I should check that I."
        ],
        [
            "So here is again now example.",
            "We have these tests and training distribution when trying to fit line to this code."
        ],
        [
            "For these data you have the kind of matching result is actually pretty good.",
            "We also run."
        ],
        [
            "Anytime.",
            "So here you can see the text chain ratio compared to a couple of other methods that when it's kind of matching and money is a factor, invite someone direct.",
            "And this is basically showing that you're able to improve performance over the radio of accounting.",
            "Test this tradition if you're prepared to regularization initial compared to introduce a bit of clients.",
            "So this is, I think, an encouraging result."
        ],
        [
            "So I thought maybe about penalty making.",
            "I wanted this PC cover another.",
            "Another elegant way to solve this problem.",
            "So this is actually using a classifier.",
            "After getting wait.",
            "Are you playing a custom class?",
            "English training intensive.",
            "I didn't try to fix.",
            "You get wait with you.",
            "After this.",
            "A number of times.",
            "Isn't he?",
            "The distribution here.",
            "These variables already vector of variables, so you're testing training point which one where the training distribution is run from zero when the test.",
            "So the again, the reason why you might want to do this.",
            "Because you can then have to fight for exotic places.",
            "And get wait which you would otherwise have trouble getting.",
            "If you're trying to do the information."
        ],
        [
            "So here is how 1 yet.",
            "Meaning.",
            "After the pacifier.",
            "So this is the probability of England from the Planning Council given a turning point in giving the parameter theater, which you've done enough training test.",
            "So basically the.",
            "Eating here.",
            "Then you get to wait and then you plug those into your learning algorithm, which turns the tables of the pattern away from the exit.",
            "Yep, we're done.",
            "So he.",
            "People paper proposed a further extension to this weekend.",
            "Yeah, where they just make an enormous like model of everything that they pay.",
            "My model tells me first I choose something from the training over distribution and then I labeled accordingly.",
            "So actually.",
            "Unpin.",
            "Told me that he had some difficulties with this.",
            "So his difficulty was to cross annotate the plan.",
            "Yeah, we have parameters associated with the Gaussian.",
            "You need to actually see unable to example, which then makes the whole thing redundant.",
            "Another difficult music.",
            "This idea of like choosing randomly ending.",
            "To talk with, I think.",
            "Like not a satisfactory intuition for as a process by which converges because.",
            "But anyway, I guess.",
            "The argument for this message is that you can have joined me, learn the need is for the training and test distribution, and then potentially get stronger.",
            "By doing it.",
            "So I have some extended."
        ],
        [
            "The first one with."
        ],
        [
            "Thank you going to come much more details on the other.",
            "Discuss the data set.",
            "We're using a Gaussian kernel for both the kernel mean matching and for the support vector machines that we say.",
            "We did fixing the bandwidth is tired and we're going to show the function of the sea, so this is the thing that controls the tradeoff between lot regularization and as it up here at Smokey means that we prioritize.",
            "So the way that we generate update and this is an adaptation example, we have a native pool.",
            "We split it randomly containing.",
            "At the head.",
            "Training data set will be of different sizes 'cause I'm gonna see performance in the function of training size.",
            "And this is the distribution we choose from.",
            "So you're basically selecting randomly, probably probably full of data according to this bias."
        ],
        [
            "So first of all, the good results here for an OPI what we think.",
            "It's at the moment.",
            "Acute improvement that you get using kind of matching is very substantial.",
            "Here we have the average luck.",
            "You can see that across the board.",
            "If you pull up.",
            "The Gray one be important, something one is actually using the underlying through ratio.",
            "And you can see here.",
            "It shouldn't be surprising because the connection easier with tap in such a way as to pay the large ratio between training and test.",
            "So I having Unregularized expression is that ratio is going to give you.",
            "The distance for a very small thing, which means that we're actually prioritizing the smoothness of the classifier over the last."
        ],
        [
            "Now let's see what happens when we use a copy of validated.",
            "So in this case, you'll see that the kind of matching actually makes everything a big one.",
            "What interesting is that for a very small value of E?",
            "Have basically pushed down the error.",
            "Yeah.",
            "But if you would do well Tuesday, well.",
            "Carefully.",
            "You would end up with the right answer.",
            "So why is it not getting improvement?",
            "I'm in very light over there where we opened up for the.",
            "Where we waited by the underlying crew.",
            "Enter."
        ],
        [
            "Misha.",
            "So to give a intuition as to why this might be overturned to our 20 example again.",
            "This time, rather than eating goodnight, I'm sitting kind of Ridge regression.",
            "Here you can see that basically.",
            "This is following the curve everywhere, and so the only thing that you get if you take some subset of that pending data up weighted down when everything else is reduced.",
            "Sample space.",
            "You're actually not helping yourself at all.",
            "So the moral to this story, I think, is that if you have a probably faint and helpful learning method.",
            "Doubtful that you're gonna get.",
            "Competitive anytime.",
            "So.",
            "Using the waiting go yeah.",
            "Yep.",
            "Yeah, I mean, even in this one which was chosen."
        ],
        [
            "Pretty much at random, you can see actually there waiting making things but so yeah.",
            "So.",
            "I mean this."
        ],
        [
            "Experiment so we should never generalize from the sample datasets, and now I'm going to show a whole bunch of data set.",
            "So it's a mixture of regression and classification.",
            "Name is again.",
            "Enter data, we basically have a pool of gender.",
            "We sample comments with some quiet.",
            "Again, a Gaussian virus on it.",
            "One thing that we're doing, which might not be the best thing to do, is if we are using the same kernel size matching.",
            "So this might not be optimal.",
            "Right, so in all of these, yeah, all of these cases we generate the data by taking a full of data sub, something it randomly come by distribution that we have created.",
            "So this is an artificial benchmark.",
            "And then yeah.",
            "The other thing that we do is we go for the pragmatism, the progression of classification over them.",
            "We set a date on the unweighted data, so we can't sell it on the unweighted training set rather than the weighted one.",
            "So this is again something I'm going to return to, but this is Mike at this point already."
        ],
        [
            "But it needed.",
            "OK, so here a benchmark.",
            "So to guide you through the graph.",
            "And these are where."
        ],
        [
            "Either waiting or you coming provement.",
            "In some cases, in most cases will feel there's only one case.",
            "That doesn't happen.",
            "But that's something that like bragging."
        ],
        [
            "Select in some cases of both."
        ],
        [
            "Well.",
            "Yes, case where what is something is, is it?",
            "If it was the one here.",
            "Here's one.",
            "So basically what we've shown here is that, yeah, I mean the the results are very new.",
            "I think what's interesting is that.",
            "Phenomenon.",
            "When?"
        ],
        [
            "When were both work?",
            "So this seems to suggest looking at a couple of tipex then that if for whatever reason.",
            "You cross validated over 2 plus agreements or your learning algorithm is not the right one for that data.",
            "Then you're going to get an improvement using the waiting, even though if you were more careful in your collection algorithm or if you were more systematic in your consolidation, you would know.",
            "So this is.",
            "Awaited.",
            "So when."
        ],
        [
            "I get final foot.",
            "Fortunately, we didn't go very well.",
            "In our regional newspaper, is this model selection of the local variant?",
            "So we have a distance measure between distributions.",
            "Is this measure is a function of the kernel?",
            "So what that means?",
            "Is it for different kernels?",
            "And for when you use these, if you get performance.",
            "So here are a bunch of high dimensional datasets.",
            "What you should note here it will translate it from someone elses payment so you can come here in German.",
            "And 2nd that the moment does show a sort of optimum.",
            "And I think you know that this optimum matches the best performance that they.",
            "Terrorism which hasn't.",
            "So what this intervene is that again, if for whatever reason the weight doesn't work.",
            "You have to be very careful with kind of matching to choose a distance measure, which allows you to recover that be waiting.",
            "So this is something which I don't have a good answer for in the cases."
        ],
        [
            "Um?",
            "There have been.",
            "General Web contact on choosing parameters for different.",
            "Algorithm.",
            "When easy cases, if there is a systematic group in the data, which just means that you have like from past values and very very good idea.",
            "That makes it easy for you.",
            "Um?",
            "E. Hannah groups have been doing personalization on the left out couple to obtain the parameters for learning algorithm.",
            "Uh huh.",
            "The thing is they could have.",
            "It's like it's not just meditation.",
            "Necessarily a. Madison or it's it's it's A kind of it's a different.",
            "Way to do it.",
            "So basically they have their estimate of their mission and then they are using that they use this ratio.",
            "I did it.",
            "I did it to some other expression.",
            "But right exactly so this is different, right?",
            "This happens as well.",
            "Why did they do that?",
            "Um?",
            "In the main conference we talked about looking at the largest energy overhead external.",
            "Or perhaps.",
            "Other optimization over which Michael may not be wasted.",
            "This I don't know if it would be useful or not, but at least something.",
            "The last point, I think is quite an important one.",
            "So again, if you know something about your learning problem.",
            "For instance, that the learner user particular features of the distribution.",
            "Then you should use the teachers in matching your.",
            "Yeah, yeah, exactly.",
            "I mean, it's like you should concentrate on actually testing the teachers that you're going to use every feature you can get your hands on.",
            "So this is.",
            "Yeah, another quite important.",
            "Thanks very much.",
            "The other thing is you remember this when I did my cost allocation for the experiment.",
            "I was using consolidation only unweighted.",
            "It doesn't reduce the bias.",
            "But again, coming back to our example because we were using high powerful learning algorithms, yeah, it seems that becomes validation.",
            "They got under way to pretty much didn't change when we use the unweighted.",
            "Yeah, so that was."
        ],
        [
            "OK so summary.",
            "I think cloud the.",
            "Currently, matching allows you to do prevent without doing press.",
            "Contest distribution.",
            "Um, it allows you to match only particular features of the distribution, and so, for instance, unstructured domains like things after this might be an approach to use.",
            "Where the moment improve in output is very generic benchmark experiment.",
            "Mainly when the learning algorithm with symptoms in the data would work.",
            "So in this case you can get very big performance improvement and this almost has the favor of local learning and that you if you have any learning algorithm which is intended to when you should have.",
            "Then focusing in on your test data is gonna help you.",
            "If the learning algorithm is helpful, is it needs to be, then it might still be useful to do concurrent chips in the sense that it gives you a little bit more pain in your consolidation every waiting.",
            "Just because if you haven't consolidated company it, it might actually help you.",
            "Or if you're using an algorithm which is not completely.",
            "And model collection."
        ],
        [
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Can approaches because.",
                    "label": 0
                },
                {
                    "sent": "I also do structured data, so I think this is relevant.",
                    "label": 0
                },
                {
                    "sent": "The talk will be more by nature.",
                    "label": 0
                },
                {
                    "sent": "They toiled and somewhat informal.",
                    "label": 0
                },
                {
                    "sent": "In particular, I'll talk about some things.",
                    "label": 0
                },
                {
                    "sent": "From an earlier work I did in fact discussed in another.",
                    "label": 0
                },
                {
                    "sent": "Subsequent to our paper on this.",
                    "label": 0
                },
                {
                    "sent": "And in particular some findings about.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Festival guests able to.",
                    "label": 0
                },
                {
                    "sent": "We have a input system in a pattern which makes something like ideal might be something like.",
                    "label": 0
                },
                {
                    "sent": "We have a training set which we receive.",
                    "label": 0
                },
                {
                    "sent": "NPR is right here.",
                    "label": 0
                },
                {
                    "sent": "I'ma need that attributed according to a.",
                    "label": 0
                },
                {
                    "sent": "And likewise.",
                    "label": 0
                },
                {
                    "sent": "And now go.",
                    "label": 0
                },
                {
                    "sent": "Training distribution might be when the users my focus to test one when the user is messed up.",
                    "label": 0
                },
                {
                    "sent": "Gene expression profiles.",
                    "label": 0
                },
                {
                    "sent": "We might want to use a classifier.",
                    "label": 0
                },
                {
                    "sent": "Provided with one another in this case.",
                    "label": 0
                },
                {
                    "sent": "Again, differences in the procedure might mean.",
                    "label": 0
                },
                {
                    "sent": "So this is just sort of, yeah.",
                    "label": 0
                },
                {
                    "sent": "Examples of.",
                    "label": 0
                },
                {
                    "sent": "Convention.",
                    "label": 0
                },
                {
                    "sent": "A person question to ask is, does it make sense?",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is actually not.",
                    "label": 0
                },
                {
                    "sent": "An unreasonable question in the sense that if you have two completely unlike distributions, then learning from one Microsoft you nothing about the other.",
                    "label": 0
                },
                {
                    "sent": "I'm going to reduce my rate.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Nicola headset any problem?",
                    "label": 0
                },
                {
                    "sent": "For which additional dependent of the labels given the data remains unchanged, and the probability distributions of the patterns alone or another change.",
                    "label": 0
                },
                {
                    "sent": "And this is the setting of.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So classic examples.",
                    "label": 0
                },
                {
                    "sent": "Went by there 1000.",
                    "label": 0
                },
                {
                    "sent": "You're appending distribution.",
                    "label": 0
                },
                {
                    "sent": "In this case is a Gaussian of a high variance.",
                    "label": 0
                },
                {
                    "sent": "Well, that's right.",
                    "label": 0
                },
                {
                    "sent": "A label, in this case of your values there is function, polynomial function of input.",
                    "label": 0
                },
                {
                    "sent": "An update by Grace that is annoying.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "We are doing here.",
                    "label": 0
                },
                {
                    "sent": "It is linear regression to making prediction of Y given.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here is the painting and test data.",
                    "label": 0
                },
                {
                    "sent": "The technique.",
                    "label": 0
                },
                {
                    "sent": "Lucian if we were tentative.",
                    "label": 0
                },
                {
                    "sent": "I'm painting and test it out.",
                    "label": 0
                },
                {
                    "sent": "We can see this in 950 on the training data is a portrait.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'll be test prediction and so you might think that you can do better than this because you know actually where the data are.",
                    "label": 0
                },
                {
                    "sent": "You should be able to predict.",
                    "label": 0
                },
                {
                    "sent": "So this is.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Example for now.",
                    "label": 0
                },
                {
                    "sent": "About the set up.",
                    "label": 0
                },
                {
                    "sent": "So in practical learning what you might want to do is to minimize a regularizer connected with.",
                    "label": 0
                },
                {
                    "sent": "Which I have yeah.",
                    "label": 0
                },
                {
                    "sent": "Two times the expectation of sunblock.",
                    "label": 0
                },
                {
                    "sent": "I regularising help.",
                    "label": 0
                },
                {
                    "sent": "So the last time, yeah, might be something like a log likelihood.",
                    "label": 0
                },
                {
                    "sent": "Either parameter parameter where optimizing over so this could be the parameter of the models.",
                    "label": 0
                },
                {
                    "sent": "I could be the direction you project on it and support vector machine and so on, and you're tasked with minimizing the expression in math.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the very setting, as I said, you have a pair of distribution rather than a single one.",
                    "label": 0
                },
                {
                    "sent": "So you're starting with a distribution.",
                    "label": 0
                },
                {
                    "sent": "You're trying to minimize the major, right?",
                    "label": 0
                },
                {
                    "sent": "You expressed it as a dumb.",
                    "label": 0
                },
                {
                    "sent": "But then we want to replace the expectation over the test distribution with an expectation over the.",
                    "label": 0
                },
                {
                    "sent": "We waited for the painting and somehow rating data is going to allow us to recover this.",
                    "label": 0
                },
                {
                    "sent": "There's a way.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We do this.",
                    "label": 0
                },
                {
                    "sent": "This is actually very straightforward simple algebra.",
                    "label": 0
                },
                {
                    "sent": "You get the correct way to use it.",
                    "label": 0
                },
                {
                    "sent": "You get exactly.",
                    "label": 0
                },
                {
                    "sent": "So this.",
                    "label": 0
                },
                {
                    "sent": "Which seems to help the problem.",
                    "label": 0
                },
                {
                    "sent": "I've open there in mind.",
                    "label": 0
                },
                {
                    "sent": "Happy denominated in the numerator 0.",
                    "label": 0
                },
                {
                    "sent": "Sing on this condition here with David, wherever the.",
                    "label": 0
                },
                {
                    "sent": "Just distribution has support declining distribution.",
                    "label": 0
                },
                {
                    "sent": "So that.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So where you get problems might arise in practice.",
                    "label": 0
                },
                {
                    "sent": "Can be seen when you look at the variance of this expression.",
                    "label": 1
                },
                {
                    "sent": "And so here I've written the variance of the last function related by the ratio of the testis training and distribution.",
                    "label": 0
                },
                {
                    "sent": "I expected that out.",
                    "label": 0
                },
                {
                    "sent": "Vacation.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In expectation of the last function.",
                    "label": 0
                },
                {
                    "sent": "Type my despacio yeah.",
                    "label": 0
                },
                {
                    "sent": "So in the West.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "ID.",
                    "label": 0
                },
                {
                    "sent": "Then you're very nice.",
                    "label": 0
                },
                {
                    "sent": "Rises processes largest ratio of the tester training distribution.",
                    "label": 0
                },
                {
                    "sent": "And if you think about it, this makes sense, because if you're training distribution has over to support in the event distribution, then quite likely this event.",
                    "label": 0
                },
                {
                    "sent": "Hi.",
                    "label": 0
                },
                {
                    "sent": "So when you.",
                    "label": 0
                },
                {
                    "sent": "Or when when should have at least obtaining distribution?",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Appointment in this case I'm just driving in very general terms.",
                    "label": 0
                },
                {
                    "sent": "So what did you have in mind?",
                    "label": 0
                },
                {
                    "sent": "Oh yeah, yeah, absolutely.",
                    "label": 0
                },
                {
                    "sent": "OK, you know it's in a couple of slides.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So OK, the next slide is just given these.",
                    "label": 0
                },
                {
                    "sent": "Wait how do you go about scoping?",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the example I used yeah is kind of recognition.",
                    "label": 0
                },
                {
                    "sent": "So assuming that somehow or other you have access to the correct solution, correct?",
                    "label": 0
                },
                {
                    "sent": "Important place you want to know.",
                    "label": 0
                },
                {
                    "sent": "These weights in that problem.",
                    "label": 0
                },
                {
                    "sent": "So yeah, yeah.",
                    "label": 0
                },
                {
                    "sent": "So why yeah?",
                    "label": 0
                },
                {
                    "sent": "Which is your prediction?",
                    "label": 0
                },
                {
                    "sent": "This is some feature of your input.",
                    "label": 0
                },
                {
                    "sent": "Can you talk more about that later?",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Minimize this expression.",
                    "label": 0
                },
                {
                    "sent": "Here you have again regularization term.",
                    "label": 0
                },
                {
                    "sent": "Here we have the weight which we've been given.",
                    "label": 0
                },
                {
                    "sent": "And you can see the victim out to in amazing this following expression.",
                    "label": 0
                },
                {
                    "sent": "K meeting is amazing.",
                    "label": 0
                },
                {
                    "sent": "Connected the difference with respect to standard Ridge regression is that you now have these leaders basically diagonal matrix in the middle of your inner product yet, but you can see that everything follows through and.",
                    "label": 0
                },
                {
                    "sent": "Again, I will protect the machines with many learning methods.",
                    "label": 0
                },
                {
                    "sent": "Be waiting in this way is just a simple result problems that you can solve as easily.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in the example and the trade up with the V team, if we use the correct training ratio, you can see that the prediction of the test data has improved.",
                    "label": 0
                },
                {
                    "sent": "In this case closest to the idea living with one.",
                    "label": 0
                },
                {
                    "sent": "Prediction paint on their distribution.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so I didn't look it up.",
                    "label": 0
                },
                {
                    "sent": "If you're using density estimation to try and get this ratio, you're gonna run into trouble, so there are a few reasons.",
                    "label": 0
                },
                {
                    "sent": "When the workshop is about complex instruction data might be possible even to meaningfully define distributions over, for instance, graft or things of that one.",
                    "label": 0
                },
                {
                    "sent": "Higher because.",
                    "label": 0
                },
                {
                    "sent": "Audi distributions on that domain and not well understood.",
                    "label": 0
                },
                {
                    "sent": "Another issue that arises is even if you do have a means of finding density estimate.",
                    "label": 0
                },
                {
                    "sent": "Window estimate.",
                    "label": 0
                },
                {
                    "sent": "You can end up with very high variance.",
                    "label": 0
                },
                {
                    "sent": "So again, going back a couple of sites.",
                    "label": 0
                },
                {
                    "sent": "Do you remember this is this capital D parameter, which depends on the ratio of the training?",
                    "label": 0
                },
                {
                    "sent": "If you are empirical estimate for whatever reason, it makes that major large, then you could have a terribly hydrant.",
                    "label": 0
                },
                {
                    "sent": "But you might also have variances because of the nature of the problem, because the training in his introductions at somewhat far away.",
                    "label": 0
                },
                {
                    "sent": "So the ratio just because there's nothing you can do about it.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So there are a number of other ways that people go about computing this ratio in a sort of indirectly.",
                    "label": 0
                },
                {
                    "sent": "And the advantages of these.",
                    "label": 0
                },
                {
                    "sent": "Each of them told the problem, which I did certain conditions will converge eventually to the right ratio.",
                    "label": 0
                },
                {
                    "sent": "Of course, assuming that.",
                    "label": 0
                },
                {
                    "sent": "Problems were able to paint it another way.",
                    "label": 0
                },
                {
                    "sent": "But they basically make different regularising assumption that my team is that the estimate of the ratio, even though it might not be as immediate.",
                    "label": 0
                },
                {
                    "sent": "Might have various properties might have fired, which is.",
                    "label": 0
                },
                {
                    "sent": "I have much reduces variance.",
                    "label": 0
                },
                {
                    "sent": "The estimate that you get when you've done on the freeway today.",
                    "label": 0
                },
                {
                    "sent": "So just to go down to this.",
                    "label": 0
                },
                {
                    "sent": "1.",
                    "label": 0
                },
                {
                    "sent": "Did you actually?",
                    "label": 0
                },
                {
                    "sent": "And as a byproduct of that, you get an answer that isn't ratio.",
                    "label": 0
                },
                {
                    "sent": "Another way is to minimize the KL divergent between training and test.",
                    "label": 0
                },
                {
                    "sent": "That was done my Yama.",
                    "label": 0
                },
                {
                    "sent": "Another way I minimize two norm of the difference between the testing ratio added value.",
                    "label": 0
                },
                {
                    "sent": "That's kind of worrying health.",
                    "label": 0
                },
                {
                    "sent": "These ones I won't talk about too much.",
                    "label": 0
                },
                {
                    "sent": "He message that I'll focus on.",
                    "label": 0
                },
                {
                    "sent": "If you think a measure of distance between distribution mappings closing maximum these discrepancies.",
                    "label": 0
                },
                {
                    "sent": "So this is defined on features of the distribution.",
                    "label": 0
                },
                {
                    "sent": "I am a reproducing kernel Hilbert space and its advantages that it can be applied on the data.",
                    "label": 0
                },
                {
                    "sent": "Dad please.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So to describe how we do.",
                    "label": 0
                },
                {
                    "sent": "Using.",
                    "label": 0
                },
                {
                    "sent": "I need this done by describing the next.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Service is a.",
                    "label": 0
                },
                {
                    "sent": "Well, this one is actually a very old.",
                    "label": 0
                },
                {
                    "sent": "Defining differences on distribution.",
                    "label": 0
                },
                {
                    "sent": "Look at the ever a set of witness function.",
                    "label": 0
                },
                {
                    "sent": "I hope the difference in expectations.",
                    "label": 0
                },
                {
                    "sent": "So this is a nice illustration here.",
                    "label": 0
                },
                {
                    "sent": "When you have a Gaussian in laptop.",
                    "label": 0
                },
                {
                    "sent": "You have a witness function F. And you can see that it has a large amplitude where the difference in probability Massachusetts allusion is large.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "OK I have it.",
                    "label": 0
                },
                {
                    "sent": "But you can see that this is a function that would make.",
                    "label": 0
                },
                {
                    "sent": "Lunch.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now I have defining this function.",
                    "label": 0
                },
                {
                    "sent": "So what we might want to do is find a custom function such that this quantity here is a metric.",
                    "label": 0
                },
                {
                    "sent": "Today very classical problem.",
                    "label": 0
                },
                {
                    "sent": "There are many solutions to it.",
                    "label": 0
                },
                {
                    "sent": "I've listed a few hears about it functions, functions of bounded variation, which metric election function, which give you the approval popular.",
                    "label": 0
                },
                {
                    "sent": "And then all of these rich enough.",
                    "label": 0
                },
                {
                    "sent": "So that means it 0 only went in to coincide.",
                    "label": 0
                },
                {
                    "sent": "Oh",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I mean, this is what she meant for the purposes of.",
                    "label": 0
                },
                {
                    "sent": "Have changing like.",
                    "label": 0
                },
                {
                    "sent": "Yeah, for the purposes of comparing distributions, you might actually.",
                    "label": 0
                },
                {
                    "sent": "Loaded.",
                    "label": 0
                },
                {
                    "sent": "One can impose conditions for it, but.",
                    "label": 0
                },
                {
                    "sent": "One knows something about the cost.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "It is a metric on the characteristic.",
                    "label": 0
                },
                {
                    "sent": "I can extend it.",
                    "label": 0
                },
                {
                    "sent": "I have some company tonight.",
                    "label": 0
                },
                {
                    "sent": "Time for them by the end of the talk.",
                    "label": 0
                },
                {
                    "sent": "For the moment, I'll just say that they're not.",
                    "label": 0
                },
                {
                    "sent": "So OK.",
                    "label": 0
                },
                {
                    "sent": "So using a Gaussian kernel will cause this.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I talked about beautiful tonight.",
                    "label": 0
                },
                {
                    "sent": "So for this I'm gonna 50 to find some Hilbert space, knology, so that's what I'm gonna stay on the next time next time.",
                    "label": 0
                },
                {
                    "sent": "The reproducing kernel Hilbert spaces at this place is a function that can be written in this book.",
                    "label": 0
                },
                {
                    "sent": "Basically, linear combinations of positive definite kernel function and the limits of these sequences reproducing kernel.",
                    "label": 1
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now, the positive definite kernel is an inner product between each of those coming back to this idea.",
                    "label": 0
                },
                {
                    "sent": "That is regression.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in particular.",
                    "label": 0
                },
                {
                    "sent": "I can't function at X.",
                    "label": 0
                },
                {
                    "sent": "Shut up.",
                    "label": 0
                },
                {
                    "sent": "So these are my locations that I'm going to be using.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we find.",
                    "label": 0
                },
                {
                    "sent": "P&Q expectations.",
                    "label": 0
                },
                {
                    "sent": "Then we make the following replacement.",
                    "label": 0
                },
                {
                    "sent": "The expectation of F inner product feature map index.",
                    "label": 0
                },
                {
                    "sent": "We then take the expectation of this feature.",
                    "label": 0
                },
                {
                    "sent": "I think about this time it's a feature map of the distribution team.",
                    "label": 0
                },
                {
                    "sent": "So just if we invented a point in an arcade.",
                    "label": 0
                },
                {
                    "sent": "Our Hostess tradition.",
                    "label": 0
                },
                {
                    "sent": "New event.",
                    "label": 0
                },
                {
                    "sent": "And that's something you detect now.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Have connected F. Now we.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Find F to be a unit all in the reproducing kernel Hilbert space.",
                    "label": 0
                },
                {
                    "sent": "What this means is that we can replace over this unit hold.",
                    "label": 0
                },
                {
                    "sent": "As just a note.",
                    "label": 0
                },
                {
                    "sent": "Now the norm of the differences mean.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then you can extend it, no doubt, and the inner product and then make a reverse argument that the inner product of UX and UX is the expectation of the inner product feature Maps event.",
                    "label": 0
                },
                {
                    "sent": "And the inner product key of X.",
                    "label": 0
                },
                {
                    "sent": "We have a simple expression in terms of kernel function of the distance between P&Q.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just to I guess we calculate the feature map.",
                    "label": 0
                },
                {
                    "sent": "The expectation of the.",
                    "label": 0
                },
                {
                    "sent": "The distribution is the implementation of the feature map of a point.",
                    "label": 0
                },
                {
                    "sent": "You can also think of it as a convolution of signals.",
                    "label": 0
                },
                {
                    "sent": "So this is how we represent distributions in me.",
                    "label": 0
                },
                {
                    "sent": "I can't get.",
                    "label": 0
                },
                {
                    "sent": "The difference between these representations is the maximum.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So it's fine now measure distance between distributions that I'm going to use.",
                    "label": 0
                },
                {
                    "sent": "After now how do you do covariant shift using this?",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The algorithm I'm going to use is going to be called tunneling matching.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For the following reason, what you want to do?",
                    "label": 0
                },
                {
                    "sent": "Anyway, your training.",
                    "label": 0
                },
                {
                    "sent": "Back such a way.",
                    "label": 0
                },
                {
                    "sent": "Sending message so if you can do that, then you're making the representations of the distributions in a new producing kernel Hilbert space.",
                    "label": 0
                },
                {
                    "sent": "And it is like a way of doing this, be waiting.",
                    "label": 0
                },
                {
                    "sent": "So the change that we put here I just to ensure that this is a legitimate backing up a probability distribution.",
                    "label": 0
                },
                {
                    "sent": "Now, if the only characteristic.",
                    "label": 0
                },
                {
                    "sent": "And if he would have the testing solution is contained in this part of the training distribution, then the solution of this optimization problem is just it.",
                    "label": 0
                },
                {
                    "sent": "You get back doing something great, which as we defined, if you'd like to go are the best.",
                    "label": 0
                },
                {
                    "sent": "Population.",
                    "label": 0
                },
                {
                    "sent": "So what about non characteristic?",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Again, you.",
                    "label": 0
                },
                {
                    "sent": "Might wish well.",
                    "label": 0
                },
                {
                    "sent": "One of which is that they might not.",
                    "label": 0
                },
                {
                    "sent": "So characteristic panels on graph.",
                    "label": 0
                },
                {
                    "sent": "Computationally too expensive.",
                    "label": 0
                },
                {
                    "sent": "Another reason you might not want to it because you might not care about asking distributions, but you might care only about matching certain moments of the distribution.",
                    "label": 0
                },
                {
                    "sent": "So for instance.",
                    "label": 0
                },
                {
                    "sent": "If you use it, your classifier that you were going to use relied only on the 1st 3 minutes, then it doesn't make sense to match or to try to match distributions using a general metric.",
                    "label": 0
                },
                {
                    "sent": "So basically, yeah, if you consider some classes of distribution.",
                    "label": 0
                },
                {
                    "sent": "It would make more sense to choose a feature space which concentrates on those properties and sometimes is not a general.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So apparently this problem can be solved straightforwardly.",
                    "label": 0
                },
                {
                    "sent": "I paint clear the population expectations.",
                    "label": 0
                },
                {
                    "sent": "Head.",
                    "label": 0
                },
                {
                    "sent": "I computed with solution here is to be weighted painting, minimizing the distance.",
                    "label": 0
                },
                {
                    "sent": "Quadratic function here.",
                    "label": 0
                },
                {
                    "sent": "Type terms are not important.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Readily.",
                    "label": 0
                },
                {
                    "sent": "Since the first of all we know the ratio of distributions is on some interval.",
                    "label": 0
                },
                {
                    "sent": "Obviously, 0 ND largest saturation and capital D. Now we also have this constraint.",
                    "label": 0
                },
                {
                    "sent": "Changes that somewhat with activation of that one.",
                    "label": 0
                },
                {
                    "sent": "Where we allow a little bit of pain around the eatery.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The reason that we did that is because if we were given.",
                    "label": 0
                },
                {
                    "sent": "The important sampling ratios is something.",
                    "label": 0
                },
                {
                    "sent": "Then the sample distance between Trump and his target isn't like.",
                    "label": 0
                },
                {
                    "sent": "Yeah, this time doesn't change the target perfectly distributed around the timing acting normal way so it doesn't make sense to include exactly, but I need to import it with increasing precision as you see more samples.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so I've described away distribution.",
                    "label": 0
                },
                {
                    "sent": "If you remember from the important something we ran into this.",
                    "label": 0
                },
                {
                    "sent": "Difficulties in the variance depends on the legislation of the tests to training distribution.",
                    "label": 0
                },
                {
                    "sent": "So again, I'm going to sit here and we run into the same problem as you would expect when you're using this mean matching procedure instead.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I will give an incorrect put in something data comes to you and sleep.",
                    "label": 0
                },
                {
                    "sent": "Then the distance computed empirically between the reweighting training map and the head snap.",
                    "label": 0
                },
                {
                    "sent": "I had this down here.",
                    "label": 0
                },
                {
                    "sent": "So it converging to 0, but converting it to read.",
                    "label": 0
                },
                {
                    "sent": "The important thing to note here is Capital D time comes back again.",
                    "label": 0
                },
                {
                    "sent": "So again, if your test distribution is very different from obtaining distribution then even though this converges, it rates one and then it might converge from somewhere very far away from where you would like it to be.",
                    "label": 0
                },
                {
                    "sent": "I'm going to just make an inside here.",
                    "label": 0
                },
                {
                    "sent": "Have shown convergence of the kernel.",
                    "label": 0
                },
                {
                    "sent": "We must be weighted painting etc.",
                    "label": 0
                },
                {
                    "sent": "To the expected list on the test distribution.",
                    "label": 0
                },
                {
                    "sent": "I mean it.",
                    "label": 0
                },
                {
                    "sent": "Oh I.",
                    "label": 0
                },
                {
                    "sent": "It might be nothing, but when actually.",
                    "label": 0
                },
                {
                    "sent": "No, no I don't.",
                    "label": 0
                },
                {
                    "sent": "I mean I should check that I.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here is again now example.",
                    "label": 0
                },
                {
                    "sent": "We have these tests and training distribution when trying to fit line to this code.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For these data you have the kind of matching result is actually pretty good.",
                    "label": 0
                },
                {
                    "sent": "We also run.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Anytime.",
                    "label": 0
                },
                {
                    "sent": "So here you can see the text chain ratio compared to a couple of other methods that when it's kind of matching and money is a factor, invite someone direct.",
                    "label": 0
                },
                {
                    "sent": "And this is basically showing that you're able to improve performance over the radio of accounting.",
                    "label": 0
                },
                {
                    "sent": "Test this tradition if you're prepared to regularization initial compared to introduce a bit of clients.",
                    "label": 0
                },
                {
                    "sent": "So this is, I think, an encouraging result.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I thought maybe about penalty making.",
                    "label": 0
                },
                {
                    "sent": "I wanted this PC cover another.",
                    "label": 0
                },
                {
                    "sent": "Another elegant way to solve this problem.",
                    "label": 0
                },
                {
                    "sent": "So this is actually using a classifier.",
                    "label": 0
                },
                {
                    "sent": "After getting wait.",
                    "label": 0
                },
                {
                    "sent": "Are you playing a custom class?",
                    "label": 0
                },
                {
                    "sent": "English training intensive.",
                    "label": 0
                },
                {
                    "sent": "I didn't try to fix.",
                    "label": 0
                },
                {
                    "sent": "You get wait with you.",
                    "label": 0
                },
                {
                    "sent": "After this.",
                    "label": 0
                },
                {
                    "sent": "A number of times.",
                    "label": 0
                },
                {
                    "sent": "Isn't he?",
                    "label": 0
                },
                {
                    "sent": "The distribution here.",
                    "label": 0
                },
                {
                    "sent": "These variables already vector of variables, so you're testing training point which one where the training distribution is run from zero when the test.",
                    "label": 0
                },
                {
                    "sent": "So the again, the reason why you might want to do this.",
                    "label": 0
                },
                {
                    "sent": "Because you can then have to fight for exotic places.",
                    "label": 0
                },
                {
                    "sent": "And get wait which you would otherwise have trouble getting.",
                    "label": 0
                },
                {
                    "sent": "If you're trying to do the information.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here is how 1 yet.",
                    "label": 0
                },
                {
                    "sent": "Meaning.",
                    "label": 0
                },
                {
                    "sent": "After the pacifier.",
                    "label": 0
                },
                {
                    "sent": "So this is the probability of England from the Planning Council given a turning point in giving the parameter theater, which you've done enough training test.",
                    "label": 0
                },
                {
                    "sent": "So basically the.",
                    "label": 0
                },
                {
                    "sent": "Eating here.",
                    "label": 0
                },
                {
                    "sent": "Then you get to wait and then you plug those into your learning algorithm, which turns the tables of the pattern away from the exit.",
                    "label": 0
                },
                {
                    "sent": "Yep, we're done.",
                    "label": 0
                },
                {
                    "sent": "So he.",
                    "label": 0
                },
                {
                    "sent": "People paper proposed a further extension to this weekend.",
                    "label": 0
                },
                {
                    "sent": "Yeah, where they just make an enormous like model of everything that they pay.",
                    "label": 0
                },
                {
                    "sent": "My model tells me first I choose something from the training over distribution and then I labeled accordingly.",
                    "label": 0
                },
                {
                    "sent": "So actually.",
                    "label": 0
                },
                {
                    "sent": "Unpin.",
                    "label": 0
                },
                {
                    "sent": "Told me that he had some difficulties with this.",
                    "label": 0
                },
                {
                    "sent": "So his difficulty was to cross annotate the plan.",
                    "label": 0
                },
                {
                    "sent": "Yeah, we have parameters associated with the Gaussian.",
                    "label": 0
                },
                {
                    "sent": "You need to actually see unable to example, which then makes the whole thing redundant.",
                    "label": 0
                },
                {
                    "sent": "Another difficult music.",
                    "label": 0
                },
                {
                    "sent": "This idea of like choosing randomly ending.",
                    "label": 0
                },
                {
                    "sent": "To talk with, I think.",
                    "label": 0
                },
                {
                    "sent": "Like not a satisfactory intuition for as a process by which converges because.",
                    "label": 0
                },
                {
                    "sent": "But anyway, I guess.",
                    "label": 0
                },
                {
                    "sent": "The argument for this message is that you can have joined me, learn the need is for the training and test distribution, and then potentially get stronger.",
                    "label": 0
                },
                {
                    "sent": "By doing it.",
                    "label": 0
                },
                {
                    "sent": "So I have some extended.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The first one with.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you going to come much more details on the other.",
                    "label": 0
                },
                {
                    "sent": "Discuss the data set.",
                    "label": 0
                },
                {
                    "sent": "We're using a Gaussian kernel for both the kernel mean matching and for the support vector machines that we say.",
                    "label": 0
                },
                {
                    "sent": "We did fixing the bandwidth is tired and we're going to show the function of the sea, so this is the thing that controls the tradeoff between lot regularization and as it up here at Smokey means that we prioritize.",
                    "label": 0
                },
                {
                    "sent": "So the way that we generate update and this is an adaptation example, we have a native pool.",
                    "label": 0
                },
                {
                    "sent": "We split it randomly containing.",
                    "label": 0
                },
                {
                    "sent": "At the head.",
                    "label": 0
                },
                {
                    "sent": "Training data set will be of different sizes 'cause I'm gonna see performance in the function of training size.",
                    "label": 0
                },
                {
                    "sent": "And this is the distribution we choose from.",
                    "label": 0
                },
                {
                    "sent": "So you're basically selecting randomly, probably probably full of data according to this bias.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So first of all, the good results here for an OPI what we think.",
                    "label": 0
                },
                {
                    "sent": "It's at the moment.",
                    "label": 0
                },
                {
                    "sent": "Acute improvement that you get using kind of matching is very substantial.",
                    "label": 0
                },
                {
                    "sent": "Here we have the average luck.",
                    "label": 0
                },
                {
                    "sent": "You can see that across the board.",
                    "label": 0
                },
                {
                    "sent": "If you pull up.",
                    "label": 0
                },
                {
                    "sent": "The Gray one be important, something one is actually using the underlying through ratio.",
                    "label": 0
                },
                {
                    "sent": "And you can see here.",
                    "label": 0
                },
                {
                    "sent": "It shouldn't be surprising because the connection easier with tap in such a way as to pay the large ratio between training and test.",
                    "label": 0
                },
                {
                    "sent": "So I having Unregularized expression is that ratio is going to give you.",
                    "label": 0
                },
                {
                    "sent": "The distance for a very small thing, which means that we're actually prioritizing the smoothness of the classifier over the last.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now let's see what happens when we use a copy of validated.",
                    "label": 0
                },
                {
                    "sent": "So in this case, you'll see that the kind of matching actually makes everything a big one.",
                    "label": 0
                },
                {
                    "sent": "What interesting is that for a very small value of E?",
                    "label": 0
                },
                {
                    "sent": "Have basically pushed down the error.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "But if you would do well Tuesday, well.",
                    "label": 0
                },
                {
                    "sent": "Carefully.",
                    "label": 0
                },
                {
                    "sent": "You would end up with the right answer.",
                    "label": 0
                },
                {
                    "sent": "So why is it not getting improvement?",
                    "label": 0
                },
                {
                    "sent": "I'm in very light over there where we opened up for the.",
                    "label": 0
                },
                {
                    "sent": "Where we waited by the underlying crew.",
                    "label": 0
                },
                {
                    "sent": "Enter.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Misha.",
                    "label": 0
                },
                {
                    "sent": "So to give a intuition as to why this might be overturned to our 20 example again.",
                    "label": 0
                },
                {
                    "sent": "This time, rather than eating goodnight, I'm sitting kind of Ridge regression.",
                    "label": 0
                },
                {
                    "sent": "Here you can see that basically.",
                    "label": 0
                },
                {
                    "sent": "This is following the curve everywhere, and so the only thing that you get if you take some subset of that pending data up weighted down when everything else is reduced.",
                    "label": 0
                },
                {
                    "sent": "Sample space.",
                    "label": 0
                },
                {
                    "sent": "You're actually not helping yourself at all.",
                    "label": 0
                },
                {
                    "sent": "So the moral to this story, I think, is that if you have a probably faint and helpful learning method.",
                    "label": 0
                },
                {
                    "sent": "Doubtful that you're gonna get.",
                    "label": 0
                },
                {
                    "sent": "Competitive anytime.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Using the waiting go yeah.",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I mean, even in this one which was chosen.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Pretty much at random, you can see actually there waiting making things but so yeah.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "I mean this.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Experiment so we should never generalize from the sample datasets, and now I'm going to show a whole bunch of data set.",
                    "label": 0
                },
                {
                    "sent": "So it's a mixture of regression and classification.",
                    "label": 1
                },
                {
                    "sent": "Name is again.",
                    "label": 0
                },
                {
                    "sent": "Enter data, we basically have a pool of gender.",
                    "label": 0
                },
                {
                    "sent": "We sample comments with some quiet.",
                    "label": 0
                },
                {
                    "sent": "Again, a Gaussian virus on it.",
                    "label": 0
                },
                {
                    "sent": "One thing that we're doing, which might not be the best thing to do, is if we are using the same kernel size matching.",
                    "label": 0
                },
                {
                    "sent": "So this might not be optimal.",
                    "label": 0
                },
                {
                    "sent": "Right, so in all of these, yeah, all of these cases we generate the data by taking a full of data sub, something it randomly come by distribution that we have created.",
                    "label": 0
                },
                {
                    "sent": "So this is an artificial benchmark.",
                    "label": 0
                },
                {
                    "sent": "And then yeah.",
                    "label": 0
                },
                {
                    "sent": "The other thing that we do is we go for the pragmatism, the progression of classification over them.",
                    "label": 1
                },
                {
                    "sent": "We set a date on the unweighted data, so we can't sell it on the unweighted training set rather than the weighted one.",
                    "label": 0
                },
                {
                    "sent": "So this is again something I'm going to return to, but this is Mike at this point already.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But it needed.",
                    "label": 0
                },
                {
                    "sent": "OK, so here a benchmark.",
                    "label": 0
                },
                {
                    "sent": "So to guide you through the graph.",
                    "label": 0
                },
                {
                    "sent": "And these are where.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Either waiting or you coming provement.",
                    "label": 0
                },
                {
                    "sent": "In some cases, in most cases will feel there's only one case.",
                    "label": 0
                },
                {
                    "sent": "That doesn't happen.",
                    "label": 0
                },
                {
                    "sent": "But that's something that like bragging.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Select in some cases of both.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well.",
                    "label": 0
                },
                {
                    "sent": "Yes, case where what is something is, is it?",
                    "label": 0
                },
                {
                    "sent": "If it was the one here.",
                    "label": 0
                },
                {
                    "sent": "Here's one.",
                    "label": 0
                },
                {
                    "sent": "So basically what we've shown here is that, yeah, I mean the the results are very new.",
                    "label": 0
                },
                {
                    "sent": "I think what's interesting is that.",
                    "label": 0
                },
                {
                    "sent": "Phenomenon.",
                    "label": 0
                },
                {
                    "sent": "When?",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "When were both work?",
                    "label": 0
                },
                {
                    "sent": "So this seems to suggest looking at a couple of tipex then that if for whatever reason.",
                    "label": 0
                },
                {
                    "sent": "You cross validated over 2 plus agreements or your learning algorithm is not the right one for that data.",
                    "label": 0
                },
                {
                    "sent": "Then you're going to get an improvement using the waiting, even though if you were more careful in your collection algorithm or if you were more systematic in your consolidation, you would know.",
                    "label": 0
                },
                {
                    "sent": "So this is.",
                    "label": 0
                },
                {
                    "sent": "Awaited.",
                    "label": 0
                },
                {
                    "sent": "So when.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I get final foot.",
                    "label": 0
                },
                {
                    "sent": "Fortunately, we didn't go very well.",
                    "label": 0
                },
                {
                    "sent": "In our regional newspaper, is this model selection of the local variant?",
                    "label": 0
                },
                {
                    "sent": "So we have a distance measure between distributions.",
                    "label": 0
                },
                {
                    "sent": "Is this measure is a function of the kernel?",
                    "label": 0
                },
                {
                    "sent": "So what that means?",
                    "label": 0
                },
                {
                    "sent": "Is it for different kernels?",
                    "label": 0
                },
                {
                    "sent": "And for when you use these, if you get performance.",
                    "label": 0
                },
                {
                    "sent": "So here are a bunch of high dimensional datasets.",
                    "label": 0
                },
                {
                    "sent": "What you should note here it will translate it from someone elses payment so you can come here in German.",
                    "label": 0
                },
                {
                    "sent": "And 2nd that the moment does show a sort of optimum.",
                    "label": 0
                },
                {
                    "sent": "And I think you know that this optimum matches the best performance that they.",
                    "label": 0
                },
                {
                    "sent": "Terrorism which hasn't.",
                    "label": 0
                },
                {
                    "sent": "So what this intervene is that again, if for whatever reason the weight doesn't work.",
                    "label": 0
                },
                {
                    "sent": "You have to be very careful with kind of matching to choose a distance measure, which allows you to recover that be waiting.",
                    "label": 0
                },
                {
                    "sent": "So this is something which I don't have a good answer for in the cases.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "There have been.",
                    "label": 0
                },
                {
                    "sent": "General Web contact on choosing parameters for different.",
                    "label": 0
                },
                {
                    "sent": "Algorithm.",
                    "label": 0
                },
                {
                    "sent": "When easy cases, if there is a systematic group in the data, which just means that you have like from past values and very very good idea.",
                    "label": 0
                },
                {
                    "sent": "That makes it easy for you.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "E. Hannah groups have been doing personalization on the left out couple to obtain the parameters for learning algorithm.",
                    "label": 1
                },
                {
                    "sent": "Uh huh.",
                    "label": 0
                },
                {
                    "sent": "The thing is they could have.",
                    "label": 0
                },
                {
                    "sent": "It's like it's not just meditation.",
                    "label": 0
                },
                {
                    "sent": "Necessarily a. Madison or it's it's it's A kind of it's a different.",
                    "label": 0
                },
                {
                    "sent": "Way to do it.",
                    "label": 0
                },
                {
                    "sent": "So basically they have their estimate of their mission and then they are using that they use this ratio.",
                    "label": 0
                },
                {
                    "sent": "I did it.",
                    "label": 0
                },
                {
                    "sent": "I did it to some other expression.",
                    "label": 0
                },
                {
                    "sent": "But right exactly so this is different, right?",
                    "label": 0
                },
                {
                    "sent": "This happens as well.",
                    "label": 0
                },
                {
                    "sent": "Why did they do that?",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "In the main conference we talked about looking at the largest energy overhead external.",
                    "label": 0
                },
                {
                    "sent": "Or perhaps.",
                    "label": 0
                },
                {
                    "sent": "Other optimization over which Michael may not be wasted.",
                    "label": 0
                },
                {
                    "sent": "This I don't know if it would be useful or not, but at least something.",
                    "label": 0
                },
                {
                    "sent": "The last point, I think is quite an important one.",
                    "label": 0
                },
                {
                    "sent": "So again, if you know something about your learning problem.",
                    "label": 1
                },
                {
                    "sent": "For instance, that the learner user particular features of the distribution.",
                    "label": 0
                },
                {
                    "sent": "Then you should use the teachers in matching your.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah, exactly.",
                    "label": 0
                },
                {
                    "sent": "I mean, it's like you should concentrate on actually testing the teachers that you're going to use every feature you can get your hands on.",
                    "label": 0
                },
                {
                    "sent": "So this is.",
                    "label": 0
                },
                {
                    "sent": "Yeah, another quite important.",
                    "label": 0
                },
                {
                    "sent": "Thanks very much.",
                    "label": 0
                },
                {
                    "sent": "The other thing is you remember this when I did my cost allocation for the experiment.",
                    "label": 0
                },
                {
                    "sent": "I was using consolidation only unweighted.",
                    "label": 0
                },
                {
                    "sent": "It doesn't reduce the bias.",
                    "label": 0
                },
                {
                    "sent": "But again, coming back to our example because we were using high powerful learning algorithms, yeah, it seems that becomes validation.",
                    "label": 0
                },
                {
                    "sent": "They got under way to pretty much didn't change when we use the unweighted.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so that was.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK so summary.",
                    "label": 0
                },
                {
                    "sent": "I think cloud the.",
                    "label": 0
                },
                {
                    "sent": "Currently, matching allows you to do prevent without doing press.",
                    "label": 0
                },
                {
                    "sent": "Contest distribution.",
                    "label": 0
                },
                {
                    "sent": "Um, it allows you to match only particular features of the distribution, and so, for instance, unstructured domains like things after this might be an approach to use.",
                    "label": 0
                },
                {
                    "sent": "Where the moment improve in output is very generic benchmark experiment.",
                    "label": 0
                },
                {
                    "sent": "Mainly when the learning algorithm with symptoms in the data would work.",
                    "label": 0
                },
                {
                    "sent": "So in this case you can get very big performance improvement and this almost has the favor of local learning and that you if you have any learning algorithm which is intended to when you should have.",
                    "label": 0
                },
                {
                    "sent": "Then focusing in on your test data is gonna help you.",
                    "label": 0
                },
                {
                    "sent": "If the learning algorithm is helpful, is it needs to be, then it might still be useful to do concurrent chips in the sense that it gives you a little bit more pain in your consolidation every waiting.",
                    "label": 0
                },
                {
                    "sent": "Just because if you haven't consolidated company it, it might actually help you.",
                    "label": 0
                },
                {
                    "sent": "Or if you're using an algorithm which is not completely.",
                    "label": 0
                },
                {
                    "sent": "And model collection.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}