{
    "id": "avli4izsfu25fc2gj3mmnvntybttmbtw",
    "title": "Combining Discriminative and Generative Methods for 3D Deformable Surface and Articulated Pose Reconstruction",
    "info": {
        "author": [
            "Mathieu Salzmann, NICTA, Australia's ICT Research Centre of Excellence"
        ],
        "published": "July 19, 2010",
        "recorded": "June 2010",
        "category": [
            "Top->Computer Science->Computer Vision->Motion and Tracking"
        ]
    },
    "url": "http://videolectures.net/cvpr2010_salzmann_cdgm/",
    "segmentation": [
        [
            "So and."
        ],
        [
            "This work we're addressing two different problems.",
            "The first one is deformable shape recovery, where given an image of a deforming surface will try to infer its three depots, and here we represent the surface as a triangulated mesh, and we parameterise it in terms of the 3D coordinates of its vertices.",
            "Is the second problem is the problem of articulated pose estimation, where given an image of a person performing some action, which router recovery the pose of the person, and we parameterized oppose in terms of the 3D coordinates of the joints?",
            "Of a human skeleton.",
            "Now in the past, these two tasks have been addressed as two different problems, and here I'll present an approach that is valid for both tasks.",
            "Well, first, by reviewing the different kind of approaches that have been proposed for these two different problems."
        ],
        [
            "So for deformable shape recovery, existing methods typically rely on generative approaches, and they exist.",
            "The recent methods focused on formulating reconstruction as an effective optimization problem, but the problem is that they typically are specifically designed to rely on point to point correspondences and do not really generalize well to other types of image representations.",
            "Not for you."
        ],
        [
            "Are articulated pose estimation.",
            "Many approaches rely on discriminative approaches and the advantage of that is that they allow for any image representation.",
            "However, to be accurate at the required to have large training sets and Furthermore the employed methods typically assume that the output dimensions are independent given the inputs and therefore they tend to yield pose that violate important constraints between the different output dimensions.",
            "Now, to overcome some of these issues.",
            "Some other techniques rely on generative approaches, and generative approaches, typically shown to yield better accuracy than discriminative approaches.",
            "However, they have the disadvantage that they require very good initializations produce good results.",
            "So from this it's."
        ],
        [
            "Seems that discriminative and generative methods should be used together, and this of course was observed in the past.",
            "However, the existing methods either rely on the generative part only for training, and therefore they tend to lose accuracy at Test time, or they rely on the discriminative part only for initialization and therefore the poles can just drift away from the original prediction.",
            "And here would like to have a more principled combination of generative and discriminative methods.",
            "So our approach relies."
        ],
        [
            "On three key components that I'll describe in the rest of this talk, I'll first describe the use of discriminative methods to predict a 3D pose from input images, and then I will introduce our approach to enforcing constraints on this three poles in order to link the output dimensions of the 3D representations.",
            "And finally I will show how we can link the pose back to the image.",
            "A while still enforcing the constraints that we used before and preventing the post to drift away from the original prediction.",
            "So first start by describing the discriminate."
        ],
        [
            "Regression task so discriminative methods typically focus on learning a mapping F from some input X2 output and output Y an.",
            "In our case, the inputs X corresponds to image features and the output Y corresponds to the 3D pose, so there is the 3D locations of points on a mesh or on a skeleton, and we learned this estimate of this mapping of hats from training data and then at Test time given a new input X star.",
            "Will compute the pose as the prediction have had a big star, and in general the methods employed in in pose estimation when the output is demoted dimensional they make the assumptions that the outputs are independent given the inputs, and that can deal very problematic solution with some constraints are violated on the output and I'll illustrate that with an example."
        ],
        [
            "Here here we're trying to recover the shape of the surface from a 2D input image an on the left, showing our reconstruction in red overlaid over the original image, and we can see that.",
            "It really represents very nicely the surface introject correctly on the surface.",
            "However, if we look at the 3D shape on the right, we can see that some parts of the surface are stretched.",
            "That is, for example, the case of the bottom right corner of the 3D surface, and this is typically due to the fact that we do not model at all the correlation between the different output dimensions.",
            "So between the different 3D points on the surface.",
            "So now we want to improve."
        ],
        [
            "This prediction, and to do that we're going to enforce some constraints on the recovery surface, and in particular, we want to consider the case of distance constraints between pairs of 3D points on the surface.",
            "So will write the following optimization problem where we seek to find oppose Y that is as close as possible to the original prediction.",
            "If had a big star and that satisfies some constraints which include the fact that the distance between 2 three points should remain constant and is known.",
            "So here is subscript K&J.",
            "Define a 3D points on the surface or on the skeleton.",
            "And the LJK are in the known distances between these points.",
            "The problem with this is that this is a non convex optimization problem because we have quadratic equality constraints.",
            "So here to address this."
        ],
        [
            "So iteratively linearize the constraints and solve the problem.",
            "So I'll illustrate this with the toy example, where we have two 1D variables Y1 and Y2, and here in blue I'm showing the surface corresponding to the squared distance between Y1 and Y2."
        ],
        [
            "Then the yellow surface here displays the constants square length L12 known length between the two variables and it means that our constraints are exactly at the intersection between these two different services.",
            "So now given the currents."
        ],
        [
            "Motion that we obtained with the discriminative prediction which does not satisfy the constraints we will approach."
        ],
        [
            "Some, it's the distance with the 1st order Taylor expansion, so that is response to the green surface here and now.",
            "We want to find a solution for which the linearized constraints are satisfied.",
            "So we want to find a solution that is at the intersection between the green plane and the yellow plane, and as we can see from this disbursement to the to the red line here, and so it's not a single solution."
        ],
        [
            "So we can actually parameterized the family of solutions that satisfies these linear constraints with a new variable gamma.",
            "And this gamma corresponds to the displacements in the null space of the linearized constraints.",
            "And now we want to find the gamma, which you suppose S of gamma, which is closest to the original prediction.",
            "F had a text or an.",
            "The good news with that is because S of gamma is a linear function of gamma.",
            "We can solve this in close form and then given that new solution will repeat this procedure.",
            "Until all the constraints are satisfied."
        ],
        [
            "So to show you the algorithm of our approach, we first initialize the pose Y with the original discriminative prediction, and then iteratively will compute the 1st order Taylor expansion of the constraints and this will leave as I showed before, new parameters gamma T that defined the posessive gamma T and then given this new parameters we want to find the pose that is close as possible to the original prediction and this can be solved in closed form and finally will update the pose with the new.",
            "Parameter gamma and will do that iteratively until all the constraints on the mesh or on the skeleton are satisfied."
        ],
        [
            "So the previous methods only uses the predictor through a fixed prediction.",
            "F had avec star, so it seems a bit of a waste of training data to only use this fixed prediction.",
            "So now we want to make a better use of that predictor and for that purpose will propose to rely on the Representer theorem.",
            "So in the case of multi dimensional outputs, if we assume that the outputs are independent given the inputs, we can write.",
            "It means that we can write the prediction of had a vector as a product between matrix Alpha.",
            "And the vector case star, which is the kernel evaluated between the end training inputs and the new input X star.",
            "So."
        ],
        [
            "To rely more strongly on the predictor will now treat that vector case star as an unknown.",
            "Which means that we can rewrite the optimization problem that we had before as that of finding a case star windshield supposed Alpha K star which is close as possible to the original prediction.",
            "If Arabic store subject to the same distance constraints as before.",
            "Where not why.",
            "So each three points.",
            "Why can YJ is a function of that vector K star?",
            "And so, similarly as before, we can iteratively linearize our constraints.",
            "I'll solve that problem to all the constraints are satisfied.",
            "Of course, now the dimensionality of case star is directly the number of training examples.",
            "So if we want to have a solution to this problem, we need to have more training examples than the number of constraints.",
            "Otherwise the problem is over constrained.",
            "And this already in."
        ],
        [
            "Proves over the previous solution.",
            "There should be some before and I'll show that in the results later on, but it has one drawback is that it only relies on the image information through the prediction of the discriminative method.",
            "So as we can see here, we have a surface on the right that satisfies the length constraints, but it doesn't really represent very accurately what we can observe in the image.",
            "So now to improve about that, we want to link."
        ],
        [
            "Like the pose back to the image through a generative method.",
            "And.",
            "To do that, instead of seeking the gamma star that just used the post closest to the original prediction, will add an image based loss function to our objective function, and in practice, the kind of image based loss function that we used where either using points, reprojection error and for that case we can show that we still have a closed form solution at each iteration of our linearisation, and we also try to use template matching which gives a better, more accurate representation of the texture of the surface.",
            "Or we learned an inverse mapping that is mapping from the pose to the image an which rather minimize the difference between the predicted image features and the actual observed image features."
        ],
        [
            "So I will show you an example of that.",
            "This is the sequence from which I have taken the individual image that I showed before.",
            "So on the left we see the prediction of the original regressor that we trained.",
            "As I said before, we can see the tree projects very accurately on the image, but the 3D shape as we can see stretches and rotates not very accurately in the middle.",
            "This is the solution that we get once we just enforce the constraints without generative parts.",
            "So we can see that the constraints are not satisfied, but doesn't really represent what's observed in the image.",
            "And finally, on the right.",
            "This is the full solution.",
            "We used the generative so we re linked the the shape again back to the image in reprojection error and we can see that now we have a very good shape and the tree projects correctly on the image as well."
        ],
        [
            "So for our experimental valuation as a discriminative predictor, we relied on Gaussian processes where Alpha can be obtaining closed form an.",
            "We tested our approach on several datasets.",
            "We use two deformable surface datasets, one acquired from Motion capture system and synthetic one, and from these we created images either with well textured or poorly textured images.",
            "Anfar articulated participation we used.",
            "Composer datasets for both human polls and handfuls estimation and we also use the human eval datasets.",
            "So here I'll just show you subsets of our results, and if you're interested in seeing all of them, then look at the paper or come to our poster tonight."
        ],
        [
            "So first also by the fact that we reconstruct a piece of Cardboard from the 2D locations of the vertices on the image.",
            "So this is the input that we use here I'm showing the mean square error between our reconstruction and ground truth as a function of the Gaussian noise variance on these two D locations and on the left hand side deployed is when we're optimizing.",
            "Why suppose directly and on the right hand side is where we are optimizing case dot.",
            "And as we can see in green, this is the results for the GP and once we impose constraints on those results, we already we get the blue curve, which is already better than than the GP itself.",
            "And finally, if we link back to the image with the generative methods then will even improve further the results and this is similar for both YNK star."
        ],
        [
            "Here I'm showing a similar errors, but as a function of the number of training examples, again on the left hand side when we're optimizing why an on the right hand side, we're optimizing case star in the case where we optimize why we can see that even with few training examples will really perform much better than the GP.",
            "One recognizing K star as I mentioned before, if we don't have enough training examples, that is if we have less training examples, the number of constraints, we cannot really get any accurate reconstructions.",
            "We perform pretty badly, but as soon as we have more examples in the number of constraints we outperform the GP.",
            "What's up?"
        ],
        [
            "Compare our approach against state of the art reconstruction methods.",
            "Both of the works that I'm showing here where published last year.",
            "One of them is actually my own work.",
            "And as we can see, we're more robust than these two approaches to the input noise."
        ],
        [
            "Finally, one of the goals of using that kind of approach was also to be able to not have only point to point correspondences, but other type of image information.",
            "So we also computed pyramid of Hog features on the input images that I showed before.",
            "So both for the well textured case an for the poorly textured case.",
            "So on the left hand side, this is the result that we have for the well textured piece of Cardboard.",
            "As we can see, again using constraints improved over the original GP results.",
            "And linking the shape back to the image even further improves the results.",
            "And this is similar when on the right hand side where we optimize the politics where we use a poorly textured surface as input."
        ],
        [
            "In the case of articulated pose estimation, I'll show results for the kids of the hands we try to apply.",
            "We try to use different types of features as input for some features of the original predictor of great performs very well, so our approach can actually improve very much.",
            "But on the other hand, for some other features which were very noisy, we had like the GPS troubles reconstructing meaningful poles, and that's what we can see on the right hand side.",
            "But Despite that very poor initialization, our approach managed to recover.",
            "Rifles"
        ],
        [
            "And finally, for human pose estimation we also use different types of features on the human eval datasets, and similarly as before in all these cases, we can see that our approach outperforms and improves the results of the original GP.",
            "So to summarize."
        ],
        [
            "I showed that articulated participation and knowledge, shape, reconstruction could be addressed within a common framework.",
            "And to this end we introduced a novel approach to incorporating explicit constraints in discriminative methods, and we also propose a principle combination of discriminative and generative methods and in the future."
        ],
        [
            "Use our framework is very general and can allow for many different constraints in the one we used, we'd like to study the use of other constraints to improve reconstruction, and we particularly interested in using physics based constraints and would also like to be able to learn a predictor that implicitly satisfy the constraints.",
            "Thank you for your attention.",
            "Just before starting the questions, could the Spotlight presenters who are not yet in the front two rows please come up immediately OK?",
            "Are there any questions?",
            "I.",
            "Are you?",
            "In the part where you linearize your constraints and iterate, that's really Newton's method for solving nonlinear equations, which is known in general, not to convert unless you're near resolution.",
            "So what are your thoughts on that so?",
            "I have no proof of convergence for principle, but what happens in our case is really converge very well as long as we're optimizing with respect to Y directly.",
            "If we have enough parameters when we like, even after training examples when working with respect to K, it also converge fairly well.",
            "Now this is only in practice.",
            "The reason is also the distance function itself is sufficiently like is a convex function, is just the equality constraints, which is not which is non convex.",
            "And also the fact that we have a sufficiently good initialization given by the predictor is also important.",
            "But I agree that in general there's no guarantee of convergence to global alter.",
            "The best local minimum.",
            "Anymore questions.",
            "OK, let's thank our speaker."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So and.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This work we're addressing two different problems.",
                    "label": 0
                },
                {
                    "sent": "The first one is deformable shape recovery, where given an image of a deforming surface will try to infer its three depots, and here we represent the surface as a triangulated mesh, and we parameterise it in terms of the 3D coordinates of its vertices.",
                    "label": 1
                },
                {
                    "sent": "Is the second problem is the problem of articulated pose estimation, where given an image of a person performing some action, which router recovery the pose of the person, and we parameterized oppose in terms of the 3D coordinates of the joints?",
                    "label": 1
                },
                {
                    "sent": "Of a human skeleton.",
                    "label": 0
                },
                {
                    "sent": "Now in the past, these two tasks have been addressed as two different problems, and here I'll present an approach that is valid for both tasks.",
                    "label": 0
                },
                {
                    "sent": "Well, first, by reviewing the different kind of approaches that have been proposed for these two different problems.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for deformable shape recovery, existing methods typically rely on generative approaches, and they exist.",
                    "label": 1
                },
                {
                    "sent": "The recent methods focused on formulating reconstruction as an effective optimization problem, but the problem is that they typically are specifically designed to rely on point to point correspondences and do not really generalize well to other types of image representations.",
                    "label": 0
                },
                {
                    "sent": "Not for you.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Are articulated pose estimation.",
                    "label": 0
                },
                {
                    "sent": "Many approaches rely on discriminative approaches and the advantage of that is that they allow for any image representation.",
                    "label": 1
                },
                {
                    "sent": "However, to be accurate at the required to have large training sets and Furthermore the employed methods typically assume that the output dimensions are independent given the inputs and therefore they tend to yield pose that violate important constraints between the different output dimensions.",
                    "label": 1
                },
                {
                    "sent": "Now, to overcome some of these issues.",
                    "label": 0
                },
                {
                    "sent": "Some other techniques rely on generative approaches, and generative approaches, typically shown to yield better accuracy than discriminative approaches.",
                    "label": 0
                },
                {
                    "sent": "However, they have the disadvantage that they require very good initializations produce good results.",
                    "label": 0
                },
                {
                    "sent": "So from this it's.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Seems that discriminative and generative methods should be used together, and this of course was observed in the past.",
                    "label": 0
                },
                {
                    "sent": "However, the existing methods either rely on the generative part only for training, and therefore they tend to lose accuracy at Test time, or they rely on the discriminative part only for initialization and therefore the poles can just drift away from the original prediction.",
                    "label": 0
                },
                {
                    "sent": "And here would like to have a more principled combination of generative and discriminative methods.",
                    "label": 1
                },
                {
                    "sent": "So our approach relies.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On three key components that I'll describe in the rest of this talk, I'll first describe the use of discriminative methods to predict a 3D pose from input images, and then I will introduce our approach to enforcing constraints on this three poles in order to link the output dimensions of the 3D representations.",
                    "label": 0
                },
                {
                    "sent": "And finally I will show how we can link the pose back to the image.",
                    "label": 0
                },
                {
                    "sent": "A while still enforcing the constraints that we used before and preventing the post to drift away from the original prediction.",
                    "label": 0
                },
                {
                    "sent": "So first start by describing the discriminate.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Regression task so discriminative methods typically focus on learning a mapping F from some input X2 output and output Y an.",
                    "label": 1
                },
                {
                    "sent": "In our case, the inputs X corresponds to image features and the output Y corresponds to the 3D pose, so there is the 3D locations of points on a mesh or on a skeleton, and we learned this estimate of this mapping of hats from training data and then at Test time given a new input X star.",
                    "label": 1
                },
                {
                    "sent": "Will compute the pose as the prediction have had a big star, and in general the methods employed in in pose estimation when the output is demoted dimensional they make the assumptions that the outputs are independent given the inputs, and that can deal very problematic solution with some constraints are violated on the output and I'll illustrate that with an example.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here here we're trying to recover the shape of the surface from a 2D input image an on the left, showing our reconstruction in red overlaid over the original image, and we can see that.",
                    "label": 0
                },
                {
                    "sent": "It really represents very nicely the surface introject correctly on the surface.",
                    "label": 0
                },
                {
                    "sent": "However, if we look at the 3D shape on the right, we can see that some parts of the surface are stretched.",
                    "label": 0
                },
                {
                    "sent": "That is, for example, the case of the bottom right corner of the 3D surface, and this is typically due to the fact that we do not model at all the correlation between the different output dimensions.",
                    "label": 0
                },
                {
                    "sent": "So between the different 3D points on the surface.",
                    "label": 0
                },
                {
                    "sent": "So now we want to improve.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This prediction, and to do that we're going to enforce some constraints on the recovery surface, and in particular, we want to consider the case of distance constraints between pairs of 3D points on the surface.",
                    "label": 1
                },
                {
                    "sent": "So will write the following optimization problem where we seek to find oppose Y that is as close as possible to the original prediction.",
                    "label": 1
                },
                {
                    "sent": "If had a big star and that satisfies some constraints which include the fact that the distance between 2 three points should remain constant and is known.",
                    "label": 0
                },
                {
                    "sent": "So here is subscript K&J.",
                    "label": 0
                },
                {
                    "sent": "Define a 3D points on the surface or on the skeleton.",
                    "label": 0
                },
                {
                    "sent": "And the LJK are in the known distances between these points.",
                    "label": 1
                },
                {
                    "sent": "The problem with this is that this is a non convex optimization problem because we have quadratic equality constraints.",
                    "label": 0
                },
                {
                    "sent": "So here to address this.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So iteratively linearize the constraints and solve the problem.",
                    "label": 0
                },
                {
                    "sent": "So I'll illustrate this with the toy example, where we have two 1D variables Y1 and Y2, and here in blue I'm showing the surface corresponding to the squared distance between Y1 and Y2.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then the yellow surface here displays the constants square length L12 known length between the two variables and it means that our constraints are exactly at the intersection between these two different services.",
                    "label": 0
                },
                {
                    "sent": "So now given the currents.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Motion that we obtained with the discriminative prediction which does not satisfy the constraints we will approach.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some, it's the distance with the 1st order Taylor expansion, so that is response to the green surface here and now.",
                    "label": 0
                },
                {
                    "sent": "We want to find a solution for which the linearized constraints are satisfied.",
                    "label": 0
                },
                {
                    "sent": "So we want to find a solution that is at the intersection between the green plane and the yellow plane, and as we can see from this disbursement to the to the red line here, and so it's not a single solution.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we can actually parameterized the family of solutions that satisfies these linear constraints with a new variable gamma.",
                    "label": 1
                },
                {
                    "sent": "And this gamma corresponds to the displacements in the null space of the linearized constraints.",
                    "label": 1
                },
                {
                    "sent": "And now we want to find the gamma, which you suppose S of gamma, which is closest to the original prediction.",
                    "label": 0
                },
                {
                    "sent": "F had a text or an.",
                    "label": 0
                },
                {
                    "sent": "The good news with that is because S of gamma is a linear function of gamma.",
                    "label": 1
                },
                {
                    "sent": "We can solve this in close form and then given that new solution will repeat this procedure.",
                    "label": 1
                },
                {
                    "sent": "Until all the constraints are satisfied.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So to show you the algorithm of our approach, we first initialize the pose Y with the original discriminative prediction, and then iteratively will compute the 1st order Taylor expansion of the constraints and this will leave as I showed before, new parameters gamma T that defined the posessive gamma T and then given this new parameters we want to find the pose that is close as possible to the original prediction and this can be solved in closed form and finally will update the pose with the new.",
                    "label": 0
                },
                {
                    "sent": "Parameter gamma and will do that iteratively until all the constraints on the mesh or on the skeleton are satisfied.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the previous methods only uses the predictor through a fixed prediction.",
                    "label": 1
                },
                {
                    "sent": "F had avec star, so it seems a bit of a waste of training data to only use this fixed prediction.",
                    "label": 0
                },
                {
                    "sent": "So now we want to make a better use of that predictor and for that purpose will propose to rely on the Representer theorem.",
                    "label": 1
                },
                {
                    "sent": "So in the case of multi dimensional outputs, if we assume that the outputs are independent given the inputs, we can write.",
                    "label": 0
                },
                {
                    "sent": "It means that we can write the prediction of had a vector as a product between matrix Alpha.",
                    "label": 1
                },
                {
                    "sent": "And the vector case star, which is the kernel evaluated between the end training inputs and the new input X star.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To rely more strongly on the predictor will now treat that vector case star as an unknown.",
                    "label": 1
                },
                {
                    "sent": "Which means that we can rewrite the optimization problem that we had before as that of finding a case star windshield supposed Alpha K star which is close as possible to the original prediction.",
                    "label": 0
                },
                {
                    "sent": "If Arabic store subject to the same distance constraints as before.",
                    "label": 0
                },
                {
                    "sent": "Where not why.",
                    "label": 0
                },
                {
                    "sent": "So each three points.",
                    "label": 0
                },
                {
                    "sent": "Why can YJ is a function of that vector K star?",
                    "label": 1
                },
                {
                    "sent": "And so, similarly as before, we can iteratively linearize our constraints.",
                    "label": 0
                },
                {
                    "sent": "I'll solve that problem to all the constraints are satisfied.",
                    "label": 1
                },
                {
                    "sent": "Of course, now the dimensionality of case star is directly the number of training examples.",
                    "label": 0
                },
                {
                    "sent": "So if we want to have a solution to this problem, we need to have more training examples than the number of constraints.",
                    "label": 0
                },
                {
                    "sent": "Otherwise the problem is over constrained.",
                    "label": 0
                },
                {
                    "sent": "And this already in.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Proves over the previous solution.",
                    "label": 0
                },
                {
                    "sent": "There should be some before and I'll show that in the results later on, but it has one drawback is that it only relies on the image information through the prediction of the discriminative method.",
                    "label": 1
                },
                {
                    "sent": "So as we can see here, we have a surface on the right that satisfies the length constraints, but it doesn't really represent very accurately what we can observe in the image.",
                    "label": 0
                },
                {
                    "sent": "So now to improve about that, we want to link.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Like the pose back to the image through a generative method.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "To do that, instead of seeking the gamma star that just used the post closest to the original prediction, will add an image based loss function to our objective function, and in practice, the kind of image based loss function that we used where either using points, reprojection error and for that case we can show that we still have a closed form solution at each iteration of our linearisation, and we also try to use template matching which gives a better, more accurate representation of the texture of the surface.",
                    "label": 1
                },
                {
                    "sent": "Or we learned an inverse mapping that is mapping from the pose to the image an which rather minimize the difference between the predicted image features and the actual observed image features.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I will show you an example of that.",
                    "label": 0
                },
                {
                    "sent": "This is the sequence from which I have taken the individual image that I showed before.",
                    "label": 0
                },
                {
                    "sent": "So on the left we see the prediction of the original regressor that we trained.",
                    "label": 0
                },
                {
                    "sent": "As I said before, we can see the tree projects very accurately on the image, but the 3D shape as we can see stretches and rotates not very accurately in the middle.",
                    "label": 0
                },
                {
                    "sent": "This is the solution that we get once we just enforce the constraints without generative parts.",
                    "label": 0
                },
                {
                    "sent": "So we can see that the constraints are not satisfied, but doesn't really represent what's observed in the image.",
                    "label": 0
                },
                {
                    "sent": "And finally, on the right.",
                    "label": 0
                },
                {
                    "sent": "This is the full solution.",
                    "label": 0
                },
                {
                    "sent": "We used the generative so we re linked the the shape again back to the image in reprojection error and we can see that now we have a very good shape and the tree projects correctly on the image as well.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for our experimental valuation as a discriminative predictor, we relied on Gaussian processes where Alpha can be obtaining closed form an.",
                    "label": 1
                },
                {
                    "sent": "We tested our approach on several datasets.",
                    "label": 0
                },
                {
                    "sent": "We use two deformable surface datasets, one acquired from Motion capture system and synthetic one, and from these we created images either with well textured or poorly textured images.",
                    "label": 0
                },
                {
                    "sent": "Anfar articulated participation we used.",
                    "label": 0
                },
                {
                    "sent": "Composer datasets for both human polls and handfuls estimation and we also use the human eval datasets.",
                    "label": 0
                },
                {
                    "sent": "So here I'll just show you subsets of our results, and if you're interested in seeing all of them, then look at the paper or come to our poster tonight.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So first also by the fact that we reconstruct a piece of Cardboard from the 2D locations of the vertices on the image.",
                    "label": 1
                },
                {
                    "sent": "So this is the input that we use here I'm showing the mean square error between our reconstruction and ground truth as a function of the Gaussian noise variance on these two D locations and on the left hand side deployed is when we're optimizing.",
                    "label": 0
                },
                {
                    "sent": "Why suppose directly and on the right hand side is where we are optimizing case dot.",
                    "label": 0
                },
                {
                    "sent": "And as we can see in green, this is the results for the GP and once we impose constraints on those results, we already we get the blue curve, which is already better than than the GP itself.",
                    "label": 0
                },
                {
                    "sent": "And finally, if we link back to the image with the generative methods then will even improve further the results and this is similar for both YNK star.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here I'm showing a similar errors, but as a function of the number of training examples, again on the left hand side when we're optimizing why an on the right hand side, we're optimizing case star in the case where we optimize why we can see that even with few training examples will really perform much better than the GP.",
                    "label": 1
                },
                {
                    "sent": "One recognizing K star as I mentioned before, if we don't have enough training examples, that is if we have less training examples, the number of constraints, we cannot really get any accurate reconstructions.",
                    "label": 0
                },
                {
                    "sent": "We perform pretty badly, but as soon as we have more examples in the number of constraints we outperform the GP.",
                    "label": 0
                },
                {
                    "sent": "What's up?",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Compare our approach against state of the art reconstruction methods.",
                    "label": 1
                },
                {
                    "sent": "Both of the works that I'm showing here where published last year.",
                    "label": 0
                },
                {
                    "sent": "One of them is actually my own work.",
                    "label": 0
                },
                {
                    "sent": "And as we can see, we're more robust than these two approaches to the input noise.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Finally, one of the goals of using that kind of approach was also to be able to not have only point to point correspondences, but other type of image information.",
                    "label": 0
                },
                {
                    "sent": "So we also computed pyramid of Hog features on the input images that I showed before.",
                    "label": 0
                },
                {
                    "sent": "So both for the well textured case an for the poorly textured case.",
                    "label": 0
                },
                {
                    "sent": "So on the left hand side, this is the result that we have for the well textured piece of Cardboard.",
                    "label": 1
                },
                {
                    "sent": "As we can see, again using constraints improved over the original GP results.",
                    "label": 0
                },
                {
                    "sent": "And linking the shape back to the image even further improves the results.",
                    "label": 0
                },
                {
                    "sent": "And this is similar when on the right hand side where we optimize the politics where we use a poorly textured surface as input.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the case of articulated pose estimation, I'll show results for the kids of the hands we try to apply.",
                    "label": 0
                },
                {
                    "sent": "We try to use different types of features as input for some features of the original predictor of great performs very well, so our approach can actually improve very much.",
                    "label": 0
                },
                {
                    "sent": "But on the other hand, for some other features which were very noisy, we had like the GPS troubles reconstructing meaningful poles, and that's what we can see on the right hand side.",
                    "label": 0
                },
                {
                    "sent": "But Despite that very poor initialization, our approach managed to recover.",
                    "label": 0
                },
                {
                    "sent": "Rifles",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And finally, for human pose estimation we also use different types of features on the human eval datasets, and similarly as before in all these cases, we can see that our approach outperforms and improves the results of the original GP.",
                    "label": 0
                },
                {
                    "sent": "So to summarize.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I showed that articulated participation and knowledge, shape, reconstruction could be addressed within a common framework.",
                    "label": 0
                },
                {
                    "sent": "And to this end we introduced a novel approach to incorporating explicit constraints in discriminative methods, and we also propose a principle combination of discriminative and generative methods and in the future.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Use our framework is very general and can allow for many different constraints in the one we used, we'd like to study the use of other constraints to improve reconstruction, and we particularly interested in using physics based constraints and would also like to be able to learn a predictor that implicitly satisfy the constraints.",
                    "label": 1
                },
                {
                    "sent": "Thank you for your attention.",
                    "label": 0
                },
                {
                    "sent": "Just before starting the questions, could the Spotlight presenters who are not yet in the front two rows please come up immediately OK?",
                    "label": 0
                },
                {
                    "sent": "Are there any questions?",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                },
                {
                    "sent": "Are you?",
                    "label": 0
                },
                {
                    "sent": "In the part where you linearize your constraints and iterate, that's really Newton's method for solving nonlinear equations, which is known in general, not to convert unless you're near resolution.",
                    "label": 0
                },
                {
                    "sent": "So what are your thoughts on that so?",
                    "label": 0
                },
                {
                    "sent": "I have no proof of convergence for principle, but what happens in our case is really converge very well as long as we're optimizing with respect to Y directly.",
                    "label": 0
                },
                {
                    "sent": "If we have enough parameters when we like, even after training examples when working with respect to K, it also converge fairly well.",
                    "label": 0
                },
                {
                    "sent": "Now this is only in practice.",
                    "label": 0
                },
                {
                    "sent": "The reason is also the distance function itself is sufficiently like is a convex function, is just the equality constraints, which is not which is non convex.",
                    "label": 0
                },
                {
                    "sent": "And also the fact that we have a sufficiently good initialization given by the predictor is also important.",
                    "label": 0
                },
                {
                    "sent": "But I agree that in general there's no guarantee of convergence to global alter.",
                    "label": 0
                },
                {
                    "sent": "The best local minimum.",
                    "label": 0
                },
                {
                    "sent": "Anymore questions.",
                    "label": 0
                },
                {
                    "sent": "OK, let's thank our speaker.",
                    "label": 0
                }
            ]
        }
    }
}