{
    "id": "db7hxbjttwti4rk4xwffkw2xw3f335gw",
    "title": "Learning from Interpretations: A Rooted Kernel for Ordered Hypergraphs",
    "info": {
        "author": [
            "Gabriel Wachman, Department of Computer Science, Tufts University"
        ],
        "published": "June 23, 2007",
        "recorded": "June 2007",
        "category": [
            "Top->Computer Science->Machine Learning->Kernel Methods"
        ]
    },
    "url": "http://videolectures.net/icml07_wachman_lfi/",
    "segmentation": [
        [
            "How do I get full screen on this?",
            "Can I get full screen?",
            "Do you know how to?",
            "You are looking for.",
            "No, I'm OK.",
            "Thank you all for coming.",
            "I'm Gabriel Walkman and today I'm going to be talking about some research I did with Ronnie Cardone.",
            "We developed a kernel that learns over hypergraphs, kernel that takes its input hypergraphs and we explored its performance in various experimental settings.",
            "And I'll be talking about."
        ],
        [
            "Add.",
            "What do we want to learn from hypergraphs?",
            "There's several interesting domains in which this could potentially be applicable.",
            "Two of the primary ones are chemical data, which you can see here.",
            "We have a simple water molecule that's represented as a graph.",
            "And we also have relational data.",
            "On the left of the screen you can see some predicates with objects and on the right of the screen you can see the equivalent hypergraph that you would obtain by drawing it."
        ],
        [
            "So.",
            "So first I'll give some basic terminology and talk about what a kernel is and some other background, and then I'll talk about what exactly we did in some detail.",
            "And the key ways in which our kernel differs from other previous methods.",
            "Then I'll outline the experiments we did and the results we obtained, and finally I'll discuss some of the questions that were raised by our research that.",
            "Remain open."
        ],
        [
            "A kernel is simply a function that just takes you objects and computes their inner product in some feature space.",
            "This is interesting.",
            "In the graph case here you can see kernel might take one of these graphs and map it into feature space that is indexed by the types of atoms it contains.",
            "So on the top graph G1 we have a hydrogen Atom and oxygen Atom and the resulting feature vector is there next to it and likewise in the graph mislabeled G1, but.",
            "G2 is we have a carbon Atom in a hydrogen Atom.",
            "The inner product of these is 1 an.",
            "In this case, it's feasible that we might be able to do this explicitly, but the point is that the kernel can perform these operations without having to represent the feature space explicitly."
        ],
        [
            "We can expand and complicate the feature space here.",
            "We have features that are simple paths in the graph or simple walks in the in the graph and you can see that we have a in the top graph.",
            "We have hydrogen, oxygen, hydrogen, an in the bottom graph.",
            "We have hydrogen, carbon, carbon, hydrogen.",
            "So again, we can continue to complicate this feature space as we will, but it gives you an idea."
        ],
        [
            "Yeah, of the kinds of features we might want to compute.",
            "And the other methods that work on relational data typically fall under the umbrella of IO P. We have propositional isation which is extracting information from these graphs and represented explicitly as a feature vector.",
            "So despondent makes a.",
            "Mines the grass for frequent substructures to work by rock as well, excuse me.",
            "I hope I LP systems represent their hypothesis explicitly, such as progol by Muggleton an tell the system as well.",
            "We have graph kernels, which is what we're going to be talking about today and.",
            "Family of graph kernels.",
            "We have labeled walk variance.",
            "These use feature spaces that are indexed by.",
            "What types, so in which are designated by the sequence of labels you get along the edges and vertices in the walk?",
            "A couple of good examples of these are the work by Gartner and colleagues Ann Cushman colleagues."
        ],
        [
            "We have to extend the definition of rock type for our situation because we're dealing with hypergraphs in that graphs we want to capture both.",
            "The edges and the edge types along the walk as as well as the entry points and exit points we are dealing with ordered hypergraphs because again in the relational setting a predicate has an ordering on the arguments.",
            "So we want to be able to capture that information.",
            "In this graph you can see we have simple 3 edge hypergraph and.",
            "Walk in this graph.",
            "We can go from the first edgy 1 to the second edgy two in the second edge E3.",
            "What's important about that is the type.",
            "I've had one is P and we go using the 5th Vertex in that edge to add another edge of type Q and to get into that edge we use the first position vertex.",
            "So every sort of segment of the walk we need to know the type of the vertex we're leaving.",
            "What position we're leaving it through.",
            "What position were entering the next edge and the type of that edge?",
            "And you can see down the bottom we can get.",
            "We can represent this substructure going P51Q so 5th type using the fifth position to exit first position to enter type Q and likewise for exit for entry three Type R. So that's the generalized walk type, so we only care about edge types and the positions, so we don't designate E1 or E2 in the walk type.",
            "This is equivalent to this conjunction.",
            "You can see down at the bottom with predicates, so for people coming from a relational perspective that that will make more sense.",
            "We have these edges just simply represented as predicates at the bottom, and this walk is a conjunction.",
            "So one important distinction to make here is that.",
            "Anne.",
            "Using these walk types, we can't capture wax that or we can't capture conjunctions in which two predicates share more than one vertex or argument, and we also can't capture long distance dependencies.",
            "So if one predicate has to share a vertex.",
            "With another predicate that are far apart in the conjunction, this will not be captured using this walk type."
        ],
        [
            "Language.",
            "What we'd like to do now that we have a walk type is taken in a product in the feature space index by all such walk types, so are ideal feature space.",
            "Here is over 2 edges, P1 and P2 from two different graphs, and this summation is an inner product, so it's a sum overall.",
            "What types W of length N and we multiply the count of that particular walk type starting at Edge P1 in graph G, one times the number of times that occurs.",
            "In Graph 2, starting at Edge P2.",
            "So again, W is a lock type and count just tells us how many times that walk appears starting at Edge P1.",
            "To get from there to a graph kernel, what we need to do or to hypergraph kernel rather is to just simply sum over all pairwise comparisons of edges in the graph you want in G2.",
            "And that's this first variant K prime.",
            "OK, never mind.",
            "And then following the escape, Prime sub and we see we have.",
            "This KD sub in an what that gives us is instead of just taking the fixed lock length of length N, we sum over all link walk links from 12 N. An and also in that variant you see there's a scammer to the I factor, which is a multiplicative factor and we can use that to either wait longer, longer walks more or to discount longer Passmore and finally and the final variant here on the bottom you can see we just normalize the middle variant, and that's what we're going to be using for our experiment."
        ],
        [
            "So how do we actually do this?",
            "We define the kernel recursively over edges.",
            "And the sort of halting condition is this case of 1, which is 1 only if two edges are of the same type, their labels are equal and 0 otherwise to get all parallel paths of certain walk type from.",
            "From one to N what we do is we define K7 / 2 edges.",
            "Via this formula on the bottom, and this is a little hard to read just off of a screen, but a couple of important things to remember.",
            "Or to take away from this or that, the first 2 summations are over the arguments in two edges.",
            "So in the final two summations are over edges in the graph, so that gives you an idea of the complexity of computing this.",
            "If we look at the well, go through just a quick example on the bottom we have 3 edge hypergraph an looking at this third summation.",
            "What we're looking for is starting at Edge E1.",
            "Pretend that edgy one is the argument P1 and what we're looking for is all edges incident to each one.",
            "Such that the 8th argument of P1 and in other words, our exit position is the Beath argument of the following edge and those have to match in both graphs G1 and G2 for us to be able to continue the path for it to be a legitimate walk type."
        ],
        [
            "So.",
            "Say A is 5 and B is 1.",
            "That means that we're looking for any edge instant to P1 such that it leaves via the 5th edge and enters the next edge via the first via the first vertex.",
            "Excuse me, so in this case.",
            "Looking at all the edges incident to P1, only one of the matches and that's this.",
            "This new E1 which is you can see using node V5.",
            "That's the 5th argument of P1 in the first argument of E1, so that would when the subscripts are fixed at that particular value.",
            "Those are the edges we would be summing over."
        ],
        [
            "Another quick example to show you when it wouldn't match the top two vertices at the top two edges are joined via the 5th vertex of the first one in the first vertex of the second one, whereas the bottom two are joined with the 4th vertex of the first one and the first vertex of the second one.",
            "So even though the edge types of the same these two, what types would not match?"
        ],
        [
            "So what we've developed is this.",
            "We handle multi area data directly, which gives us an advantage over previous methods which work only on graphs.",
            "We use bounded walk lengths instead of infinite walk links, and this allows us to compute kernel using a dynamic programming algorithm.",
            "Previous labeled walk variants use some kind of convergence, so they calculate all rock types from one to Infinity and they will use either some matrix power series or assist solving a system of linear equations in order to compute their kernel so we can avoid."
        ],
        [
            "That kind of computation, even in the graph case where we're doing something similar to previous graph kernels, our feature space is still significantly different in the following way.",
            "If you look at the star topology here, we.",
            "Using the labeled walk variance from previous work on the left of the screen, you can see that in order to capture this substructure will need.",
            "Walk of length 6 so going from starting from this vertex on the right of the star and following the edges labeled one through 6 in our edge kernel, our edge based hypergraph kernel we can capture this using for a length four walk.",
            "So in this particular case our feature space is more expressive."
        ],
        [
            "We ran experiments over 4 chemical datasets.",
            "The NCT.",
            "Our data set is.",
            "List of chemical compounds that are classified based on their ability to inhibit or or not inhibit estrogen reception.",
            "Predictive toxicology is another chemical data set in which.",
            "Chemicals are labeled based on whether or not they are toxic to male rats, female rats, male mice, and female mice, so they're actually four different labelings of that data set.",
            "The NCI HIV data set is chemical compounds.",
            "Again that are classified based on their ability to inhibit the HIV virus and some specific experimental setting.",
            "And finally we have mitogenesis.",
            "Which are chemicals classified based on their muted mutagenicity.",
            "2 interesting things here are the HIV data set, which is extremely large compared to the rest and also extremely skewed, so that is of course going to introduce a new set of challenges and mutagenesis.",
            "We have the only data set with high rarity edges, so.",
            "This is the only actual hypergraph data set, and this allows us to sort of explore.",
            "Weather how the use of hyperedges helps us improve."
        ],
        [
            "For graph kernels.",
            "Another dimension of our experiments is exploring edging coatings, so taking from previous work and notably Gardner, we have this way of encoding or coloring vertices, and we apply this back, changing the encoding of our edges to incorporate more information about the local substructure around them.",
            "In the initial data set were given.",
            "Is this encoding one designated L sub one V1 and that's just the bond label.",
            "It will sometimes it says bond type one or bond type 2, but that's simply the bond label."
        ],
        [
            "And types are encoded using unary edges.",
            "Expanding this, we have label labeling L sub two A V1."
        ],
        [
            "In which we incorporate the types of the nodes on either side of the bond so.",
            "We would now have the Type B."
        ],
        [
            "And the Type C encoded in this edge.",
            "Expanding that one more time to take into account the the types of the edges on the types of the nodes on either side of the edge as well."
        ],
        [
            "As their immediate neighborhood, we have encode finally encoding 3."
        ],
        [
            "So we will have type B with neighborhood AC."
        ],
        [
            "And type C with neighborhood."
        ],
        [
            "Abcd.",
            "We"
        ],
        [
            "The perception with margin and all of our experiments and explored the following major areas.",
            "Encoding how the encoding 1 two and three.",
            "Affect performance as well as walk length affects performance under those encodings.",
            "How discounting or incrementing pass using that multiplicative factor, I showed effective performance.",
            "Whether or not these higher rarity edges in mutagenesis give us any benefit, and finally just generally comparing to other."
        ],
        [
            "Methods on relational data.",
            "The encoding experiments were pretty cut and dried, and coding three vastly improved performance, which is something we would expect based on previous."
        ],
        [
            "Work.",
            "You can see here that using encoding, three were able to perform pretty well.",
            "Down at the bottom we have the results.",
            "In the bottom row of this table you'll see results from a paper that surveys various ilpo methods, and this is the best performance on this data set from that paper.",
            "So this is a comparison to an actual high LP method.",
            "The other rows, other walk length we use in the columns, are the encodings, so you can see over on the right under encoding three with this window of about two to."
        ],
        [
            "ETA five we're getting our best performance.",
            "Predictive toxicology data set on the top table you'll see again the second column is the walk length and we have our hypergraph kernel going over to the right.",
            "Then the last two columns are a kernel by ferlic, an colleagues Anna Colonel Bakushima and colleagues.",
            "And you can see that the walk length varies, so we ran with a short, medium and long walk length and we show the best performing version of our kernel there, and so even within the predictive toxicology data set were having various walk length be effective down at the bottom we have the NCI HIV data set and that's compared to a cyclic pattern kernel.",
            "Again, the left the rightmost two columns are cyclic pattern kernel.",
            "And this label.",
            "Other label lock variant."
        ],
        [
            "So discounting are incrementing experience were less interesting.",
            "We didn't see any improvement or change based on varying that multiplicative factor.",
            "As you saw the best length walk is data set dependent and even within that particular particular toxicology data set, we saw that it's very hard to predict or have any intuition about what walk length might be better."
        ],
        [
            "Finally, the role of hyper edges in me."
        ],
        [
            "Genesis, I actually made a small data preprocessing error, so these numbers are slightly different than what you'll see in the paper, but the relationships and conclusions are the same.",
            "You can see on the first.",
            "Let me explain the column, so again we have length along the rows and then going across we add various edges types back into the data set.",
            "So starting on the left we have Adam Bond.",
            "Then we add hyper edges in a B + H. Going further to the right we have this numerical quantities that were that are included in the data set and finally all the way on the right we have everything.",
            "The user under encoding one, we see that immediately adding the hyperedges lowers the walk length we need to perform.",
            "Our best.",
            "That's pretty intuitive because.",
            "Thinking about capturing substructures in the graph.",
            "It will take longer to capture a substructure using just simple Atom bond edges.",
            "Versus if we can use hyperedges that take into account a substructure with five or six vertices in them."
        ],
        [
            "The numerical properties were also extremely helpful and."
        ],
        [
            "Finally, encoding three is again showing us that it's extremely helpful.",
            "This might be somewhat surprising, but if you think about it, this is also intuitive that encoding three we're able to do quite well with a low walk length, and that makes sense because in the mutagenesis data set that hyper edges represent locally connected substructures.",
            "Thinking back to encoding three, we capture information about no types and their immediate neighborhood, so encoding three is seems to be providing the same kind of information to the kernel as hyperedge."
        ],
        [
            "And finally, our best area performance is pretty much throwing everything at it, and that's all the way on the right here."
        ],
        [
            "To sum up, we were able to show some competitive competitive results with the LP methods as well as previous graph kernels in the graph kernel.",
            "Case and when the data is a graph, we actually do use a different feature space and previous work.",
            "The hyper edges do seem to improve performance and the data encoding was clearly a critical factor going forward.",
            "We'd like to see if there's a way to use extend the hypergraph kernel to the case of the infinite path, and see how that may affect performance.",
            "The multi area data that we used was the mutagenesis data set, and again because those hyper edges were.",
            "Locally connected substructures it would be interesting to know if we could use datasets that have hyper edges that aren't so close to each other in the original graph, because these are capturable using a long enough path with just the regular Atom bond edges.",
            "Is there a way to capture this encoding 3 performance implicitly without having to preprocess it?",
            "And can we go back?",
            "Can run some of these I LP solvers that we compare ourselves to.",
            "And using coding three, would they also experience the same kind of improvement?",
            "And finally, most Interestingly, I think that we'd like to be able to capture more complex walk types, so these long distance dependencies that was talking about at the beginning conjunctions in which either 2 vertices are shared between two conjunctions, or there's one vertex has to be the same.",
            "Some argument way down the line would be really interesting to capture.",
            "So does are some of the problems we're looking at solving in the future.",
            "If anyone knows of good multi Arity datasets please come find me at some point.",
            "I'm hoping lots of people will come to me and say I've got these great datasets for you to work on so."
        ],
        [
            "Thank you very much for your time and I'll take questions.",
            "Pretty sensitive.",
            "Well, in the experiments where we were exploring walk length, we obviously.",
            "So in the.",
            "Sorry.",
            "So in the in this bottom one here we.",
            "Based on our previous experience, we said, well, we're going to.",
            "We ran using.",
            "I think 2 through 5 or something like that.",
            "They all ended up pretty much being the same, so we just put this one in here.",
            "Yeah, right so.",
            "Right, so we're sort of trying to explore multiple things here we we didn't explore across all walk links from 1 to 16.",
            "We did a short medium and along yeah.",
            "Right, absolutely this is a.",
            "This isn't meant to be, you know, our statistical Rust argument that ours is better.",
            "We're just trying to explore, but absolutely for anything, anything, yeah.",
            "I agree, thank you.",
            "Are you doing this?"
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How do I get full screen on this?",
                    "label": 0
                },
                {
                    "sent": "Can I get full screen?",
                    "label": 0
                },
                {
                    "sent": "Do you know how to?",
                    "label": 0
                },
                {
                    "sent": "You are looking for.",
                    "label": 0
                },
                {
                    "sent": "No, I'm OK.",
                    "label": 0
                },
                {
                    "sent": "Thank you all for coming.",
                    "label": 0
                },
                {
                    "sent": "I'm Gabriel Walkman and today I'm going to be talking about some research I did with Ronnie Cardone.",
                    "label": 0
                },
                {
                    "sent": "We developed a kernel that learns over hypergraphs, kernel that takes its input hypergraphs and we explored its performance in various experimental settings.",
                    "label": 0
                },
                {
                    "sent": "And I'll be talking about.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Add.",
                    "label": 0
                },
                {
                    "sent": "What do we want to learn from hypergraphs?",
                    "label": 0
                },
                {
                    "sent": "There's several interesting domains in which this could potentially be applicable.",
                    "label": 0
                },
                {
                    "sent": "Two of the primary ones are chemical data, which you can see here.",
                    "label": 0
                },
                {
                    "sent": "We have a simple water molecule that's represented as a graph.",
                    "label": 1
                },
                {
                    "sent": "And we also have relational data.",
                    "label": 1
                },
                {
                    "sent": "On the left of the screen you can see some predicates with objects and on the right of the screen you can see the equivalent hypergraph that you would obtain by drawing it.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So first I'll give some basic terminology and talk about what a kernel is and some other background, and then I'll talk about what exactly we did in some detail.",
                    "label": 0
                },
                {
                    "sent": "And the key ways in which our kernel differs from other previous methods.",
                    "label": 0
                },
                {
                    "sent": "Then I'll outline the experiments we did and the results we obtained, and finally I'll discuss some of the questions that were raised by our research that.",
                    "label": 0
                },
                {
                    "sent": "Remain open.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A kernel is simply a function that just takes you objects and computes their inner product in some feature space.",
                    "label": 1
                },
                {
                    "sent": "This is interesting.",
                    "label": 0
                },
                {
                    "sent": "In the graph case here you can see kernel might take one of these graphs and map it into feature space that is indexed by the types of atoms it contains.",
                    "label": 0
                },
                {
                    "sent": "So on the top graph G1 we have a hydrogen Atom and oxygen Atom and the resulting feature vector is there next to it and likewise in the graph mislabeled G1, but.",
                    "label": 0
                },
                {
                    "sent": "G2 is we have a carbon Atom in a hydrogen Atom.",
                    "label": 0
                },
                {
                    "sent": "The inner product of these is 1 an.",
                    "label": 0
                },
                {
                    "sent": "In this case, it's feasible that we might be able to do this explicitly, but the point is that the kernel can perform these operations without having to represent the feature space explicitly.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We can expand and complicate the feature space here.",
                    "label": 0
                },
                {
                    "sent": "We have features that are simple paths in the graph or simple walks in the in the graph and you can see that we have a in the top graph.",
                    "label": 0
                },
                {
                    "sent": "We have hydrogen, oxygen, hydrogen, an in the bottom graph.",
                    "label": 0
                },
                {
                    "sent": "We have hydrogen, carbon, carbon, hydrogen.",
                    "label": 0
                },
                {
                    "sent": "So again, we can continue to complicate this feature space as we will, but it gives you an idea.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yeah, of the kinds of features we might want to compute.",
                    "label": 0
                },
                {
                    "sent": "And the other methods that work on relational data typically fall under the umbrella of IO P. We have propositional isation which is extracting information from these graphs and represented explicitly as a feature vector.",
                    "label": 0
                },
                {
                    "sent": "So despondent makes a.",
                    "label": 0
                },
                {
                    "sent": "Mines the grass for frequent substructures to work by rock as well, excuse me.",
                    "label": 0
                },
                {
                    "sent": "I hope I LP systems represent their hypothesis explicitly, such as progol by Muggleton an tell the system as well.",
                    "label": 0
                },
                {
                    "sent": "We have graph kernels, which is what we're going to be talking about today and.",
                    "label": 1
                },
                {
                    "sent": "Family of graph kernels.",
                    "label": 0
                },
                {
                    "sent": "We have labeled walk variance.",
                    "label": 1
                },
                {
                    "sent": "These use feature spaces that are indexed by.",
                    "label": 0
                },
                {
                    "sent": "What types, so in which are designated by the sequence of labels you get along the edges and vertices in the walk?",
                    "label": 0
                },
                {
                    "sent": "A couple of good examples of these are the work by Gartner and colleagues Ann Cushman colleagues.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We have to extend the definition of rock type for our situation because we're dealing with hypergraphs in that graphs we want to capture both.",
                    "label": 0
                },
                {
                    "sent": "The edges and the edge types along the walk as as well as the entry points and exit points we are dealing with ordered hypergraphs because again in the relational setting a predicate has an ordering on the arguments.",
                    "label": 0
                },
                {
                    "sent": "So we want to be able to capture that information.",
                    "label": 0
                },
                {
                    "sent": "In this graph you can see we have simple 3 edge hypergraph and.",
                    "label": 1
                },
                {
                    "sent": "Walk in this graph.",
                    "label": 0
                },
                {
                    "sent": "We can go from the first edgy 1 to the second edgy two in the second edge E3.",
                    "label": 0
                },
                {
                    "sent": "What's important about that is the type.",
                    "label": 0
                },
                {
                    "sent": "I've had one is P and we go using the 5th Vertex in that edge to add another edge of type Q and to get into that edge we use the first position vertex.",
                    "label": 1
                },
                {
                    "sent": "So every sort of segment of the walk we need to know the type of the vertex we're leaving.",
                    "label": 0
                },
                {
                    "sent": "What position we're leaving it through.",
                    "label": 0
                },
                {
                    "sent": "What position were entering the next edge and the type of that edge?",
                    "label": 0
                },
                {
                    "sent": "And you can see down the bottom we can get.",
                    "label": 1
                },
                {
                    "sent": "We can represent this substructure going P51Q so 5th type using the fifth position to exit first position to enter type Q and likewise for exit for entry three Type R. So that's the generalized walk type, so we only care about edge types and the positions, so we don't designate E1 or E2 in the walk type.",
                    "label": 0
                },
                {
                    "sent": "This is equivalent to this conjunction.",
                    "label": 0
                },
                {
                    "sent": "You can see down at the bottom with predicates, so for people coming from a relational perspective that that will make more sense.",
                    "label": 0
                },
                {
                    "sent": "We have these edges just simply represented as predicates at the bottom, and this walk is a conjunction.",
                    "label": 0
                },
                {
                    "sent": "So one important distinction to make here is that.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "Using these walk types, we can't capture wax that or we can't capture conjunctions in which two predicates share more than one vertex or argument, and we also can't capture long distance dependencies.",
                    "label": 0
                },
                {
                    "sent": "So if one predicate has to share a vertex.",
                    "label": 0
                },
                {
                    "sent": "With another predicate that are far apart in the conjunction, this will not be captured using this walk type.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Language.",
                    "label": 0
                },
                {
                    "sent": "What we'd like to do now that we have a walk type is taken in a product in the feature space index by all such walk types, so are ideal feature space.",
                    "label": 0
                },
                {
                    "sent": "Here is over 2 edges, P1 and P2 from two different graphs, and this summation is an inner product, so it's a sum overall.",
                    "label": 0
                },
                {
                    "sent": "What types W of length N and we multiply the count of that particular walk type starting at Edge P1 in graph G, one times the number of times that occurs.",
                    "label": 1
                },
                {
                    "sent": "In Graph 2, starting at Edge P2.",
                    "label": 0
                },
                {
                    "sent": "So again, W is a lock type and count just tells us how many times that walk appears starting at Edge P1.",
                    "label": 0
                },
                {
                    "sent": "To get from there to a graph kernel, what we need to do or to hypergraph kernel rather is to just simply sum over all pairwise comparisons of edges in the graph you want in G2.",
                    "label": 0
                },
                {
                    "sent": "And that's this first variant K prime.",
                    "label": 0
                },
                {
                    "sent": "OK, never mind.",
                    "label": 0
                },
                {
                    "sent": "And then following the escape, Prime sub and we see we have.",
                    "label": 0
                },
                {
                    "sent": "This KD sub in an what that gives us is instead of just taking the fixed lock length of length N, we sum over all link walk links from 12 N. An and also in that variant you see there's a scammer to the I factor, which is a multiplicative factor and we can use that to either wait longer, longer walks more or to discount longer Passmore and finally and the final variant here on the bottom you can see we just normalize the middle variant, and that's what we're going to be using for our experiment.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how do we actually do this?",
                    "label": 0
                },
                {
                    "sent": "We define the kernel recursively over edges.",
                    "label": 0
                },
                {
                    "sent": "And the sort of halting condition is this case of 1, which is 1 only if two edges are of the same type, their labels are equal and 0 otherwise to get all parallel paths of certain walk type from.",
                    "label": 0
                },
                {
                    "sent": "From one to N what we do is we define K7 / 2 edges.",
                    "label": 0
                },
                {
                    "sent": "Via this formula on the bottom, and this is a little hard to read just off of a screen, but a couple of important things to remember.",
                    "label": 0
                },
                {
                    "sent": "Or to take away from this or that, the first 2 summations are over the arguments in two edges.",
                    "label": 0
                },
                {
                    "sent": "So in the final two summations are over edges in the graph, so that gives you an idea of the complexity of computing this.",
                    "label": 0
                },
                {
                    "sent": "If we look at the well, go through just a quick example on the bottom we have 3 edge hypergraph an looking at this third summation.",
                    "label": 0
                },
                {
                    "sent": "What we're looking for is starting at Edge E1.",
                    "label": 0
                },
                {
                    "sent": "Pretend that edgy one is the argument P1 and what we're looking for is all edges incident to each one.",
                    "label": 0
                },
                {
                    "sent": "Such that the 8th argument of P1 and in other words, our exit position is the Beath argument of the following edge and those have to match in both graphs G1 and G2 for us to be able to continue the path for it to be a legitimate walk type.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Say A is 5 and B is 1.",
                    "label": 0
                },
                {
                    "sent": "That means that we're looking for any edge instant to P1 such that it leaves via the 5th edge and enters the next edge via the first via the first vertex.",
                    "label": 0
                },
                {
                    "sent": "Excuse me, so in this case.",
                    "label": 0
                },
                {
                    "sent": "Looking at all the edges incident to P1, only one of the matches and that's this.",
                    "label": 0
                },
                {
                    "sent": "This new E1 which is you can see using node V5.",
                    "label": 0
                },
                {
                    "sent": "That's the 5th argument of P1 in the first argument of E1, so that would when the subscripts are fixed at that particular value.",
                    "label": 0
                },
                {
                    "sent": "Those are the edges we would be summing over.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another quick example to show you when it wouldn't match the top two vertices at the top two edges are joined via the 5th vertex of the first one in the first vertex of the second one, whereas the bottom two are joined with the 4th vertex of the first one and the first vertex of the second one.",
                    "label": 0
                },
                {
                    "sent": "So even though the edge types of the same these two, what types would not match?",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what we've developed is this.",
                    "label": 0
                },
                {
                    "sent": "We handle multi area data directly, which gives us an advantage over previous methods which work only on graphs.",
                    "label": 1
                },
                {
                    "sent": "We use bounded walk lengths instead of infinite walk links, and this allows us to compute kernel using a dynamic programming algorithm.",
                    "label": 0
                },
                {
                    "sent": "Previous labeled walk variants use some kind of convergence, so they calculate all rock types from one to Infinity and they will use either some matrix power series or assist solving a system of linear equations in order to compute their kernel so we can avoid.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That kind of computation, even in the graph case where we're doing something similar to previous graph kernels, our feature space is still significantly different in the following way.",
                    "label": 0
                },
                {
                    "sent": "If you look at the star topology here, we.",
                    "label": 0
                },
                {
                    "sent": "Using the labeled walk variance from previous work on the left of the screen, you can see that in order to capture this substructure will need.",
                    "label": 0
                },
                {
                    "sent": "Walk of length 6 so going from starting from this vertex on the right of the star and following the edges labeled one through 6 in our edge kernel, our edge based hypergraph kernel we can capture this using for a length four walk.",
                    "label": 0
                },
                {
                    "sent": "So in this particular case our feature space is more expressive.",
                    "label": 1
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We ran experiments over 4 chemical datasets.",
                    "label": 0
                },
                {
                    "sent": "The NCT.",
                    "label": 0
                },
                {
                    "sent": "Our data set is.",
                    "label": 0
                },
                {
                    "sent": "List of chemical compounds that are classified based on their ability to inhibit or or not inhibit estrogen reception.",
                    "label": 0
                },
                {
                    "sent": "Predictive toxicology is another chemical data set in which.",
                    "label": 0
                },
                {
                    "sent": "Chemicals are labeled based on whether or not they are toxic to male rats, female rats, male mice, and female mice, so they're actually four different labelings of that data set.",
                    "label": 0
                },
                {
                    "sent": "The NCI HIV data set is chemical compounds.",
                    "label": 0
                },
                {
                    "sent": "Again that are classified based on their ability to inhibit the HIV virus and some specific experimental setting.",
                    "label": 0
                },
                {
                    "sent": "And finally we have mitogenesis.",
                    "label": 0
                },
                {
                    "sent": "Which are chemicals classified based on their muted mutagenicity.",
                    "label": 0
                },
                {
                    "sent": "2 interesting things here are the HIV data set, which is extremely large compared to the rest and also extremely skewed, so that is of course going to introduce a new set of challenges and mutagenesis.",
                    "label": 0
                },
                {
                    "sent": "We have the only data set with high rarity edges, so.",
                    "label": 0
                },
                {
                    "sent": "This is the only actual hypergraph data set, and this allows us to sort of explore.",
                    "label": 0
                },
                {
                    "sent": "Weather how the use of hyperedges helps us improve.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For graph kernels.",
                    "label": 0
                },
                {
                    "sent": "Another dimension of our experiments is exploring edging coatings, so taking from previous work and notably Gardner, we have this way of encoding or coloring vertices, and we apply this back, changing the encoding of our edges to incorporate more information about the local substructure around them.",
                    "label": 0
                },
                {
                    "sent": "In the initial data set were given.",
                    "label": 0
                },
                {
                    "sent": "Is this encoding one designated L sub one V1 and that's just the bond label.",
                    "label": 0
                },
                {
                    "sent": "It will sometimes it says bond type one or bond type 2, but that's simply the bond label.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And types are encoded using unary edges.",
                    "label": 0
                },
                {
                    "sent": "Expanding this, we have label labeling L sub two A V1.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In which we incorporate the types of the nodes on either side of the bond so.",
                    "label": 0
                },
                {
                    "sent": "We would now have the Type B.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the Type C encoded in this edge.",
                    "label": 0
                },
                {
                    "sent": "Expanding that one more time to take into account the the types of the edges on the types of the nodes on either side of the edge as well.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As their immediate neighborhood, we have encode finally encoding 3.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we will have type B with neighborhood AC.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And type C with neighborhood.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Abcd.",
                    "label": 0
                },
                {
                    "sent": "We",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The perception with margin and all of our experiments and explored the following major areas.",
                    "label": 1
                },
                {
                    "sent": "Encoding how the encoding 1 two and three.",
                    "label": 0
                },
                {
                    "sent": "Affect performance as well as walk length affects performance under those encodings.",
                    "label": 1
                },
                {
                    "sent": "How discounting or incrementing pass using that multiplicative factor, I showed effective performance.",
                    "label": 0
                },
                {
                    "sent": "Whether or not these higher rarity edges in mutagenesis give us any benefit, and finally just generally comparing to other.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Methods on relational data.",
                    "label": 0
                },
                {
                    "sent": "The encoding experiments were pretty cut and dried, and coding three vastly improved performance, which is something we would expect based on previous.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Work.",
                    "label": 0
                },
                {
                    "sent": "You can see here that using encoding, three were able to perform pretty well.",
                    "label": 0
                },
                {
                    "sent": "Down at the bottom we have the results.",
                    "label": 0
                },
                {
                    "sent": "In the bottom row of this table you'll see results from a paper that surveys various ilpo methods, and this is the best performance on this data set from that paper.",
                    "label": 0
                },
                {
                    "sent": "So this is a comparison to an actual high LP method.",
                    "label": 0
                },
                {
                    "sent": "The other rows, other walk length we use in the columns, are the encodings, so you can see over on the right under encoding three with this window of about two to.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "ETA five we're getting our best performance.",
                    "label": 0
                },
                {
                    "sent": "Predictive toxicology data set on the top table you'll see again the second column is the walk length and we have our hypergraph kernel going over to the right.",
                    "label": 0
                },
                {
                    "sent": "Then the last two columns are a kernel by ferlic, an colleagues Anna Colonel Bakushima and colleagues.",
                    "label": 0
                },
                {
                    "sent": "And you can see that the walk length varies, so we ran with a short, medium and long walk length and we show the best performing version of our kernel there, and so even within the predictive toxicology data set were having various walk length be effective down at the bottom we have the NCI HIV data set and that's compared to a cyclic pattern kernel.",
                    "label": 0
                },
                {
                    "sent": "Again, the left the rightmost two columns are cyclic pattern kernel.",
                    "label": 0
                },
                {
                    "sent": "And this label.",
                    "label": 0
                },
                {
                    "sent": "Other label lock variant.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So discounting are incrementing experience were less interesting.",
                    "label": 0
                },
                {
                    "sent": "We didn't see any improvement or change based on varying that multiplicative factor.",
                    "label": 0
                },
                {
                    "sent": "As you saw the best length walk is data set dependent and even within that particular particular toxicology data set, we saw that it's very hard to predict or have any intuition about what walk length might be better.",
                    "label": 1
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Finally, the role of hyper edges in me.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Genesis, I actually made a small data preprocessing error, so these numbers are slightly different than what you'll see in the paper, but the relationships and conclusions are the same.",
                    "label": 0
                },
                {
                    "sent": "You can see on the first.",
                    "label": 0
                },
                {
                    "sent": "Let me explain the column, so again we have length along the rows and then going across we add various edges types back into the data set.",
                    "label": 0
                },
                {
                    "sent": "So starting on the left we have Adam Bond.",
                    "label": 0
                },
                {
                    "sent": "Then we add hyper edges in a B + H. Going further to the right we have this numerical quantities that were that are included in the data set and finally all the way on the right we have everything.",
                    "label": 0
                },
                {
                    "sent": "The user under encoding one, we see that immediately adding the hyperedges lowers the walk length we need to perform.",
                    "label": 0
                },
                {
                    "sent": "Our best.",
                    "label": 0
                },
                {
                    "sent": "That's pretty intuitive because.",
                    "label": 0
                },
                {
                    "sent": "Thinking about capturing substructures in the graph.",
                    "label": 0
                },
                {
                    "sent": "It will take longer to capture a substructure using just simple Atom bond edges.",
                    "label": 0
                },
                {
                    "sent": "Versus if we can use hyperedges that take into account a substructure with five or six vertices in them.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The numerical properties were also extremely helpful and.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Finally, encoding three is again showing us that it's extremely helpful.",
                    "label": 0
                },
                {
                    "sent": "This might be somewhat surprising, but if you think about it, this is also intuitive that encoding three we're able to do quite well with a low walk length, and that makes sense because in the mutagenesis data set that hyper edges represent locally connected substructures.",
                    "label": 0
                },
                {
                    "sent": "Thinking back to encoding three, we capture information about no types and their immediate neighborhood, so encoding three is seems to be providing the same kind of information to the kernel as hyperedge.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And finally, our best area performance is pretty much throwing everything at it, and that's all the way on the right here.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To sum up, we were able to show some competitive competitive results with the LP methods as well as previous graph kernels in the graph kernel.",
                    "label": 1
                },
                {
                    "sent": "Case and when the data is a graph, we actually do use a different feature space and previous work.",
                    "label": 0
                },
                {
                    "sent": "The hyper edges do seem to improve performance and the data encoding was clearly a critical factor going forward.",
                    "label": 1
                },
                {
                    "sent": "We'd like to see if there's a way to use extend the hypergraph kernel to the case of the infinite path, and see how that may affect performance.",
                    "label": 0
                },
                {
                    "sent": "The multi area data that we used was the mutagenesis data set, and again because those hyper edges were.",
                    "label": 1
                },
                {
                    "sent": "Locally connected substructures it would be interesting to know if we could use datasets that have hyper edges that aren't so close to each other in the original graph, because these are capturable using a long enough path with just the regular Atom bond edges.",
                    "label": 0
                },
                {
                    "sent": "Is there a way to capture this encoding 3 performance implicitly without having to preprocess it?",
                    "label": 0
                },
                {
                    "sent": "And can we go back?",
                    "label": 0
                },
                {
                    "sent": "Can run some of these I LP solvers that we compare ourselves to.",
                    "label": 0
                },
                {
                    "sent": "And using coding three, would they also experience the same kind of improvement?",
                    "label": 0
                },
                {
                    "sent": "And finally, most Interestingly, I think that we'd like to be able to capture more complex walk types, so these long distance dependencies that was talking about at the beginning conjunctions in which either 2 vertices are shared between two conjunctions, or there's one vertex has to be the same.",
                    "label": 0
                },
                {
                    "sent": "Some argument way down the line would be really interesting to capture.",
                    "label": 0
                },
                {
                    "sent": "So does are some of the problems we're looking at solving in the future.",
                    "label": 0
                },
                {
                    "sent": "If anyone knows of good multi Arity datasets please come find me at some point.",
                    "label": 0
                },
                {
                    "sent": "I'm hoping lots of people will come to me and say I've got these great datasets for you to work on so.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Thank you very much for your time and I'll take questions.",
                    "label": 1
                },
                {
                    "sent": "Pretty sensitive.",
                    "label": 0
                },
                {
                    "sent": "Well, in the experiments where we were exploring walk length, we obviously.",
                    "label": 0
                },
                {
                    "sent": "So in the.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "So in the in this bottom one here we.",
                    "label": 0
                },
                {
                    "sent": "Based on our previous experience, we said, well, we're going to.",
                    "label": 0
                },
                {
                    "sent": "We ran using.",
                    "label": 0
                },
                {
                    "sent": "I think 2 through 5 or something like that.",
                    "label": 0
                },
                {
                    "sent": "They all ended up pretty much being the same, so we just put this one in here.",
                    "label": 0
                },
                {
                    "sent": "Yeah, right so.",
                    "label": 0
                },
                {
                    "sent": "Right, so we're sort of trying to explore multiple things here we we didn't explore across all walk links from 1 to 16.",
                    "label": 0
                },
                {
                    "sent": "We did a short medium and along yeah.",
                    "label": 0
                },
                {
                    "sent": "Right, absolutely this is a.",
                    "label": 0
                },
                {
                    "sent": "This isn't meant to be, you know, our statistical Rust argument that ours is better.",
                    "label": 0
                },
                {
                    "sent": "We're just trying to explore, but absolutely for anything, anything, yeah.",
                    "label": 0
                },
                {
                    "sent": "I agree, thank you.",
                    "label": 0
                },
                {
                    "sent": "Are you doing this?",
                    "label": 0
                }
            ]
        }
    }
}