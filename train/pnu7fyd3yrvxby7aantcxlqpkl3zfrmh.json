{
    "id": "pnu7fyd3yrvxby7aantcxlqpkl3zfrmh",
    "title": "Tracking dynamic point processes on networks",
    "info": {
        "author": [
            "Rebecca Willett, Department of Electrical and Computer Engineering, University of Wisconsin-Madison"
        ],
        "published": "Oct. 29, 2014",
        "recorded": "September 2014",
        "category": [
            "Top->Computer Science->Digital Signal Processing",
            "Top->Computer Science->Machine Learning->Computational Learning Theory",
            "Top->Computer Science->Machine Learning->Deep Learning",
            "Top->Computer Science->Information Theory",
            "Top->Mathematics->Statistics"
        ]
    },
    "url": "http://videolectures.net/sahd2014_willett_tracking_dynamic/",
    "segmentation": [
        [
            "Thank you very much.",
            "It's a real pleasure to be here today and to see so many old friends and familiar faces.",
            "I'd like to tell you today about some work that I've done with my student Eric Hall on tracking influences within dynamic networks and in general the kinds of problems that we're interested in exploring here involve cascading chains of interactions among agents within a network.",
            "So, for example, you could imagine a social network where different members of the social network have influence.",
            "Over one another and when one person acts within that social network, it triggers actions among other people within that network, and this arises in many different contexts.",
            "For instance, you could imagine how Internet memes propagate among friends on social media.",
            "If I like something on Facebook, then the people who are influenced by me are likely to like it as well."
        ],
        [
            "We also see cascading chains of interactions in the context of gang violence.",
            "So Andrea Bertozzi at UCLA studied how one gang attacking a member of another gang would trigger retaliatory action in the future.",
            "And we also see these kind of cascading chains of interactions in nation state conflicts, especially when there are proxy wars and proxy actions in play.",
            "So the question is, in these kinds of social networks, can we infer who?",
            "Who is influencing what is this underlying network of influences and can we track it as it evolves overtime?",
            "Simmer."
        ],
        [
            "Situations arise in Epidemiology, so you could imagine every time one person gets sick.",
            "People within our neighbors of that that sick person might start to exhibit symptoms, and we'd like to be able to figure out how a disease is most likely to spread, and how different policy's like quarantine or how we.",
            "Treat deal can help stem the spread of an epidemic, and so we'd like to be able to infer these patterns of actions or the spread of disease in this network of people.",
            "Some of my former colleagues at Duke even combined the two problems of studying Epidemiology and social networks when they studied social networks of prostitutes and Johns and tried to understand how.",
            "Sexually transmitted diseases were spread throughout this network.",
            "I don't have a picture for that.",
            "Uh, we"
        ],
        [
            "You see similar problems in neurobiology and so you could in each of you.",
            "Hopefully you've got multiple neurons that are spiky and those spikes trigger spikes in the neighboring neurons and there are physical connections between the neurons and we can see those using different imaging techniques, but biologists believe that not all of those connections are active all the time, but rather there are functional networks that some of those actions or those influences between neurons are different depending on what task you're engaged in weather your way.",
            "Walking or sleeping or reading, and So what we'd like to be able to do is to infer this functional network and track how it changes in response to external stimuli or in response to to the task that you're engaged in."
        ],
        [
            "Finally, we see these kind of cascading chains of interactions in seismology.",
            "So in the news we might read about a single earthquake in the damage that it causes by in reality there's often a four shock that occurs before the main shock, and that's followed by multiple aftershocks.",
            "And so seismologists believe that these have these sort of this kind of causal relationship that there is this underlying sort of network or chain of of reactions, and we'd like to understand.",
            "How that works so that we can better predict when something damaging is about to occur.",
            "So in all of these settings, what we'd like to infer is how likely future actions are and how different actors within the network are influencing one another."
        ],
        [
            "Oh, I'm sorry.",
            "Not one more application.",
            "Finance financial institutions obviously influence one another move."
        ],
        [
            "On here, so the sequence of events that we're interested that would sort of like to follow is the following.",
            "At each time T, we'd like to make an observation XD.",
            "So for instance, in our social network setting, XD could correspond to which person acted at time T. And then we would like to incur a loss base that says how well we were able to predict that action given our current estimate.",
            "So Theta hat T is our current estimate and we can compute a negative log likelihood, for instance.",
            "That would tell us how well they'd had T predicted are observed actions XD.",
            "And then based on that loss or the accuracy of that former prediction, we'd like to update our prediction for the next time step.",
            "So the question is, well, how do we make these predictions and how do we leverage this loss in order to have good, highly accurate predictions?",
            "And the way we're going to judge the efficacy of our prediction scheme is with the notion called regret here.",
            "So our series of estimates overtime is going to be this series of Theta hat tease.",
            "And we're going to compare the total cumulative sum of losses for our estimates with the total cumulative sum of losses for some alternative comparative sequence.",
            "These Theta tease.",
            "And you can think about this comparative sequence as corresponding to what you might have computed if you had more computational resources.",
            "If you weren't trying to work in an online environment with streaming data.",
            "And what we'd like to be able to show is that given the same set of data that we're doing nearly as well with an efficient online algorithm as you might have done with a far more complex, possibly batch algorithm, and so the lower this regret is, the better we're doing relative to that comparator.",
            "So our goal is to come up with some sort of prediction scheme that's going to ensure that this average per round regret is going to zero as quickly as possible, as T gets larger and larger.",
            "OK, so on line learning has a long and rich."
        ],
        [
            "History and there are variety of methods out there.",
            "One particularly popular and well understood method is called Mirror descent, and it says that we should make our predictions according to the following scheme.",
            "At time T we should choose or we should search over all possible predictions and choose one that's well aligned to the gradient of the loss that we just observed.",
            "So that correspond that's moving in the direction of the negative gradient to the loss.",
            "And which is close to our last prediction as measured by a Bregman divergences.",
            "So in this special case where this Bregman divergences a squared Euclidean norm, then this amounts to something like stochastic gradient descent.",
            "So let's just think about what would happen if we tried to apply this kind of scheme to our cascading chains of events.",
            "The first thing we have to do is to come up with a good loss function, and I mentioned that negative log likelihood was a strong candidate, but we need to think about what that likelihood function should look like.",
            "The kinds of data were."
        ],
        [
            "Being here corresponds to point process data, so our observations are of the form where we know who acted and at what time they acted.",
            "So we basically have all this timing information of events within this network.",
            "So we can think about this as a multivariate point process.",
            "So for each node in our network K, we're going to have a different kind of point process which corresponds to the times at which at which actor a acted.",
            "So I've got that represented graphically here.",
            "These little red bars would correspond to the times at which a person acted.",
            "Traditionally, this is represented with this kind of cumulative sum of the number of actions that have a curd at any given time, and that's represented with the green curve and what we're interested.",
            "In is the blue curve, the rate function which gives us the likelihood of an event occurring at any given time.",
            "So in particular, if we were interested in the likelihood of node K participating in an event over some interval of time, it would be controlled by the integral of this rate function you, so we're interested in understanding this rate function knew for all the different actors in our network.",
            "So we can use this in order to."
        ],
        [
            "Form a loss function.",
            "So given all of.",
            "Excuse me given all of the events up to some time T, we can compute a log likelihood just using standard point process theory and we can come up with a discretized version where we've discretized time to intervals Delta.",
            "That looks like this very simple sum of inner products.",
            "We've got the inner product between our rate and a ones vector, and the inner product between our observation and the log of the rate.",
            "So what we can do is we can use this log likelihood expression to come up with a loss function that we could use in an algorithm like mirror descent, and so this loss function here corresponds exactly to one of the terms within this expression.",
            "For the negative log likelihood.",
            "It's going to be helpful as we go along to realize that we could write things in terms of this rate parameter, mu, which is the kind of proportional to the likelihood of an event occurring at any given time.",
            "Or we could write it in terms of the log rate, which I'm going to write Theta and working with the law great gives us several different computational and mathematical advantages that will see as we go along here.",
            "OK, but we can work in either parameter space so."
        ],
        [
            "If we now try to apply mirror descent using this loss function that we've constructed, so this is the look, sorry.",
            "So we use the loss function from the previous slide.",
            "We've got a simple expression for the gradient and we can have our print Bregman divergences within that mirror descent expression correspond to the KL divergences between two point processes.",
            "Then this expression for mirror descent that we were looking at before can be solved in closed form.",
            "So we've got these very simple closed form updates for the rate or for the log rate.",
            "So let's see what we can say about."
        ],
        [
            "Regret associated with a procedure like this in this context.",
            "The classical kinds of regret bounds assume that our parameter that we're interested in estimating or tracking is unchanging overtime, so we're comparing our series of estimates.",
            "These Theta hat tease with the single best point estimate.",
            "That's not changing overtime, and you can get a regret bound that scales like square root T using classical techniques, but it's also kind of meaningless, right?",
            "We're very interested in situations where this true rate is changing overtime, right?",
            "We're interested in these networks where.",
            "The rate is dependent on previous actions in the network, so things are inherently very dynamic, and so we might be able to get a little regret, but it won't necessarily mean that our method is doing anything useful."
        ],
        [
            "We can also compute tracking regret bounds where we're comparing the performance of our series of estimates.",
            "These state ahead tease with an arbitrary sequence of Theta tease.",
            "Anna tracking.",
            "Regret bound typically has a form like this.",
            "It looks like sqrt T * A variation term that measures how much are compared or sequences changing overtime.",
            "And so if that comparative sequences say piecewise constant or piecewise static overtime, or changing extremely slowly, then methods like mirror descent will give us low regret.",
            "But of course we've got this sort of inherent dynamic aspect to our problem, so again, this isn't useful in many of the applications that we discussed up front.",
            "OK, so to try to understand how we can get better bounds that are more relevant to the applications at hand, we need to take a step back and think more about the underlying point process that's helping us to generate this data.",
            "So far we haven't really talked much about the underlying network and its role in all of this."
        ],
        [
            "I'm going to use a something called the multivariate Hawkes process to model our observations and if I just show you the point process equations, it's a little ugly, so I'm going to kind of demonstrate this graphically.",
            "The idea is that one actor in our network does some action like like something on Facebook and that's going to change."
        ],
        [
            "Change the rate functions associated with the other people in the network so she maybe has more influence over the blue person and so he has this increased likelihood of acting and less so influence over the yellow person, and so she has increased.",
            "Perhaps likelihood of acting, but not as strongly increased as this guy.",
            "So then, based on these increase."
        ],
        [
            "Straight functions, perhaps the blue guy acts and he's going."
        ],
        [
            "To trigger a change in the rate functions associated with his neighbors within this social network."
        ],
        [
            "And that's going to trigger an action."
        ],
        [
            "Green person at."
        ],
        [
            "Cetera and so."
        ],
        [
            "I can see every time."
        ],
        [
            "Somebody acts."
        ],
        [
            "Is change."
        ],
        [
            "Pushing the rate fund."
        ],
        [
            "Oceans, asos"
        ],
        [
            "Created with all the other people within this network and that's the basic idea of this multivariate Hawkes process.",
            "So what we'd like to do?"
        ],
        [
            "So is to take."
        ],
        [
            "Observations that just correspond to who acted when, and from that infer."
        ],
        [
            "All these nice, pretty colorful curves, so we'd like to understand what these patterns of influences are."
        ],
        [
            "So a little bit more precisely what a multivariate Hawkes process does is it assumes that this rate function, let's say for person K. Has the following form.",
            "It's the sum of sum average background rate plus the sum of these influence functions where we have the influence function between person K and its neighbor K in, and we're evaluating that function based on how long ago neighbor Kate and acted.",
            "OK, so we're saying exactly what the picture is."
        ],
        [
            "You said that this rate function H sort of looks like this little curve here and its placement along time corresponds to how long ago this red person acted.",
            "OK, so."
        ],
        [
            "I've got this very nice relationship between the rates at time Tau and the history of events up to time tell and what we're going to do is we're going to make a simplifying assumption here that these rate functions all have the same form.",
            "They correspond to a scalar amplitude WKC N times a common H function, so all of these influence functions have the same shape like in our graphical representation, but they've got different amplitudes.",
            "And so when we talk about estimating the underlying network, what we really mean is we're trying to estimate this matrix of amplitudes or this matrix of numbers that indicates how much each person is influencing every other person or every other actor within this network.",
            "So our objective is to track these rates.",
            "These mus for all actors in the network and the underlying network W using streaming observations.",
            "OK, so the."
        ],
        [
            "Question is, how do we actually make this work in our online learning setting?",
            "The first thing to notice that when we have this sort of Hox model for how intensities change overtime, we can kind of think about that as being a dynamical model.",
            "So given a rate at time T we can make a prediction of what we think the rate at time T + 1 should be.",
            "Using this matrix W. And So what we'd like to be able to do is to incorporate this concept of a dynamical model into a method like mirror descent.",
            "So in the next slide, I'm going to have this capital, Phi here correspond to our dynamical model."
        ],
        [
            "So if we had a collection of dynamical models, one for each time step, then we can use a variant of mirror descent in order to make our predictions.",
            "We would say at each time T what we're going to do is again search over all possible predictions.",
            "Choose something that's aligned with the gradient of our loss and close in terms of Bregman divergences.",
            "But when we evaluate this gradient, and when we evaluate this Bregman divergences, we're going to incorporate our dynamical model fee.",
            "And so we're taking this dynamical model into account every step of the way, and then we can show is that if you do this for a modest increase in computational cost.",
            "And if your dynamical models satisfy a contractive property which basically says if I've got two different rates and I apply the same dynamical model to them, they get closer together, not farther apart.",
            "Then we get a regret bounds that looks similar in form to the other regret bounds.",
            "We've looked in sqrt T * A variation term, but now our variation term is going to measure how much are compared or sequence is deviating from our dynamical model as opposed to measuring how flat and constant it is.",
            "And so this tells us if we've got some good dynamical models that are accurate predictors of what is going on in the network, then we're going to be able to get achieve a very low regret.",
            "We're going to be able to do as well as a batch algorithm for a much broader class of problems.",
            "And for a much broader class of networks.",
            "OK, now going back to our let me just say it."
        ],
        [
            "Couple of words about this contract evety condition.",
            "We said that the dynamical model has to move two different rate functions closer together instead of further apart, and so you might ask, well, how much of a restriction is this, or how much is this really constraining us?",
            "Essentially, what this condition means in our particular multivariate Hawkes context is that when we apply our dynamical model, we're not going to force this likelihood of events to go negative, right?",
            "We've got this rate function, mu, which is proportional to the likelihood of a person or an agent acting in our network, and that inherently needs to be non negative.",
            "So as long as elements of RW matrix and our old rates are non negative.",
            "Then we satisfy this contract tivity property without any problem."
        ],
        [
            "OK, so we've got a way to incorporate dynamical models into mirror descent and based on the multivariate Hawkes process we have nice forms of dynamical models that are relevant to the kinds of data that we're interested in analyzing.",
            "The problem, however, is that this is that we don't fully know these dynamical models because they are a function of W. So W is the network this matrix of amplitudes which we're trying to estimate or track.",
            "It's completely unknown when we start off, and so we'd like to be able to track it or to learn the ideal dynamical model as we go along and receive more data.",
            "You could say, well, I mean just consider a finite set of candidate WS.",
            "Try 'em all out in parallel and do something like prediction with expert advice to hone in on whichever one is working best at any given time.",
            "And that's a reasonable solution.",
            "But if you think about having a network with hundreds of nodes, then W is hundreds of nodes squared.",
            "It's large, and if you try to discretize the space of all possible W matrix, it gets very big very quickly, and so that's not really a viable solution.",
            "In general, the big challenge that we face is that if we start using some estimate of W and perform this sort of dynamic mirror descent using that W doesn't provide us any information about how well we might have done if we used some W prime.",
            "Some other matrix of representing the underlying network.",
            "This is generally the case, but Fortunately in our multivariate Hawkes setting we can sidestep the challenge in a pretty neat way."
        ],
        [
            "OK, so we've got this, this lemma, which looks messier than it really is.",
            "All it's really saying is that, let's say we were doing tracking.",
            "We were running our method with some assumed estimate W prime.",
            "I'm sorry with some assumed estimate W prime, so we know our estimates of the rates using W prime at time T. And our limit tells us that we can always compute the estimates that we would have gotten if we had been using W from the very beginning via a simple linear transformation of this previous of this estimate with W prime.",
            "So we can use whatever W we want, and at any given time we can figure out what estimate we would have had with any other W. And this is very important because it's going to allow us to track both them using the WS.",
            "Both the rates in the underlying network simultaneously, and very, very computationally efficiently."
        ],
        [
            "OK, so the basic idea is the following.",
            "At any given time, we can compute how our loss associated with our current estimate of the network W and the gradient of that loss using the lemma from the previous slide, and then we can apply something like Mirror descent to update our estimate of that network or influence matrix.",
            "Given that, then we can simply apply this dynamic mirror descent method that I described before and do some simple bookkeeping, and we're going to have a method that is tracking both them, use the thetas and the WS simultaneously.",
            "OK, so every step in here is very computationally efficient and it's very well suited to high dimensional problems."
        ],
        [
            "So our main result is the following.",
            "If we use this kind of procedure where we're trying to track the WS and the Muse simultaneously, then we get a regret that has the same form that we've seen all along sqrt T * A variation term.",
            "But now our variation term corresponds to the smallest possible variation that we could have gotten with any W we considered.",
            "So this is telling us that with the kind of procedure that I just described, we're trying to track WMU simultaneously.",
            "We are going to do nearly as well as if some Oracle had told us the very best Mewtwo use from the very beginning.",
            "OK, so let."
        ],
        [
            "See some of this in action in this particular case, just to highlight a couple of aspects of this.",
            "I have W known, so we're just using that dynamic mirror descent method with a known underlying influence matrix.",
            "And what we see at the bottom here are the true rate in red covered up by this discretized approximation that we're using throughout in Cyan.",
            "And so we see that the discretization is really not hurting anything.",
            "The blue corresponds to what you would get if you tried to just track the network W directly, but if you didn't, if you had some model mismatch.",
            "If you didn't know all the parameters of your system exactly, then because you're not tracking the rates them use along with the WS you incur larger losses than if you try to track both of them simultaneously, and we see this when we look at average per round loss or from a different perspective.",
            "If we were to just look at the instantaneous loss.",
            "Smooth slightly so you can visualize it better.",
            "OK, we."
        ],
        [
            "W is unknown.",
            "We see a similar effect, so the blue curve here corresponds to what you would get with standard online learning algorithms, which essentially assumed that that network has no edges anywhere, so it's not a network.",
            "It assumes that that W matrix is zero everywhere, and so you can see it performs very poorly.",
            "The red curve corresponds to what you would get if you just did stand stochastic gradient descent directly on W and assume everything else about the system is known exactly.",
            "If you are wrong about those assumptions, then you are going to get consistently higher losses than you would get with the proposed algorithm that I'm describing here, where you're tracking both these influence matrices and the rates simultaneously and again, we see this both in terms of cumulative loss or in terms of this instantaneous loss.",
            "Alright, finally we examined given the zesta."
        ],
        [
            "How well can we detect the significant or high weight edges within this network?",
            "And we plotted some tomorrow, see curves.",
            "So the purple curve corresponds to how well we can detect significant edges.",
            "If you just try to track W and assume you know everything else about the system in or perhaps wrong.",
            "And the cyan curve corresponds to how well you can detect those significant edges in using the method that we developed here.",
            "The blue and the red or the same thing.",
            "Our method versus standard gradient descent.",
            "Stochastic gradient descent when you do know all of the system parameters exactly and there's no errors whatsoever, and so in that idealized scenario, there is very little difference between the performance of the two methods.",
            "But once you start having model mismatch, you start to see more significant gap between.",
            "The performance you can get with standard stochastic gradient descent and the approach I'm describing here."
        ],
        [
            "Alright, so to conclude, what we've developed are some online learning techniques that are pretty significantly different from standard on line learning methods, and that they give us a nice principled way for incorporating notions of system dynamics.",
            "So they give us unique regret bounds, and they give us a way to handle things like multivariate Hawkes data.",
            "We've got these nice theoretical performance bounds, but they're also extremely computationally efficient, which is nice for some of the very large scale.",
            "Data analysis problems that I described at the beginning."
        ],
        [
            "So with that, thank you very much and I'd be happy answer any questions."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Thank you very much.",
                    "label": 0
                },
                {
                    "sent": "It's a real pleasure to be here today and to see so many old friends and familiar faces.",
                    "label": 0
                },
                {
                    "sent": "I'd like to tell you today about some work that I've done with my student Eric Hall on tracking influences within dynamic networks and in general the kinds of problems that we're interested in exploring here involve cascading chains of interactions among agents within a network.",
                    "label": 1
                },
                {
                    "sent": "So, for example, you could imagine a social network where different members of the social network have influence.",
                    "label": 0
                },
                {
                    "sent": "Over one another and when one person acts within that social network, it triggers actions among other people within that network, and this arises in many different contexts.",
                    "label": 0
                },
                {
                    "sent": "For instance, you could imagine how Internet memes propagate among friends on social media.",
                    "label": 0
                },
                {
                    "sent": "If I like something on Facebook, then the people who are influenced by me are likely to like it as well.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We also see cascading chains of interactions in the context of gang violence.",
                    "label": 1
                },
                {
                    "sent": "So Andrea Bertozzi at UCLA studied how one gang attacking a member of another gang would trigger retaliatory action in the future.",
                    "label": 0
                },
                {
                    "sent": "And we also see these kind of cascading chains of interactions in nation state conflicts, especially when there are proxy wars and proxy actions in play.",
                    "label": 0
                },
                {
                    "sent": "So the question is, in these kinds of social networks, can we infer who?",
                    "label": 1
                },
                {
                    "sent": "Who is influencing what is this underlying network of influences and can we track it as it evolves overtime?",
                    "label": 0
                },
                {
                    "sent": "Simmer.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Situations arise in Epidemiology, so you could imagine every time one person gets sick.",
                    "label": 0
                },
                {
                    "sent": "People within our neighbors of that that sick person might start to exhibit symptoms, and we'd like to be able to figure out how a disease is most likely to spread, and how different policy's like quarantine or how we.",
                    "label": 0
                },
                {
                    "sent": "Treat deal can help stem the spread of an epidemic, and so we'd like to be able to infer these patterns of actions or the spread of disease in this network of people.",
                    "label": 1
                },
                {
                    "sent": "Some of my former colleagues at Duke even combined the two problems of studying Epidemiology and social networks when they studied social networks of prostitutes and Johns and tried to understand how.",
                    "label": 0
                },
                {
                    "sent": "Sexually transmitted diseases were spread throughout this network.",
                    "label": 0
                },
                {
                    "sent": "I don't have a picture for that.",
                    "label": 0
                },
                {
                    "sent": "Uh, we",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You see similar problems in neurobiology and so you could in each of you.",
                    "label": 0
                },
                {
                    "sent": "Hopefully you've got multiple neurons that are spiky and those spikes trigger spikes in the neighboring neurons and there are physical connections between the neurons and we can see those using different imaging techniques, but biologists believe that not all of those connections are active all the time, but rather there are functional networks that some of those actions or those influences between neurons are different depending on what task you're engaged in weather your way.",
                    "label": 0
                },
                {
                    "sent": "Walking or sleeping or reading, and So what we'd like to be able to do is to infer this functional network and track how it changes in response to external stimuli or in response to to the task that you're engaged in.",
                    "label": 1
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Finally, we see these kind of cascading chains of interactions in seismology.",
                    "label": 0
                },
                {
                    "sent": "So in the news we might read about a single earthquake in the damage that it causes by in reality there's often a four shock that occurs before the main shock, and that's followed by multiple aftershocks.",
                    "label": 0
                },
                {
                    "sent": "And so seismologists believe that these have these sort of this kind of causal relationship that there is this underlying sort of network or chain of of reactions, and we'd like to understand.",
                    "label": 0
                },
                {
                    "sent": "How that works so that we can better predict when something damaging is about to occur.",
                    "label": 0
                },
                {
                    "sent": "So in all of these settings, what we'd like to infer is how likely future actions are and how different actors within the network are influencing one another.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Oh, I'm sorry.",
                    "label": 0
                },
                {
                    "sent": "Not one more application.",
                    "label": 0
                },
                {
                    "sent": "Finance financial institutions obviously influence one another move.",
                    "label": 1
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "On here, so the sequence of events that we're interested that would sort of like to follow is the following.",
                    "label": 1
                },
                {
                    "sent": "At each time T, we'd like to make an observation XD.",
                    "label": 1
                },
                {
                    "sent": "So for instance, in our social network setting, XD could correspond to which person acted at time T. And then we would like to incur a loss base that says how well we were able to predict that action given our current estimate.",
                    "label": 0
                },
                {
                    "sent": "So Theta hat T is our current estimate and we can compute a negative log likelihood, for instance.",
                    "label": 0
                },
                {
                    "sent": "That would tell us how well they'd had T predicted are observed actions XD.",
                    "label": 0
                },
                {
                    "sent": "And then based on that loss or the accuracy of that former prediction, we'd like to update our prediction for the next time step.",
                    "label": 0
                },
                {
                    "sent": "So the question is, well, how do we make these predictions and how do we leverage this loss in order to have good, highly accurate predictions?",
                    "label": 0
                },
                {
                    "sent": "And the way we're going to judge the efficacy of our prediction scheme is with the notion called regret here.",
                    "label": 0
                },
                {
                    "sent": "So our series of estimates overtime is going to be this series of Theta hat tease.",
                    "label": 0
                },
                {
                    "sent": "And we're going to compare the total cumulative sum of losses for our estimates with the total cumulative sum of losses for some alternative comparative sequence.",
                    "label": 0
                },
                {
                    "sent": "These Theta tease.",
                    "label": 0
                },
                {
                    "sent": "And you can think about this comparative sequence as corresponding to what you might have computed if you had more computational resources.",
                    "label": 0
                },
                {
                    "sent": "If you weren't trying to work in an online environment with streaming data.",
                    "label": 0
                },
                {
                    "sent": "And what we'd like to be able to show is that given the same set of data that we're doing nearly as well with an efficient online algorithm as you might have done with a far more complex, possibly batch algorithm, and so the lower this regret is, the better we're doing relative to that comparator.",
                    "label": 0
                },
                {
                    "sent": "So our goal is to come up with some sort of prediction scheme that's going to ensure that this average per round regret is going to zero as quickly as possible, as T gets larger and larger.",
                    "label": 0
                },
                {
                    "sent": "OK, so on line learning has a long and rich.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "History and there are variety of methods out there.",
                    "label": 0
                },
                {
                    "sent": "One particularly popular and well understood method is called Mirror descent, and it says that we should make our predictions according to the following scheme.",
                    "label": 0
                },
                {
                    "sent": "At time T we should choose or we should search over all possible predictions and choose one that's well aligned to the gradient of the loss that we just observed.",
                    "label": 0
                },
                {
                    "sent": "So that correspond that's moving in the direction of the negative gradient to the loss.",
                    "label": 0
                },
                {
                    "sent": "And which is close to our last prediction as measured by a Bregman divergences.",
                    "label": 0
                },
                {
                    "sent": "So in this special case where this Bregman divergences a squared Euclidean norm, then this amounts to something like stochastic gradient descent.",
                    "label": 1
                },
                {
                    "sent": "So let's just think about what would happen if we tried to apply this kind of scheme to our cascading chains of events.",
                    "label": 0
                },
                {
                    "sent": "The first thing we have to do is to come up with a good loss function, and I mentioned that negative log likelihood was a strong candidate, but we need to think about what that likelihood function should look like.",
                    "label": 0
                },
                {
                    "sent": "The kinds of data were.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Being here corresponds to point process data, so our observations are of the form where we know who acted and at what time they acted.",
                    "label": 0
                },
                {
                    "sent": "So we basically have all this timing information of events within this network.",
                    "label": 0
                },
                {
                    "sent": "So we can think about this as a multivariate point process.",
                    "label": 0
                },
                {
                    "sent": "So for each node in our network K, we're going to have a different kind of point process which corresponds to the times at which at which actor a acted.",
                    "label": 0
                },
                {
                    "sent": "So I've got that represented graphically here.",
                    "label": 0
                },
                {
                    "sent": "These little red bars would correspond to the times at which a person acted.",
                    "label": 0
                },
                {
                    "sent": "Traditionally, this is represented with this kind of cumulative sum of the number of actions that have a curd at any given time, and that's represented with the green curve and what we're interested.",
                    "label": 0
                },
                {
                    "sent": "In is the blue curve, the rate function which gives us the likelihood of an event occurring at any given time.",
                    "label": 0
                },
                {
                    "sent": "So in particular, if we were interested in the likelihood of node K participating in an event over some interval of time, it would be controlled by the integral of this rate function you, so we're interested in understanding this rate function knew for all the different actors in our network.",
                    "label": 1
                },
                {
                    "sent": "So we can use this in order to.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Form a loss function.",
                    "label": 0
                },
                {
                    "sent": "So given all of.",
                    "label": 0
                },
                {
                    "sent": "Excuse me given all of the events up to some time T, we can compute a log likelihood just using standard point process theory and we can come up with a discretized version where we've discretized time to intervals Delta.",
                    "label": 0
                },
                {
                    "sent": "That looks like this very simple sum of inner products.",
                    "label": 0
                },
                {
                    "sent": "We've got the inner product between our rate and a ones vector, and the inner product between our observation and the log of the rate.",
                    "label": 0
                },
                {
                    "sent": "So what we can do is we can use this log likelihood expression to come up with a loss function that we could use in an algorithm like mirror descent, and so this loss function here corresponds exactly to one of the terms within this expression.",
                    "label": 1
                },
                {
                    "sent": "For the negative log likelihood.",
                    "label": 1
                },
                {
                    "sent": "It's going to be helpful as we go along to realize that we could write things in terms of this rate parameter, mu, which is the kind of proportional to the likelihood of an event occurring at any given time.",
                    "label": 0
                },
                {
                    "sent": "Or we could write it in terms of the log rate, which I'm going to write Theta and working with the law great gives us several different computational and mathematical advantages that will see as we go along here.",
                    "label": 0
                },
                {
                    "sent": "OK, but we can work in either parameter space so.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If we now try to apply mirror descent using this loss function that we've constructed, so this is the look, sorry.",
                    "label": 1
                },
                {
                    "sent": "So we use the loss function from the previous slide.",
                    "label": 0
                },
                {
                    "sent": "We've got a simple expression for the gradient and we can have our print Bregman divergences within that mirror descent expression correspond to the KL divergences between two point processes.",
                    "label": 0
                },
                {
                    "sent": "Then this expression for mirror descent that we were looking at before can be solved in closed form.",
                    "label": 0
                },
                {
                    "sent": "So we've got these very simple closed form updates for the rate or for the log rate.",
                    "label": 0
                },
                {
                    "sent": "So let's see what we can say about.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Regret associated with a procedure like this in this context.",
                    "label": 0
                },
                {
                    "sent": "The classical kinds of regret bounds assume that our parameter that we're interested in estimating or tracking is unchanging overtime, so we're comparing our series of estimates.",
                    "label": 0
                },
                {
                    "sent": "These Theta hat tease with the single best point estimate.",
                    "label": 0
                },
                {
                    "sent": "That's not changing overtime, and you can get a regret bound that scales like square root T using classical techniques, but it's also kind of meaningless, right?",
                    "label": 0
                },
                {
                    "sent": "We're very interested in situations where this true rate is changing overtime, right?",
                    "label": 0
                },
                {
                    "sent": "We're interested in these networks where.",
                    "label": 0
                },
                {
                    "sent": "The rate is dependent on previous actions in the network, so things are inherently very dynamic, and so we might be able to get a little regret, but it won't necessarily mean that our method is doing anything useful.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We can also compute tracking regret bounds where we're comparing the performance of our series of estimates.",
                    "label": 0
                },
                {
                    "sent": "These state ahead tease with an arbitrary sequence of Theta tease.",
                    "label": 0
                },
                {
                    "sent": "Anna tracking.",
                    "label": 0
                },
                {
                    "sent": "Regret bound typically has a form like this.",
                    "label": 0
                },
                {
                    "sent": "It looks like sqrt T * A variation term that measures how much are compared or sequences changing overtime.",
                    "label": 0
                },
                {
                    "sent": "And so if that comparative sequences say piecewise constant or piecewise static overtime, or changing extremely slowly, then methods like mirror descent will give us low regret.",
                    "label": 0
                },
                {
                    "sent": "But of course we've got this sort of inherent dynamic aspect to our problem, so again, this isn't useful in many of the applications that we discussed up front.",
                    "label": 0
                },
                {
                    "sent": "OK, so to try to understand how we can get better bounds that are more relevant to the applications at hand, we need to take a step back and think more about the underlying point process that's helping us to generate this data.",
                    "label": 0
                },
                {
                    "sent": "So far we haven't really talked much about the underlying network and its role in all of this.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm going to use a something called the multivariate Hawkes process to model our observations and if I just show you the point process equations, it's a little ugly, so I'm going to kind of demonstrate this graphically.",
                    "label": 0
                },
                {
                    "sent": "The idea is that one actor in our network does some action like like something on Facebook and that's going to change.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Change the rate functions associated with the other people in the network so she maybe has more influence over the blue person and so he has this increased likelihood of acting and less so influence over the yellow person, and so she has increased.",
                    "label": 0
                },
                {
                    "sent": "Perhaps likelihood of acting, but not as strongly increased as this guy.",
                    "label": 0
                },
                {
                    "sent": "So then, based on these increase.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Straight functions, perhaps the blue guy acts and he's going.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To trigger a change in the rate functions associated with his neighbors within this social network.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And that's going to trigger an action.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Green person at.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Cetera and so.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I can see every time.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Somebody acts.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is change.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Pushing the rate fund.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Oceans, asos",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Created with all the other people within this network and that's the basic idea of this multivariate Hawkes process.",
                    "label": 0
                },
                {
                    "sent": "So what we'd like to do?",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So is to take.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Observations that just correspond to who acted when, and from that infer.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "All these nice, pretty colorful curves, so we'd like to understand what these patterns of influences are.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So a little bit more precisely what a multivariate Hawkes process does is it assumes that this rate function, let's say for person K. Has the following form.",
                    "label": 1
                },
                {
                    "sent": "It's the sum of sum average background rate plus the sum of these influence functions where we have the influence function between person K and its neighbor K in, and we're evaluating that function based on how long ago neighbor Kate and acted.",
                    "label": 0
                },
                {
                    "sent": "OK, so we're saying exactly what the picture is.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You said that this rate function H sort of looks like this little curve here and its placement along time corresponds to how long ago this red person acted.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I've got this very nice relationship between the rates at time Tau and the history of events up to time tell and what we're going to do is we're going to make a simplifying assumption here that these rate functions all have the same form.",
                    "label": 1
                },
                {
                    "sent": "They correspond to a scalar amplitude WKC N times a common H function, so all of these influence functions have the same shape like in our graphical representation, but they've got different amplitudes.",
                    "label": 0
                },
                {
                    "sent": "And so when we talk about estimating the underlying network, what we really mean is we're trying to estimate this matrix of amplitudes or this matrix of numbers that indicates how much each person is influencing every other person or every other actor within this network.",
                    "label": 0
                },
                {
                    "sent": "So our objective is to track these rates.",
                    "label": 0
                },
                {
                    "sent": "These mus for all actors in the network and the underlying network W using streaming observations.",
                    "label": 0
                },
                {
                    "sent": "OK, so the.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Question is, how do we actually make this work in our online learning setting?",
                    "label": 0
                },
                {
                    "sent": "The first thing to notice that when we have this sort of Hox model for how intensities change overtime, we can kind of think about that as being a dynamical model.",
                    "label": 0
                },
                {
                    "sent": "So given a rate at time T we can make a prediction of what we think the rate at time T + 1 should be.",
                    "label": 0
                },
                {
                    "sent": "Using this matrix W. And So what we'd like to be able to do is to incorporate this concept of a dynamical model into a method like mirror descent.",
                    "label": 0
                },
                {
                    "sent": "So in the next slide, I'm going to have this capital, Phi here correspond to our dynamical model.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if we had a collection of dynamical models, one for each time step, then we can use a variant of mirror descent in order to make our predictions.",
                    "label": 0
                },
                {
                    "sent": "We would say at each time T what we're going to do is again search over all possible predictions.",
                    "label": 0
                },
                {
                    "sent": "Choose something that's aligned with the gradient of our loss and close in terms of Bregman divergences.",
                    "label": 0
                },
                {
                    "sent": "But when we evaluate this gradient, and when we evaluate this Bregman divergences, we're going to incorporate our dynamical model fee.",
                    "label": 0
                },
                {
                    "sent": "And so we're taking this dynamical model into account every step of the way, and then we can show is that if you do this for a modest increase in computational cost.",
                    "label": 0
                },
                {
                    "sent": "And if your dynamical models satisfy a contractive property which basically says if I've got two different rates and I apply the same dynamical model to them, they get closer together, not farther apart.",
                    "label": 0
                },
                {
                    "sent": "Then we get a regret bounds that looks similar in form to the other regret bounds.",
                    "label": 0
                },
                {
                    "sent": "We've looked in sqrt T * A variation term, but now our variation term is going to measure how much are compared or sequence is deviating from our dynamical model as opposed to measuring how flat and constant it is.",
                    "label": 0
                },
                {
                    "sent": "And so this tells us if we've got some good dynamical models that are accurate predictors of what is going on in the network, then we're going to be able to get achieve a very low regret.",
                    "label": 0
                },
                {
                    "sent": "We're going to be able to do as well as a batch algorithm for a much broader class of problems.",
                    "label": 0
                },
                {
                    "sent": "And for a much broader class of networks.",
                    "label": 0
                },
                {
                    "sent": "OK, now going back to our let me just say it.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Couple of words about this contract evety condition.",
                    "label": 0
                },
                {
                    "sent": "We said that the dynamical model has to move two different rate functions closer together instead of further apart, and so you might ask, well, how much of a restriction is this, or how much is this really constraining us?",
                    "label": 0
                },
                {
                    "sent": "Essentially, what this condition means in our particular multivariate Hawkes context is that when we apply our dynamical model, we're not going to force this likelihood of events to go negative, right?",
                    "label": 0
                },
                {
                    "sent": "We've got this rate function, mu, which is proportional to the likelihood of a person or an agent acting in our network, and that inherently needs to be non negative.",
                    "label": 0
                },
                {
                    "sent": "So as long as elements of RW matrix and our old rates are non negative.",
                    "label": 0
                },
                {
                    "sent": "Then we satisfy this contract tivity property without any problem.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so we've got a way to incorporate dynamical models into mirror descent and based on the multivariate Hawkes process we have nice forms of dynamical models that are relevant to the kinds of data that we're interested in analyzing.",
                    "label": 1
                },
                {
                    "sent": "The problem, however, is that this is that we don't fully know these dynamical models because they are a function of W. So W is the network this matrix of amplitudes which we're trying to estimate or track.",
                    "label": 0
                },
                {
                    "sent": "It's completely unknown when we start off, and so we'd like to be able to track it or to learn the ideal dynamical model as we go along and receive more data.",
                    "label": 0
                },
                {
                    "sent": "You could say, well, I mean just consider a finite set of candidate WS.",
                    "label": 0
                },
                {
                    "sent": "Try 'em all out in parallel and do something like prediction with expert advice to hone in on whichever one is working best at any given time.",
                    "label": 0
                },
                {
                    "sent": "And that's a reasonable solution.",
                    "label": 0
                },
                {
                    "sent": "But if you think about having a network with hundreds of nodes, then W is hundreds of nodes squared.",
                    "label": 0
                },
                {
                    "sent": "It's large, and if you try to discretize the space of all possible W matrix, it gets very big very quickly, and so that's not really a viable solution.",
                    "label": 0
                },
                {
                    "sent": "In general, the big challenge that we face is that if we start using some estimate of W and perform this sort of dynamic mirror descent using that W doesn't provide us any information about how well we might have done if we used some W prime.",
                    "label": 0
                },
                {
                    "sent": "Some other matrix of representing the underlying network.",
                    "label": 0
                },
                {
                    "sent": "This is generally the case, but Fortunately in our multivariate Hawkes setting we can sidestep the challenge in a pretty neat way.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so we've got this, this lemma, which looks messier than it really is.",
                    "label": 0
                },
                {
                    "sent": "All it's really saying is that, let's say we were doing tracking.",
                    "label": 0
                },
                {
                    "sent": "We were running our method with some assumed estimate W prime.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry with some assumed estimate W prime, so we know our estimates of the rates using W prime at time T. And our limit tells us that we can always compute the estimates that we would have gotten if we had been using W from the very beginning via a simple linear transformation of this previous of this estimate with W prime.",
                    "label": 0
                },
                {
                    "sent": "So we can use whatever W we want, and at any given time we can figure out what estimate we would have had with any other W. And this is very important because it's going to allow us to track both them using the WS.",
                    "label": 0
                },
                {
                    "sent": "Both the rates in the underlying network simultaneously, and very, very computationally efficiently.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so the basic idea is the following.",
                    "label": 0
                },
                {
                    "sent": "At any given time, we can compute how our loss associated with our current estimate of the network W and the gradient of that loss using the lemma from the previous slide, and then we can apply something like Mirror descent to update our estimate of that network or influence matrix.",
                    "label": 0
                },
                {
                    "sent": "Given that, then we can simply apply this dynamic mirror descent method that I described before and do some simple bookkeeping, and we're going to have a method that is tracking both them, use the thetas and the WS simultaneously.",
                    "label": 0
                },
                {
                    "sent": "OK, so every step in here is very computationally efficient and it's very well suited to high dimensional problems.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So our main result is the following.",
                    "label": 0
                },
                {
                    "sent": "If we use this kind of procedure where we're trying to track the WS and the Muse simultaneously, then we get a regret that has the same form that we've seen all along sqrt T * A variation term.",
                    "label": 0
                },
                {
                    "sent": "But now our variation term corresponds to the smallest possible variation that we could have gotten with any W we considered.",
                    "label": 0
                },
                {
                    "sent": "So this is telling us that with the kind of procedure that I just described, we're trying to track WMU simultaneously.",
                    "label": 0
                },
                {
                    "sent": "We are going to do nearly as well as if some Oracle had told us the very best Mewtwo use from the very beginning.",
                    "label": 0
                },
                {
                    "sent": "OK, so let.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "See some of this in action in this particular case, just to highlight a couple of aspects of this.",
                    "label": 0
                },
                {
                    "sent": "I have W known, so we're just using that dynamic mirror descent method with a known underlying influence matrix.",
                    "label": 0
                },
                {
                    "sent": "And what we see at the bottom here are the true rate in red covered up by this discretized approximation that we're using throughout in Cyan.",
                    "label": 0
                },
                {
                    "sent": "And so we see that the discretization is really not hurting anything.",
                    "label": 0
                },
                {
                    "sent": "The blue corresponds to what you would get if you tried to just track the network W directly, but if you didn't, if you had some model mismatch.",
                    "label": 0
                },
                {
                    "sent": "If you didn't know all the parameters of your system exactly, then because you're not tracking the rates them use along with the WS you incur larger losses than if you try to track both of them simultaneously, and we see this when we look at average per round loss or from a different perspective.",
                    "label": 0
                },
                {
                    "sent": "If we were to just look at the instantaneous loss.",
                    "label": 0
                },
                {
                    "sent": "Smooth slightly so you can visualize it better.",
                    "label": 0
                },
                {
                    "sent": "OK, we.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "W is unknown.",
                    "label": 0
                },
                {
                    "sent": "We see a similar effect, so the blue curve here corresponds to what you would get with standard online learning algorithms, which essentially assumed that that network has no edges anywhere, so it's not a network.",
                    "label": 0
                },
                {
                    "sent": "It assumes that that W matrix is zero everywhere, and so you can see it performs very poorly.",
                    "label": 0
                },
                {
                    "sent": "The red curve corresponds to what you would get if you just did stand stochastic gradient descent directly on W and assume everything else about the system is known exactly.",
                    "label": 0
                },
                {
                    "sent": "If you are wrong about those assumptions, then you are going to get consistently higher losses than you would get with the proposed algorithm that I'm describing here, where you're tracking both these influence matrices and the rates simultaneously and again, we see this both in terms of cumulative loss or in terms of this instantaneous loss.",
                    "label": 0
                },
                {
                    "sent": "Alright, finally we examined given the zesta.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How well can we detect the significant or high weight edges within this network?",
                    "label": 0
                },
                {
                    "sent": "And we plotted some tomorrow, see curves.",
                    "label": 0
                },
                {
                    "sent": "So the purple curve corresponds to how well we can detect significant edges.",
                    "label": 0
                },
                {
                    "sent": "If you just try to track W and assume you know everything else about the system in or perhaps wrong.",
                    "label": 0
                },
                {
                    "sent": "And the cyan curve corresponds to how well you can detect those significant edges in using the method that we developed here.",
                    "label": 0
                },
                {
                    "sent": "The blue and the red or the same thing.",
                    "label": 0
                },
                {
                    "sent": "Our method versus standard gradient descent.",
                    "label": 0
                },
                {
                    "sent": "Stochastic gradient descent when you do know all of the system parameters exactly and there's no errors whatsoever, and so in that idealized scenario, there is very little difference between the performance of the two methods.",
                    "label": 0
                },
                {
                    "sent": "But once you start having model mismatch, you start to see more significant gap between.",
                    "label": 0
                },
                {
                    "sent": "The performance you can get with standard stochastic gradient descent and the approach I'm describing here.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so to conclude, what we've developed are some online learning techniques that are pretty significantly different from standard on line learning methods, and that they give us a nice principled way for incorporating notions of system dynamics.",
                    "label": 0
                },
                {
                    "sent": "So they give us unique regret bounds, and they give us a way to handle things like multivariate Hawkes data.",
                    "label": 0
                },
                {
                    "sent": "We've got these nice theoretical performance bounds, but they're also extremely computationally efficient, which is nice for some of the very large scale.",
                    "label": 0
                },
                {
                    "sent": "Data analysis problems that I described at the beginning.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So with that, thank you very much and I'd be happy answer any questions.",
                    "label": 0
                }
            ]
        }
    }
}