{
    "id": "rt7vkymwopzq3gicqs45cmj7k6kgpi6e",
    "title": "Label optimal regret bounds for online local learning",
    "info": {
        "author": [
            "Andrej Risteski, Computer Science Department, Princeton University"
        ],
        "published": "Aug. 20, 2015",
        "recorded": "July 2015",
        "category": [
            "Top->Computer Science->Machine Learning->Active Learning",
            "Top->Computer Science->Machine Learning->Computational Learning Theory",
            "Top->Computer Science->Machine Learning->On-line Learning",
            "Top->Computer Science->Machine Learning->Reinforcement Learning",
            "Top->Computer Science->Machine Learning->Semi-supervised Learning"
        ]
    },
    "url": "http://videolectures.net/colt2015_risteski_local_learning/",
    "segmentation": [
        [
            "So this is a."
        ],
        [
            "Setting up online learning where the learner is asked to make some local predictions so completely.",
            "This is going to be some set of items X and some set of labels help at any wrong T the learner will get a pair of items XD YT and needs to predict a pair of labels for them, after which it observes a payoff and the goal is to minimize basically the difference between OPT and the expected payoff it gets for Optus.",
            "The payoff of the best fixed labeling.",
            "Alright."
        ],
        [
            "So what's known about this problem previously?",
            "Well, it's kind of not too difficult to see that the optimal algorithm information theoretically would be to just run experts over all possible L to the experts.",
            "Well, is the number of labels, and is the number of items, and this will get you regret of square root N log Lt.",
            "So despite the fact that this is an actual computational efficient algorithm in this case 'cause you want the polynomial time algorithm, it's actually useful to look at the online convex optimization and interpretation of experts, which would say that at round T + 1 the optimal distribution over the experts to play is the one which maximizes basically the.",
            "Expected cumulative payoff minus regularizer and the correct regularizer uses just the Shannon entropy, and this is actually suggests sort of natural polynomial time algorithm, which will be instead of essentially optimizing over that intractable politic of all possible distribution over labelings.",
            "Just do so over relaxation of that positive, which is the 2nd order pseudo moment polytope, and this sometimes goes by the name of Lasserre.",
            "Basically level 2 hierarchy.",
            "You also need a proxy for the regularizer, 'cause you don't have the Shannon entropy now, and the reasonable thing to do is to use.",
            "Log determinant of the second moment matrix, because this is actually the entropy of a Gaussian matching those moments and with Shannon showed in 2014 was that followed the regulars leader with this regularizer actually will get you regretted screwed an L ^3."
        ],
        [
            "And the question he posed to last year's goal was to actually close this gap.",
            "So basically we do just that, so we prove that one the same algorithm he proposed to follow the regular leader over the 2nd order pseudo manipulative with the log that regularizer will get you regretted screwed an Lt. And Furthermore we show that if you want to achieve regret obscured NL to the 1 -- 6 epsilon T, let's say will refute the planted Cleek conjecture with planted cliques of size N to the half minus epsilon.",
            "So we already heard about this conjecture.",
            "But just to reiterate it, one more time this is a setting where you get a graph which is sampled from one or two possible.",
            "Distributions one is just G and half and the other one is G. And have we also pick K vertices at random and you put a click on them and so the conjecture says that if you want to distinguish between these two distributions of probability constant, this is impossible in polynomial time.",
            "So you should."
        ],
        [
            "I really view this as sort of an online version of a celebrated resulted ragavendra approved in 2008 for constraint satisfaction problems.",
            "So he showed that for constraint satisfaction problems under the unique games conjecture, this pseudo moment relaxation is actually optimal among all polynomial time algorithms.",
            "So this is just saying for online local learning, which is really the online version of constraint satisfaction problems.",
            "The same student woman relaxation is basically the optimal thing to do if you choose the appropriate regularizer."
        ],
        [
            "I'll briefly mention that we also just show a similar lower bound under related conjecture that we proposed to planted clique, which we think is a bit more robust, so this is a setting where, again, you have a distinguishing scenario, either getting a graph which is GNP, or its GNP, and you pick K vertices at random, and you put a GK Q graph on them, and now the conjecture is that if P then to the minus Alpha K is enter the half minus epsilon and Q is key to the minus Alpha minus epsilon, then basically this is difficult, then this is impossible to do with constant probability in polynomial time.",
            "Why?"
        ],
        [
            "Do you prefer this over planted Cleek?",
            "The punchline is that basically, while there is quasi polynomial time, algorithms are planted Cleek.",
            "For this, there's actually only two to the end to the Epsilon running time algorithms for now.",
            "Then the state of the art is in Buskerud, all from 2010."
        ],
        [
            "So just to encourage you to still come to the open problem section, there's actually still come to the Post Recession.",
            "There's actually still some interesting open problems remaining, so in particular getting better regret in subexponential time is open hardness under some weaker and more standard assumptions is also open.",
            "An in general, there's really not that many computational hardness results in online learning, so just proving more results there is.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is a.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Setting up online learning where the learner is asked to make some local predictions so completely.",
                    "label": 0
                },
                {
                    "sent": "This is going to be some set of items X and some set of labels help at any wrong T the learner will get a pair of items XD YT and needs to predict a pair of labels for them, after which it observes a payoff and the goal is to minimize basically the difference between OPT and the expected payoff it gets for Optus.",
                    "label": 0
                },
                {
                    "sent": "The payoff of the best fixed labeling.",
                    "label": 1
                },
                {
                    "sent": "Alright.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what's known about this problem previously?",
                    "label": 0
                },
                {
                    "sent": "Well, it's kind of not too difficult to see that the optimal algorithm information theoretically would be to just run experts over all possible L to the experts.",
                    "label": 1
                },
                {
                    "sent": "Well, is the number of labels, and is the number of items, and this will get you regret of square root N log Lt.",
                    "label": 1
                },
                {
                    "sent": "So despite the fact that this is an actual computational efficient algorithm in this case 'cause you want the polynomial time algorithm, it's actually useful to look at the online convex optimization and interpretation of experts, which would say that at round T + 1 the optimal distribution over the experts to play is the one which maximizes basically the.",
                    "label": 0
                },
                {
                    "sent": "Expected cumulative payoff minus regularizer and the correct regularizer uses just the Shannon entropy, and this is actually suggests sort of natural polynomial time algorithm, which will be instead of essentially optimizing over that intractable politic of all possible distribution over labelings.",
                    "label": 0
                },
                {
                    "sent": "Just do so over relaxation of that positive, which is the 2nd order pseudo moment polytope, and this sometimes goes by the name of Lasserre.",
                    "label": 0
                },
                {
                    "sent": "Basically level 2 hierarchy.",
                    "label": 0
                },
                {
                    "sent": "You also need a proxy for the regularizer, 'cause you don't have the Shannon entropy now, and the reasonable thing to do is to use.",
                    "label": 0
                },
                {
                    "sent": "Log determinant of the second moment matrix, because this is actually the entropy of a Gaussian matching those moments and with Shannon showed in 2014 was that followed the regulars leader with this regularizer actually will get you regretted screwed an L ^3.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the question he posed to last year's goal was to actually close this gap.",
                    "label": 0
                },
                {
                    "sent": "So basically we do just that, so we prove that one the same algorithm he proposed to follow the regular leader over the 2nd order pseudo manipulative with the log that regularizer will get you regretted screwed an Lt. And Furthermore we show that if you want to achieve regret obscured NL to the 1 -- 6 epsilon T, let's say will refute the planted Cleek conjecture with planted cliques of size N to the half minus epsilon.",
                    "label": 1
                },
                {
                    "sent": "So we already heard about this conjecture.",
                    "label": 0
                },
                {
                    "sent": "But just to reiterate it, one more time this is a setting where you get a graph which is sampled from one or two possible.",
                    "label": 0
                },
                {
                    "sent": "Distributions one is just G and half and the other one is G. And have we also pick K vertices at random and you put a click on them and so the conjecture says that if you want to distinguish between these two distributions of probability constant, this is impossible in polynomial time.",
                    "label": 1
                },
                {
                    "sent": "So you should.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I really view this as sort of an online version of a celebrated resulted ragavendra approved in 2008 for constraint satisfaction problems.",
                    "label": 0
                },
                {
                    "sent": "So he showed that for constraint satisfaction problems under the unique games conjecture, this pseudo moment relaxation is actually optimal among all polynomial time algorithms.",
                    "label": 1
                },
                {
                    "sent": "So this is just saying for online local learning, which is really the online version of constraint satisfaction problems.",
                    "label": 1
                },
                {
                    "sent": "The same student woman relaxation is basically the optimal thing to do if you choose the appropriate regularizer.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'll briefly mention that we also just show a similar lower bound under related conjecture that we proposed to planted clique, which we think is a bit more robust, so this is a setting where, again, you have a distinguishing scenario, either getting a graph which is GNP, or its GNP, and you pick K vertices at random, and you put a GK Q graph on them, and now the conjecture is that if P then to the minus Alpha K is enter the half minus epsilon and Q is key to the minus Alpha minus epsilon, then basically this is difficult, then this is impossible to do with constant probability in polynomial time.",
                    "label": 0
                },
                {
                    "sent": "Why?",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Do you prefer this over planted Cleek?",
                    "label": 0
                },
                {
                    "sent": "The punchline is that basically, while there is quasi polynomial time, algorithms are planted Cleek.",
                    "label": 1
                },
                {
                    "sent": "For this, there's actually only two to the end to the Epsilon running time algorithms for now.",
                    "label": 0
                },
                {
                    "sent": "Then the state of the art is in Buskerud, all from 2010.",
                    "label": 1
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So just to encourage you to still come to the open problem section, there's actually still come to the Post Recession.",
                    "label": 0
                },
                {
                    "sent": "There's actually still some interesting open problems remaining, so in particular getting better regret in subexponential time is open hardness under some weaker and more standard assumptions is also open.",
                    "label": 1
                },
                {
                    "sent": "An in general, there's really not that many computational hardness results in online learning, so just proving more results there is.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}