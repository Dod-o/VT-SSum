{
    "id": "atw4mu74fbrlc65n776bpkh263nu2hha",
    "title": "Orbit-Product Representation and Correction of Gaussian Belief Propagation",
    "info": {
        "author": [
            "Jason K. Johnson, Stochastic Systems Group, Massachusetts Institute of Technology, MIT"
        ],
        "published": "Aug. 26, 2009",
        "recorded": "June 2009",
        "category": [
            "Top->Computer Science->Machine Learning->Gaussian Processes"
        ]
    },
    "url": "http://videolectures.net/icml09_johnson_opr/",
    "segmentation": [
        [
            "I'm Jason, and so I'm actually.",
            "I've moved on from MIT finally.",
            "I'm at Los Alamos national lab.",
            "Now I'm working with Michael Chirkov Misha.",
            "And this paper is with Misha and Vladimir Czerniak.",
            "I also want to mention that that this also builds upon earlier work from MIT with Dmitri Molotov and Alan Wilsky."
        ],
        [
            "OK, so I'll just have a brief review of like graphical models and particularly inference in Gaussian graphical models.",
            "A graphical model is a multivariate probability distribution where the overall distribution has a compact representation in terms of potential is defined on nodes and edges of a graph.",
            "So you draw a graph.",
            "The nodes represent random variables and the joint distribution of all of these is determined by this product of interactions or potential functions.",
            "These models have a Markov property, which means that if you condition on the variables on a separator of the graph, there separated pieces are conditionally independent is actually sort of defining property of the graphical model.",
            "Given such a model specified by potentials like this, we're interested in the inference problem and this means to compute marginal distributions by summing or integrating over all variables except for a single variable.",
            "Are computing this normalization constant, also known as the partition function Z an?",
            "These calculations are generally difficult in large complex graphical models.",
            "A Gaussian graphical model is."
        ],
        [
            "Just one which has this quadratic form as your energy function or in the exponent.",
            "Is also called the information form of the Gaussian density, 'cause this matrix J its inverse is the covariance matrix, so the covariance K is like the uncertainty and Jay is like the information matrix and so here we'd like to calculate the covariance at least elements of that.",
            "The mean vector, and perhaps the determinant of K or J inverse, which is related to the partition function.",
            "This is a graphical model when JS sparse, so you only have non zero entries off the diagonal J for edges of the graph.",
            "And you can also write this in this potential factorization from the previous page.",
            "And here, if computing marginals reduces computing the mean or the variance of a variable."
        ],
        [
            "OK, so belief propagation is an approximate inference method.",
            "It allows you to estimate these marginals through calculating set of messages, and these messages are calculated from solving these fixed point equations and involves taking in a set of messages from all your neighbors except for except for one and if using that with local information and then predicting that to your remaining neighbor, and this is thought of as a message passing from node I to know J and so function of the state of node J.",
            "And you iterate this type of update until it converges to a fixed point, and then you compute marginals by combining these data node.",
            "Um?",
            "You also can calculate pair."
        ],
        [
            "Wise marginals this is slightly more complicated formula, but involves merging your local potentials with messages coming into a region and this is important if you want to estimate this partition function.",
            "So here are the estimate of the partition function is formed from these local normalization constants computed from these in the course of calculating these marginal estimates.",
            "Actually, belief propagation can be regarded as solving for a saddle point of this right expression on the right hand side with respect to variations in the messages.",
            "But the motivation for this is that in trees it converges in a finite number of steps, and then it's exact.",
            "In that case BP is really just a form of.",
            "You can think of it as a form of variable elimination.",
            "To calculate this this partition the normalization constant."
        ],
        [
            "In the marginals.",
            "So Gaussian belief propagation is just a special case of this, where we have messages that are written in this form, so the messages are based on the quadratic form.",
            "So rather than actually passing this function is a message.",
            "You just store these two parameters of this function and those become your messages in Gaussian belief propagation.",
            "Computing these integrals involved in the in the in the BP equations reduces to these formulas in terms of these parameters, and actually this is equivalent to.",
            "Basically, this performing Gaussian elimination in this representation of this information form.",
            "Once you have one, once these converge, then you compute means and variances using these rules, and that determines the marginal distributions."
        ],
        [
            "Well, you also can calculate the pairwise covariance and edges, and from this you can calculate an estimate of the of the determinant.",
            "So here Z is the determinant of the covariance matrix and the BP estimate is formed from local determinants of edges and at nodes.",
            "And again, this would give you the exact determinant restructuring model, but it's an approximation loopy graphs.",
            "So a big part of this talk is basically aimed at how to interpret this estimate and understand how accurate it is and how to correct it.",
            "OK, so one of."
        ],
        [
            "Important piece of background is that.",
            "I believe propagation is can be interpreted as exact inference on what's called the computation tree graph.",
            "So here we have a loopy graph and when we run belief propagation on it, and if you look at the calculation and the marginal at one node after 1234 steps is equivalent to building this tree where you start at that node and you attach his neighbors.",
            "Then you attach their neighbors and you sort of trace all paths.",
            "Four steps away from that node.",
            "And then the messages that you computed in those four iterations basically corresponds to variable elimination in history.",
            "At the first iteration, you sort of eliminated these nodes, and that's the first set of messages in the second set of messages in 3rd and 4th.",
            "OK."
        ],
        [
            "OK, so now I'm going to give a little bit of review on some background work idea.",
            "Which meeting are some work I did earlier with Dmitry Molotov and Alan will scheme.",
            "And this involves what we call walk sums.",
            "So let Jay this information sparse information matrix be written as I -- R. And actually if you normalize J so that the diagonal is unit diagonal, this R it's a matrix of partial correlation coefficients in the Gaussian model, and so it's a sparse matrix.",
            "You only have these coefficients where there's an interaction in your graphical model.",
            "Well, there's this Neumann series, which is I minus.",
            "Our inverse is a sum of powers of our.",
            "Um?",
            "This is this basically generates walks in the graph 'cause are sparse matrix is like a ninja weighted adjacency matrix of the graph.",
            "So you take powers of this.",
            "This is generating sums of walks of length L in the graph, and so this leads to this walk.",
            "Some interpretation of inference in Gaussian models were basically you.",
            "By expanding this SRL, you expressed the elements of the covariance as sums of walks from I to J in the graph, but it's sort of sorted by length.",
            "Well, you can relax that to just some overall walks in my DJ without requiring this sorting of walks by their length, but requires an additional condition.",
            "This is what we call walk Summable.",
            "And this is defined as the sum over all walks is absolutely convergent 'cause there's infinitely many walks in a graph between two points, so that then implies that these time kind of expressions are well defined, and since they converge for no any ordering that you can think of.",
            "And Conversely, the same value, independent of the ordering also means are expressed as walks, which ended a node related by this H vector devalues H at the start of the lock.",
            "OK, so we now have an."
        ],
        [
            "I understand how to extend this to compute the determinant.",
            "But we have to define what we call orbits so."
        ],
        [
            "If you look at this.",
            "Here if you look at KII, it's a sum of clothes walk."
        ],
        [
            "Is it a node?",
            "Well, a similar idea shows up in this expression and the determinant.",
            "So walk is closed.",
            "It begins and ends at the same vertex.",
            "It's primitive if it's not a duplicate of a shorter walk.",
            "And then we consider two primitive walks to be equivalent if one is just sort of a cyclic shift to the other if they start at different points.",
            "And then we define orbits L to be these equivalence classes of closed primitive walks.",
            "Well then the determinant can be expressed as a product over all orbits of the graph of this expression.",
            "So this is yell is sort of the weight of an orbit and is constructed by taking a product of edge weights over the orbit and computing this one minus that number inverse.",
            "And this is again for these walk symbol models where where actually I think I forgot to mention that walks mobility property is equivalent to the spectral radius of this matrix being less than one after you take absolute values of all its elements.",
            "So that's the first main result of our paper.",
            "Um?",
            "OK, so now we're going to look at how to interpret Gaussian belief propagation within this framework.",
            "So."
        ],
        [
            "Going back to the work with Demetria Nanalan we showed we basically just said, well, we combine the interpretation and belief propagation is exact inference in the computation tree, together with interpreting inference in the computation tree.",
            "Computing these walk sums.",
            "And this leads to a simple picture where we can show that BP computes the complete walk, some for the means it captures all the walks you need to get the means, but it's incomplete with respect to the variances.",
            "Fucking this go back.",
            "The reason for."
        ],
        [
            "That is, if you look at a walk that goes around a cycle like 12541.",
            "Well, you can trace.",
            "You can map that to walk in the computation tree by going backwards from from the root node.",
            "So 14521 so that walk lose there now for the mean calculations.",
            "This actually is included in the calculation of the mean at this node, 'cause it only has to end it at the root node, but the variance is you have to begin and in at the root node, so that wouldn't be added to the variance estimate computed by Gaussian BP.",
            "So a similar thing happens with respect to the determinant estimate, so we have."
        ],
        [
            "Define.",
            "This definition of a totally backtracking orbit.",
            "So an orbit is reduce aghbal if it contains backtracking steps like Iga to Ji.",
            "Otherwise it's irreducible or back track list.",
            "We say so.",
            "Every orbit has a unique irreducible core.",
            "If you start deleting these backtracks, eventually you get to a back trackless orbit and so will do.",
            "Note that by gamma.",
            "And also we let L gamma denote the set of all orbits which reduced to gamma under this backtrack deletion procedure.",
            "And finally we stay in orbit is totally backtracking.",
            "If it actually reduces down to just named the walk."
        ],
        [
            "So for example, if you just go 12321, if you delete these backtracking steps, it just reduces to nothing.",
            "So that's a totally backtracking walk, and these are exactly the sort of walks that you can bet is closed walks in the computation tree.",
            "So the theorem says that that GBP, which we defined earlier is actually equal to a product over just the subset of totally backtracking orbits, whereas the fools you would be include more orbits.",
            "OK, so we have this correction.",
            "Z is equal to VBP times the rest of these orbits.",
            "These, not these orbits, aren't totally backtracking.",
            "We actually can look at this in bound the error based on this expression and we have.",
            "If you look at the ratio of Zetas EP."
        ],
        [
            "Like that would be close to one.",
            "Take the log of that.",
            "The absolute value is bounded by this expression, where row is the spectral radius parameter.",
            "So you see if you fix if you bound the spectral radius on G is the growth of the graph is the length of the shortest cycle.",
            "Then you see that the error is sort of decaying exponentially with this growth."
        ],
        [
            "OK, so now we're interested in starting to compute how to think about computing corrections to BP, and it's not really tractable to actually enumerate these one at a time, so we want to start reducing this to things which are more tractable to compute.",
            "The first step is this reduction to backtrack less orbit products.",
            "So here we take this full product overall orbits and we group them by their by their back trackless core and define the gamma prime to be the product over that equivalence class of orbits.",
            "Well the nice thing is is that the Z camera prime you actually compute that easily from the Gaussian BP solution.",
            "So this is the formula for Z. Gamer Prime is exactly the same As for ZL, except we modify these edge weights.",
            "By multiplying by this factor of 1 minus Alpha universe where Alpha is coming from belief propagation.",
            "The idea here is basically that multiplying by this this factor is reinserting all of the totally backtracking walks at each point along a back trackless orbit.",
            "So rather than looking at all these little sort of variations on it, if you take a backtrack a sore but you can add little excursions.",
            "Each point which are totally backtracking rather than look counting those separately and count them all at once with the help of this BP solution and basis, because BP is already pre computing these totally backtracking excursions at a point."
        ],
        [
            "OK, so one other thing which is kind of cute.",
            "Once once we reduce this to a product of back trackless orbits, we can actually construct another determinant which we calculate all of those.",
            "So for this graph G We construct this graph G prime, where for each directed edge of the graph you include two nodes in this G prime and then you connect these biotics according to this non backtracking rule.",
            "So you connect node I jatin ojk.",
            "As long as I is not equal to K. And so and then all the orbits in this graph are exactly equivalent to backtrack with orbits in the original graph, and so then by adding appropriate edge weights.",
            "Here we can make the determinant of this graph equal.",
            "This correction factor would like to compute.",
            "So the advantage of this though, is it sort of tells us how to approximate this approximate this correction factor.",
            "And the actual algorithm that we used to compute these sort of things is based on what I'm calling block resomation here.",
            "Sort of.",
            "The idea is if you look at a graph like this.",
            "And you look at some sub graph.",
            "You can compute the determinant based on just that sub graph and what you're capturing is just a subset of orbits, all orbits of the larger graph which live in that sub graph.",
            "So what you'd like to do is do these computations and sort of overlapping blocks covering, say, the grid.",
            "Anne piece these pieces together to get all the orbits you can from the original graph."
        ],
        [
            "So here's a little technical.",
            "Maybe I won't do all the details, but basically you said if you specify a set of subgraphs, I'm calling blocks here.",
            "And because some of these on intersections of blocks, you have to avoid over counting the orbits in that intersection, so you also include intersections.",
            "But then you sort of assign accounting number teaching these blocks.",
            "And then to form an estimate of Z based on all the loops covered by any block, use this formula and basically involves computing determine subgraphs and multiplying these together, but raised the power is determined by this rule.",
            "And if you choose your blocks appropriately, say to cover all orbits of the graph up to some length L, then you again get error bounds 'cause you know you're capturing at least all orbits shorter than L, and so you get the error bound.",
            "Looks like this, where it's decaying with respect to the spectral radius of the graph."
        ],
        [
            "OK, so here's an example where we tried this on 2D grids and so actually the example was a 256 by 256 grid with periodic boundary conditions.",
            "So at the ends that kind of wrapped around wraps around on itself an uniform edge weights, and then we construct blocks by taking L by L blocks and shifting these by half the width of the block to cover the grid.",
            "But also you have to include these intersections so you have L by L at half and Ella half by L&L 1/2 mile half.",
            "And doing all these calculations using this block Resomation ruled, estimate the determinant and using different block sizes from small to up to 32 by 32.",
            "And what I'm showing here is actually different in these three figures.",
            "Is results.",
            "As you vary this parameter.",
            "R&R is the largest you can make it in.",
            "This model is .25 because past that it becomes.",
            "The matrix becomes indefinite.",
            "And the first figure shows the relationship between the spectral radius of R and of this backtracking back trackless graph are prime.",
            "The second figure is showing well.",
            "First of all, the blue is the actual partition function or the log of the partition function normalized by the number of nodes.",
            "The red is the BP estimate an what I'm showing in green here is for different block sizes 248 and so forth.",
            "Are the estimates you would get using this block resomation method.",
            "Just capturing these local Orbitz and you see that the two by two block is actually worse than the BP estimate between 4:00 and 8:00, and so on for approaching the correct."
        ],
        [
            "Sir.",
            "This third figure.",
            "So I think I forgot to mention here.",
            "So in addition to using this block Resomation method to calculate Z directly, you also can use it to calculate this correction term based on this auxiliary graph G prime is non backtracking graph.",
            "So then."
        ],
        [
            "Computing a correction to be P. And so here we see that indeed.",
            "So for block size of two, we're already well doing much better than belief propagation.",
            "And then again it quickly converges to the correct answer.",
            "And this last figure is comparing these two results for fixed value of our like something like .2 or .23.",
            "And looking at how the errors decaying as you increase the block size and it decays as we would expect for this exponential decay when you plot this in a log scale.",
            "One curious thing though, is that if you compare the block correction method against this or the block estimate versus the block correction, it's the correction method is better, but the amount seems to be sort of fixed, so for small block sizes there's an advantage to using this correction method, but for large block sizes the two methods are pretty comparable."
        ],
        [
            "OK, so to conclude, I mean, I guess the main point is I think this walk some orbit product representation of inference in Gaussian models is very useful.",
            "So useful tool is very intuitive way of thinking about inference is somehow it's.",
            "Using it, looking at the Gaussian model, you can get a clearer picture of what's going on.",
            "Then you could with a discrete model.",
            "For future work, we have a few extensions in mind.",
            "One is looking at generalized belief propagation and this actually is very closely related to this block resomation method I was talking about.",
            "Another is to try to extend these kind of methods to work for non walks on mobile models.",
            "And sort of.",
            "The idea is to choose the nearest walk solvable model, do inference based on that model and then try to compute corrections similar to in this talk.",
            "Another idea is using a bootstrapping approach where instead of looking at applying Gaussian belief propagation is matrix J.",
            "You take powers of J and running on this and use this to recover the determinant of J and finally multiscale methods.",
            "Since we can't really the hard thing is capturing these long orbits of the graph, maybe by looking at a coarse grain representation in the model, you can estimate those those orbits and add that to like this block of summation method.",
            "Thanks very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm Jason, and so I'm actually.",
                    "label": 0
                },
                {
                    "sent": "I've moved on from MIT finally.",
                    "label": 0
                },
                {
                    "sent": "I'm at Los Alamos national lab.",
                    "label": 1
                },
                {
                    "sent": "Now I'm working with Michael Chirkov Misha.",
                    "label": 0
                },
                {
                    "sent": "And this paper is with Misha and Vladimir Czerniak.",
                    "label": 0
                },
                {
                    "sent": "I also want to mention that that this also builds upon earlier work from MIT with Dmitri Molotov and Alan Wilsky.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so I'll just have a brief review of like graphical models and particularly inference in Gaussian graphical models.",
                    "label": 0
                },
                {
                    "sent": "A graphical model is a multivariate probability distribution where the overall distribution has a compact representation in terms of potential is defined on nodes and edges of a graph.",
                    "label": 1
                },
                {
                    "sent": "So you draw a graph.",
                    "label": 0
                },
                {
                    "sent": "The nodes represent random variables and the joint distribution of all of these is determined by this product of interactions or potential functions.",
                    "label": 0
                },
                {
                    "sent": "These models have a Markov property, which means that if you condition on the variables on a separator of the graph, there separated pieces are conditionally independent is actually sort of defining property of the graphical model.",
                    "label": 0
                },
                {
                    "sent": "Given such a model specified by potentials like this, we're interested in the inference problem and this means to compute marginal distributions by summing or integrating over all variables except for a single variable.",
                    "label": 0
                },
                {
                    "sent": "Are computing this normalization constant, also known as the partition function Z an?",
                    "label": 1
                },
                {
                    "sent": "These calculations are generally difficult in large complex graphical models.",
                    "label": 0
                },
                {
                    "sent": "A Gaussian graphical model is.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Just one which has this quadratic form as your energy function or in the exponent.",
                    "label": 0
                },
                {
                    "sent": "Is also called the information form of the Gaussian density, 'cause this matrix J its inverse is the covariance matrix, so the covariance K is like the uncertainty and Jay is like the information matrix and so here we'd like to calculate the covariance at least elements of that.",
                    "label": 1
                },
                {
                    "sent": "The mean vector, and perhaps the determinant of K or J inverse, which is related to the partition function.",
                    "label": 0
                },
                {
                    "sent": "This is a graphical model when JS sparse, so you only have non zero entries off the diagonal J for edges of the graph.",
                    "label": 0
                },
                {
                    "sent": "And you can also write this in this potential factorization from the previous page.",
                    "label": 0
                },
                {
                    "sent": "And here, if computing marginals reduces computing the mean or the variance of a variable.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so belief propagation is an approximate inference method.",
                    "label": 1
                },
                {
                    "sent": "It allows you to estimate these marginals through calculating set of messages, and these messages are calculated from solving these fixed point equations and involves taking in a set of messages from all your neighbors except for except for one and if using that with local information and then predicting that to your remaining neighbor, and this is thought of as a message passing from node I to know J and so function of the state of node J.",
                    "label": 0
                },
                {
                    "sent": "And you iterate this type of update until it converges to a fixed point, and then you compute marginals by combining these data node.",
                    "label": 1
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "You also can calculate pair.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Wise marginals this is slightly more complicated formula, but involves merging your local potentials with messages coming into a region and this is important if you want to estimate this partition function.",
                    "label": 0
                },
                {
                    "sent": "So here are the estimate of the partition function is formed from these local normalization constants computed from these in the course of calculating these marginal estimates.",
                    "label": 0
                },
                {
                    "sent": "Actually, belief propagation can be regarded as solving for a saddle point of this right expression on the right hand side with respect to variations in the messages.",
                    "label": 1
                },
                {
                    "sent": "But the motivation for this is that in trees it converges in a finite number of steps, and then it's exact.",
                    "label": 1
                },
                {
                    "sent": "In that case BP is really just a form of.",
                    "label": 1
                },
                {
                    "sent": "You can think of it as a form of variable elimination.",
                    "label": 0
                },
                {
                    "sent": "To calculate this this partition the normalization constant.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In the marginals.",
                    "label": 0
                },
                {
                    "sent": "So Gaussian belief propagation is just a special case of this, where we have messages that are written in this form, so the messages are based on the quadratic form.",
                    "label": 0
                },
                {
                    "sent": "So rather than actually passing this function is a message.",
                    "label": 0
                },
                {
                    "sent": "You just store these two parameters of this function and those become your messages in Gaussian belief propagation.",
                    "label": 1
                },
                {
                    "sent": "Computing these integrals involved in the in the in the BP equations reduces to these formulas in terms of these parameters, and actually this is equivalent to.",
                    "label": 0
                },
                {
                    "sent": "Basically, this performing Gaussian elimination in this representation of this information form.",
                    "label": 0
                },
                {
                    "sent": "Once you have one, once these converge, then you compute means and variances using these rules, and that determines the marginal distributions.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well, you also can calculate the pairwise covariance and edges, and from this you can calculate an estimate of the of the determinant.",
                    "label": 1
                },
                {
                    "sent": "So here Z is the determinant of the covariance matrix and the BP estimate is formed from local determinants of edges and at nodes.",
                    "label": 0
                },
                {
                    "sent": "And again, this would give you the exact determinant restructuring model, but it's an approximation loopy graphs.",
                    "label": 0
                },
                {
                    "sent": "So a big part of this talk is basically aimed at how to interpret this estimate and understand how accurate it is and how to correct it.",
                    "label": 0
                },
                {
                    "sent": "OK, so one of.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Important piece of background is that.",
                    "label": 0
                },
                {
                    "sent": "I believe propagation is can be interpreted as exact inference on what's called the computation tree graph.",
                    "label": 0
                },
                {
                    "sent": "So here we have a loopy graph and when we run belief propagation on it, and if you look at the calculation and the marginal at one node after 1234 steps is equivalent to building this tree where you start at that node and you attach his neighbors.",
                    "label": 0
                },
                {
                    "sent": "Then you attach their neighbors and you sort of trace all paths.",
                    "label": 0
                },
                {
                    "sent": "Four steps away from that node.",
                    "label": 0
                },
                {
                    "sent": "And then the messages that you computed in those four iterations basically corresponds to variable elimination in history.",
                    "label": 0
                },
                {
                    "sent": "At the first iteration, you sort of eliminated these nodes, and that's the first set of messages in the second set of messages in 3rd and 4th.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so now I'm going to give a little bit of review on some background work idea.",
                    "label": 0
                },
                {
                    "sent": "Which meeting are some work I did earlier with Dmitry Molotov and Alan will scheme.",
                    "label": 0
                },
                {
                    "sent": "And this involves what we call walk sums.",
                    "label": 0
                },
                {
                    "sent": "So let Jay this information sparse information matrix be written as I -- R. And actually if you normalize J so that the diagonal is unit diagonal, this R it's a matrix of partial correlation coefficients in the Gaussian model, and so it's a sparse matrix.",
                    "label": 0
                },
                {
                    "sent": "You only have these coefficients where there's an interaction in your graphical model.",
                    "label": 0
                },
                {
                    "sent": "Well, there's this Neumann series, which is I minus.",
                    "label": 1
                },
                {
                    "sent": "Our inverse is a sum of powers of our.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "This is this basically generates walks in the graph 'cause are sparse matrix is like a ninja weighted adjacency matrix of the graph.",
                    "label": 0
                },
                {
                    "sent": "So you take powers of this.",
                    "label": 0
                },
                {
                    "sent": "This is generating sums of walks of length L in the graph, and so this leads to this walk.",
                    "label": 0
                },
                {
                    "sent": "Some interpretation of inference in Gaussian models were basically you.",
                    "label": 1
                },
                {
                    "sent": "By expanding this SRL, you expressed the elements of the covariance as sums of walks from I to J in the graph, but it's sort of sorted by length.",
                    "label": 0
                },
                {
                    "sent": "Well, you can relax that to just some overall walks in my DJ without requiring this sorting of walks by their length, but requires an additional condition.",
                    "label": 0
                },
                {
                    "sent": "This is what we call walk Summable.",
                    "label": 0
                },
                {
                    "sent": "And this is defined as the sum over all walks is absolutely convergent 'cause there's infinitely many walks in a graph between two points, so that then implies that these time kind of expressions are well defined, and since they converge for no any ordering that you can think of.",
                    "label": 0
                },
                {
                    "sent": "And Conversely, the same value, independent of the ordering also means are expressed as walks, which ended a node related by this H vector devalues H at the start of the lock.",
                    "label": 0
                },
                {
                    "sent": "OK, so we now have an.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I understand how to extend this to compute the determinant.",
                    "label": 0
                },
                {
                    "sent": "But we have to define what we call orbits so.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you look at this.",
                    "label": 0
                },
                {
                    "sent": "Here if you look at KII, it's a sum of clothes walk.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is it a node?",
                    "label": 0
                },
                {
                    "sent": "Well, a similar idea shows up in this expression and the determinant.",
                    "label": 0
                },
                {
                    "sent": "So walk is closed.",
                    "label": 0
                },
                {
                    "sent": "It begins and ends at the same vertex.",
                    "label": 1
                },
                {
                    "sent": "It's primitive if it's not a duplicate of a shorter walk.",
                    "label": 0
                },
                {
                    "sent": "And then we consider two primitive walks to be equivalent if one is just sort of a cyclic shift to the other if they start at different points.",
                    "label": 1
                },
                {
                    "sent": "And then we define orbits L to be these equivalence classes of closed primitive walks.",
                    "label": 0
                },
                {
                    "sent": "Well then the determinant can be expressed as a product over all orbits of the graph of this expression.",
                    "label": 0
                },
                {
                    "sent": "So this is yell is sort of the weight of an orbit and is constructed by taking a product of edge weights over the orbit and computing this one minus that number inverse.",
                    "label": 0
                },
                {
                    "sent": "And this is again for these walk symbol models where where actually I think I forgot to mention that walks mobility property is equivalent to the spectral radius of this matrix being less than one after you take absolute values of all its elements.",
                    "label": 0
                },
                {
                    "sent": "So that's the first main result of our paper.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "OK, so now we're going to look at how to interpret Gaussian belief propagation within this framework.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Going back to the work with Demetria Nanalan we showed we basically just said, well, we combine the interpretation and belief propagation is exact inference in the computation tree, together with interpreting inference in the computation tree.",
                    "label": 1
                },
                {
                    "sent": "Computing these walk sums.",
                    "label": 1
                },
                {
                    "sent": "And this leads to a simple picture where we can show that BP computes the complete walk, some for the means it captures all the walks you need to get the means, but it's incomplete with respect to the variances.",
                    "label": 0
                },
                {
                    "sent": "Fucking this go back.",
                    "label": 0
                },
                {
                    "sent": "The reason for.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That is, if you look at a walk that goes around a cycle like 12541.",
                    "label": 0
                },
                {
                    "sent": "Well, you can trace.",
                    "label": 0
                },
                {
                    "sent": "You can map that to walk in the computation tree by going backwards from from the root node.",
                    "label": 0
                },
                {
                    "sent": "So 14521 so that walk lose there now for the mean calculations.",
                    "label": 0
                },
                {
                    "sent": "This actually is included in the calculation of the mean at this node, 'cause it only has to end it at the root node, but the variance is you have to begin and in at the root node, so that wouldn't be added to the variance estimate computed by Gaussian BP.",
                    "label": 0
                },
                {
                    "sent": "So a similar thing happens with respect to the determinant estimate, so we have.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Define.",
                    "label": 0
                },
                {
                    "sent": "This definition of a totally backtracking orbit.",
                    "label": 0
                },
                {
                    "sent": "So an orbit is reduce aghbal if it contains backtracking steps like Iga to Ji.",
                    "label": 1
                },
                {
                    "sent": "Otherwise it's irreducible or back track list.",
                    "label": 0
                },
                {
                    "sent": "We say so.",
                    "label": 0
                },
                {
                    "sent": "Every orbit has a unique irreducible core.",
                    "label": 1
                },
                {
                    "sent": "If you start deleting these backtracks, eventually you get to a back trackless orbit and so will do.",
                    "label": 1
                },
                {
                    "sent": "Note that by gamma.",
                    "label": 0
                },
                {
                    "sent": "And also we let L gamma denote the set of all orbits which reduced to gamma under this backtrack deletion procedure.",
                    "label": 0
                },
                {
                    "sent": "And finally we stay in orbit is totally backtracking.",
                    "label": 0
                },
                {
                    "sent": "If it actually reduces down to just named the walk.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for example, if you just go 12321, if you delete these backtracking steps, it just reduces to nothing.",
                    "label": 0
                },
                {
                    "sent": "So that's a totally backtracking walk, and these are exactly the sort of walks that you can bet is closed walks in the computation tree.",
                    "label": 0
                },
                {
                    "sent": "So the theorem says that that GBP, which we defined earlier is actually equal to a product over just the subset of totally backtracking orbits, whereas the fools you would be include more orbits.",
                    "label": 0
                },
                {
                    "sent": "OK, so we have this correction.",
                    "label": 0
                },
                {
                    "sent": "Z is equal to VBP times the rest of these orbits.",
                    "label": 0
                },
                {
                    "sent": "These, not these orbits, aren't totally backtracking.",
                    "label": 0
                },
                {
                    "sent": "We actually can look at this in bound the error based on this expression and we have.",
                    "label": 0
                },
                {
                    "sent": "If you look at the ratio of Zetas EP.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Like that would be close to one.",
                    "label": 0
                },
                {
                    "sent": "Take the log of that.",
                    "label": 0
                },
                {
                    "sent": "The absolute value is bounded by this expression, where row is the spectral radius parameter.",
                    "label": 0
                },
                {
                    "sent": "So you see if you fix if you bound the spectral radius on G is the growth of the graph is the length of the shortest cycle.",
                    "label": 1
                },
                {
                    "sent": "Then you see that the error is sort of decaying exponentially with this growth.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so now we're interested in starting to compute how to think about computing corrections to BP, and it's not really tractable to actually enumerate these one at a time, so we want to start reducing this to things which are more tractable to compute.",
                    "label": 0
                },
                {
                    "sent": "The first step is this reduction to backtrack less orbit products.",
                    "label": 1
                },
                {
                    "sent": "So here we take this full product overall orbits and we group them by their by their back trackless core and define the gamma prime to be the product over that equivalence class of orbits.",
                    "label": 0
                },
                {
                    "sent": "Well the nice thing is is that the Z camera prime you actually compute that easily from the Gaussian BP solution.",
                    "label": 0
                },
                {
                    "sent": "So this is the formula for Z. Gamer Prime is exactly the same As for ZL, except we modify these edge weights.",
                    "label": 0
                },
                {
                    "sent": "By multiplying by this factor of 1 minus Alpha universe where Alpha is coming from belief propagation.",
                    "label": 0
                },
                {
                    "sent": "The idea here is basically that multiplying by this this factor is reinserting all of the totally backtracking walks at each point along a back trackless orbit.",
                    "label": 1
                },
                {
                    "sent": "So rather than looking at all these little sort of variations on it, if you take a backtrack a sore but you can add little excursions.",
                    "label": 0
                },
                {
                    "sent": "Each point which are totally backtracking rather than look counting those separately and count them all at once with the help of this BP solution and basis, because BP is already pre computing these totally backtracking excursions at a point.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so one other thing which is kind of cute.",
                    "label": 0
                },
                {
                    "sent": "Once once we reduce this to a product of back trackless orbits, we can actually construct another determinant which we calculate all of those.",
                    "label": 0
                },
                {
                    "sent": "So for this graph G We construct this graph G prime, where for each directed edge of the graph you include two nodes in this G prime and then you connect these biotics according to this non backtracking rule.",
                    "label": 0
                },
                {
                    "sent": "So you connect node I jatin ojk.",
                    "label": 0
                },
                {
                    "sent": "As long as I is not equal to K. And so and then all the orbits in this graph are exactly equivalent to backtrack with orbits in the original graph, and so then by adding appropriate edge weights.",
                    "label": 0
                },
                {
                    "sent": "Here we can make the determinant of this graph equal.",
                    "label": 0
                },
                {
                    "sent": "This correction factor would like to compute.",
                    "label": 0
                },
                {
                    "sent": "So the advantage of this though, is it sort of tells us how to approximate this approximate this correction factor.",
                    "label": 0
                },
                {
                    "sent": "And the actual algorithm that we used to compute these sort of things is based on what I'm calling block resomation here.",
                    "label": 0
                },
                {
                    "sent": "Sort of.",
                    "label": 0
                },
                {
                    "sent": "The idea is if you look at a graph like this.",
                    "label": 0
                },
                {
                    "sent": "And you look at some sub graph.",
                    "label": 0
                },
                {
                    "sent": "You can compute the determinant based on just that sub graph and what you're capturing is just a subset of orbits, all orbits of the larger graph which live in that sub graph.",
                    "label": 0
                },
                {
                    "sent": "So what you'd like to do is do these computations and sort of overlapping blocks covering, say, the grid.",
                    "label": 0
                },
                {
                    "sent": "Anne piece these pieces together to get all the orbits you can from the original graph.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's a little technical.",
                    "label": 0
                },
                {
                    "sent": "Maybe I won't do all the details, but basically you said if you specify a set of subgraphs, I'm calling blocks here.",
                    "label": 0
                },
                {
                    "sent": "And because some of these on intersections of blocks, you have to avoid over counting the orbits in that intersection, so you also include intersections.",
                    "label": 0
                },
                {
                    "sent": "But then you sort of assign accounting number teaching these blocks.",
                    "label": 0
                },
                {
                    "sent": "And then to form an estimate of Z based on all the loops covered by any block, use this formula and basically involves computing determine subgraphs and multiplying these together, but raised the power is determined by this rule.",
                    "label": 0
                },
                {
                    "sent": "And if you choose your blocks appropriately, say to cover all orbits of the graph up to some length L, then you again get error bounds 'cause you know you're capturing at least all orbits shorter than L, and so you get the error bound.",
                    "label": 1
                },
                {
                    "sent": "Looks like this, where it's decaying with respect to the spectral radius of the graph.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so here's an example where we tried this on 2D grids and so actually the example was a 256 by 256 grid with periodic boundary conditions.",
                    "label": 0
                },
                {
                    "sent": "So at the ends that kind of wrapped around wraps around on itself an uniform edge weights, and then we construct blocks by taking L by L blocks and shifting these by half the width of the block to cover the grid.",
                    "label": 0
                },
                {
                    "sent": "But also you have to include these intersections so you have L by L at half and Ella half by L&L 1/2 mile half.",
                    "label": 0
                },
                {
                    "sent": "And doing all these calculations using this block Resomation ruled, estimate the determinant and using different block sizes from small to up to 32 by 32.",
                    "label": 0
                },
                {
                    "sent": "And what I'm showing here is actually different in these three figures.",
                    "label": 0
                },
                {
                    "sent": "Is results.",
                    "label": 0
                },
                {
                    "sent": "As you vary this parameter.",
                    "label": 0
                },
                {
                    "sent": "R&R is the largest you can make it in.",
                    "label": 0
                },
                {
                    "sent": "This model is .25 because past that it becomes.",
                    "label": 0
                },
                {
                    "sent": "The matrix becomes indefinite.",
                    "label": 0
                },
                {
                    "sent": "And the first figure shows the relationship between the spectral radius of R and of this backtracking back trackless graph are prime.",
                    "label": 0
                },
                {
                    "sent": "The second figure is showing well.",
                    "label": 0
                },
                {
                    "sent": "First of all, the blue is the actual partition function or the log of the partition function normalized by the number of nodes.",
                    "label": 0
                },
                {
                    "sent": "The red is the BP estimate an what I'm showing in green here is for different block sizes 248 and so forth.",
                    "label": 0
                },
                {
                    "sent": "Are the estimates you would get using this block resomation method.",
                    "label": 0
                },
                {
                    "sent": "Just capturing these local Orbitz and you see that the two by two block is actually worse than the BP estimate between 4:00 and 8:00, and so on for approaching the correct.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sir.",
                    "label": 0
                },
                {
                    "sent": "This third figure.",
                    "label": 0
                },
                {
                    "sent": "So I think I forgot to mention here.",
                    "label": 0
                },
                {
                    "sent": "So in addition to using this block Resomation method to calculate Z directly, you also can use it to calculate this correction term based on this auxiliary graph G prime is non backtracking graph.",
                    "label": 0
                },
                {
                    "sent": "So then.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Computing a correction to be P. And so here we see that indeed.",
                    "label": 0
                },
                {
                    "sent": "So for block size of two, we're already well doing much better than belief propagation.",
                    "label": 0
                },
                {
                    "sent": "And then again it quickly converges to the correct answer.",
                    "label": 0
                },
                {
                    "sent": "And this last figure is comparing these two results for fixed value of our like something like .2 or .23.",
                    "label": 0
                },
                {
                    "sent": "And looking at how the errors decaying as you increase the block size and it decays as we would expect for this exponential decay when you plot this in a log scale.",
                    "label": 0
                },
                {
                    "sent": "One curious thing though, is that if you compare the block correction method against this or the block estimate versus the block correction, it's the correction method is better, but the amount seems to be sort of fixed, so for small block sizes there's an advantage to using this correction method, but for large block sizes the two methods are pretty comparable.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so to conclude, I mean, I guess the main point is I think this walk some orbit product representation of inference in Gaussian models is very useful.",
                    "label": 1
                },
                {
                    "sent": "So useful tool is very intuitive way of thinking about inference is somehow it's.",
                    "label": 0
                },
                {
                    "sent": "Using it, looking at the Gaussian model, you can get a clearer picture of what's going on.",
                    "label": 1
                },
                {
                    "sent": "Then you could with a discrete model.",
                    "label": 1
                },
                {
                    "sent": "For future work, we have a few extensions in mind.",
                    "label": 0
                },
                {
                    "sent": "One is looking at generalized belief propagation and this actually is very closely related to this block resomation method I was talking about.",
                    "label": 1
                },
                {
                    "sent": "Another is to try to extend these kind of methods to work for non walks on mobile models.",
                    "label": 0
                },
                {
                    "sent": "And sort of.",
                    "label": 0
                },
                {
                    "sent": "The idea is to choose the nearest walk solvable model, do inference based on that model and then try to compute corrections similar to in this talk.",
                    "label": 1
                },
                {
                    "sent": "Another idea is using a bootstrapping approach where instead of looking at applying Gaussian belief propagation is matrix J.",
                    "label": 0
                },
                {
                    "sent": "You take powers of J and running on this and use this to recover the determinant of J and finally multiscale methods.",
                    "label": 0
                },
                {
                    "sent": "Since we can't really the hard thing is capturing these long orbits of the graph, maybe by looking at a coarse grain representation in the model, you can estimate those those orbits and add that to like this block of summation method.",
                    "label": 0
                },
                {
                    "sent": "Thanks very much.",
                    "label": 0
                }
            ]
        }
    }
}