{
    "id": "33jwkug7y7w6vfrhlwf7wo6jenqg636j",
    "title": "Latent distance graphs from news data",
    "info": {
        "author": [
            "Luka Bizjak, Artificial Intelligence Laboratory, Jo\u017eef Stefan Institute"
        ],
        "published": "Nov. 14, 2019",
        "recorded": "October 2019",
        "category": [
            "Top->Computer Science->Data Mining",
            "Top->Computer Science->Artificial Intelligence"
        ]
    },
    "url": "http://videolectures.net/sikdd2019_bizjak_latent_distance_graphs/",
    "segmentation": [
        [
            "So I'm going to talk about later distance graphs from you.",
            "This data.",
            "This is joint work with Micah Parker and Alaska's Merle.",
            "Yeah."
        ],
        [
            "So news data basically offers a constant stream of new information about his business activities, political events, natural disasters, and many other topics and what we would like to do is somehow find the relevant structures in such data.",
            "But the difficulties that one faces is basically that we have very fuzzy nature of this data.",
            "So this is really hard to build models, and one of the goal is to build models which overcome some of these difficulties.",
            "An at the end one would like to maybe make predictions from this data.",
            "Say for example we may want to monitor to news data.",
            "Which types of industries are doing well?",
            "So in our case."
        ],
        [
            "We took the data from the event registry and basically we focused on the business category.",
            "And we took data from years 2017 and 2018 and we obtained this data through this Python package event registry, which an event registry gives you.",
            "This classification of events into certain categories.",
            "Ann, you have a hierarchical structure of this category, which is very nice to work with.",
            "So for example you have business being split into banking and services and this goes to investing and so on.",
            "And."
        ],
        [
            "First watch, we'll see later why we want to do this.",
            "But first we want to associate a vector for two each event.",
            "And how we do this with this?",
            "We do this with this pre trained Google's work track model and this gives us a vector in three dimensional space in this 3 dimensional is a consequence of this.",
            "Google's pre trained model.",
            "Otherwise we could have some other.",
            "The marginal is whatever N dimensional space.",
            "So we use all counts, concepts and weights that are extracted from the news articles of every event by Event Registry.",
            "So here is the formula.",
            "So this is really a vector, so it's a linear combination where you sum over the set of all concept of event and have some weights which represented the scalars.",
            "Factors of this fact."
        ],
        [
            "So this is sort of the core of this.",
            "This is this latent distance model.",
            "We're collecting feature this is yeah, yeah, exactly otherwise you just take concept of event and then.",
            "Otherwise it will just too much so late and distance model is random graph model, so random graph is just the graph, But you are given probability between edges, so the best example is say elders rainy graph when you take class of all graphs with N vertices and you uniformly at random pick one out and this is your random graph.",
            "So how you construct this you constructed with adjacency matrix?",
            "But first you define distance function and this is really distant function, not a metric.",
            "So this is the formula some exponential with some uniforming parameters.",
            "Basically this represents the sparsity of a network and characteristic scale of your.",
            "Not your problem, so this parameter is very much depends on the problem you consider.",
            "So how you get the graph?",
            "Basically, each vertex of your network network is represented by some vector in this Euclidean space, an probabilities for edges are given by Bernoulli distribution of this distance function.",
            "So you take pairs and compute and this is symmetric, so you get the symmetric adjacency matrix.",
            "So this also implies that you're.",
            "Random graph would be undirected otherwise yeah.",
            "So."
        ],
        [
            "So how you do this?",
            "Now you can build this news data latent model.",
            "So now we have numeric forms of data.",
            "We have events 2 vectors.",
            "And you can use above model that we previously described to represent this data.",
            "So embedded vents now correspond to this vector vectors in this highly dimensional Indian space.",
            "And you can construct adjacency matrix by simply computing this distance function for every event.",
            "Every pair of events OK. And then you just take the Bernoulli an you get your random graph.",
            "But in order to.",
            "You see in.",
            "If you take scale only day by day, the number of events varies, so then it's really hard to model.",
            "I mean random graph being dynamic and model it with vertices changing through time.",
            "It's practically impractical in from mathematical point of view.",
            "So what you have to do you have to aggregate this matrix W to get a matrix depending of fixed number of parameters.",
            "So here is the formula how you do this.",
            "So basically seeing.",
            "CK and Ally and CL represent the fixed.",
            "Sort of concept, so you fix 100 most frequent concepts and you check over your.",
            "Over your big I mean initial matrix.",
            "Whether your event is in one of these two concepts and you range through all possible values, and this is what you do so you don't end up in now.",
            "This will be sort of so the new matrix will be will not be 01, but will be depending on natural numbers because you some OK.",
            "It's really natural times natural."
        ],
        [
            "So here is the example of this graph for business category.",
            "And you can see that.",
            "Pretty much right.",
            "Things are connected, like coaching, consulting and have investment banks, financial services, payment associations.",
            "Holding companies an loans college financing, residential housing and so on.",
            "So it kind of works.",
            "Uh."
        ],
        [
            "So when you have these graphs, you can do some graph analysis, so we will make a generated the adjacency matrix for each day in my one year time period, and we obviously use the aggregated adjacency matrix because the problem I said before of varying varying vertice is.",
            "And then you get a sequence of graphs and you can say OK, this is now a dynamic graph.",
            "OK, because you have a sequence of graphs for each day.",
            "And then once you have this graph, you can check the interaction between some categories.",
            "So you just some overall adjacency matrices and then check row.",
            "So because every row represents a particular category or event or whatever you like and also what you can do is to check evolution of degree.",
            "So you fix a node and check how it evolves through time and you get As for every node you get a degree as a function of time which is.",
            "At which will see next slide."
        ],
        [
            "So here you have some dependencies between categories.",
            "For instance, you fix the category banking and services an it's much related to holding companies, financial services, finance, payments, associations.",
            "Ann, you have other one oil and gas and we want to point out this one because you see you have fats and oil and this kind of does not make sense.",
            "You know, because oil and gas has more to do with mining and import export.",
            "But oil, fats and oil has something do I know food industry or something so this is probably the.",
            "This call, this is basically probably from the vault embeddings, because as far as they're kind of similar, so this is a consequence.",
            "Yeah, yeah, so this is kind of kind of things that you have to take into account.",
            "And."
        ],
        [
            "So this is then the evolution of nodes and this kind of opens up that you might be able to define a certain random process on the these degrees, but.",
            "Who knows?",
            "And because there is no theory."
        ],
        [
            "Random graphs, I mean of dynamic random graphs, but you want if you want to make predictions you have to use neural networks.",
            "So this is what we did.",
            "And.",
            "So we tried to use neural networks to make prediction about potential structure of the network and we build really top level model.",
            "So we only use really top level categories like business, politics and so on.",
            "Things we use like 10 of them and what we are what we were using we were using LSD M neural network with three residual STM layer layers and final dense layer an we optimize mean square error with Adam Optimizer so.",
            "This is just some some sort of a sophisticated gradient descent method or algorithm."
        ],
        [
            "So this is a picture of this model.",
            "Chicken."
        ],
        [
            "And this is the mean squared error of the learning of the on the whole neural net.",
            "So you see it kind of minimizes around 800 epochs.",
            "And the next slide shows you."
        ],
        [
            "The prediction scores for training and prediction, so this is the prediction.",
            "This is the real line and this is a validation so.",
            "The model kind of catches the trend, but not too well.",
            "Cannot see the the pig so you can tell something, but not too much.",
            "And this this is the problem is in the graph structure.",
            "Is the problem with sparsity of the adjacency matrices."
        ],
        [
            "So the conclusion of this work is basically we use.",
            "We use this data from event registry build this late in distant model on top of it and we see that we get a reasonably good representation of events, registry data which we saw in the business graph that we showed.",
            "And obviously, because the latent model is quite general, it could be used for other datasets.",
            "It's really general model, but with news data in any sort of wild datasets you have big problem of noise and this implies that you have problems with sparsity of your adjacency matrix.",
            "And then this is really makes life hard for analysis because you cannot use graph laplacians, you cannot use any modern techniques.",
            "Uh.",
            "An obviously as we saw on the table, we have dependency on board embeddings which is also has to be taken into account and maybe use some other like birds maybe to see if you get better better scores with that so."
        ],
        [
            "And this is it."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I'm going to talk about later distance graphs from you.",
                    "label": 1
                },
                {
                    "sent": "This data.",
                    "label": 0
                },
                {
                    "sent": "This is joint work with Micah Parker and Alaska's Merle.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So news data basically offers a constant stream of new information about his business activities, political events, natural disasters, and many other topics and what we would like to do is somehow find the relevant structures in such data.",
                    "label": 1
                },
                {
                    "sent": "But the difficulties that one faces is basically that we have very fuzzy nature of this data.",
                    "label": 0
                },
                {
                    "sent": "So this is really hard to build models, and one of the goal is to build models which overcome some of these difficulties.",
                    "label": 0
                },
                {
                    "sent": "An at the end one would like to maybe make predictions from this data.",
                    "label": 1
                },
                {
                    "sent": "Say for example we may want to monitor to news data.",
                    "label": 1
                },
                {
                    "sent": "Which types of industries are doing well?",
                    "label": 0
                },
                {
                    "sent": "So in our case.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We took the data from the event registry and basically we focused on the business category.",
                    "label": 1
                },
                {
                    "sent": "And we took data from years 2017 and 2018 and we obtained this data through this Python package event registry, which an event registry gives you.",
                    "label": 0
                },
                {
                    "sent": "This classification of events into certain categories.",
                    "label": 1
                },
                {
                    "sent": "Ann, you have a hierarchical structure of this category, which is very nice to work with.",
                    "label": 0
                },
                {
                    "sent": "So for example you have business being split into banking and services and this goes to investing and so on.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "First watch, we'll see later why we want to do this.",
                    "label": 0
                },
                {
                    "sent": "But first we want to associate a vector for two each event.",
                    "label": 1
                },
                {
                    "sent": "And how we do this with this?",
                    "label": 0
                },
                {
                    "sent": "We do this with this pre trained Google's work track model and this gives us a vector in three dimensional space in this 3 dimensional is a consequence of this.",
                    "label": 0
                },
                {
                    "sent": "Google's pre trained model.",
                    "label": 0
                },
                {
                    "sent": "Otherwise we could have some other.",
                    "label": 0
                },
                {
                    "sent": "The marginal is whatever N dimensional space.",
                    "label": 0
                },
                {
                    "sent": "So we use all counts, concepts and weights that are extracted from the news articles of every event by Event Registry.",
                    "label": 1
                },
                {
                    "sent": "So here is the formula.",
                    "label": 0
                },
                {
                    "sent": "So this is really a vector, so it's a linear combination where you sum over the set of all concept of event and have some weights which represented the scalars.",
                    "label": 0
                },
                {
                    "sent": "Factors of this fact.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is sort of the core of this.",
                    "label": 0
                },
                {
                    "sent": "This is this latent distance model.",
                    "label": 1
                },
                {
                    "sent": "We're collecting feature this is yeah, yeah, exactly otherwise you just take concept of event and then.",
                    "label": 0
                },
                {
                    "sent": "Otherwise it will just too much so late and distance model is random graph model, so random graph is just the graph, But you are given probability between edges, so the best example is say elders rainy graph when you take class of all graphs with N vertices and you uniformly at random pick one out and this is your random graph.",
                    "label": 0
                },
                {
                    "sent": "So how you construct this you constructed with adjacency matrix?",
                    "label": 0
                },
                {
                    "sent": "But first you define distance function and this is really distant function, not a metric.",
                    "label": 0
                },
                {
                    "sent": "So this is the formula some exponential with some uniforming parameters.",
                    "label": 1
                },
                {
                    "sent": "Basically this represents the sparsity of a network and characteristic scale of your.",
                    "label": 0
                },
                {
                    "sent": "Not your problem, so this parameter is very much depends on the problem you consider.",
                    "label": 0
                },
                {
                    "sent": "So how you get the graph?",
                    "label": 0
                },
                {
                    "sent": "Basically, each vertex of your network network is represented by some vector in this Euclidean space, an probabilities for edges are given by Bernoulli distribution of this distance function.",
                    "label": 1
                },
                {
                    "sent": "So you take pairs and compute and this is symmetric, so you get the symmetric adjacency matrix.",
                    "label": 0
                },
                {
                    "sent": "So this also implies that you're.",
                    "label": 0
                },
                {
                    "sent": "Random graph would be undirected otherwise yeah.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how you do this?",
                    "label": 0
                },
                {
                    "sent": "Now you can build this news data latent model.",
                    "label": 1
                },
                {
                    "sent": "So now we have numeric forms of data.",
                    "label": 1
                },
                {
                    "sent": "We have events 2 vectors.",
                    "label": 1
                },
                {
                    "sent": "And you can use above model that we previously described to represent this data.",
                    "label": 0
                },
                {
                    "sent": "So embedded vents now correspond to this vector vectors in this highly dimensional Indian space.",
                    "label": 0
                },
                {
                    "sent": "And you can construct adjacency matrix by simply computing this distance function for every event.",
                    "label": 0
                },
                {
                    "sent": "Every pair of events OK. And then you just take the Bernoulli an you get your random graph.",
                    "label": 0
                },
                {
                    "sent": "But in order to.",
                    "label": 0
                },
                {
                    "sent": "You see in.",
                    "label": 0
                },
                {
                    "sent": "If you take scale only day by day, the number of events varies, so then it's really hard to model.",
                    "label": 0
                },
                {
                    "sent": "I mean random graph being dynamic and model it with vertices changing through time.",
                    "label": 0
                },
                {
                    "sent": "It's practically impractical in from mathematical point of view.",
                    "label": 0
                },
                {
                    "sent": "So what you have to do you have to aggregate this matrix W to get a matrix depending of fixed number of parameters.",
                    "label": 1
                },
                {
                    "sent": "So here is the formula how you do this.",
                    "label": 0
                },
                {
                    "sent": "So basically seeing.",
                    "label": 0
                },
                {
                    "sent": "CK and Ally and CL represent the fixed.",
                    "label": 0
                },
                {
                    "sent": "Sort of concept, so you fix 100 most frequent concepts and you check over your.",
                    "label": 0
                },
                {
                    "sent": "Over your big I mean initial matrix.",
                    "label": 0
                },
                {
                    "sent": "Whether your event is in one of these two concepts and you range through all possible values, and this is what you do so you don't end up in now.",
                    "label": 0
                },
                {
                    "sent": "This will be sort of so the new matrix will be will not be 01, but will be depending on natural numbers because you some OK.",
                    "label": 0
                },
                {
                    "sent": "It's really natural times natural.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here is the example of this graph for business category.",
                    "label": 1
                },
                {
                    "sent": "And you can see that.",
                    "label": 0
                },
                {
                    "sent": "Pretty much right.",
                    "label": 0
                },
                {
                    "sent": "Things are connected, like coaching, consulting and have investment banks, financial services, payment associations.",
                    "label": 0
                },
                {
                    "sent": "Holding companies an loans college financing, residential housing and so on.",
                    "label": 0
                },
                {
                    "sent": "So it kind of works.",
                    "label": 0
                },
                {
                    "sent": "Uh.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So when you have these graphs, you can do some graph analysis, so we will make a generated the adjacency matrix for each day in my one year time period, and we obviously use the aggregated adjacency matrix because the problem I said before of varying varying vertice is.",
                    "label": 1
                },
                {
                    "sent": "And then you get a sequence of graphs and you can say OK, this is now a dynamic graph.",
                    "label": 1
                },
                {
                    "sent": "OK, because you have a sequence of graphs for each day.",
                    "label": 0
                },
                {
                    "sent": "And then once you have this graph, you can check the interaction between some categories.",
                    "label": 0
                },
                {
                    "sent": "So you just some overall adjacency matrices and then check row.",
                    "label": 0
                },
                {
                    "sent": "So because every row represents a particular category or event or whatever you like and also what you can do is to check evolution of degree.",
                    "label": 0
                },
                {
                    "sent": "So you fix a node and check how it evolves through time and you get As for every node you get a degree as a function of time which is.",
                    "label": 0
                },
                {
                    "sent": "At which will see next slide.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here you have some dependencies between categories.",
                    "label": 1
                },
                {
                    "sent": "For instance, you fix the category banking and services an it's much related to holding companies, financial services, finance, payments, associations.",
                    "label": 1
                },
                {
                    "sent": "Ann, you have other one oil and gas and we want to point out this one because you see you have fats and oil and this kind of does not make sense.",
                    "label": 1
                },
                {
                    "sent": "You know, because oil and gas has more to do with mining and import export.",
                    "label": 0
                },
                {
                    "sent": "But oil, fats and oil has something do I know food industry or something so this is probably the.",
                    "label": 0
                },
                {
                    "sent": "This call, this is basically probably from the vault embeddings, because as far as they're kind of similar, so this is a consequence.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah, so this is kind of kind of things that you have to take into account.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is then the evolution of nodes and this kind of opens up that you might be able to define a certain random process on the these degrees, but.",
                    "label": 1
                },
                {
                    "sent": "Who knows?",
                    "label": 0
                },
                {
                    "sent": "And because there is no theory.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Random graphs, I mean of dynamic random graphs, but you want if you want to make predictions you have to use neural networks.",
                    "label": 0
                },
                {
                    "sent": "So this is what we did.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "So we tried to use neural networks to make prediction about potential structure of the network and we build really top level model.",
                    "label": 1
                },
                {
                    "sent": "So we only use really top level categories like business, politics and so on.",
                    "label": 1
                },
                {
                    "sent": "Things we use like 10 of them and what we are what we were using we were using LSD M neural network with three residual STM layer layers and final dense layer an we optimize mean square error with Adam Optimizer so.",
                    "label": 0
                },
                {
                    "sent": "This is just some some sort of a sophisticated gradient descent method or algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is a picture of this model.",
                    "label": 0
                },
                {
                    "sent": "Chicken.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is the mean squared error of the learning of the on the whole neural net.",
                    "label": 0
                },
                {
                    "sent": "So you see it kind of minimizes around 800 epochs.",
                    "label": 0
                },
                {
                    "sent": "And the next slide shows you.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The prediction scores for training and prediction, so this is the prediction.",
                    "label": 1
                },
                {
                    "sent": "This is the real line and this is a validation so.",
                    "label": 0
                },
                {
                    "sent": "The model kind of catches the trend, but not too well.",
                    "label": 0
                },
                {
                    "sent": "Cannot see the the pig so you can tell something, but not too much.",
                    "label": 0
                },
                {
                    "sent": "And this this is the problem is in the graph structure.",
                    "label": 0
                },
                {
                    "sent": "Is the problem with sparsity of the adjacency matrices.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the conclusion of this work is basically we use.",
                    "label": 0
                },
                {
                    "sent": "We use this data from event registry build this late in distant model on top of it and we see that we get a reasonably good representation of events, registry data which we saw in the business graph that we showed.",
                    "label": 1
                },
                {
                    "sent": "And obviously, because the latent model is quite general, it could be used for other datasets.",
                    "label": 0
                },
                {
                    "sent": "It's really general model, but with news data in any sort of wild datasets you have big problem of noise and this implies that you have problems with sparsity of your adjacency matrix.",
                    "label": 0
                },
                {
                    "sent": "And then this is really makes life hard for analysis because you cannot use graph laplacians, you cannot use any modern techniques.",
                    "label": 0
                },
                {
                    "sent": "Uh.",
                    "label": 0
                },
                {
                    "sent": "An obviously as we saw on the table, we have dependency on board embeddings which is also has to be taken into account and maybe use some other like birds maybe to see if you get better better scores with that so.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is it.",
                    "label": 0
                }
            ]
        }
    }
}