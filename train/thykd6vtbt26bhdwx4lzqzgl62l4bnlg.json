{
    "id": "thykd6vtbt26bhdwx4lzqzgl62l4bnlg",
    "title": "Empirical Game-Theoretic Analysis and the Behavior of Software Agents",
    "info": {
        "author": [
            "Michael P. Wellman, Department of Electrical Engineering and Computer Science, University of Michigan"
        ],
        "published": "July 21, 2011",
        "recorded": "June 2011",
        "category": [
            "Top->Computer Science->Artificial Intelligence->Planning and Scheduling"
        ]
    },
    "url": "http://videolectures.net/icaps2011_wellman_game/",
    "segmentation": [
        [
            "Thank you Carmela for those very kind words and thank you to the organizers for inviting me here.",
            "It's really a great pleasure to be here at Icaps.",
            "As Carmel mentioned, my thesis had the word planning in it and I used to do work that was called planning."
        ],
        [
            "But it's been awhile since I've been to icaps.",
            "In fact, thinking back the last talk I gave at Icaps was in actually wasn't in Icaps.",
            "It was apes back back then.",
            "Is about utility representation for decision theoretic planning, and I suspect not too many of you were here then.",
            "So I thought, hey, I know it's still actually a relevant topic.",
            "I can give that talk again.",
            "But unfortunately PowerPoint from 1992 is no longer viable, so looking at a couple more recent papers that actually we did have it icaps presented by my Co authors are more about the kinds of things that I've been doing since the reason I haven't been at icaps in recent years is because my research has focused on the multi agent aspect of decision making.",
            "I think that actually what I'm still interested in is decision making and planning.",
            "But particularly with respect to the issues that come up when there are multiple planners in the world, and so actually I'm going to talk about in and working to talk about today, I'm going to touch back on some of the things that were presented here seven years ago on market based scheduling an decision-making on supply chains."
        ],
        [
            "So just to make clear, this point of departure.",
            "Let me just end at a high level.",
            "Say what the planning problem is is that we want to find some behavior for our agent.",
            "That's going to optimize or satisfy some objectives with respect to the environment we expect, and we're striving for rationality.",
            "However, you want to define that we're all doing that when the environment contains other agents.",
            "I that means that what you do, how well, how effective, what you do turns out to be depends on what the other agents are going to do as well, and to even say that we have an informal radiance means we're according to them some kind of rationality as well.",
            "So to even acknowledge that problem, it says we want to view the other agents in the environment as themselves being rational planners.",
            "And that means your problem is now a game.",
            "You have this kind of reflection and you can still think of things in some respects in the same way we're still searching for.",
            "What to do with searching for a strategy or policy or a plan?",
            "But we have to now think in this multi dimensional space where there's a dimension for each agents plan.",
            "So we've taken whatever our planning problem is and there's multiplied the dimensionality by the number of agents and Moreover we can't just now think of the objective from one agents perspective, we have to now think of an overall perspective objective.",
            "So for example you're searching in this multi dimensional space and you're saying I want to find a plan for me that is going to be good when the other agents, being rational planners, are doing what they would.",
            "Be likely to do.",
            "OK, and you can characterize that, so we're looking at those problems."
        ],
        [
            "And the kinds of games that were particularly interested in are ones that have very complex dynamics.",
            "An high degrees of uncertainty, especially.",
            "For example, a lot of the games that we're interested in are motivated by scenarios in electronic Commerce, markets and trading.",
            "Very huge strategy.",
            "Space is a strategy.",
            "Is any function from a history of observations to what to do next?",
            "And you have severely incomplete information that is theirs.",
            "State of the other agents and information that they have.",
            "And it's not just that you might want to infer that, but you actually get relevant information dribbled out overtime based on what they do, and so that just tremendously complicates the problem.",
            "And because of that, you don't really see a lot of analytic solutions to game theoretic problems, except for, as I mentioned, very simple ones.",
            "These are problems that can be formalized and well specified in game theoretic terms, but regardless of the specific computational complexity results you believe or don't believe about this domain, the proof is in what actually happens that you just don't see analytic solutions for games that you care about, so there's two approaches, at least two approaches one can take, and I think the approach that most of the literature that labels itself as game theoretic takes is too.",
            "Abstract and approximate the game to the point where the analytic methods actually get traction, and typically that happens by getting rid of these characteristics like the dynamics and the uncertainty that are so problematic to begin with, and you can get a lot of insight.",
            "I think from some of these abstractions, and often that is actually the starting point for anything else, so I'm totally in favor of this approach.",
            "But in my group over the years we've been.",
            "Pursuing another approach, which is what the topic of today's talk is on using empirical and particularly simulation based methods for understanding a strategic environment for a game.",
            "And I think.",
            "Within that, within simulation based methods you could conceive of search based methods.",
            "OK, when I said the natural path from going from your roles of planning to games is to just up the dimensionality of the search, I'm not going to talk so much about search intensive methods.",
            "Actually this is probably an area where this community I think could contribute a lot to the multi agent world based on the tool set that you understand so well.",
            "I I think I think that would be a very worthwhile thing to do, but I'm going to talk about today.",
            "There are methods that are certainly employ a lot of search but also emphasize empirical techniques like statistics sampling, machine learning.",
            "So let me say what?"
        ],
        [
            "I mean by that and the approach that we've been calling empirical game theoretic analysis.",
            "You we start out actually by not even being given a an an analytic description of the game model, so I guess that's actually the point where you split off whether I want to search approach or empirical approach.",
            "So in a typical planning problem formulation, you're given a domain description, a formal description.",
            "And a lot of the things we care about your what we have really is a black box simulator.",
            "That's the best description we have of the game, and I think actually in.",
            "In practice, you wind up using something like that, so the way I would think about, say, the international planning competition, by the way, I really enjoyed that session the other day, showing that you have, you know, just really terrific enthusiasm and very vibrant competition.",
            "You view that as now resorting to the simulation based way of evaluating your planners the input to a planner is a domain model, and the planner itself is using that domain model to evaluate a plan.",
            "But when you want to evaluate planners.",
            "You are now going to a simulation based approach.",
            "OK, so that's the that's the the analogy to draw here is that now I'm going to want to look at be evaluating planners or decision makers agents again using the simulation based approach.",
            "Now, I said there's a huge strategy space, so we're going to parameterise it based on some structure given by an agent architecture and will give examples of that.",
            "And we're going to selectively explore this.",
            "We're going to give up right off the bat at trying to have exhaustive coverage, but hope that we're we have some principled coverage.",
            "We use this simulation data.",
            "We simulate a restricted set of possible strategy candidates, profile strategy profiles, and we get the data from those simulations, and we use that to induce a game form.",
            "And that is what we then reason about.",
            "So that.",
            "Induced game model from simulation data is what I'm calling the empirical."
        ],
        [
            "Again, so let me show you this in a little bit of a block diagram, which I will also be fleshing out throughout the talk.",
            "We have here.",
            "The first step here is to parameterise the strategy space to decide what are the range of strategies I want to be considering.",
            "Once you have a set of possible strategies, that's going to induce a space of profiles.",
            "A profile is a. Vector of strategies, one for each agent, and then our description of the environment is given by a simulator.",
            "This rectangular blue box.",
            "Here we feed in a profile.",
            "We get a sample of the pay offs.",
            "The utility values of the agent gets by playing it.",
            "Strategy in that profile and we collect that payoff data.",
            "We then estimate or induce an empirical game from that and we can analyze analyze that using standard techniques.",
            "Say to calculate Nash equilibrium for example.",
            "OK, let me give an example."
        ],
        [
            "It's such a game that we want to analyze this way, so I mentioned supply chain decision making.",
            "Well the main domain that we've looked at there is the scenario that is defined by the trading agent competition supply chain game.",
            "This was designed.",
            "Years ago or so by group at Carnegie Mellon and Swedish Institute of Computer Science.",
            "It's a simulated PC manufacturing scenario and I'll go describe it in full detail, but hope to give you a flavor of it.",
            "Maybe actually think of it as a domain for planning that you might be interested in.",
            "It's a simulated manufacturing year 220 days and every day the PC manufacturers issue RFQ's requests for quotes to their suppliers.",
            "For parts, they might want to buy with what the PC manufacturers do is they get parts and they assemble finished the season they sell to customers from the previous day.",
            "They may have some offers from the RF cues they gave yesterday and they have to decide which of those they want to actually order.",
            "At the same time, on the customer side, on the sales side they are getting bids from customers for producing finished PC's and they are getting RF cues from customers and they need to bid on those.",
            "So there's a certain batch of PC's that a customer wants for delivery on a certain day, and they're going to be willing to pay at most this amount.",
            "What are you going to offer it for?",
            "Um?",
            "You you send those to the customer, you get you find out which of yesterday's bids got accepted and also you have to schedule your factory.",
            "You have to decide.",
            "OK, given the my inventory of parts, how do I want to schedule my factory in order to make PCs today did I can potentially ship to customers to satisfy previous orders.",
            "So it's a very embedded operational scenario that involves two tiers of interaction with suppliers and customers some.",
            "A lot of planning ahead.",
            "Alot of projecting under certainty that little curve above the customers is to indicate that the global demand for PC's is highly variable and that is a major strategic factor in the game.",
            "OK, so the space of strategies here is really not something that we're going to search in any kind of systematic way.",
            "There's.",
            "Separate policies you need to come up with for issuing the RF cues, and you're doing every single part of this.",
            "So instead we want to isolate certain strategic variables as one would do it.",
            "One more stylizing thing so."
        ],
        [
            "And the simplest possible case, just to give you an example, we were interested in one particular strategic issue that had to do with procurement of components, whether to be aggressive or not OK, I'm not going to really go into what that meant.",
            "That turned out to be really important strategic variable in the early days of this competition.",
            "And so we fix an agent architecture and we just let this one thing very how aggressive you are in your in your component procurement.",
            "At the beginning of the game an A is aggressive and be as baseline.",
            "And we can.",
            "Now it's a six player game so we can simulate all combinations of profiles.",
            "In this case it's a symmetric game.",
            "So all that matters is how many days and how many bees there are.",
            "So it's only 7 different profiles.",
            "So here's the game matrix.",
            "It doesn't look like a matrix, but when it's symmetric we can just write down all the profiles and this shows the payoff to being in a in the profile when everybody's in a, the payoff to being an A when there's 5A's and 1B, and so on.",
            "And we can do a game theoretic analysis here by inspection in this case."
        ],
        [
            "And see that the unique Nash equilibrium is this profile here with two bees and four A's.",
            "This one actually collaborate, because if you're at a here you would rather switch and become a be in this profile and you can see that the we draw here in Arrow whenever somebody would want to deviate from their strategy in their profile to a different one.",
            "And so any profile with all the arrows leading in is a Nash equilibrium.",
            "So in this case there's one pure strategy Nash equilibrium with mostly A's.",
            "Which was the particular issue that we were trying to get at in this analysis.",
            "By the way, one thing you might notice is that in equilibrium the profits are highly negative.",
            "Both the bees and these are losing millions of dollars.",
            "They would much rather be in a profile where there's more bees everyones profitable, but those are not strategically stable.",
            "OK, so here's this is the crux of why you have to think about a game differently than you think of a plan, right?",
            "You cannot.",
            "This aggressive procurement was something that was inevitable from the competition in the game.",
            "The profiles where everybody was not so competitive and was making lots of profits was unstable and was not going to actually turn out in practice.",
            "And this was this kind of analysis was an example that validated what happened in the actual competition."
        ],
        [
            "This is an example of the same game with with three strategies.",
            "Now a P for preemptive and I'm not going to go into what that is, but just to show we can draw these graphs that getting to get a little bit.",
            "More complex now there's 28 profiles with peas, Asian bees, and we do the same thing with the arrows.",
            "And in this case there are four Nash equilibrium there.",
            "Bolded for your so you can see and there they are all over the place except that the.",
            "Key thing that we were getting out was that they all involve peas.",
            "OK you you once he was a possibility there was going to be a PA pre emptor which was going to which a lot of neutralizing the difference between Asian bees.",
            "The other thing I have here are numbers here.",
            "You can't probably read very well.",
            "This has zero.",
            "This says 6.38 million.",
            "This is the regret of a profile, which is the maximum gain from deviating so.",
            "If you're in this profile, what is the among all the players?",
            "What is the maximum you can get by changing your strategy in that profile so it definition of a Nash equilibrium is a profile that has zero regret.",
            "I mention this because we're going to use this regret measure for a lot of things.",
            "So as you can see, even when we just have three strategies and six agents, we've got 28 profiles and the number of profiles grows exponentially in both number of agents and number strategies, even with symmetry.",
            "So that's ultimately that's ultimately going to limit us, I should say."
        ],
        [
            "This is actually a bit embarrassing to the game theoretic reasoning field, in my view.",
            "Whatever complexity measures people give for your game computations.",
            "Everything scales certainly know better than the description of the game, and that's exponential number of players.",
            "So if we just had a kind of log log scale for the size of the game, that's going to grow with the number of players.",
            "So complexity of reasoning is going to be at least as complex of writing down the game, and that's grows exponentially with other players.",
            "That's bad.",
            "However, in intuitively games do not get more complex.",
            "With more players, what they actually do is they get more complex for awhile and then they get much easier.",
            "Certainly with one player you're back to it.",
            "Just a regular planning problem.",
            "OK, there's no strategic complexity.",
            "Once you get a few more, it gets more complex, but once you get a real lot.",
            "Then the strategic effects are very weak because nobody has much of an influence on the whole system, and you can then start ignoring them again, and I'm pointing this out just to say, you know we're not somehow living up to this, but there's something we're missing here by not having a formalism technology that's letting us get this automatically now.",
            "Certainly there are lots of theoretical results that let you justify in some cases that in the limit, as number of players goes to Infinity, you can ignore stuff, but we would like to start.",
            "Getting the benefit of weaker ties well before the number of players goes to Infinity 4.",
            "Most economic situations I have, they have way fewer than an infinite number of firms involved, say.",
            "But yet you still have this ability to really take advantage of this."
        ],
        [
            "So we there certainly is a lot of work on trying to improve scalability and number of players, and there's one facet of that.",
            "Some of you may be familiar with things like graphical games, Multiagent influence diagrams.",
            "These are some formalisms that have emerged over the last eight or eight years or so that try to exploit locality of interaction in a graphical model kind of sense.",
            "You may have a lot of players, but if they only have small neighborhoods interacting, you can exploit that.",
            "An approach that we've looked at, which is kind of orthogonal, is to use aggregation of various kinds to simplify the game and the particular method that we use is hierarchal reduction."
        ],
        [
            "Which works as follows.",
            "We have a.",
            "A game gamma that has P * Q players in it, say a symmetric game symmetric means like I said before, all that matters is how many players are playing each strategy, not which ones they are.",
            "Things that are the same for everyone's point of view.",
            "We can reduce that Tucupi player game by letting each of these P players essentially choose the strategy for Q of the players in the original Game Cube.",
            "The agents in the original game.",
            "And.",
            "This of course is an approximation, but we argue that in many natural games this often gives you a very good approximation with an exponentially smaller profile space, and I'll give some examples of that.",
            "OK, we have some."
        ],
        [
            "Evidence in favor of this.",
            "OK, first let me even try to suggest what it would mean to say.",
            "It's a good approximation.",
            "Well, one way we define it is to say, suppose you take the reduce game and solve that and then look at the quality of your solution with respect to the original game.",
            "Say we find an equilibrium in the reduced game and then we can say what would be the regret.",
            "How far from equilibrium regret is a natural measure of how far you are from equilibrium?",
            "It's saying how much could somebody benefit by deviating right?",
            "If zero, there's no benefit.",
            "If there's large regret, then it's unstable in the original game that will be relatively stable in full game.",
            "Now we can of course contrive a game that where this is.",
            "This fails arbitrarily.",
            "But we've taken natural classes of games, say from the gamut repository schoensee in local effect games that you get reasonable approximations as you would expect.",
            "As you have a finer grained reduction, so here's a local of an 8 player local effect game reduced to a one player game, reducing it to one player game means you say what would be the best strategy if everybody did it.",
            "Ignoring strategic facts, you get a lot of benefit by going to a two player game, right?",
            "You're getting some key parts of the strategic interaction and you get a little bit more benefit from the four player game and we see this pattern of kind of diminishing returns.",
            "Is something that we tend to see and just on the right I have just a benchmark.",
            "If you just say let's pick the profile that is the global optimum.",
            "OK, that's usually worse than taking into account some strategic interactions.",
            "We have some theoretical support for this, and here's a great.",
            "So if we had the resolution, this would be a crystal clear point that you would just, you know, beginning dramatic insight from but.",
            "You'll have to take my word for that.",
            "But we can actually prove and for some games where we have closed form solutions that in some sense is that you can bound the quality of the approximation you get from this kind of reduction."
        ],
        [
            "OK, there's there's.",
            "There's still a lot of open questions about this is one way to do reduction.",
            "There's many other ways that you could conceive of, and I think it's we don't really understand well enough.",
            "What are the relative tradeoffs for bias?",
            "Is an approximation quality, and this is really an active area of research.",
            "There's even questions about whether you need to do.",
            "So any kind of really strict reduction at all, or you could you could just.",
            "I get away with just looking at a small subset of the profile space, which I'll get into a little bit later.",
            "OK."
        ],
        [
            "I showed you those those graphs of the deviations.",
            "We'd like to draw those.",
            "We find those give us an inside a lot of games.",
            "Here's a deviation graph from the trading agent competition supply chain management game.",
            "This happens to be the one involving the agents from 2006, and here we just lay it out a little bit differently.",
            "So first thing I'll mention is now we've reduced it to A3 player game by having each agent Control 2.",
            "Players in the original game.",
            "And we've now drawn things in terms of these.",
            "I so regret concentric... here.",
            "So in the center you see all the arrows are kind of heading toward the center, they don't.",
            "They don't have to, but the ones in the center are more stable and you can get a visualization here of what are the parts of profiles.",
            "But you you're just not going to see a world where there's two ends and APK.",
            "There's just no way out, and an outer space here.",
            "To be strong benefit from deviating out of that and the ones in the middle are intuitively much more likely to be played on a more the parts of the search space you want to be focused on, maybe refining further."
        ],
        [
            "OK.",
            "This graph will show that we also use color coding.",
            "Sometimes to visualize that this is.",
            "An example of empirical game we did to analyze continuous double auction's.",
            "That's a very Canonical trading environment of an abstract model of stock markets and commodity markets.",
            "There's a 20 year literature of people trying to do agent based simulation to come up with the best strategies for continuous level auctions.",
            "It's one of these cases where it's the simplest possible trading mechanism to describe, but the game theorists have no ability at all to say anything about what idea what equilibrium strategies are.",
            "So simulation is the game there."
        ],
        [
            "I thought I would say something about how.",
            "We look at something like ranking strategies.",
            "Now this is again something that you were doing in this planning competition right?",
            "The whole purpose is to try to.",
            "We have these different planners we want to say which is which are better.",
            "One way we do things in competition.",
            "We have a tournament now.",
            "A key difference between the trading agent competition in your planning competition is our competition is a game, so there's interaction among among the strategies that really matters.",
            "That's the crux.",
            "That's why we have to do this thing as a competition.",
            "Whereas you, I think are mainly viewing your planning competition is these are everybody's got an objective measure and now we're just seeing which one is better.",
            "Respect to that.",
            "Actually, though, it occurs to me and see how you do this.",
            "The way that you normalize the strategy scores, you've actually got a little bit of a game element going on there that I'm not sure it was intended.",
            "I'm not sure it's necessary bad either, but something to think about offline.",
            "I thought throughout there.",
            "In any case, the tournament gives you a ranking right?",
            "But there's something that's arbitrary about that.",
            "It has something to do with the particular sequence you know, just like the World Cup, soccer, or.",
            "You know college football in the USA, the sequence of WHO plays who and those matchings has a lot to do with the end outcome.",
            "In this whole.",
            "Actually literature on tournament design.",
            "But the real outcome is not that we need to design tournaments.",
            "Better is that the idea of a tournament as a way of coming up with a ranking is is probably very limited.",
            "So what we do is we have a measure called any Nash equilibrium regret.",
            "The premise here is that.",
            "In evaluating strategy again, you can't do in isolation.",
            "It depends what everyone else is doing, so you know you want to avoid this.",
            "Arguments were saying, well, my strategy is better because it does best against Carmel, and someone says no, my strategy is better because it does best against Shlomo.",
            "Well, you know which is more relevant.",
            "Being better against Carmelo being better, national well maybe it has to do with which of slow more caramel or better, right?",
            "You should maybe be better against which of them are so if you believe in some equilibrium solution concept.",
            "As defining the plausable, what rational agents would do it, what you should care about is that I'm doing well when the other agents are being rational.",
            "If I'm doing well when the other ages are being irrational, that is arguably less of a breaking point.",
            "Now of course, let me Add all the qualifications.",
            "Sometimes you may have good reason to think that agents are irrational in certain ways and you should exploit that.",
            "OK, but you need to provide that justification.",
            "So when we're in the generic world will say, let's be good in equilibrium.",
            "So we can say let's fix, the other agents are playing the Nash equilibrium and rank everybody else by how well they do against that equilibrium and we get a regret measure and then often gives us very different rankings.",
            "Then we would get in the tournament.",
            "OK, we can argue about that."
        ],
        [
            "We've done this with the Tack travel game.",
            "Here is 50 strategies that we explored in simulation over a period of many years, and they're they're just numbers, so they're meaningless.",
            "But the point is that we can certainly rule out whole bunch of strategies as not being very effective in equilibrium and limit our attention to the ones that are that have overlapping error bars."
        ],
        [
            "We've done this with continuous level auctions, these are.",
            "Not quite, totally exhausted, but the main strategies that have appeared in the literature.",
            "I.",
            "Most of the literature had done pretty ad hoc comparisons.",
            "Somebody comes up with a new strategy.",
            "Axen says, well, I tried my strategy when half of them play axe and half of them play ZI and see I do better than ZI or or something.",
            "Well, again, why's that the relevant comparison to make?",
            "So what we propose it, you've got to look at the all the combinations form a game of that and then say, let's find an equilibrium.",
            "And we can rank against that.",
            "Now.",
            "One problem that would come to mind if you know about equilibrium is that there could be more than one of them.",
            "And so here's an example where we have two pure strategy Nash equilibrium.",
            "Anyone any two and we get different rankings based on whether we.",
            "Thinking is pretty similar.",
            "The regret measures are a bit different.",
            "OK."
        ],
        [
            "I think I want to point out is that we.",
            "These are very complex strategies themselves, so when something like supply chain competition they said there this is a very large piece of code and it's written by many people with many different modules.",
            "We have a sales module in a factory scheduling module and all these different things and so when we want to even explore the space of those, we would naturally parameterized it by those modules and somebody says, hey, I have an idea for doing prediction of future component prices better let me redo that module and put it in the agent.",
            "Is that going to make the agent better or not?",
            "Well, here's why we need to be able to have this ability to do a kind of ranking.",
            "There's often very complex interactions between these parts, and you can tell and notice.",
            "You might notice we have.",
            "This is a partial privatization of our deep maze agent.",
            "For this watch in Game an we have one feature which is whether or whether we have a bug in the.",
            "In some of the price prediction part, well, it turns out and I'm sure you've all noticed this.",
            "Sometimes you have a complex strategy and you fix a bug and it gets worse.",
            "I'm sure you've all had this experience.",
            "And that's not unreasonable, right?",
            "Because in any kind of complex system where you've made approximations and simplifications, the fact that you.",
            "Did something wrong here?",
            "Doesn't mean that it's actually not the best thing to do given what everything else is an, especially if you've got a very adaptive system where you maybe other parts have been tuned to fit with the bad behavior you had before fixing their bad behavior is going to make things worse, OK, and this until you start fixing some other things as well so we just track it alright, once you have these parts, that's just another.",
            "Another feature of the agent."
        ],
        [
            "OK.",
            "So actually, the way we would pursue designing an agent for this game is to iterate this empirical game theoretic analysis process.",
            "So this is what I showed you before and we also use this structure to identify the different research topics that we've worked on.",
            "So one of them is given you've got a database of simulation data, how do you come up with a game model?",
            "Another is cake.",
            "Now that we've analyzed the game, we're not done.",
            "OK, we might say we're done, but more often than not, there's still more time before the competition.",
            "We haven't explored everything.",
            "We have a choice we can explore.",
            "We could do more sampling of the strategies that we've already started looking at.",
            "Or we could start to think of entirely new strategies so we could add more strategies.",
            "We could add more samples anymore.",
            "Samples is the sample control problem, so either more samples of existing profiles or some of the existing strategies with different combinations.",
            "And I'll talk a little bit about that.",
            "OK, there's also the strategy exploration problem.",
            "How would we even add new strategies to think up?"
        ],
        [
            "So for sampling control, we've looked at there's different models for what a sample gives you, and we've explored this in two models and there's a little bit of literature in each one in the reveal payoff model, the unit computation is finding out the payoff for a given strategy profile and the noisy payoff model.",
            "You get a noisy sample.",
            "So and we have algorithms for both.",
            "I'm going to talk about the revealed payoff model, where we've introduced a very straightforward algorithm called minimum regret first search."
        ],
        [
            "So the idea is that we want to refute, refute the best equilibrium candidate we have.",
            "So this.",
            "Let's say we have this two player for strategy game to pretty simple.",
            "So obviously we could explore exhaustively and let's say, but let's say there's some, there's a cost to filling in a cell of the payoff matrix.",
            "So we start in some arbitrary place with the profile where the role player plays are one the column player plays C1, and that has some payoff 9 to the role player 5 to the column player.",
            "On our epsilon bound, epsilon is regret is zero as far as we know.",
            "This could be in equilibrium, there's no lower bound on how close to equilibrium this could be."
        ],
        [
            "But once we explore, some deviation will pick some.",
            "Random deviation of this will have the column player try C2.",
            "We see that this also this doesn't do any better for either player.",
            "I mean for the column player comp players worse, but the this new profile has an epsilon bound of two, right?",
            "We know that the column player could benefit by two by going to play C1 instead of C2, so that has an epsilon bound of two.",
            "So still our first one, R1C1 is the best candidate we have.",
            "This priority queue here on the right."
        ],
        [
            "So we're going to still expand the R1C1, and we explore a deviation to R2.",
            "Again, that's not as good."
        ],
        [
            "We'll try our three, though."
        ],
        [
            "That is good.",
            "Will try C4 this now we now we do have a positive deviation.",
            "Right, so now we have a lower bound of three.",
            "On the regret for that R1C1, but we have a new candidate that has that could be in equilibrium which is R1C four.",
            "So now we look.",
            "We explore deviation from that.",
            "We try to refute that by looking at a deviation."
        ],
        [
            "From that OK and we."
        ],
        [
            "Proceed with this.",
            "By just always finding a deviation, exploring a deviation to the lowest regret bound."
        ],
        [
            "Profile"
        ],
        [
            "And we finally get to a point where we have confirmed an equilibrium.",
            "R2C2 is in equilibrium.",
            "We looked at all the deviations and probably want to want to emphasize is that we've established that this is an equilibrium without knowing the whole game.",
            "Right, it doesn't matter these these white cells.",
            "It doesn't matter what's in there.",
            "Those are not going to affect the proposition that R2C2 is in equilibrium, so you can often establish equilibrium without knowing the full game.",
            "Now, of course, we can't rule out that any of these other unexplored profiles themselves might be equilibrium.",
            "There could be multiple equilibrium, but we can.",
            "We can get some traction on game analysis without looking at the whole game."
        ],
        [
            "And in fact, this minimum regret for search often finds.",
            "A very good approximations equilibrium.",
            "Here's a regret measure with exploring a very small fraction of the profile space.",
            "Here we compare it to a previous proposal in the literature that was based on a tabu search."
        ],
        [
            "OK, I'm I'm just going to just briefly say something about the game model induction problem."
        ],
        [
            "Once you view that you've got some set of data on some subset of the profiles, what you can think of is what we're trying to do is really generalize this the whole game.",
            "You can think of it as a curve fitting problem.",
            "I've got a bunch of of data points.",
            "Here's the strategy profile.",
            "Here's the utility for that.",
            "Is the payoff vector for that.",
            "Let me now try to.",
            "Generalize this to a payoff function over the whole space.",
            "And."
        ],
        [
            "So we've explored doing this as a regression problem where we basically we can even use this to learn a model that has a continuous, has a infinite strategy space.",
            "Right by assuming there's some structure in the in the space, and under certain circumstances we can quantify how well that well that does.",
            "OK."
        ],
        [
            "Move ahead a little bit.",
            "I want to say a word about the strategy exploration problem.",
            "So one possibility is that we want to not just sample the strategy that we want to generate entirely destroyed.",
            "This is when you're going back to the drawing board and say I want to rewrite some part of my plan or I want to introduce a new module for my.",
            "My supply chain agency."
        ],
        [
            "So one approach we've looked at this, you know, and you can plug in.",
            "Really, this is really a planning problem.",
            "So here we using reinforcement learning.",
            "But what we try to do is we have a provisional Nash equilibrium based on the search we've done so far and we say, well, can we think of a strategy that does better when everybody else is playing the equilibrium?",
            "Notice the way I formulated that we're fixing the behavior of everybody else and you could do this too.",
            "And then you've basically got a one single agent planning problem.",
            "Just finding a best response.",
            "To that man.",
            "And here we're using reinforcement learning.",
            "We try to find a better strategy, assuming that there fixed by doing a search in a space of strategies and we get that and we test it out.",
            "If that is in fact a beneficial deviation, then we add it to the strategy set an we're back on our merry way in this iterative approach.",
            "If it's not a deviation, then we've got to do something to improve our planning or improve our our learning model to do this or give up.",
            "So one."
        ],
        [
            "Domain in which we've done this is in that continuous double auction problem.",
            "OK, remember this is the area I said.",
            "This is a very Canonical auction model that's at the basis for all financial markets, but yet there's no games resolution authorises this literature on agents that.",
            "Are simulated against each other.",
            "Here we say, let's just.",
            "Try to do a reinforcement learning approach.",
            "We come up with some features.",
            "For the state space that includes things like some statistics on history of recent trades, some price quotes for what the current bid ask spread is what time is it?",
            "How much time has there been since the trade happened, and some state about for us?",
            "What is the value of the next unit to be traded?",
            "Or action is not?",
            "How much we bid, but rather how much of a margin we request from our value.",
            "OK, this helps make make our policy is a little bit more robust, we say.",
            "I want to ask for a profit of 10 if it's worth hundreds of me.",
            "I'm going to offer to buy it for 90.",
            "And the rewards are the profit you make from trading.",
            "So we've we tried this version of this state space."
        ],
        [
            "Come on CD's and we get this.",
            "This is the iterative approach.",
            "We actually didn't first build the game of all the previous literature.",
            "I said it was a little more impatient to try out the learning stuff, so we just took some some three strategies.",
            "Kaplan, Zi and Zi beat the quote.",
            "We found an equilibrium of those which was everybody playing Zi.",
            "We ran reinforcement learning and came up with a strategy.",
            "We'll call it L1, which successfully deviated from that, and in fact after that we had a new equilibrium, which is everybody playing L1 said great this thing.",
            "This stuff works."
        ],
        [
            "We then added a few more agents from literature and now got back to an equilibrium where it was all agents.",
            "The GD agent gears that Dick out.",
            "Trader from literature was.",
            "The soul play in equilibrium.",
            "So we ran learning on that.",
            "Now L2 through LA it means the next seven iterations of reinforcement learning didn't work for us, and we had to keep triggering the state space description and how we formulated the URL problem until we finally came up with something that worked that successfully deviated."
        ],
        [
            "And we did this for many more rounds.",
            "We eventually.",
            "Came up with a strategy L 11 and then threw in GDX which was the champion from literally probably should have put in earlier.",
            "It took over most of the equilibrium, but then we eventually overthrew that and then ultimately ended up with an equilibrium with just new learn strategies.",
            "So the claim here is that we've got a new new champion.",
            "12 and 13.",
            "Through this process now the you might ask.",
            "Well, great.",
            "So what does L 12 and 13 do?",
            "And I wish I could answer that question.",
            "L 12 and 13 are strategies that were learned by a reinforcement learner, and there this very opaque.",
            "Mapping from those features to actions and we actually did a lot of analysis to try to understand under what circuit and we got a little bit of insight into under what circumstances it does something different than what GDX does and that gives us some sense and how to characterize it.",
            "But it's not satisfying like the manually defined strategies, right?",
            "The manually defined strategies have an idea behind them, and there's a drawback of learning strategies automatically.",
            "But nevertheless what we have here is a method that.",
            "Can improve strategies automatically."
        ],
        [
            "Well, listen.",
            "We want to step back and say we had.",
            "This was a particular approach to strategy exploration.",
            "Was it reasonable?",
            "We you know it's expensive to introduce a new strategy because then you want you're expecting to do simulations over the whole profile space, right?",
            "We wouldn't want to do that over all conceivable policies, so we need to be deliberate.",
            "So what we did, that's why we only introduced strategy when it was a deviation of beneficial deviation to occur in equilibrium.",
            "And in particular, what I what we did, and I didn't justify it was we said, let's find a best response.",
            "In our case by reinforcement learning or I suggested by planning to the car and equilibrium well, is that the right thing to even be trying to do?",
            "If we could compute the best response."
        ],
        [
            "Not necessarily.",
            "In fact, any strategies itself may be a really bad idea, so.",
            "Here's a contrived game that has two players and four strategies.",
            "If we just had a one was the only strategy we knew about, we would say, oh, the equilibrium is play one and the regret with respect to the true game is 3 because you could do better by playing a four against A1.",
            "But if we added a two in there, we would say we have a new equilibrium.",
            "Just think of this.",
            "A subgame with the upper left corner but a 2.",
            "Actually that would be a worse.",
            "That would have a higher regret.",
            "And in fact you know it's contrived so that.",
            "Adding strategies in a certain order, we actually get worse and worse and worse every time until finally you have the whole game and then we get better.",
            "Then we get better but you always get better in the end.",
            "So it matters what order you look at things looking at more is not always better."
        ],
        [
            "So we ask about weather.",
            "Best response is good, so here's a game that we understand really well because we have closed form characterizations of part of it, and we use this to test our understanding of some of these questions.",
            "First, price sealed bid auction for two players, and this is a regret surface that says if these two players play bid different fractions of their valuation, how far are we from an equilibrium and?",
            "It's a little.",
            "It's a bit hard to see here, but it turns out that if you do a best response dynamics here, we start at some point in that surface and somebody changes to a best response to what the other guy is doing.",
            "You crawl down that a tiny bit and you'll eventually get to an equilibrium.",
            "However, if at any point.",
            "You get to the other half of plane.",
            "Here in one shot, the best response will give you give you right to equilibrium.",
            "So what this suggests is actually what you should do is you should if you should just randomly throw in some some guesses, because if you have those in the mix a best response there is going to get you in one shot to the equilibrium.",
            "So this is kind of in retrospect to kind of not so surprising.",
            "Explore, exploit kind of thing where having a diversity of strategies in the mix is also really valuable, and what that."
        ],
        [
            "Means for exploration policy zizza question.",
            "Our current best is something we call MMT.",
            "That it is based on a rational closure concept, which I'm not going to go into here, but I just wanted to make the point that this is itself an issue that we find that this does just systematically better than best response across a range of games.",
            "OK, so I'm closing time.",
            "I'd like to have some time for questions so."
        ],
        [
            "Let me just.",
            "Point out that we've been really our main agenda is to build this methodology to look at these various sub questions in how to do game analysis in this empirical way.",
            "We've applied it to a lot of different market games, for example those from the trading agent competition I mentioned.",
            "Briefly, the travel game is supply chain game.",
            "There's also an ad auction game this year.",
            "The trading agent competition is introducing a power attack, an energy trading game.",
            "Another kind of hot topic.",
            "We've also used it to explore.",
            "I mentioned continuous double auctions.",
            "We have some new results on on simultaneous.",
            "One shot, second price sealed bid auctions we've done work on on others the kind of mechanisms that are close to what exists in the world, but yet you are totally lacking.",
            "Currently game theoretic satisfactory solutions.",
            "We looked at other problems in finance problems in security and privacy networking.",
            "No end of kinds of games that I think are amenable to this kind of view.",
            "We've also looked at not just game analysis, but the outer loop of that mechanism design if we can.",
            "Some control some aspects of the game.",
            "How would we use empirical methods to get a handle on what to do there?"
        ],
        [
            "So what I hope you will take away from this is at least my claim that you can employ game theoretic approaches beyond where you can really just use them in a purely analytical way, even when you have procedurally defined scenarios and you do that by embracing methods like simulation and machine learning.",
            "The the key complementarity is uses the game theoretic concepts come into the four in giving you a guide towards what.",
            "Context of the other agents matter.",
            "OK, which profiles of the other agents should you actually care about when you're evaluating your own strategy?",
            "And then you have your regular toolkit of ways to explore your own strategies given given that context.",
            "So in the end, what we're shooting for is a.",
            "Principled approach to evaluate these repeated domains, and we're building the toolbox and we could use some help, so I'll end it there.",
            "Thank you very much.",
            "So going back to your example of the six players, with the four playing A and two playing be equilibrium.",
            "So if I'm one of the players, what do I play?",
            "Haha I.",
            "Gay, good question.",
            "So the the.",
            "This does not answer, would be well, it depends.",
            "If you have 1A and four bees among the rest you you're an A, and if there's two azan three bees among rescue Roby.",
            "But how how they did actually coordinate on a non symmetric pure equilibrium is, I think a good reasonable question, so I don't think we literally say that's going to be the answer right?",
            "But the we actually used to say you know it's as expected.",
            "There would be a predominant surveys, and in fact we actually derived in this case more normally symmetric mixed equilibrium is the is when we are going for a particular equilibrium we typically prefer.",
            "The symmetric equilibrium when we have a symmetric game, and so once you have if we had this symmetric mixture then then that would answer your question directly but good catch.",
            "Michael, so I wondered whether you may have already talked about this and I I sort of didn't get the details, but I wondered whether you looked at trying to pinpoint where the challenges are in the games by using the strategies as judges of where the difficulty lies.",
            "So we did this in the 2003 planning competition trying to understand which domains were really hard domains in which were easy.",
            "We used the competing planners of as judges of of that and then tried to see whether there was a statistical significance in the difference in.",
            "In their performance, and if planners were consistently finding domains easy, then that told us something about the structure of the domain and it equally if they were consistently finding them difficult, then that told us something and we were able to do a comparison between the domains on that basis.",
            "So I just thought you have a lot of statistical information in the way that the strategies are being played out and the effect on the games, and it might be possible to, for example, pinpoint better that relationship between the game and the number of players to give you a better idea of actually where it becomes easy again because you're.",
            "You're losing the strategic information when you've got so many players, so I just wondered if you'd explored that.",
            "Yes, absolutely.",
            "I mean not that we have in an automatic way of cranking out answers to that, but certainly anecdotally what you get out of these competitions and even just a game analysis, is a better understanding of which are the pivotal strategic issues.",
            "So for us, it's not.",
            "Is it hard or easy, so much as what actually are the issues that matter what?",
            "Which are the sub problems that are more instrumental to improving overall performance so?",
            "Actually, that first example that I didn't explain of what aggressive and baseline were there was because there was a surprise to the designers.",
            "The first in the first couple of years of the supply chain game that the procurement of a lot of components at the very beginning was a driver of everything else.",
            "It put a lot of the other issues that the designers were hoping to explore into the noise.",
            "Kind of thing that you maybe didn't even it became so obvious just based on what actually happened when you observe the game.",
            "It wasn't obvious from the design, but it was obvious once people through their strategies in and we saw what happened.",
            "The analysis we did was more of a post competition way to verify.",
            "So a little bit more of the story there was a.",
            "A strong incentive to buy lots of components right at the beginning of the game.",
            "Because there was a limited amount of them and there was cheap as they were going to be.",
            "And if you did that.",
            "Then everybody else to do it too, because then there would be no components left later in the game.",
            "The suppliers had already committed their capacity, but then the whole system was very vulnerable because if the demand for PC's turned out to be low, everybody had all these components and they were just killing each other to sell PCs at no price.",
            "And everybody was.",
            "That's why you had everyone losing money in equilibrium.",
            "And this is what happened in the actual tournament.",
            "There was this destructive thing, but everyone knows.",
            "Hey, the ones who are buying the components of the beginning are doing well.",
            "Let me do that to an it was and we were looking at the same node.",
            "This is terrible.",
            "Don't do this.",
            "This is suicidal.",
            "We're lemmings running off the Cliff and the game theoretic analysis is a way of saying, you know what?",
            "You know.",
            "The lemmings were rational that this was inevitable.",
            "This was going to happen given the setup of the game.",
            "It wasn't just that everybody who entered the tournament that year was insane.",
            "So I think that's the kind of thing you get from the company, both having real people throwing their strategy ideas and also doing a little bit of analysis.",
            "Yeah, there was an assertion of the in in the middle of the talk that when the number of players increases then the game begets simple intuitively.",
            "But I couldn't understand the intuition.",
            "Could you elaborate on it, right?",
            "So it was.",
            "This was a very informal statement, right?",
            "And I think it actually can be made formal, but usually only in very limited in in the in limit kinds of arguments.",
            "But the basic intuition is that think of think of something like these PC makers, right?",
            "If there's if there's three of them, then.",
            "It really pays a lot for you to think about the what the other two are doing, because that's going to affect you alot if there's 100 of them, every one of them is affecting only a small part of the market and it's kind of negligible and you yourself are also going to have a negligible effect on the market, so you can just not think about the strategy so much.",
            "Just think about basically your own situation and take the rest of the world is pretty much fixed, so that's the sense in which as the number of agents gets large but way short of Infinity, you can really start discounting the strategic effects.",
            "And we should have a technology that exploits that.",
            "I presume you don't allow any collusion between players.",
            "So that's interesting, and in the trading agent competition we have generally not disallowed collusion.",
            "What we've disallowed is sacrificial collusion.",
            "So what you got to do is say, you know what I'm going to buy PC's for you for $1,000,000 each I'll have a big negative profit.",
            "You'll have a big positive profit.",
            "You'll win the competition.",
            "I'll lose that.",
            "That's not allowed, but price fixing, other kinds of things we've generally not disallowed that, in part because I was skeptical that people would be able to pull it off.",
            "In the first place, interesting to see if they could.",
            "Maybe if it was real money agents would do it more, but we have not observed that happening.",
            "Has anybody really studied the problem of if you're stuck in one Nash equilibrium and you can do collusion, how a group of players might actually get you out of that Nash equilibrium to one another, one that was more attractive?",
            "OK, well that's not so technically that would necessarily be called collusion, just doing it for different equilibrium selection.",
            "Certainly communication and all that kind of stuff is also not disallowed.",
            "Um?",
            "I, I think there's a reluctance, so for example in that really, that suicidal, effective digital procurement, it wasn't clear that there was anything that anybody could say that was going to stop this March into the really.",
            "Bad equilibrium.",
            "Except this preemption kind of thing that we ended up doing, but.",
            "In general, coordination and equilibrium is something that should be studied.",
            "I mean, it's a relevant aspect of.",
            "Games when there are multiple equilibrium you do need criteria outside of game theory to give you a sense of what's really going to happen, and that's another very interesting question of how you formulate such criteria and incorporate them in your analysis."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you Carmela for those very kind words and thank you to the organizers for inviting me here.",
                    "label": 0
                },
                {
                    "sent": "It's really a great pleasure to be here at Icaps.",
                    "label": 0
                },
                {
                    "sent": "As Carmel mentioned, my thesis had the word planning in it and I used to do work that was called planning.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But it's been awhile since I've been to icaps.",
                    "label": 0
                },
                {
                    "sent": "In fact, thinking back the last talk I gave at Icaps was in actually wasn't in Icaps.",
                    "label": 0
                },
                {
                    "sent": "It was apes back back then.",
                    "label": 0
                },
                {
                    "sent": "Is about utility representation for decision theoretic planning, and I suspect not too many of you were here then.",
                    "label": 1
                },
                {
                    "sent": "So I thought, hey, I know it's still actually a relevant topic.",
                    "label": 0
                },
                {
                    "sent": "I can give that talk again.",
                    "label": 0
                },
                {
                    "sent": "But unfortunately PowerPoint from 1992 is no longer viable, so looking at a couple more recent papers that actually we did have it icaps presented by my Co authors are more about the kinds of things that I've been doing since the reason I haven't been at icaps in recent years is because my research has focused on the multi agent aspect of decision making.",
                    "label": 0
                },
                {
                    "sent": "I think that actually what I'm still interested in is decision making and planning.",
                    "label": 0
                },
                {
                    "sent": "But particularly with respect to the issues that come up when there are multiple planners in the world, and so actually I'm going to talk about in and working to talk about today, I'm going to touch back on some of the things that were presented here seven years ago on market based scheduling an decision-making on supply chains.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So just to make clear, this point of departure.",
                    "label": 0
                },
                {
                    "sent": "Let me just end at a high level.",
                    "label": 0
                },
                {
                    "sent": "Say what the planning problem is is that we want to find some behavior for our agent.",
                    "label": 0
                },
                {
                    "sent": "That's going to optimize or satisfy some objectives with respect to the environment we expect, and we're striving for rationality.",
                    "label": 0
                },
                {
                    "sent": "However, you want to define that we're all doing that when the environment contains other agents.",
                    "label": 1
                },
                {
                    "sent": "I that means that what you do, how well, how effective, what you do turns out to be depends on what the other agents are going to do as well, and to even say that we have an informal radiance means we're according to them some kind of rationality as well.",
                    "label": 0
                },
                {
                    "sent": "So to even acknowledge that problem, it says we want to view the other agents in the environment as themselves being rational planners.",
                    "label": 1
                },
                {
                    "sent": "And that means your problem is now a game.",
                    "label": 0
                },
                {
                    "sent": "You have this kind of reflection and you can still think of things in some respects in the same way we're still searching for.",
                    "label": 0
                },
                {
                    "sent": "What to do with searching for a strategy or policy or a plan?",
                    "label": 0
                },
                {
                    "sent": "But we have to now think in this multi dimensional space where there's a dimension for each agents plan.",
                    "label": 0
                },
                {
                    "sent": "So we've taken whatever our planning problem is and there's multiplied the dimensionality by the number of agents and Moreover we can't just now think of the objective from one agents perspective, we have to now think of an overall perspective objective.",
                    "label": 0
                },
                {
                    "sent": "So for example you're searching in this multi dimensional space and you're saying I want to find a plan for me that is going to be good when the other agents, being rational planners, are doing what they would.",
                    "label": 0
                },
                {
                    "sent": "Be likely to do.",
                    "label": 0
                },
                {
                    "sent": "OK, and you can characterize that, so we're looking at those problems.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the kinds of games that were particularly interested in are ones that have very complex dynamics.",
                    "label": 1
                },
                {
                    "sent": "An high degrees of uncertainty, especially.",
                    "label": 0
                },
                {
                    "sent": "For example, a lot of the games that we're interested in are motivated by scenarios in electronic Commerce, markets and trading.",
                    "label": 0
                },
                {
                    "sent": "Very huge strategy.",
                    "label": 0
                },
                {
                    "sent": "Space is a strategy.",
                    "label": 0
                },
                {
                    "sent": "Is any function from a history of observations to what to do next?",
                    "label": 0
                },
                {
                    "sent": "And you have severely incomplete information that is theirs.",
                    "label": 1
                },
                {
                    "sent": "State of the other agents and information that they have.",
                    "label": 0
                },
                {
                    "sent": "And it's not just that you might want to infer that, but you actually get relevant information dribbled out overtime based on what they do, and so that just tremendously complicates the problem.",
                    "label": 0
                },
                {
                    "sent": "And because of that, you don't really see a lot of analytic solutions to game theoretic problems, except for, as I mentioned, very simple ones.",
                    "label": 0
                },
                {
                    "sent": "These are problems that can be formalized and well specified in game theoretic terms, but regardless of the specific computational complexity results you believe or don't believe about this domain, the proof is in what actually happens that you just don't see analytic solutions for games that you care about, so there's two approaches, at least two approaches one can take, and I think the approach that most of the literature that labels itself as game theoretic takes is too.",
                    "label": 0
                },
                {
                    "sent": "Abstract and approximate the game to the point where the analytic methods actually get traction, and typically that happens by getting rid of these characteristics like the dynamics and the uncertainty that are so problematic to begin with, and you can get a lot of insight.",
                    "label": 0
                },
                {
                    "sent": "I think from some of these abstractions, and often that is actually the starting point for anything else, so I'm totally in favor of this approach.",
                    "label": 0
                },
                {
                    "sent": "But in my group over the years we've been.",
                    "label": 0
                },
                {
                    "sent": "Pursuing another approach, which is what the topic of today's talk is on using empirical and particularly simulation based methods for understanding a strategic environment for a game.",
                    "label": 0
                },
                {
                    "sent": "And I think.",
                    "label": 0
                },
                {
                    "sent": "Within that, within simulation based methods you could conceive of search based methods.",
                    "label": 0
                },
                {
                    "sent": "OK, when I said the natural path from going from your roles of planning to games is to just up the dimensionality of the search, I'm not going to talk so much about search intensive methods.",
                    "label": 0
                },
                {
                    "sent": "Actually this is probably an area where this community I think could contribute a lot to the multi agent world based on the tool set that you understand so well.",
                    "label": 1
                },
                {
                    "sent": "I I think I think that would be a very worthwhile thing to do, but I'm going to talk about today.",
                    "label": 0
                },
                {
                    "sent": "There are methods that are certainly employ a lot of search but also emphasize empirical techniques like statistics sampling, machine learning.",
                    "label": 0
                },
                {
                    "sent": "So let me say what?",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I mean by that and the approach that we've been calling empirical game theoretic analysis.",
                    "label": 0
                },
                {
                    "sent": "You we start out actually by not even being given a an an analytic description of the game model, so I guess that's actually the point where you split off whether I want to search approach or empirical approach.",
                    "label": 0
                },
                {
                    "sent": "So in a typical planning problem formulation, you're given a domain description, a formal description.",
                    "label": 0
                },
                {
                    "sent": "And a lot of the things we care about your what we have really is a black box simulator.",
                    "label": 0
                },
                {
                    "sent": "That's the best description we have of the game, and I think actually in.",
                    "label": 0
                },
                {
                    "sent": "In practice, you wind up using something like that, so the way I would think about, say, the international planning competition, by the way, I really enjoyed that session the other day, showing that you have, you know, just really terrific enthusiasm and very vibrant competition.",
                    "label": 0
                },
                {
                    "sent": "You view that as now resorting to the simulation based way of evaluating your planners the input to a planner is a domain model, and the planner itself is using that domain model to evaluate a plan.",
                    "label": 0
                },
                {
                    "sent": "But when you want to evaluate planners.",
                    "label": 0
                },
                {
                    "sent": "You are now going to a simulation based approach.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's the that's the the analogy to draw here is that now I'm going to want to look at be evaluating planners or decision makers agents again using the simulation based approach.",
                    "label": 0
                },
                {
                    "sent": "Now, I said there's a huge strategy space, so we're going to parameterise it based on some structure given by an agent architecture and will give examples of that.",
                    "label": 1
                },
                {
                    "sent": "And we're going to selectively explore this.",
                    "label": 0
                },
                {
                    "sent": "We're going to give up right off the bat at trying to have exhaustive coverage, but hope that we're we have some principled coverage.",
                    "label": 0
                },
                {
                    "sent": "We use this simulation data.",
                    "label": 0
                },
                {
                    "sent": "We simulate a restricted set of possible strategy candidates, profile strategy profiles, and we get the data from those simulations, and we use that to induce a game form.",
                    "label": 0
                },
                {
                    "sent": "And that is what we then reason about.",
                    "label": 0
                },
                {
                    "sent": "So that.",
                    "label": 0
                },
                {
                    "sent": "Induced game model from simulation data is what I'm calling the empirical.",
                    "label": 1
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Again, so let me show you this in a little bit of a block diagram, which I will also be fleshing out throughout the talk.",
                    "label": 0
                },
                {
                    "sent": "We have here.",
                    "label": 0
                },
                {
                    "sent": "The first step here is to parameterise the strategy space to decide what are the range of strategies I want to be considering.",
                    "label": 1
                },
                {
                    "sent": "Once you have a set of possible strategies, that's going to induce a space of profiles.",
                    "label": 0
                },
                {
                    "sent": "A profile is a. Vector of strategies, one for each agent, and then our description of the environment is given by a simulator.",
                    "label": 0
                },
                {
                    "sent": "This rectangular blue box.",
                    "label": 0
                },
                {
                    "sent": "Here we feed in a profile.",
                    "label": 0
                },
                {
                    "sent": "We get a sample of the pay offs.",
                    "label": 0
                },
                {
                    "sent": "The utility values of the agent gets by playing it.",
                    "label": 0
                },
                {
                    "sent": "Strategy in that profile and we collect that payoff data.",
                    "label": 1
                },
                {
                    "sent": "We then estimate or induce an empirical game from that and we can analyze analyze that using standard techniques.",
                    "label": 0
                },
                {
                    "sent": "Say to calculate Nash equilibrium for example.",
                    "label": 0
                },
                {
                    "sent": "OK, let me give an example.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's such a game that we want to analyze this way, so I mentioned supply chain decision making.",
                    "label": 0
                },
                {
                    "sent": "Well the main domain that we've looked at there is the scenario that is defined by the trading agent competition supply chain game.",
                    "label": 0
                },
                {
                    "sent": "This was designed.",
                    "label": 0
                },
                {
                    "sent": "Years ago or so by group at Carnegie Mellon and Swedish Institute of Computer Science.",
                    "label": 0
                },
                {
                    "sent": "It's a simulated PC manufacturing scenario and I'll go describe it in full detail, but hope to give you a flavor of it.",
                    "label": 0
                },
                {
                    "sent": "Maybe actually think of it as a domain for planning that you might be interested in.",
                    "label": 0
                },
                {
                    "sent": "It's a simulated manufacturing year 220 days and every day the PC manufacturers issue RFQ's requests for quotes to their suppliers.",
                    "label": 0
                },
                {
                    "sent": "For parts, they might want to buy with what the PC manufacturers do is they get parts and they assemble finished the season they sell to customers from the previous day.",
                    "label": 0
                },
                {
                    "sent": "They may have some offers from the RF cues they gave yesterday and they have to decide which of those they want to actually order.",
                    "label": 0
                },
                {
                    "sent": "At the same time, on the customer side, on the sales side they are getting bids from customers for producing finished PC's and they are getting RF cues from customers and they need to bid on those.",
                    "label": 0
                },
                {
                    "sent": "So there's a certain batch of PC's that a customer wants for delivery on a certain day, and they're going to be willing to pay at most this amount.",
                    "label": 0
                },
                {
                    "sent": "What are you going to offer it for?",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "You you send those to the customer, you get you find out which of yesterday's bids got accepted and also you have to schedule your factory.",
                    "label": 0
                },
                {
                    "sent": "You have to decide.",
                    "label": 0
                },
                {
                    "sent": "OK, given the my inventory of parts, how do I want to schedule my factory in order to make PCs today did I can potentially ship to customers to satisfy previous orders.",
                    "label": 0
                },
                {
                    "sent": "So it's a very embedded operational scenario that involves two tiers of interaction with suppliers and customers some.",
                    "label": 0
                },
                {
                    "sent": "A lot of planning ahead.",
                    "label": 0
                },
                {
                    "sent": "Alot of projecting under certainty that little curve above the customers is to indicate that the global demand for PC's is highly variable and that is a major strategic factor in the game.",
                    "label": 0
                },
                {
                    "sent": "OK, so the space of strategies here is really not something that we're going to search in any kind of systematic way.",
                    "label": 0
                },
                {
                    "sent": "There's.",
                    "label": 0
                },
                {
                    "sent": "Separate policies you need to come up with for issuing the RF cues, and you're doing every single part of this.",
                    "label": 0
                },
                {
                    "sent": "So instead we want to isolate certain strategic variables as one would do it.",
                    "label": 0
                },
                {
                    "sent": "One more stylizing thing so.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the simplest possible case, just to give you an example, we were interested in one particular strategic issue that had to do with procurement of components, whether to be aggressive or not OK, I'm not going to really go into what that meant.",
                    "label": 0
                },
                {
                    "sent": "That turned out to be really important strategic variable in the early days of this competition.",
                    "label": 0
                },
                {
                    "sent": "And so we fix an agent architecture and we just let this one thing very how aggressive you are in your in your component procurement.",
                    "label": 0
                },
                {
                    "sent": "At the beginning of the game an A is aggressive and be as baseline.",
                    "label": 0
                },
                {
                    "sent": "And we can.",
                    "label": 0
                },
                {
                    "sent": "Now it's a six player game so we can simulate all combinations of profiles.",
                    "label": 0
                },
                {
                    "sent": "In this case it's a symmetric game.",
                    "label": 0
                },
                {
                    "sent": "So all that matters is how many days and how many bees there are.",
                    "label": 0
                },
                {
                    "sent": "So it's only 7 different profiles.",
                    "label": 0
                },
                {
                    "sent": "So here's the game matrix.",
                    "label": 0
                },
                {
                    "sent": "It doesn't look like a matrix, but when it's symmetric we can just write down all the profiles and this shows the payoff to being in a in the profile when everybody's in a, the payoff to being an A when there's 5A's and 1B, and so on.",
                    "label": 0
                },
                {
                    "sent": "And we can do a game theoretic analysis here by inspection in this case.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And see that the unique Nash equilibrium is this profile here with two bees and four A's.",
                    "label": 0
                },
                {
                    "sent": "This one actually collaborate, because if you're at a here you would rather switch and become a be in this profile and you can see that the we draw here in Arrow whenever somebody would want to deviate from their strategy in their profile to a different one.",
                    "label": 0
                },
                {
                    "sent": "And so any profile with all the arrows leading in is a Nash equilibrium.",
                    "label": 0
                },
                {
                    "sent": "So in this case there's one pure strategy Nash equilibrium with mostly A's.",
                    "label": 0
                },
                {
                    "sent": "Which was the particular issue that we were trying to get at in this analysis.",
                    "label": 0
                },
                {
                    "sent": "By the way, one thing you might notice is that in equilibrium the profits are highly negative.",
                    "label": 0
                },
                {
                    "sent": "Both the bees and these are losing millions of dollars.",
                    "label": 0
                },
                {
                    "sent": "They would much rather be in a profile where there's more bees everyones profitable, but those are not strategically stable.",
                    "label": 0
                },
                {
                    "sent": "OK, so here's this is the crux of why you have to think about a game differently than you think of a plan, right?",
                    "label": 0
                },
                {
                    "sent": "You cannot.",
                    "label": 0
                },
                {
                    "sent": "This aggressive procurement was something that was inevitable from the competition in the game.",
                    "label": 0
                },
                {
                    "sent": "The profiles where everybody was not so competitive and was making lots of profits was unstable and was not going to actually turn out in practice.",
                    "label": 0
                },
                {
                    "sent": "And this was this kind of analysis was an example that validated what happened in the actual competition.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is an example of the same game with with three strategies.",
                    "label": 0
                },
                {
                    "sent": "Now a P for preemptive and I'm not going to go into what that is, but just to show we can draw these graphs that getting to get a little bit.",
                    "label": 0
                },
                {
                    "sent": "More complex now there's 28 profiles with peas, Asian bees, and we do the same thing with the arrows.",
                    "label": 0
                },
                {
                    "sent": "And in this case there are four Nash equilibrium there.",
                    "label": 0
                },
                {
                    "sent": "Bolded for your so you can see and there they are all over the place except that the.",
                    "label": 0
                },
                {
                    "sent": "Key thing that we were getting out was that they all involve peas.",
                    "label": 0
                },
                {
                    "sent": "OK you you once he was a possibility there was going to be a PA pre emptor which was going to which a lot of neutralizing the difference between Asian bees.",
                    "label": 0
                },
                {
                    "sent": "The other thing I have here are numbers here.",
                    "label": 0
                },
                {
                    "sent": "You can't probably read very well.",
                    "label": 0
                },
                {
                    "sent": "This has zero.",
                    "label": 0
                },
                {
                    "sent": "This says 6.38 million.",
                    "label": 0
                },
                {
                    "sent": "This is the regret of a profile, which is the maximum gain from deviating so.",
                    "label": 0
                },
                {
                    "sent": "If you're in this profile, what is the among all the players?",
                    "label": 0
                },
                {
                    "sent": "What is the maximum you can get by changing your strategy in that profile so it definition of a Nash equilibrium is a profile that has zero regret.",
                    "label": 0
                },
                {
                    "sent": "I mention this because we're going to use this regret measure for a lot of things.",
                    "label": 0
                },
                {
                    "sent": "So as you can see, even when we just have three strategies and six agents, we've got 28 profiles and the number of profiles grows exponentially in both number of agents and number strategies, even with symmetry.",
                    "label": 0
                },
                {
                    "sent": "So that's ultimately that's ultimately going to limit us, I should say.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is actually a bit embarrassing to the game theoretic reasoning field, in my view.",
                    "label": 0
                },
                {
                    "sent": "Whatever complexity measures people give for your game computations.",
                    "label": 0
                },
                {
                    "sent": "Everything scales certainly know better than the description of the game, and that's exponential number of players.",
                    "label": 0
                },
                {
                    "sent": "So if we just had a kind of log log scale for the size of the game, that's going to grow with the number of players.",
                    "label": 0
                },
                {
                    "sent": "So complexity of reasoning is going to be at least as complex of writing down the game, and that's grows exponentially with other players.",
                    "label": 0
                },
                {
                    "sent": "That's bad.",
                    "label": 0
                },
                {
                    "sent": "However, in intuitively games do not get more complex.",
                    "label": 0
                },
                {
                    "sent": "With more players, what they actually do is they get more complex for awhile and then they get much easier.",
                    "label": 0
                },
                {
                    "sent": "Certainly with one player you're back to it.",
                    "label": 0
                },
                {
                    "sent": "Just a regular planning problem.",
                    "label": 0
                },
                {
                    "sent": "OK, there's no strategic complexity.",
                    "label": 1
                },
                {
                    "sent": "Once you get a few more, it gets more complex, but once you get a real lot.",
                    "label": 0
                },
                {
                    "sent": "Then the strategic effects are very weak because nobody has much of an influence on the whole system, and you can then start ignoring them again, and I'm pointing this out just to say, you know we're not somehow living up to this, but there's something we're missing here by not having a formalism technology that's letting us get this automatically now.",
                    "label": 0
                },
                {
                    "sent": "Certainly there are lots of theoretical results that let you justify in some cases that in the limit, as number of players goes to Infinity, you can ignore stuff, but we would like to start.",
                    "label": 0
                },
                {
                    "sent": "Getting the benefit of weaker ties well before the number of players goes to Infinity 4.",
                    "label": 0
                },
                {
                    "sent": "Most economic situations I have, they have way fewer than an infinite number of firms involved, say.",
                    "label": 0
                },
                {
                    "sent": "But yet you still have this ability to really take advantage of this.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we there certainly is a lot of work on trying to improve scalability and number of players, and there's one facet of that.",
                    "label": 0
                },
                {
                    "sent": "Some of you may be familiar with things like graphical games, Multiagent influence diagrams.",
                    "label": 1
                },
                {
                    "sent": "These are some formalisms that have emerged over the last eight or eight years or so that try to exploit locality of interaction in a graphical model kind of sense.",
                    "label": 1
                },
                {
                    "sent": "You may have a lot of players, but if they only have small neighborhoods interacting, you can exploit that.",
                    "label": 0
                },
                {
                    "sent": "An approach that we've looked at, which is kind of orthogonal, is to use aggregation of various kinds to simplify the game and the particular method that we use is hierarchal reduction.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Which works as follows.",
                    "label": 0
                },
                {
                    "sent": "We have a.",
                    "label": 0
                },
                {
                    "sent": "A game gamma that has P * Q players in it, say a symmetric game symmetric means like I said before, all that matters is how many players are playing each strategy, not which ones they are.",
                    "label": 0
                },
                {
                    "sent": "Things that are the same for everyone's point of view.",
                    "label": 0
                },
                {
                    "sent": "We can reduce that Tucupi player game by letting each of these P players essentially choose the strategy for Q of the players in the original Game Cube.",
                    "label": 0
                },
                {
                    "sent": "The agents in the original game.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "This of course is an approximation, but we argue that in many natural games this often gives you a very good approximation with an exponentially smaller profile space, and I'll give some examples of that.",
                    "label": 1
                },
                {
                    "sent": "OK, we have some.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Evidence in favor of this.",
                    "label": 1
                },
                {
                    "sent": "OK, first let me even try to suggest what it would mean to say.",
                    "label": 0
                },
                {
                    "sent": "It's a good approximation.",
                    "label": 0
                },
                {
                    "sent": "Well, one way we define it is to say, suppose you take the reduce game and solve that and then look at the quality of your solution with respect to the original game.",
                    "label": 0
                },
                {
                    "sent": "Say we find an equilibrium in the reduced game and then we can say what would be the regret.",
                    "label": 0
                },
                {
                    "sent": "How far from equilibrium regret is a natural measure of how far you are from equilibrium?",
                    "label": 0
                },
                {
                    "sent": "It's saying how much could somebody benefit by deviating right?",
                    "label": 0
                },
                {
                    "sent": "If zero, there's no benefit.",
                    "label": 0
                },
                {
                    "sent": "If there's large regret, then it's unstable in the original game that will be relatively stable in full game.",
                    "label": 1
                },
                {
                    "sent": "Now we can of course contrive a game that where this is.",
                    "label": 0
                },
                {
                    "sent": "This fails arbitrarily.",
                    "label": 0
                },
                {
                    "sent": "But we've taken natural classes of games, say from the gamut repository schoensee in local effect games that you get reasonable approximations as you would expect.",
                    "label": 0
                },
                {
                    "sent": "As you have a finer grained reduction, so here's a local of an 8 player local effect game reduced to a one player game, reducing it to one player game means you say what would be the best strategy if everybody did it.",
                    "label": 0
                },
                {
                    "sent": "Ignoring strategic facts, you get a lot of benefit by going to a two player game, right?",
                    "label": 0
                },
                {
                    "sent": "You're getting some key parts of the strategic interaction and you get a little bit more benefit from the four player game and we see this pattern of kind of diminishing returns.",
                    "label": 0
                },
                {
                    "sent": "Is something that we tend to see and just on the right I have just a benchmark.",
                    "label": 0
                },
                {
                    "sent": "If you just say let's pick the profile that is the global optimum.",
                    "label": 0
                },
                {
                    "sent": "OK, that's usually worse than taking into account some strategic interactions.",
                    "label": 0
                },
                {
                    "sent": "We have some theoretical support for this, and here's a great.",
                    "label": 0
                },
                {
                    "sent": "So if we had the resolution, this would be a crystal clear point that you would just, you know, beginning dramatic insight from but.",
                    "label": 0
                },
                {
                    "sent": "You'll have to take my word for that.",
                    "label": 0
                },
                {
                    "sent": "But we can actually prove and for some games where we have closed form solutions that in some sense is that you can bound the quality of the approximation you get from this kind of reduction.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, there's there's.",
                    "label": 0
                },
                {
                    "sent": "There's still a lot of open questions about this is one way to do reduction.",
                    "label": 0
                },
                {
                    "sent": "There's many other ways that you could conceive of, and I think it's we don't really understand well enough.",
                    "label": 0
                },
                {
                    "sent": "What are the relative tradeoffs for bias?",
                    "label": 0
                },
                {
                    "sent": "Is an approximation quality, and this is really an active area of research.",
                    "label": 0
                },
                {
                    "sent": "There's even questions about whether you need to do.",
                    "label": 0
                },
                {
                    "sent": "So any kind of really strict reduction at all, or you could you could just.",
                    "label": 0
                },
                {
                    "sent": "I get away with just looking at a small subset of the profile space, which I'll get into a little bit later.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I showed you those those graphs of the deviations.",
                    "label": 0
                },
                {
                    "sent": "We'd like to draw those.",
                    "label": 0
                },
                {
                    "sent": "We find those give us an inside a lot of games.",
                    "label": 0
                },
                {
                    "sent": "Here's a deviation graph from the trading agent competition supply chain management game.",
                    "label": 1
                },
                {
                    "sent": "This happens to be the one involving the agents from 2006, and here we just lay it out a little bit differently.",
                    "label": 0
                },
                {
                    "sent": "So first thing I'll mention is now we've reduced it to A3 player game by having each agent Control 2.",
                    "label": 0
                },
                {
                    "sent": "Players in the original game.",
                    "label": 0
                },
                {
                    "sent": "And we've now drawn things in terms of these.",
                    "label": 0
                },
                {
                    "sent": "I so regret concentric... here.",
                    "label": 0
                },
                {
                    "sent": "So in the center you see all the arrows are kind of heading toward the center, they don't.",
                    "label": 0
                },
                {
                    "sent": "They don't have to, but the ones in the center are more stable and you can get a visualization here of what are the parts of profiles.",
                    "label": 0
                },
                {
                    "sent": "But you you're just not going to see a world where there's two ends and APK.",
                    "label": 0
                },
                {
                    "sent": "There's just no way out, and an outer space here.",
                    "label": 0
                },
                {
                    "sent": "To be strong benefit from deviating out of that and the ones in the middle are intuitively much more likely to be played on a more the parts of the search space you want to be focused on, maybe refining further.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "This graph will show that we also use color coding.",
                    "label": 0
                },
                {
                    "sent": "Sometimes to visualize that this is.",
                    "label": 0
                },
                {
                    "sent": "An example of empirical game we did to analyze continuous double auction's.",
                    "label": 0
                },
                {
                    "sent": "That's a very Canonical trading environment of an abstract model of stock markets and commodity markets.",
                    "label": 0
                },
                {
                    "sent": "There's a 20 year literature of people trying to do agent based simulation to come up with the best strategies for continuous level auctions.",
                    "label": 0
                },
                {
                    "sent": "It's one of these cases where it's the simplest possible trading mechanism to describe, but the game theorists have no ability at all to say anything about what idea what equilibrium strategies are.",
                    "label": 0
                },
                {
                    "sent": "So simulation is the game there.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I thought I would say something about how.",
                    "label": 0
                },
                {
                    "sent": "We look at something like ranking strategies.",
                    "label": 1
                },
                {
                    "sent": "Now this is again something that you were doing in this planning competition right?",
                    "label": 0
                },
                {
                    "sent": "The whole purpose is to try to.",
                    "label": 0
                },
                {
                    "sent": "We have these different planners we want to say which is which are better.",
                    "label": 0
                },
                {
                    "sent": "One way we do things in competition.",
                    "label": 0
                },
                {
                    "sent": "We have a tournament now.",
                    "label": 0
                },
                {
                    "sent": "A key difference between the trading agent competition in your planning competition is our competition is a game, so there's interaction among among the strategies that really matters.",
                    "label": 0
                },
                {
                    "sent": "That's the crux.",
                    "label": 0
                },
                {
                    "sent": "That's why we have to do this thing as a competition.",
                    "label": 0
                },
                {
                    "sent": "Whereas you, I think are mainly viewing your planning competition is these are everybody's got an objective measure and now we're just seeing which one is better.",
                    "label": 0
                },
                {
                    "sent": "Respect to that.",
                    "label": 0
                },
                {
                    "sent": "Actually, though, it occurs to me and see how you do this.",
                    "label": 0
                },
                {
                    "sent": "The way that you normalize the strategy scores, you've actually got a little bit of a game element going on there that I'm not sure it was intended.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure it's necessary bad either, but something to think about offline.",
                    "label": 0
                },
                {
                    "sent": "I thought throughout there.",
                    "label": 0
                },
                {
                    "sent": "In any case, the tournament gives you a ranking right?",
                    "label": 0
                },
                {
                    "sent": "But there's something that's arbitrary about that.",
                    "label": 0
                },
                {
                    "sent": "It has something to do with the particular sequence you know, just like the World Cup, soccer, or.",
                    "label": 0
                },
                {
                    "sent": "You know college football in the USA, the sequence of WHO plays who and those matchings has a lot to do with the end outcome.",
                    "label": 0
                },
                {
                    "sent": "In this whole.",
                    "label": 0
                },
                {
                    "sent": "Actually literature on tournament design.",
                    "label": 0
                },
                {
                    "sent": "But the real outcome is not that we need to design tournaments.",
                    "label": 0
                },
                {
                    "sent": "Better is that the idea of a tournament as a way of coming up with a ranking is is probably very limited.",
                    "label": 0
                },
                {
                    "sent": "So what we do is we have a measure called any Nash equilibrium regret.",
                    "label": 0
                },
                {
                    "sent": "The premise here is that.",
                    "label": 0
                },
                {
                    "sent": "In evaluating strategy again, you can't do in isolation.",
                    "label": 0
                },
                {
                    "sent": "It depends what everyone else is doing, so you know you want to avoid this.",
                    "label": 0
                },
                {
                    "sent": "Arguments were saying, well, my strategy is better because it does best against Carmel, and someone says no, my strategy is better because it does best against Shlomo.",
                    "label": 0
                },
                {
                    "sent": "Well, you know which is more relevant.",
                    "label": 0
                },
                {
                    "sent": "Being better against Carmelo being better, national well maybe it has to do with which of slow more caramel or better, right?",
                    "label": 0
                },
                {
                    "sent": "You should maybe be better against which of them are so if you believe in some equilibrium solution concept.",
                    "label": 0
                },
                {
                    "sent": "As defining the plausable, what rational agents would do it, what you should care about is that I'm doing well when the other agents are being rational.",
                    "label": 0
                },
                {
                    "sent": "If I'm doing well when the other ages are being irrational, that is arguably less of a breaking point.",
                    "label": 0
                },
                {
                    "sent": "Now of course, let me Add all the qualifications.",
                    "label": 0
                },
                {
                    "sent": "Sometimes you may have good reason to think that agents are irrational in certain ways and you should exploit that.",
                    "label": 0
                },
                {
                    "sent": "OK, but you need to provide that justification.",
                    "label": 0
                },
                {
                    "sent": "So when we're in the generic world will say, let's be good in equilibrium.",
                    "label": 0
                },
                {
                    "sent": "So we can say let's fix, the other agents are playing the Nash equilibrium and rank everybody else by how well they do against that equilibrium and we get a regret measure and then often gives us very different rankings.",
                    "label": 0
                },
                {
                    "sent": "Then we would get in the tournament.",
                    "label": 0
                },
                {
                    "sent": "OK, we can argue about that.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We've done this with the Tack travel game.",
                    "label": 0
                },
                {
                    "sent": "Here is 50 strategies that we explored in simulation over a period of many years, and they're they're just numbers, so they're meaningless.",
                    "label": 0
                },
                {
                    "sent": "But the point is that we can certainly rule out whole bunch of strategies as not being very effective in equilibrium and limit our attention to the ones that are that have overlapping error bars.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We've done this with continuous level auctions, these are.",
                    "label": 0
                },
                {
                    "sent": "Not quite, totally exhausted, but the main strategies that have appeared in the literature.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                },
                {
                    "sent": "Most of the literature had done pretty ad hoc comparisons.",
                    "label": 0
                },
                {
                    "sent": "Somebody comes up with a new strategy.",
                    "label": 0
                },
                {
                    "sent": "Axen says, well, I tried my strategy when half of them play axe and half of them play ZI and see I do better than ZI or or something.",
                    "label": 0
                },
                {
                    "sent": "Well, again, why's that the relevant comparison to make?",
                    "label": 0
                },
                {
                    "sent": "So what we propose it, you've got to look at the all the combinations form a game of that and then say, let's find an equilibrium.",
                    "label": 0
                },
                {
                    "sent": "And we can rank against that.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "One problem that would come to mind if you know about equilibrium is that there could be more than one of them.",
                    "label": 0
                },
                {
                    "sent": "And so here's an example where we have two pure strategy Nash equilibrium.",
                    "label": 0
                },
                {
                    "sent": "Anyone any two and we get different rankings based on whether we.",
                    "label": 0
                },
                {
                    "sent": "Thinking is pretty similar.",
                    "label": 0
                },
                {
                    "sent": "The regret measures are a bit different.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I think I want to point out is that we.",
                    "label": 0
                },
                {
                    "sent": "These are very complex strategies themselves, so when something like supply chain competition they said there this is a very large piece of code and it's written by many people with many different modules.",
                    "label": 0
                },
                {
                    "sent": "We have a sales module in a factory scheduling module and all these different things and so when we want to even explore the space of those, we would naturally parameterized it by those modules and somebody says, hey, I have an idea for doing prediction of future component prices better let me redo that module and put it in the agent.",
                    "label": 0
                },
                {
                    "sent": "Is that going to make the agent better or not?",
                    "label": 0
                },
                {
                    "sent": "Well, here's why we need to be able to have this ability to do a kind of ranking.",
                    "label": 0
                },
                {
                    "sent": "There's often very complex interactions between these parts, and you can tell and notice.",
                    "label": 0
                },
                {
                    "sent": "You might notice we have.",
                    "label": 0
                },
                {
                    "sent": "This is a partial privatization of our deep maze agent.",
                    "label": 0
                },
                {
                    "sent": "For this watch in Game an we have one feature which is whether or whether we have a bug in the.",
                    "label": 0
                },
                {
                    "sent": "In some of the price prediction part, well, it turns out and I'm sure you've all noticed this.",
                    "label": 0
                },
                {
                    "sent": "Sometimes you have a complex strategy and you fix a bug and it gets worse.",
                    "label": 0
                },
                {
                    "sent": "I'm sure you've all had this experience.",
                    "label": 0
                },
                {
                    "sent": "And that's not unreasonable, right?",
                    "label": 0
                },
                {
                    "sent": "Because in any kind of complex system where you've made approximations and simplifications, the fact that you.",
                    "label": 0
                },
                {
                    "sent": "Did something wrong here?",
                    "label": 0
                },
                {
                    "sent": "Doesn't mean that it's actually not the best thing to do given what everything else is an, especially if you've got a very adaptive system where you maybe other parts have been tuned to fit with the bad behavior you had before fixing their bad behavior is going to make things worse, OK, and this until you start fixing some other things as well so we just track it alright, once you have these parts, that's just another.",
                    "label": 0
                },
                {
                    "sent": "Another feature of the agent.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So actually, the way we would pursue designing an agent for this game is to iterate this empirical game theoretic analysis process.",
                    "label": 0
                },
                {
                    "sent": "So this is what I showed you before and we also use this structure to identify the different research topics that we've worked on.",
                    "label": 0
                },
                {
                    "sent": "So one of them is given you've got a database of simulation data, how do you come up with a game model?",
                    "label": 0
                },
                {
                    "sent": "Another is cake.",
                    "label": 0
                },
                {
                    "sent": "Now that we've analyzed the game, we're not done.",
                    "label": 0
                },
                {
                    "sent": "OK, we might say we're done, but more often than not, there's still more time before the competition.",
                    "label": 0
                },
                {
                    "sent": "We haven't explored everything.",
                    "label": 0
                },
                {
                    "sent": "We have a choice we can explore.",
                    "label": 0
                },
                {
                    "sent": "We could do more sampling of the strategies that we've already started looking at.",
                    "label": 0
                },
                {
                    "sent": "Or we could start to think of entirely new strategies so we could add more strategies.",
                    "label": 1
                },
                {
                    "sent": "We could add more samples anymore.",
                    "label": 0
                },
                {
                    "sent": "Samples is the sample control problem, so either more samples of existing profiles or some of the existing strategies with different combinations.",
                    "label": 1
                },
                {
                    "sent": "And I'll talk a little bit about that.",
                    "label": 0
                },
                {
                    "sent": "OK, there's also the strategy exploration problem.",
                    "label": 1
                },
                {
                    "sent": "How would we even add new strategies to think up?",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for sampling control, we've looked at there's different models for what a sample gives you, and we've explored this in two models and there's a little bit of literature in each one in the reveal payoff model, the unit computation is finding out the payoff for a given strategy profile and the noisy payoff model.",
                    "label": 1
                },
                {
                    "sent": "You get a noisy sample.",
                    "label": 0
                },
                {
                    "sent": "So and we have algorithms for both.",
                    "label": 1
                },
                {
                    "sent": "I'm going to talk about the revealed payoff model, where we've introduced a very straightforward algorithm called minimum regret first search.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the idea is that we want to refute, refute the best equilibrium candidate we have.",
                    "label": 0
                },
                {
                    "sent": "So this.",
                    "label": 0
                },
                {
                    "sent": "Let's say we have this two player for strategy game to pretty simple.",
                    "label": 0
                },
                {
                    "sent": "So obviously we could explore exhaustively and let's say, but let's say there's some, there's a cost to filling in a cell of the payoff matrix.",
                    "label": 0
                },
                {
                    "sent": "So we start in some arbitrary place with the profile where the role player plays are one the column player plays C1, and that has some payoff 9 to the role player 5 to the column player.",
                    "label": 0
                },
                {
                    "sent": "On our epsilon bound, epsilon is regret is zero as far as we know.",
                    "label": 0
                },
                {
                    "sent": "This could be in equilibrium, there's no lower bound on how close to equilibrium this could be.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But once we explore, some deviation will pick some.",
                    "label": 0
                },
                {
                    "sent": "Random deviation of this will have the column player try C2.",
                    "label": 0
                },
                {
                    "sent": "We see that this also this doesn't do any better for either player.",
                    "label": 0
                },
                {
                    "sent": "I mean for the column player comp players worse, but the this new profile has an epsilon bound of two, right?",
                    "label": 0
                },
                {
                    "sent": "We know that the column player could benefit by two by going to play C1 instead of C2, so that has an epsilon bound of two.",
                    "label": 0
                },
                {
                    "sent": "So still our first one, R1C1 is the best candidate we have.",
                    "label": 0
                },
                {
                    "sent": "This priority queue here on the right.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we're going to still expand the R1C1, and we explore a deviation to R2.",
                    "label": 0
                },
                {
                    "sent": "Again, that's not as good.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We'll try our three, though.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That is good.",
                    "label": 0
                },
                {
                    "sent": "Will try C4 this now we now we do have a positive deviation.",
                    "label": 0
                },
                {
                    "sent": "Right, so now we have a lower bound of three.",
                    "label": 0
                },
                {
                    "sent": "On the regret for that R1C1, but we have a new candidate that has that could be in equilibrium which is R1C four.",
                    "label": 0
                },
                {
                    "sent": "So now we look.",
                    "label": 0
                },
                {
                    "sent": "We explore deviation from that.",
                    "label": 0
                },
                {
                    "sent": "We try to refute that by looking at a deviation.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "From that OK and we.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Proceed with this.",
                    "label": 0
                },
                {
                    "sent": "By just always finding a deviation, exploring a deviation to the lowest regret bound.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Profile",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we finally get to a point where we have confirmed an equilibrium.",
                    "label": 0
                },
                {
                    "sent": "R2C2 is in equilibrium.",
                    "label": 0
                },
                {
                    "sent": "We looked at all the deviations and probably want to want to emphasize is that we've established that this is an equilibrium without knowing the whole game.",
                    "label": 0
                },
                {
                    "sent": "Right, it doesn't matter these these white cells.",
                    "label": 0
                },
                {
                    "sent": "It doesn't matter what's in there.",
                    "label": 0
                },
                {
                    "sent": "Those are not going to affect the proposition that R2C2 is in equilibrium, so you can often establish equilibrium without knowing the full game.",
                    "label": 0
                },
                {
                    "sent": "Now, of course, we can't rule out that any of these other unexplored profiles themselves might be equilibrium.",
                    "label": 0
                },
                {
                    "sent": "There could be multiple equilibrium, but we can.",
                    "label": 0
                },
                {
                    "sent": "We can get some traction on game analysis without looking at the whole game.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in fact, this minimum regret for search often finds.",
                    "label": 0
                },
                {
                    "sent": "A very good approximations equilibrium.",
                    "label": 0
                },
                {
                    "sent": "Here's a regret measure with exploring a very small fraction of the profile space.",
                    "label": 0
                },
                {
                    "sent": "Here we compare it to a previous proposal in the literature that was based on a tabu search.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, I'm I'm just going to just briefly say something about the game model induction problem.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Once you view that you've got some set of data on some subset of the profiles, what you can think of is what we're trying to do is really generalize this the whole game.",
                    "label": 0
                },
                {
                    "sent": "You can think of it as a curve fitting problem.",
                    "label": 0
                },
                {
                    "sent": "I've got a bunch of of data points.",
                    "label": 0
                },
                {
                    "sent": "Here's the strategy profile.",
                    "label": 0
                },
                {
                    "sent": "Here's the utility for that.",
                    "label": 0
                },
                {
                    "sent": "Is the payoff vector for that.",
                    "label": 0
                },
                {
                    "sent": "Let me now try to.",
                    "label": 0
                },
                {
                    "sent": "Generalize this to a payoff function over the whole space.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we've explored doing this as a regression problem where we basically we can even use this to learn a model that has a continuous, has a infinite strategy space.",
                    "label": 0
                },
                {
                    "sent": "Right by assuming there's some structure in the in the space, and under certain circumstances we can quantify how well that well that does.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Move ahead a little bit.",
                    "label": 0
                },
                {
                    "sent": "I want to say a word about the strategy exploration problem.",
                    "label": 0
                },
                {
                    "sent": "So one possibility is that we want to not just sample the strategy that we want to generate entirely destroyed.",
                    "label": 0
                },
                {
                    "sent": "This is when you're going back to the drawing board and say I want to rewrite some part of my plan or I want to introduce a new module for my.",
                    "label": 0
                },
                {
                    "sent": "My supply chain agency.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So one approach we've looked at this, you know, and you can plug in.",
                    "label": 0
                },
                {
                    "sent": "Really, this is really a planning problem.",
                    "label": 0
                },
                {
                    "sent": "So here we using reinforcement learning.",
                    "label": 0
                },
                {
                    "sent": "But what we try to do is we have a provisional Nash equilibrium based on the search we've done so far and we say, well, can we think of a strategy that does better when everybody else is playing the equilibrium?",
                    "label": 0
                },
                {
                    "sent": "Notice the way I formulated that we're fixing the behavior of everybody else and you could do this too.",
                    "label": 0
                },
                {
                    "sent": "And then you've basically got a one single agent planning problem.",
                    "label": 0
                },
                {
                    "sent": "Just finding a best response.",
                    "label": 0
                },
                {
                    "sent": "To that man.",
                    "label": 0
                },
                {
                    "sent": "And here we're using reinforcement learning.",
                    "label": 0
                },
                {
                    "sent": "We try to find a better strategy, assuming that there fixed by doing a search in a space of strategies and we get that and we test it out.",
                    "label": 0
                },
                {
                    "sent": "If that is in fact a beneficial deviation, then we add it to the strategy set an we're back on our merry way in this iterative approach.",
                    "label": 0
                },
                {
                    "sent": "If it's not a deviation, then we've got to do something to improve our planning or improve our our learning model to do this or give up.",
                    "label": 0
                },
                {
                    "sent": "So one.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Domain in which we've done this is in that continuous double auction problem.",
                    "label": 0
                },
                {
                    "sent": "OK, remember this is the area I said.",
                    "label": 0
                },
                {
                    "sent": "This is a very Canonical auction model that's at the basis for all financial markets, but yet there's no games resolution authorises this literature on agents that.",
                    "label": 0
                },
                {
                    "sent": "Are simulated against each other.",
                    "label": 0
                },
                {
                    "sent": "Here we say, let's just.",
                    "label": 0
                },
                {
                    "sent": "Try to do a reinforcement learning approach.",
                    "label": 0
                },
                {
                    "sent": "We come up with some features.",
                    "label": 0
                },
                {
                    "sent": "For the state space that includes things like some statistics on history of recent trades, some price quotes for what the current bid ask spread is what time is it?",
                    "label": 0
                },
                {
                    "sent": "How much time has there been since the trade happened, and some state about for us?",
                    "label": 0
                },
                {
                    "sent": "What is the value of the next unit to be traded?",
                    "label": 0
                },
                {
                    "sent": "Or action is not?",
                    "label": 0
                },
                {
                    "sent": "How much we bid, but rather how much of a margin we request from our value.",
                    "label": 0
                },
                {
                    "sent": "OK, this helps make make our policy is a little bit more robust, we say.",
                    "label": 0
                },
                {
                    "sent": "I want to ask for a profit of 10 if it's worth hundreds of me.",
                    "label": 0
                },
                {
                    "sent": "I'm going to offer to buy it for 90.",
                    "label": 0
                },
                {
                    "sent": "And the rewards are the profit you make from trading.",
                    "label": 0
                },
                {
                    "sent": "So we've we tried this version of this state space.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Come on CD's and we get this.",
                    "label": 0
                },
                {
                    "sent": "This is the iterative approach.",
                    "label": 0
                },
                {
                    "sent": "We actually didn't first build the game of all the previous literature.",
                    "label": 0
                },
                {
                    "sent": "I said it was a little more impatient to try out the learning stuff, so we just took some some three strategies.",
                    "label": 0
                },
                {
                    "sent": "Kaplan, Zi and Zi beat the quote.",
                    "label": 0
                },
                {
                    "sent": "We found an equilibrium of those which was everybody playing Zi.",
                    "label": 0
                },
                {
                    "sent": "We ran reinforcement learning and came up with a strategy.",
                    "label": 0
                },
                {
                    "sent": "We'll call it L1, which successfully deviated from that, and in fact after that we had a new equilibrium, which is everybody playing L1 said great this thing.",
                    "label": 0
                },
                {
                    "sent": "This stuff works.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We then added a few more agents from literature and now got back to an equilibrium where it was all agents.",
                    "label": 0
                },
                {
                    "sent": "The GD agent gears that Dick out.",
                    "label": 0
                },
                {
                    "sent": "Trader from literature was.",
                    "label": 0
                },
                {
                    "sent": "The soul play in equilibrium.",
                    "label": 0
                },
                {
                    "sent": "So we ran learning on that.",
                    "label": 0
                },
                {
                    "sent": "Now L2 through LA it means the next seven iterations of reinforcement learning didn't work for us, and we had to keep triggering the state space description and how we formulated the URL problem until we finally came up with something that worked that successfully deviated.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we did this for many more rounds.",
                    "label": 0
                },
                {
                    "sent": "We eventually.",
                    "label": 0
                },
                {
                    "sent": "Came up with a strategy L 11 and then threw in GDX which was the champion from literally probably should have put in earlier.",
                    "label": 0
                },
                {
                    "sent": "It took over most of the equilibrium, but then we eventually overthrew that and then ultimately ended up with an equilibrium with just new learn strategies.",
                    "label": 0
                },
                {
                    "sent": "So the claim here is that we've got a new new champion.",
                    "label": 0
                },
                {
                    "sent": "12 and 13.",
                    "label": 0
                },
                {
                    "sent": "Through this process now the you might ask.",
                    "label": 0
                },
                {
                    "sent": "Well, great.",
                    "label": 0
                },
                {
                    "sent": "So what does L 12 and 13 do?",
                    "label": 0
                },
                {
                    "sent": "And I wish I could answer that question.",
                    "label": 0
                },
                {
                    "sent": "L 12 and 13 are strategies that were learned by a reinforcement learner, and there this very opaque.",
                    "label": 0
                },
                {
                    "sent": "Mapping from those features to actions and we actually did a lot of analysis to try to understand under what circuit and we got a little bit of insight into under what circumstances it does something different than what GDX does and that gives us some sense and how to characterize it.",
                    "label": 0
                },
                {
                    "sent": "But it's not satisfying like the manually defined strategies, right?",
                    "label": 0
                },
                {
                    "sent": "The manually defined strategies have an idea behind them, and there's a drawback of learning strategies automatically.",
                    "label": 0
                },
                {
                    "sent": "But nevertheless what we have here is a method that.",
                    "label": 0
                },
                {
                    "sent": "Can improve strategies automatically.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, listen.",
                    "label": 0
                },
                {
                    "sent": "We want to step back and say we had.",
                    "label": 0
                },
                {
                    "sent": "This was a particular approach to strategy exploration.",
                    "label": 0
                },
                {
                    "sent": "Was it reasonable?",
                    "label": 0
                },
                {
                    "sent": "We you know it's expensive to introduce a new strategy because then you want you're expecting to do simulations over the whole profile space, right?",
                    "label": 0
                },
                {
                    "sent": "We wouldn't want to do that over all conceivable policies, so we need to be deliberate.",
                    "label": 0
                },
                {
                    "sent": "So what we did, that's why we only introduced strategy when it was a deviation of beneficial deviation to occur in equilibrium.",
                    "label": 0
                },
                {
                    "sent": "And in particular, what I what we did, and I didn't justify it was we said, let's find a best response.",
                    "label": 0
                },
                {
                    "sent": "In our case by reinforcement learning or I suggested by planning to the car and equilibrium well, is that the right thing to even be trying to do?",
                    "label": 0
                },
                {
                    "sent": "If we could compute the best response.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Not necessarily.",
                    "label": 0
                },
                {
                    "sent": "In fact, any strategies itself may be a really bad idea, so.",
                    "label": 0
                },
                {
                    "sent": "Here's a contrived game that has two players and four strategies.",
                    "label": 0
                },
                {
                    "sent": "If we just had a one was the only strategy we knew about, we would say, oh, the equilibrium is play one and the regret with respect to the true game is 3 because you could do better by playing a four against A1.",
                    "label": 0
                },
                {
                    "sent": "But if we added a two in there, we would say we have a new equilibrium.",
                    "label": 0
                },
                {
                    "sent": "Just think of this.",
                    "label": 0
                },
                {
                    "sent": "A subgame with the upper left corner but a 2.",
                    "label": 0
                },
                {
                    "sent": "Actually that would be a worse.",
                    "label": 0
                },
                {
                    "sent": "That would have a higher regret.",
                    "label": 0
                },
                {
                    "sent": "And in fact you know it's contrived so that.",
                    "label": 0
                },
                {
                    "sent": "Adding strategies in a certain order, we actually get worse and worse and worse every time until finally you have the whole game and then we get better.",
                    "label": 0
                },
                {
                    "sent": "Then we get better but you always get better in the end.",
                    "label": 0
                },
                {
                    "sent": "So it matters what order you look at things looking at more is not always better.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we ask about weather.",
                    "label": 0
                },
                {
                    "sent": "Best response is good, so here's a game that we understand really well because we have closed form characterizations of part of it, and we use this to test our understanding of some of these questions.",
                    "label": 0
                },
                {
                    "sent": "First, price sealed bid auction for two players, and this is a regret surface that says if these two players play bid different fractions of their valuation, how far are we from an equilibrium and?",
                    "label": 0
                },
                {
                    "sent": "It's a little.",
                    "label": 0
                },
                {
                    "sent": "It's a bit hard to see here, but it turns out that if you do a best response dynamics here, we start at some point in that surface and somebody changes to a best response to what the other guy is doing.",
                    "label": 0
                },
                {
                    "sent": "You crawl down that a tiny bit and you'll eventually get to an equilibrium.",
                    "label": 0
                },
                {
                    "sent": "However, if at any point.",
                    "label": 0
                },
                {
                    "sent": "You get to the other half of plane.",
                    "label": 0
                },
                {
                    "sent": "Here in one shot, the best response will give you give you right to equilibrium.",
                    "label": 0
                },
                {
                    "sent": "So what this suggests is actually what you should do is you should if you should just randomly throw in some some guesses, because if you have those in the mix a best response there is going to get you in one shot to the equilibrium.",
                    "label": 0
                },
                {
                    "sent": "So this is kind of in retrospect to kind of not so surprising.",
                    "label": 0
                },
                {
                    "sent": "Explore, exploit kind of thing where having a diversity of strategies in the mix is also really valuable, and what that.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Means for exploration policy zizza question.",
                    "label": 0
                },
                {
                    "sent": "Our current best is something we call MMT.",
                    "label": 0
                },
                {
                    "sent": "That it is based on a rational closure concept, which I'm not going to go into here, but I just wanted to make the point that this is itself an issue that we find that this does just systematically better than best response across a range of games.",
                    "label": 0
                },
                {
                    "sent": "OK, so I'm closing time.",
                    "label": 0
                },
                {
                    "sent": "I'd like to have some time for questions so.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let me just.",
                    "label": 0
                },
                {
                    "sent": "Point out that we've been really our main agenda is to build this methodology to look at these various sub questions in how to do game analysis in this empirical way.",
                    "label": 0
                },
                {
                    "sent": "We've applied it to a lot of different market games, for example those from the trading agent competition I mentioned.",
                    "label": 0
                },
                {
                    "sent": "Briefly, the travel game is supply chain game.",
                    "label": 0
                },
                {
                    "sent": "There's also an ad auction game this year.",
                    "label": 0
                },
                {
                    "sent": "The trading agent competition is introducing a power attack, an energy trading game.",
                    "label": 0
                },
                {
                    "sent": "Another kind of hot topic.",
                    "label": 0
                },
                {
                    "sent": "We've also used it to explore.",
                    "label": 0
                },
                {
                    "sent": "I mentioned continuous double auctions.",
                    "label": 0
                },
                {
                    "sent": "We have some new results on on simultaneous.",
                    "label": 0
                },
                {
                    "sent": "One shot, second price sealed bid auctions we've done work on on others the kind of mechanisms that are close to what exists in the world, but yet you are totally lacking.",
                    "label": 0
                },
                {
                    "sent": "Currently game theoretic satisfactory solutions.",
                    "label": 0
                },
                {
                    "sent": "We looked at other problems in finance problems in security and privacy networking.",
                    "label": 0
                },
                {
                    "sent": "No end of kinds of games that I think are amenable to this kind of view.",
                    "label": 0
                },
                {
                    "sent": "We've also looked at not just game analysis, but the outer loop of that mechanism design if we can.",
                    "label": 0
                },
                {
                    "sent": "Some control some aspects of the game.",
                    "label": 0
                },
                {
                    "sent": "How would we use empirical methods to get a handle on what to do there?",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what I hope you will take away from this is at least my claim that you can employ game theoretic approaches beyond where you can really just use them in a purely analytical way, even when you have procedurally defined scenarios and you do that by embracing methods like simulation and machine learning.",
                    "label": 0
                },
                {
                    "sent": "The the key complementarity is uses the game theoretic concepts come into the four in giving you a guide towards what.",
                    "label": 0
                },
                {
                    "sent": "Context of the other agents matter.",
                    "label": 0
                },
                {
                    "sent": "OK, which profiles of the other agents should you actually care about when you're evaluating your own strategy?",
                    "label": 0
                },
                {
                    "sent": "And then you have your regular toolkit of ways to explore your own strategies given given that context.",
                    "label": 0
                },
                {
                    "sent": "So in the end, what we're shooting for is a.",
                    "label": 0
                },
                {
                    "sent": "Principled approach to evaluate these repeated domains, and we're building the toolbox and we could use some help, so I'll end it there.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                },
                {
                    "sent": "So going back to your example of the six players, with the four playing A and two playing be equilibrium.",
                    "label": 0
                },
                {
                    "sent": "So if I'm one of the players, what do I play?",
                    "label": 0
                },
                {
                    "sent": "Haha I.",
                    "label": 0
                },
                {
                    "sent": "Gay, good question.",
                    "label": 0
                },
                {
                    "sent": "So the the.",
                    "label": 0
                },
                {
                    "sent": "This does not answer, would be well, it depends.",
                    "label": 0
                },
                {
                    "sent": "If you have 1A and four bees among the rest you you're an A, and if there's two azan three bees among rescue Roby.",
                    "label": 0
                },
                {
                    "sent": "But how how they did actually coordinate on a non symmetric pure equilibrium is, I think a good reasonable question, so I don't think we literally say that's going to be the answer right?",
                    "label": 0
                },
                {
                    "sent": "But the we actually used to say you know it's as expected.",
                    "label": 0
                },
                {
                    "sent": "There would be a predominant surveys, and in fact we actually derived in this case more normally symmetric mixed equilibrium is the is when we are going for a particular equilibrium we typically prefer.",
                    "label": 0
                },
                {
                    "sent": "The symmetric equilibrium when we have a symmetric game, and so once you have if we had this symmetric mixture then then that would answer your question directly but good catch.",
                    "label": 0
                },
                {
                    "sent": "Michael, so I wondered whether you may have already talked about this and I I sort of didn't get the details, but I wondered whether you looked at trying to pinpoint where the challenges are in the games by using the strategies as judges of where the difficulty lies.",
                    "label": 0
                },
                {
                    "sent": "So we did this in the 2003 planning competition trying to understand which domains were really hard domains in which were easy.",
                    "label": 0
                },
                {
                    "sent": "We used the competing planners of as judges of of that and then tried to see whether there was a statistical significance in the difference in.",
                    "label": 0
                },
                {
                    "sent": "In their performance, and if planners were consistently finding domains easy, then that told us something about the structure of the domain and it equally if they were consistently finding them difficult, then that told us something and we were able to do a comparison between the domains on that basis.",
                    "label": 0
                },
                {
                    "sent": "So I just thought you have a lot of statistical information in the way that the strategies are being played out and the effect on the games, and it might be possible to, for example, pinpoint better that relationship between the game and the number of players to give you a better idea of actually where it becomes easy again because you're.",
                    "label": 0
                },
                {
                    "sent": "You're losing the strategic information when you've got so many players, so I just wondered if you'd explored that.",
                    "label": 0
                },
                {
                    "sent": "Yes, absolutely.",
                    "label": 0
                },
                {
                    "sent": "I mean not that we have in an automatic way of cranking out answers to that, but certainly anecdotally what you get out of these competitions and even just a game analysis, is a better understanding of which are the pivotal strategic issues.",
                    "label": 0
                },
                {
                    "sent": "So for us, it's not.",
                    "label": 0
                },
                {
                    "sent": "Is it hard or easy, so much as what actually are the issues that matter what?",
                    "label": 0
                },
                {
                    "sent": "Which are the sub problems that are more instrumental to improving overall performance so?",
                    "label": 0
                },
                {
                    "sent": "Actually, that first example that I didn't explain of what aggressive and baseline were there was because there was a surprise to the designers.",
                    "label": 0
                },
                {
                    "sent": "The first in the first couple of years of the supply chain game that the procurement of a lot of components at the very beginning was a driver of everything else.",
                    "label": 0
                },
                {
                    "sent": "It put a lot of the other issues that the designers were hoping to explore into the noise.",
                    "label": 0
                },
                {
                    "sent": "Kind of thing that you maybe didn't even it became so obvious just based on what actually happened when you observe the game.",
                    "label": 0
                },
                {
                    "sent": "It wasn't obvious from the design, but it was obvious once people through their strategies in and we saw what happened.",
                    "label": 0
                },
                {
                    "sent": "The analysis we did was more of a post competition way to verify.",
                    "label": 0
                },
                {
                    "sent": "So a little bit more of the story there was a.",
                    "label": 0
                },
                {
                    "sent": "A strong incentive to buy lots of components right at the beginning of the game.",
                    "label": 0
                },
                {
                    "sent": "Because there was a limited amount of them and there was cheap as they were going to be.",
                    "label": 0
                },
                {
                    "sent": "And if you did that.",
                    "label": 0
                },
                {
                    "sent": "Then everybody else to do it too, because then there would be no components left later in the game.",
                    "label": 0
                },
                {
                    "sent": "The suppliers had already committed their capacity, but then the whole system was very vulnerable because if the demand for PC's turned out to be low, everybody had all these components and they were just killing each other to sell PCs at no price.",
                    "label": 0
                },
                {
                    "sent": "And everybody was.",
                    "label": 0
                },
                {
                    "sent": "That's why you had everyone losing money in equilibrium.",
                    "label": 0
                },
                {
                    "sent": "And this is what happened in the actual tournament.",
                    "label": 0
                },
                {
                    "sent": "There was this destructive thing, but everyone knows.",
                    "label": 0
                },
                {
                    "sent": "Hey, the ones who are buying the components of the beginning are doing well.",
                    "label": 0
                },
                {
                    "sent": "Let me do that to an it was and we were looking at the same node.",
                    "label": 0
                },
                {
                    "sent": "This is terrible.",
                    "label": 0
                },
                {
                    "sent": "Don't do this.",
                    "label": 0
                },
                {
                    "sent": "This is suicidal.",
                    "label": 0
                },
                {
                    "sent": "We're lemmings running off the Cliff and the game theoretic analysis is a way of saying, you know what?",
                    "label": 0
                },
                {
                    "sent": "You know.",
                    "label": 0
                },
                {
                    "sent": "The lemmings were rational that this was inevitable.",
                    "label": 0
                },
                {
                    "sent": "This was going to happen given the setup of the game.",
                    "label": 0
                },
                {
                    "sent": "It wasn't just that everybody who entered the tournament that year was insane.",
                    "label": 0
                },
                {
                    "sent": "So I think that's the kind of thing you get from the company, both having real people throwing their strategy ideas and also doing a little bit of analysis.",
                    "label": 0
                },
                {
                    "sent": "Yeah, there was an assertion of the in in the middle of the talk that when the number of players increases then the game begets simple intuitively.",
                    "label": 0
                },
                {
                    "sent": "But I couldn't understand the intuition.",
                    "label": 0
                },
                {
                    "sent": "Could you elaborate on it, right?",
                    "label": 0
                },
                {
                    "sent": "So it was.",
                    "label": 0
                },
                {
                    "sent": "This was a very informal statement, right?",
                    "label": 0
                },
                {
                    "sent": "And I think it actually can be made formal, but usually only in very limited in in the in limit kinds of arguments.",
                    "label": 0
                },
                {
                    "sent": "But the basic intuition is that think of think of something like these PC makers, right?",
                    "label": 0
                },
                {
                    "sent": "If there's if there's three of them, then.",
                    "label": 0
                },
                {
                    "sent": "It really pays a lot for you to think about the what the other two are doing, because that's going to affect you alot if there's 100 of them, every one of them is affecting only a small part of the market and it's kind of negligible and you yourself are also going to have a negligible effect on the market, so you can just not think about the strategy so much.",
                    "label": 0
                },
                {
                    "sent": "Just think about basically your own situation and take the rest of the world is pretty much fixed, so that's the sense in which as the number of agents gets large but way short of Infinity, you can really start discounting the strategic effects.",
                    "label": 0
                },
                {
                    "sent": "And we should have a technology that exploits that.",
                    "label": 0
                },
                {
                    "sent": "I presume you don't allow any collusion between players.",
                    "label": 0
                },
                {
                    "sent": "So that's interesting, and in the trading agent competition we have generally not disallowed collusion.",
                    "label": 0
                },
                {
                    "sent": "What we've disallowed is sacrificial collusion.",
                    "label": 0
                },
                {
                    "sent": "So what you got to do is say, you know what I'm going to buy PC's for you for $1,000,000 each I'll have a big negative profit.",
                    "label": 0
                },
                {
                    "sent": "You'll have a big positive profit.",
                    "label": 0
                },
                {
                    "sent": "You'll win the competition.",
                    "label": 0
                },
                {
                    "sent": "I'll lose that.",
                    "label": 0
                },
                {
                    "sent": "That's not allowed, but price fixing, other kinds of things we've generally not disallowed that, in part because I was skeptical that people would be able to pull it off.",
                    "label": 0
                },
                {
                    "sent": "In the first place, interesting to see if they could.",
                    "label": 0
                },
                {
                    "sent": "Maybe if it was real money agents would do it more, but we have not observed that happening.",
                    "label": 0
                },
                {
                    "sent": "Has anybody really studied the problem of if you're stuck in one Nash equilibrium and you can do collusion, how a group of players might actually get you out of that Nash equilibrium to one another, one that was more attractive?",
                    "label": 0
                },
                {
                    "sent": "OK, well that's not so technically that would necessarily be called collusion, just doing it for different equilibrium selection.",
                    "label": 0
                },
                {
                    "sent": "Certainly communication and all that kind of stuff is also not disallowed.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "I, I think there's a reluctance, so for example in that really, that suicidal, effective digital procurement, it wasn't clear that there was anything that anybody could say that was going to stop this March into the really.",
                    "label": 0
                },
                {
                    "sent": "Bad equilibrium.",
                    "label": 0
                },
                {
                    "sent": "Except this preemption kind of thing that we ended up doing, but.",
                    "label": 0
                },
                {
                    "sent": "In general, coordination and equilibrium is something that should be studied.",
                    "label": 0
                },
                {
                    "sent": "I mean, it's a relevant aspect of.",
                    "label": 0
                },
                {
                    "sent": "Games when there are multiple equilibrium you do need criteria outside of game theory to give you a sense of what's really going to happen, and that's another very interesting question of how you formulate such criteria and incorporate them in your analysis.",
                    "label": 0
                }
            ]
        }
    }
}