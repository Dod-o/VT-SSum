{
    "id": "6ki76gf2ptxy3czbblpgd5zospbxtrm5",
    "title": "Casuality and feature selection",
    "info": {
        "author": [
            "Isabelle Guyon, Clopinet"
        ],
        "published": "Nov. 14, 2007",
        "recorded": "July 2007",
        "category": [
            "Top->Computer Science->Machine Learning->Feature Selection"
        ]
    },
    "url": "http://videolectures.net/bootcamp07_guyon_cfs/",
    "segmentation": [
        [
            "Two now.",
            "We have not at all talked about whether the features that we're selecting are causes or consequences of our target of interests.",
            "What difference does it make in the 1st place?",
            "So for years you know the people working in the feature selection domain have been saying we should not care about causality because take the example that we're trying to diagnose disease.",
            "Example, we trying to diagnose cancer and there can be features that are causing cancer that are as predictive as features that are consequences of cancer.",
            "Or you know, let's see.",
            "Imagine that an example which is familiar to us.",
            "Let's try to see how we can diagnose AIDS.",
            "There are features that can be causes of AIDS.",
            "Like you know some behavior of people and or some country of origin.",
            "Those are all things that can be identified.",
            "Risk factors for ads, and using the risk factors you can predict with some confidence whether the person is going to contract the disease or not.",
            "But with respect to making diagnosis, we are also using consequences.",
            "The ELISA test is an antibody test that measures some consequences of aid.",
            "By some immune reaction that we have.",
            "So with respect to feature selection, the feature selection people usually say we want any feature that has some predictive power, and it could be either A cause or consequence.",
            "We don't care.",
            "Let's just predict the target variable.",
            "However, as we will see in this lecture, there is much to be gained by understanding whether the features are causes or consequences of the target.",
            "And imagine now the following situation.",
            "People have lung cancer.",
            "And there are features that are causing lung cancer.",
            "For example, smoking may be an identifiable cause of cancer and there are features that are consequences.",
            "For example, coughing.",
            "Now those two kinds of features are not equivalent with respect to actions you might want to take on the system if your goal now is not only to make prediction, but to improve the health status of people, then if you make a policy that you shouldn't smoke in public places, this might have a consequence on how many people get lung cancer.",
            "But if you make a policy that people should take one spoon of anti coughing medicine every morning then this will reduce the amount of coughing.",
            "But this will have eventually no consequences on contract ING or not Lang cancer.",
            "So causes and consequences don't have the same power with respect to.",
            "Making the correct action in order to change the target of interest, and this is particularly important in economy for policymaking, you want to know whether changing the tax rate is going to have a positive impact on the economy.",
            "For example, it's very important in ecology should you restric the emission of carbon dioxide to reduce the risk of global warming.",
            "In that case, you know you only care about detecting the causes, so the consequences of global warming, for example, like the melting of the ice on in the North Pole, are not going to change the global warming.",
            "If you could put a big refrigerator and freezer again the North Pole.",
            "Is not going to improve the global warming.",
            "So and there are many, many cases like that.",
            "You know in medicine for drug discovery, health policymaking, etc.",
            "So this is one reason we care about causality.",
            "Another reason we care about causality is because it's going to help us understand the difference between what is true in our measurements and what comes from experimental artifacts.",
            "We just had a lecture before where I hope I convinced you that if you just trust your data blindly and you don't know how the data was collected, you may make very wrong decisions about which feature is relevant or not, or about you know.",
            "How predictive feature is going to be causality is going to help you sort out things and figure out you know whether you can believe in this feature or not."
        ],
        [
            "So this is the setup of variable and feature selection.",
            "The way people usually think about it.",
            "He want to remove feature XI.",
            "If it improves or this degrades predictions of Y."
        ],
        [
            "What can go wrong?",
            "You have seen these two scatter plots in one of the lecture I gave before.",
            "Hopefully you remember them.",
            "I use them to do what?",
            "Anybody remembers the scatter plots?",
            "Importance of features single features.",
            "Yes, I use them to justify multivariate feature selection.",
            "I use them to tell you well, if you look, you know in projection on single axis you may be fooling yourself.",
            "This feature X1 looks like it's separating the two classes fine.",
            "This feature X2 looks like it's not separating anything.",
            "You might be discarding it, but in fact it's helping you because it's helping, making you a much better separation in two dimensions that you would get by using feature X1 alone and I told you be careful, don't use univariate feature selection because you may get also cases like that.",
            "In which none of the features is predicted by itself, but in several dimensions, you get very good separation, and that's the case.",
            "You know the metal and data set that we are studying in the practical class in the practical session, you know.",
            "This case, however, happens very rarely, and.",
            "Mostly that's just your theoretical interest.",
            "It does happen in practice and we will see when it happens.",
            "Now I'm going to tell you the opposite of what I said before I told you.",
            "Well, don't choose always univariate feature selection, because sometimes you need to have multivariate feature selection.",
            "I'm going to tell you be careful when you use multivariate feature selection and when you have cases like that.",
            "This should raise a red flag and you should be looking at your data very carefully because this is a non trivial case."
        ],
        [
            "Let's examine the first case.",
            "I encountered this case in real data and we had it was a case of mass spectrometry data.",
            "And we had spectral like that.",
            "In that case, you have to think that each feature is a position in the spectrum.",
            "So what you see on the on the X and the Y axis here is the magnitude of the feature and each position here is a different feature, OK?",
            "Now when you run a feature selection algorithm.",
            "On that, so each pattern here is a is one of the Spectra, and we have the red Spectra which of examples from one class and the green Spectra examples from the other class.",
            "So the feature selection algorithm happily tells you that this is a very good feature here at this position, because you see that the red class is very well discriminated from the green class, right?",
            "And then the feature selection algorithm, which is a forward selection algorithm.",
            "There is nothing you know special about this.",
            "I just run the gram Schmidt organization method.",
            "The most complementary feature to the first feature is this one.",
            "Now, as you can see by eye, the spectral completely overlap in this region.",
            "By itself, this feature is not at all discriminative, so we have this case here.",
            "Feature X One is like this.",
            "It separates quite well the two classes feature X2 does not.",
            "Separate the classes at all by itself.",
            "But when taken together, they gave a nice separation.",
            "Now the question is, should we trust feature X2?",
            "What would you do?",
            "Any comments on that?",
            "Anybody can think of something it's not so easy when you see that for the first time, but maybe some of you have seen similar things.",
            "Or maybe it occurs to you what this case, could you know?",
            "Trusting well by trusting, I mean that this this indicating that particular case.",
            "You know.",
            "Every position here corresponds to.",
            "To some amount of protein in blood, right?",
            "This picture indicates that this mass value it's a mass spectrum.",
            "At this mass value there is a protein that discriminates very well between these two populations.",
            "Now at this mass value here there is an interesting feature that complements that feature.",
            "Should we consider this as you know when people call in the field of biomarker?",
            "So an important thing to be measuring right so that we can make the decision about the health status of the patient.",
            "It is not easy because of course you don't know the domain, but The thing is that what would happen if I change instrument?",
            "What?",
            "What is this?",
            "You know here that we're measuring here Valley, we know that peaks represent protein amounts, but valleys?",
            "What are the meaning of values here?",
            "We're measuring, you know, the amount of something in a Valley.",
            "It's kind of bizarre, right?",
            "If you think about it, what's happening here is that we are measuring locali.",
            "The other thing I have to tell you is that this is only a small part of a big spectrum.",
            "In fact, you know there is this tons of things going here and thumbs up thing I'm zooming in on a small part here, so this is actually measuring locali what the baseline is.",
            "For this pic here this is, you know, a nice flat part.",
            "In which you can easily measure that there is an offset up or an upset down of all the Spectra of all the pics simultaneously.",
            "So for one spectrum, if this is high here, this is a little bit high here also by a certain offset.",
            "So what this does here is that helps you subtracting the baseline.",
            "From that pic here.",
            "I think you think you know.",
            "Realize what I'm talking about, right?",
            "So this is what I would call an experimental artifact.",
            "Because we have not done the preprocessing correctly, we have not subtracted well enough the baseline here.",
            "There is some residual noise.",
            "Systematic noise right?",
            "This is noise that we could have gotten rid of by good preprocessing.",
            "The residual systematic noise is taken care of by the feature selection stage.",
            "Feature selection stage is smart enough to say OK if I use this second feature, I'm going to be able to subtract the noise from the first feature and get better prediction results.",
            "So you do get better prediction results if you if you.",
            "If you do cross validation and you use these two features.",
            "You do get better prediction results.",
            "But now imagine you change instrument.",
            "Then you have an instrument which is differently calibrated or has a better as less noise or has different kind of noise.",
            "This feature is going to become completely useless.",
            "I think we have to assume the IID assumption in our experiments, right?",
            "So you train a model and select features and it kind of you know distribution.",
            "So why do you have?",
            "Why do you have to make the idea assumption?",
            "Learning algorithm that we are talking here has this assumption implicit.",
            "So I cannot speak right?",
            "So if you want to publish papers in respectable machine learning journals, you have to make the idea assumptions.",
            "If you want to solve problems in the real life, the idea assumption fails most of the time.",
            "So what you'll have to do is that you have to be clever enough to do something that you can use the toolbox of machine learning, even in cases where the data are not IID.",
            "So I think that I can probably has a lot to say about that too.",
            "You'll be able to ask him questions about that because he has organized in your competition in which there was different.",
            "There were different distributions between training data and this data, and this is where machine learning is going.",
            "Now, right?",
            "You have the old times machine learning where the data are IID.",
            "Now the new challenge for Machine learning is going to use non IID data because that's the real life.",
            "That's what's happening in the real life.",
            "Alright, so."
        ],
        [
            "The next, so this is, you know, the actually the real.",
            "The real scatter plot of that data you see it's this is my you know example and you see that it's really the same thing.",
            "This is the real data."
        ],
        [
            "Alright, so now the second plot.",
            "The second plot you know the chess board problem or the other problem?",
            "OK, so you have actually another case in which this happens in real life.",
            "So imagine that it's again something I found you know in in my mass spectrometry work.",
            "So imagine that this variable here is again measuring the height of a peak in the spectrum.",
            "And this is another variable, so I'd say you know it's one of the metavariable this is this is time and I say that I do a scatter plot of all my samples.",
            "According to this peak here and according to time here, and assume I'm seeing something like that.",
            "This happened in real data.",
            "You have, you know, all the examples that are on one side.",
            "Up to a certain time, and then it's inverted.",
            "Well, as it turned out, you know this was organic calibration problem, but this time instead of being, you know the spectral going up and down globally.",
            "Like you know, my nice problem was they were the spectral going a little bit right and left like that.",
            "And instead of measuring the amount of protein at a given position for a given peak after awhile, there has been a problem of calibration of the mass spectrometer.",
            "All the peaks were shifted it a little bit, and so I was measuring another peak.",
            "So in fact these were two different peaks.",
            "So you gonna tell me?",
            "I mean this does not happen, this cannot happen.",
            "This is cheating, right?",
            "How can you?",
            "How can you give such a nasty case to a learning machine?",
            "The problem is that we are educated in machine learning replicating to think well, we need to be able to solve the chess board problem.",
            "But then in real life what happens is that whenever you have a chess board problem, this should raise a red flag for you.",
            "This something probably wrong in your data if you have a chess board problem, it's an experimental artifact, or it can be that you have not deeply enough understood your categories.",
            "You may be having two different diseases that have been lumped into one that happened very frequently.",
            "People for many years I've been.",
            "Categorizing diseases according to symptoms and there are diseases that have the same series of symptoms.",
            "But then when you look at the molecular level, what's happening actually in the body, these are two completely different diseases, but the doctors keep thinking about them as the same disease, so you might be seeing something like that according to a given variable, and you might be realizing all of the sudden.",
            "Well, I'm looking at actually two different things, and then you need to infect split your classes into a.",
            "Two categories, it makes more sense than just applying a nonlinear classification method.",
            "Have 10 more minutes right?",
            "10 more minutes now.",
            "No.",
            "I need to stop at 20.",
            "OK. Coffee.",
            "OK, I'll be brief.",
            "So here's what where causality comes into play.",
            "This these two cases are described by the following causal model.",
            "The white variable is generating the X one, so for example, the disease state of the patient is causing a certain probably a certain protein level in blood.",
            "And.",
            "There is a second variable X2 that is also influencing X1.",
            "So this is your noise.",
            "So there is actually no correlation.",
            "Between your target variable and your noise.",
            "Your noise and the target variable.",
            "Are dependent upon one another only becausw.",
            "You are caring about X1.",
            "OK.",
            "So.",
            "In every.",
            "In every slice.",
            "You know, for a particular value of X1, you see that there is a dependency between.",
            "X2.",
            "And why so?",
            "If you take a slice of data here, right?",
            "And you look at the correlation.",
            "Between X2 and Y you see that Huawei is nicely separated by X2.",
            "For every possible value of X1.",
            "Same thing applies here.",
            "So given values of X1.",
            "Variable X2.",
            "Is predictive?",
            "But if now you look at the overall projection, so if you don't give information about X1.",
            "And you get to know the marginal or the average.",
            "Then there is independence.",
            "Between X2 and Y.",
            "In reality, things are a little bit, you know, more subtle than that.",
            "In reality you know the the true way of seeing things is that there is an unknown systematic source of noise here that is causing both X1 and X2 because you remember that X2 is just a measurement spectrum, so it's an observation of the noise and X one is another observation of the noise an at the same times of Y.",
            "But formally these two things are.",
            "Equivalent if you don't know that thing.",
            "It doesn't really matter.",
            "What matters is that when you see a graph like that, it should raise a red flag and you should be thinking haha.",
            "I'm in a case like that X2 is independent of why it becomes dependent only because of X1.",
            "So maybe maybe X2 is just a symptom of some system."
        ],
        [
            "Matic, noise well I don't have time to do more than that.",
            "And we have, you know, in principle, to open the belly of your of our system that generated the data and try to get a deeper understanding of it and make a distinction between the variables that are two variables of the system and the variables that are experimental artifacts.",
            "Um?",
            "I might, you know, talk to you briefly about that.",
            "More in the exercise class, but now we have to break and I'll be happy to take questions during the break.",
            "Thank you for your attention."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Two now.",
                    "label": 0
                },
                {
                    "sent": "We have not at all talked about whether the features that we're selecting are causes or consequences of our target of interests.",
                    "label": 0
                },
                {
                    "sent": "What difference does it make in the 1st place?",
                    "label": 0
                },
                {
                    "sent": "So for years you know the people working in the feature selection domain have been saying we should not care about causality because take the example that we're trying to diagnose disease.",
                    "label": 0
                },
                {
                    "sent": "Example, we trying to diagnose cancer and there can be features that are causing cancer that are as predictive as features that are consequences of cancer.",
                    "label": 0
                },
                {
                    "sent": "Or you know, let's see.",
                    "label": 0
                },
                {
                    "sent": "Imagine that an example which is familiar to us.",
                    "label": 0
                },
                {
                    "sent": "Let's try to see how we can diagnose AIDS.",
                    "label": 0
                },
                {
                    "sent": "There are features that can be causes of AIDS.",
                    "label": 0
                },
                {
                    "sent": "Like you know some behavior of people and or some country of origin.",
                    "label": 0
                },
                {
                    "sent": "Those are all things that can be identified.",
                    "label": 0
                },
                {
                    "sent": "Risk factors for ads, and using the risk factors you can predict with some confidence whether the person is going to contract the disease or not.",
                    "label": 0
                },
                {
                    "sent": "But with respect to making diagnosis, we are also using consequences.",
                    "label": 0
                },
                {
                    "sent": "The ELISA test is an antibody test that measures some consequences of aid.",
                    "label": 0
                },
                {
                    "sent": "By some immune reaction that we have.",
                    "label": 0
                },
                {
                    "sent": "So with respect to feature selection, the feature selection people usually say we want any feature that has some predictive power, and it could be either A cause or consequence.",
                    "label": 1
                },
                {
                    "sent": "We don't care.",
                    "label": 0
                },
                {
                    "sent": "Let's just predict the target variable.",
                    "label": 0
                },
                {
                    "sent": "However, as we will see in this lecture, there is much to be gained by understanding whether the features are causes or consequences of the target.",
                    "label": 0
                },
                {
                    "sent": "And imagine now the following situation.",
                    "label": 0
                },
                {
                    "sent": "People have lung cancer.",
                    "label": 0
                },
                {
                    "sent": "And there are features that are causing lung cancer.",
                    "label": 0
                },
                {
                    "sent": "For example, smoking may be an identifiable cause of cancer and there are features that are consequences.",
                    "label": 0
                },
                {
                    "sent": "For example, coughing.",
                    "label": 0
                },
                {
                    "sent": "Now those two kinds of features are not equivalent with respect to actions you might want to take on the system if your goal now is not only to make prediction, but to improve the health status of people, then if you make a policy that you shouldn't smoke in public places, this might have a consequence on how many people get lung cancer.",
                    "label": 0
                },
                {
                    "sent": "But if you make a policy that people should take one spoon of anti coughing medicine every morning then this will reduce the amount of coughing.",
                    "label": 0
                },
                {
                    "sent": "But this will have eventually no consequences on contract ING or not Lang cancer.",
                    "label": 0
                },
                {
                    "sent": "So causes and consequences don't have the same power with respect to.",
                    "label": 0
                },
                {
                    "sent": "Making the correct action in order to change the target of interest, and this is particularly important in economy for policymaking, you want to know whether changing the tax rate is going to have a positive impact on the economy.",
                    "label": 0
                },
                {
                    "sent": "For example, it's very important in ecology should you restric the emission of carbon dioxide to reduce the risk of global warming.",
                    "label": 0
                },
                {
                    "sent": "In that case, you know you only care about detecting the causes, so the consequences of global warming, for example, like the melting of the ice on in the North Pole, are not going to change the global warming.",
                    "label": 0
                },
                {
                    "sent": "If you could put a big refrigerator and freezer again the North Pole.",
                    "label": 0
                },
                {
                    "sent": "Is not going to improve the global warming.",
                    "label": 0
                },
                {
                    "sent": "So and there are many, many cases like that.",
                    "label": 0
                },
                {
                    "sent": "You know in medicine for drug discovery, health policymaking, etc.",
                    "label": 0
                },
                {
                    "sent": "So this is one reason we care about causality.",
                    "label": 0
                },
                {
                    "sent": "Another reason we care about causality is because it's going to help us understand the difference between what is true in our measurements and what comes from experimental artifacts.",
                    "label": 0
                },
                {
                    "sent": "We just had a lecture before where I hope I convinced you that if you just trust your data blindly and you don't know how the data was collected, you may make very wrong decisions about which feature is relevant or not, or about you know.",
                    "label": 0
                },
                {
                    "sent": "How predictive feature is going to be causality is going to help you sort out things and figure out you know whether you can believe in this feature or not.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is the setup of variable and feature selection.",
                    "label": 0
                },
                {
                    "sent": "The way people usually think about it.",
                    "label": 0
                },
                {
                    "sent": "He want to remove feature XI.",
                    "label": 0
                },
                {
                    "sent": "If it improves or this degrades predictions of Y.",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What can go wrong?",
                    "label": 0
                },
                {
                    "sent": "You have seen these two scatter plots in one of the lecture I gave before.",
                    "label": 0
                },
                {
                    "sent": "Hopefully you remember them.",
                    "label": 0
                },
                {
                    "sent": "I use them to do what?",
                    "label": 0
                },
                {
                    "sent": "Anybody remembers the scatter plots?",
                    "label": 0
                },
                {
                    "sent": "Importance of features single features.",
                    "label": 0
                },
                {
                    "sent": "Yes, I use them to justify multivariate feature selection.",
                    "label": 0
                },
                {
                    "sent": "I use them to tell you well, if you look, you know in projection on single axis you may be fooling yourself.",
                    "label": 0
                },
                {
                    "sent": "This feature X1 looks like it's separating the two classes fine.",
                    "label": 0
                },
                {
                    "sent": "This feature X2 looks like it's not separating anything.",
                    "label": 0
                },
                {
                    "sent": "You might be discarding it, but in fact it's helping you because it's helping, making you a much better separation in two dimensions that you would get by using feature X1 alone and I told you be careful, don't use univariate feature selection because you may get also cases like that.",
                    "label": 0
                },
                {
                    "sent": "In which none of the features is predicted by itself, but in several dimensions, you get very good separation, and that's the case.",
                    "label": 0
                },
                {
                    "sent": "You know the metal and data set that we are studying in the practical class in the practical session, you know.",
                    "label": 0
                },
                {
                    "sent": "This case, however, happens very rarely, and.",
                    "label": 0
                },
                {
                    "sent": "Mostly that's just your theoretical interest.",
                    "label": 0
                },
                {
                    "sent": "It does happen in practice and we will see when it happens.",
                    "label": 0
                },
                {
                    "sent": "Now I'm going to tell you the opposite of what I said before I told you.",
                    "label": 0
                },
                {
                    "sent": "Well, don't choose always univariate feature selection, because sometimes you need to have multivariate feature selection.",
                    "label": 0
                },
                {
                    "sent": "I'm going to tell you be careful when you use multivariate feature selection and when you have cases like that.",
                    "label": 0
                },
                {
                    "sent": "This should raise a red flag and you should be looking at your data very carefully because this is a non trivial case.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's examine the first case.",
                    "label": 0
                },
                {
                    "sent": "I encountered this case in real data and we had it was a case of mass spectrometry data.",
                    "label": 0
                },
                {
                    "sent": "And we had spectral like that.",
                    "label": 0
                },
                {
                    "sent": "In that case, you have to think that each feature is a position in the spectrum.",
                    "label": 0
                },
                {
                    "sent": "So what you see on the on the X and the Y axis here is the magnitude of the feature and each position here is a different feature, OK?",
                    "label": 0
                },
                {
                    "sent": "Now when you run a feature selection algorithm.",
                    "label": 0
                },
                {
                    "sent": "On that, so each pattern here is a is one of the Spectra, and we have the red Spectra which of examples from one class and the green Spectra examples from the other class.",
                    "label": 0
                },
                {
                    "sent": "So the feature selection algorithm happily tells you that this is a very good feature here at this position, because you see that the red class is very well discriminated from the green class, right?",
                    "label": 0
                },
                {
                    "sent": "And then the feature selection algorithm, which is a forward selection algorithm.",
                    "label": 0
                },
                {
                    "sent": "There is nothing you know special about this.",
                    "label": 0
                },
                {
                    "sent": "I just run the gram Schmidt organization method.",
                    "label": 0
                },
                {
                    "sent": "The most complementary feature to the first feature is this one.",
                    "label": 0
                },
                {
                    "sent": "Now, as you can see by eye, the spectral completely overlap in this region.",
                    "label": 0
                },
                {
                    "sent": "By itself, this feature is not at all discriminative, so we have this case here.",
                    "label": 0
                },
                {
                    "sent": "Feature X One is like this.",
                    "label": 0
                },
                {
                    "sent": "It separates quite well the two classes feature X2 does not.",
                    "label": 0
                },
                {
                    "sent": "Separate the classes at all by itself.",
                    "label": 0
                },
                {
                    "sent": "But when taken together, they gave a nice separation.",
                    "label": 0
                },
                {
                    "sent": "Now the question is, should we trust feature X2?",
                    "label": 0
                },
                {
                    "sent": "What would you do?",
                    "label": 0
                },
                {
                    "sent": "Any comments on that?",
                    "label": 0
                },
                {
                    "sent": "Anybody can think of something it's not so easy when you see that for the first time, but maybe some of you have seen similar things.",
                    "label": 0
                },
                {
                    "sent": "Or maybe it occurs to you what this case, could you know?",
                    "label": 0
                },
                {
                    "sent": "Trusting well by trusting, I mean that this this indicating that particular case.",
                    "label": 0
                },
                {
                    "sent": "You know.",
                    "label": 0
                },
                {
                    "sent": "Every position here corresponds to.",
                    "label": 0
                },
                {
                    "sent": "To some amount of protein in blood, right?",
                    "label": 0
                },
                {
                    "sent": "This picture indicates that this mass value it's a mass spectrum.",
                    "label": 0
                },
                {
                    "sent": "At this mass value there is a protein that discriminates very well between these two populations.",
                    "label": 0
                },
                {
                    "sent": "Now at this mass value here there is an interesting feature that complements that feature.",
                    "label": 0
                },
                {
                    "sent": "Should we consider this as you know when people call in the field of biomarker?",
                    "label": 0
                },
                {
                    "sent": "So an important thing to be measuring right so that we can make the decision about the health status of the patient.",
                    "label": 0
                },
                {
                    "sent": "It is not easy because of course you don't know the domain, but The thing is that what would happen if I change instrument?",
                    "label": 0
                },
                {
                    "sent": "What?",
                    "label": 0
                },
                {
                    "sent": "What is this?",
                    "label": 0
                },
                {
                    "sent": "You know here that we're measuring here Valley, we know that peaks represent protein amounts, but valleys?",
                    "label": 0
                },
                {
                    "sent": "What are the meaning of values here?",
                    "label": 0
                },
                {
                    "sent": "We're measuring, you know, the amount of something in a Valley.",
                    "label": 0
                },
                {
                    "sent": "It's kind of bizarre, right?",
                    "label": 0
                },
                {
                    "sent": "If you think about it, what's happening here is that we are measuring locali.",
                    "label": 0
                },
                {
                    "sent": "The other thing I have to tell you is that this is only a small part of a big spectrum.",
                    "label": 0
                },
                {
                    "sent": "In fact, you know there is this tons of things going here and thumbs up thing I'm zooming in on a small part here, so this is actually measuring locali what the baseline is.",
                    "label": 0
                },
                {
                    "sent": "For this pic here this is, you know, a nice flat part.",
                    "label": 0
                },
                {
                    "sent": "In which you can easily measure that there is an offset up or an upset down of all the Spectra of all the pics simultaneously.",
                    "label": 0
                },
                {
                    "sent": "So for one spectrum, if this is high here, this is a little bit high here also by a certain offset.",
                    "label": 0
                },
                {
                    "sent": "So what this does here is that helps you subtracting the baseline.",
                    "label": 0
                },
                {
                    "sent": "From that pic here.",
                    "label": 0
                },
                {
                    "sent": "I think you think you know.",
                    "label": 0
                },
                {
                    "sent": "Realize what I'm talking about, right?",
                    "label": 0
                },
                {
                    "sent": "So this is what I would call an experimental artifact.",
                    "label": 0
                },
                {
                    "sent": "Because we have not done the preprocessing correctly, we have not subtracted well enough the baseline here.",
                    "label": 0
                },
                {
                    "sent": "There is some residual noise.",
                    "label": 0
                },
                {
                    "sent": "Systematic noise right?",
                    "label": 0
                },
                {
                    "sent": "This is noise that we could have gotten rid of by good preprocessing.",
                    "label": 0
                },
                {
                    "sent": "The residual systematic noise is taken care of by the feature selection stage.",
                    "label": 0
                },
                {
                    "sent": "Feature selection stage is smart enough to say OK if I use this second feature, I'm going to be able to subtract the noise from the first feature and get better prediction results.",
                    "label": 0
                },
                {
                    "sent": "So you do get better prediction results if you if you.",
                    "label": 0
                },
                {
                    "sent": "If you do cross validation and you use these two features.",
                    "label": 0
                },
                {
                    "sent": "You do get better prediction results.",
                    "label": 0
                },
                {
                    "sent": "But now imagine you change instrument.",
                    "label": 0
                },
                {
                    "sent": "Then you have an instrument which is differently calibrated or has a better as less noise or has different kind of noise.",
                    "label": 0
                },
                {
                    "sent": "This feature is going to become completely useless.",
                    "label": 0
                },
                {
                    "sent": "I think we have to assume the IID assumption in our experiments, right?",
                    "label": 0
                },
                {
                    "sent": "So you train a model and select features and it kind of you know distribution.",
                    "label": 0
                },
                {
                    "sent": "So why do you have?",
                    "label": 0
                },
                {
                    "sent": "Why do you have to make the idea assumption?",
                    "label": 0
                },
                {
                    "sent": "Learning algorithm that we are talking here has this assumption implicit.",
                    "label": 0
                },
                {
                    "sent": "So I cannot speak right?",
                    "label": 0
                },
                {
                    "sent": "So if you want to publish papers in respectable machine learning journals, you have to make the idea assumptions.",
                    "label": 0
                },
                {
                    "sent": "If you want to solve problems in the real life, the idea assumption fails most of the time.",
                    "label": 0
                },
                {
                    "sent": "So what you'll have to do is that you have to be clever enough to do something that you can use the toolbox of machine learning, even in cases where the data are not IID.",
                    "label": 0
                },
                {
                    "sent": "So I think that I can probably has a lot to say about that too.",
                    "label": 0
                },
                {
                    "sent": "You'll be able to ask him questions about that because he has organized in your competition in which there was different.",
                    "label": 0
                },
                {
                    "sent": "There were different distributions between training data and this data, and this is where machine learning is going.",
                    "label": 0
                },
                {
                    "sent": "Now, right?",
                    "label": 0
                },
                {
                    "sent": "You have the old times machine learning where the data are IID.",
                    "label": 0
                },
                {
                    "sent": "Now the new challenge for Machine learning is going to use non IID data because that's the real life.",
                    "label": 0
                },
                {
                    "sent": "That's what's happening in the real life.",
                    "label": 0
                },
                {
                    "sent": "Alright, so.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The next, so this is, you know, the actually the real.",
                    "label": 0
                },
                {
                    "sent": "The real scatter plot of that data you see it's this is my you know example and you see that it's really the same thing.",
                    "label": 0
                },
                {
                    "sent": "This is the real data.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so now the second plot.",
                    "label": 0
                },
                {
                    "sent": "The second plot you know the chess board problem or the other problem?",
                    "label": 0
                },
                {
                    "sent": "OK, so you have actually another case in which this happens in real life.",
                    "label": 0
                },
                {
                    "sent": "So imagine that it's again something I found you know in in my mass spectrometry work.",
                    "label": 0
                },
                {
                    "sent": "So imagine that this variable here is again measuring the height of a peak in the spectrum.",
                    "label": 0
                },
                {
                    "sent": "And this is another variable, so I'd say you know it's one of the metavariable this is this is time and I say that I do a scatter plot of all my samples.",
                    "label": 0
                },
                {
                    "sent": "According to this peak here and according to time here, and assume I'm seeing something like that.",
                    "label": 0
                },
                {
                    "sent": "This happened in real data.",
                    "label": 0
                },
                {
                    "sent": "You have, you know, all the examples that are on one side.",
                    "label": 0
                },
                {
                    "sent": "Up to a certain time, and then it's inverted.",
                    "label": 0
                },
                {
                    "sent": "Well, as it turned out, you know this was organic calibration problem, but this time instead of being, you know the spectral going up and down globally.",
                    "label": 0
                },
                {
                    "sent": "Like you know, my nice problem was they were the spectral going a little bit right and left like that.",
                    "label": 0
                },
                {
                    "sent": "And instead of measuring the amount of protein at a given position for a given peak after awhile, there has been a problem of calibration of the mass spectrometer.",
                    "label": 0
                },
                {
                    "sent": "All the peaks were shifted it a little bit, and so I was measuring another peak.",
                    "label": 0
                },
                {
                    "sent": "So in fact these were two different peaks.",
                    "label": 0
                },
                {
                    "sent": "So you gonna tell me?",
                    "label": 0
                },
                {
                    "sent": "I mean this does not happen, this cannot happen.",
                    "label": 0
                },
                {
                    "sent": "This is cheating, right?",
                    "label": 0
                },
                {
                    "sent": "How can you?",
                    "label": 0
                },
                {
                    "sent": "How can you give such a nasty case to a learning machine?",
                    "label": 0
                },
                {
                    "sent": "The problem is that we are educated in machine learning replicating to think well, we need to be able to solve the chess board problem.",
                    "label": 0
                },
                {
                    "sent": "But then in real life what happens is that whenever you have a chess board problem, this should raise a red flag for you.",
                    "label": 0
                },
                {
                    "sent": "This something probably wrong in your data if you have a chess board problem, it's an experimental artifact, or it can be that you have not deeply enough understood your categories.",
                    "label": 0
                },
                {
                    "sent": "You may be having two different diseases that have been lumped into one that happened very frequently.",
                    "label": 0
                },
                {
                    "sent": "People for many years I've been.",
                    "label": 0
                },
                {
                    "sent": "Categorizing diseases according to symptoms and there are diseases that have the same series of symptoms.",
                    "label": 0
                },
                {
                    "sent": "But then when you look at the molecular level, what's happening actually in the body, these are two completely different diseases, but the doctors keep thinking about them as the same disease, so you might be seeing something like that according to a given variable, and you might be realizing all of the sudden.",
                    "label": 0
                },
                {
                    "sent": "Well, I'm looking at actually two different things, and then you need to infect split your classes into a.",
                    "label": 0
                },
                {
                    "sent": "Two categories, it makes more sense than just applying a nonlinear classification method.",
                    "label": 0
                },
                {
                    "sent": "Have 10 more minutes right?",
                    "label": 0
                },
                {
                    "sent": "10 more minutes now.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "I need to stop at 20.",
                    "label": 0
                },
                {
                    "sent": "OK. Coffee.",
                    "label": 0
                },
                {
                    "sent": "OK, I'll be brief.",
                    "label": 0
                },
                {
                    "sent": "So here's what where causality comes into play.",
                    "label": 0
                },
                {
                    "sent": "This these two cases are described by the following causal model.",
                    "label": 0
                },
                {
                    "sent": "The white variable is generating the X one, so for example, the disease state of the patient is causing a certain probably a certain protein level in blood.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "There is a second variable X2 that is also influencing X1.",
                    "label": 0
                },
                {
                    "sent": "So this is your noise.",
                    "label": 0
                },
                {
                    "sent": "So there is actually no correlation.",
                    "label": 0
                },
                {
                    "sent": "Between your target variable and your noise.",
                    "label": 0
                },
                {
                    "sent": "Your noise and the target variable.",
                    "label": 0
                },
                {
                    "sent": "Are dependent upon one another only becausw.",
                    "label": 0
                },
                {
                    "sent": "You are caring about X1.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "In every.",
                    "label": 0
                },
                {
                    "sent": "In every slice.",
                    "label": 0
                },
                {
                    "sent": "You know, for a particular value of X1, you see that there is a dependency between.",
                    "label": 0
                },
                {
                    "sent": "X2.",
                    "label": 0
                },
                {
                    "sent": "And why so?",
                    "label": 0
                },
                {
                    "sent": "If you take a slice of data here, right?",
                    "label": 0
                },
                {
                    "sent": "And you look at the correlation.",
                    "label": 0
                },
                {
                    "sent": "Between X2 and Y you see that Huawei is nicely separated by X2.",
                    "label": 0
                },
                {
                    "sent": "For every possible value of X1.",
                    "label": 0
                },
                {
                    "sent": "Same thing applies here.",
                    "label": 0
                },
                {
                    "sent": "So given values of X1.",
                    "label": 0
                },
                {
                    "sent": "Variable X2.",
                    "label": 0
                },
                {
                    "sent": "Is predictive?",
                    "label": 0
                },
                {
                    "sent": "But if now you look at the overall projection, so if you don't give information about X1.",
                    "label": 0
                },
                {
                    "sent": "And you get to know the marginal or the average.",
                    "label": 0
                },
                {
                    "sent": "Then there is independence.",
                    "label": 0
                },
                {
                    "sent": "Between X2 and Y.",
                    "label": 0
                },
                {
                    "sent": "In reality, things are a little bit, you know, more subtle than that.",
                    "label": 0
                },
                {
                    "sent": "In reality you know the the true way of seeing things is that there is an unknown systematic source of noise here that is causing both X1 and X2 because you remember that X2 is just a measurement spectrum, so it's an observation of the noise and X one is another observation of the noise an at the same times of Y.",
                    "label": 0
                },
                {
                    "sent": "But formally these two things are.",
                    "label": 0
                },
                {
                    "sent": "Equivalent if you don't know that thing.",
                    "label": 0
                },
                {
                    "sent": "It doesn't really matter.",
                    "label": 0
                },
                {
                    "sent": "What matters is that when you see a graph like that, it should raise a red flag and you should be thinking haha.",
                    "label": 0
                },
                {
                    "sent": "I'm in a case like that X2 is independent of why it becomes dependent only because of X1.",
                    "label": 0
                },
                {
                    "sent": "So maybe maybe X2 is just a symptom of some system.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Matic, noise well I don't have time to do more than that.",
                    "label": 0
                },
                {
                    "sent": "And we have, you know, in principle, to open the belly of your of our system that generated the data and try to get a deeper understanding of it and make a distinction between the variables that are two variables of the system and the variables that are experimental artifacts.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "I might, you know, talk to you briefly about that.",
                    "label": 0
                },
                {
                    "sent": "More in the exercise class, but now we have to break and I'll be happy to take questions during the break.",
                    "label": 0
                },
                {
                    "sent": "Thank you for your attention.",
                    "label": 0
                }
            ]
        }
    }
}