{
    "id": "fbkttngf3aqc52fqiunk4uiipn47dwao",
    "title": "Separating Precision and Mean in Dirichlet-enhanced High-order Markov Models",
    "info": {
        "author": [
            "Rikiya Takahashi, IBM Research"
        ],
        "published": "Jan. 29, 2008",
        "recorded": "September 2007",
        "category": [
            "Top->Computer Science->Machine Learning->Markov Processes"
        ]
    },
    "url": "http://videolectures.net/ecml07_takahashi_spm/",
    "segmentation": [
        [
            "Taking the natural language example is easier to understand the algorithm.",
            "So today I will explain the algorithm by taking the example of, not."
        ],
        [
            "Fungus.",
            "I saw that the content of the presentation consists of at first beginning I begin the white robustly estimating the states transition probability of Markov process is important.",
            "On the second, I briefly introduced prior work and interpret them as a hierarchical Bayesian approaches, 'cause it's easier to understand the applying the hierarchical Bayesian approaches to understand the robust the existing smoothing method or so.",
            "Secondly, we propose a new idea to separate 1st and being in the complier.",
            "I show you the experiment."
        ],
        [
            "Is that also?",
            "So please look at the figure of the left side.",
            "This figure shows the Markov process to generate a natural language sequence.",
            "And please look at the formulation with the right side.",
            "This corresponds to frequency of state transition.",
            "For example, the frequency of area given is an extent we can.",
            "Correct many data from us, some natural language corpus is and we want to precisely estimate the stage function probability of given some given some context words.",
            "For example, a probability of area given its N."
        ],
        [
            "In some situations tip type carry that if the data is extremely sparse, the frequency of state pension frequency is not so large.",
            "For example, in this situation, the state transition frequency of end given is only one and the state transition frequencies are given on is 0.",
            "If we take simply the ratio of these statements of weekends, it's the estimated state transition probabilities is not robust.",
            "For example here just statements of probability of arm given among is 0, but the true probability of it is not zero.",
            "It cannot be used for pro."
        ],
        [
            "Action.",
            "So instead we sometimes discount the existing positive frequency and assigning the some positive weight to the zero frequency state.",
            "After after doing this kind of discounting, we can acquire a smooth state function probabilities.",
            "So our main interest is to search for the best method to smooth step function probabilities from the limited amount of training data."
        ],
        [
            "So the next."
        ],
        [
            "I should apply at work.",
            "Generally when we discount the existing state transition frequency and assigning the positive way to the Dell frequency state, we interpolate with a lower order distribution.",
            "What I mean, lower distribution is just show you that example.",
            "Look at the upper right side formulation.",
            "When we estimate probability of area given on we, we can use the state transition frequency and the lower distribution probability area given only N. The lower distribution is less specific than the state function probability of what we want to estimate.",
            "And I also let you know that there is a two major smoothing quite area what, which is additive smoothing and subtracted smoothing.",
            "The item smoothing adds some should accounts to the denominator.",
            "When we calculate the state transition probability while subtracting smoothing family subtracts the existing positive frequency.",
            "For example, here, the in the items amazing for me the adding should count plus one is a discounting factor and in subtracting smoothing family minus .6 is the discounting."
        ],
        [
            "Doctor.",
            "And these discounting methods can be interpreted as hierarchical version approaches.",
            "This state transition probabilities are just polymeters of multinomial model.",
            "Choosing the smoothing methods correspond to choosing a prior distribution.",
            "In additive smoothing family it's known that supplier is directional distribution.",
            "In contrast, in subtractive smoothing, formerly the prior is personal racial distribution.",
            "And.",
            "So the the at first the state function probability is permitted.",
            "And the discounting factor on the lower order distribution corresponds to the hyperparameter.",
            "Finally, the smooth state transition probability corresponds to expectation over posterior.",
            "When we take this hierarchical Bayesian perspective.",
            "Interest is how to determine the discounting factors.",
            "But to compute the discounting factors corresponds to estimating hyperparameters by some empirical based method."
        ],
        [
            "So we currently understand the.",
            "Estimating the discount.",
            "You folks that corresponds to estimating hyperparameters, so our next research interest is the is the state of the art method, which is a state of the art method additive smoothing or subtractive smoothing in a course in case of fire work, the state of the art smoothing belonged to subtracting smoothing family.",
            "I don't because of the time constraint.",
            "I don't you introduce the deeply about the content of subtracting smoothing, but I simply let you know that the subtracting smoothing family it's using force and Richard Pryor distribution is mathematically analytically intractable, so we need some approximation algorithm while using additive smoothing family.",
            "It's corresponds to direction applier.",
            "It's mathematically tractable, but adapting Richard Pryor.",
            "Using adaptive smoothing does not show the competitive performance.",
            "Here I introduce another good practical method to estimate the state transition probabilities.",
            "It's called frequency modifications based on indicator."
        ],
        [
            "So it can be applied both methods, so I show you the what is the frequency modification.",
            "Look at the figure of the left and right of the formulations are right up.",
            "In this figure, the formulation of the write up simply shows that when what how we calculate the state transition frequency for lower order distribution, it's just summing up the statements of we can see.",
            "In contrast.",
            "Look at the right under formulation formulation located on the right, and this is kind of frequency modification where any existing positive frequency is reduced into one while their frequency stays up still 0.",
            "By this kind of frequency modification, we can drive another kind of step transfer frequency for less specific lower order distribution.",
            "And it is known that this another kind of frequency modification used to follow a distribution can hear better predictive performance."
        ],
        [
            "So I."
        ],
        [
            "Proposition.",
            "It is known that the indicator function approximation is known to have here the better performance, but here we extend the indicator function so that the simple question at first is the is the indicator function approximations always optimal?",
            "And our answer is, we find that it's optimal when number of the states is rush.",
            "So here we focus on the case.",
            "The one number of states is small and we extend this time there supplier.",
            "Ideally, extending POS and Richard Pryor.",
            "It's can hear more better performance, but since the extended person there supplier is analytically intractable, this time we decided to extend their supplier instead.",
            "We intended to replacing just the indicator function into more precise formulation."
        ],
        [
            "So.",
            "But the existing Richard Pryor method is known to not competitive, so we need to extend the duration.",
            "Apoya a bit more.",
            "This is mainly the shows why the existing delusional pile was not competitive.",
            "Apparently, for example, think about.",
            "Think about that when we think about the situation.",
            "When we predict the next state after an or R, which is a article.",
            "Upper entry is what the kind of the kind of was.",
            "Follows the word arm is limited.",
            "In contrast, the kind of word forwards are is not limited.",
            "So even if the situation of some, there are some of their frequency time which is not observed here, for example forearm, it's for its zoo.",
            "In this situation, the existing distro PIA imposes the the same constraint discounting factors.",
            "The existing distro, Playa, or weights use this constant discounting factors, but.",
            "When we imagine the situation of the right side figure article are the discounting factors are flexible too and.",
            "Discretion in the right side, the discounting factor should be higher.",
            "Because many kinds of words can be appear after the word are.",
            "So the discounting factor must depend on context.",
            "Here the context what is on or are where the standard SharePoint imposes single discounting factor."
        ],
        [
            "So we show you that this is our approach, separating person and mean in their supplier.",
            "We intend to distinguish the roles of discounting factor under lower distribution.",
            "The discounting factor corresponds to is known to correspond to direct repression, which is some of the parameters in dresser distribution.",
            "In contrast, the lower distribution corresponds to directional mean, which is just a normalizing marginal vector."
        ],
        [
            "So mathematically, we can introduce of these pliers, but I don't explain deeply just showing the difference of difference between my approach and existing approach.",
            "In my approach.",
            "The decision process on Alpha is context dependent, while the prior or existing approaches context."
        ],
        [
            "Dependant.",
            "And we also need to estimate the parameters of this oppression on the dresser mean.",
            "If it takes, the bar is not influenced approach and the buyers name first estimated RMB gives a interesting mapping function from low frequency the effective frequency.",
            "The upper formulation corresponds the mapping function, and this formulation corresponds to.",
            "This is a mapping function from low frequency to effective frequency and this one has.",
            "This function has one control parameter.",
            "Here we call this parameter beta and we.",
            "Or sorry OK. Alpha Theta equals I. Alpha Sitter is better and when better is small it's it reaches the indicator function.",
            "Typically when better reaches 0 it's just an indicator function, while when better is watch it corresponds to the linear function just low free."
        ],
        [
            "Nancy also that our new dealership, right yeah, will outperform when number of states is small.",
            "Becausw the mapping function of the counterpart of the mapping function corresponds to multiplication with their suppression and dresser mean, and when the number of states rights, the elements of derision mean is low, while the number of states is small elements of the addition means not low.",
            "So in such situation the indicator function approximation.",
            "Is sufficient when number of states is large, while the indicator function approximation is not sufficient when."
        ],
        [
            "State small."
        ],
        [
            "So I share the experimental result.",
            "And the main purpose of this experiment compares us several smoothing method when number with state is Raj and the Vin number will stated small.",
            "As an example, when number of stages rush, we take the natural language example which are potentially infinite vocabulary as a number of states.",
            "Small example, we take protein sequences.",
            "The potency consists only constable 2020 kinds of amino acids.",
            "And we using cross validation."
        ],
        [
            "For the cross validation, we calculated that test set perplexity of several smoothing methods.",
            "The test set perplexity is just the exponential negative likelihood, so I simply show you that the lower test set perplexity is shows the better predictive performance.",
            "Look at the left side figure.",
            "The MKS is state of the art method and in language natural language modeling my model slightly worse than the state of the art method."
        ],
        [
            "But important sequence model in my approach outperforms slightly outperformed the state with other method that led trying the lowest, which is lowest.",
            "Fourplex T outperforms the state of the art method and some of your wonder.",
            "Is this the result?",
            "Depend on the kind of the training data and test data?",
            "And I also tested the cross validation and for each fault the rank between several smoothing methods was stable.",
            "I mean the my approach was the best and the MKS was the second best, and so on."
        ],
        [
            "So, and I also tested several kinds of training data corresponding to Organism type."
        ],
        [
            "So the conclusion we formulate, the new desert Playa.",
            "Further suppression is context dependent.",
            "In order to robustly estimate state to some probabilities in higher order Markov process models and the proposed method slightly outperforms the state of the art method when number of state is small.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Taking the natural language example is easier to understand the algorithm.",
                    "label": 0
                },
                {
                    "sent": "So today I will explain the algorithm by taking the example of, not.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Fungus.",
                    "label": 0
                },
                {
                    "sent": "I saw that the content of the presentation consists of at first beginning I begin the white robustly estimating the states transition probability of Markov process is important.",
                    "label": 0
                },
                {
                    "sent": "On the second, I briefly introduced prior work and interpret them as a hierarchical Bayesian approaches, 'cause it's easier to understand the applying the hierarchical Bayesian approaches to understand the robust the existing smoothing method or so.",
                    "label": 1
                },
                {
                    "sent": "Secondly, we propose a new idea to separate 1st and being in the complier.",
                    "label": 0
                },
                {
                    "sent": "I show you the experiment.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is that also?",
                    "label": 0
                },
                {
                    "sent": "So please look at the figure of the left side.",
                    "label": 0
                },
                {
                    "sent": "This figure shows the Markov process to generate a natural language sequence.",
                    "label": 1
                },
                {
                    "sent": "And please look at the formulation with the right side.",
                    "label": 0
                },
                {
                    "sent": "This corresponds to frequency of state transition.",
                    "label": 1
                },
                {
                    "sent": "For example, the frequency of area given is an extent we can.",
                    "label": 0
                },
                {
                    "sent": "Correct many data from us, some natural language corpus is and we want to precisely estimate the stage function probability of given some given some context words.",
                    "label": 0
                },
                {
                    "sent": "For example, a probability of area given its N.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In some situations tip type carry that if the data is extremely sparse, the frequency of state pension frequency is not so large.",
                    "label": 0
                },
                {
                    "sent": "For example, in this situation, the state transition frequency of end given is only one and the state transition frequencies are given on is 0.",
                    "label": 0
                },
                {
                    "sent": "If we take simply the ratio of these statements of weekends, it's the estimated state transition probabilities is not robust.",
                    "label": 0
                },
                {
                    "sent": "For example here just statements of probability of arm given among is 0, but the true probability of it is not zero.",
                    "label": 0
                },
                {
                    "sent": "It cannot be used for pro.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Action.",
                    "label": 0
                },
                {
                    "sent": "So instead we sometimes discount the existing positive frequency and assigning the some positive weight to the zero frequency state.",
                    "label": 0
                },
                {
                    "sent": "After after doing this kind of discounting, we can acquire a smooth state function probabilities.",
                    "label": 0
                },
                {
                    "sent": "So our main interest is to search for the best method to smooth step function probabilities from the limited amount of training data.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the next.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I should apply at work.",
                    "label": 0
                },
                {
                    "sent": "Generally when we discount the existing state transition frequency and assigning the positive way to the Dell frequency state, we interpolate with a lower order distribution.",
                    "label": 0
                },
                {
                    "sent": "What I mean, lower distribution is just show you that example.",
                    "label": 0
                },
                {
                    "sent": "Look at the upper right side formulation.",
                    "label": 0
                },
                {
                    "sent": "When we estimate probability of area given on we, we can use the state transition frequency and the lower distribution probability area given only N. The lower distribution is less specific than the state function probability of what we want to estimate.",
                    "label": 0
                },
                {
                    "sent": "And I also let you know that there is a two major smoothing quite area what, which is additive smoothing and subtracted smoothing.",
                    "label": 1
                },
                {
                    "sent": "The item smoothing adds some should accounts to the denominator.",
                    "label": 1
                },
                {
                    "sent": "When we calculate the state transition probability while subtracting smoothing family subtracts the existing positive frequency.",
                    "label": 0
                },
                {
                    "sent": "For example, here, the in the items amazing for me the adding should count plus one is a discounting factor and in subtracting smoothing family minus .6 is the discounting.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Doctor.",
                    "label": 0
                },
                {
                    "sent": "And these discounting methods can be interpreted as hierarchical version approaches.",
                    "label": 0
                },
                {
                    "sent": "This state transition probabilities are just polymeters of multinomial model.",
                    "label": 0
                },
                {
                    "sent": "Choosing the smoothing methods correspond to choosing a prior distribution.",
                    "label": 1
                },
                {
                    "sent": "In additive smoothing family it's known that supplier is directional distribution.",
                    "label": 0
                },
                {
                    "sent": "In contrast, in subtractive smoothing, formerly the prior is personal racial distribution.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "So the the at first the state function probability is permitted.",
                    "label": 1
                },
                {
                    "sent": "And the discounting factor on the lower order distribution corresponds to the hyperparameter.",
                    "label": 0
                },
                {
                    "sent": "Finally, the smooth state transition probability corresponds to expectation over posterior.",
                    "label": 0
                },
                {
                    "sent": "When we take this hierarchical Bayesian perspective.",
                    "label": 0
                },
                {
                    "sent": "Interest is how to determine the discounting factors.",
                    "label": 1
                },
                {
                    "sent": "But to compute the discounting factors corresponds to estimating hyperparameters by some empirical based method.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we currently understand the.",
                    "label": 0
                },
                {
                    "sent": "Estimating the discount.",
                    "label": 0
                },
                {
                    "sent": "You folks that corresponds to estimating hyperparameters, so our next research interest is the is the state of the art method, which is a state of the art method additive smoothing or subtractive smoothing in a course in case of fire work, the state of the art smoothing belonged to subtracting smoothing family.",
                    "label": 1
                },
                {
                    "sent": "I don't because of the time constraint.",
                    "label": 0
                },
                {
                    "sent": "I don't you introduce the deeply about the content of subtracting smoothing, but I simply let you know that the subtracting smoothing family it's using force and Richard Pryor distribution is mathematically analytically intractable, so we need some approximation algorithm while using additive smoothing family.",
                    "label": 1
                },
                {
                    "sent": "It's corresponds to direction applier.",
                    "label": 1
                },
                {
                    "sent": "It's mathematically tractable, but adapting Richard Pryor.",
                    "label": 0
                },
                {
                    "sent": "Using adaptive smoothing does not show the competitive performance.",
                    "label": 1
                },
                {
                    "sent": "Here I introduce another good practical method to estimate the state transition probabilities.",
                    "label": 0
                },
                {
                    "sent": "It's called frequency modifications based on indicator.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So it can be applied both methods, so I show you the what is the frequency modification.",
                    "label": 0
                },
                {
                    "sent": "Look at the figure of the left and right of the formulations are right up.",
                    "label": 0
                },
                {
                    "sent": "In this figure, the formulation of the write up simply shows that when what how we calculate the state transition frequency for lower order distribution, it's just summing up the statements of we can see.",
                    "label": 0
                },
                {
                    "sent": "In contrast.",
                    "label": 0
                },
                {
                    "sent": "Look at the right under formulation formulation located on the right, and this is kind of frequency modification where any existing positive frequency is reduced into one while their frequency stays up still 0.",
                    "label": 0
                },
                {
                    "sent": "By this kind of frequency modification, we can drive another kind of step transfer frequency for less specific lower order distribution.",
                    "label": 0
                },
                {
                    "sent": "And it is known that this another kind of frequency modification used to follow a distribution can hear better predictive performance.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Proposition.",
                    "label": 0
                },
                {
                    "sent": "It is known that the indicator function approximation is known to have here the better performance, but here we extend the indicator function so that the simple question at first is the is the indicator function approximations always optimal?",
                    "label": 1
                },
                {
                    "sent": "And our answer is, we find that it's optimal when number of the states is rush.",
                    "label": 1
                },
                {
                    "sent": "So here we focus on the case.",
                    "label": 0
                },
                {
                    "sent": "The one number of states is small and we extend this time there supplier.",
                    "label": 1
                },
                {
                    "sent": "Ideally, extending POS and Richard Pryor.",
                    "label": 0
                },
                {
                    "sent": "It's can hear more better performance, but since the extended person there supplier is analytically intractable, this time we decided to extend their supplier instead.",
                    "label": 0
                },
                {
                    "sent": "We intended to replacing just the indicator function into more precise formulation.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "But the existing Richard Pryor method is known to not competitive, so we need to extend the duration.",
                    "label": 0
                },
                {
                    "sent": "Apoya a bit more.",
                    "label": 0
                },
                {
                    "sent": "This is mainly the shows why the existing delusional pile was not competitive.",
                    "label": 0
                },
                {
                    "sent": "Apparently, for example, think about.",
                    "label": 0
                },
                {
                    "sent": "Think about that when we think about the situation.",
                    "label": 0
                },
                {
                    "sent": "When we predict the next state after an or R, which is a article.",
                    "label": 0
                },
                {
                    "sent": "Upper entry is what the kind of the kind of was.",
                    "label": 0
                },
                {
                    "sent": "Follows the word arm is limited.",
                    "label": 0
                },
                {
                    "sent": "In contrast, the kind of word forwards are is not limited.",
                    "label": 0
                },
                {
                    "sent": "So even if the situation of some, there are some of their frequency time which is not observed here, for example forearm, it's for its zoo.",
                    "label": 0
                },
                {
                    "sent": "In this situation, the existing distro PIA imposes the the same constraint discounting factors.",
                    "label": 0
                },
                {
                    "sent": "The existing distro, Playa, or weights use this constant discounting factors, but.",
                    "label": 0
                },
                {
                    "sent": "When we imagine the situation of the right side figure article are the discounting factors are flexible too and.",
                    "label": 0
                },
                {
                    "sent": "Discretion in the right side, the discounting factor should be higher.",
                    "label": 1
                },
                {
                    "sent": "Because many kinds of words can be appear after the word are.",
                    "label": 0
                },
                {
                    "sent": "So the discounting factor must depend on context.",
                    "label": 1
                },
                {
                    "sent": "Here the context what is on or are where the standard SharePoint imposes single discounting factor.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we show you that this is our approach, separating person and mean in their supplier.",
                    "label": 1
                },
                {
                    "sent": "We intend to distinguish the roles of discounting factor under lower distribution.",
                    "label": 1
                },
                {
                    "sent": "The discounting factor corresponds to is known to correspond to direct repression, which is some of the parameters in dresser distribution.",
                    "label": 0
                },
                {
                    "sent": "In contrast, the lower distribution corresponds to directional mean, which is just a normalizing marginal vector.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So mathematically, we can introduce of these pliers, but I don't explain deeply just showing the difference of difference between my approach and existing approach.",
                    "label": 0
                },
                {
                    "sent": "In my approach.",
                    "label": 0
                },
                {
                    "sent": "The decision process on Alpha is context dependent, while the prior or existing approaches context.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Dependant.",
                    "label": 0
                },
                {
                    "sent": "And we also need to estimate the parameters of this oppression on the dresser mean.",
                    "label": 1
                },
                {
                    "sent": "If it takes, the bar is not influenced approach and the buyers name first estimated RMB gives a interesting mapping function from low frequency the effective frequency.",
                    "label": 1
                },
                {
                    "sent": "The upper formulation corresponds the mapping function, and this formulation corresponds to.",
                    "label": 0
                },
                {
                    "sent": "This is a mapping function from low frequency to effective frequency and this one has.",
                    "label": 1
                },
                {
                    "sent": "This function has one control parameter.",
                    "label": 0
                },
                {
                    "sent": "Here we call this parameter beta and we.",
                    "label": 1
                },
                {
                    "sent": "Or sorry OK. Alpha Theta equals I. Alpha Sitter is better and when better is small it's it reaches the indicator function.",
                    "label": 0
                },
                {
                    "sent": "Typically when better reaches 0 it's just an indicator function, while when better is watch it corresponds to the linear function just low free.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Nancy also that our new dealership, right yeah, will outperform when number of states is small.",
                    "label": 1
                },
                {
                    "sent": "Becausw the mapping function of the counterpart of the mapping function corresponds to multiplication with their suppression and dresser mean, and when the number of states rights, the elements of derision mean is low, while the number of states is small elements of the addition means not low.",
                    "label": 1
                },
                {
                    "sent": "So in such situation the indicator function approximation.",
                    "label": 0
                },
                {
                    "sent": "Is sufficient when number of states is large, while the indicator function approximation is not sufficient when.",
                    "label": 1
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "State small.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I share the experimental result.",
                    "label": 1
                },
                {
                    "sent": "And the main purpose of this experiment compares us several smoothing method when number with state is Raj and the Vin number will stated small.",
                    "label": 1
                },
                {
                    "sent": "As an example, when number of stages rush, we take the natural language example which are potentially infinite vocabulary as a number of states.",
                    "label": 1
                },
                {
                    "sent": "Small example, we take protein sequences.",
                    "label": 0
                },
                {
                    "sent": "The potency consists only constable 2020 kinds of amino acids.",
                    "label": 1
                },
                {
                    "sent": "And we using cross validation.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For the cross validation, we calculated that test set perplexity of several smoothing methods.",
                    "label": 0
                },
                {
                    "sent": "The test set perplexity is just the exponential negative likelihood, so I simply show you that the lower test set perplexity is shows the better predictive performance.",
                    "label": 0
                },
                {
                    "sent": "Look at the left side figure.",
                    "label": 0
                },
                {
                    "sent": "The MKS is state of the art method and in language natural language modeling my model slightly worse than the state of the art method.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But important sequence model in my approach outperforms slightly outperformed the state with other method that led trying the lowest, which is lowest.",
                    "label": 0
                },
                {
                    "sent": "Fourplex T outperforms the state of the art method and some of your wonder.",
                    "label": 0
                },
                {
                    "sent": "Is this the result?",
                    "label": 0
                },
                {
                    "sent": "Depend on the kind of the training data and test data?",
                    "label": 0
                },
                {
                    "sent": "And I also tested the cross validation and for each fault the rank between several smoothing methods was stable.",
                    "label": 0
                },
                {
                    "sent": "I mean the my approach was the best and the MKS was the second best, and so on.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So, and I also tested several kinds of training data corresponding to Organism type.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the conclusion we formulate, the new desert Playa.",
                    "label": 0
                },
                {
                    "sent": "Further suppression is context dependent.",
                    "label": 0
                },
                {
                    "sent": "In order to robustly estimate state to some probabilities in higher order Markov process models and the proposed method slightly outperforms the state of the art method when number of state is small.",
                    "label": 1
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}