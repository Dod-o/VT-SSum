{
    "id": "epmv75ee5h2xpewglfloct2nvt3m6qq3",
    "title": "The Light Field Camera: Extended Depth of Field, Aliasing and Superresolution",
    "info": {
        "author": [
            "Paolo Favaro, School of Engineering and Physical Sciences, Heriot-Watt University"
        ],
        "published": "Jan. 23, 2012",
        "recorded": "December 2011",
        "category": [
            "Top->Computer Science->Computer Vision->Computational Photography"
        ]
    },
    "url": "http://videolectures.net/nipsworkshops2011_favaro_superresolution/",
    "segmentation": [
        [
            "Thank you very much for being here.",
            "I'll talk about Lightfield camera.",
            "In particular, we refer to the prototype built by Berkeley Boy and range of which we also built a replica and in particular will look at how this device can allows you to extend active field and how we need to deal with aliasing and some other aspects.",
            "So super resolution.",
            "And this is joint work with Tom Bishop."
        ],
        [
            "So the way I like to see it is start to observe that conventional cameras are kind of based on a similar design to the human eye.",
            "Basically, there's alliance.",
            "He can change the lens and bring a different positions in place in the space in focus.",
            "And also there is a rattling under works similar to a sensor.",
            "However, what you can ask?"
        ],
        [
            "Is is this kind of design optimal for all vision tasks?",
            "And clearly if you look in nature."
        ],
        [
            "There are many other device designs that allow other animals to survive, so clearly they achieve the purpose there made for and also they are quite different from the human eye.",
            "For example, if you take the the eye of a fly, this will mean by a collection of lenses they actually cannot change the focal plane and nonetheless this kind of rigid structure still is very successful in getting implies to survive.",
            "Another observation would like to."
        ],
        [
            "Point out is that.",
            "Animals have different computational capabilities.",
            "And the design of all these eyes actually kind of matches.",
            "There's very tasks, their completion capabilities and also the environment.",
            "The scale of the moment where they lived.",
            "So there must be something interesting that we can derive by."
        ],
        [
            "Mentally designing both the optical system and also the computational arguments that go with it.",
            "And in general the idea is OK. Can I change my device so that I can?"
        ],
        [
            "Obtain a different image, something that perhaps I've never seen.",
            "But success with some."
        ],
        [
            "Additional processing from which I can extract new information, perhaps more information than I could with commercial cameras.",
            "Please take this this week.",
            "No, actually this is an old image.",
            "Perhaps they should have done that."
        ],
        [
            "Let me try to convince you with one very simple way of changing the system that has been introduced not too long ago.",
            "Basically you take a conventional camera and then apply a mask and you've seen this in your previous talks.",
            "While this leads to the coded aperture camera, so we."
        ],
        [
            "We have our own version where we put them a simple mask with four apertures.",
            "If you capture an image with a camera with such mask, A becomes blurred.",
            "With this kind of odd looking blur.",
            "I think it's kind of unusual, and now if you want actually to restore this image, you know you need to use the blinded condition algorithms as we've seen a few stocks, but in general in this case where basically the blur scale changes with the depth you need to estimate for each pixel the scale of blur.",
            "So turns out that if you actually use a conventional camera where you have a desk, estimating this killer is much more difficult, much more ill posed than when you have such a mask, and indeed we have our own algorithms that."
        ],
        [
            "Taking that image managed to get this restored image.",
            "And just appreciate."
        ],
        [
            "The difference this is."
        ],
        [
            "To restore."
        ],
        [
            "And you can see them side by side and cleaning to use all the price we been hearing about and all the latest techniques to do that.",
            "With essentially, if you try to do the same with different masks, you will see that you will get different results, so there is something to be gained by designing the the system."
        ],
        [
            "So in this talk will look at one such system where actually we don't just change the aperture, we actually introduced additional optics and that is the light field camera.",
            "I will look at three or four parts about this topic.",
            "One is first of all.",
            "What can you get?",
            "What kind of information can extract from this camera?",
            "Talk about how we actually do that briefly, within the time that we are given and because I want to spend some time on looking at the limits of this camera.",
            "Net perhaps I find more interesting and finally will show some comparison with other existing methods and devices."
        ],
        [
            "So if you capture first of all and I feel camera essentially is a commercial camera where you add an additional layer of microlenses in front right in front of the sensor.",
            "And you do that such that each microlens does not cover just one pixel, but it covers a region, a Patch of pixels.",
            "So that's all there is for the design.",
            "Now you capture an image with such a device.",
            "This is what you get, which doesn't look very impressive.",
            "But if you."
        ],
        [
            "So mean then you start to see the structure that is conveyed by the microlenses.",
            "Essentially can see a number of discs and each of these is basically imaging a similar portion of the scene.",
            "That you're looking at."
        ],
        [
            "So what can we do with one such image?",
            "But what you can do for exam?"
        ],
        [
            "Please get 3D.",
            "And this is encoded in this case as where we have the distance for each pixel encoding in grayscale or bright means that it's closer to the camera and arc that is far away.",
            "Another thing."
        ],
        [
            "You can do is get a sharp image.",
            "Out of it, so extending the depth of field in technical terms."
        ],
        [
            "And another cool application has been demonstrated by Marc Levoy.",
            "Run errands while ago.",
            "Is that the digital refocusing essentially can take this image.",
            "One single snapshot and perform what is called digital refocusing.",
            "Where basically you change the focal plane you actually can swipe.",
            "You can choose any position in space.",
            "And this actually was very very impressive, although the calculations involved to do this are actually rather simple, so it actually is pretty pretty good.",
            "You can do this very quickly.",
            "So, however, there's a little cat."
        ],
        [
            "So we start from."
        ],
        [
            "14 Four thousand 4000 pixels seems.",
            "Now this is rectangle is is a crop of the original image, but pretend it is.",
            "You know the square image.",
            "And Levi and and basically start from this image and perform digital refocusing."
        ],
        [
            "At this resolution, right?"
        ],
        [
            "303 hundred pixels, which is still a decent resolution by these much, much smaller than the number of pixels you have, but I mean there's nothing wrong with it, because actually if you want to do it exactly for any generic scene, this is how you have to do it.",
            "But from a practical point of view, looks like you lost a lot right?",
            "So our contribution is to say, well, if you assume the scene is liberation.",
            "Actually you can go back to the full resolution if you want to do digital refocusing.",
            "Then if I have to be really accurate, you can't really get the full precision at the full resolution, because you have misalignments because there are some errors in computing all the quantity infer, but pretty much all say you would get maybe a loss of half the resolution for each axis, which is still very far away from 178 loss.",
            "OK, so that's the contribution of this work."
        ],
        [
            "There is also course.",
            "There is quite a lot of other work in super resolution dry fields.",
            "One I would like to mention because then we'll refer to that later is the one of Georgia Finance Lane Georgia from Adobe.",
            "Actually, the same time that we came up with our work, they also came up with the idea of getting super resolved light field image.",
            "And their method is basically based on this."
        ],
        [
            "Principle, suppose that this desk is one of the disks obtained from the light field image corresponding to one microlens.",
            "But what they do is they extract one portion right rectangle portion from the disk and they scale it up."
        ],
        [
            "Until it becomes, uh, adjacent to a nearby.",
            "Michael and see Image for which you do the same process, and then that's the image you get.",
            "So clearly it is very efficient.",
            "It's very simple to do that is very simple to understand, but there are several shortcomings.",
            "First of all, you can see that when you scale up, introduce some extra blur number two, you need to pick actually the right rectangle and scale it up to do the right process and that depends on the depth of the scene.",
            "They have no depth estimation, so that basically is kind of.",
            "Based on our chosen plane.",
            "Which will give you some artifacts, and there's one more important aspect of it to point out which is.",
            "There's no deep learning this procedure, but actually there is blur in the light field camera and I'll show you more about that."
        ],
        [
            "Slides.",
            "So here's a prototype we have and the way I approach this point is basically by studying the optical process using calculating the analytic points, functions and so on, and the way we do it is."
        ],
        [
            "He is a very very simple approximation with geometric optics of how light propagates inside the camera.",
            "So essentially we have."
        ],
        [
            "The the optics are summarized into single thin lens.",
            "Which we call the mainlands.",
            "Then we have."
        ],
        [
            "Have the Michael answer.",
            "A plane will be approximately that plane.",
            "That position and here you can see free microlenses with the size as being exaggerated.",
            "Clearly we have to fit about 300 of them in that space, but this is for visualization purposes."
        ],
        [
            "And then here in the back we have the sensor.",
            "So that's quite simple, just three components.",
            "Now suppose we have a point in this.",
            "In the CMP, this is emitting or reflecting light from the scene towards the camera number of light.",
            "Rays will go through the mainlands and then this will be deflected and form a sharp image.",
            "Conject image P prime.",
            "Then this will continue onto the microlens plane and then each of the microlenses would repeat the procedure as the mainlands and deflect them into their own regional pixels.",
            "And as you can see, generally get even a small blur, right?",
            "You can see that here.",
            "We have some small blur and he's due to the microlenses.",
            "So that should be taken into account, right?"
        ],
        [
            "So."
        ],
        [
            "'cause now we place just to give an idea of what kind of images we get.",
            "Let's suppose we place a plane at this position P. With some"
        ],
        [
            "Text QR 2 letters.",
            "The image that we get."
        ],
        [
            "In focus in this case is again at the position P prime."
        ],
        [
            "And then this will produce an image like this.",
            "Essentially, each microlens will will generate an image on the sensor plane.",
            "There will be a slightly different shifted version of a region scene, but also flipped both X&Y coordinates.",
            "If you know."
        ],
        [
            "Move the plane closer to the camera.",
            "Such that The Conjuring images on the microlens plane this is the image you get on the sensor.",
            "Now, in this case, the difference is that you don't get that different portions of the senior repeatedly.",
            "Just get one with one single repetition.",
            "And also that very blurred within each microlens image."
        ],
        [
            "If we keep going then until the plane the conjugate plane is past the microlens plane, then this is type of image you get which is very similar to that except that each image in the in the sensor is not flipped.",
            "So that these are the three cases that essentially you need to know about."
        ],
        [
            "Of course, since this delightful camera, I need to briefly introduce what the life will be is for those of you who may be less familiar with this kind of representation.",
            "So in very simple terms, so I feel is a representation of how light propagates in space."
        ],
        [
            "We try to be more precise.",
            "Suppose we have a scene with a certain object and now we sit on a sphere.",
            "Possible positions, observations, viewpoints and we take a section of that, so we get this cut out the object and."
        ],
        [
            "The and the circle now illuminate the object and this was CATA light in the scene.",
            "Now if we sit."
        ],
        [
            "At any position of the sphere an observed, the object will see along each direction different densities, which will depend on the light scattered by the object.",
            "Now what we can do is we can assign an intensity value that is measured for each direction corresponding to each position on the sphere.",
            "So."
        ],
        [
            "That mapping is what gives us the light field and you can see immediately because we have to the possible positions on a sphere of viewpoint.",
            "Santa deposit positions of incoming directions.",
            "We have a 40 function.",
            "But if you also think of this as a as in the life of cameras, a local selection of possible positions on the sphere and possible in our subset of all possible incoming directions, you can actually rectify that in two D2D planes, wherever the viewpoints and incoming Rays."
        ],
        [
            "And now the job of the life of camera is taking this 40 map and map it onto to the sensor.",
            "Because that's all you have to measure.",
            "And the way it does that is simply by taking these coordinates an arranging them in this way.",
            "Say will put the incoming Rays on the outside for blocks of pieces of information, and each of these blocks which correspond to one microlens will give you the coordinates UV.",
            "So that's only us.",
            "This is without considering blur."
        ],
        [
            "So to be more visual.",
            "That is the representation that we had before, and this is the corresponding image that you get on the sensor.",
            "However, you can actually take an swap the order of X&Y just by doing some scrambling on the pixel."
        ],
        [
            "And get this other representation right?",
            "No particular.",
            "Processing world here and you get what we call the camera review and nurse interpretation here is that you get a collection of views."
        ],
        [
            "Here, where basically you can think of them as if they are taking by sitting on different points on the main lens of the camera.",
            "There's just a different dual interpretation of the data.",
            "But we'll use this for our reconstruction purposes."
        ],
        [
            "So now let's get to how we do the same.",
            "How we obtain all the information about 3D and the sharp image.",
            "So our observation starts from this.",
            "We take a light field image.",
            "And then."
        ],
        [
            "So we magnify that portion and we observe here that each microlens is portraying a shifted version of the same region in space.",
            "So the first thing one can say is that, well, there's."
        ],
        [
            "A lot of redundancy here.",
            "It seems that there is a lot of redundancy, especially if you have lamberson objects.",
            "So can't we perhaps take an approach like in super resolution where we take all these small images and align them because we don't know the alignment.",
            "Here we find the alignment and then we put the samples together into a super resolved image seems plausible.",
            "Indeed, that's actually what you can do.",
            "But one thing you can do, even that goes beyond that is to say, well, in the end we have just a camera with some optics.",
            "This is going to give some odd blurb assembler.",
            "So you can write the blur as a PSF and have the usual.",
            "This user convolution problem.",
            "So how about we just pose this as?"
        ],
        [
            "Classic Spy spacefaring blinded pollution problem right?",
            "This is a blind condition problem.",
            "The hint we got though is that because of this redundancy, the identification of the blur kernel seems to be feasible.",
            "Because we can identify the shifts which actually tell us something about blur.",
            "Indeed, that's the key for the success of this system.",
            "There is a lot of structure in the blur that allows you to identify the scale or blur."
        ],
        [
            "So the approach will use is basically by estimating the depth map of the scene, which is what will determine fully determine the blur of the PSF."
        ],
        [
            "Then we'll also introduce.",
            "Of course, we need, because this is still a neopost problem.",
            "Texture priors, and also that map price, so that's all there is really here."
        ],
        [
            "So as I mentioned, we can take right the problem as a classic blinding pollution problem where we have."
        ],
        [
            "The light film is all you can think it a very long vector.",
            "16,000,000 inches, right?"
        ],
        [
            "Then you have your points for the function H, which depends on the depth map and also if you think about the single point in space.",
            "This is the image that sort of image you will get.",
            "And you can send this over a huge matrix because it's space varying cannot do a convolution here.",
            "But you can always write it as a linear linear model, right?",
            "And age is going to be in general at 16,000,000 by 60 million edges matrix, which is quite huge.",
            "But this is very, very sparse.",
            "Right?"
        ],
        [
            "And then this is your own sharp image R, which is.",
            "Again, you can think of it as a very long vector."
        ],
        [
            "And finally we have noise.",
            "So the approach we take to this is essentially that of a vision approach, as we heard in the pre."
        ],
        [
            "Talks were first identified a PSF by determining depth map.",
            "And then we use that to find the map estimate, as here wise was suggesting you can have first estimation of the kernel and then the estimation of the sharp image.",
            "And of course we use different models for the priors on the the sharp texture.",
            "Some of those are actually exactly the ones that Rafael Molina was talking about, and we also use total variation and they all work very well."
        ],
        [
            "And one thing I would like to point out is just to give an idea of the form of the points per function HS it can be written as the product of two point spread functions.",
            "One is due to the mainlands and when is due today microlenses.",
            "And they."
        ],
        [
            "A form like this.",
            "Which looks may look daunting, but actually it is simply something computing can implement and is.",
            "There's no big challenge here, so it's just a matter of sitting down doing all the calculations.",
            "But the reason why we did this is actually because you will see later you can understand much better the limits of the system once you actually have the exact form of the blur."
        ],
        [
            "So the step that I didn't explain is how do we get the depth map, so I'll try to explain some of of that here.",
            "Well, essentially because we had."
        ],
        [
            "This interpretation in multiple views, one approach you can take is that of very popular technique in computer vision, which is multi view stereo.",
            "Essentially, try to align all the views simultaneously with a common depth map and that can be done very well by using some allergy minimization techniques where you have some regularization for the depth map we use to variationen can minimize that in a countless number of ways.",
            "What we do is we compute the order again equations, we linearize them and then we run.",
            "Conjuring descent, so that's is a very well start."
        ],
        [
            "Technique anywhere it's quite well under to point out briefly, one of the terms in the energy which is the data term and essentially what?"
        ],
        [
            "We do is you have a robust norm to match them.",
            "Still want this to be close to convex so that optimization is guaranteed to converge to something good and then."
        ],
        [
            "You match 2 views.",
            "From any, any 2 vantage points in the in the image you captured."
        ],
        [
            "Where you have the disparity map which is scaling the shift between."
        ],
        [
            "The two relative positions which you have.",
            "So that's really all there is.",
            "But one thing I need to mention, uh?"
        ],
        [
            "Super Brief is that you need to take into account aliasing.",
            "If you actually take one of those lightfield images.",
            "In this case there is not a lot but for example, in one of the previous datasets you do have such kind of aliasing effects if you try to align these images is not going to work, so I need to introduce anti aliasing filters that depend on the desktop and so and so forth.",
            "And then you can take care of that.",
            "So."
        ],
        [
            "But also you can take the different approach of working not just with a view based interpretation that I feel they actually can stick to the microlens array view.",
            "And obtain a depth map by working simply on, for example, a method of Georgia where you actually you magnify the tires and then you make sure that the tires that are adjacent have a continuity in the gradient.",
            "So you don't have this kind of artifact that you get one after this killing is wrong.",
            "And you can impose an energy minimization.",
            "We do that globally, and what you get is essentially."
        ],
        [
            "A high resolution reconstruction, the depth map, which allows you to get a better reconstruction of the of the soup result image, and you can see here that if you have the incorrect depth Maps then you get more artifacts.",
            "Well, it's more difficult to see it here, but there are some blocky artifacts.",
            "So."
        ],
        [
            "Either we have the dock map.",
            "Then we can.",
            "I can show you what we get, you know where datasets, and then we can see some of the limits of the system.",
            "So this is a data set we captured, rearranged as the camera View camera review so."
        ],
        [
            "This is one of the single views.",
            "Anne."
        ],
        [
            "And this is the depth map we reconstruct from such single image."
        ],
        [
            "And this is this.",
            "Is the reconstruction working so?",
            "On the left column we have the view resolution.",
            "This is what Marc Levoy and range have been working with, right?",
            "So you can see is quite low resolution there and you can see all the aliasing effects in the data set by Adobe.",
            "The Center column is the results obtained by using Georgiev's method and you can see that it gains resolution compared to the.",
            "Of course the single view one, but there's still some blur left right?",
            "And this is what we get with our method.",
            "So you can see there is.",
            "Much sharper effect, even for this data set, you can see that.",
            "Now what I'd like to ask you is, can you notice anything odd in this bottom row?",
            "In the reconstruction, is there anything that can do leaves you puzzled?",
            "So let me help you, let me.",
            "Yes.",
            "So."
        ],
        [
            "So you can see that in the center is kind of pixelized.",
            "It's not our algorithms, fault is actually because of the light field camera and."
        ],
        [
            "I'll explain what happens here, so let me give you at the outset the result, essentially with a commercial camera, you have a planning focus in space.",
            "As you move away from the plane, things become blurrier Ambler in the life of camera, you get the opposite.",
            "You have a planning focus where it's out of focus as you move away, becomes sharper and sharper.",
            "This is the plane in focus for the mainlands, which becomes the blurry playing focus for the light field camera, but away from that things are sharp.",
            "That is how the camera works.",
            "So clearly there is a big advantage using this system as long as you keep the planning focus before or away from the objects of interest, and generally again much more adaptive field, right?",
            "So that let me so."
        ],
        [
            "To understand that analytically, you need to use the correct PSF.",
            "That's why we needed to have all the formulas, because then what you can do is OK. You can plot on this axis.",
            "Here the depth of the object in space.",
            "So we go from.",
            "At 10 centimeters to 1 meter to 10 meters to 100 meters right, and for each of these we plot the blur generated by one microlens on the plane in pixels.",
            "So as long as we are below one pixel, we're producing a sharp image or point in space.",
            "And what you can see by using the analytic formula is that as you approach the planning focus, the blur increases is then capped by the size of the microlens.",
            "So it actually is bound and then it starts to decrease again.",
            "So it's a very nice behavior in a way, and it's complementary to that of a regular camera which is in red dashed curve, where you can see that it gets sharp there and then he goes out of focus.",
            "In this case, we have a very shallow depth of field for the camera.",
            "But this actually doesn't tell you the full story.",
            "Because actually is not exactly true that we gain the full resolution here.",
            "Yes, the blurry is is below one pixel, but there are some other effects."
        ],
        [
            "So to understand a couple of these effects, basically I need to refer back to this model that we introduced earlier on, But let's simplify all we need to do is to observe that every object in space is imaged inside.",
            "As conjugate images, right?",
            "So all we need to do is reason inside because we have all the Rays outside replicating in the in the camera."
        ],
        [
            "So we just work on the conjugate domain."
        ],
        [
            "So now we can try to retrace just a few races and try to understand what happens.",
            "The first observation would like to make is this.",
            "If we have that the conjugate image of the object is for example in this plane here with all these colors.",
            "Then what happens is that each of these microlenses will see this point from their point of view, because the blur generated by the mainlands is actually covering those my classes and each of them will produce a different shifted version of that single point on this object.",
            "So that's fine.",
            "We can use this to triangulate, like in a cabaret.",
            "Find a position determined blur and so on and so forth.",
            "However, if that object is actually imaged here, which is when we have the planning focus in space, then we have just one copy, so there's no triangulation we can do, and we lose the information on the blur.",
            "So that's what happens.",
            "At this location we have the pixelized effect.",
            "We can't retrieve the 3D position for this band, and we can retrieve also the image because we have the blur explodes."
        ],
        [
            "So a second one that I want to point out is this.",
            "So in super resolution you know that when you align the images, if they actually collect the same exact image samples and your line them, although they are shifted, you actually get the blurry image because there's no new information.",
            "All you need is actually images that contain different samples that you can still align by content different samples.",
            "So when you put them together you truly get a high resolution image.",
            "So what we don't want is in this case that microlenses collect the same sampling space, because then it would be a duplicate.",
            "But unfortunately, because of these race cross, they will intersect in space.",
            "Anyway."
        ],
        [
            "You will get planes where actually they collect the same exact sample.",
            "In that case you lose resolution in the reconstruction because truly get blur.",
            "And actually."
        ],
        [
            "And get in the intersection of several exact planes which you can calculate."
        ],
        [
            "There going to be."
        ],
        [
            "All these positions."
        ],
        [
            "And this indeed is the worst position ever.",
            "We know that already.",
            "So you can."
        ],
        [
            "See that they also experimentally."
        ],
        [
            "If you try to do the reconstruction, see that all these depths in resolution and these are exactly those planes.",
            "So here we show a comparison using.",
            "The SNR were basically the higher the better."
        ],
        [
            "And.",
            "This is your Jeff method.",
            "You can see it has this lower bound and then we show the performance of our method."
        ],
        [
            "Four different noise levels, so if you add enough noise, we go to the level of Georgia.",
            "But overall we have again."
        ],
        [
            "And this, as I mentioned, the coincidence of samples that dips."
        ],
        [
            "You can see this also if you try to compare with other systems."
        ],
        [
            "Again, this for reference is the low resolution reconstruction quality."
        ],
        [
            "We don't.",
            "We don't want to exceed that.",
            "Otherwise we do worse than than just taking the low resolution images and not doing anything.",
            "We compare different systems, one is the coded aperture assistant was doing a yard."
        ],
        [
            "This is that in both faces the traditional camera."
        ],
        [
            "And the story the solid one is the Sean camera and the BF.",
            "The Bold one is the light field camera, so you can see.",
            "Overall we have again overall the systems, but clearly at a planning focus we have a loss of resolution so there we don't gain."
        ],
        [
            "And this is a more extensive comparison.",
            "This is the second to last slide, so should be on time and on the all these columns we have different cases on the leftmost column we have a light field block for different planes, just because we want to get an extensive evaluation of that.",
            "The second column is the restoration deal by Georgia.",
            "You can see that we gain some resolution, but there's still some lower left.",
            "Then you can say, well, how about we apply deep learning to that result?",
            "Well then you get the third column, which improves a little bit, but you get a lot of artifacts because it's imposed when you start from that image alone, we use our method where you do that everything together, then you get a much better result.",
            "You can also compare it to a coded aperture camera, so that's the E column.",
            "Again, for different planes and this is the reconstruction team by coded aperture.",
            "Not too bad, but as you can see there are more artifacts than in life field camera.",
            "You can also use a focus sweep camera, which is one of the systems that you consider the top ones.",
            "And what the way works for those of you listening or less familiar with that is simply that you accumulate all the images by changing the focal plane, sweeping a certain range, the deer being that as you do that, you're averaging all the PSS for different ducklings, and this way you get a piece of this kind of not dependent on the depth.",
            "Truth is that it's still dependent on the depth, because as you get to the extreme layers of the range we are capturing the averaging all the planes you're still dependent on the PSF that is there.",
            "That is very different from the average PSF.",
            "We still get a decent result, but you can see that there are more artifacts than if you use a life with camera.",
            "So however community, that, despite of their limitations, there is quite some good stuff in it so."
        ],
        [
            "To conclude my presentation, you looked at some of the aspects of the life of camera sampling patterns, limits that this camera has.",
            "We've seen also algorithms to do that, although I didn't explain detail how I do it, but basically get the deal that you need to get adapt map.",
            "Need to introduce some image priors is also very important, and to me one aspect is very interesting.",
            "Is this essentially the reason why we managed to reconstruct?",
            "The dock map the and therefore also the the sharp image of the scene is because there was a lot of structure in the in the PSF.",
            "Indeed, if you try to do the same with the regular camera is much more difficult.",
            "Probably get way worse results so clearly by introducing some structure in the PSF you can improve the quality of the image reconstruction and what you do is that you sacrifice some of it in the process.",
            "So the question is, how much do you need to sacrifice to be able sacrificing the image reconstruction to be able to get as much of it?",
            "And clearly there must be a tradeoff in between, and it's not clear what system will achieve that and so that to me is the open question.",
            "So if you have any questions, I'll be happy to answer.",
            "The question is, we make the assumption of having immersion scene.",
            "Where is that going to the analysis in the model?",
            "Well, essentially it goes right.",
            "Maybe good idea to flip through."
        ],
        [
            "Then it goes right here where you say that there is a single intensity to be retrieved for all possible viewpoints.",
            "That's the immersion model, right imposed.",
            "No regions way, so that's where we use it.",
            "So can you explain what's going to happen if you take a picture of this shiny board, for example?",
            "Oh, I can show it directly in the results we get.",
            "Essentially get an averaging."
        ],
        [
            "So this is a plastic object is very shiny, right?",
            "We still managed to get some reconstruction of the high resolution view, but the effect is that it is going to blur out the average.",
            "All the shiny effects you have to keep in mind as well that."
        ],
        [
            "The same thing happens here actually, if you have, I don't know.",
            "It was more visible in some zooming zoomed in version of the image is basically there's a shiny spot here and actually you can see that this is washed out more here in our reconstruction.",
            "Or even well anyway, basically you have to consider also that you are observing the scene from a kind of narrow range of angular directions, so it can still tolerate a wide variety of shiny objects.",
            "That kind of wider blob of reflection.",
            "But for all the other ones is going to do an averaging effect.",
            "It's still OK, but it's not.",
            "Maybe ideal, yes?",
            "So the depth.",
            "Seems to be very good over very nearby objects.",
            "Well, yes, we have a small baseline.",
            "Or can you quantify that?",
            "Yes, we actually did the analysis and we obtain the best possible resolution can get you lose very quickly as you go far away as you as you said, because indeed the baseline that you get and you can understand that immediately from the camera review is that of the mainlands.",
            "So when you do triangulation, you're going to be able to do.",
            "Maybe you want to meters reasonably well.",
            "And then as you go far away, the resolution goes down very quickly.",
            "So yes, it's not made for pretty estimation, so.",
            "So the question is.",
            "In my model I have at the point spread function split in two components, one that relates the mainland, so it relates the microlenses and it was mentioned that Georgia has a different model where he says that he readjusts the system so that it doesn't get blur from the mainland's.",
            "Is that correct?",
            "Well, you cannot not get blur from the mainland's because we know that that would be a huge problem.",
            "You need to cover several microlenses to get anything out of it, so probably what they tried to avoid is the microlens player.",
            "And indeed, in this image they limit my clans blur alot, but what they do is they make a small aperture on each microlens so they sacrificed light.",
            "Which again to me, is not necessarily a very good idea, but maybe something between still is OK. OK, so the question was that flies have two eyes we do.",
            "We have two eyes and so how about two light field cameras?",
            "Well, one thing I would like to point out is that the life that the fly has two eyes, but there are kind of you know on two opposite sides.",
            "To me they are there to cover different fields of view.",
            "They probably operate, you know, independent fashion because there is little overlap, and indeed I think like the camera can be seen as similar designers in the fly system.",
            "Or basically they don't have, they don't need to actually adjust the focal plane as we do with our eyes and you can see why because we can do these are focusing they can actually recombine the views and get all the blur layers they want, so that's maybe how they achieve it.",
            "We don't.",
            "I don't know every year.",
            "Wiring up there, it's too far beyond.",
            "I wish I knew, but it comes at a cost.",
            "And you know you need to spend months on that.",
            "Now having two cameras for life camera, yes, could be very beneficial, especially if you put two different planes in focus for the cameras, because then will be sharpened, gets blurred.",
            "You can combine everything into a single, very sharp image.",
            "The question is basically that in the Model age, the point spread function has a lot of structure.",
            "Do we use it?",
            "Yes we do a lot actually we.",
            "We have the exact model of.",
            "Of that, and I tried to."
        ],
        [
            "Briefly illustrate that here we have the analytic form of it.",
            "And we compute that for several data positions we store.",
            "That's a humongous piece of data.",
            "So so yes.",
            "I want trivia question usually usable for color image Ng.",
            "We have this on top like yes we have a Bayer pattern in the camera at the moment.",
            "As you've seen we then converted to black and white for simplicity, but this can be done on color too and you can consider also the fact that they're on different pixels too.",
            "That's what we should do.",
            "I think there are some papers where they they do that so you don't have any effects with more the pattern or whatever that the lens array in the biohazard ODI l'aimant.",
            "So let me repeat this question is very interesting because it falls.",
            "Through the cracks of the business.",
            "So the question is, do you have any problems with the alignment between the Mark lanceray and assisted?",
            "Yes, of course you do.",
            "Is actually the calibration step.",
            "That is a very tricky one.",
            "You get more than that, not only need to find the alignment between the two grids, we actually also have ways to adjust, but to certain extent you get still maybe a few pixels error, but also you guys, some photometric issues were basically across the array of my classes.",
            "You have that.",
            "Maybe they respond.",
            "Let light through in a different way.",
            "So you need to correct for all of these, but it's possible we have different techniques to do that, yes.",
            "So the question was, can we skip calibration and do it with machine learning?",
            "Well.",
            "Probably.",
            "Probably it seems plausible, so how soon can I have one of these in my cell phone?",
            "Well summary Peter question how soon can I have a rifle camera in my cell phone?",
            "There is an expensive which is that I feel that light, sorry, the microlens array.",
            "But if you make it in scaled and if you make many of them, it's not going to be expensive.",
            "Indeed there's a company that is a starter.",
            "Byron Edge is called light right now and they just came out in November I think with their cameras, delightful cameras and they do this refocusing.",
            "Just click capture picture.",
            "So probably if that goes well then they will go to the cell phones and so on.",
            "I have no idea, they're very secretive.",
            "About their parents so.",
            "Yes, let me repeat the question so there are other ways to get sharp images, and one of this is to make pixel smaller.",
            "Or maybe reducing the aperture size.",
            "Why do you need to use light field camera?",
            "Because the answer the short answer is because this allows you to get a lot of light in the camera so it works well when things are dark and when you have a lot of noise in the sensor.",
            "So if you try for example to get a sharp image by using a pinhole camera.",
            "Then, as in the cell phones, you know very well when it's dark, it won't work very well with this one has the advantage that gathers as much light as can get through the sensor, so you can work with a very large aperture as wide as possible, and then the Michael instance will do the job of splitting information, but you still get most of it.",
            "Maybe maybe because of the gaps, you will lose 17%, but you know this is nothing compared to having a pinhole.",
            "So that's the reason.",
            "Thanks again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Thank you very much for being here.",
                    "label": 0
                },
                {
                    "sent": "I'll talk about Lightfield camera.",
                    "label": 0
                },
                {
                    "sent": "In particular, we refer to the prototype built by Berkeley Boy and range of which we also built a replica and in particular will look at how this device can allows you to extend active field and how we need to deal with aliasing and some other aspects.",
                    "label": 0
                },
                {
                    "sent": "So super resolution.",
                    "label": 0
                },
                {
                    "sent": "And this is joint work with Tom Bishop.",
                    "label": 1
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the way I like to see it is start to observe that conventional cameras are kind of based on a similar design to the human eye.",
                    "label": 1
                },
                {
                    "sent": "Basically, there's alliance.",
                    "label": 0
                },
                {
                    "sent": "He can change the lens and bring a different positions in place in the space in focus.",
                    "label": 0
                },
                {
                    "sent": "And also there is a rattling under works similar to a sensor.",
                    "label": 0
                },
                {
                    "sent": "However, what you can ask?",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is is this kind of design optimal for all vision tasks?",
                    "label": 0
                },
                {
                    "sent": "And clearly if you look in nature.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There are many other device designs that allow other animals to survive, so clearly they achieve the purpose there made for and also they are quite different from the human eye.",
                    "label": 0
                },
                {
                    "sent": "For example, if you take the the eye of a fly, this will mean by a collection of lenses they actually cannot change the focal plane and nonetheless this kind of rigid structure still is very successful in getting implies to survive.",
                    "label": 0
                },
                {
                    "sent": "Another observation would like to.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Point out is that.",
                    "label": 0
                },
                {
                    "sent": "Animals have different computational capabilities.",
                    "label": 1
                },
                {
                    "sent": "And the design of all these eyes actually kind of matches.",
                    "label": 1
                },
                {
                    "sent": "There's very tasks, their completion capabilities and also the environment.",
                    "label": 0
                },
                {
                    "sent": "The scale of the moment where they lived.",
                    "label": 0
                },
                {
                    "sent": "So there must be something interesting that we can derive by.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Mentally designing both the optical system and also the computational arguments that go with it.",
                    "label": 0
                },
                {
                    "sent": "And in general the idea is OK. Can I change my device so that I can?",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Obtain a different image, something that perhaps I've never seen.",
                    "label": 0
                },
                {
                    "sent": "But success with some.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Additional processing from which I can extract new information, perhaps more information than I could with commercial cameras.",
                    "label": 0
                },
                {
                    "sent": "Please take this this week.",
                    "label": 0
                },
                {
                    "sent": "No, actually this is an old image.",
                    "label": 0
                },
                {
                    "sent": "Perhaps they should have done that.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let me try to convince you with one very simple way of changing the system that has been introduced not too long ago.",
                    "label": 0
                },
                {
                    "sent": "Basically you take a conventional camera and then apply a mask and you've seen this in your previous talks.",
                    "label": 0
                },
                {
                    "sent": "While this leads to the coded aperture camera, so we.",
                    "label": 1
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We have our own version where we put them a simple mask with four apertures.",
                    "label": 0
                },
                {
                    "sent": "If you capture an image with a camera with such mask, A becomes blurred.",
                    "label": 0
                },
                {
                    "sent": "With this kind of odd looking blur.",
                    "label": 0
                },
                {
                    "sent": "I think it's kind of unusual, and now if you want actually to restore this image, you know you need to use the blinded condition algorithms as we've seen a few stocks, but in general in this case where basically the blur scale changes with the depth you need to estimate for each pixel the scale of blur.",
                    "label": 0
                },
                {
                    "sent": "So turns out that if you actually use a conventional camera where you have a desk, estimating this killer is much more difficult, much more ill posed than when you have such a mask, and indeed we have our own algorithms that.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Taking that image managed to get this restored image.",
                    "label": 0
                },
                {
                    "sent": "And just appreciate.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The difference this is.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To restore.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And you can see them side by side and cleaning to use all the price we been hearing about and all the latest techniques to do that.",
                    "label": 0
                },
                {
                    "sent": "With essentially, if you try to do the same with different masks, you will see that you will get different results, so there is something to be gained by designing the the system.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in this talk will look at one such system where actually we don't just change the aperture, we actually introduced additional optics and that is the light field camera.",
                    "label": 1
                },
                {
                    "sent": "I will look at three or four parts about this topic.",
                    "label": 0
                },
                {
                    "sent": "One is first of all.",
                    "label": 0
                },
                {
                    "sent": "What can you get?",
                    "label": 1
                },
                {
                    "sent": "What kind of information can extract from this camera?",
                    "label": 0
                },
                {
                    "sent": "Talk about how we actually do that briefly, within the time that we are given and because I want to spend some time on looking at the limits of this camera.",
                    "label": 0
                },
                {
                    "sent": "Net perhaps I find more interesting and finally will show some comparison with other existing methods and devices.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if you capture first of all and I feel camera essentially is a commercial camera where you add an additional layer of microlenses in front right in front of the sensor.",
                    "label": 0
                },
                {
                    "sent": "And you do that such that each microlens does not cover just one pixel, but it covers a region, a Patch of pixels.",
                    "label": 0
                },
                {
                    "sent": "So that's all there is for the design.",
                    "label": 0
                },
                {
                    "sent": "Now you capture an image with such a device.",
                    "label": 0
                },
                {
                    "sent": "This is what you get, which doesn't look very impressive.",
                    "label": 0
                },
                {
                    "sent": "But if you.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So mean then you start to see the structure that is conveyed by the microlenses.",
                    "label": 0
                },
                {
                    "sent": "Essentially can see a number of discs and each of these is basically imaging a similar portion of the scene.",
                    "label": 0
                },
                {
                    "sent": "That you're looking at.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what can we do with one such image?",
                    "label": 0
                },
                {
                    "sent": "But what you can do for exam?",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Please get 3D.",
                    "label": 0
                },
                {
                    "sent": "And this is encoded in this case as where we have the distance for each pixel encoding in grayscale or bright means that it's closer to the camera and arc that is far away.",
                    "label": 0
                },
                {
                    "sent": "Another thing.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can do is get a sharp image.",
                    "label": 0
                },
                {
                    "sent": "Out of it, so extending the depth of field in technical terms.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And another cool application has been demonstrated by Marc Levoy.",
                    "label": 0
                },
                {
                    "sent": "Run errands while ago.",
                    "label": 0
                },
                {
                    "sent": "Is that the digital refocusing essentially can take this image.",
                    "label": 1
                },
                {
                    "sent": "One single snapshot and perform what is called digital refocusing.",
                    "label": 0
                },
                {
                    "sent": "Where basically you change the focal plane you actually can swipe.",
                    "label": 0
                },
                {
                    "sent": "You can choose any position in space.",
                    "label": 0
                },
                {
                    "sent": "And this actually was very very impressive, although the calculations involved to do this are actually rather simple, so it actually is pretty pretty good.",
                    "label": 0
                },
                {
                    "sent": "You can do this very quickly.",
                    "label": 0
                },
                {
                    "sent": "So, however, there's a little cat.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we start from.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "14 Four thousand 4000 pixels seems.",
                    "label": 0
                },
                {
                    "sent": "Now this is rectangle is is a crop of the original image, but pretend it is.",
                    "label": 0
                },
                {
                    "sent": "You know the square image.",
                    "label": 0
                },
                {
                    "sent": "And Levi and and basically start from this image and perform digital refocusing.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At this resolution, right?",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "303 hundred pixels, which is still a decent resolution by these much, much smaller than the number of pixels you have, but I mean there's nothing wrong with it, because actually if you want to do it exactly for any generic scene, this is how you have to do it.",
                    "label": 0
                },
                {
                    "sent": "But from a practical point of view, looks like you lost a lot right?",
                    "label": 0
                },
                {
                    "sent": "So our contribution is to say, well, if you assume the scene is liberation.",
                    "label": 0
                },
                {
                    "sent": "Actually you can go back to the full resolution if you want to do digital refocusing.",
                    "label": 0
                },
                {
                    "sent": "Then if I have to be really accurate, you can't really get the full precision at the full resolution, because you have misalignments because there are some errors in computing all the quantity infer, but pretty much all say you would get maybe a loss of half the resolution for each axis, which is still very far away from 178 loss.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's the contribution of this work.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There is also course.",
                    "label": 0
                },
                {
                    "sent": "There is quite a lot of other work in super resolution dry fields.",
                    "label": 0
                },
                {
                    "sent": "One I would like to mention because then we'll refer to that later is the one of Georgia Finance Lane Georgia from Adobe.",
                    "label": 0
                },
                {
                    "sent": "Actually, the same time that we came up with our work, they also came up with the idea of getting super resolved light field image.",
                    "label": 0
                },
                {
                    "sent": "And their method is basically based on this.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Principle, suppose that this desk is one of the disks obtained from the light field image corresponding to one microlens.",
                    "label": 0
                },
                {
                    "sent": "But what they do is they extract one portion right rectangle portion from the disk and they scale it up.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Until it becomes, uh, adjacent to a nearby.",
                    "label": 0
                },
                {
                    "sent": "Michael and see Image for which you do the same process, and then that's the image you get.",
                    "label": 0
                },
                {
                    "sent": "So clearly it is very efficient.",
                    "label": 0
                },
                {
                    "sent": "It's very simple to do that is very simple to understand, but there are several shortcomings.",
                    "label": 0
                },
                {
                    "sent": "First of all, you can see that when you scale up, introduce some extra blur number two, you need to pick actually the right rectangle and scale it up to do the right process and that depends on the depth of the scene.",
                    "label": 0
                },
                {
                    "sent": "They have no depth estimation, so that basically is kind of.",
                    "label": 1
                },
                {
                    "sent": "Based on our chosen plane.",
                    "label": 0
                },
                {
                    "sent": "Which will give you some artifacts, and there's one more important aspect of it to point out which is.",
                    "label": 0
                },
                {
                    "sent": "There's no deep learning this procedure, but actually there is blur in the light field camera and I'll show you more about that.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Slides.",
                    "label": 0
                },
                {
                    "sent": "So here's a prototype we have and the way I approach this point is basically by studying the optical process using calculating the analytic points, functions and so on, and the way we do it is.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "He is a very very simple approximation with geometric optics of how light propagates inside the camera.",
                    "label": 0
                },
                {
                    "sent": "So essentially we have.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The the optics are summarized into single thin lens.",
                    "label": 0
                },
                {
                    "sent": "Which we call the mainlands.",
                    "label": 0
                },
                {
                    "sent": "Then we have.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Have the Michael answer.",
                    "label": 0
                },
                {
                    "sent": "A plane will be approximately that plane.",
                    "label": 0
                },
                {
                    "sent": "That position and here you can see free microlenses with the size as being exaggerated.",
                    "label": 0
                },
                {
                    "sent": "Clearly we have to fit about 300 of them in that space, but this is for visualization purposes.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then here in the back we have the sensor.",
                    "label": 0
                },
                {
                    "sent": "So that's quite simple, just three components.",
                    "label": 0
                },
                {
                    "sent": "Now suppose we have a point in this.",
                    "label": 0
                },
                {
                    "sent": "In the CMP, this is emitting or reflecting light from the scene towards the camera number of light.",
                    "label": 0
                },
                {
                    "sent": "Rays will go through the mainlands and then this will be deflected and form a sharp image.",
                    "label": 0
                },
                {
                    "sent": "Conject image P prime.",
                    "label": 0
                },
                {
                    "sent": "Then this will continue onto the microlens plane and then each of the microlenses would repeat the procedure as the mainlands and deflect them into their own regional pixels.",
                    "label": 0
                },
                {
                    "sent": "And as you can see, generally get even a small blur, right?",
                    "label": 0
                },
                {
                    "sent": "You can see that here.",
                    "label": 0
                },
                {
                    "sent": "We have some small blur and he's due to the microlenses.",
                    "label": 0
                },
                {
                    "sent": "So that should be taken into account, right?",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "'cause now we place just to give an idea of what kind of images we get.",
                    "label": 0
                },
                {
                    "sent": "Let's suppose we place a plane at this position P. With some",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Text QR 2 letters.",
                    "label": 0
                },
                {
                    "sent": "The image that we get.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In focus in this case is again at the position P prime.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then this will produce an image like this.",
                    "label": 0
                },
                {
                    "sent": "Essentially, each microlens will will generate an image on the sensor plane.",
                    "label": 0
                },
                {
                    "sent": "There will be a slightly different shifted version of a region scene, but also flipped both X&Y coordinates.",
                    "label": 0
                },
                {
                    "sent": "If you know.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Move the plane closer to the camera.",
                    "label": 0
                },
                {
                    "sent": "Such that The Conjuring images on the microlens plane this is the image you get on the sensor.",
                    "label": 0
                },
                {
                    "sent": "Now, in this case, the difference is that you don't get that different portions of the senior repeatedly.",
                    "label": 0
                },
                {
                    "sent": "Just get one with one single repetition.",
                    "label": 0
                },
                {
                    "sent": "And also that very blurred within each microlens image.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If we keep going then until the plane the conjugate plane is past the microlens plane, then this is type of image you get which is very similar to that except that each image in the in the sensor is not flipped.",
                    "label": 0
                },
                {
                    "sent": "So that these are the three cases that essentially you need to know about.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of course, since this delightful camera, I need to briefly introduce what the life will be is for those of you who may be less familiar with this kind of representation.",
                    "label": 0
                },
                {
                    "sent": "So in very simple terms, so I feel is a representation of how light propagates in space.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We try to be more precise.",
                    "label": 0
                },
                {
                    "sent": "Suppose we have a scene with a certain object and now we sit on a sphere.",
                    "label": 0
                },
                {
                    "sent": "Possible positions, observations, viewpoints and we take a section of that, so we get this cut out the object and.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The and the circle now illuminate the object and this was CATA light in the scene.",
                    "label": 0
                },
                {
                    "sent": "Now if we sit.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "At any position of the sphere an observed, the object will see along each direction different densities, which will depend on the light scattered by the object.",
                    "label": 0
                },
                {
                    "sent": "Now what we can do is we can assign an intensity value that is measured for each direction corresponding to each position on the sphere.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That mapping is what gives us the light field and you can see immediately because we have to the possible positions on a sphere of viewpoint.",
                    "label": 1
                },
                {
                    "sent": "Santa deposit positions of incoming directions.",
                    "label": 0
                },
                {
                    "sent": "We have a 40 function.",
                    "label": 1
                },
                {
                    "sent": "But if you also think of this as a as in the life of cameras, a local selection of possible positions on the sphere and possible in our subset of all possible incoming directions, you can actually rectify that in two D2D planes, wherever the viewpoints and incoming Rays.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And now the job of the life of camera is taking this 40 map and map it onto to the sensor.",
                    "label": 0
                },
                {
                    "sent": "Because that's all you have to measure.",
                    "label": 0
                },
                {
                    "sent": "And the way it does that is simply by taking these coordinates an arranging them in this way.",
                    "label": 0
                },
                {
                    "sent": "Say will put the incoming Rays on the outside for blocks of pieces of information, and each of these blocks which correspond to one microlens will give you the coordinates UV.",
                    "label": 0
                },
                {
                    "sent": "So that's only us.",
                    "label": 0
                },
                {
                    "sent": "This is without considering blur.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So to be more visual.",
                    "label": 0
                },
                {
                    "sent": "That is the representation that we had before, and this is the corresponding image that you get on the sensor.",
                    "label": 0
                },
                {
                    "sent": "However, you can actually take an swap the order of X&Y just by doing some scrambling on the pixel.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And get this other representation right?",
                    "label": 0
                },
                {
                    "sent": "No particular.",
                    "label": 0
                },
                {
                    "sent": "Processing world here and you get what we call the camera review and nurse interpretation here is that you get a collection of views.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here, where basically you can think of them as if they are taking by sitting on different points on the main lens of the camera.",
                    "label": 0
                },
                {
                    "sent": "There's just a different dual interpretation of the data.",
                    "label": 0
                },
                {
                    "sent": "But we'll use this for our reconstruction purposes.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now let's get to how we do the same.",
                    "label": 0
                },
                {
                    "sent": "How we obtain all the information about 3D and the sharp image.",
                    "label": 0
                },
                {
                    "sent": "So our observation starts from this.",
                    "label": 0
                },
                {
                    "sent": "We take a light field image.",
                    "label": 1
                },
                {
                    "sent": "And then.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we magnify that portion and we observe here that each microlens is portraying a shifted version of the same region in space.",
                    "label": 0
                },
                {
                    "sent": "So the first thing one can say is that, well, there's.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A lot of redundancy here.",
                    "label": 1
                },
                {
                    "sent": "It seems that there is a lot of redundancy, especially if you have lamberson objects.",
                    "label": 0
                },
                {
                    "sent": "So can't we perhaps take an approach like in super resolution where we take all these small images and align them because we don't know the alignment.",
                    "label": 0
                },
                {
                    "sent": "Here we find the alignment and then we put the samples together into a super resolved image seems plausible.",
                    "label": 0
                },
                {
                    "sent": "Indeed, that's actually what you can do.",
                    "label": 0
                },
                {
                    "sent": "But one thing you can do, even that goes beyond that is to say, well, in the end we have just a camera with some optics.",
                    "label": 0
                },
                {
                    "sent": "This is going to give some odd blurb assembler.",
                    "label": 0
                },
                {
                    "sent": "So you can write the blur as a PSF and have the usual.",
                    "label": 0
                },
                {
                    "sent": "This user convolution problem.",
                    "label": 0
                },
                {
                    "sent": "So how about we just pose this as?",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Classic Spy spacefaring blinded pollution problem right?",
                    "label": 0
                },
                {
                    "sent": "This is a blind condition problem.",
                    "label": 0
                },
                {
                    "sent": "The hint we got though is that because of this redundancy, the identification of the blur kernel seems to be feasible.",
                    "label": 0
                },
                {
                    "sent": "Because we can identify the shifts which actually tell us something about blur.",
                    "label": 0
                },
                {
                    "sent": "Indeed, that's the key for the success of this system.",
                    "label": 0
                },
                {
                    "sent": "There is a lot of structure in the blur that allows you to identify the scale or blur.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the approach will use is basically by estimating the depth map of the scene, which is what will determine fully determine the blur of the PSF.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then we'll also introduce.",
                    "label": 0
                },
                {
                    "sent": "Of course, we need, because this is still a neopost problem.",
                    "label": 0
                },
                {
                    "sent": "Texture priors, and also that map price, so that's all there is really here.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So as I mentioned, we can take right the problem as a classic blinding pollution problem where we have.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The light film is all you can think it a very long vector.",
                    "label": 0
                },
                {
                    "sent": "16,000,000 inches, right?",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then you have your points for the function H, which depends on the depth map and also if you think about the single point in space.",
                    "label": 0
                },
                {
                    "sent": "This is the image that sort of image you will get.",
                    "label": 0
                },
                {
                    "sent": "And you can send this over a huge matrix because it's space varying cannot do a convolution here.",
                    "label": 0
                },
                {
                    "sent": "But you can always write it as a linear linear model, right?",
                    "label": 0
                },
                {
                    "sent": "And age is going to be in general at 16,000,000 by 60 million edges matrix, which is quite huge.",
                    "label": 0
                },
                {
                    "sent": "But this is very, very sparse.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then this is your own sharp image R, which is.",
                    "label": 0
                },
                {
                    "sent": "Again, you can think of it as a very long vector.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And finally we have noise.",
                    "label": 0
                },
                {
                    "sent": "So the approach we take to this is essentially that of a vision approach, as we heard in the pre.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Talks were first identified a PSF by determining depth map.",
                    "label": 0
                },
                {
                    "sent": "And then we use that to find the map estimate, as here wise was suggesting you can have first estimation of the kernel and then the estimation of the sharp image.",
                    "label": 1
                },
                {
                    "sent": "And of course we use different models for the priors on the the sharp texture.",
                    "label": 0
                },
                {
                    "sent": "Some of those are actually exactly the ones that Rafael Molina was talking about, and we also use total variation and they all work very well.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And one thing I would like to point out is just to give an idea of the form of the points per function HS it can be written as the product of two point spread functions.",
                    "label": 0
                },
                {
                    "sent": "One is due to the mainlands and when is due today microlenses.",
                    "label": 0
                },
                {
                    "sent": "And they.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A form like this.",
                    "label": 0
                },
                {
                    "sent": "Which looks may look daunting, but actually it is simply something computing can implement and is.",
                    "label": 0
                },
                {
                    "sent": "There's no big challenge here, so it's just a matter of sitting down doing all the calculations.",
                    "label": 0
                },
                {
                    "sent": "But the reason why we did this is actually because you will see later you can understand much better the limits of the system once you actually have the exact form of the blur.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the step that I didn't explain is how do we get the depth map, so I'll try to explain some of of that here.",
                    "label": 0
                },
                {
                    "sent": "Well, essentially because we had.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This interpretation in multiple views, one approach you can take is that of very popular technique in computer vision, which is multi view stereo.",
                    "label": 0
                },
                {
                    "sent": "Essentially, try to align all the views simultaneously with a common depth map and that can be done very well by using some allergy minimization techniques where you have some regularization for the depth map we use to variationen can minimize that in a countless number of ways.",
                    "label": 0
                },
                {
                    "sent": "What we do is we compute the order again equations, we linearize them and then we run.",
                    "label": 0
                },
                {
                    "sent": "Conjuring descent, so that's is a very well start.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Technique anywhere it's quite well under to point out briefly, one of the terms in the energy which is the data term and essentially what?",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We do is you have a robust norm to match them.",
                    "label": 0
                },
                {
                    "sent": "Still want this to be close to convex so that optimization is guaranteed to converge to something good and then.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You match 2 views.",
                    "label": 0
                },
                {
                    "sent": "From any, any 2 vantage points in the in the image you captured.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Where you have the disparity map which is scaling the shift between.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The two relative positions which you have.",
                    "label": 0
                },
                {
                    "sent": "So that's really all there is.",
                    "label": 0
                },
                {
                    "sent": "But one thing I need to mention, uh?",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Super Brief is that you need to take into account aliasing.",
                    "label": 0
                },
                {
                    "sent": "If you actually take one of those lightfield images.",
                    "label": 0
                },
                {
                    "sent": "In this case there is not a lot but for example, in one of the previous datasets you do have such kind of aliasing effects if you try to align these images is not going to work, so I need to introduce anti aliasing filters that depend on the desktop and so and so forth.",
                    "label": 0
                },
                {
                    "sent": "And then you can take care of that.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But also you can take the different approach of working not just with a view based interpretation that I feel they actually can stick to the microlens array view.",
                    "label": 0
                },
                {
                    "sent": "And obtain a depth map by working simply on, for example, a method of Georgia where you actually you magnify the tires and then you make sure that the tires that are adjacent have a continuity in the gradient.",
                    "label": 0
                },
                {
                    "sent": "So you don't have this kind of artifact that you get one after this killing is wrong.",
                    "label": 0
                },
                {
                    "sent": "And you can impose an energy minimization.",
                    "label": 0
                },
                {
                    "sent": "We do that globally, and what you get is essentially.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A high resolution reconstruction, the depth map, which allows you to get a better reconstruction of the of the soup result image, and you can see here that if you have the incorrect depth Maps then you get more artifacts.",
                    "label": 0
                },
                {
                    "sent": "Well, it's more difficult to see it here, but there are some blocky artifacts.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Either we have the dock map.",
                    "label": 0
                },
                {
                    "sent": "Then we can.",
                    "label": 0
                },
                {
                    "sent": "I can show you what we get, you know where datasets, and then we can see some of the limits of the system.",
                    "label": 0
                },
                {
                    "sent": "So this is a data set we captured, rearranged as the camera View camera review so.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is one of the single views.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is the depth map we reconstruct from such single image.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is this.",
                    "label": 0
                },
                {
                    "sent": "Is the reconstruction working so?",
                    "label": 0
                },
                {
                    "sent": "On the left column we have the view resolution.",
                    "label": 0
                },
                {
                    "sent": "This is what Marc Levoy and range have been working with, right?",
                    "label": 0
                },
                {
                    "sent": "So you can see is quite low resolution there and you can see all the aliasing effects in the data set by Adobe.",
                    "label": 0
                },
                {
                    "sent": "The Center column is the results obtained by using Georgiev's method and you can see that it gains resolution compared to the.",
                    "label": 0
                },
                {
                    "sent": "Of course the single view one, but there's still some blur left right?",
                    "label": 0
                },
                {
                    "sent": "And this is what we get with our method.",
                    "label": 0
                },
                {
                    "sent": "So you can see there is.",
                    "label": 0
                },
                {
                    "sent": "Much sharper effect, even for this data set, you can see that.",
                    "label": 0
                },
                {
                    "sent": "Now what I'd like to ask you is, can you notice anything odd in this bottom row?",
                    "label": 0
                },
                {
                    "sent": "In the reconstruction, is there anything that can do leaves you puzzled?",
                    "label": 0
                },
                {
                    "sent": "So let me help you, let me.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So you can see that in the center is kind of pixelized.",
                    "label": 0
                },
                {
                    "sent": "It's not our algorithms, fault is actually because of the light field camera and.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'll explain what happens here, so let me give you at the outset the result, essentially with a commercial camera, you have a planning focus in space.",
                    "label": 0
                },
                {
                    "sent": "As you move away from the plane, things become blurrier Ambler in the life of camera, you get the opposite.",
                    "label": 0
                },
                {
                    "sent": "You have a planning focus where it's out of focus as you move away, becomes sharper and sharper.",
                    "label": 0
                },
                {
                    "sent": "This is the plane in focus for the mainlands, which becomes the blurry playing focus for the light field camera, but away from that things are sharp.",
                    "label": 0
                },
                {
                    "sent": "That is how the camera works.",
                    "label": 0
                },
                {
                    "sent": "So clearly there is a big advantage using this system as long as you keep the planning focus before or away from the objects of interest, and generally again much more adaptive field, right?",
                    "label": 0
                },
                {
                    "sent": "So that let me so.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To understand that analytically, you need to use the correct PSF.",
                    "label": 0
                },
                {
                    "sent": "That's why we needed to have all the formulas, because then what you can do is OK. You can plot on this axis.",
                    "label": 0
                },
                {
                    "sent": "Here the depth of the object in space.",
                    "label": 0
                },
                {
                    "sent": "So we go from.",
                    "label": 0
                },
                {
                    "sent": "At 10 centimeters to 1 meter to 10 meters to 100 meters right, and for each of these we plot the blur generated by one microlens on the plane in pixels.",
                    "label": 0
                },
                {
                    "sent": "So as long as we are below one pixel, we're producing a sharp image or point in space.",
                    "label": 0
                },
                {
                    "sent": "And what you can see by using the analytic formula is that as you approach the planning focus, the blur increases is then capped by the size of the microlens.",
                    "label": 0
                },
                {
                    "sent": "So it actually is bound and then it starts to decrease again.",
                    "label": 0
                },
                {
                    "sent": "So it's a very nice behavior in a way, and it's complementary to that of a regular camera which is in red dashed curve, where you can see that it gets sharp there and then he goes out of focus.",
                    "label": 0
                },
                {
                    "sent": "In this case, we have a very shallow depth of field for the camera.",
                    "label": 0
                },
                {
                    "sent": "But this actually doesn't tell you the full story.",
                    "label": 0
                },
                {
                    "sent": "Because actually is not exactly true that we gain the full resolution here.",
                    "label": 0
                },
                {
                    "sent": "Yes, the blurry is is below one pixel, but there are some other effects.",
                    "label": 0
                }
            ]
        },
        "clip_80": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So to understand a couple of these effects, basically I need to refer back to this model that we introduced earlier on, But let's simplify all we need to do is to observe that every object in space is imaged inside.",
                    "label": 0
                },
                {
                    "sent": "As conjugate images, right?",
                    "label": 0
                },
                {
                    "sent": "So all we need to do is reason inside because we have all the Rays outside replicating in the in the camera.",
                    "label": 0
                }
            ]
        },
        "clip_81": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we just work on the conjugate domain.",
                    "label": 0
                }
            ]
        },
        "clip_82": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now we can try to retrace just a few races and try to understand what happens.",
                    "label": 0
                },
                {
                    "sent": "The first observation would like to make is this.",
                    "label": 0
                },
                {
                    "sent": "If we have that the conjugate image of the object is for example in this plane here with all these colors.",
                    "label": 0
                },
                {
                    "sent": "Then what happens is that each of these microlenses will see this point from their point of view, because the blur generated by the mainlands is actually covering those my classes and each of them will produce a different shifted version of that single point on this object.",
                    "label": 0
                },
                {
                    "sent": "So that's fine.",
                    "label": 0
                },
                {
                    "sent": "We can use this to triangulate, like in a cabaret.",
                    "label": 0
                },
                {
                    "sent": "Find a position determined blur and so on and so forth.",
                    "label": 0
                },
                {
                    "sent": "However, if that object is actually imaged here, which is when we have the planning focus in space, then we have just one copy, so there's no triangulation we can do, and we lose the information on the blur.",
                    "label": 0
                },
                {
                    "sent": "So that's what happens.",
                    "label": 0
                },
                {
                    "sent": "At this location we have the pixelized effect.",
                    "label": 0
                },
                {
                    "sent": "We can't retrieve the 3D position for this band, and we can retrieve also the image because we have the blur explodes.",
                    "label": 0
                }
            ]
        },
        "clip_83": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So a second one that I want to point out is this.",
                    "label": 0
                },
                {
                    "sent": "So in super resolution you know that when you align the images, if they actually collect the same exact image samples and your line them, although they are shifted, you actually get the blurry image because there's no new information.",
                    "label": 0
                },
                {
                    "sent": "All you need is actually images that contain different samples that you can still align by content different samples.",
                    "label": 0
                },
                {
                    "sent": "So when you put them together you truly get a high resolution image.",
                    "label": 0
                },
                {
                    "sent": "So what we don't want is in this case that microlenses collect the same sampling space, because then it would be a duplicate.",
                    "label": 0
                },
                {
                    "sent": "But unfortunately, because of these race cross, they will intersect in space.",
                    "label": 0
                },
                {
                    "sent": "Anyway.",
                    "label": 0
                }
            ]
        },
        "clip_84": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You will get planes where actually they collect the same exact sample.",
                    "label": 0
                },
                {
                    "sent": "In that case you lose resolution in the reconstruction because truly get blur.",
                    "label": 0
                },
                {
                    "sent": "And actually.",
                    "label": 0
                }
            ]
        },
        "clip_85": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And get in the intersection of several exact planes which you can calculate.",
                    "label": 0
                }
            ]
        },
        "clip_86": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There going to be.",
                    "label": 0
                }
            ]
        },
        "clip_87": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "All these positions.",
                    "label": 0
                }
            ]
        },
        "clip_88": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this indeed is the worst position ever.",
                    "label": 0
                },
                {
                    "sent": "We know that already.",
                    "label": 0
                },
                {
                    "sent": "So you can.",
                    "label": 0
                }
            ]
        },
        "clip_89": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "See that they also experimentally.",
                    "label": 0
                }
            ]
        },
        "clip_90": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you try to do the reconstruction, see that all these depths in resolution and these are exactly those planes.",
                    "label": 0
                },
                {
                    "sent": "So here we show a comparison using.",
                    "label": 0
                },
                {
                    "sent": "The SNR were basically the higher the better.",
                    "label": 0
                }
            ]
        },
        "clip_91": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "This is your Jeff method.",
                    "label": 0
                },
                {
                    "sent": "You can see it has this lower bound and then we show the performance of our method.",
                    "label": 0
                }
            ]
        },
        "clip_92": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Four different noise levels, so if you add enough noise, we go to the level of Georgia.",
                    "label": 0
                },
                {
                    "sent": "But overall we have again.",
                    "label": 0
                }
            ]
        },
        "clip_93": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this, as I mentioned, the coincidence of samples that dips.",
                    "label": 0
                }
            ]
        },
        "clip_94": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can see this also if you try to compare with other systems.",
                    "label": 0
                }
            ]
        },
        "clip_95": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Again, this for reference is the low resolution reconstruction quality.",
                    "label": 0
                }
            ]
        },
        "clip_96": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We don't.",
                    "label": 0
                },
                {
                    "sent": "We don't want to exceed that.",
                    "label": 0
                },
                {
                    "sent": "Otherwise we do worse than than just taking the low resolution images and not doing anything.",
                    "label": 0
                },
                {
                    "sent": "We compare different systems, one is the coded aperture assistant was doing a yard.",
                    "label": 0
                }
            ]
        },
        "clip_97": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is that in both faces the traditional camera.",
                    "label": 0
                }
            ]
        },
        "clip_98": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the story the solid one is the Sean camera and the BF.",
                    "label": 0
                },
                {
                    "sent": "The Bold one is the light field camera, so you can see.",
                    "label": 0
                },
                {
                    "sent": "Overall we have again overall the systems, but clearly at a planning focus we have a loss of resolution so there we don't gain.",
                    "label": 0
                }
            ]
        },
        "clip_99": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is a more extensive comparison.",
                    "label": 0
                },
                {
                    "sent": "This is the second to last slide, so should be on time and on the all these columns we have different cases on the leftmost column we have a light field block for different planes, just because we want to get an extensive evaluation of that.",
                    "label": 0
                },
                {
                    "sent": "The second column is the restoration deal by Georgia.",
                    "label": 0
                },
                {
                    "sent": "You can see that we gain some resolution, but there's still some lower left.",
                    "label": 0
                },
                {
                    "sent": "Then you can say, well, how about we apply deep learning to that result?",
                    "label": 0
                },
                {
                    "sent": "Well then you get the third column, which improves a little bit, but you get a lot of artifacts because it's imposed when you start from that image alone, we use our method where you do that everything together, then you get a much better result.",
                    "label": 0
                },
                {
                    "sent": "You can also compare it to a coded aperture camera, so that's the E column.",
                    "label": 0
                },
                {
                    "sent": "Again, for different planes and this is the reconstruction team by coded aperture.",
                    "label": 0
                },
                {
                    "sent": "Not too bad, but as you can see there are more artifacts than in life field camera.",
                    "label": 0
                },
                {
                    "sent": "You can also use a focus sweep camera, which is one of the systems that you consider the top ones.",
                    "label": 0
                },
                {
                    "sent": "And what the way works for those of you listening or less familiar with that is simply that you accumulate all the images by changing the focal plane, sweeping a certain range, the deer being that as you do that, you're averaging all the PSS for different ducklings, and this way you get a piece of this kind of not dependent on the depth.",
                    "label": 0
                },
                {
                    "sent": "Truth is that it's still dependent on the depth, because as you get to the extreme layers of the range we are capturing the averaging all the planes you're still dependent on the PSF that is there.",
                    "label": 0
                },
                {
                    "sent": "That is very different from the average PSF.",
                    "label": 0
                },
                {
                    "sent": "We still get a decent result, but you can see that there are more artifacts than if you use a life with camera.",
                    "label": 0
                },
                {
                    "sent": "So however community, that, despite of their limitations, there is quite some good stuff in it so.",
                    "label": 0
                }
            ]
        },
        "clip_100": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To conclude my presentation, you looked at some of the aspects of the life of camera sampling patterns, limits that this camera has.",
                    "label": 0
                },
                {
                    "sent": "We've seen also algorithms to do that, although I didn't explain detail how I do it, but basically get the deal that you need to get adapt map.",
                    "label": 0
                },
                {
                    "sent": "Need to introduce some image priors is also very important, and to me one aspect is very interesting.",
                    "label": 0
                },
                {
                    "sent": "Is this essentially the reason why we managed to reconstruct?",
                    "label": 0
                },
                {
                    "sent": "The dock map the and therefore also the the sharp image of the scene is because there was a lot of structure in the in the PSF.",
                    "label": 0
                },
                {
                    "sent": "Indeed, if you try to do the same with the regular camera is much more difficult.",
                    "label": 0
                },
                {
                    "sent": "Probably get way worse results so clearly by introducing some structure in the PSF you can improve the quality of the image reconstruction and what you do is that you sacrifice some of it in the process.",
                    "label": 0
                },
                {
                    "sent": "So the question is, how much do you need to sacrifice to be able sacrificing the image reconstruction to be able to get as much of it?",
                    "label": 0
                },
                {
                    "sent": "And clearly there must be a tradeoff in between, and it's not clear what system will achieve that and so that to me is the open question.",
                    "label": 0
                },
                {
                    "sent": "So if you have any questions, I'll be happy to answer.",
                    "label": 0
                },
                {
                    "sent": "The question is, we make the assumption of having immersion scene.",
                    "label": 0
                },
                {
                    "sent": "Where is that going to the analysis in the model?",
                    "label": 0
                },
                {
                    "sent": "Well, essentially it goes right.",
                    "label": 0
                },
                {
                    "sent": "Maybe good idea to flip through.",
                    "label": 0
                }
            ]
        },
        "clip_101": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then it goes right here where you say that there is a single intensity to be retrieved for all possible viewpoints.",
                    "label": 0
                },
                {
                    "sent": "That's the immersion model, right imposed.",
                    "label": 0
                },
                {
                    "sent": "No regions way, so that's where we use it.",
                    "label": 0
                },
                {
                    "sent": "So can you explain what's going to happen if you take a picture of this shiny board, for example?",
                    "label": 0
                },
                {
                    "sent": "Oh, I can show it directly in the results we get.",
                    "label": 0
                },
                {
                    "sent": "Essentially get an averaging.",
                    "label": 0
                }
            ]
        },
        "clip_102": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is a plastic object is very shiny, right?",
                    "label": 0
                },
                {
                    "sent": "We still managed to get some reconstruction of the high resolution view, but the effect is that it is going to blur out the average.",
                    "label": 0
                },
                {
                    "sent": "All the shiny effects you have to keep in mind as well that.",
                    "label": 0
                }
            ]
        },
        "clip_103": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The same thing happens here actually, if you have, I don't know.",
                    "label": 0
                },
                {
                    "sent": "It was more visible in some zooming zoomed in version of the image is basically there's a shiny spot here and actually you can see that this is washed out more here in our reconstruction.",
                    "label": 0
                },
                {
                    "sent": "Or even well anyway, basically you have to consider also that you are observing the scene from a kind of narrow range of angular directions, so it can still tolerate a wide variety of shiny objects.",
                    "label": 0
                },
                {
                    "sent": "That kind of wider blob of reflection.",
                    "label": 0
                },
                {
                    "sent": "But for all the other ones is going to do an averaging effect.",
                    "label": 0
                },
                {
                    "sent": "It's still OK, but it's not.",
                    "label": 0
                },
                {
                    "sent": "Maybe ideal, yes?",
                    "label": 0
                },
                {
                    "sent": "So the depth.",
                    "label": 0
                },
                {
                    "sent": "Seems to be very good over very nearby objects.",
                    "label": 0
                },
                {
                    "sent": "Well, yes, we have a small baseline.",
                    "label": 0
                },
                {
                    "sent": "Or can you quantify that?",
                    "label": 0
                },
                {
                    "sent": "Yes, we actually did the analysis and we obtain the best possible resolution can get you lose very quickly as you go far away as you as you said, because indeed the baseline that you get and you can understand that immediately from the camera review is that of the mainlands.",
                    "label": 0
                },
                {
                    "sent": "So when you do triangulation, you're going to be able to do.",
                    "label": 0
                },
                {
                    "sent": "Maybe you want to meters reasonably well.",
                    "label": 0
                },
                {
                    "sent": "And then as you go far away, the resolution goes down very quickly.",
                    "label": 0
                },
                {
                    "sent": "So yes, it's not made for pretty estimation, so.",
                    "label": 0
                },
                {
                    "sent": "So the question is.",
                    "label": 0
                },
                {
                    "sent": "In my model I have at the point spread function split in two components, one that relates the mainland, so it relates the microlenses and it was mentioned that Georgia has a different model where he says that he readjusts the system so that it doesn't get blur from the mainland's.",
                    "label": 0
                },
                {
                    "sent": "Is that correct?",
                    "label": 0
                },
                {
                    "sent": "Well, you cannot not get blur from the mainland's because we know that that would be a huge problem.",
                    "label": 0
                },
                {
                    "sent": "You need to cover several microlenses to get anything out of it, so probably what they tried to avoid is the microlens player.",
                    "label": 0
                },
                {
                    "sent": "And indeed, in this image they limit my clans blur alot, but what they do is they make a small aperture on each microlens so they sacrificed light.",
                    "label": 0
                },
                {
                    "sent": "Which again to me, is not necessarily a very good idea, but maybe something between still is OK. OK, so the question was that flies have two eyes we do.",
                    "label": 0
                },
                {
                    "sent": "We have two eyes and so how about two light field cameras?",
                    "label": 0
                },
                {
                    "sent": "Well, one thing I would like to point out is that the life that the fly has two eyes, but there are kind of you know on two opposite sides.",
                    "label": 0
                },
                {
                    "sent": "To me they are there to cover different fields of view.",
                    "label": 0
                },
                {
                    "sent": "They probably operate, you know, independent fashion because there is little overlap, and indeed I think like the camera can be seen as similar designers in the fly system.",
                    "label": 0
                },
                {
                    "sent": "Or basically they don't have, they don't need to actually adjust the focal plane as we do with our eyes and you can see why because we can do these are focusing they can actually recombine the views and get all the blur layers they want, so that's maybe how they achieve it.",
                    "label": 0
                },
                {
                    "sent": "We don't.",
                    "label": 0
                },
                {
                    "sent": "I don't know every year.",
                    "label": 0
                },
                {
                    "sent": "Wiring up there, it's too far beyond.",
                    "label": 0
                },
                {
                    "sent": "I wish I knew, but it comes at a cost.",
                    "label": 0
                },
                {
                    "sent": "And you know you need to spend months on that.",
                    "label": 0
                },
                {
                    "sent": "Now having two cameras for life camera, yes, could be very beneficial, especially if you put two different planes in focus for the cameras, because then will be sharpened, gets blurred.",
                    "label": 0
                },
                {
                    "sent": "You can combine everything into a single, very sharp image.",
                    "label": 0
                },
                {
                    "sent": "The question is basically that in the Model age, the point spread function has a lot of structure.",
                    "label": 0
                },
                {
                    "sent": "Do we use it?",
                    "label": 0
                },
                {
                    "sent": "Yes we do a lot actually we.",
                    "label": 0
                },
                {
                    "sent": "We have the exact model of.",
                    "label": 0
                },
                {
                    "sent": "Of that, and I tried to.",
                    "label": 0
                }
            ]
        },
        "clip_104": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Briefly illustrate that here we have the analytic form of it.",
                    "label": 0
                },
                {
                    "sent": "And we compute that for several data positions we store.",
                    "label": 0
                },
                {
                    "sent": "That's a humongous piece of data.",
                    "label": 0
                },
                {
                    "sent": "So so yes.",
                    "label": 0
                },
                {
                    "sent": "I want trivia question usually usable for color image Ng.",
                    "label": 0
                },
                {
                    "sent": "We have this on top like yes we have a Bayer pattern in the camera at the moment.",
                    "label": 0
                },
                {
                    "sent": "As you've seen we then converted to black and white for simplicity, but this can be done on color too and you can consider also the fact that they're on different pixels too.",
                    "label": 0
                },
                {
                    "sent": "That's what we should do.",
                    "label": 0
                },
                {
                    "sent": "I think there are some papers where they they do that so you don't have any effects with more the pattern or whatever that the lens array in the biohazard ODI l'aimant.",
                    "label": 0
                },
                {
                    "sent": "So let me repeat this question is very interesting because it falls.",
                    "label": 0
                },
                {
                    "sent": "Through the cracks of the business.",
                    "label": 0
                },
                {
                    "sent": "So the question is, do you have any problems with the alignment between the Mark lanceray and assisted?",
                    "label": 0
                },
                {
                    "sent": "Yes, of course you do.",
                    "label": 0
                },
                {
                    "sent": "Is actually the calibration step.",
                    "label": 0
                },
                {
                    "sent": "That is a very tricky one.",
                    "label": 0
                },
                {
                    "sent": "You get more than that, not only need to find the alignment between the two grids, we actually also have ways to adjust, but to certain extent you get still maybe a few pixels error, but also you guys, some photometric issues were basically across the array of my classes.",
                    "label": 0
                },
                {
                    "sent": "You have that.",
                    "label": 0
                },
                {
                    "sent": "Maybe they respond.",
                    "label": 0
                },
                {
                    "sent": "Let light through in a different way.",
                    "label": 0
                },
                {
                    "sent": "So you need to correct for all of these, but it's possible we have different techniques to do that, yes.",
                    "label": 0
                },
                {
                    "sent": "So the question was, can we skip calibration and do it with machine learning?",
                    "label": 1
                },
                {
                    "sent": "Well.",
                    "label": 0
                },
                {
                    "sent": "Probably.",
                    "label": 0
                },
                {
                    "sent": "Probably it seems plausible, so how soon can I have one of these in my cell phone?",
                    "label": 0
                },
                {
                    "sent": "Well summary Peter question how soon can I have a rifle camera in my cell phone?",
                    "label": 0
                },
                {
                    "sent": "There is an expensive which is that I feel that light, sorry, the microlens array.",
                    "label": 0
                },
                {
                    "sent": "But if you make it in scaled and if you make many of them, it's not going to be expensive.",
                    "label": 0
                },
                {
                    "sent": "Indeed there's a company that is a starter.",
                    "label": 0
                },
                {
                    "sent": "Byron Edge is called light right now and they just came out in November I think with their cameras, delightful cameras and they do this refocusing.",
                    "label": 0
                },
                {
                    "sent": "Just click capture picture.",
                    "label": 0
                },
                {
                    "sent": "So probably if that goes well then they will go to the cell phones and so on.",
                    "label": 0
                },
                {
                    "sent": "I have no idea, they're very secretive.",
                    "label": 0
                },
                {
                    "sent": "About their parents so.",
                    "label": 0
                },
                {
                    "sent": "Yes, let me repeat the question so there are other ways to get sharp images, and one of this is to make pixel smaller.",
                    "label": 0
                },
                {
                    "sent": "Or maybe reducing the aperture size.",
                    "label": 0
                },
                {
                    "sent": "Why do you need to use light field camera?",
                    "label": 0
                },
                {
                    "sent": "Because the answer the short answer is because this allows you to get a lot of light in the camera so it works well when things are dark and when you have a lot of noise in the sensor.",
                    "label": 0
                },
                {
                    "sent": "So if you try for example to get a sharp image by using a pinhole camera.",
                    "label": 0
                },
                {
                    "sent": "Then, as in the cell phones, you know very well when it's dark, it won't work very well with this one has the advantage that gathers as much light as can get through the sensor, so you can work with a very large aperture as wide as possible, and then the Michael instance will do the job of splitting information, but you still get most of it.",
                    "label": 0
                },
                {
                    "sent": "Maybe maybe because of the gaps, you will lose 17%, but you know this is nothing compared to having a pinhole.",
                    "label": 0
                },
                {
                    "sent": "So that's the reason.",
                    "label": 0
                },
                {
                    "sent": "Thanks again.",
                    "label": 0
                }
            ]
        }
    }
}