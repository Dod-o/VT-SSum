{
    "id": "geb2wvm4wjlwvcwjc27ltfwgygqtqdhy",
    "title": "UKParl: A Semantified and Topically Organized Corpus of Political Speeches",
    "info": {
        "author": [
            "Federico Nanni, Institut f\u00fcr Informatik, University of Mannheim"
        ],
        "published": "May 30, 2018",
        "recorded": "May 2018",
        "category": [
            "Top->Computers->Digital Media",
            "Top->Humanities->Languages",
            "Top->Social Sciences->Society->Politics"
        ]
    },
    "url": "http://videolectures.net/parlaCLARIN2018_nanni_political_speeches/",
    "segmentation": [
        [
            "Time and so they can."
        ],
        [
            "Honey, I'm from the University of Mannheim and I'm presenting today at joint work that I did together with Simona Ponsetto, Laura Dietz and two of my Masters student Mahmoud Osman, an hero, China.",
            "You will hear me speaking quite a lot because also this afternoon I'll be presenting another paper.",
            "Then I'm involving a panel, so sorry for my like strong Italian accent is like something that you have to deal with today so I."
        ],
        [
            "I'm a postdoc since 6 seven months ago in computational social science at the University of Mannheim, where I'm working on NLP.",
            "Application is in order to support political science research.",
            "OK, I did something similar during my PhD where I was working in collaboration with historians and so it was again NLP application.",
            "In order to support historical research, especially in the use of web archive.",
            "And now I'm focusing mostly on topic detection on collection building especially.",
            "Bayes collection building an intact scaling.",
            "I'll speak about tech scaling in this afternoon.",
            "Today I will."
        ],
        [
            "Now I'll focus on mostly on topic detection, because it's kind of essential when you're doing or you would like to do automatic analysis of political speeches because you want to start by detecting the topics, and because we want to do exploration.",
            "For example, you want to do topic based argumentation mining, understand what politicians are discussing about or in general because we want to understand which are the most relevant topics in a corpus.",
            "So for example, just like."
        ],
        [
            "Quick example made by the Atlantic on the state of the Union address is in in the US.",
            "Here you can see how the topic war has been relevant in the state of the Union.",
            "Addresses over the years and as you can see there's a huge spike around the Second World War.",
            "Same thing."
        ],
        [
            "For the topping, employment, and year you can see two different spikes around the crisis in the 20s and in the 70s and the topic."
        ],
        [
            "Health and you can see a spike at the very end during the Obama.",
            "Here.",
            "There are no state of the union addresses by Donald Trump because it was made in 2015.",
            "So you can see the impact of these and the growth of like the immigration topic.",
            "For example lacking."
        ],
        [
            "But there is a problem.",
            "OK, this kind of research are like pretty useful, but generally the collection that we're providing to the Community do not have topic annotation at the document level.",
            "OK, so we have all these beautiful speeches with all the metadata, and often we don't know what are the topics that have been addressed in the documents.",
            "OK, and so the problem that then political scientists or humanities researchers will?"
        ],
        [
            "Use unsupervised methods for doing this, like LDA.",
            "There was a presentation this morning using let and directly allocation an if you have experience with LDA, so topic models, it's kind of a cool tool for doing quick corpus exploration, but then when you want to move from that to doing real analysis well."
        ],
        [
            "The results are pretty messy, so it starts to say so you run LDA you think is a very cool tool, and then you pick the number of topics you create these topics and then most of them do not make sense.",
            "You look at them and these are like words Co occurring together.",
            "Some of these topics are nice, others you know it's just a mixture of word.",
            "Then you change the number of topics and everything is gone and you have new topics and they again do not make most of the sensor.",
            "It's quite hard to use and quite hard to evaluate what you're getting out of it, OK?",
            "And then you start cherry picking things and say, OK, I kind of like this topic and so let's take this one and take that one and let's drop out all the rest.",
            "OK, so, because of all these problems, I started discussing with my master students and I wanted to provide that a different collection in order to support the evaluation of topic detection method.",
            "Both supervisor and supervisor.",
            "OK, so this is a very initial work that I want to continue doing during the next 3 four years while being my name.",
            "But I'm presenting it today so you can give me some feedback so we can start.",
            "King about this together and things like this, OK?"
        ],
        [
            "So we decided to focus on the answer carbon and a very small part of the answer corpus.",
            "Because we are collaborating with social scientists in man, I'm focusing on, well, Brexit.",
            "As you may imagine, by the years that we are analyzing an, we decided to use this because there are topics highlighted regarding each of the discussions.",
            "OK and."
        ],
        [
            "So, OK, you know that the answer corpus is way larger, but for the moment we're only using the last part of it."
        ],
        [
            "And we have aligned all the topics for all the discussion with their related Wikipedia page.",
            "When it's possible that there are some issues here and there.",
            "So for example, you have the topic."
        ],
        [
            "Exit and then you align with the related Wikipedia page of Brexit.",
            "This because then you want to.",
            "You can use semantic web technologies, and you can use the PDF for days and things like that.",
            "It's kind of an issue to do this already.",
            "We try to do it in an automatic way and the results are OK. We are redoing everything manually, will available will be very available very soon because there are different issues.",
            "So for example the topics could be very ambiguous.",
            "You can have health care as a topic, but it's actually healthcare in the UK.",
            "Not healthcare in general and then you can have overlapping topics so Brexit is expressed in many different ways, but it's always that OK or we have very specific problem like topics like feature is related to Brexit or you have like super fine grained things like Wi-Fi in hospitals as a topic of discussion and then you can't align it to Wikipedia and you if you try to align you get like a line to hospitals and the discussion is about something else.",
            "So there are many issues there.",
            "And so we started with this and what we provide are different ways of aligning it, and then you can pick whatever you prefer."
        ],
        [
            "And then we did.",
            "Entity will entity link the data set.",
            "So we spotted all the entities in all the speech."
        ],
        [
            "As."
        ],
        [
            "And align with their related Wikipedia entities.",
            "So you have every mention of Nigel Farage online with it and things like this.",
            "Again, we did this only on the years 2013 to 2016 because imagine if you want to do entity linking on speeches from the 19th century, well it will be way out there and already the entities that we're spotting are usually the more general entities.",
            "OK if there's something very specific or something very ambiguous.",
            "It's also very hard to spot."
        ],
        [
            "Some statistics on the data set so we have around 17,000 speeches and around 6000 topics.",
            "OK, so this is the collection that my students created during their master thesis and then we decided to present a benchmark of supervised and unsupervised method to approach it.",
            "OK, a set of baseline so we know more or less standard method they perform on this OK."
        ],
        [
            "Yeah, the first version is available on my website on the digital library of the University of Miami and we plan in the future to have like extended version that we want to align with the answered corpus at the at the moment if you want to get this small data set to compare what you're doing with what we would try to do, you can get it from there.",
            "OK, yeah, as you can see I'm not coming from a digital library background so but I'm usually doing in this case is very messy, but there's a Jason file with all the data if you want.",
            "Anne."
        ],
        [
            "OK, so first of all."
        ],
        [
            "Supervised approach OK. You have some speeches where you know the topic and you want to classify other speeches.",
            "With the correct topic OK?",
            "So this is like supervised machine learning classification tenfold cross validation, things that if you're from NLP you know otherwise is you train on some documents and then you try to classify others OK."
        ],
        [
            "And you want to predict the correct one.",
            "OK, you want to say that document over there is also about Brexit, OK?",
            "Or this document over there is about the war in Syria for example."
        ],
        [
            "We tested a few different baseline different document representation, all standard things in NLP."
        ],
        [
            "And what we found out is mostly that you know, as you may know in NLP, usually if you go with TF IDF Anna standard classifier that already performs OK and all the new fancy things actually explode when you try with something like this.",
            "So we went with word embeddings and entity embeddings and everything became incredibly noisy because we were taking this long text, averaging all the embeddings in it, creating an average embedding, classifying by that and it was that he wasn't working at all.",
            "But these are all initial experiments.",
            "But if you want to work on this, you know that that's the baseline.",
            "OK, we reached more or less that point.",
            "I have a student now working also on neural approaches doing training a CNN for doing this, but we don't have enough data for that.",
            "OK, at the moment it doesn't work.",
            "We're trying to expand the corpus and have more training data, but we have way too many topics at the moment, so it's kind of art.",
            "But still, if you are interested in this, drop me an email we can try to collaborate on this."
        ],
        [
            "And then Hero work on unsupervised approach and topic rank."
        ],
        [
            "So in our case, she was taking a document, a speech with all the entities in it and she wanted to predict the topic which is also."
        ],
        [
            "Entity, so imagine you have a speech saying Nigel Farage, London, European Union, Brexit and you want to say the topic is probably Brexit.",
            "OK, what she found out?"
        ],
        [
            "And it's in line with previous research on entity salience and things like that is around only 20% of the documents mentioned.",
            "The topic that is assigned to it in the text most of the time you're talking, for example, about Brexit without same Brexit.",
            "Because you are saying the referendum or you're saying all the previous deal with the European.",
            "You're not mentioning Brexit.",
            "You can say that this is you can address this with fine grained entity linker but still.",
            "If you want to do entity salience or topic ranking, it's kind of hard.",
            "If you don't mention the topic in the text, OK. At."
        ],
        [
            "So she moved on and she tried different baselines, trying to rank entities mentioning document by frequency by weighted frequency, computing the centroid, and then she took Ristic from previous work on entity saliency, where they were saying that usually this is based on as an autistic on news, and they were saying, oh, if you take a news article, the topic is usually mentioned in the first couple of sentences, so you just read the first couple of sentences and you know the topic and you said, well, let's see.",
            "This work on parliamentary speeches because, well, we presume it wasn't.",
            "It will not work at all any."
        ],
        [
            "It doesn't work at all because the first few sentences that usually not mentioned in the topic as we just seen in presentation before they're discussing addressing what someone said before an putting all this long introduction and then the topic comes a bit later.",
            "Or maybe doesn't even come out at all.",
            "OK, maybe they start speaking about something completely different, and so as you can see again, we're setting only the baseline here, and we're saying at the moment if you just go with easier Ristic, just counting the entities and taking the most frequent entities.",
            "You are getting more or less there with the topic, but this is a starting point.",
            "So what we will work on with the menu."
        ],
        [
            "Master student and maybe with Mahmoud and hero if they want is to expand this set of."
        ],
        [
            "This line extended data set diachronically, so having more and more speeches annotated.",
            "And here we have lots of problem entity linking aligning the topics.",
            "And things like this.",
            "Anne.",
            "Expanded baseline, so having way more baseline.",
            "If you have any ideas of something to suggest, let's discuss about it.",
            "An aligning with other resources.",
            "There will be a presentation later on sentiment analysis on the same data, and so it would be interesting to see the differences and the comparison and maybe doing some topic based sentiment analysis and see the results so."
        ],
        [
            "That's it from me.",
            "If you have any question or suggestion here, thanks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Time and so they can.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Honey, I'm from the University of Mannheim and I'm presenting today at joint work that I did together with Simona Ponsetto, Laura Dietz and two of my Masters student Mahmoud Osman, an hero, China.",
                    "label": 1
                },
                {
                    "sent": "You will hear me speaking quite a lot because also this afternoon I'll be presenting another paper.",
                    "label": 0
                },
                {
                    "sent": "Then I'm involving a panel, so sorry for my like strong Italian accent is like something that you have to deal with today so I.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm a postdoc since 6 seven months ago in computational social science at the University of Mannheim, where I'm working on NLP.",
                    "label": 1
                },
                {
                    "sent": "Application is in order to support political science research.",
                    "label": 0
                },
                {
                    "sent": "OK, I did something similar during my PhD where I was working in collaboration with historians and so it was again NLP application.",
                    "label": 0
                },
                {
                    "sent": "In order to support historical research, especially in the use of web archive.",
                    "label": 0
                },
                {
                    "sent": "And now I'm focusing mostly on topic detection on collection building especially.",
                    "label": 0
                },
                {
                    "sent": "Bayes collection building an intact scaling.",
                    "label": 0
                },
                {
                    "sent": "I'll speak about tech scaling in this afternoon.",
                    "label": 0
                },
                {
                    "sent": "Today I will.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now I'll focus on mostly on topic detection, because it's kind of essential when you're doing or you would like to do automatic analysis of political speeches because you want to start by detecting the topics, and because we want to do exploration.",
                    "label": 0
                },
                {
                    "sent": "For example, you want to do topic based argumentation mining, understand what politicians are discussing about or in general because we want to understand which are the most relevant topics in a corpus.",
                    "label": 0
                },
                {
                    "sent": "So for example, just like.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Quick example made by the Atlantic on the state of the Union address is in in the US.",
                    "label": 0
                },
                {
                    "sent": "Here you can see how the topic war has been relevant in the state of the Union.",
                    "label": 1
                },
                {
                    "sent": "Addresses over the years and as you can see there's a huge spike around the Second World War.",
                    "label": 0
                },
                {
                    "sent": "Same thing.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For the topping, employment, and year you can see two different spikes around the crisis in the 20s and in the 70s and the topic.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Health and you can see a spike at the very end during the Obama.",
                    "label": 0
                },
                {
                    "sent": "Here.",
                    "label": 0
                },
                {
                    "sent": "There are no state of the union addresses by Donald Trump because it was made in 2015.",
                    "label": 1
                },
                {
                    "sent": "So you can see the impact of these and the growth of like the immigration topic.",
                    "label": 0
                },
                {
                    "sent": "For example lacking.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But there is a problem.",
                    "label": 0
                },
                {
                    "sent": "OK, this kind of research are like pretty useful, but generally the collection that we're providing to the Community do not have topic annotation at the document level.",
                    "label": 1
                },
                {
                    "sent": "OK, so we have all these beautiful speeches with all the metadata, and often we don't know what are the topics that have been addressed in the documents.",
                    "label": 0
                },
                {
                    "sent": "OK, and so the problem that then political scientists or humanities researchers will?",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Use unsupervised methods for doing this, like LDA.",
                    "label": 0
                },
                {
                    "sent": "There was a presentation this morning using let and directly allocation an if you have experience with LDA, so topic models, it's kind of a cool tool for doing quick corpus exploration, but then when you want to move from that to doing real analysis well.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The results are pretty messy, so it starts to say so you run LDA you think is a very cool tool, and then you pick the number of topics you create these topics and then most of them do not make sense.",
                    "label": 0
                },
                {
                    "sent": "You look at them and these are like words Co occurring together.",
                    "label": 0
                },
                {
                    "sent": "Some of these topics are nice, others you know it's just a mixture of word.",
                    "label": 0
                },
                {
                    "sent": "Then you change the number of topics and everything is gone and you have new topics and they again do not make most of the sensor.",
                    "label": 0
                },
                {
                    "sent": "It's quite hard to use and quite hard to evaluate what you're getting out of it, OK?",
                    "label": 1
                },
                {
                    "sent": "And then you start cherry picking things and say, OK, I kind of like this topic and so let's take this one and take that one and let's drop out all the rest.",
                    "label": 0
                },
                {
                    "sent": "OK, so, because of all these problems, I started discussing with my master students and I wanted to provide that a different collection in order to support the evaluation of topic detection method.",
                    "label": 0
                },
                {
                    "sent": "Both supervisor and supervisor.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is a very initial work that I want to continue doing during the next 3 four years while being my name.",
                    "label": 0
                },
                {
                    "sent": "But I'm presenting it today so you can give me some feedback so we can start.",
                    "label": 0
                },
                {
                    "sent": "King about this together and things like this, OK?",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we decided to focus on the answer carbon and a very small part of the answer corpus.",
                    "label": 0
                },
                {
                    "sent": "Because we are collaborating with social scientists in man, I'm focusing on, well, Brexit.",
                    "label": 0
                },
                {
                    "sent": "As you may imagine, by the years that we are analyzing an, we decided to use this because there are topics highlighted regarding each of the discussions.",
                    "label": 0
                },
                {
                    "sent": "OK and.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So, OK, you know that the answer corpus is way larger, but for the moment we're only using the last part of it.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we have aligned all the topics for all the discussion with their related Wikipedia page.",
                    "label": 1
                },
                {
                    "sent": "When it's possible that there are some issues here and there.",
                    "label": 0
                },
                {
                    "sent": "So for example, you have the topic.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Exit and then you align with the related Wikipedia page of Brexit.",
                    "label": 1
                },
                {
                    "sent": "This because then you want to.",
                    "label": 0
                },
                {
                    "sent": "You can use semantic web technologies, and you can use the PDF for days and things like that.",
                    "label": 0
                },
                {
                    "sent": "It's kind of an issue to do this already.",
                    "label": 0
                },
                {
                    "sent": "We try to do it in an automatic way and the results are OK. We are redoing everything manually, will available will be very available very soon because there are different issues.",
                    "label": 0
                },
                {
                    "sent": "So for example the topics could be very ambiguous.",
                    "label": 0
                },
                {
                    "sent": "You can have health care as a topic, but it's actually healthcare in the UK.",
                    "label": 0
                },
                {
                    "sent": "Not healthcare in general and then you can have overlapping topics so Brexit is expressed in many different ways, but it's always that OK or we have very specific problem like topics like feature is related to Brexit or you have like super fine grained things like Wi-Fi in hospitals as a topic of discussion and then you can't align it to Wikipedia and you if you try to align you get like a line to hospitals and the discussion is about something else.",
                    "label": 0
                },
                {
                    "sent": "So there are many issues there.",
                    "label": 0
                },
                {
                    "sent": "And so we started with this and what we provide are different ways of aligning it, and then you can pick whatever you prefer.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we did.",
                    "label": 0
                },
                {
                    "sent": "Entity will entity link the data set.",
                    "label": 0
                },
                {
                    "sent": "So we spotted all the entities in all the speech.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And align with their related Wikipedia entities.",
                    "label": 1
                },
                {
                    "sent": "So you have every mention of Nigel Farage online with it and things like this.",
                    "label": 0
                },
                {
                    "sent": "Again, we did this only on the years 2013 to 2016 because imagine if you want to do entity linking on speeches from the 19th century, well it will be way out there and already the entities that we're spotting are usually the more general entities.",
                    "label": 1
                },
                {
                    "sent": "OK if there's something very specific or something very ambiguous.",
                    "label": 0
                },
                {
                    "sent": "It's also very hard to spot.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Some statistics on the data set so we have around 17,000 speeches and around 6000 topics.",
                    "label": 1
                },
                {
                    "sent": "OK, so this is the collection that my students created during their master thesis and then we decided to present a benchmark of supervised and unsupervised method to approach it.",
                    "label": 0
                },
                {
                    "sent": "OK, a set of baseline so we know more or less standard method they perform on this OK.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yeah, the first version is available on my website on the digital library of the University of Miami and we plan in the future to have like extended version that we want to align with the answered corpus at the at the moment if you want to get this small data set to compare what you're doing with what we would try to do, you can get it from there.",
                    "label": 1
                },
                {
                    "sent": "OK, yeah, as you can see I'm not coming from a digital library background so but I'm usually doing in this case is very messy, but there's a Jason file with all the data if you want.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so first of all.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Supervised approach OK. You have some speeches where you know the topic and you want to classify other speeches.",
                    "label": 0
                },
                {
                    "sent": "With the correct topic OK?",
                    "label": 0
                },
                {
                    "sent": "So this is like supervised machine learning classification tenfold cross validation, things that if you're from NLP you know otherwise is you train on some documents and then you try to classify others OK.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And you want to predict the correct one.",
                    "label": 0
                },
                {
                    "sent": "OK, you want to say that document over there is also about Brexit, OK?",
                    "label": 0
                },
                {
                    "sent": "Or this document over there is about the war in Syria for example.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We tested a few different baseline different document representation, all standard things in NLP.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And what we found out is mostly that you know, as you may know in NLP, usually if you go with TF IDF Anna standard classifier that already performs OK and all the new fancy things actually explode when you try with something like this.",
                    "label": 0
                },
                {
                    "sent": "So we went with word embeddings and entity embeddings and everything became incredibly noisy because we were taking this long text, averaging all the embeddings in it, creating an average embedding, classifying by that and it was that he wasn't working at all.",
                    "label": 0
                },
                {
                    "sent": "But these are all initial experiments.",
                    "label": 0
                },
                {
                    "sent": "But if you want to work on this, you know that that's the baseline.",
                    "label": 0
                },
                {
                    "sent": "OK, we reached more or less that point.",
                    "label": 0
                },
                {
                    "sent": "I have a student now working also on neural approaches doing training a CNN for doing this, but we don't have enough data for that.",
                    "label": 0
                },
                {
                    "sent": "OK, at the moment it doesn't work.",
                    "label": 0
                },
                {
                    "sent": "We're trying to expand the corpus and have more training data, but we have way too many topics at the moment, so it's kind of art.",
                    "label": 0
                },
                {
                    "sent": "But still, if you are interested in this, drop me an email we can try to collaborate on this.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then Hero work on unsupervised approach and topic rank.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in our case, she was taking a document, a speech with all the entities in it and she wanted to predict the topic which is also.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Entity, so imagine you have a speech saying Nigel Farage, London, European Union, Brexit and you want to say the topic is probably Brexit.",
                    "label": 0
                },
                {
                    "sent": "OK, what she found out?",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And it's in line with previous research on entity salience and things like that is around only 20% of the documents mentioned.",
                    "label": 0
                },
                {
                    "sent": "The topic that is assigned to it in the text most of the time you're talking, for example, about Brexit without same Brexit.",
                    "label": 0
                },
                {
                    "sent": "Because you are saying the referendum or you're saying all the previous deal with the European.",
                    "label": 0
                },
                {
                    "sent": "You're not mentioning Brexit.",
                    "label": 0
                },
                {
                    "sent": "You can say that this is you can address this with fine grained entity linker but still.",
                    "label": 0
                },
                {
                    "sent": "If you want to do entity salience or topic ranking, it's kind of hard.",
                    "label": 0
                },
                {
                    "sent": "If you don't mention the topic in the text, OK. At.",
                    "label": 1
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So she moved on and she tried different baselines, trying to rank entities mentioning document by frequency by weighted frequency, computing the centroid, and then she took Ristic from previous work on entity saliency, where they were saying that usually this is based on as an autistic on news, and they were saying, oh, if you take a news article, the topic is usually mentioned in the first couple of sentences, so you just read the first couple of sentences and you know the topic and you said, well, let's see.",
                    "label": 0
                },
                {
                    "sent": "This work on parliamentary speeches because, well, we presume it wasn't.",
                    "label": 0
                },
                {
                    "sent": "It will not work at all any.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It doesn't work at all because the first few sentences that usually not mentioned in the topic as we just seen in presentation before they're discussing addressing what someone said before an putting all this long introduction and then the topic comes a bit later.",
                    "label": 0
                },
                {
                    "sent": "Or maybe doesn't even come out at all.",
                    "label": 0
                },
                {
                    "sent": "OK, maybe they start speaking about something completely different, and so as you can see again, we're setting only the baseline here, and we're saying at the moment if you just go with easier Ristic, just counting the entities and taking the most frequent entities.",
                    "label": 0
                },
                {
                    "sent": "You are getting more or less there with the topic, but this is a starting point.",
                    "label": 0
                },
                {
                    "sent": "So what we will work on with the menu.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Master student and maybe with Mahmoud and hero if they want is to expand this set of.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This line extended data set diachronically, so having more and more speeches annotated.",
                    "label": 1
                },
                {
                    "sent": "And here we have lots of problem entity linking aligning the topics.",
                    "label": 0
                },
                {
                    "sent": "And things like this.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "Expanded baseline, so having way more baseline.",
                    "label": 0
                },
                {
                    "sent": "If you have any ideas of something to suggest, let's discuss about it.",
                    "label": 1
                },
                {
                    "sent": "An aligning with other resources.",
                    "label": 0
                },
                {
                    "sent": "There will be a presentation later on sentiment analysis on the same data, and so it would be interesting to see the differences and the comparison and maybe doing some topic based sentiment analysis and see the results so.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's it from me.",
                    "label": 0
                },
                {
                    "sent": "If you have any question or suggestion here, thanks.",
                    "label": 0
                }
            ]
        }
    }
}