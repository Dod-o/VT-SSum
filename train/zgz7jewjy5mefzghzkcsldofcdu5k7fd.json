{
    "id": "zgz7jewjy5mefzghzkcsldofcdu5k7fd",
    "title": "Measuring Semantic Relatedness Across Languages",
    "info": {
        "author": [
            "Alistair Kennedy, Department of Computer Science, University of Toronto"
        ],
        "published": "Jan. 11, 2013",
        "recorded": "December 2012",
        "category": [
            "Top->Computer Science->Computational Linguistics->Machine Translation"
        ]
    },
    "url": "http://videolectures.net/nipsworkshops2012_kennedy_semantic_relatedness/",
    "segmentation": [
        [
            "So my name is Alistair Kennedy and I'm presenting measuring semantic relatedness across languages.",
            "So in this talk I'm going to create a distributional semantic relatedness measure that works between French and English and."
        ],
        [
            "For those of you who do speak French, I'm just going to apologize in advance for my accent and pronunciation.",
            "So distributional measures of semantic relatedness, basically they work on the principle that words that are related tend to appear in the same context.",
            "But this only makes sense between words in a single language.",
            "If you have two translations in two different languages, then they are unlikely to ever appear in the same context simply because they appear in language written or text written in their respective languages.",
            "So I'm going to come up with a method of mapping the context space from one language into another, often distributional, semantic, relatedness measures or semantic relatedness measures of any type work are evaluated using datasets in the style of Rubenstein and good enough where you're basically given a pair of words and human assigned similarity score, and you want your system to correlate's highly with the human scores as possible.",
            "So I'm going to create a new bilingual version out of two unilingual versions of that data set.",
            "And this is a fairly early work for us, but we think it will be useful for maybe machine translation and we have some plans to use it on cross language information retrieval and key point of this is that we're trying to do this without using a parallel corpus."
        ],
        [
            "So what do we mean by semantic relatedness example, but basically it's just the degree of similarity in meaning between 2 words.",
            "So in English it would be something like cat and feline or very similar cat and animal or less similar Captain hair dryer of almost nothing in common, and cat and math really unrelated.",
            "We want to do the same thing between words in English, an French so cat and shot would be very closely related, feline slightly less related and mathematic would be unrelated altogether."
        ],
        [
            "So how we build a unilingual measure?",
            "First we start by building a term context matrix which contains counts of how many times a word appears in a particular context.",
            "So contexts are just going to be neighboring words within a sliding window of five.",
            "So the word toast could be represented as a vector containing the words burnt, delicious butter, and so on.",
            "Like that, words that are likely to appear in the same context as it.",
            "We start with a weight matrix of just accounts of these Co occurrences and we re weight it using pointwise mutual information to find the dependency between a word in a context.",
            "This found generally to improve these measures quite a bit and we use cosine similarity to find the distance between 2 words or their relatedness.",
            "I guess between 2 words and we use the French and English Wikipedias as our corpus."
        ],
        [
            "So using this we can get vector representations of words like bread and jam will be fairly related.",
            "Pain would be much, much less related we want."
        ],
        [
            "Do this with French words as well where related words to pain would be much closer related.",
            "An example I was like is that pain and pen in French, meaning bread are spelled identically but are completely dissimilar so.",
            "We'd like to be able to capture this sort of thing within our measure.",
            "So how we go?"
        ],
        [
            "About doing this, so we start by building a translation matrix and translation matrix is just going to be a mapping from the context space in one language to another.",
            "So to do this, we start with a number of seed translations.",
            "We get these seed translations from 2 versions of Word net to the Free French Word Net, and Princeton Wordnet, which have been aligned.",
            "I know it's a perfect alignment.",
            "There's a number of cases where there's no translations of English words in the French version, but still using this we were able to extract up to 10,000 translations.",
            "What we then do is use these translations to figure out a weighted mapping between the contexts.",
            "So if two contexts, one in English and one in French, say Yellow and Joan tend to contain these, context tend to appear around words that are known to be translations of each other.",
            "Then we can deduce that this these two contexts you probably have a fairly strong mapping between each other.",
            "So what we do is we use the known translation set to basically measure the pointwise mutual information.",
            "Between context pairs in French and English, and this creates basically a matrix in the style of what we see up here.",
            "So."
        ],
        [
            "So we built a matrix like that.",
            "The next step is to do a mapping between the two languages.",
            "We mapped French contexts into English, so there's two thresholds that we examine when doing this.",
            "So we use the translation matrix.",
            "It's a many to many mapping, so every French context can be mapped into many different English contexts, so two thresholds that we looked at.",
            "One was a minimum PMI value, so."
        ],
        [
            "In the French translation Matrix, if the value."
        ],
        [
            "Between two contexts was above 1.0 or 2.0 or all the way up to 5.0.",
            "Then we would use that as a possible translation.",
            "The context is at 5 grand.",
            "The context is a context that we."
        ],
        [
            "Mr Actually just unigrams in this case, so it's any word within a space of five.",
            "We had some restrictions based on part of speech, but that was basically what we were working with, so an example of context to be yellow or bread or English and French versions would be Joan or Pan and on Glee."
        ],
        [
            "Um?",
            "So we're doing a mapping between these individual words, although in theory it could be done between a 5 gram as well, we're not actually directly translating the context, we're just translating them through the words that they appear beside.",
            "So we come up with five will test our method with five different PMI thresholds.",
            "We also have a lower bound threshold, so if because of French context can be mapped in multiple English ones, if that mapping results in a weight of less than .05, then we just ignore it.",
            "And the last step is to merge the two matrices together.",
            "Their translated French Matrix and the English matrix, which is really just a matter of labeling.",
            "Each word is either being from French or English."
        ],
        [
            "So how we evaluate this?",
            "So there's a number of datasets in the style of Reuben.",
            "Well, Rubenstein, good enough data set has been around for a good 40 years now, and recently some French and German versions have been created up these datasets.",
            "So these datasets consist of 65 word pairs with human assigned similarity scores ranging from zero to four.",
            "I'll show some examples in a second.",
            "So.",
            "In the translated versions, the word pairs are the same translations.",
            "However, new similarity scores have been assigned to them because I guess the similarity scores don't translate perfectly between languages.",
            "The experiments were redone in French.",
            "So what we did was we took every corresponding pair between the French and English versions that were within a score of plus minus one, and we used them to create 2 new English French pairs, bilingual pairs, and then we evaluated our cross language measure of semantic relatedness using Pearson's correlation, Spearman's correlation and Kendall's Tau.",
            "So Pearson's correlation might not make too much sense in this case because were the scores were coming up with or just averages of the French and English scores, so they're not really very precise.",
            "So we figure Spearman's correlation or kendals would make more sense.",
            "So."
        ],
        [
            "So just an example of what I'm talking about, so here's 4 examples from the French in English versions of Rubinstein, and good enough so for every corresponding French and English pair we can create 2 new translation pairs with the average scores.",
            "The examples in the bilingual set that are in italics where once we didn't use because the scores weren't within plus or minus one of each other.",
            "So."
        ],
        [
            "With this in mind, we used our new cross language measure and.",
            "As a baseline, we used the unilingual French in English measures as well or measures of semantic relatedness.",
            "The reason why we chose those as our baselines is just that there is a fair amount of overlap between English and French, and we didn't want to assume that zero would be the actual correlation.",
            "That you would get on a bilingual data set.",
            "So the good news is our system had a correlation much better than our unilingual baselines.",
            "We got scores as high as over .3, and our best threshold best PMI threshold for measure was around 2.0, although values of one and three weren't too bad started to decline quite a bit by the time we reached 5."
        ],
        [
            "So in conclusion, we've created a new cross language measure of semantic relatedness and put together a data set for evaluating that, and our experiments showed that our system works reasonably well and that we have the best PMI threshold of 2.0, so we've tuned it to least to this data set.",
            "For future work, would like to work with other languages, particularly German, since there is already a German version of the Rubenstein and good enough data set.",
            "We also think using LSA would make a big difference and actually tried this already.",
            "Just applying it on top of our cross language matrix, one of the big problems is that the French portion of the Matrix tends to be much, much more dense than the English portion, so LSA will give you a more uniform density into the matrix and boosts results quite a bit.",
            "And we're also looking at new applications of this, and we want to experiment with different sources and quantities of seed translations."
        ],
        [
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So my name is Alistair Kennedy and I'm presenting measuring semantic relatedness across languages.",
                    "label": 0
                },
                {
                    "sent": "So in this talk I'm going to create a distributional semantic relatedness measure that works between French and English and.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For those of you who do speak French, I'm just going to apologize in advance for my accent and pronunciation.",
                    "label": 0
                },
                {
                    "sent": "So distributional measures of semantic relatedness, basically they work on the principle that words that are related tend to appear in the same context.",
                    "label": 1
                },
                {
                    "sent": "But this only makes sense between words in a single language.",
                    "label": 0
                },
                {
                    "sent": "If you have two translations in two different languages, then they are unlikely to ever appear in the same context simply because they appear in language written or text written in their respective languages.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to come up with a method of mapping the context space from one language into another, often distributional, semantic, relatedness measures or semantic relatedness measures of any type work are evaluated using datasets in the style of Rubenstein and good enough where you're basically given a pair of words and human assigned similarity score, and you want your system to correlate's highly with the human scores as possible.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to create a new bilingual version out of two unilingual versions of that data set.",
                    "label": 1
                },
                {
                    "sent": "And this is a fairly early work for us, but we think it will be useful for maybe machine translation and we have some plans to use it on cross language information retrieval and key point of this is that we're trying to do this without using a parallel corpus.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what do we mean by semantic relatedness example, but basically it's just the degree of similarity in meaning between 2 words.",
                    "label": 0
                },
                {
                    "sent": "So in English it would be something like cat and feline or very similar cat and animal or less similar Captain hair dryer of almost nothing in common, and cat and math really unrelated.",
                    "label": 1
                },
                {
                    "sent": "We want to do the same thing between words in English, an French so cat and shot would be very closely related, feline slightly less related and mathematic would be unrelated altogether.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how we build a unilingual measure?",
                    "label": 0
                },
                {
                    "sent": "First we start by building a term context matrix which contains counts of how many times a word appears in a particular context.",
                    "label": 0
                },
                {
                    "sent": "So contexts are just going to be neighboring words within a sliding window of five.",
                    "label": 0
                },
                {
                    "sent": "So the word toast could be represented as a vector containing the words burnt, delicious butter, and so on.",
                    "label": 0
                },
                {
                    "sent": "Like that, words that are likely to appear in the same context as it.",
                    "label": 0
                },
                {
                    "sent": "We start with a weight matrix of just accounts of these Co occurrences and we re weight it using pointwise mutual information to find the dependency between a word in a context.",
                    "label": 0
                },
                {
                    "sent": "This found generally to improve these measures quite a bit and we use cosine similarity to find the distance between 2 words or their relatedness.",
                    "label": 0
                },
                {
                    "sent": "I guess between 2 words and we use the French and English Wikipedias as our corpus.",
                    "label": 1
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So using this we can get vector representations of words like bread and jam will be fairly related.",
                    "label": 0
                },
                {
                    "sent": "Pain would be much, much less related we want.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Do this with French words as well where related words to pain would be much closer related.",
                    "label": 0
                },
                {
                    "sent": "An example I was like is that pain and pen in French, meaning bread are spelled identically but are completely dissimilar so.",
                    "label": 0
                },
                {
                    "sent": "We'd like to be able to capture this sort of thing within our measure.",
                    "label": 0
                },
                {
                    "sent": "So how we go?",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "About doing this, so we start by building a translation matrix and translation matrix is just going to be a mapping from the context space in one language to another.",
                    "label": 1
                },
                {
                    "sent": "So to do this, we start with a number of seed translations.",
                    "label": 1
                },
                {
                    "sent": "We get these seed translations from 2 versions of Word net to the Free French Word Net, and Princeton Wordnet, which have been aligned.",
                    "label": 0
                },
                {
                    "sent": "I know it's a perfect alignment.",
                    "label": 0
                },
                {
                    "sent": "There's a number of cases where there's no translations of English words in the French version, but still using this we were able to extract up to 10,000 translations.",
                    "label": 0
                },
                {
                    "sent": "What we then do is use these translations to figure out a weighted mapping between the contexts.",
                    "label": 0
                },
                {
                    "sent": "So if two contexts, one in English and one in French, say Yellow and Joan tend to contain these, context tend to appear around words that are known to be translations of each other.",
                    "label": 0
                },
                {
                    "sent": "Then we can deduce that this these two contexts you probably have a fairly strong mapping between each other.",
                    "label": 0
                },
                {
                    "sent": "So what we do is we use the known translation set to basically measure the pointwise mutual information.",
                    "label": 0
                },
                {
                    "sent": "Between context pairs in French and English, and this creates basically a matrix in the style of what we see up here.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we built a matrix like that.",
                    "label": 0
                },
                {
                    "sent": "The next step is to do a mapping between the two languages.",
                    "label": 0
                },
                {
                    "sent": "We mapped French contexts into English, so there's two thresholds that we examine when doing this.",
                    "label": 0
                },
                {
                    "sent": "So we use the translation matrix.",
                    "label": 1
                },
                {
                    "sent": "It's a many to many mapping, so every French context can be mapped into many different English contexts, so two thresholds that we looked at.",
                    "label": 1
                },
                {
                    "sent": "One was a minimum PMI value, so.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the French translation Matrix, if the value.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Between two contexts was above 1.0 or 2.0 or all the way up to 5.0.",
                    "label": 0
                },
                {
                    "sent": "Then we would use that as a possible translation.",
                    "label": 0
                },
                {
                    "sent": "The context is at 5 grand.",
                    "label": 0
                },
                {
                    "sent": "The context is a context that we.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Mr Actually just unigrams in this case, so it's any word within a space of five.",
                    "label": 0
                },
                {
                    "sent": "We had some restrictions based on part of speech, but that was basically what we were working with, so an example of context to be yellow or bread or English and French versions would be Joan or Pan and on Glee.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So we're doing a mapping between these individual words, although in theory it could be done between a 5 gram as well, we're not actually directly translating the context, we're just translating them through the words that they appear beside.",
                    "label": 0
                },
                {
                    "sent": "So we come up with five will test our method with five different PMI thresholds.",
                    "label": 0
                },
                {
                    "sent": "We also have a lower bound threshold, so if because of French context can be mapped in multiple English ones, if that mapping results in a weight of less than .05, then we just ignore it.",
                    "label": 0
                },
                {
                    "sent": "And the last step is to merge the two matrices together.",
                    "label": 0
                },
                {
                    "sent": "Their translated French Matrix and the English matrix, which is really just a matter of labeling.",
                    "label": 0
                },
                {
                    "sent": "Each word is either being from French or English.",
                    "label": 1
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how we evaluate this?",
                    "label": 0
                },
                {
                    "sent": "So there's a number of datasets in the style of Reuben.",
                    "label": 0
                },
                {
                    "sent": "Well, Rubenstein, good enough data set has been around for a good 40 years now, and recently some French and German versions have been created up these datasets.",
                    "label": 0
                },
                {
                    "sent": "So these datasets consist of 65 word pairs with human assigned similarity scores ranging from zero to four.",
                    "label": 1
                },
                {
                    "sent": "I'll show some examples in a second.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "In the translated versions, the word pairs are the same translations.",
                    "label": 0
                },
                {
                    "sent": "However, new similarity scores have been assigned to them because I guess the similarity scores don't translate perfectly between languages.",
                    "label": 0
                },
                {
                    "sent": "The experiments were redone in French.",
                    "label": 1
                },
                {
                    "sent": "So what we did was we took every corresponding pair between the French and English versions that were within a score of plus minus one, and we used them to create 2 new English French pairs, bilingual pairs, and then we evaluated our cross language measure of semantic relatedness using Pearson's correlation, Spearman's correlation and Kendall's Tau.",
                    "label": 0
                },
                {
                    "sent": "So Pearson's correlation might not make too much sense in this case because were the scores were coming up with or just averages of the French and English scores, so they're not really very precise.",
                    "label": 0
                },
                {
                    "sent": "So we figure Spearman's correlation or kendals would make more sense.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So just an example of what I'm talking about, so here's 4 examples from the French in English versions of Rubinstein, and good enough so for every corresponding French and English pair we can create 2 new translation pairs with the average scores.",
                    "label": 0
                },
                {
                    "sent": "The examples in the bilingual set that are in italics where once we didn't use because the scores weren't within plus or minus one of each other.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With this in mind, we used our new cross language measure and.",
                    "label": 0
                },
                {
                    "sent": "As a baseline, we used the unilingual French in English measures as well or measures of semantic relatedness.",
                    "label": 0
                },
                {
                    "sent": "The reason why we chose those as our baselines is just that there is a fair amount of overlap between English and French, and we didn't want to assume that zero would be the actual correlation.",
                    "label": 0
                },
                {
                    "sent": "That you would get on a bilingual data set.",
                    "label": 0
                },
                {
                    "sent": "So the good news is our system had a correlation much better than our unilingual baselines.",
                    "label": 0
                },
                {
                    "sent": "We got scores as high as over .3, and our best threshold best PMI threshold for measure was around 2.0, although values of one and three weren't too bad started to decline quite a bit by the time we reached 5.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in conclusion, we've created a new cross language measure of semantic relatedness and put together a data set for evaluating that, and our experiments showed that our system works reasonably well and that we have the best PMI threshold of 2.0, so we've tuned it to least to this data set.",
                    "label": 0
                },
                {
                    "sent": "For future work, would like to work with other languages, particularly German, since there is already a German version of the Rubenstein and good enough data set.",
                    "label": 1
                },
                {
                    "sent": "We also think using LSA would make a big difference and actually tried this already.",
                    "label": 0
                },
                {
                    "sent": "Just applying it on top of our cross language matrix, one of the big problems is that the French portion of the Matrix tends to be much, much more dense than the English portion, so LSA will give you a more uniform density into the matrix and boosts results quite a bit.",
                    "label": 0
                },
                {
                    "sent": "And we're also looking at new applications of this, and we want to experiment with different sources and quantities of seed translations.",
                    "label": 1
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}