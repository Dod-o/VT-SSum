{
    "id": "n74f7okbqqnb4qrvexfn4mpwixqcrxpo",
    "title": "Strategy Evaluation in Extensive Games with Importance Sampling",
    "info": {
        "author": [
            "Michael Johanson, Department of Computing Science, University of Alberta"
        ],
        "published": "Aug. 7, 2008",
        "recorded": "July 2008",
        "category": [
            "Top->Computer Science->Machine Learning->Monte Carlo Methods"
        ]
    },
    "url": "http://videolectures.net/icml08_johanson_see/",
    "segmentation": [
        [
            "Hi so I'm like Johansson.",
            "I'm from the UK's computer Poker research group.",
            "I'm going to start with some really exciting news that."
        ],
        [
            "Up in 2 days ago I actually just flew in on the six from Las Vegas or Research Group.",
            "Played a man machine competition against six professionals at poker.",
            "These guys play heads up limit Poker, so two player limit.",
            "It's not quite like you see on TV, but it's a very serious game.",
            "Humans play for money.",
            "Our program, named Polaris, played six 500 matches.",
            "We went up with three wins, two losses and one tie, so it's a win for AI, and we think this is kind of a crossover point.",
            "Program should be able to beat the best human players of this game.",
            "From here on and the research I'm going to talk about today played a critical role."
        ],
        [
            "Owner success.",
            "So here's the problem.",
            "We're trying to address, so if you're playing against this is Metrolink.",
            "Oh on the left and Jay forget his last name on the right.",
            "Both these guys make about $6000 per hour on expectation.",
            "Playing online poker, right?",
            "So there are some of the best in the world.",
            "So if you're going to match like this, you might have several candidate programs you're going to use to play the game.",
            "And you might only have samples of any one of them playing against strong opponents and the samples you have might not even have full information.",
            "If you're playing a game like poker, then there's hidden information or private information.",
            "For example, you might not know their cards."
        ],
        [
            "Even after the fact.",
            "So there's two problems we want to solve.",
            "The first problem is if we have these samples of 1 strategy, how can we evaluate how all the other strategies would do against these opponents?"
        ],
        [
            "And the second problem is, how can we reduce as much of the variance as possible from our result so we can make good choices."
        ],
        [
            "So our solution we're going to propose using important sampling to evaluate other strategies that didn't even play the game.",
            "Our approach can be combined with existing estimators to reduce the variance further and the main contribution of our talk is this Third Point.",
            "We're going to show how to create synthetic data so you can observe one hand, but then look at a couple thousand more situations.",
            "You can evaluate where the opponent had to do the same thing.",
            "The assumption we're making we're playing a static opponent, so playing as humans that's not true, but it seems to work fairly well in practice.",
            "There's actually 8 different cases that discovers we're only going to talk about two.",
            "In the talk, we mentioned four in the paper.",
            "The big to hear this on policy and off policy.",
            "UN policy means you're looking at sample hands of our program, playing someone else, or your program.",
            "For any game playing at any other opponent.",
            "Off policy means you're trying to evaluate a strategy that you haven't even seen.",
            "Play the game.",
            "On the other axis here we have perfect information, meaning that you get to see all the information after the fact and partial information.",
            "Which means you might not have all the information in the talk were just doing this row.",
            "The paper discusses this one.",
            "The other axis is online versus offline learning.",
            "We're just doing offline learning for the talk and the paper, but this does work for online as well and I'll give a clue of that at the."
        ],
        [
            "Slide.",
            "Sore framework is we work in repeated extensive form games.",
            "So if you're playing a game like poker, you're going to do several.",
            "What many maybe 500 or 1000 or so, repeated games each game.",
            "This is an extensive form game, so it has you and your opponent, or taking actions throughout the game tree.",
            "The added twist for games like Poker is that there's hidden information.",
            "So here for example, if we were dealt these cards or opponent were dealt either this set of cards or this set of cards, we don't actually know what game State we're in, right?",
            "They could have this, or they could have that, and so we need to have a strategy that plays the same way in both of these situations.",
            "Just because we can't differentiate them.",
            "The red squares at the top are terminal nodes.",
            "Those we get payoff."
        ],
        [
            "So I've already used the term strategy several times.",
            "So what I mean by strategy is.",
            "For each information set, for each of these cases that you can't tell apart if it's your turn to act, a strategy is the distribution of probability distribution over your actions.",
            "So, for example, if you're here, you might have a 20% chance of choosing action a, an 80% chance of choosing Action B.",
            "And Sigma I represents the strategy for player I.",
            "And Sigma is a strategy profile that just means it's a one strategy for each player."
        ],
        [
            "And the last bit of notation here before we get to the fun stuff.",
            "Pi Sigma is the probability of the strategy profile.",
            "That's all the players reaching a certain terminal history.",
            "History is just one path through the tree.",
            "\u03a0 Sigma I is 1 player's contribution to that probability.",
            "So for example, if I'm player I then Pi Sigma is just the product of my probabilities.",
            "And Pi Sigma minus I is everyone else is probabilities everyone but player I."
        ],
        [
            "OK, getting into interesting stuff.",
            "So the usual way you would evaluate one strategy playing it's another strategy, assuming that you don't know what your opponent is actually going to do is, you can just do Monte Carlo estimation so you play a whole bunch of hands and you evaluate the score after every hand, and you take the mean and there you go.",
            "What we're going to do with important sampling is fairly similar to this.",
            "Important sampling is a well known technique for.",
            "If you have two distributions and maybe one is expensive to sample from and one is easy to sample from, you can find the expected value of the expensive one by drawing samples from the simple one."
        ],
        [
            "So here's the trick for this.",
            "We're going to have two strategy profiles.",
            "The first one, Sigma, is the strategy profile that contains a strategy we want to evaluate.",
            "And the second one, Sigma hat, contains the strategy that we actually observed playing.",
            "So this is against the same opponent.",
            "The only thing that changed is what strategy of ours is in the seat.",
            "And if you're doing online learning or sorry on policy, then Sigma and Sigma had are the same.",
            "So it's just the same strategy on both sides.",
            "So this first part looks just like Monte Carlo sampling.",
            "The difference here is the waiting term.",
            "So here we have \u03c0 Sigma over \u03c0 Sigma hat, so this is again your probability of reaching a terminal node.",
            "The trick that we're doing here is that you can separate Pi Sigma into the probability that we go to a terminal node, and the probability that everything else, the opponent, and the chance player contribute towards getting there.",
            "And since the only thing that changes between \u03c0 Sigma and Pi Sigma hat is our strategy.",
            "These are actually the same right?",
            "Everyone else is.",
            "Probability is the same on the top and the bottom, so that cancels out and then we get this nice term that we can compute using only our strategy.",
            "And so if you use this waiting term and.",
            "This value function.",
            "Then you can get the expected value for player that wasn't even in the game.",
            "So this seems kind of magic so far."
        ],
        [
            "Anyway, it is because if you do this just as is, you end up with very high variance estimate of the other player.",
            "An lots of bias so.",
            "The rest of the talk we had."
        ],
        [
            "Best ways to fix that?",
            "One way is you can just use a different value function."
        ],
        [
            "Here for example.",
            "If you're doing Monte Carlo estimation, you might just be using the money you win or something like that as your value."
        ],
        [
            "Function but you can sub in something else.",
            "For example, in poker there's this function called the divett function that gives a low variance estimate just by rolling out cards.",
            "So you can do something like that."
        ],
        [
            "But the main contribution of our talk, like I mentioned before, is creating synthetic data."
        ],
        [
            "So how can you do that?",
            "So after you observe some terminal history, you can imagine that something else might have happened instead."
        ],
        [
            "So to give it some notation, if you let zed be the set of thermal histories that you can imagine that if you see some terminal history said, let's imagine we have some mapping that takes that and it gives us a set of thermal histories such that every time we said we can evaluate all of the terminal histories in that set."
        ],
        [
            "And we have the inverse as well where.",
            "You said is if you see a member of that, you can evaluate said.",
            "The trick here is that if you choose you carefully, then you can make it depend.",
            "Sorry you can make it not.",
            "You make the opponent strategy not depend on the terminal histories that you get out, which means you can still do that trick where you cancel above and below an important sampling, and so we have two examples of this.",
            "The first one is called game ending actions, the second was called."
        ],
        [
            "Other private information.",
            "So game ending actions first.",
            "So let's imagine you know this is our game that we played, and let's imagine we observe that history up in the top right corner there, right?",
            "So this is we were dealt.",
            "These cards are opponent got these cards.",
            "We chose the action on the right, which might be to call about or something like that.",
            "Then they call an we lose money."
        ],
        [
            "So you can kind of equally.",
            "Imagine that if I got to hear this time, I happened to choose the right path and I lost money, but I could have chosen the left path, which in poker might be folding for example.",
            "Or anything that ends the game immediately, right?",
            "If you had done that, your opponent doesn't have a chance to respond, so they couldn't have done anything different, and so you get a different payoff.",
            "So every time you see the top right one, you can also imagine that you went down this other path."
        ],
        [
            "This is the equation for it.",
            "The proof is in the paper, but it's probably unbiased if you're in the on policy full information case, so you're just getting more samples, so reducing the variance."
        ],
        [
            "The other example is this one called private information or other private information.",
            "So just like before, we imagined that we could have folded.",
            "This time you can imagine that you got different private information like you can imagine you were dealt different cards.",
            "If you're dealt different cards and your opponent doesn't see them, they could have acted any differently and now you can generate more samples that you can evaluate.",
            "So here for example, maybe we were dealt this set of cards and we lost, but we could have imagined.",
            "Well I would have done the same thing with better cards and my opponent had to play the same way.",
            "And so."
        ],
        [
            "They get more samples to evaluate.",
            "In a game like Texas Hold'em Poker 2375 more samples every time."
        ],
        [
            "Play hand."
        ],
        [
            "So again, there's the equation.",
            "Again, this is probably unbiased in the on policy full information case.",
            "The neat thing too is that all of these can be combined.",
            "You can do game ending actions and other private information at the same time, so you can get 5 or 6000 more samples.",
            "You can combine that with another value estimate so you get a low variance estimate on top of."
        ],
        [
            "All of this.",
            "So here's some results I can show you how well this works.",
            "What we did was we have several other poker programs and we played sets of million hands between them.",
            "So what we've done here, this section of the top we played one of our programs called S 2298 against another program.",
            "And we're trying to evaluate it using data that it actually played, right?",
            "So that's on policy.",
            "This one here is we're trying to evaluate a different program called CFR 8, not using data that it played.",
            "We're trying to evaluate it using the data from the other program, from S2298.",
            "The really interesting column here is the standard deviation column.",
            "Sir biggest concern is just getting the variance down, so at the top of the center deviation column, the first number that 5103.",
            "That's just Monte Carlo estimation, so that kind of gives you a feel for how much variance is in the game without doing these tricks.",
            "As you go down the column you see using this devt function that I mentioned before that takes off some of the variants.",
            "Hughes game ending actions.",
            "It doesn't do much on its own private information, brings the variance down a little, but then we start combining these right.",
            "So now we're down to 2000.",
            "If you put together all the tricks, now you're at about 1800 for the center deviation down from 5100, so we have a much lower variance result.",
            "I mentioned earlier that if you just did basic important sampling, then you had a lot of variance, right?",
            "So that's a lot of variance.",
            "But again, for the off policy case, once you add in all your tricks, you can get down to very low variance for results.",
            "It has.",
            "No statistical or not a significant bias to it.",
            "The interesting thing about this number is that this player didn't even play the game.",
            "We never watched him play against this opponent, and yet we can estimate how well he does.",
            "Far better than if we actually watched him just play the game and just use Monte Carlo estimation.",
            "So that came down a lot."
        ],
        [
            "But we ran more experiments though, so this is just the summary table showing on policy and off policy, the maximum minimum that we observed.",
            "So again, overall over tests that we did write, the center deviation doesn't go up all that high.",
            "It's still far better to not watch the guy play and do all these tricks than if you just watched him play games."
        ],
        [
            "So I guess the conclusion is, is that this is a pretty neat technique.",
            "You can generate lots of data.",
            "We use this in the main machine competition that I mentioned at the start of the talk.",
            "This is my last slide here, so this is kind of neat prize at the end.",
            "Each line on the graph here is a different one of five strategies that we use during the match, and so this is after the match is over.",
            "Analyzing how well each of these players did, so we can actually track all of the lines and estimate.",
            "You know if this player had been in the match, we've done a lot worse than the one at the top, which is what actually got chosen an we did something like this for online learning during the match as well.",
            "Figure out which one to use at anytime.",
            "And that's my talk.",
            "Any questions?",
            "I see your solution seems to show off policy learning, whether with complete complete information or incomplete information.",
            "Missions are our best.",
            "I."
        ],
        [
            "Otherwise it's possible cause.",
            "I am in 2000 two 2002 thousand 2001 three Cup and suddenly they prove or positive learning is unbiased.",
            "So I wonder why this happened.",
            "OK yeah, so you mentioned perfect information and partial information.",
            "So in the talk I just talked about perfect.",
            "But you're right, even with perfect information, we still get a little bit of bias.",
            "The reason for that is the strategies don't all have the same support.",
            "They don't all go down the same path, so you might.",
            "For example, if you had two players you're trying to evaluate and one was always called, another one was always raised, since they have no actions that will go down in common, then you have no.",
            "You have no way of.",
            "Sorry, let me back up to the equation here."
        ],
        [
            "There we go.",
            "Yeah, So what this is relying on here when we do this?",
            "Is you have to choose some terminal history and you have to have some probability that both strategies would try to reach that history.",
            "So if you have always called and always raise then they have no histories in common and you just like one of these terms will be 0 and it will be this one 'cause the observed one always goes down at least one path right?",
            "So that's where this is coming from.",
            "If they don't have the same support, then you're going to have some cases where you can't evaluate them properly.",
            "In the full information case, it's pretty low.",
            "But that's mostly because we can toss in all the extra tricks of saying, well, if I had different cards, I would have gone down that same path.",
            "Or if I could have folded earlier, I would have gone down that same path.",
            "In the partial information case, the bias is quite a bit higher.",
            "It can be boat.",
            "I'll show you numbers to compare against."
        ],
        [
            "There we go in the personal information case, some of these bias terms can be about 100 or 150, so then it actually becomes a problem.",
            "So you have these five lines that show that."
        ],
        [
            "Any of your players have been in the match?",
            "They would inhuman statistically significantly is the lower 2 might not have been.",
            "Oh no, maybe.",
            "Yeah, OK. How correlated are those tests?",
            "In other words, are they going to be there?",
            "Presumably all right or all wrong?",
            "Yeah, they do tend to.",
            "As you can see from the graph, they go up and go down at the same points.",
            "No, mostly because you see some hand.",
            "In particular, there's a big spike here.",
            "They may have noticed this turns out to be if the opponent does something really, really dumb.",
            "All of your strategies think Who Will Win, so there are correlated, so you have to do more matches in order to really say.",
            "Yeah, for sure the way that we did these matches too is we did duplicate poker.",
            "Duplicate poker is where you have two humans in separate rooms and two copies of your program and you deal with the same cards in both rooms, but the opposite players.",
            "So the human in one room gets the same cards as the program in the other, and then you add the scores together.",
            "So that eliminates a lot of the luck as well.",
            "So actually if you do duplicate for the last match, this number goes down to 702.",
            "So just vote.",
            "Usually for I for told him we see a third deviation of about 6000.",
            "So go from 6000 down to 700 is.",
            "A pretty big drop.",
            "Anyone else?",
            "So probably the difficulty of these are ways that the variance grows exponentially with the number of steps in the game.",
            "So about how many steps with these games usually have prepared OK.",
            "So there's for the game we play, there's four rounds.",
            "Each round has between 2:00 and 5:00.",
            "Six actions.",
            "So probably anyone history like the one traced through the game tree is probably going to be.",
            "12 or 14 steps.",
            "So.",
            "What's the difference between?",
            "The difference between the five programs OK, each one of the five is a different game theoretic strategy.",
            "One of them.",
            "The red line here plays something.",
            "It plays closest to a Nash equilibrium strategy.",
            "The other lines are different tilts that we had on top of this we.",
            "Our equilibrium solver seems to handle non 0 sum games.",
            "I'm not sure that we've actually proven a properties voted, but you can give it a non 0 sum game and it does something reasonable.",
            "So here's what I mean by that this green line that's up top the best performer.",
            "This is what happens if you tell the solver is playing a game where every time it wins it gets a 7% bonus every time it loses, it takes the normal penalty, so this is non 0 sum.",
            "There's more money going into the pot, every hand, whoever wins gets this little bonus.",
            "But it winds up making the programs a lot more aggressive 'cause they think there's more money there.",
            "They're more willing to bet because they're expected payoff is better.",
            "And against humans it just does great rated really pushes them into uncomfortable situations.",
            "So all four of the lines that aren't red or different adjustments like this.",
            "They are either more aggressive or passive or more tight or loose.",
            "And if you play them all and you pick online which one to do, you can try to hone in on which robust strategy is going to exploit this point the most.",
            "Any other questions?",
            "Facebook, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Hi so I'm like Johansson.",
                    "label": 0
                },
                {
                    "sent": "I'm from the UK's computer Poker research group.",
                    "label": 1
                },
                {
                    "sent": "I'm going to start with some really exciting news that.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Up in 2 days ago I actually just flew in on the six from Las Vegas or Research Group.",
                    "label": 0
                },
                {
                    "sent": "Played a man machine competition against six professionals at poker.",
                    "label": 0
                },
                {
                    "sent": "These guys play heads up limit Poker, so two player limit.",
                    "label": 0
                },
                {
                    "sent": "It's not quite like you see on TV, but it's a very serious game.",
                    "label": 0
                },
                {
                    "sent": "Humans play for money.",
                    "label": 0
                },
                {
                    "sent": "Our program, named Polaris, played six 500 matches.",
                    "label": 1
                },
                {
                    "sent": "We went up with three wins, two losses and one tie, so it's a win for AI, and we think this is kind of a crossover point.",
                    "label": 0
                },
                {
                    "sent": "Program should be able to beat the best human players of this game.",
                    "label": 0
                },
                {
                    "sent": "From here on and the research I'm going to talk about today played a critical role.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Owner success.",
                    "label": 0
                },
                {
                    "sent": "So here's the problem.",
                    "label": 0
                },
                {
                    "sent": "We're trying to address, so if you're playing against this is Metrolink.",
                    "label": 0
                },
                {
                    "sent": "Oh on the left and Jay forget his last name on the right.",
                    "label": 0
                },
                {
                    "sent": "Both these guys make about $6000 per hour on expectation.",
                    "label": 0
                },
                {
                    "sent": "Playing online poker, right?",
                    "label": 0
                },
                {
                    "sent": "So there are some of the best in the world.",
                    "label": 0
                },
                {
                    "sent": "So if you're going to match like this, you might have several candidate programs you're going to use to play the game.",
                    "label": 0
                },
                {
                    "sent": "And you might only have samples of any one of them playing against strong opponents and the samples you have might not even have full information.",
                    "label": 1
                },
                {
                    "sent": "If you're playing a game like poker, then there's hidden information or private information.",
                    "label": 0
                },
                {
                    "sent": "For example, you might not know their cards.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Even after the fact.",
                    "label": 0
                },
                {
                    "sent": "So there's two problems we want to solve.",
                    "label": 0
                },
                {
                    "sent": "The first problem is if we have these samples of 1 strategy, how can we evaluate how all the other strategies would do against these opponents?",
                    "label": 1
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the second problem is, how can we reduce as much of the variance as possible from our result so we can make good choices.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So our solution we're going to propose using important sampling to evaluate other strategies that didn't even play the game.",
                    "label": 0
                },
                {
                    "sent": "Our approach can be combined with existing estimators to reduce the variance further and the main contribution of our talk is this Third Point.",
                    "label": 1
                },
                {
                    "sent": "We're going to show how to create synthetic data so you can observe one hand, but then look at a couple thousand more situations.",
                    "label": 0
                },
                {
                    "sent": "You can evaluate where the opponent had to do the same thing.",
                    "label": 0
                },
                {
                    "sent": "The assumption we're making we're playing a static opponent, so playing as humans that's not true, but it seems to work fairly well in practice.",
                    "label": 0
                },
                {
                    "sent": "There's actually 8 different cases that discovers we're only going to talk about two.",
                    "label": 0
                },
                {
                    "sent": "In the talk, we mentioned four in the paper.",
                    "label": 1
                },
                {
                    "sent": "The big to hear this on policy and off policy.",
                    "label": 0
                },
                {
                    "sent": "UN policy means you're looking at sample hands of our program, playing someone else, or your program.",
                    "label": 0
                },
                {
                    "sent": "For any game playing at any other opponent.",
                    "label": 0
                },
                {
                    "sent": "Off policy means you're trying to evaluate a strategy that you haven't even seen.",
                    "label": 0
                },
                {
                    "sent": "Play the game.",
                    "label": 0
                },
                {
                    "sent": "On the other axis here we have perfect information, meaning that you get to see all the information after the fact and partial information.",
                    "label": 0
                },
                {
                    "sent": "Which means you might not have all the information in the talk were just doing this row.",
                    "label": 0
                },
                {
                    "sent": "The paper discusses this one.",
                    "label": 0
                },
                {
                    "sent": "The other axis is online versus offline learning.",
                    "label": 0
                },
                {
                    "sent": "We're just doing offline learning for the talk and the paper, but this does work for online as well and I'll give a clue of that at the.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Slide.",
                    "label": 0
                },
                {
                    "sent": "Sore framework is we work in repeated extensive form games.",
                    "label": 0
                },
                {
                    "sent": "So if you're playing a game like poker, you're going to do several.",
                    "label": 0
                },
                {
                    "sent": "What many maybe 500 or 1000 or so, repeated games each game.",
                    "label": 0
                },
                {
                    "sent": "This is an extensive form game, so it has you and your opponent, or taking actions throughout the game tree.",
                    "label": 0
                },
                {
                    "sent": "The added twist for games like Poker is that there's hidden information.",
                    "label": 0
                },
                {
                    "sent": "So here for example, if we were dealt these cards or opponent were dealt either this set of cards or this set of cards, we don't actually know what game State we're in, right?",
                    "label": 0
                },
                {
                    "sent": "They could have this, or they could have that, and so we need to have a strategy that plays the same way in both of these situations.",
                    "label": 0
                },
                {
                    "sent": "Just because we can't differentiate them.",
                    "label": 0
                },
                {
                    "sent": "The red squares at the top are terminal nodes.",
                    "label": 0
                },
                {
                    "sent": "Those we get payoff.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I've already used the term strategy several times.",
                    "label": 0
                },
                {
                    "sent": "So what I mean by strategy is.",
                    "label": 0
                },
                {
                    "sent": "For each information set, for each of these cases that you can't tell apart if it's your turn to act, a strategy is the distribution of probability distribution over your actions.",
                    "label": 0
                },
                {
                    "sent": "So, for example, if you're here, you might have a 20% chance of choosing action a, an 80% chance of choosing Action B.",
                    "label": 0
                },
                {
                    "sent": "And Sigma I represents the strategy for player I.",
                    "label": 1
                },
                {
                    "sent": "And Sigma is a strategy profile that just means it's a one strategy for each player.",
                    "label": 1
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the last bit of notation here before we get to the fun stuff.",
                    "label": 0
                },
                {
                    "sent": "Pi Sigma is the probability of the strategy profile.",
                    "label": 1
                },
                {
                    "sent": "That's all the players reaching a certain terminal history.",
                    "label": 0
                },
                {
                    "sent": "History is just one path through the tree.",
                    "label": 0
                },
                {
                    "sent": "\u03a0 Sigma I is 1 player's contribution to that probability.",
                    "label": 0
                },
                {
                    "sent": "So for example, if I'm player I then Pi Sigma is just the product of my probabilities.",
                    "label": 1
                },
                {
                    "sent": "And Pi Sigma minus I is everyone else is probabilities everyone but player I.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, getting into interesting stuff.",
                    "label": 0
                },
                {
                    "sent": "So the usual way you would evaluate one strategy playing it's another strategy, assuming that you don't know what your opponent is actually going to do is, you can just do Monte Carlo estimation so you play a whole bunch of hands and you evaluate the score after every hand, and you take the mean and there you go.",
                    "label": 0
                },
                {
                    "sent": "What we're going to do with important sampling is fairly similar to this.",
                    "label": 0
                },
                {
                    "sent": "Important sampling is a well known technique for.",
                    "label": 1
                },
                {
                    "sent": "If you have two distributions and maybe one is expensive to sample from and one is easy to sample from, you can find the expected value of the expensive one by drawing samples from the simple one.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's the trick for this.",
                    "label": 0
                },
                {
                    "sent": "We're going to have two strategy profiles.",
                    "label": 0
                },
                {
                    "sent": "The first one, Sigma, is the strategy profile that contains a strategy we want to evaluate.",
                    "label": 1
                },
                {
                    "sent": "And the second one, Sigma hat, contains the strategy that we actually observed playing.",
                    "label": 0
                },
                {
                    "sent": "So this is against the same opponent.",
                    "label": 1
                },
                {
                    "sent": "The only thing that changed is what strategy of ours is in the seat.",
                    "label": 0
                },
                {
                    "sent": "And if you're doing online learning or sorry on policy, then Sigma and Sigma had are the same.",
                    "label": 0
                },
                {
                    "sent": "So it's just the same strategy on both sides.",
                    "label": 0
                },
                {
                    "sent": "So this first part looks just like Monte Carlo sampling.",
                    "label": 0
                },
                {
                    "sent": "The difference here is the waiting term.",
                    "label": 0
                },
                {
                    "sent": "So here we have \u03c0 Sigma over \u03c0 Sigma hat, so this is again your probability of reaching a terminal node.",
                    "label": 0
                },
                {
                    "sent": "The trick that we're doing here is that you can separate Pi Sigma into the probability that we go to a terminal node, and the probability that everything else, the opponent, and the chance player contribute towards getting there.",
                    "label": 0
                },
                {
                    "sent": "And since the only thing that changes between \u03c0 Sigma and Pi Sigma hat is our strategy.",
                    "label": 0
                },
                {
                    "sent": "These are actually the same right?",
                    "label": 0
                },
                {
                    "sent": "Everyone else is.",
                    "label": 0
                },
                {
                    "sent": "Probability is the same on the top and the bottom, so that cancels out and then we get this nice term that we can compute using only our strategy.",
                    "label": 0
                },
                {
                    "sent": "And so if you use this waiting term and.",
                    "label": 0
                },
                {
                    "sent": "This value function.",
                    "label": 0
                },
                {
                    "sent": "Then you can get the expected value for player that wasn't even in the game.",
                    "label": 0
                },
                {
                    "sent": "So this seems kind of magic so far.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Anyway, it is because if you do this just as is, you end up with very high variance estimate of the other player.",
                    "label": 0
                },
                {
                    "sent": "An lots of bias so.",
                    "label": 0
                },
                {
                    "sent": "The rest of the talk we had.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Best ways to fix that?",
                    "label": 0
                },
                {
                    "sent": "One way is you can just use a different value function.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here for example.",
                    "label": 0
                },
                {
                    "sent": "If you're doing Monte Carlo estimation, you might just be using the money you win or something like that as your value.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Function but you can sub in something else.",
                    "label": 0
                },
                {
                    "sent": "For example, in poker there's this function called the divett function that gives a low variance estimate just by rolling out cards.",
                    "label": 1
                },
                {
                    "sent": "So you can do something like that.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But the main contribution of our talk, like I mentioned before, is creating synthetic data.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how can you do that?",
                    "label": 0
                },
                {
                    "sent": "So after you observe some terminal history, you can imagine that something else might have happened instead.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So to give it some notation, if you let zed be the set of thermal histories that you can imagine that if you see some terminal history said, let's imagine we have some mapping that takes that and it gives us a set of thermal histories such that every time we said we can evaluate all of the terminal histories in that set.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we have the inverse as well where.",
                    "label": 0
                },
                {
                    "sent": "You said is if you see a member of that, you can evaluate said.",
                    "label": 1
                },
                {
                    "sent": "The trick here is that if you choose you carefully, then you can make it depend.",
                    "label": 0
                },
                {
                    "sent": "Sorry you can make it not.",
                    "label": 1
                },
                {
                    "sent": "You make the opponent strategy not depend on the terminal histories that you get out, which means you can still do that trick where you cancel above and below an important sampling, and so we have two examples of this.",
                    "label": 0
                },
                {
                    "sent": "The first one is called game ending actions, the second was called.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Other private information.",
                    "label": 0
                },
                {
                    "sent": "So game ending actions first.",
                    "label": 0
                },
                {
                    "sent": "So let's imagine you know this is our game that we played, and let's imagine we observe that history up in the top right corner there, right?",
                    "label": 0
                },
                {
                    "sent": "So this is we were dealt.",
                    "label": 0
                },
                {
                    "sent": "These cards are opponent got these cards.",
                    "label": 0
                },
                {
                    "sent": "We chose the action on the right, which might be to call about or something like that.",
                    "label": 0
                },
                {
                    "sent": "Then they call an we lose money.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So you can kind of equally.",
                    "label": 0
                },
                {
                    "sent": "Imagine that if I got to hear this time, I happened to choose the right path and I lost money, but I could have chosen the left path, which in poker might be folding for example.",
                    "label": 0
                },
                {
                    "sent": "Or anything that ends the game immediately, right?",
                    "label": 1
                },
                {
                    "sent": "If you had done that, your opponent doesn't have a chance to respond, so they couldn't have done anything different, and so you get a different payoff.",
                    "label": 0
                },
                {
                    "sent": "So every time you see the top right one, you can also imagine that you went down this other path.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is the equation for it.",
                    "label": 0
                },
                {
                    "sent": "The proof is in the paper, but it's probably unbiased if you're in the on policy full information case, so you're just getting more samples, so reducing the variance.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The other example is this one called private information or other private information.",
                    "label": 1
                },
                {
                    "sent": "So just like before, we imagined that we could have folded.",
                    "label": 0
                },
                {
                    "sent": "This time you can imagine that you got different private information like you can imagine you were dealt different cards.",
                    "label": 0
                },
                {
                    "sent": "If you're dealt different cards and your opponent doesn't see them, they could have acted any differently and now you can generate more samples that you can evaluate.",
                    "label": 0
                },
                {
                    "sent": "So here for example, maybe we were dealt this set of cards and we lost, but we could have imagined.",
                    "label": 0
                },
                {
                    "sent": "Well I would have done the same thing with better cards and my opponent had to play the same way.",
                    "label": 0
                },
                {
                    "sent": "And so.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "They get more samples to evaluate.",
                    "label": 0
                },
                {
                    "sent": "In a game like Texas Hold'em Poker 2375 more samples every time.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Play hand.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So again, there's the equation.",
                    "label": 0
                },
                {
                    "sent": "Again, this is probably unbiased in the on policy full information case.",
                    "label": 1
                },
                {
                    "sent": "The neat thing too is that all of these can be combined.",
                    "label": 1
                },
                {
                    "sent": "You can do game ending actions and other private information at the same time, so you can get 5 or 6000 more samples.",
                    "label": 0
                },
                {
                    "sent": "You can combine that with another value estimate so you get a low variance estimate on top of.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "All of this.",
                    "label": 0
                },
                {
                    "sent": "So here's some results I can show you how well this works.",
                    "label": 0
                },
                {
                    "sent": "What we did was we have several other poker programs and we played sets of million hands between them.",
                    "label": 0
                },
                {
                    "sent": "So what we've done here, this section of the top we played one of our programs called S 2298 against another program.",
                    "label": 0
                },
                {
                    "sent": "And we're trying to evaluate it using data that it actually played, right?",
                    "label": 0
                },
                {
                    "sent": "So that's on policy.",
                    "label": 0
                },
                {
                    "sent": "This one here is we're trying to evaluate a different program called CFR 8, not using data that it played.",
                    "label": 0
                },
                {
                    "sent": "We're trying to evaluate it using the data from the other program, from S2298.",
                    "label": 0
                },
                {
                    "sent": "The really interesting column here is the standard deviation column.",
                    "label": 0
                },
                {
                    "sent": "Sir biggest concern is just getting the variance down, so at the top of the center deviation column, the first number that 5103.",
                    "label": 0
                },
                {
                    "sent": "That's just Monte Carlo estimation, so that kind of gives you a feel for how much variance is in the game without doing these tricks.",
                    "label": 0
                },
                {
                    "sent": "As you go down the column you see using this devt function that I mentioned before that takes off some of the variants.",
                    "label": 0
                },
                {
                    "sent": "Hughes game ending actions.",
                    "label": 0
                },
                {
                    "sent": "It doesn't do much on its own private information, brings the variance down a little, but then we start combining these right.",
                    "label": 0
                },
                {
                    "sent": "So now we're down to 2000.",
                    "label": 0
                },
                {
                    "sent": "If you put together all the tricks, now you're at about 1800 for the center deviation down from 5100, so we have a much lower variance result.",
                    "label": 0
                },
                {
                    "sent": "I mentioned earlier that if you just did basic important sampling, then you had a lot of variance, right?",
                    "label": 0
                },
                {
                    "sent": "So that's a lot of variance.",
                    "label": 0
                },
                {
                    "sent": "But again, for the off policy case, once you add in all your tricks, you can get down to very low variance for results.",
                    "label": 0
                },
                {
                    "sent": "It has.",
                    "label": 0
                },
                {
                    "sent": "No statistical or not a significant bias to it.",
                    "label": 0
                },
                {
                    "sent": "The interesting thing about this number is that this player didn't even play the game.",
                    "label": 0
                },
                {
                    "sent": "We never watched him play against this opponent, and yet we can estimate how well he does.",
                    "label": 0
                },
                {
                    "sent": "Far better than if we actually watched him just play the game and just use Monte Carlo estimation.",
                    "label": 0
                },
                {
                    "sent": "So that came down a lot.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But we ran more experiments though, so this is just the summary table showing on policy and off policy, the maximum minimum that we observed.",
                    "label": 0
                },
                {
                    "sent": "So again, overall over tests that we did write, the center deviation doesn't go up all that high.",
                    "label": 0
                },
                {
                    "sent": "It's still far better to not watch the guy play and do all these tricks than if you just watched him play games.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I guess the conclusion is, is that this is a pretty neat technique.",
                    "label": 0
                },
                {
                    "sent": "You can generate lots of data.",
                    "label": 0
                },
                {
                    "sent": "We use this in the main machine competition that I mentioned at the start of the talk.",
                    "label": 0
                },
                {
                    "sent": "This is my last slide here, so this is kind of neat prize at the end.",
                    "label": 0
                },
                {
                    "sent": "Each line on the graph here is a different one of five strategies that we use during the match, and so this is after the match is over.",
                    "label": 0
                },
                {
                    "sent": "Analyzing how well each of these players did, so we can actually track all of the lines and estimate.",
                    "label": 0
                },
                {
                    "sent": "You know if this player had been in the match, we've done a lot worse than the one at the top, which is what actually got chosen an we did something like this for online learning during the match as well.",
                    "label": 0
                },
                {
                    "sent": "Figure out which one to use at anytime.",
                    "label": 0
                },
                {
                    "sent": "And that's my talk.",
                    "label": 0
                },
                {
                    "sent": "Any questions?",
                    "label": 0
                },
                {
                    "sent": "I see your solution seems to show off policy learning, whether with complete complete information or incomplete information.",
                    "label": 0
                },
                {
                    "sent": "Missions are our best.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Otherwise it's possible cause.",
                    "label": 0
                },
                {
                    "sent": "I am in 2000 two 2002 thousand 2001 three Cup and suddenly they prove or positive learning is unbiased.",
                    "label": 0
                },
                {
                    "sent": "So I wonder why this happened.",
                    "label": 0
                },
                {
                    "sent": "OK yeah, so you mentioned perfect information and partial information.",
                    "label": 0
                },
                {
                    "sent": "So in the talk I just talked about perfect.",
                    "label": 0
                },
                {
                    "sent": "But you're right, even with perfect information, we still get a little bit of bias.",
                    "label": 0
                },
                {
                    "sent": "The reason for that is the strategies don't all have the same support.",
                    "label": 0
                },
                {
                    "sent": "They don't all go down the same path, so you might.",
                    "label": 0
                },
                {
                    "sent": "For example, if you had two players you're trying to evaluate and one was always called, another one was always raised, since they have no actions that will go down in common, then you have no.",
                    "label": 0
                },
                {
                    "sent": "You have no way of.",
                    "label": 0
                },
                {
                    "sent": "Sorry, let me back up to the equation here.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There we go.",
                    "label": 0
                },
                {
                    "sent": "Yeah, So what this is relying on here when we do this?",
                    "label": 0
                },
                {
                    "sent": "Is you have to choose some terminal history and you have to have some probability that both strategies would try to reach that history.",
                    "label": 0
                },
                {
                    "sent": "So if you have always called and always raise then they have no histories in common and you just like one of these terms will be 0 and it will be this one 'cause the observed one always goes down at least one path right?",
                    "label": 0
                },
                {
                    "sent": "So that's where this is coming from.",
                    "label": 0
                },
                {
                    "sent": "If they don't have the same support, then you're going to have some cases where you can't evaluate them properly.",
                    "label": 0
                },
                {
                    "sent": "In the full information case, it's pretty low.",
                    "label": 0
                },
                {
                    "sent": "But that's mostly because we can toss in all the extra tricks of saying, well, if I had different cards, I would have gone down that same path.",
                    "label": 0
                },
                {
                    "sent": "Or if I could have folded earlier, I would have gone down that same path.",
                    "label": 0
                },
                {
                    "sent": "In the partial information case, the bias is quite a bit higher.",
                    "label": 0
                },
                {
                    "sent": "It can be boat.",
                    "label": 0
                },
                {
                    "sent": "I'll show you numbers to compare against.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There we go in the personal information case, some of these bias terms can be about 100 or 150, so then it actually becomes a problem.",
                    "label": 0
                },
                {
                    "sent": "So you have these five lines that show that.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Any of your players have been in the match?",
                    "label": 0
                },
                {
                    "sent": "They would inhuman statistically significantly is the lower 2 might not have been.",
                    "label": 0
                },
                {
                    "sent": "Oh no, maybe.",
                    "label": 0
                },
                {
                    "sent": "Yeah, OK. How correlated are those tests?",
                    "label": 0
                },
                {
                    "sent": "In other words, are they going to be there?",
                    "label": 0
                },
                {
                    "sent": "Presumably all right or all wrong?",
                    "label": 0
                },
                {
                    "sent": "Yeah, they do tend to.",
                    "label": 0
                },
                {
                    "sent": "As you can see from the graph, they go up and go down at the same points.",
                    "label": 0
                },
                {
                    "sent": "No, mostly because you see some hand.",
                    "label": 0
                },
                {
                    "sent": "In particular, there's a big spike here.",
                    "label": 0
                },
                {
                    "sent": "They may have noticed this turns out to be if the opponent does something really, really dumb.",
                    "label": 0
                },
                {
                    "sent": "All of your strategies think Who Will Win, so there are correlated, so you have to do more matches in order to really say.",
                    "label": 0
                },
                {
                    "sent": "Yeah, for sure the way that we did these matches too is we did duplicate poker.",
                    "label": 0
                },
                {
                    "sent": "Duplicate poker is where you have two humans in separate rooms and two copies of your program and you deal with the same cards in both rooms, but the opposite players.",
                    "label": 0
                },
                {
                    "sent": "So the human in one room gets the same cards as the program in the other, and then you add the scores together.",
                    "label": 0
                },
                {
                    "sent": "So that eliminates a lot of the luck as well.",
                    "label": 0
                },
                {
                    "sent": "So actually if you do duplicate for the last match, this number goes down to 702.",
                    "label": 0
                },
                {
                    "sent": "So just vote.",
                    "label": 0
                },
                {
                    "sent": "Usually for I for told him we see a third deviation of about 6000.",
                    "label": 0
                },
                {
                    "sent": "So go from 6000 down to 700 is.",
                    "label": 0
                },
                {
                    "sent": "A pretty big drop.",
                    "label": 0
                },
                {
                    "sent": "Anyone else?",
                    "label": 0
                },
                {
                    "sent": "So probably the difficulty of these are ways that the variance grows exponentially with the number of steps in the game.",
                    "label": 0
                },
                {
                    "sent": "So about how many steps with these games usually have prepared OK.",
                    "label": 0
                },
                {
                    "sent": "So there's for the game we play, there's four rounds.",
                    "label": 0
                },
                {
                    "sent": "Each round has between 2:00 and 5:00.",
                    "label": 0
                },
                {
                    "sent": "Six actions.",
                    "label": 0
                },
                {
                    "sent": "So probably anyone history like the one traced through the game tree is probably going to be.",
                    "label": 0
                },
                {
                    "sent": "12 or 14 steps.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "What's the difference between?",
                    "label": 0
                },
                {
                    "sent": "The difference between the five programs OK, each one of the five is a different game theoretic strategy.",
                    "label": 0
                },
                {
                    "sent": "One of them.",
                    "label": 0
                },
                {
                    "sent": "The red line here plays something.",
                    "label": 0
                },
                {
                    "sent": "It plays closest to a Nash equilibrium strategy.",
                    "label": 0
                },
                {
                    "sent": "The other lines are different tilts that we had on top of this we.",
                    "label": 0
                },
                {
                    "sent": "Our equilibrium solver seems to handle non 0 sum games.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure that we've actually proven a properties voted, but you can give it a non 0 sum game and it does something reasonable.",
                    "label": 0
                },
                {
                    "sent": "So here's what I mean by that this green line that's up top the best performer.",
                    "label": 0
                },
                {
                    "sent": "This is what happens if you tell the solver is playing a game where every time it wins it gets a 7% bonus every time it loses, it takes the normal penalty, so this is non 0 sum.",
                    "label": 0
                },
                {
                    "sent": "There's more money going into the pot, every hand, whoever wins gets this little bonus.",
                    "label": 0
                },
                {
                    "sent": "But it winds up making the programs a lot more aggressive 'cause they think there's more money there.",
                    "label": 0
                },
                {
                    "sent": "They're more willing to bet because they're expected payoff is better.",
                    "label": 0
                },
                {
                    "sent": "And against humans it just does great rated really pushes them into uncomfortable situations.",
                    "label": 0
                },
                {
                    "sent": "So all four of the lines that aren't red or different adjustments like this.",
                    "label": 0
                },
                {
                    "sent": "They are either more aggressive or passive or more tight or loose.",
                    "label": 0
                },
                {
                    "sent": "And if you play them all and you pick online which one to do, you can try to hone in on which robust strategy is going to exploit this point the most.",
                    "label": 0
                },
                {
                    "sent": "Any other questions?",
                    "label": 0
                },
                {
                    "sent": "Facebook, thank you.",
                    "label": 0
                }
            ]
        }
    }
}