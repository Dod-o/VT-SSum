{
    "id": "tqq4vvt5mg5y4z4ojedsnklc6qrzui5y",
    "title": "Efficiently Learning Linear-Linear Exponential Family Predictive Representations of State",
    "info": {
        "author": [
            "Satinder Singh, Electrical Engineering and Computer Science Department, University of Michigan"
        ],
        "published": "Aug. 12, 2008",
        "recorded": "July 2008",
        "category": [
            "Top->Computer Science->Machine Learning->Linear Models"
        ]
    },
    "url": "http://videolectures.net/icml08_singh_ell/",
    "segmentation": [
        [
            "I actually really David.",
            "This is David's work.",
            "When he was a student at University Michigan, now is a postdoc at MIT with Josh Tenenbaum and he couldn't make it here, so I'm giving the talk instead.",
            "And I give this talk.",
            "I'll explain how it's different from the tips from the nips stuff, so this is about efficient learning, linear, linear, exponential, family predictive representations of state."
        ],
        [
            "And so here's the outline of the talk.",
            "I'll explain what exponential family PSR.",
            "I'll talk about the linear linear case of the PSR, FPS, ours and talk about a tractable learning algorithm.",
            "That's what distinguishes this from the NIPS submission, NIPS NIPS paper because we didn't have a really attractive learning algorithm at that point, and talk about some."
        ],
        [
            "Comments and conclusions.",
            "OK, So what is the?"
        ],
        [
            "Exponential family PSR what are we trying to do with the exponential family?",
            "PSR is trying to model a dynamical system because of course you want to use the model dynamical system to do planning and reinforcement learning thereafter.",
            "So here's a trajectory of experience.",
            "The current time is T, so we've observed all the actions and observations that have happened until time T shown in lower case.",
            "Because we've already observed them.",
            "So that's the history at time T and the future, which is an infinite trajectory of future actions and observations are random variables.",
            "And so we talk about the conditional future F is for future the infinite future given the current history.",
            "And of course the goal of modeling is to model this conditional distribution of the infinite future given any history, right?",
            "That's our task."
        ],
        [
            "So what do PSR's do?",
            "These central predictive state representations assumption is that the parameters describing the conditional distribution of some short term future or state.",
            "That is, the parameters that define the conditional distribution of short-term futures.",
            "Are a sufficient statistic of history capture all the information there is in history so we can make the infinite future prediction for that history just as well as if we had the entire history.",
            "So that's the key PSR assumption."
        ],
        [
            "OK, so is this does not make any sense.",
            "Is this assumption any good?",
            "So let me describe what we already know about what follows from this assumption.",
            "So for the discrete observation case it's known that for example, all Hmm's flat Hmm's in Palm DPS, you can capture it by the by the expectations of a core set of indicator random variables which basically is the probability of specific action observation sequences of length no more than a number of underlying states in HMM.",
            "Palm DP so there is a short term future whose statistics are exactly able to capture state.",
            "In the case of Hmm's, in Palm DP's, so that's the discrete observation case.",
            "The continuous observation case we're going to build on today that we already know is that if we assume that the next, if we assume a Gaussian distribution jointly Gaussian distribution for the next 10 observations, then the parameters, the mean and the covariance of the Gaussian are in fact the state represent our.",
            "Are perfect representations of all linear dynamical systems.",
            "So if the dimension of the linear dynamical system or common filter system is N, then you don't the short term future need not be anymore than length, and so that's what we know, so this.",
            "So the point is that this assumption the central assumptions that PSR makes is actually a fruitful assumption."
        ],
        [
            "So what is the ear?",
            "The exponential family assumption?",
            "The exponential families are basically generalizes the examples.",
            "We just saw an assume that the distribution of short term future is an exponential family form.",
            "So what does that?",
            "Here is the.",
            "Here is the assumption that the modeling assumption is that the density of a future given history is has exponential form.",
            "So this is a standard exponential form fee of Fenner futures.",
            "The parameters of the distribution are accepte.",
            "We use S because it is the parameters of this exponential family that form the state representation.",
            "So SMT is the state fear the future other features of the future and the log partition function is the usual lock partition function.",
            "OK.",
            "So these parameters will be."
        ],
        [
            "State, so how are we going to build a model from this?",
            "We have to have a way of maintaining this state representation.",
            "That is, we have a current state.",
            "We take an action scene observation.",
            "We have to update state.",
            "So how does that process work?",
            "Let's just talk about that.",
            "So here is the current history we've already seen up until they the blue part.",
            "The lower case part and we have our current representation of state.",
            "However, we got it.",
            "We talk about learning that in a minute in a few minutes, but this is our current representation of state.",
            "And we take an action A and see another observation.",
            "So now the new future and we want to update our state representation so that it captures the distribution of length future from the new history T + 1.",
            "How does this process work?",
            "Because that's how the model works.",
            "So we use what's called conditioning and extension and condition by basically formulating a intermediate representation.",
            "Which captures the distribution of length N plus one futures.",
            "Also an exponential form.",
            "So there's an intermediate representation that extends the length N distribution to a length N plus one distribution.",
            "And we have to preserve.",
            "We have to choose the features in such a way that the exponential family form is is preserved and will talk about how to do that.",
            "So there is a key step extension that takes the current state and has some parameters.",
            "In fact, it is these parameters that form the model parameters of the FPS our model, right?",
            "It is these parameters that the current state and extend it.",
            "And then of course there's the conditioning step that takes the observation an.",
            "And then conditions it back to a length an length and distribution.",
            "So it's extending condition, right?",
            "That's the process that gets repeated in order to project the model forward."
        ],
        [
            "OK, so what's that task?",
            "Our task is we're going to be given a trajectory of length T data, and we have to learn this model.",
            "This FPS, our model.",
            "How do we do that?",
            "One of the things to learn that three things to learn.",
            "We have to learn the dimension.",
            "What is the dimension of the distribution we have to model in order to capture state?",
            "We have to find the features of the future and we have to learn the model parameters.",
            "In this talk, I'm really just going to focus on the model parameters part and not the dimension an features the future.",
            "We don't really have any currently any great answers for dimension for the future of the future we use basically density estimation, feature extraction ideas, dealer petrol and or ideas from them, so it's not terribly novel.",
            "The feature of the future part, the model parameters part is where I'm going to focus OK, so."
        ],
        [
            "Let's say that was the general exponential family PSR.",
            "Let's talk about the special case of linear Lin."
        ],
        [
            "Exponential family PSR.",
            "So what do I mean by linear linear ones?",
            "The first linear is because we're going to assume that the extension function is a linear function.",
            "So this is the state of this N + 1.",
            "The parameters of this N + 1 dimensional Gaussian distribution is computed as a linear function with the parameters Theta of the current parameters St. And Furthermore, we're going to assume that the conditioning itself is also linear.",
            "That is, a new state is a linear function dollar.",
            "Now the function can depend on the observation, right?",
            "It's conditioning.",
            "And so we assume both of these are linear, and if we assume it, if we assume this, then the overall state update is linear.",
            "That is, the next state is this observation dependent linear function of state.",
            "Now this looks like a really severe assumption, right?",
            "But notice that this is linear in states.",
            "But not linear in the observation, so it is a nonlinear function of the observation.",
            "But if we make these assumptions, then 2 two things result.",
            "Basically two useful computational properties.",
            "Maximum likelihood gradients are easy to derive, and more importantly, linearity will make efficient approximations possible."
        ],
        [
            "So let's talk about.",
            "Let's get to that part of the talk, so here.",
            "So how are we going to learn this?",
            "We're going to learn this through maximum likelihood.",
            "We're going to fit the model to the data to maximum likelihood.",
            "So here's the likelihood equation.",
            "The log likelihood equation.",
            "OK, so now this should look fairly familiar to those of you who do graphical model like things, but the really key thing is there are no latent variables in this model.",
            "Right, there's no latent variables in this model, so we can do it.",
            "We don't have to do M, there's no need for you, and that's the win, right?",
            "That is where if there is a win, which I know some of you should be skeptical about reasonably so you know that would be the source of the win.",
            "OK.",
            "I'm not a fan of EMS, as you can tell.",
            "OK, so I've defined the likelihood we can do gradient ascent unlikelihood an and in some cases in toy cases we can do exactly exactly.",
            "So let's first do that."
        ],
        [
            "Let's take toy cases and do exact gradient calculations.",
            "And so here I will show you some results on really easy problems.",
            "Small problems palm DP like problems with two 345 states.",
            "Tiny ones like that and the idea here is to just show you that.",
            "So we're comparing the performance.",
            "We are comparing the data likelihood under the Model 2 model so we know the true model in these cases, so we can compute the likelihood of the data and we can compute the likelihood under the learned FPS are.",
            "And ask and also learn and also compute the likelihood for a completely naive model that makes uniform predictions.",
            "And what we're asking is what percentage of the difference between the naive model in the true model does the FPS are makes up.",
            "So ideally we want to be at 100%, that is, it gets exactly the true thing, and so you know the training and test set performance and you can see more or less many of the problems gets close to 100%.",
            "OK, so this is just where we can do the exact calculations, which unfortunately we can't really do in."
        ],
        [
            "Large domains.",
            "OK, so this is the part that's sort of distinct from the next one."
        ],
        [
            "So tractable learning algorithm.",
            "We want to come up with something that's more tractable.",
            "So first, before I describe the the assumptions we make, let's look at why exact MLE maximum likelihood is intractable.",
            "So.",
            "You know this should be fairly familiar to all of you.",
            "This is the inference problem and not surprisingly, inferences intractable.",
            "So we're going to use standard approximate inference techniques.",
            "Variational, we tried all kinds of things, naive mean field, loopy belief, propagation, things of that sort, and we can do those sorts of things here as well.",
            "I'm not going to talk very much about that.",
            "I'm going to tell you what I'm going to talk about in one minute, so we also have this problem that we want to be able to deal with problems where we have 10s of thousands of features.",
            "If you have 10s of thousands of features.",
            "Extension matrix will be of that dimension and we can't really do that.",
            "And there are again standard things that people have developed.",
            "Basically, low rank approximation ideas and we we use those.",
            "The other of course, bigger problems.",
            "Even if you could do all that exactly, is that we have a sum from time T = 1 to the length of the trajectory, and to compute a gradient step will have to do this sort of calculation once for every time step for each gradient calculation, and that's too much also.",
            "So we're going to get this is the part I'm going to focus on.",
            "How do we get a form for the likelihood that an approximate form that we can do tractable things with?"
        ],
        [
            "OK, so this is the equation we're going to simplify, so here's the exact likelihood of the data we're going to make 2 assumptions.",
            "And get this form.",
            "So we're going to get a approximate lower bound on the likelihood of the data, and that's the one we're going to do.",
            "Gradient methods on, and the way we get it is, well, one thing that's clearly familiar with all those who work in graphical models.",
            "We apply Jensen's inequality a couple of times and that gets to the lower bound, but the other more challenging assumptions we make is we make this zero covariance assumption between so before.",
            "Before I describe that.",
            "You know basically what it is is an empirical average, right?",
            "We're taking a sum from T going from one to capital T and we're averaging it.",
            "So there's an empirical expectation.",
            "And if you just replace the Summon normalization by an empirical expectation, you should get expectation of a product with the expectation of the log partition function.",
            "And basically zero covariance assumption allows us to split that first term into the product of this form.",
            "Andy Jensen's inequality allows us to get the log partition function like this and it gives us a lower bound in which we can do very understandable right?",
            "So I don't think this would be terribly surprising to those of you who work on which I don't really work in graphical models.",
            "So this is all quite quite interesting to me.",
            "And of course, we could use the same tricks."
        ],
        [
            "Other models, but let's stay with this particular model and let's start to understand what this approximate likelihood equation says.",
            "So what is the first term?",
            "The first term is the unconditional expectation.",
            "Of the parameters of the exponential form, which are states.",
            "So it is the stationary distribution of states.",
            "With a you know are going to city assumption underlying that we can assume we can think of this first term as a stationary distribution of states.",
            "Anfora linear linear FPS are.",
            "This can be computed.",
            "As a solution to a linear system of equations from the stationary distribution of observations which we do get to see.",
            "So given our current parameters data, we can use that to compute the stationary distribution over states in a linear way from this stationary distribution of observations which we actually get to see.",
            "So this term we can compute fairly simply."
        ],
        [
            "OK, let's look at this.",
            "What is this?",
            "This is the unconditional expectation to the features.",
            "Basically this is a stationary distribution of features.",
            "So this we can just go through data once and be done, compute this one, sweep the data and we get we get the we get we get this form, the other one we have to do it every time we change we have to redo every time we change the parameters.",
            "OK."
        ],
        [
            "That's how we can compute these two terms, and this last term is the log partition function.",
            "Using the stationary distribution of States and we do the same sort of approximations that people do, but for the stationary distribution, as opposed to once for each term in that summation, and so we do the same approximations for this that people have tried it."
        ],
        [
            "Graphical models OK, So what is the gradient look like?",
            "Here's what the gradient looks like.",
            "The gradient with respect to the stationary distribution over states.",
            "OK, so this is actually a very nice form.",
            "What does this say?",
            "This is saying we want to change the parameters of the model where the parameters of the extension function or the parameters extension function the linear part.",
            "So that the expected features of the future.",
            "Induced by the model.",
            "Match the expected features of the future observed in the data.",
            "Right, so this is a very intuitive algorithm, right?",
            "It's saying let's move the model parameters so that the model computer expectation of the features.",
            "Matches the empirical expectation of the features that we are observing in the data and that becomes the basic underlying, intuitive, intuitive algorithm."
        ],
        [
            "So I'm saying this.",
            "I already said this, find model parameters, Theta cetera, models stationary distribution of feature matches the empirical spatial distribution of features.",
            "And it's tractable because of course the model is fully the IT has no latent variables and the state update is linear."
        ],
        [
            "OK, so."
        ],
        [
            "How does this work?",
            "So let's try a couple of problems.",
            "Before I describe the harder problems we tried this on.",
            "One problem that happens is we can't do the same comparison we just did in the past where we're looking at comparison to true likelihood.",
            "Because we're looking at really complex problems, we don't have two likelihood.",
            "Furthermore.",
            "We're doing we're not even computing the because we can't even compute likelihoods, right?",
            "We're using a lower bound, so you can't really compare lower bounds in any sort of sensible way.",
            "So what we're going to do instead is we're going to take the model and use reinforcement learning on the learning model and ask how well does it do in the in the reward sense.",
            "In the usual reinforcement learning sense.",
            "So for example, let's do some simple problems before I delete the more interesting problem.",
            "So here is the cheese made in the four by three maze that various people have used.",
            "An here's the performance of the random sort of model.",
            "Here is the performance of a first order model.",
            "Here's the performance of the optimal model here, because we know optimality, and here is the performance.",
            "This is a reward average award.",
            "Of the FPS, our model and you know it doesn't really get all the way to optimal, but it does perform 1st order Markov with the and the conclusion we can draw from that is that it is finding more of state than a first order Markov model is at least in order to.",
            "So we build a model where we build a model assuming the 1st order Markov condition holds, that is the, which is which means.",
            "The.",
            "No, no no.",
            "This is maybe not going to same four by three.",
            "Well, this is a palm DP.",
            "Jimmy firm up in the observation yes yes yes yes sorry yes.",
            "So it's a very impoverished model.",
            "We're trying to see all this is showing is all these results are showing really is that we're doing better capturing more state than just the last observation does in effect."
        ],
        [
            "OK, but I really wanted to see if this could goal of this work was to really get scalable algorithms.",
            "So here's a problem we tried.",
            "We made up a problem.",
            "This is what we call the ball bouncing problem, which is basically a 10 by 11 pixel array and a pixel just bounces about when hits the wall it bounces and the control task is we get maximum reward by keeping it in the middle of the square so the reward falls off and the actions we have our reverse direction.",
            "Off the boats and you know in this in this state in this problem with 110 possible observations, and it turns out it's a second order Markov problem, because noise free observations.",
            "So this is one problem we did, and we wanted to find a problem which is not short order Markov.",
            "So we can really test whether we're capturing information from a lot of history.",
            "So we had a noisy version of this problem in which several pixels have some independent probability of turning on and off.",
            "So now you try to see where the ball is.",
            "It's very hard to see right, because every pixel has some probability of turning on and off, and this is not a shorter Markov problem.",
            "So now there are.",
            "Now there are 210 possible observations, and again it's no longer."
        ],
        [
            "Same remark off.",
            "So how do we do in this?",
            "But before I do that.",
            "Before I do that, I want to just talk a little bit about how we choose features because we have to choose features in such a way that conditioning becomes linear and I just want to give you a sense of how we could incorporate prior knowledge of the domain into our observation feature vector.",
            "So we have this 10 by 11 binary feature array right by binary observation array and our features basically.",
            "Are conjunctions of observations across time.",
            "We know that a ball moves diagonally, so we put features.",
            "If you like binary features on these conjunctions, that becomes our feature space for the, we assume a length of two in the short in the sense of what future distribution we're modeling, and so that becomes basically are."
        ],
        [
            "Our model graphical form of the model and an extension will then do the normal extension going two time steps out.",
            "So this is the form of our features.",
            "Just if you're interested in that."
        ],
        [
            "OK, so how did it do?",
            "How do we do?",
            "Here are the results.",
            "Again, this is the performance of the random policy.",
            "A first order Markov assumption leads to in the model leads to the red performance in terms of average or higher is better.",
            "You know numbers are negative and the FPS are does.",
            "Does does better still this is on the noises on the harder task the noisy one.",
            "OK."
        ],
        [
            "Alright, one more task, and then I'll be done.",
            "We also did this robot domain, in which we simulated robot in which the images are what you're seeing with what the robot gets.",
            "This is the overhead view of the domain, so it's a very stylized but you know, but still the observation space is very large, so it's not a real robotics domain, but it's a made up robotics robotics domain, so observations are camera images.",
            "We extract features binary features about 1000 binary features.",
            "That basically looks like edge detection's.",
            "And from this we construct our graphical form of the features for our the that we use in our in the exponential family format.",
            "About 12,000 features.",
            "So it's a pretty big, pretty big feature space.",
            "We used an equal to three 200,000 samples.",
            "Various approximations that we have into."
        ],
        [
            "And here are the results.",
            "So we had various Maps.",
            "I showed you one map.",
            "There were two Maps we use coarse features and and some finer features.",
            "These are the edge detection like things that we're talking about and basically the short answer is that it we were able to do this whole PSR thing on a very large observation space.",
            "Now the and and basically outperform a first order Markov system so.",
            "Again, the claim really is that mean there are two real claims here, right?",
            "One is we've made PSR at least applicable to very large problems, which had, which was a challenge we need to meet, and also that we are capturing more state information than a first order Markov.",
            "How much more is?"
        ],
        [
            "Hard to quantify from this OK Diner standing up slightly to conclude.",
            "It turns out that learning a linear linear model is fairly straightforward.",
            "Mainly because we get these interpretations based on stationary distributions, which makes the problem of learning fairly simple.",
            "We believe that this sort of method can be reached at the point where we can try it on real domains, and that's the next challenge where we're heading up to.",
            "OK, thank you.",
            "So I was wondering about.",
            "This can be extended addition operations.",
            "In this model, consistency in a formal sense, yeah.",
            "Yes, yes.",
            "Sure, that would be given set of features.",
            "It's possible and 2nd order.",
            "So there is a way of thinking about how the features which are at least at least in the way we thought about it, which is binary features an features that are basically conjunctions or binary features where the edges are the conjunctions we mean.",
            "Then we can think about the what features we can include so that the extension and conditioning comes back to exactly those features.",
            "And so I think there is a.",
            "There is a nice mathematical way of saying it, but there is a graphical way, at least we know.",
            "Of how to say it?",
            "But it's still.",
            "I wish there was a.",
            "In nice resolution to the question you have, which I also have, but there is a graphical intuition as to how this could work.",
            "There isn't a mathematical intuition yet for me.",
            "In other words, given a domain, we can design features and tell you how that would work, but I can't give you a mathematical condition that if met would be would be true.",
            "At least I haven't thought about it enough yet.",
            "Yes.",
            "Extended to compositional predictions.",
            "So rather than just predictions about direct observations in the next in time steps.",
            "About future states.",
            "Absolutely.",
            "One of the things on my agenda which I haven't gotten to yet, is to blur the distinction between tenet like things in PSR like things, and I see no reason why it can't be done.",
            "Just haven't made the effort yet.",
            "Yes.",
            "But if I understand well, you are using parcel history slices to construct this PSR.",
            "So in principle you could build a second order Markov model on this.",
            "Historic slices will be we're actually not using history slices to build a PS, are we not in this form?",
            "We have done that in the past in suffix tree like suffix history based algorithms for discrete observation, PSR's.",
            "In this case we're doing maximum likelihood.",
            "On a on a parametric form to fit the data right?",
            "So we're so I just want to correct that we're not using a suffix history like idea here, but I think your larger question might have been why didn't we compare 2nd order mark offer to mark off?",
            "The observation space is so large right in these in these cases that even second order Markov is very large.",
            "Should have kept us from trying it, maybe not, but it is a very large space, right?",
            "Because we're looking at a very large observation space, so even just squaring it is a huge huge thing.",
            "Sparse.",
            "It might be might be, so you're right, it would be a fair comparison to try it against higher order Markov processes.",
            "Assumption on the covariance.",
            "Yes.",
            "Other domains here or you don't know.",
            "That assumption, important for practical reasons or just one theoretical?",
            "It wasn't satisfied here, so you're right, we could certainly apply it without that condition.",
            "Holding it was the condition needed in order to derive the approximate maximum likelihood equation.",
            "The more it's violated, the more that approximate equation is wrong, and so so.",
            "So there is only so much you can say about that.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I actually really David.",
                    "label": 0
                },
                {
                    "sent": "This is David's work.",
                    "label": 0
                },
                {
                    "sent": "When he was a student at University Michigan, now is a postdoc at MIT with Josh Tenenbaum and he couldn't make it here, so I'm giving the talk instead.",
                    "label": 1
                },
                {
                    "sent": "And I give this talk.",
                    "label": 0
                },
                {
                    "sent": "I'll explain how it's different from the tips from the nips stuff, so this is about efficient learning, linear, linear, exponential, family predictive representations of state.",
                    "label": 1
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so here's the outline of the talk.",
                    "label": 0
                },
                {
                    "sent": "I'll explain what exponential family PSR.",
                    "label": 1
                },
                {
                    "sent": "I'll talk about the linear linear case of the PSR, FPS, ours and talk about a tractable learning algorithm.",
                    "label": 0
                },
                {
                    "sent": "That's what distinguishes this from the NIPS submission, NIPS NIPS paper because we didn't have a really attractive learning algorithm at that point, and talk about some.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Comments and conclusions.",
                    "label": 0
                },
                {
                    "sent": "OK, So what is the?",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Exponential family PSR what are we trying to do with the exponential family?",
                    "label": 0
                },
                {
                    "sent": "PSR is trying to model a dynamical system because of course you want to use the model dynamical system to do planning and reinforcement learning thereafter.",
                    "label": 0
                },
                {
                    "sent": "So here's a trajectory of experience.",
                    "label": 0
                },
                {
                    "sent": "The current time is T, so we've observed all the actions and observations that have happened until time T shown in lower case.",
                    "label": 0
                },
                {
                    "sent": "Because we've already observed them.",
                    "label": 0
                },
                {
                    "sent": "So that's the history at time T and the future, which is an infinite trajectory of future actions and observations are random variables.",
                    "label": 0
                },
                {
                    "sent": "And so we talk about the conditional future F is for future the infinite future given the current history.",
                    "label": 0
                },
                {
                    "sent": "And of course the goal of modeling is to model this conditional distribution of the infinite future given any history, right?",
                    "label": 1
                },
                {
                    "sent": "That's our task.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what do PSR's do?",
                    "label": 0
                },
                {
                    "sent": "These central predictive state representations assumption is that the parameters describing the conditional distribution of some short term future or state.",
                    "label": 1
                },
                {
                    "sent": "That is, the parameters that define the conditional distribution of short-term futures.",
                    "label": 0
                },
                {
                    "sent": "Are a sufficient statistic of history capture all the information there is in history so we can make the infinite future prediction for that history just as well as if we had the entire history.",
                    "label": 1
                },
                {
                    "sent": "So that's the key PSR assumption.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so is this does not make any sense.",
                    "label": 0
                },
                {
                    "sent": "Is this assumption any good?",
                    "label": 0
                },
                {
                    "sent": "So let me describe what we already know about what follows from this assumption.",
                    "label": 0
                },
                {
                    "sent": "So for the discrete observation case it's known that for example, all Hmm's flat Hmm's in Palm DPS, you can capture it by the by the expectations of a core set of indicator random variables which basically is the probability of specific action observation sequences of length no more than a number of underlying states in HMM.",
                    "label": 1
                },
                {
                    "sent": "Palm DP so there is a short term future whose statistics are exactly able to capture state.",
                    "label": 0
                },
                {
                    "sent": "In the case of Hmm's, in Palm DP's, so that's the discrete observation case.",
                    "label": 0
                },
                {
                    "sent": "The continuous observation case we're going to build on today that we already know is that if we assume that the next, if we assume a Gaussian distribution jointly Gaussian distribution for the next 10 observations, then the parameters, the mean and the covariance of the Gaussian are in fact the state represent our.",
                    "label": 0
                },
                {
                    "sent": "Are perfect representations of all linear dynamical systems.",
                    "label": 1
                },
                {
                    "sent": "So if the dimension of the linear dynamical system or common filter system is N, then you don't the short term future need not be anymore than length, and so that's what we know, so this.",
                    "label": 0
                },
                {
                    "sent": "So the point is that this assumption the central assumptions that PSR makes is actually a fruitful assumption.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what is the ear?",
                    "label": 0
                },
                {
                    "sent": "The exponential family assumption?",
                    "label": 0
                },
                {
                    "sent": "The exponential families are basically generalizes the examples.",
                    "label": 0
                },
                {
                    "sent": "We just saw an assume that the distribution of short term future is an exponential family form.",
                    "label": 1
                },
                {
                    "sent": "So what does that?",
                    "label": 0
                },
                {
                    "sent": "Here is the.",
                    "label": 0
                },
                {
                    "sent": "Here is the assumption that the modeling assumption is that the density of a future given history is has exponential form.",
                    "label": 0
                },
                {
                    "sent": "So this is a standard exponential form fee of Fenner futures.",
                    "label": 0
                },
                {
                    "sent": "The parameters of the distribution are accepte.",
                    "label": 0
                },
                {
                    "sent": "We use S because it is the parameters of this exponential family that form the state representation.",
                    "label": 0
                },
                {
                    "sent": "So SMT is the state fear the future other features of the future and the log partition function is the usual lock partition function.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 1
                },
                {
                    "sent": "So these parameters will be.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "State, so how are we going to build a model from this?",
                    "label": 0
                },
                {
                    "sent": "We have to have a way of maintaining this state representation.",
                    "label": 0
                },
                {
                    "sent": "That is, we have a current state.",
                    "label": 0
                },
                {
                    "sent": "We take an action scene observation.",
                    "label": 0
                },
                {
                    "sent": "We have to update state.",
                    "label": 0
                },
                {
                    "sent": "So how does that process work?",
                    "label": 0
                },
                {
                    "sent": "Let's just talk about that.",
                    "label": 0
                },
                {
                    "sent": "So here is the current history we've already seen up until they the blue part.",
                    "label": 0
                },
                {
                    "sent": "The lower case part and we have our current representation of state.",
                    "label": 0
                },
                {
                    "sent": "However, we got it.",
                    "label": 0
                },
                {
                    "sent": "We talk about learning that in a minute in a few minutes, but this is our current representation of state.",
                    "label": 0
                },
                {
                    "sent": "And we take an action A and see another observation.",
                    "label": 0
                },
                {
                    "sent": "So now the new future and we want to update our state representation so that it captures the distribution of length future from the new history T + 1.",
                    "label": 0
                },
                {
                    "sent": "How does this process work?",
                    "label": 0
                },
                {
                    "sent": "Because that's how the model works.",
                    "label": 0
                },
                {
                    "sent": "So we use what's called conditioning and extension and condition by basically formulating a intermediate representation.",
                    "label": 0
                },
                {
                    "sent": "Which captures the distribution of length N plus one futures.",
                    "label": 0
                },
                {
                    "sent": "Also an exponential form.",
                    "label": 0
                },
                {
                    "sent": "So there's an intermediate representation that extends the length N distribution to a length N plus one distribution.",
                    "label": 0
                },
                {
                    "sent": "And we have to preserve.",
                    "label": 0
                },
                {
                    "sent": "We have to choose the features in such a way that the exponential family form is is preserved and will talk about how to do that.",
                    "label": 0
                },
                {
                    "sent": "So there is a key step extension that takes the current state and has some parameters.",
                    "label": 0
                },
                {
                    "sent": "In fact, it is these parameters that form the model parameters of the FPS our model, right?",
                    "label": 0
                },
                {
                    "sent": "It is these parameters that the current state and extend it.",
                    "label": 0
                },
                {
                    "sent": "And then of course there's the conditioning step that takes the observation an.",
                    "label": 0
                },
                {
                    "sent": "And then conditions it back to a length an length and distribution.",
                    "label": 0
                },
                {
                    "sent": "So it's extending condition, right?",
                    "label": 0
                },
                {
                    "sent": "That's the process that gets repeated in order to project the model forward.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so what's that task?",
                    "label": 0
                },
                {
                    "sent": "Our task is we're going to be given a trajectory of length T data, and we have to learn this model.",
                    "label": 1
                },
                {
                    "sent": "This FPS, our model.",
                    "label": 0
                },
                {
                    "sent": "How do we do that?",
                    "label": 0
                },
                {
                    "sent": "One of the things to learn that three things to learn.",
                    "label": 0
                },
                {
                    "sent": "We have to learn the dimension.",
                    "label": 0
                },
                {
                    "sent": "What is the dimension of the distribution we have to model in order to capture state?",
                    "label": 0
                },
                {
                    "sent": "We have to find the features of the future and we have to learn the model parameters.",
                    "label": 1
                },
                {
                    "sent": "In this talk, I'm really just going to focus on the model parameters part and not the dimension an features the future.",
                    "label": 0
                },
                {
                    "sent": "We don't really have any currently any great answers for dimension for the future of the future we use basically density estimation, feature extraction ideas, dealer petrol and or ideas from them, so it's not terribly novel.",
                    "label": 0
                },
                {
                    "sent": "The feature of the future part, the model parameters part is where I'm going to focus OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's say that was the general exponential family PSR.",
                    "label": 0
                },
                {
                    "sent": "Let's talk about the special case of linear Lin.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Exponential family PSR.",
                    "label": 0
                },
                {
                    "sent": "So what do I mean by linear linear ones?",
                    "label": 0
                },
                {
                    "sent": "The first linear is because we're going to assume that the extension function is a linear function.",
                    "label": 0
                },
                {
                    "sent": "So this is the state of this N + 1.",
                    "label": 0
                },
                {
                    "sent": "The parameters of this N + 1 dimensional Gaussian distribution is computed as a linear function with the parameters Theta of the current parameters St. And Furthermore, we're going to assume that the conditioning itself is also linear.",
                    "label": 0
                },
                {
                    "sent": "That is, a new state is a linear function dollar.",
                    "label": 0
                },
                {
                    "sent": "Now the function can depend on the observation, right?",
                    "label": 0
                },
                {
                    "sent": "It's conditioning.",
                    "label": 0
                },
                {
                    "sent": "And so we assume both of these are linear, and if we assume it, if we assume this, then the overall state update is linear.",
                    "label": 0
                },
                {
                    "sent": "That is, the next state is this observation dependent linear function of state.",
                    "label": 0
                },
                {
                    "sent": "Now this looks like a really severe assumption, right?",
                    "label": 0
                },
                {
                    "sent": "But notice that this is linear in states.",
                    "label": 0
                },
                {
                    "sent": "But not linear in the observation, so it is a nonlinear function of the observation.",
                    "label": 0
                },
                {
                    "sent": "But if we make these assumptions, then 2 two things result.",
                    "label": 0
                },
                {
                    "sent": "Basically two useful computational properties.",
                    "label": 0
                },
                {
                    "sent": "Maximum likelihood gradients are easy to derive, and more importantly, linearity will make efficient approximations possible.",
                    "label": 1
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's talk about.",
                    "label": 0
                },
                {
                    "sent": "Let's get to that part of the talk, so here.",
                    "label": 1
                },
                {
                    "sent": "So how are we going to learn this?",
                    "label": 0
                },
                {
                    "sent": "We're going to learn this through maximum likelihood.",
                    "label": 0
                },
                {
                    "sent": "We're going to fit the model to the data to maximum likelihood.",
                    "label": 1
                },
                {
                    "sent": "So here's the likelihood equation.",
                    "label": 0
                },
                {
                    "sent": "The log likelihood equation.",
                    "label": 1
                },
                {
                    "sent": "OK, so now this should look fairly familiar to those of you who do graphical model like things, but the really key thing is there are no latent variables in this model.",
                    "label": 0
                },
                {
                    "sent": "Right, there's no latent variables in this model, so we can do it.",
                    "label": 0
                },
                {
                    "sent": "We don't have to do M, there's no need for you, and that's the win, right?",
                    "label": 0
                },
                {
                    "sent": "That is where if there is a win, which I know some of you should be skeptical about reasonably so you know that would be the source of the win.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "I'm not a fan of EMS, as you can tell.",
                    "label": 0
                },
                {
                    "sent": "OK, so I've defined the likelihood we can do gradient ascent unlikelihood an and in some cases in toy cases we can do exactly exactly.",
                    "label": 0
                },
                {
                    "sent": "So let's first do that.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let's take toy cases and do exact gradient calculations.",
                    "label": 0
                },
                {
                    "sent": "And so here I will show you some results on really easy problems.",
                    "label": 0
                },
                {
                    "sent": "Small problems palm DP like problems with two 345 states.",
                    "label": 0
                },
                {
                    "sent": "Tiny ones like that and the idea here is to just show you that.",
                    "label": 0
                },
                {
                    "sent": "So we're comparing the performance.",
                    "label": 0
                },
                {
                    "sent": "We are comparing the data likelihood under the Model 2 model so we know the true model in these cases, so we can compute the likelihood of the data and we can compute the likelihood under the learned FPS are.",
                    "label": 1
                },
                {
                    "sent": "And ask and also learn and also compute the likelihood for a completely naive model that makes uniform predictions.",
                    "label": 0
                },
                {
                    "sent": "And what we're asking is what percentage of the difference between the naive model in the true model does the FPS are makes up.",
                    "label": 0
                },
                {
                    "sent": "So ideally we want to be at 100%, that is, it gets exactly the true thing, and so you know the training and test set performance and you can see more or less many of the problems gets close to 100%.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is just where we can do the exact calculations, which unfortunately we can't really do in.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Large domains.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is the part that's sort of distinct from the next one.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So tractable learning algorithm.",
                    "label": 0
                },
                {
                    "sent": "We want to come up with something that's more tractable.",
                    "label": 0
                },
                {
                    "sent": "So first, before I describe the the assumptions we make, let's look at why exact MLE maximum likelihood is intractable.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "You know this should be fairly familiar to all of you.",
                    "label": 0
                },
                {
                    "sent": "This is the inference problem and not surprisingly, inferences intractable.",
                    "label": 0
                },
                {
                    "sent": "So we're going to use standard approximate inference techniques.",
                    "label": 0
                },
                {
                    "sent": "Variational, we tried all kinds of things, naive mean field, loopy belief, propagation, things of that sort, and we can do those sorts of things here as well.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to talk very much about that.",
                    "label": 0
                },
                {
                    "sent": "I'm going to tell you what I'm going to talk about in one minute, so we also have this problem that we want to be able to deal with problems where we have 10s of thousands of features.",
                    "label": 0
                },
                {
                    "sent": "If you have 10s of thousands of features.",
                    "label": 0
                },
                {
                    "sent": "Extension matrix will be of that dimension and we can't really do that.",
                    "label": 0
                },
                {
                    "sent": "And there are again standard things that people have developed.",
                    "label": 0
                },
                {
                    "sent": "Basically, low rank approximation ideas and we we use those.",
                    "label": 0
                },
                {
                    "sent": "The other of course, bigger problems.",
                    "label": 0
                },
                {
                    "sent": "Even if you could do all that exactly, is that we have a sum from time T = 1 to the length of the trajectory, and to compute a gradient step will have to do this sort of calculation once for every time step for each gradient calculation, and that's too much also.",
                    "label": 0
                },
                {
                    "sent": "So we're going to get this is the part I'm going to focus on.",
                    "label": 0
                },
                {
                    "sent": "How do we get a form for the likelihood that an approximate form that we can do tractable things with?",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so this is the equation we're going to simplify, so here's the exact likelihood of the data we're going to make 2 assumptions.",
                    "label": 1
                },
                {
                    "sent": "And get this form.",
                    "label": 0
                },
                {
                    "sent": "So we're going to get a approximate lower bound on the likelihood of the data, and that's the one we're going to do.",
                    "label": 1
                },
                {
                    "sent": "Gradient methods on, and the way we get it is, well, one thing that's clearly familiar with all those who work in graphical models.",
                    "label": 0
                },
                {
                    "sent": "We apply Jensen's inequality a couple of times and that gets to the lower bound, but the other more challenging assumptions we make is we make this zero covariance assumption between so before.",
                    "label": 0
                },
                {
                    "sent": "Before I describe that.",
                    "label": 0
                },
                {
                    "sent": "You know basically what it is is an empirical average, right?",
                    "label": 0
                },
                {
                    "sent": "We're taking a sum from T going from one to capital T and we're averaging it.",
                    "label": 0
                },
                {
                    "sent": "So there's an empirical expectation.",
                    "label": 0
                },
                {
                    "sent": "And if you just replace the Summon normalization by an empirical expectation, you should get expectation of a product with the expectation of the log partition function.",
                    "label": 0
                },
                {
                    "sent": "And basically zero covariance assumption allows us to split that first term into the product of this form.",
                    "label": 0
                },
                {
                    "sent": "Andy Jensen's inequality allows us to get the log partition function like this and it gives us a lower bound in which we can do very understandable right?",
                    "label": 0
                },
                {
                    "sent": "So I don't think this would be terribly surprising to those of you who work on which I don't really work in graphical models.",
                    "label": 0
                },
                {
                    "sent": "So this is all quite quite interesting to me.",
                    "label": 0
                },
                {
                    "sent": "And of course, we could use the same tricks.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Other models, but let's stay with this particular model and let's start to understand what this approximate likelihood equation says.",
                    "label": 0
                },
                {
                    "sent": "So what is the first term?",
                    "label": 0
                },
                {
                    "sent": "The first term is the unconditional expectation.",
                    "label": 0
                },
                {
                    "sent": "Of the parameters of the exponential form, which are states.",
                    "label": 0
                },
                {
                    "sent": "So it is the stationary distribution of states.",
                    "label": 1
                },
                {
                    "sent": "With a you know are going to city assumption underlying that we can assume we can think of this first term as a stationary distribution of states.",
                    "label": 0
                },
                {
                    "sent": "Anfora linear linear FPS are.",
                    "label": 0
                },
                {
                    "sent": "This can be computed.",
                    "label": 0
                },
                {
                    "sent": "As a solution to a linear system of equations from the stationary distribution of observations which we do get to see.",
                    "label": 1
                },
                {
                    "sent": "So given our current parameters data, we can use that to compute the stationary distribution over states in a linear way from this stationary distribution of observations which we actually get to see.",
                    "label": 0
                },
                {
                    "sent": "So this term we can compute fairly simply.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, let's look at this.",
                    "label": 0
                },
                {
                    "sent": "What is this?",
                    "label": 0
                },
                {
                    "sent": "This is the unconditional expectation to the features.",
                    "label": 1
                },
                {
                    "sent": "Basically this is a stationary distribution of features.",
                    "label": 1
                },
                {
                    "sent": "So this we can just go through data once and be done, compute this one, sweep the data and we get we get the we get we get this form, the other one we have to do it every time we change we have to redo every time we change the parameters.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's how we can compute these two terms, and this last term is the log partition function.",
                    "label": 0
                },
                {
                    "sent": "Using the stationary distribution of States and we do the same sort of approximations that people do, but for the stationary distribution, as opposed to once for each term in that summation, and so we do the same approximations for this that people have tried it.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Graphical models OK, So what is the gradient look like?",
                    "label": 0
                },
                {
                    "sent": "Here's what the gradient looks like.",
                    "label": 0
                },
                {
                    "sent": "The gradient with respect to the stationary distribution over states.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is actually a very nice form.",
                    "label": 0
                },
                {
                    "sent": "What does this say?",
                    "label": 0
                },
                {
                    "sent": "This is saying we want to change the parameters of the model where the parameters of the extension function or the parameters extension function the linear part.",
                    "label": 0
                },
                {
                    "sent": "So that the expected features of the future.",
                    "label": 1
                },
                {
                    "sent": "Induced by the model.",
                    "label": 0
                },
                {
                    "sent": "Match the expected features of the future observed in the data.",
                    "label": 1
                },
                {
                    "sent": "Right, so this is a very intuitive algorithm, right?",
                    "label": 0
                },
                {
                    "sent": "It's saying let's move the model parameters so that the model computer expectation of the features.",
                    "label": 0
                },
                {
                    "sent": "Matches the empirical expectation of the features that we are observing in the data and that becomes the basic underlying, intuitive, intuitive algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I'm saying this.",
                    "label": 0
                },
                {
                    "sent": "I already said this, find model parameters, Theta cetera, models stationary distribution of feature matches the empirical spatial distribution of features.",
                    "label": 1
                },
                {
                    "sent": "And it's tractable because of course the model is fully the IT has no latent variables and the state update is linear.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "How does this work?",
                    "label": 0
                },
                {
                    "sent": "So let's try a couple of problems.",
                    "label": 0
                },
                {
                    "sent": "Before I describe the harder problems we tried this on.",
                    "label": 0
                },
                {
                    "sent": "One problem that happens is we can't do the same comparison we just did in the past where we're looking at comparison to true likelihood.",
                    "label": 0
                },
                {
                    "sent": "Because we're looking at really complex problems, we don't have two likelihood.",
                    "label": 0
                },
                {
                    "sent": "Furthermore.",
                    "label": 0
                },
                {
                    "sent": "We're doing we're not even computing the because we can't even compute likelihoods, right?",
                    "label": 0
                },
                {
                    "sent": "We're using a lower bound, so you can't really compare lower bounds in any sort of sensible way.",
                    "label": 0
                },
                {
                    "sent": "So what we're going to do instead is we're going to take the model and use reinforcement learning on the learning model and ask how well does it do in the in the reward sense.",
                    "label": 0
                },
                {
                    "sent": "In the usual reinforcement learning sense.",
                    "label": 1
                },
                {
                    "sent": "So for example, let's do some simple problems before I delete the more interesting problem.",
                    "label": 0
                },
                {
                    "sent": "So here is the cheese made in the four by three maze that various people have used.",
                    "label": 0
                },
                {
                    "sent": "An here's the performance of the random sort of model.",
                    "label": 0
                },
                {
                    "sent": "Here is the performance of a first order model.",
                    "label": 0
                },
                {
                    "sent": "Here's the performance of the optimal model here, because we know optimality, and here is the performance.",
                    "label": 0
                },
                {
                    "sent": "This is a reward average award.",
                    "label": 0
                },
                {
                    "sent": "Of the FPS, our model and you know it doesn't really get all the way to optimal, but it does perform 1st order Markov with the and the conclusion we can draw from that is that it is finding more of state than a first order Markov model is at least in order to.",
                    "label": 0
                },
                {
                    "sent": "So we build a model where we build a model assuming the 1st order Markov condition holds, that is the, which is which means.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "No, no no.",
                    "label": 0
                },
                {
                    "sent": "This is maybe not going to same four by three.",
                    "label": 0
                },
                {
                    "sent": "Well, this is a palm DP.",
                    "label": 0
                },
                {
                    "sent": "Jimmy firm up in the observation yes yes yes yes sorry yes.",
                    "label": 0
                },
                {
                    "sent": "So it's a very impoverished model.",
                    "label": 0
                },
                {
                    "sent": "We're trying to see all this is showing is all these results are showing really is that we're doing better capturing more state than just the last observation does in effect.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, but I really wanted to see if this could goal of this work was to really get scalable algorithms.",
                    "label": 0
                },
                {
                    "sent": "So here's a problem we tried.",
                    "label": 0
                },
                {
                    "sent": "We made up a problem.",
                    "label": 0
                },
                {
                    "sent": "This is what we call the ball bouncing problem, which is basically a 10 by 11 pixel array and a pixel just bounces about when hits the wall it bounces and the control task is we get maximum reward by keeping it in the middle of the square so the reward falls off and the actions we have our reverse direction.",
                    "label": 0
                },
                {
                    "sent": "Off the boats and you know in this in this state in this problem with 110 possible observations, and it turns out it's a second order Markov problem, because noise free observations.",
                    "label": 1
                },
                {
                    "sent": "So this is one problem we did, and we wanted to find a problem which is not short order Markov.",
                    "label": 0
                },
                {
                    "sent": "So we can really test whether we're capturing information from a lot of history.",
                    "label": 0
                },
                {
                    "sent": "So we had a noisy version of this problem in which several pixels have some independent probability of turning on and off.",
                    "label": 0
                },
                {
                    "sent": "So now you try to see where the ball is.",
                    "label": 0
                },
                {
                    "sent": "It's very hard to see right, because every pixel has some probability of turning on and off, and this is not a shorter Markov problem.",
                    "label": 0
                },
                {
                    "sent": "So now there are.",
                    "label": 0
                },
                {
                    "sent": "Now there are 210 possible observations, and again it's no longer.",
                    "label": 1
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Same remark off.",
                    "label": 0
                },
                {
                    "sent": "So how do we do in this?",
                    "label": 0
                },
                {
                    "sent": "But before I do that.",
                    "label": 0
                },
                {
                    "sent": "Before I do that, I want to just talk a little bit about how we choose features because we have to choose features in such a way that conditioning becomes linear and I just want to give you a sense of how we could incorporate prior knowledge of the domain into our observation feature vector.",
                    "label": 0
                },
                {
                    "sent": "So we have this 10 by 11 binary feature array right by binary observation array and our features basically.",
                    "label": 0
                },
                {
                    "sent": "Are conjunctions of observations across time.",
                    "label": 0
                },
                {
                    "sent": "We know that a ball moves diagonally, so we put features.",
                    "label": 0
                },
                {
                    "sent": "If you like binary features on these conjunctions, that becomes our feature space for the, we assume a length of two in the short in the sense of what future distribution we're modeling, and so that becomes basically are.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Our model graphical form of the model and an extension will then do the normal extension going two time steps out.",
                    "label": 0
                },
                {
                    "sent": "So this is the form of our features.",
                    "label": 0
                },
                {
                    "sent": "Just if you're interested in that.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so how did it do?",
                    "label": 0
                },
                {
                    "sent": "How do we do?",
                    "label": 0
                },
                {
                    "sent": "Here are the results.",
                    "label": 0
                },
                {
                    "sent": "Again, this is the performance of the random policy.",
                    "label": 0
                },
                {
                    "sent": "A first order Markov assumption leads to in the model leads to the red performance in terms of average or higher is better.",
                    "label": 0
                },
                {
                    "sent": "You know numbers are negative and the FPS are does.",
                    "label": 0
                },
                {
                    "sent": "Does does better still this is on the noises on the harder task the noisy one.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, one more task, and then I'll be done.",
                    "label": 0
                },
                {
                    "sent": "We also did this robot domain, in which we simulated robot in which the images are what you're seeing with what the robot gets.",
                    "label": 0
                },
                {
                    "sent": "This is the overhead view of the domain, so it's a very stylized but you know, but still the observation space is very large, so it's not a real robotics domain, but it's a made up robotics robotics domain, so observations are camera images.",
                    "label": 0
                },
                {
                    "sent": "We extract features binary features about 1000 binary features.",
                    "label": 1
                },
                {
                    "sent": "That basically looks like edge detection's.",
                    "label": 0
                },
                {
                    "sent": "And from this we construct our graphical form of the features for our the that we use in our in the exponential family format.",
                    "label": 0
                },
                {
                    "sent": "About 12,000 features.",
                    "label": 0
                },
                {
                    "sent": "So it's a pretty big, pretty big feature space.",
                    "label": 1
                },
                {
                    "sent": "We used an equal to three 200,000 samples.",
                    "label": 0
                },
                {
                    "sent": "Various approximations that we have into.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here are the results.",
                    "label": 0
                },
                {
                    "sent": "So we had various Maps.",
                    "label": 0
                },
                {
                    "sent": "I showed you one map.",
                    "label": 0
                },
                {
                    "sent": "There were two Maps we use coarse features and and some finer features.",
                    "label": 0
                },
                {
                    "sent": "These are the edge detection like things that we're talking about and basically the short answer is that it we were able to do this whole PSR thing on a very large observation space.",
                    "label": 0
                },
                {
                    "sent": "Now the and and basically outperform a first order Markov system so.",
                    "label": 0
                },
                {
                    "sent": "Again, the claim really is that mean there are two real claims here, right?",
                    "label": 0
                },
                {
                    "sent": "One is we've made PSR at least applicable to very large problems, which had, which was a challenge we need to meet, and also that we are capturing more state information than a first order Markov.",
                    "label": 0
                },
                {
                    "sent": "How much more is?",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Hard to quantify from this OK Diner standing up slightly to conclude.",
                    "label": 0
                },
                {
                    "sent": "It turns out that learning a linear linear model is fairly straightforward.",
                    "label": 1
                },
                {
                    "sent": "Mainly because we get these interpretations based on stationary distributions, which makes the problem of learning fairly simple.",
                    "label": 1
                },
                {
                    "sent": "We believe that this sort of method can be reached at the point where we can try it on real domains, and that's the next challenge where we're heading up to.",
                    "label": 0
                },
                {
                    "sent": "OK, thank you.",
                    "label": 0
                },
                {
                    "sent": "So I was wondering about.",
                    "label": 0
                },
                {
                    "sent": "This can be extended addition operations.",
                    "label": 0
                },
                {
                    "sent": "In this model, consistency in a formal sense, yeah.",
                    "label": 0
                },
                {
                    "sent": "Yes, yes.",
                    "label": 0
                },
                {
                    "sent": "Sure, that would be given set of features.",
                    "label": 0
                },
                {
                    "sent": "It's possible and 2nd order.",
                    "label": 0
                },
                {
                    "sent": "So there is a way of thinking about how the features which are at least at least in the way we thought about it, which is binary features an features that are basically conjunctions or binary features where the edges are the conjunctions we mean.",
                    "label": 0
                },
                {
                    "sent": "Then we can think about the what features we can include so that the extension and conditioning comes back to exactly those features.",
                    "label": 0
                },
                {
                    "sent": "And so I think there is a.",
                    "label": 0
                },
                {
                    "sent": "There is a nice mathematical way of saying it, but there is a graphical way, at least we know.",
                    "label": 0
                },
                {
                    "sent": "Of how to say it?",
                    "label": 0
                },
                {
                    "sent": "But it's still.",
                    "label": 0
                },
                {
                    "sent": "I wish there was a.",
                    "label": 0
                },
                {
                    "sent": "In nice resolution to the question you have, which I also have, but there is a graphical intuition as to how this could work.",
                    "label": 0
                },
                {
                    "sent": "There isn't a mathematical intuition yet for me.",
                    "label": 0
                },
                {
                    "sent": "In other words, given a domain, we can design features and tell you how that would work, but I can't give you a mathematical condition that if met would be would be true.",
                    "label": 0
                },
                {
                    "sent": "At least I haven't thought about it enough yet.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Extended to compositional predictions.",
                    "label": 0
                },
                {
                    "sent": "So rather than just predictions about direct observations in the next in time steps.",
                    "label": 0
                },
                {
                    "sent": "About future states.",
                    "label": 0
                },
                {
                    "sent": "Absolutely.",
                    "label": 0
                },
                {
                    "sent": "One of the things on my agenda which I haven't gotten to yet, is to blur the distinction between tenet like things in PSR like things, and I see no reason why it can't be done.",
                    "label": 0
                },
                {
                    "sent": "Just haven't made the effort yet.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "But if I understand well, you are using parcel history slices to construct this PSR.",
                    "label": 0
                },
                {
                    "sent": "So in principle you could build a second order Markov model on this.",
                    "label": 0
                },
                {
                    "sent": "Historic slices will be we're actually not using history slices to build a PS, are we not in this form?",
                    "label": 0
                },
                {
                    "sent": "We have done that in the past in suffix tree like suffix history based algorithms for discrete observation, PSR's.",
                    "label": 0
                },
                {
                    "sent": "In this case we're doing maximum likelihood.",
                    "label": 0
                },
                {
                    "sent": "On a on a parametric form to fit the data right?",
                    "label": 0
                },
                {
                    "sent": "So we're so I just want to correct that we're not using a suffix history like idea here, but I think your larger question might have been why didn't we compare 2nd order mark offer to mark off?",
                    "label": 0
                },
                {
                    "sent": "The observation space is so large right in these in these cases that even second order Markov is very large.",
                    "label": 0
                },
                {
                    "sent": "Should have kept us from trying it, maybe not, but it is a very large space, right?",
                    "label": 0
                },
                {
                    "sent": "Because we're looking at a very large observation space, so even just squaring it is a huge huge thing.",
                    "label": 0
                },
                {
                    "sent": "Sparse.",
                    "label": 0
                },
                {
                    "sent": "It might be might be, so you're right, it would be a fair comparison to try it against higher order Markov processes.",
                    "label": 0
                },
                {
                    "sent": "Assumption on the covariance.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Other domains here or you don't know.",
                    "label": 0
                },
                {
                    "sent": "That assumption, important for practical reasons or just one theoretical?",
                    "label": 0
                },
                {
                    "sent": "It wasn't satisfied here, so you're right, we could certainly apply it without that condition.",
                    "label": 0
                },
                {
                    "sent": "Holding it was the condition needed in order to derive the approximate maximum likelihood equation.",
                    "label": 0
                },
                {
                    "sent": "The more it's violated, the more that approximate equation is wrong, and so so.",
                    "label": 0
                },
                {
                    "sent": "So there is only so much you can say about that.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}