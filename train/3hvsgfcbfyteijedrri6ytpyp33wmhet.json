{
    "id": "3hvsgfcbfyteijedrri6ytpyp33wmhet",
    "title": "Discovering Cyclic Causal Models by Independent Components Analysis",
    "info": {
        "author": [
            "Gustavo Lacerda, Carnegie Mellon University"
        ],
        "published": "July 30, 2008",
        "recorded": "July 2008",
        "category": [
            "Top->Computer Science->Data Modeling"
        ]
    },
    "url": "http://videolectures.net/uai08_lacerda_dccm/",
    "segmentation": [
        [
            "OK, so as he said.",
            "This talk is about discovering physical models by independent components analysis and we are interested in identifiability questions as well as some algorithmic."
        ],
        [
            "So first let me tell you our goal.",
            "Our goal is to discover the structure and the parameters.",
            "Of linear structural equation models with only observation, ULL data meaning without.",
            "This one oh sorry.",
            "Yeah, that would be good.",
            "Hear me now.",
            "So our goal is to discover the structure and parameters of linear structural equation models with only observational data."
        ],
        [
            "So first I'm going to introduce linear structural equation models.",
            "Then I'm going to present the Lingam method, which uniquely identifies a structural equation model using the cyclicity assumption.",
            "And this uses ICA.",
            "Then I'll present our new method, which is based on the game, but it also handles cycles.",
            "Now the answer will be undetermined, meaning we will have multiple models that give the same likelihood for the data.",
            "Finally, I argue that stability can be used as a constraint for selecting among these many.",
            "Models many equivalen."
        ],
        [
            "Model.",
            "So.",
            "Linear structural equation models.",
            "Are used in econometrics, biology, social Sciences.",
            "They are a kind of directed graphical model.",
            "That have a causal interpretation so.",
            "As you can see here X one is a cause of X3.",
            "X3 the cause of X4.",
            "And each node is a function of its variance.",
            "So in particular a linear combination.",
            "So as you can see, X3 is a linear combination of X, one X2 and its own error term E3.",
            "And typically the exs are observed and the ease are not.",
            "Causal here means that we these models tell you what would happen if you were to manipulate certain variable.",
            "So for example, if we were to manipulate X3."
        ],
        [
            "The equation for X3 changes.",
            "And the graph is also changed accordingly.",
            "As you can see."
        ],
        [
            "So just give an example.",
            "X1 could be your appetite.",
            "X2 could be your impulsivity level, X3 is the amount of food you eat, an X4 would be your cholesterol level.",
            "So you can control the amount you eat."
        ],
        [
            "In particular, this would make your appetite independent of your cholesterol level."
        ],
        [
            "So linear structural equation models can also be cyclic, in which case they correspond to dynamical systems.",
            "So in this case.",
            "As you can see, the dynamical equation tells you that X3.",
            "At time, at any given time, step is a linear combination of X1 and X2.",
            "At the previous time step and E3.",
            "Now note that E3.",
            "Does not have a time index.",
            "That's because it's constant.",
            "So this means that.",
            "Our models correspond to deterministic dynamical systems.",
            "And they converge.",
            "They reach equilibrium unless they are unstable.",
            "As you can see, the equilibrium equation corresponds closely to the dynamical equation.",
            "They have the same coefficients."
        ],
        [
            "So our goal again, given a distribution of equilibrium.",
            "We wanna.",
            "Recover the structure of the process.",
            "Find the values of this B matrix that entailed the observed distribution."
        ],
        [
            "So.",
            "The distribution of the error terms together with the equations determine a joint distribution over X.",
            "This is easy to see if you just solve the equation for X.",
            "You can see that X is just a mixture of the East.",
            "You can think of the error terms propagating in an infinite cycle perfectly through the cycle in many times.",
            "And we give a new name to this I -- B inverse we call it A and it's called the mixing matrix because it tells you how these mix."
        ],
        [
            "Into the excess.",
            "So now let's give the assumptions needed for our model.",
            "So we assume the data equilibrium of a linear structural equation model.",
            "Yeah, some sample data ID that the error terms have positive variance.",
            "At most one error term is Gaussian.",
            "We make the weak causal Markov assumption.",
            "So if X&Y are causally unconnected then they are independent.",
            "This means that there's no active path conditional on the empty set, so X doesn't cause Y and widen calls X, and nobody causes both.",
            "And colors efficiencies, but there's no hidden confounders.",
            "That's kind of a big assumption.",
            "And another big assumption.",
            "Causal faithfulness.",
            "The effect of E sebion exhibi is not zero."
        ],
        [
            "So causal faithfulness we define it here and show how it can be violated.",
            "So in the second case, it's never violated in cyclic.",
            "In the second case, it could be violated if, for example, the coefficient of X1 in its own dynamical equation is 1.",
            "And other violations can also happen if a certain polynomial function of the cycle product."
        ],
        [
            "Is equal to 1.",
            "Now we've covered linear structure equation models, and I'm going to prison."
        ],
        [
            "Lincoln method, but first.",
            "The more fundamental question what can be identified in principle from just observation, ULL data.",
            "The answer is when the error terms of Gaussian all you can get is that the separation equivalence class.",
            "So if you have these two models where X1 causes X2 and X2 causes X1.",
            "They will be.",
            "They will have the same distribution, the same joint distribution."
        ],
        [
            "So.",
            "If we plot the joint distribution, you can see that this cloud here looks just like this cloud here.",
            "So in the Gaussian case, there's no way to tell them apart.",
            "But in the non Gaussian case, in this case the uniform is an example.",
            "You can tell that the two joint distributions are different.",
            "ICA is going to exploit this difference.",
            "And as you can see in the Gaussian case, the separation equivalence is the same thing as distribution equivalence in the non Gaussian case.",
            "This operation equivalence does not imply distributionally equivalents."
        ],
        [
            "Distribution equivalence.",
            "Now let's talk about ICA.",
            "So this cocktail party problem, you have two sources of sound.",
            "And you're capturing them through microphones.",
            "They're both linear mixtures.",
            "Different linear mixtures.",
            "We can represent this as this equation X = 80, which is just which is the same as the equation we had before.",
            "So.",
            "We want to get back to the original signals, so we want the inverse of the mixing matrix.",
            "So we defined to just be the inverse of the mixing matrix.",
            "And if you look at that, if you're only observing X, so there would be infinitely many solutions for A&E.",
            "So you would say there's nothing you can do, but if you assume independence own gaussianity, it's possible to estimate A&E from just X, so that's what."
        ],
        [
            "ICA does.",
            "And the sources in the cocktail party problem correspond to the error terms in structural equation models.",
            "One problem of using ICA is that it it only finds this unmixing matrix.",
            "Up to a permutation of the roast.",
            "So this means that you can permute the error terms around and it wouldn't know which is, which doesn't have labels for them."
        ],
        [
            "So the Lincoln method.",
            "What would happen if you ran?",
            "I see a few generated data from a structural equation model like this one.",
            "And you ran ICA on it?",
            "You would."
        ],
        [
            "Something like this?",
            "You would get a W matrix representing it as a bipartite graph, which tells you how to mix the X is back into the East or unmix it if you will.",
            "So I say would return your W matrix like this one.",
            "And we first need to find a permutation of the East such that there is always a vertical arrow.",
            "So that's a constraint guaranteed by our equations."
        ],
        [
            "So we do that.",
            "We flip the 1st and 2nd error term and we get this."
        ],
        [
            "And then we label these accordingly.",
            "So we know that E1 will correspond to X1Y2."
        ],
        [
            "Two etc.",
            "And using the equation that we've derived, B = I -- W, we get back the original model.",
            "So that's Lincoln."
        ],
        [
            "It works.",
            "So Lincoln discovers the full structure of the DAG.",
            "By assuming causal sufficiency, which guarantees the independence of the error terms.",
            "And in particular, we cannot distinguish these two models."
        ],
        [
            "Now suppose you run ICA.",
            "And it gives you a matrix like this one.",
            "Now there's more than one way to permute the error terms so that the constraint is satisfied so that all the vertical arrows are present.",
            "Wellingham will pretend the red edge isn't there."
        ],
        [
            "So.",
            "Lingam cannot discover cyclic models.",
            "Because it assumes the data was generated by a DAG.",
            "And therefore it searches for an ordering.",
            "Which gives it.",
            "A single permutation.",
            "So if we stop imposing an ordering and we just search for any number of valid permutations.",
            "Then we can discover some models.",
            "So that's it.",
            "That's the idea."
        ],
        [
            "So the link the method.",
            "When the data looks like it will work just like Lingeman, return a single model.",
            "When the data looks cyclic more than one permutation will be considered valid, so it only turns the distribution equivalent set.",
            "That is more than one model.",
            "And distribution equivalent means that we can't do any better without experimental data or further assumptions.",
            "Because it just means that they produce the same joint distribution."
        ],
        [
            "So Lindy finds multiple row permutations of the W matrix returned by ICA.",
            "Solving this is equivalent to solving the so called constraint in rocks problem.",
            "Namely, if you have N rooks in an end by end chess board.",
            "You want to place them on the chess board so that no two rooks threaten each other and also no Rook is sitting on top of a 0.",
            "So naive algorithm is just to a depth first search.",
            "Better algorithm.",
            "That all the all the do significance testing and set all the zeros to 0 all the non zeros to one and run a case best assignment algorithm iteratively until you get a score less than N. In the worst case you have in factorial models and you do equally badly."
        ],
        [
            "Um?",
            "So.",
            "Let's simulate using this model.",
            "So the error terms are generated by sampling from a Gaussian squaring.",
            "15,000 data points.",
            "We prune the really small coefficients.",
            "The really small entries of the matrix.",
            "So we're going to run this now."
        ],
        [
            "And you get this set.",
            "Two models.",
            "And they explain the data equally well.",
            "They give the same likelihood for the data.",
            "So what can you do?",
            "How can you select one?",
            "We could start looking at their stability.",
            "So the first model if you multiply the coefficients in those edges, you get about 1.66.",
            "That would make it unstable.",
            "And the second model you get about 0.6.",
            "So it will be stable, so we can.",
            "Using this criterion we can rule out the first one.",
            "We can just use the second one, and as you can see, the second one actually corresponds pretty closely to the true model."
        ],
        [
            "Just to illustrate it."
        ],
        [
            "Pretty much."
        ],
        [
            "Same thing.",
            "And.",
            "So only one of them is stable.",
            "And since we're assuming the data is a set of equilibrium, then we are entitled to use this criterion.",
            "Natural question is, how powerful is this constraint of stability?"
        ],
        [
            "Much, can you rule out?",
            "And we proved the theorem that if the two model cycles don't intersect.",
            "Then exactly 1 model will be stable or at most one model will be stable.",
            "The intuition is just that the cycle product get inverted for any alternative permutation.",
            "And they're all independent of each other, so.",
            "So only only the true one will have.",
            "Allstate."
        ],
        [
            "Cycles.",
            "This is also been tried on real data.",
            "Z Tian Wang has a 10 variable model, 28 edges.",
            "And running link D he got 240 models distribution equivalent.",
            "But that's too many.",
            "So.",
            "Using the stability criterion, he verified that only two of those are stable.",
            "So the lesson is, this ability can be a powerful constraint.",
            "But there's a caveat.",
            "We are assuming no self loops, so we are assuming here that the coefficient of exhibi on the equation for exhibi is 0.",
            "And that's a pretty strong assumption."
        ],
        [
            "So in general.",
            "There's the question of what method should you use to discover your causal models.",
            "If your terms are Gaussian and you are assuming a simplicity.",
            "Then you can use constraint based vectors like PC or SGS or.",
            "Bayesian alternatives.",
            "And that gives you the D separation equivalence class.",
            "If you have non Gaussian error terms.",
            "You can run linggam and that gives you a unique model.",
            "If you have Gaussian error terms but you relax the cyclicity assumption.",
            "Richardson CCD algorithm can be used but it gives you a very very large class.",
            "And finally, if you have non Gaussian error terms.",
            "We can apply link D. Which works just as well as Lingam in the cyclic case.",
            "But I will give you.",
            "The full distribution equivalence class in the cyclic case.",
            "Another question you may be asking right now is.",
            "Is there a sharp line between Gaussian and non Gaussian?",
            "And the answer is no.",
            "So.",
            "You could, for example, have some error terms be Gaussian, some be non Gaussian.",
            "You could have too little data to really tell.",
            "So in the acyclic case.",
            "If you're interested in that question, you could read our paper from yesterday presented by Patrick.",
            "Is this poster session.",
            "In the second case, this hasn't been investigated yet."
        ],
        [
            "So.",
            "Finally.",
            "Summarizing.",
            "Lingam exploits non gaussianity in a single case.",
            "To give you a unique structural equation model rather than the separation equivalence, which is what Gaussian which is all you can do in the Gaussian case.",
            "Link D. Similarly, narrows the output class to the distribution equivalence class of structural equation models.",
            "In the cyclic case, or the more general case.",
            "But still there may be multiple structural equation models that explain the data equally well.",
            "And finally, I have argued that stability can sometimes be used to rule out a good chunk of those.",
            "Thank you.",
            "If you're trying to use the stability criterion you would you would make that assumption right.",
            "Dynamic.",
            "OK, I I may not have presented this optimally.",
            "So now we don't actually need that assumption.",
            "We can have self loops as long as the coefficient is not one.",
            "Poor baby.",
            "What do you mean by score based methods?",
            "Yeah, I think it would be interesting.",
            "I think it would be interesting to look at Bayesian ways to do this.",
            "But our current paper is not Bayesian.",
            "Yeah."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so as he said.",
                    "label": 0
                },
                {
                    "sent": "This talk is about discovering physical models by independent components analysis and we are interested in identifiability questions as well as some algorithmic.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So first let me tell you our goal.",
                    "label": 0
                },
                {
                    "sent": "Our goal is to discover the structure and the parameters.",
                    "label": 0
                },
                {
                    "sent": "Of linear structural equation models with only observation, ULL data meaning without.",
                    "label": 0
                },
                {
                    "sent": "This one oh sorry.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that would be good.",
                    "label": 0
                },
                {
                    "sent": "Hear me now.",
                    "label": 0
                },
                {
                    "sent": "So our goal is to discover the structure and parameters of linear structural equation models with only observational data.",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So first I'm going to introduce linear structural equation models.",
                    "label": 0
                },
                {
                    "sent": "Then I'm going to present the Lingam method, which uniquely identifies a structural equation model using the cyclicity assumption.",
                    "label": 0
                },
                {
                    "sent": "And this uses ICA.",
                    "label": 0
                },
                {
                    "sent": "Then I'll present our new method, which is based on the game, but it also handles cycles.",
                    "label": 1
                },
                {
                    "sent": "Now the answer will be undetermined, meaning we will have multiple models that give the same likelihood for the data.",
                    "label": 0
                },
                {
                    "sent": "Finally, I argue that stability can be used as a constraint for selecting among these many.",
                    "label": 1
                },
                {
                    "sent": "Models many equivalen.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Model.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Linear structural equation models.",
                    "label": 0
                },
                {
                    "sent": "Are used in econometrics, biology, social Sciences.",
                    "label": 0
                },
                {
                    "sent": "They are a kind of directed graphical model.",
                    "label": 1
                },
                {
                    "sent": "That have a causal interpretation so.",
                    "label": 0
                },
                {
                    "sent": "As you can see here X one is a cause of X3.",
                    "label": 0
                },
                {
                    "sent": "X3 the cause of X4.",
                    "label": 0
                },
                {
                    "sent": "And each node is a function of its variance.",
                    "label": 0
                },
                {
                    "sent": "So in particular a linear combination.",
                    "label": 0
                },
                {
                    "sent": "So as you can see, X3 is a linear combination of X, one X2 and its own error term E3.",
                    "label": 1
                },
                {
                    "sent": "And typically the exs are observed and the ease are not.",
                    "label": 0
                },
                {
                    "sent": "Causal here means that we these models tell you what would happen if you were to manipulate certain variable.",
                    "label": 0
                },
                {
                    "sent": "So for example, if we were to manipulate X3.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The equation for X3 changes.",
                    "label": 0
                },
                {
                    "sent": "And the graph is also changed accordingly.",
                    "label": 0
                },
                {
                    "sent": "As you can see.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So just give an example.",
                    "label": 0
                },
                {
                    "sent": "X1 could be your appetite.",
                    "label": 0
                },
                {
                    "sent": "X2 could be your impulsivity level, X3 is the amount of food you eat, an X4 would be your cholesterol level.",
                    "label": 0
                },
                {
                    "sent": "So you can control the amount you eat.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In particular, this would make your appetite independent of your cholesterol level.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So linear structural equation models can also be cyclic, in which case they correspond to dynamical systems.",
                    "label": 1
                },
                {
                    "sent": "So in this case.",
                    "label": 1
                },
                {
                    "sent": "As you can see, the dynamical equation tells you that X3.",
                    "label": 0
                },
                {
                    "sent": "At time, at any given time, step is a linear combination of X1 and X2.",
                    "label": 0
                },
                {
                    "sent": "At the previous time step and E3.",
                    "label": 0
                },
                {
                    "sent": "Now note that E3.",
                    "label": 0
                },
                {
                    "sent": "Does not have a time index.",
                    "label": 0
                },
                {
                    "sent": "That's because it's constant.",
                    "label": 0
                },
                {
                    "sent": "So this means that.",
                    "label": 0
                },
                {
                    "sent": "Our models correspond to deterministic dynamical systems.",
                    "label": 0
                },
                {
                    "sent": "And they converge.",
                    "label": 0
                },
                {
                    "sent": "They reach equilibrium unless they are unstable.",
                    "label": 0
                },
                {
                    "sent": "As you can see, the equilibrium equation corresponds closely to the dynamical equation.",
                    "label": 1
                },
                {
                    "sent": "They have the same coefficients.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So our goal again, given a distribution of equilibrium.",
                    "label": 1
                },
                {
                    "sent": "We wanna.",
                    "label": 0
                },
                {
                    "sent": "Recover the structure of the process.",
                    "label": 1
                },
                {
                    "sent": "Find the values of this B matrix that entailed the observed distribution.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The distribution of the error terms together with the equations determine a joint distribution over X.",
                    "label": 1
                },
                {
                    "sent": "This is easy to see if you just solve the equation for X.",
                    "label": 0
                },
                {
                    "sent": "You can see that X is just a mixture of the East.",
                    "label": 0
                },
                {
                    "sent": "You can think of the error terms propagating in an infinite cycle perfectly through the cycle in many times.",
                    "label": 1
                },
                {
                    "sent": "And we give a new name to this I -- B inverse we call it A and it's called the mixing matrix because it tells you how these mix.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Into the excess.",
                    "label": 0
                },
                {
                    "sent": "So now let's give the assumptions needed for our model.",
                    "label": 0
                },
                {
                    "sent": "So we assume the data equilibrium of a linear structural equation model.",
                    "label": 0
                },
                {
                    "sent": "Yeah, some sample data ID that the error terms have positive variance.",
                    "label": 1
                },
                {
                    "sent": "At most one error term is Gaussian.",
                    "label": 1
                },
                {
                    "sent": "We make the weak causal Markov assumption.",
                    "label": 1
                },
                {
                    "sent": "So if X&Y are causally unconnected then they are independent.",
                    "label": 0
                },
                {
                    "sent": "This means that there's no active path conditional on the empty set, so X doesn't cause Y and widen calls X, and nobody causes both.",
                    "label": 0
                },
                {
                    "sent": "And colors efficiencies, but there's no hidden confounders.",
                    "label": 0
                },
                {
                    "sent": "That's kind of a big assumption.",
                    "label": 1
                },
                {
                    "sent": "And another big assumption.",
                    "label": 0
                },
                {
                    "sent": "Causal faithfulness.",
                    "label": 0
                },
                {
                    "sent": "The effect of E sebion exhibi is not zero.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So causal faithfulness we define it here and show how it can be violated.",
                    "label": 0
                },
                {
                    "sent": "So in the second case, it's never violated in cyclic.",
                    "label": 1
                },
                {
                    "sent": "In the second case, it could be violated if, for example, the coefficient of X1 in its own dynamical equation is 1.",
                    "label": 0
                },
                {
                    "sent": "And other violations can also happen if a certain polynomial function of the cycle product.",
                    "label": 1
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is equal to 1.",
                    "label": 0
                },
                {
                    "sent": "Now we've covered linear structure equation models, and I'm going to prison.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Lincoln method, but first.",
                    "label": 0
                },
                {
                    "sent": "The more fundamental question what can be identified in principle from just observation, ULL data.",
                    "label": 1
                },
                {
                    "sent": "The answer is when the error terms of Gaussian all you can get is that the separation equivalence class.",
                    "label": 0
                },
                {
                    "sent": "So if you have these two models where X1 causes X2 and X2 causes X1.",
                    "label": 0
                },
                {
                    "sent": "They will be.",
                    "label": 0
                },
                {
                    "sent": "They will have the same distribution, the same joint distribution.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "If we plot the joint distribution, you can see that this cloud here looks just like this cloud here.",
                    "label": 0
                },
                {
                    "sent": "So in the Gaussian case, there's no way to tell them apart.",
                    "label": 0
                },
                {
                    "sent": "But in the non Gaussian case, in this case the uniform is an example.",
                    "label": 0
                },
                {
                    "sent": "You can tell that the two joint distributions are different.",
                    "label": 0
                },
                {
                    "sent": "ICA is going to exploit this difference.",
                    "label": 0
                },
                {
                    "sent": "And as you can see in the Gaussian case, the separation equivalence is the same thing as distribution equivalence in the non Gaussian case.",
                    "label": 0
                },
                {
                    "sent": "This operation equivalence does not imply distributionally equivalents.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Distribution equivalence.",
                    "label": 0
                },
                {
                    "sent": "Now let's talk about ICA.",
                    "label": 0
                },
                {
                    "sent": "So this cocktail party problem, you have two sources of sound.",
                    "label": 1
                },
                {
                    "sent": "And you're capturing them through microphones.",
                    "label": 0
                },
                {
                    "sent": "They're both linear mixtures.",
                    "label": 0
                },
                {
                    "sent": "Different linear mixtures.",
                    "label": 0
                },
                {
                    "sent": "We can represent this as this equation X = 80, which is just which is the same as the equation we had before.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We want to get back to the original signals, so we want the inverse of the mixing matrix.",
                    "label": 1
                },
                {
                    "sent": "So we defined to just be the inverse of the mixing matrix.",
                    "label": 1
                },
                {
                    "sent": "And if you look at that, if you're only observing X, so there would be infinitely many solutions for A&E.",
                    "label": 0
                },
                {
                    "sent": "So you would say there's nothing you can do, but if you assume independence own gaussianity, it's possible to estimate A&E from just X, so that's what.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "ICA does.",
                    "label": 0
                },
                {
                    "sent": "And the sources in the cocktail party problem correspond to the error terms in structural equation models.",
                    "label": 1
                },
                {
                    "sent": "One problem of using ICA is that it it only finds this unmixing matrix.",
                    "label": 1
                },
                {
                    "sent": "Up to a permutation of the roast.",
                    "label": 0
                },
                {
                    "sent": "So this means that you can permute the error terms around and it wouldn't know which is, which doesn't have labels for them.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the Lincoln method.",
                    "label": 0
                },
                {
                    "sent": "What would happen if you ran?",
                    "label": 0
                },
                {
                    "sent": "I see a few generated data from a structural equation model like this one.",
                    "label": 0
                },
                {
                    "sent": "And you ran ICA on it?",
                    "label": 0
                },
                {
                    "sent": "You would.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Something like this?",
                    "label": 0
                },
                {
                    "sent": "You would get a W matrix representing it as a bipartite graph, which tells you how to mix the X is back into the East or unmix it if you will.",
                    "label": 0
                },
                {
                    "sent": "So I say would return your W matrix like this one.",
                    "label": 1
                },
                {
                    "sent": "And we first need to find a permutation of the East such that there is always a vertical arrow.",
                    "label": 1
                },
                {
                    "sent": "So that's a constraint guaranteed by our equations.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we do that.",
                    "label": 0
                },
                {
                    "sent": "We flip the 1st and 2nd error term and we get this.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we label these accordingly.",
                    "label": 0
                },
                {
                    "sent": "So we know that E1 will correspond to X1Y2.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Two etc.",
                    "label": 0
                },
                {
                    "sent": "And using the equation that we've derived, B = I -- W, we get back the original model.",
                    "label": 1
                },
                {
                    "sent": "So that's Lincoln.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It works.",
                    "label": 0
                },
                {
                    "sent": "So Lincoln discovers the full structure of the DAG.",
                    "label": 1
                },
                {
                    "sent": "By assuming causal sufficiency, which guarantees the independence of the error terms.",
                    "label": 0
                },
                {
                    "sent": "And in particular, we cannot distinguish these two models.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now suppose you run ICA.",
                    "label": 0
                },
                {
                    "sent": "And it gives you a matrix like this one.",
                    "label": 0
                },
                {
                    "sent": "Now there's more than one way to permute the error terms so that the constraint is satisfied so that all the vertical arrows are present.",
                    "label": 0
                },
                {
                    "sent": "Wellingham will pretend the red edge isn't there.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Lingam cannot discover cyclic models.",
                    "label": 1
                },
                {
                    "sent": "Because it assumes the data was generated by a DAG.",
                    "label": 1
                },
                {
                    "sent": "And therefore it searches for an ordering.",
                    "label": 1
                },
                {
                    "sent": "Which gives it.",
                    "label": 0
                },
                {
                    "sent": "A single permutation.",
                    "label": 0
                },
                {
                    "sent": "So if we stop imposing an ordering and we just search for any number of valid permutations.",
                    "label": 1
                },
                {
                    "sent": "Then we can discover some models.",
                    "label": 0
                },
                {
                    "sent": "So that's it.",
                    "label": 0
                },
                {
                    "sent": "That's the idea.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the link the method.",
                    "label": 0
                },
                {
                    "sent": "When the data looks like it will work just like Lingeman, return a single model.",
                    "label": 1
                },
                {
                    "sent": "When the data looks cyclic more than one permutation will be considered valid, so it only turns the distribution equivalent set.",
                    "label": 1
                },
                {
                    "sent": "That is more than one model.",
                    "label": 0
                },
                {
                    "sent": "And distribution equivalent means that we can't do any better without experimental data or further assumptions.",
                    "label": 0
                },
                {
                    "sent": "Because it just means that they produce the same joint distribution.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So Lindy finds multiple row permutations of the W matrix returned by ICA.",
                    "label": 0
                },
                {
                    "sent": "Solving this is equivalent to solving the so called constraint in rocks problem.",
                    "label": 0
                },
                {
                    "sent": "Namely, if you have N rooks in an end by end chess board.",
                    "label": 0
                },
                {
                    "sent": "You want to place them on the chess board so that no two rooks threaten each other and also no Rook is sitting on top of a 0.",
                    "label": 0
                },
                {
                    "sent": "So naive algorithm is just to a depth first search.",
                    "label": 0
                },
                {
                    "sent": "Better algorithm.",
                    "label": 0
                },
                {
                    "sent": "That all the all the do significance testing and set all the zeros to 0 all the non zeros to one and run a case best assignment algorithm iteratively until you get a score less than N. In the worst case you have in factorial models and you do equally badly.",
                    "label": 1
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Let's simulate using this model.",
                    "label": 1
                },
                {
                    "sent": "So the error terms are generated by sampling from a Gaussian squaring.",
                    "label": 1
                },
                {
                    "sent": "15,000 data points.",
                    "label": 0
                },
                {
                    "sent": "We prune the really small coefficients.",
                    "label": 0
                },
                {
                    "sent": "The really small entries of the matrix.",
                    "label": 0
                },
                {
                    "sent": "So we're going to run this now.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And you get this set.",
                    "label": 0
                },
                {
                    "sent": "Two models.",
                    "label": 0
                },
                {
                    "sent": "And they explain the data equally well.",
                    "label": 0
                },
                {
                    "sent": "They give the same likelihood for the data.",
                    "label": 0
                },
                {
                    "sent": "So what can you do?",
                    "label": 0
                },
                {
                    "sent": "How can you select one?",
                    "label": 0
                },
                {
                    "sent": "We could start looking at their stability.",
                    "label": 0
                },
                {
                    "sent": "So the first model if you multiply the coefficients in those edges, you get about 1.66.",
                    "label": 0
                },
                {
                    "sent": "That would make it unstable.",
                    "label": 0
                },
                {
                    "sent": "And the second model you get about 0.6.",
                    "label": 0
                },
                {
                    "sent": "So it will be stable, so we can.",
                    "label": 0
                },
                {
                    "sent": "Using this criterion we can rule out the first one.",
                    "label": 0
                },
                {
                    "sent": "We can just use the second one, and as you can see, the second one actually corresponds pretty closely to the true model.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just to illustrate it.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Pretty much.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Same thing.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "So only one of them is stable.",
                    "label": 1
                },
                {
                    "sent": "And since we're assuming the data is a set of equilibrium, then we are entitled to use this criterion.",
                    "label": 0
                },
                {
                    "sent": "Natural question is, how powerful is this constraint of stability?",
                    "label": 1
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Much, can you rule out?",
                    "label": 0
                },
                {
                    "sent": "And we proved the theorem that if the two model cycles don't intersect.",
                    "label": 1
                },
                {
                    "sent": "Then exactly 1 model will be stable or at most one model will be stable.",
                    "label": 0
                },
                {
                    "sent": "The intuition is just that the cycle product get inverted for any alternative permutation.",
                    "label": 0
                },
                {
                    "sent": "And they're all independent of each other, so.",
                    "label": 0
                },
                {
                    "sent": "So only only the true one will have.",
                    "label": 0
                },
                {
                    "sent": "Allstate.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Cycles.",
                    "label": 0
                },
                {
                    "sent": "This is also been tried on real data.",
                    "label": 1
                },
                {
                    "sent": "Z Tian Wang has a 10 variable model, 28 edges.",
                    "label": 0
                },
                {
                    "sent": "And running link D he got 240 models distribution equivalent.",
                    "label": 0
                },
                {
                    "sent": "But that's too many.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 1
                },
                {
                    "sent": "Using the stability criterion, he verified that only two of those are stable.",
                    "label": 1
                },
                {
                    "sent": "So the lesson is, this ability can be a powerful constraint.",
                    "label": 0
                },
                {
                    "sent": "But there's a caveat.",
                    "label": 0
                },
                {
                    "sent": "We are assuming no self loops, so we are assuming here that the coefficient of exhibi on the equation for exhibi is 0.",
                    "label": 0
                },
                {
                    "sent": "And that's a pretty strong assumption.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in general.",
                    "label": 0
                },
                {
                    "sent": "There's the question of what method should you use to discover your causal models.",
                    "label": 0
                },
                {
                    "sent": "If your terms are Gaussian and you are assuming a simplicity.",
                    "label": 0
                },
                {
                    "sent": "Then you can use constraint based vectors like PC or SGS or.",
                    "label": 1
                },
                {
                    "sent": "Bayesian alternatives.",
                    "label": 0
                },
                {
                    "sent": "And that gives you the D separation equivalence class.",
                    "label": 1
                },
                {
                    "sent": "If you have non Gaussian error terms.",
                    "label": 1
                },
                {
                    "sent": "You can run linggam and that gives you a unique model.",
                    "label": 0
                },
                {
                    "sent": "If you have Gaussian error terms but you relax the cyclicity assumption.",
                    "label": 0
                },
                {
                    "sent": "Richardson CCD algorithm can be used but it gives you a very very large class.",
                    "label": 1
                },
                {
                    "sent": "And finally, if you have non Gaussian error terms.",
                    "label": 0
                },
                {
                    "sent": "We can apply link D. Which works just as well as Lingam in the cyclic case.",
                    "label": 0
                },
                {
                    "sent": "But I will give you.",
                    "label": 0
                },
                {
                    "sent": "The full distribution equivalence class in the cyclic case.",
                    "label": 1
                },
                {
                    "sent": "Another question you may be asking right now is.",
                    "label": 0
                },
                {
                    "sent": "Is there a sharp line between Gaussian and non Gaussian?",
                    "label": 0
                },
                {
                    "sent": "And the answer is no.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "You could, for example, have some error terms be Gaussian, some be non Gaussian.",
                    "label": 1
                },
                {
                    "sent": "You could have too little data to really tell.",
                    "label": 0
                },
                {
                    "sent": "So in the acyclic case.",
                    "label": 0
                },
                {
                    "sent": "If you're interested in that question, you could read our paper from yesterday presented by Patrick.",
                    "label": 0
                },
                {
                    "sent": "Is this poster session.",
                    "label": 0
                },
                {
                    "sent": "In the second case, this hasn't been investigated yet.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Finally.",
                    "label": 0
                },
                {
                    "sent": "Summarizing.",
                    "label": 0
                },
                {
                    "sent": "Lingam exploits non gaussianity in a single case.",
                    "label": 0
                },
                {
                    "sent": "To give you a unique structural equation model rather than the separation equivalence, which is what Gaussian which is all you can do in the Gaussian case.",
                    "label": 0
                },
                {
                    "sent": "Link D. Similarly, narrows the output class to the distribution equivalence class of structural equation models.",
                    "label": 1
                },
                {
                    "sent": "In the cyclic case, or the more general case.",
                    "label": 1
                },
                {
                    "sent": "But still there may be multiple structural equation models that explain the data equally well.",
                    "label": 0
                },
                {
                    "sent": "And finally, I have argued that stability can sometimes be used to rule out a good chunk of those.",
                    "label": 1
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "If you're trying to use the stability criterion you would you would make that assumption right.",
                    "label": 0
                },
                {
                    "sent": "Dynamic.",
                    "label": 0
                },
                {
                    "sent": "OK, I I may not have presented this optimally.",
                    "label": 0
                },
                {
                    "sent": "So now we don't actually need that assumption.",
                    "label": 0
                },
                {
                    "sent": "We can have self loops as long as the coefficient is not one.",
                    "label": 0
                },
                {
                    "sent": "Poor baby.",
                    "label": 0
                },
                {
                    "sent": "What do you mean by score based methods?",
                    "label": 0
                },
                {
                    "sent": "Yeah, I think it would be interesting.",
                    "label": 0
                },
                {
                    "sent": "I think it would be interesting to look at Bayesian ways to do this.",
                    "label": 0
                },
                {
                    "sent": "But our current paper is not Bayesian.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                }
            ]
        }
    }
}