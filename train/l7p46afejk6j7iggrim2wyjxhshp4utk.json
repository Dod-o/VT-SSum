{
    "id": "l7p46afejk6j7iggrim2wyjxhshp4utk",
    "title": "Efficient ORC Post-processing Combining Language, Hypothesis and Error Models",
    "info": {
        "author": [
            "Juan-Carlos Perez-Cortes, Technical University of Valencia (UPV)"
        ],
        "published": "Sept. 13, 2010",
        "recorded": "August 2010",
        "category": [
            "Top->Computer Science->Pattern Recognition"
        ]
    },
    "url": "http://videolectures.net/ssspr2010_perez_cortes_eocr/",
    "segmentation": [
        [
            "Good afternoon, I'm going to present the paper efficient OCR post processing combining language.",
            "My hypothesis and error models.",
            "Anne."
        ],
        [
            "Well, first of all, the 1% that ask what which is our problem, our problem is too.",
            "To I mean to complete the optical character recognition workflow involving the first.",
            "The first task, which is the the traditional task of of training a set of hypothesis for the characters of.",
            "Much on dating text then, but the final problem is obviously to get a final hypothesis or final recognition, which involves selecting the best hypothesis, taking into account not only the obviously the original OCR hypothesis, but also the.",
            "Typical behavior of the recognizer or, for example, which confusions are more likely or the reliability or uncertainty of the recognition result that is output by the OCR or any other particular constraints of the specific task of that text.",
            "I mean related to that text then.",
            "We propose to model all these elements.",
            "As a different model that we will combine together to get a global optimization.",
            "So the idea is to define a hypothesis model, an error model and a language model.",
            "Usually only the language model is is is employed with an error model inherent or in the.",
            "The algorithm of the language model."
        ],
        [
            "Of language modeling, then in this in our proposal, the.",
            "We want to have our full language.",
            "We want to have full language modeling, in this case stochastic error correcting.",
            "Parsing is the is the.",
            "Maybe the base we're building on, but we want to.",
            "We want to to have a model that is flexible and efficient as I mean flexible and efficient, as are the kobold model.",
            "I mean, when the OCR is performed 1st and.",
            "The post processing is performed later.",
            "In that case, we can change any part of the system, and it's usually more Morrissey.",
            "I mean is here to to deal with with the system from a practical point of view, but on the other side's on the other side, we want to take advantage is also of all the information, like in a completely integrated global model, let's say."
        ],
        [
            "Yeah, that's the goal.",
            "So the complete process will would be to obtain a hypothesis from the OCR, take into account all the possible hypothesis and posterior probabilities of a classifier and then.",
            "Apply an error model.",
            "Apply a language model.",
            "Hypothesis that would be the first element.",
            "Then to apply the error model and apply the language model and to get the best possible it would be the best path in this case to get the final result so."
        ],
        [
            "In the.",
            "We will use a. Transducers, I find this transducers which are as a generalization of the final state of domada.",
            "I'm not going to.",
            "I mean, this is the classical way to define a."
        ],
        [
            "If I say then the weighted finite state transducers are special kinds of essay.",
            "I mean generalized essay, where a number of new elements are included, like weights and transduction from assembl.",
            "For my son bowl to set aside, most other status symbols.",
            "So from alphabet to another alphabet so."
        ],
        [
            "I am well, I'm not going to to get into the details of of.",
            "Wait a minute.",
            "This is users, but well, the main operation we will use is the composition operation.",
            "That composes combines two transducers in a way that they original the original.",
            "Alphabet is just used to the final alphabet.",
            "The original for this from the first user.",
            "The input alphabet of the first user and target alphabet is the output alphabet of the second transducer, so the composition is defined is defined using generic operations that we will instantiate to simply a simple in a simple way.",
            "So.",
            "The details I will not get into into them, but but we will see an example, so maybe it's easier."
        ],
        [
            "Anne.",
            "OK, so the first the first part.",
            "I mean we will do this kind of transition for the three models for the hypothesis model.",
            "For the error model an for the language model, which is the first, we're going to deal with so.",
            "And the language model of course can be is something quite quite specific to the task, and there are many different possibilities.",
            "In our case where using the.",
            "We are using a grammatical inference.",
            "Salaries 2 build the language model as a weighted filter state transducer.",
            "OK, this language can be, I mean using a sample which using a set of strings from the language.",
            "Of course the languages does not mean and always a natural language.",
            "It can be just a lexicon, for example.",
            "A very simple simple list of words of codes, maybe of numbers, any kind of.",
            "Real, I mean, in practice I mean and many different kind of world languages exist in this sense and then, well, we have a number of.",
            "Of.",
            "Properties or characteristics that we will exploit for any for every different, for each different application.",
            "OK. We have also the.",
            "Sergei, which will also define the behavior of the model, the the properties of the model.",
            "In a way to give a leanto language modeling using N grams, I mean the value of KE specifies how long the substring is modeled in the by the grammar in Ferd.",
            "In this case.",
            "OK, so."
        ],
        [
            "The language model will will be built as a WFT.",
            "In this case, uh, an example is this.",
            "This sample of language will will.",
            "With some with this sample we will obtain this.",
            "WFT well with final with final States and no final states, an initial state and this.",
            "In fact, for the language model we use any identity transducer.",
            "Maybe cause the input symbols on the output symbols are always the same, so it's completely equivalent to an automaton, since the other models will be transducer, so it's in practice we prefer.",
            "To the big disk as another test user.",
            "So all the operations are the same are compositions that we will see."
        ],
        [
            "Then the second model is the hypothesis model.",
            "We define the output of the classifier as we will find out the server not not as a string, but another transducer.",
            "So that's the main difference between other techniques, and this is that here we don't treat the output of the OCR as a string, but as another transition as I said and.",
            "In particular, we we can have for any sign any symbol of the string.",
            "We can have all put all the possible characters as hypothesis for that symbol.",
            "So if we have a M. A string of with MM.",
            "When with M symbols and N is the number of possible is the number of symbols in the in the alphabet.",
            "Then we will have a sequence of vectors with vectors of dimension M, which is the number of symbols in the alphabet.",
            "Because each symbol in the input string can be any symbol of the alphabet with the we what we get from the OCR is the uh posterior probability of each symbol, four of each.",
            "Element in the text in the OCR text.",
            "OK, so we have.",
            "This inform all this information from the OCR and we build an identity transducer.",
            "Jane with a.",
            "As many states, plus one as the original number of characters that the OCR read from the from the image of the text image.",
            "OK, so this transducer will model all the information that the OCR can."
        ],
        [
            "Output I mean all the all the.",
            "Posterior probabilities of for any symbol, for any character of the of the string so.",
            "And if our.",
            "Also, your up output is like is like this.",
            "It means that the first character is very probably on a, but it could be also be.",
            "The second character is very probably AB, but it could be also a C or an A and so on.",
            "OK, so that those are, those will be the likelihoods or probably this or confidence values or it depends on the particular OCR OK?",
            "In this case we we say probably this, in case they OCR gifts real, true, or estimated posterior probabilities.",
            "So this is the user we build with all the all the probabilities for each for each possible output of the OCR, the transitions with zero probability are not shown, obviously."
        ],
        [
            "So the and finally the error model.",
            "There are model is.",
            "So.",
            "The only way to to correct or to accept or to get finally words that have not been recognized.",
            "I mean with characters that have not recognized at all by the OCR, for example so.",
            "If the language model does not have any of the possible paths in the in the hypothesis model, and we need another model to convert the original or the hypothesis model into one of the possible language model strings, one of the possible strings accepted by the language model.",
            "Anne.",
            "And also it's possible that the path or the hypothesis of the OCR gives is in the language model, but with a low very low probability and something very similar is in the language model with higher probability.",
            "So the global combination, the global optimization would allow us to get the more problem or probabilistic instead of less problem one.",
            "OK, so well, this is a classical error model with substitution, insertion and relations with different probabilities for each, and the only particular thing here is that the substitutions typically come from the confusion matrix of the OCR, so we are encoding the static behavior of the OCR into the confusion matrix and the substitution of a symbol by itself.",
            "It's typically the.",
            "Probably the by itself our by the other symbols is typically comes typically from the confusion matrix of the classifier.",
            "OK, so the static behavior or the model is here, and the dynamic estimation is the one problem provided by the OCR hypothesis.",
            "That will give the dynamic because it's the hypothesis for that special given sentence.",
            "OK. Obviously, the data substitutions and insertions and deletions are come empirical, estimated as."
        ],
        [
            "As usual.",
            "Then, for example, error models.",
            "In this case, the Constitution gives the producers give us a little more flexibility and thus than just using the the.",
            "In typical edit distance for error model, because you can for example.",
            "A typical I mean, we substitute each collector by itself with a probability of with another.",
            "In this case it would be probabilities 'cause they don't sum up to one.",
            "It will be confidences or whatever, and we substitute or delete or insert with given given probabilities.",
            "And we've given weights in this case and in this case for example, we only allow in sessions to be performed at the at the beginning of the string.",
            "It's an example of possible.",
            "Of possible error model which is different from the classical one from the simplest one."
        ],
        [
            "OK, so finally what we do with all these?",
            "What do we do with all these three models?",
            "These three are transducers.",
            "We compose them.",
            "So we asked compose the three the three models.",
            "We must remember that we don't have any string so far.",
            "I mean, we all we don't have an input string, we only have 3 transducers, so we compose them and find the best path.",
            "The lowest cost path in the composed transducer.",
            "So there's no parsing in a way.",
            "I mean, it's only looking for the best.",
            "But we we obviously have to do some running some special kind of composition, not to not to need so much memory as to have the whole composition in memory.",
            "That's they call it lazy composition.",
            "We use lazy composition.",
            "Also running to get an approximate best path in this case because the language model, I mean the.",
            "Which models can be very large, so it's important to have this computational.",
            "Aspect under control, so there's also another another element to deal with.",
            "This is a relative influence of the different models into the final.",
            "Weight of the path to minimize and in this case we use a typical.",
            "Typical combination of probabilities and we adjust the parameters for four of the models and let the other model have one as a parameter."
        ],
        [
            "So.",
            "An example of hypothesis model and error model composed it would be this one, the previous previous hypothesis model we made.",
            "We gave us an example and the error model.",
            "The simple simple one.",
            "And the first one we saw a they are composed on doing this, and then you compose this with the language model, which would be very large and I don't.",
            "I don't have it here, for it doesn't fit in the slide so but that's the way it will look after the language model.",
            "Then the language model has to be composed.",
            "OK, so."
        ],
        [
            "The experiments.",
            "A we we try to compare the system with a typical system that doesn't take into account the output probabilities of the OCR.",
            "OK, so that gets in a string and parses the string.",
            "And we use the data from forms from 100 and forms OK. For it was a sample form of 4040 thousand 100 surnames.",
            "I mean the field in the form where you write your surname.",
            "We used a reference language model of.",
            "4.5 million Spanish or names of one 100,000 of which were unique, so it's it's so it has probabilities.",
            "It has frequencies and we use a K equal to 25, which is the largest surname size, so we only accept completes or names that we know because we think that's large enough.",
            "Some reference of surname.",
            "So we just accept one of the known ones.",
            "A.",
            "In this case, we took out 15% of the of the set to train the.",
            "And the session relation probabilities and also the parameters of the composition and we left the other 85% for for the test for the real test OK."
        ],
        [
            "The performance there is also these are the results.",
            "Well, this would be the OCR without any correction.",
            "Obviously at the at field level the field level the error is huge.",
            "I mean if you have only a 5% error in each character, obviously we have some names of seven or eight characters.",
            "Hey there are is is very large for this is the error.",
            "I mean if we allow this error rate this output error rates and we get this recognition rate.",
            "I mean we obviously reject all those strings that have less than a given confidence.",
            "So we get this error rate.",
            "And that recognition rate.",
            "Usually the error rate is limited, maximum 2 one or 2%.",
            "In a typical real operation, so you don't allow more than one or 2% error rates and then.",
            "You get this recognition rate and the rest you have to type it manually.",
            "I mean it's left for manual input, so that's the that's.",
            "So if the recognition rate is higher is better because you don't have to input so many surnames.",
            "In this case by hand so.",
            "The difference in this in this area as you see well, it's it's significant."
        ],
        [
            "We have here the daily salary between 2 and 3% of improvement.",
            "So this is the the improvement we get with this with this."
        ],
        [
            "The.",
            "Technique and the time is also so.",
            "I mean, this is with very.",
            "Practical in this case, correction time using typical PC and the language model with this language model we used.",
            "Which finally gives rise to a transducer with 64,000 States and 140,000 transitions.",
            "The typical input string length of well, it's more less linear with the input string length, and it's about half a second as.",
            "Even with less than half a second, even with the longest surnames.",
            "Anne."
        ],
        [
            "Sam so the conclusions is that we improved.",
            "The system of character recognition using the technique based on on.",
            "Users.",
            "And then we get a global minimization of taking into account all the information of the system.",
            "So we get the most probabilistic compatible with the language, the hypothesis, and the error models.",
            "We improved.",
            "In fact the efficiency and also the results and.",
            "But the most probably the most interesting thing from practical, from a practical point of view, is that we have.",
            "A language OCR and error models that are independently that can be independently modified.",
            "This is quite useful because in typical form, for example you have.",
            "1015 different fields with different language models.",
            "You have.",
            "Surname, name, address.",
            "So many different fields in the same document, so it's very interesting to have an OCR well.",
            "Optimal optimized for forgiven, forgiven?",
            "Language, I mean County or whatever, but then to be able to change and optimize independently the language model and but the final result is a global globally optimized with all the information.",
            "So that's more or less the final advantage we see in this model."
        ],
        [
            "OK.",
            "So thank you for your attention.",
            "The result of the combination is actually normal deterministic.",
            "He combination of the three transducers.",
            "Computing device probable translation is not that simple.",
            "You only you only have to look for the best path.",
            "A so so so, so at each possible at it's possible selection you get the highest probability and then the final path is typical.",
            "Typical operation.",
            "In fact we're using.",
            "An open source.",
            "Where does user package that gives the result of the optimization?",
            "Very fast, in fact.",
            "I mean the the building the transducer is there is a is the heavy part of the of the time.",
            "I mean of the final time.",
            "So the best path is not a problem, but I cannot say exactly which technique they are using.",
            "Are you using?",
            "It's open FST.",
            "No."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Good afternoon, I'm going to present the paper efficient OCR post processing combining language.",
                    "label": 1
                },
                {
                    "sent": "My hypothesis and error models.",
                    "label": 1
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well, first of all, the 1% that ask what which is our problem, our problem is too.",
                    "label": 0
                },
                {
                    "sent": "To I mean to complete the optical character recognition workflow involving the first.",
                    "label": 1
                },
                {
                    "sent": "The first task, which is the the traditional task of of training a set of hypothesis for the characters of.",
                    "label": 1
                },
                {
                    "sent": "Much on dating text then, but the final problem is obviously to get a final hypothesis or final recognition, which involves selecting the best hypothesis, taking into account not only the obviously the original OCR hypothesis, but also the.",
                    "label": 1
                },
                {
                    "sent": "Typical behavior of the recognizer or, for example, which confusions are more likely or the reliability or uncertainty of the recognition result that is output by the OCR or any other particular constraints of the specific task of that text.",
                    "label": 1
                },
                {
                    "sent": "I mean related to that text then.",
                    "label": 1
                },
                {
                    "sent": "We propose to model all these elements.",
                    "label": 0
                },
                {
                    "sent": "As a different model that we will combine together to get a global optimization.",
                    "label": 1
                },
                {
                    "sent": "So the idea is to define a hypothesis model, an error model and a language model.",
                    "label": 0
                },
                {
                    "sent": "Usually only the language model is is is employed with an error model inherent or in the.",
                    "label": 0
                },
                {
                    "sent": "The algorithm of the language model.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Of language modeling, then in this in our proposal, the.",
                    "label": 0
                },
                {
                    "sent": "We want to have our full language.",
                    "label": 0
                },
                {
                    "sent": "We want to have full language modeling, in this case stochastic error correcting.",
                    "label": 1
                },
                {
                    "sent": "Parsing is the is the.",
                    "label": 0
                },
                {
                    "sent": "Maybe the base we're building on, but we want to.",
                    "label": 1
                },
                {
                    "sent": "We want to to have a model that is flexible and efficient as I mean flexible and efficient, as are the kobold model.",
                    "label": 0
                },
                {
                    "sent": "I mean, when the OCR is performed 1st and.",
                    "label": 0
                },
                {
                    "sent": "The post processing is performed later.",
                    "label": 0
                },
                {
                    "sent": "In that case, we can change any part of the system, and it's usually more Morrissey.",
                    "label": 0
                },
                {
                    "sent": "I mean is here to to deal with with the system from a practical point of view, but on the other side's on the other side, we want to take advantage is also of all the information, like in a completely integrated global model, let's say.",
                    "label": 1
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yeah, that's the goal.",
                    "label": 0
                },
                {
                    "sent": "So the complete process will would be to obtain a hypothesis from the OCR, take into account all the possible hypothesis and posterior probabilities of a classifier and then.",
                    "label": 1
                },
                {
                    "sent": "Apply an error model.",
                    "label": 0
                },
                {
                    "sent": "Apply a language model.",
                    "label": 0
                },
                {
                    "sent": "Hypothesis that would be the first element.",
                    "label": 1
                },
                {
                    "sent": "Then to apply the error model and apply the language model and to get the best possible it would be the best path in this case to get the final result so.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the.",
                    "label": 0
                },
                {
                    "sent": "We will use a. Transducers, I find this transducers which are as a generalization of the final state of domada.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to.",
                    "label": 0
                },
                {
                    "sent": "I mean, this is the classical way to define a.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If I say then the weighted finite state transducers are special kinds of essay.",
                    "label": 0
                },
                {
                    "sent": "I mean generalized essay, where a number of new elements are included, like weights and transduction from assembl.",
                    "label": 0
                },
                {
                    "sent": "For my son bowl to set aside, most other status symbols.",
                    "label": 0
                },
                {
                    "sent": "So from alphabet to another alphabet so.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I am well, I'm not going to to get into the details of of.",
                    "label": 0
                },
                {
                    "sent": "Wait a minute.",
                    "label": 0
                },
                {
                    "sent": "This is users, but well, the main operation we will use is the composition operation.",
                    "label": 0
                },
                {
                    "sent": "That composes combines two transducers in a way that they original the original.",
                    "label": 0
                },
                {
                    "sent": "Alphabet is just used to the final alphabet.",
                    "label": 0
                },
                {
                    "sent": "The original for this from the first user.",
                    "label": 0
                },
                {
                    "sent": "The input alphabet of the first user and target alphabet is the output alphabet of the second transducer, so the composition is defined is defined using generic operations that we will instantiate to simply a simple in a simple way.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The details I will not get into into them, but but we will see an example, so maybe it's easier.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "OK, so the first the first part.",
                    "label": 0
                },
                {
                    "sent": "I mean we will do this kind of transition for the three models for the hypothesis model.",
                    "label": 1
                },
                {
                    "sent": "For the error model an for the language model, which is the first, we're going to deal with so.",
                    "label": 1
                },
                {
                    "sent": "And the language model of course can be is something quite quite specific to the task, and there are many different possibilities.",
                    "label": 1
                },
                {
                    "sent": "In our case where using the.",
                    "label": 0
                },
                {
                    "sent": "We are using a grammatical inference.",
                    "label": 1
                },
                {
                    "sent": "Salaries 2 build the language model as a weighted filter state transducer.",
                    "label": 1
                },
                {
                    "sent": "OK, this language can be, I mean using a sample which using a set of strings from the language.",
                    "label": 0
                },
                {
                    "sent": "Of course the languages does not mean and always a natural language.",
                    "label": 0
                },
                {
                    "sent": "It can be just a lexicon, for example.",
                    "label": 0
                },
                {
                    "sent": "A very simple simple list of words of codes, maybe of numbers, any kind of.",
                    "label": 0
                },
                {
                    "sent": "Real, I mean, in practice I mean and many different kind of world languages exist in this sense and then, well, we have a number of.",
                    "label": 0
                },
                {
                    "sent": "Of.",
                    "label": 0
                },
                {
                    "sent": "Properties or characteristics that we will exploit for any for every different, for each different application.",
                    "label": 0
                },
                {
                    "sent": "OK. We have also the.",
                    "label": 0
                },
                {
                    "sent": "Sergei, which will also define the behavior of the model, the the properties of the model.",
                    "label": 1
                },
                {
                    "sent": "In a way to give a leanto language modeling using N grams, I mean the value of KE specifies how long the substring is modeled in the by the grammar in Ferd.",
                    "label": 0
                },
                {
                    "sent": "In this case.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The language model will will be built as a WFT.",
                    "label": 1
                },
                {
                    "sent": "In this case, uh, an example is this.",
                    "label": 0
                },
                {
                    "sent": "This sample of language will will.",
                    "label": 0
                },
                {
                    "sent": "With some with this sample we will obtain this.",
                    "label": 0
                },
                {
                    "sent": "WFT well with final with final States and no final states, an initial state and this.",
                    "label": 1
                },
                {
                    "sent": "In fact, for the language model we use any identity transducer.",
                    "label": 0
                },
                {
                    "sent": "Maybe cause the input symbols on the output symbols are always the same, so it's completely equivalent to an automaton, since the other models will be transducer, so it's in practice we prefer.",
                    "label": 0
                },
                {
                    "sent": "To the big disk as another test user.",
                    "label": 0
                },
                {
                    "sent": "So all the operations are the same are compositions that we will see.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then the second model is the hypothesis model.",
                    "label": 1
                },
                {
                    "sent": "We define the output of the classifier as we will find out the server not not as a string, but another transducer.",
                    "label": 0
                },
                {
                    "sent": "So that's the main difference between other techniques, and this is that here we don't treat the output of the OCR as a string, but as another transition as I said and.",
                    "label": 0
                },
                {
                    "sent": "In particular, we we can have for any sign any symbol of the string.",
                    "label": 0
                },
                {
                    "sent": "We can have all put all the possible characters as hypothesis for that symbol.",
                    "label": 0
                },
                {
                    "sent": "So if we have a M. A string of with MM.",
                    "label": 0
                },
                {
                    "sent": "When with M symbols and N is the number of possible is the number of symbols in the in the alphabet.",
                    "label": 1
                },
                {
                    "sent": "Then we will have a sequence of vectors with vectors of dimension M, which is the number of symbols in the alphabet.",
                    "label": 1
                },
                {
                    "sent": "Because each symbol in the input string can be any symbol of the alphabet with the we what we get from the OCR is the uh posterior probability of each symbol, four of each.",
                    "label": 0
                },
                {
                    "sent": "Element in the text in the OCR text.",
                    "label": 1
                },
                {
                    "sent": "OK, so we have.",
                    "label": 1
                },
                {
                    "sent": "This inform all this information from the OCR and we build an identity transducer.",
                    "label": 0
                },
                {
                    "sent": "Jane with a.",
                    "label": 0
                },
                {
                    "sent": "As many states, plus one as the original number of characters that the OCR read from the from the image of the text image.",
                    "label": 0
                },
                {
                    "sent": "OK, so this transducer will model all the information that the OCR can.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Output I mean all the all the.",
                    "label": 0
                },
                {
                    "sent": "Posterior probabilities of for any symbol, for any character of the of the string so.",
                    "label": 0
                },
                {
                    "sent": "And if our.",
                    "label": 0
                },
                {
                    "sent": "Also, your up output is like is like this.",
                    "label": 0
                },
                {
                    "sent": "It means that the first character is very probably on a, but it could be also be.",
                    "label": 0
                },
                {
                    "sent": "The second character is very probably AB, but it could be also a C or an A and so on.",
                    "label": 0
                },
                {
                    "sent": "OK, so that those are, those will be the likelihoods or probably this or confidence values or it depends on the particular OCR OK?",
                    "label": 0
                },
                {
                    "sent": "In this case we we say probably this, in case they OCR gifts real, true, or estimated posterior probabilities.",
                    "label": 0
                },
                {
                    "sent": "So this is the user we build with all the all the probabilities for each for each possible output of the OCR, the transitions with zero probability are not shown, obviously.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the and finally the error model.",
                    "label": 0
                },
                {
                    "sent": "There are model is.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The only way to to correct or to accept or to get finally words that have not been recognized.",
                    "label": 0
                },
                {
                    "sent": "I mean with characters that have not recognized at all by the OCR, for example so.",
                    "label": 0
                },
                {
                    "sent": "If the language model does not have any of the possible paths in the in the hypothesis model, and we need another model to convert the original or the hypothesis model into one of the possible language model strings, one of the possible strings accepted by the language model.",
                    "label": 1
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "And also it's possible that the path or the hypothesis of the OCR gives is in the language model, but with a low very low probability and something very similar is in the language model with higher probability.",
                    "label": 0
                },
                {
                    "sent": "So the global combination, the global optimization would allow us to get the more problem or probabilistic instead of less problem one.",
                    "label": 1
                },
                {
                    "sent": "OK, so well, this is a classical error model with substitution, insertion and relations with different probabilities for each, and the only particular thing here is that the substitutions typically come from the confusion matrix of the OCR, so we are encoding the static behavior of the OCR into the confusion matrix and the substitution of a symbol by itself.",
                    "label": 0
                },
                {
                    "sent": "It's typically the.",
                    "label": 1
                },
                {
                    "sent": "Probably the by itself our by the other symbols is typically comes typically from the confusion matrix of the classifier.",
                    "label": 0
                },
                {
                    "sent": "OK, so the static behavior or the model is here, and the dynamic estimation is the one problem provided by the OCR hypothesis.",
                    "label": 0
                },
                {
                    "sent": "That will give the dynamic because it's the hypothesis for that special given sentence.",
                    "label": 0
                },
                {
                    "sent": "OK. Obviously, the data substitutions and insertions and deletions are come empirical, estimated as.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As usual.",
                    "label": 0
                },
                {
                    "sent": "Then, for example, error models.",
                    "label": 1
                },
                {
                    "sent": "In this case, the Constitution gives the producers give us a little more flexibility and thus than just using the the.",
                    "label": 1
                },
                {
                    "sent": "In typical edit distance for error model, because you can for example.",
                    "label": 0
                },
                {
                    "sent": "A typical I mean, we substitute each collector by itself with a probability of with another.",
                    "label": 0
                },
                {
                    "sent": "In this case it would be probabilities 'cause they don't sum up to one.",
                    "label": 0
                },
                {
                    "sent": "It will be confidences or whatever, and we substitute or delete or insert with given given probabilities.",
                    "label": 1
                },
                {
                    "sent": "And we've given weights in this case and in this case for example, we only allow in sessions to be performed at the at the beginning of the string.",
                    "label": 1
                },
                {
                    "sent": "It's an example of possible.",
                    "label": 0
                },
                {
                    "sent": "Of possible error model which is different from the classical one from the simplest one.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so finally what we do with all these?",
                    "label": 0
                },
                {
                    "sent": "What do we do with all these three models?",
                    "label": 0
                },
                {
                    "sent": "These three are transducers.",
                    "label": 0
                },
                {
                    "sent": "We compose them.",
                    "label": 0
                },
                {
                    "sent": "So we asked compose the three the three models.",
                    "label": 0
                },
                {
                    "sent": "We must remember that we don't have any string so far.",
                    "label": 0
                },
                {
                    "sent": "I mean, we all we don't have an input string, we only have 3 transducers, so we compose them and find the best path.",
                    "label": 0
                },
                {
                    "sent": "The lowest cost path in the composed transducer.",
                    "label": 1
                },
                {
                    "sent": "So there's no parsing in a way.",
                    "label": 0
                },
                {
                    "sent": "I mean, it's only looking for the best.",
                    "label": 0
                },
                {
                    "sent": "But we we obviously have to do some running some special kind of composition, not to not to need so much memory as to have the whole composition in memory.",
                    "label": 1
                },
                {
                    "sent": "That's they call it lazy composition.",
                    "label": 1
                },
                {
                    "sent": "We use lazy composition.",
                    "label": 1
                },
                {
                    "sent": "Also running to get an approximate best path in this case because the language model, I mean the.",
                    "label": 0
                },
                {
                    "sent": "Which models can be very large, so it's important to have this computational.",
                    "label": 0
                },
                {
                    "sent": "Aspect under control, so there's also another another element to deal with.",
                    "label": 1
                },
                {
                    "sent": "This is a relative influence of the different models into the final.",
                    "label": 0
                },
                {
                    "sent": "Weight of the path to minimize and in this case we use a typical.",
                    "label": 1
                },
                {
                    "sent": "Typical combination of probabilities and we adjust the parameters for four of the models and let the other model have one as a parameter.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "An example of hypothesis model and error model composed it would be this one, the previous previous hypothesis model we made.",
                    "label": 1
                },
                {
                    "sent": "We gave us an example and the error model.",
                    "label": 1
                },
                {
                    "sent": "The simple simple one.",
                    "label": 0
                },
                {
                    "sent": "And the first one we saw a they are composed on doing this, and then you compose this with the language model, which would be very large and I don't.",
                    "label": 0
                },
                {
                    "sent": "I don't have it here, for it doesn't fit in the slide so but that's the way it will look after the language model.",
                    "label": 1
                },
                {
                    "sent": "Then the language model has to be composed.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The experiments.",
                    "label": 0
                },
                {
                    "sent": "A we we try to compare the system with a typical system that doesn't take into account the output probabilities of the OCR.",
                    "label": 1
                },
                {
                    "sent": "OK, so that gets in a string and parses the string.",
                    "label": 0
                },
                {
                    "sent": "And we use the data from forms from 100 and forms OK. For it was a sample form of 4040 thousand 100 surnames.",
                    "label": 0
                },
                {
                    "sent": "I mean the field in the form where you write your surname.",
                    "label": 1
                },
                {
                    "sent": "We used a reference language model of.",
                    "label": 0
                },
                {
                    "sent": "4.5 million Spanish or names of one 100,000 of which were unique, so it's it's so it has probabilities.",
                    "label": 1
                },
                {
                    "sent": "It has frequencies and we use a K equal to 25, which is the largest surname size, so we only accept completes or names that we know because we think that's large enough.",
                    "label": 0
                },
                {
                    "sent": "Some reference of surname.",
                    "label": 0
                },
                {
                    "sent": "So we just accept one of the known ones.",
                    "label": 0
                },
                {
                    "sent": "A.",
                    "label": 0
                },
                {
                    "sent": "In this case, we took out 15% of the of the set to train the.",
                    "label": 0
                },
                {
                    "sent": "And the session relation probabilities and also the parameters of the composition and we left the other 85% for for the test for the real test OK.",
                    "label": 1
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The performance there is also these are the results.",
                    "label": 0
                },
                {
                    "sent": "Well, this would be the OCR without any correction.",
                    "label": 0
                },
                {
                    "sent": "Obviously at the at field level the field level the error is huge.",
                    "label": 0
                },
                {
                    "sent": "I mean if you have only a 5% error in each character, obviously we have some names of seven or eight characters.",
                    "label": 0
                },
                {
                    "sent": "Hey there are is is very large for this is the error.",
                    "label": 0
                },
                {
                    "sent": "I mean if we allow this error rate this output error rates and we get this recognition rate.",
                    "label": 0
                },
                {
                    "sent": "I mean we obviously reject all those strings that have less than a given confidence.",
                    "label": 0
                },
                {
                    "sent": "So we get this error rate.",
                    "label": 1
                },
                {
                    "sent": "And that recognition rate.",
                    "label": 0
                },
                {
                    "sent": "Usually the error rate is limited, maximum 2 one or 2%.",
                    "label": 0
                },
                {
                    "sent": "In a typical real operation, so you don't allow more than one or 2% error rates and then.",
                    "label": 0
                },
                {
                    "sent": "You get this recognition rate and the rest you have to type it manually.",
                    "label": 1
                },
                {
                    "sent": "I mean it's left for manual input, so that's the that's.",
                    "label": 0
                },
                {
                    "sent": "So if the recognition rate is higher is better because you don't have to input so many surnames.",
                    "label": 0
                },
                {
                    "sent": "In this case by hand so.",
                    "label": 0
                },
                {
                    "sent": "The difference in this in this area as you see well, it's it's significant.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We have here the daily salary between 2 and 3% of improvement.",
                    "label": 0
                },
                {
                    "sent": "So this is the the improvement we get with this with this.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "Technique and the time is also so.",
                    "label": 0
                },
                {
                    "sent": "I mean, this is with very.",
                    "label": 0
                },
                {
                    "sent": "Practical in this case, correction time using typical PC and the language model with this language model we used.",
                    "label": 1
                },
                {
                    "sent": "Which finally gives rise to a transducer with 64,000 States and 140,000 transitions.",
                    "label": 1
                },
                {
                    "sent": "The typical input string length of well, it's more less linear with the input string length, and it's about half a second as.",
                    "label": 0
                },
                {
                    "sent": "Even with less than half a second, even with the longest surnames.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sam so the conclusions is that we improved.",
                    "label": 0
                },
                {
                    "sent": "The system of character recognition using the technique based on on.",
                    "label": 1
                },
                {
                    "sent": "Users.",
                    "label": 0
                },
                {
                    "sent": "And then we get a global minimization of taking into account all the information of the system.",
                    "label": 0
                },
                {
                    "sent": "So we get the most probabilistic compatible with the language, the hypothesis, and the error models.",
                    "label": 1
                },
                {
                    "sent": "We improved.",
                    "label": 0
                },
                {
                    "sent": "In fact the efficiency and also the results and.",
                    "label": 0
                },
                {
                    "sent": "But the most probably the most interesting thing from practical, from a practical point of view, is that we have.",
                    "label": 1
                },
                {
                    "sent": "A language OCR and error models that are independently that can be independently modified.",
                    "label": 0
                },
                {
                    "sent": "This is quite useful because in typical form, for example you have.",
                    "label": 0
                },
                {
                    "sent": "1015 different fields with different language models.",
                    "label": 0
                },
                {
                    "sent": "You have.",
                    "label": 0
                },
                {
                    "sent": "Surname, name, address.",
                    "label": 0
                },
                {
                    "sent": "So many different fields in the same document, so it's very interesting to have an OCR well.",
                    "label": 0
                },
                {
                    "sent": "Optimal optimized for forgiven, forgiven?",
                    "label": 0
                },
                {
                    "sent": "Language, I mean County or whatever, but then to be able to change and optimize independently the language model and but the final result is a global globally optimized with all the information.",
                    "label": 0
                },
                {
                    "sent": "So that's more or less the final advantage we see in this model.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So thank you for your attention.",
                    "label": 1
                },
                {
                    "sent": "The result of the combination is actually normal deterministic.",
                    "label": 0
                },
                {
                    "sent": "He combination of the three transducers.",
                    "label": 0
                },
                {
                    "sent": "Computing device probable translation is not that simple.",
                    "label": 0
                },
                {
                    "sent": "You only you only have to look for the best path.",
                    "label": 0
                },
                {
                    "sent": "A so so so, so at each possible at it's possible selection you get the highest probability and then the final path is typical.",
                    "label": 0
                },
                {
                    "sent": "Typical operation.",
                    "label": 0
                },
                {
                    "sent": "In fact we're using.",
                    "label": 0
                },
                {
                    "sent": "An open source.",
                    "label": 0
                },
                {
                    "sent": "Where does user package that gives the result of the optimization?",
                    "label": 0
                },
                {
                    "sent": "Very fast, in fact.",
                    "label": 0
                },
                {
                    "sent": "I mean the the building the transducer is there is a is the heavy part of the of the time.",
                    "label": 0
                },
                {
                    "sent": "I mean of the final time.",
                    "label": 0
                },
                {
                    "sent": "So the best path is not a problem, but I cannot say exactly which technique they are using.",
                    "label": 0
                },
                {
                    "sent": "Are you using?",
                    "label": 0
                },
                {
                    "sent": "It's open FST.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                }
            ]
        }
    }
}