{
    "id": "nyl37q6jsed2om34mnc4s5h4w2mtyect",
    "title": "Gaussian process modelling of transcription factor networks using Markov Chain Monte-Carlo",
    "info": {
        "author": [
            "Michalis K. Titsias, School of Mathematics, University of Manchester"
        ],
        "published": "April 17, 2008",
        "recorded": "March 2008",
        "category": [
            "Top->Computer Science->Machine Learning->Gaussian Processes",
            "Top->Computer Science->Machine Learning->Markov Processes"
        ]
    },
    "url": "http://videolectures.net/licsb08_titsias_gpm/",
    "segmentation": [
        [
            "I'm going to talk about Gaussian process modeling of transcription factor networks using Markov chain model Carlo.",
            "This work I'm doing with near Lawrence and Magnus."
        ],
        [
            "I.",
            "Just a brief outline and I'm going to present the new sub lingering for Gaussian process models.",
            "I'm going to apply this for the problem of transcription factor, protein inference and I will show some results and there are some conclu."
        ],
        [
            "A very brief overview about Gaussian processes.",
            "Gaussian processes of the distribution over functions.",
            "It has a main function, which typically is the zero function and a covariance function.",
            "For example, with RBF.",
            "OK, what does it mean?"
        ],
        [
            "Over the function.",
            "Well, in practice we don't actually have to answer this question because in reality we only have.",
            "We only need to evaluate a function in a set of points, then a Gaussian processes reduces to multi variate Gaussian distribution over the outputs of the function where the covariance of the distribution is defined by the kernel function on important thing for someone to notice here is that these distributions conditional we condition on the inputs."
        ],
        [
            "On the input OK, How can we the Gaussian process many problems when we do?",
            "The modeling involves some influence over some latent or an observed function.",
            "For example in classification.",
            "There is a decision boundary or integration, so the Gaussian process can allow us.",
            "To place a prior over function over functions and then apply Bayesian inference, we observe some data.",
            "Why always associated with some inputs?",
            "We assume a likelihood model with associates the data with the latent function.",
            "We assume a Gaussian process prior for the latent function, and then we apply the bias rule and get the posterior over the latent function for the regression where the likelihood is Gaussian, the goal computations are tractable."
        ],
        [
            "Just to show you some pictures, we have some data.",
            "We believe that there is some other line function that characterize this data."
        ],
        [
            "We assume a prior over this function which just says that the function can be.",
            "Pretty much arbitrary, but there is some smooth constraints that are imposed by the cannon by the covariance function, But the kernel function."
        ],
        [
            "We apply the bias rule and we update the posterior.",
            "This is in terms of samples."
        ],
        [
            "From the posterior.",
            "OK, if the likelihood the model that associates are observations with latent functions is not Gaussian, then things become intractable.",
            "Exams are in classification problems or nonlinear differential equations.",
            "When we did this kind of models in systems biology in this kind of.",
            "Cases we need to consider approximations.",
            "MCMC offers a general and powerful framework for inference and it has.",
            "Some of the properties, for example, is that it can be applied independently from the actual function and form of the likelihood.",
            "Gives exact inference in the limit of many sums.",
            "You can also use can be used to validate."
        ],
        [
            "The terministic methods that can be faster than MCMC.",
            "OK, in the context of mockery of Mark of Gaussian processes.",
            "The metropolis casting gallons that we're going to use have this form.",
            "We initialize the the Gaussian process latent function or this set of points.",
            "We form a Markov chain.",
            "Recover proposal distribution that allow us to propose, given the current state and you state and we accept or reject the new state based on the metropolis casting probability.",
            "Now a very important question.",
            "When we do sampling Gaussian processes that this safe is a very high dimensional.",
            "We discretize a function here so this can be really can be hundreds of points.",
            "So how would actually do?",
            "How do we choose the proposal?",
            "So OK, someone we say, let's let's let's assume the prior.",
            "Let's use the price for the proposal.",
            "If we do this, we actually cannot do this because the reason is that when you send from the prior is very unlikely to get a function that will feed the data.",
            "So in some sense the Markov chain it will stuck in the same state forever or something.",
            "You could get a zero acceptance rate, but on the other hand the prior has a very nice property because when you some from the prior you always some functions that satisfy the smoothest smoothing constraints.",
            "That are imposed by the covariance function.",
            "So this is really important.",
            "So this is actually the motivation of our algorithm to some from the prior but but imposing some."
        ],
        [
            "Behavior, so this is the definition of the algorithm.",
            "We separate the points in F into two groups.",
            "We have few control points.",
            "This is just five or 696 points in our application, and the last majority of the remaining points would be like the whole function.",
            "Then we send first the control points using this proposal.",
            "Given the current value of the proposed of the of the control points with new new control points, and then we sum.",
            "The remaining points using the conditional prior.",
            "OK, here is a table should be T + 1, so the proposal is like this.",
            "Given given the old state of the of the control points you stayed for value for the control points and then you submit all the remaining points given the values of the control points.",
            "So the idea is that the same sense you something from the prior, as long as these control points are independent, you always draw a sample that that satisfy the smoothest constraints of of your Gaussian process prior."
        ],
        [
            "I would just show you some pictures of this.",
            "We have 120 points.",
            "A regression problem with the green.",
            "Here is the current Gaussian process function in the Markov saying this is the current state.",
            "This is the control points, so the proposed."
        ],
        [
            "It works as follows.",
            "We Ferd we first submucosal points, which is the new red points here."
        ],
        [
            "And then we just interpolate between between these points by drawing from the conditional prior some levels."
        ],
        [
            "Taxes.",
            "Another example, this is the."
        ],
        [
            "State we proposed."
        ],
        [
            "All points and with depilate between these points by drawing from the condition applier."
        ],
        [
            "This is a sound drawing from the during."
        ],
        [
            "CMC.",
            "OK so OK always when you apply name CMC method we should really have the real problem.",
            "We have to think about adoption.",
            "We have to adapt.",
            "In some sense the proposal during the bending period of MCMC issues that we have to solve.",
            "In this algorithm is how many quadrants points we have to use, where we should put this quadrant points.",
            "How can you prove the acceptance rates OK, there are.",
            "There are answers to these questions.",
            "For example, we can sum the control points in a blockwise manner.",
            "We can keep some some control points fixed and some of the others.",
            "This will increase the random behavior of the album.",
            "So we improve the acceptance rates.",
            "The good news is that for the application of the transcription factor modeling, when we have an order ordinary differential equation, we have a very good natural answers for all these questions.",
            "We know how much how many control points we should use, and pretty much where we should place them.",
            "So the only thing we're doing during the adoption is to adapt the variances of this proposal distribution that the variance with just this distribution, just a Gaussian with."
        ],
        [
            "Covariance matrix.",
            "So I'm just going to the application.",
            "So we have some data, the data, some expression levels.",
            "Of engines that are measured in two different times, the objective of modeling is that.",
            "Whom I know that there is a protein that is a transcription factor that regulates disease and we want to model this this relationship this situation.",
            "So we're going to use a differential equation model proposed by Branco 2006 and allows us at 20,007 having this form where T is time.",
            "Why there is the expression of the Avs in FT?",
            "Is the concentration of the transcription factor providing these are continuous function, overtime is unknown.",
            "We don't observe this this decade 8B is the bus.",
            "Relatives in South is the sensitivity Z.",
            "Here is some possible nonlinear function can be defined can be for example linear can be defined by behinds magnetic equation.",
            "OK, when we.",
            "The way that we do in this equation here we just have the derivative of the expression overtime, while the observations actually are the the genes."
        ],
        [
            "This in expressions, so we solve.",
            "This equation still distinguishes tractable becausw.",
            "We cannot compute in general this decade, so we use numerical decoration for exam Simpson method.",
            "So at the end of the day, this ordinary differential equation defines the likelihood defines the model that associates the data with the latent function where the latent functions that concentrates the concentration of the product.",
            "So then we know how how to move on.",
            "We apply Bayesian inference.",
            "We assume a Gaussian process prior for the transcription.",
            "For the transcription factor, protein for this function.",
            "If we assume priors for all this kinetic parameters which.",
            "Are unknown and we apply MCMC.",
            "One important thing here is that we infer the protein in a continuous matter in a continuous manner.",
            "Becausw, we discretize this differential equation in agreed that is really large.",
            "This P here is much larger than the number of times that we have measurements of."
        ],
        [
            "Of the of the gene expressions.",
            "I also just show you results in two data sets, one that I said is was considered by Rosa scanning 2007 is the equally data.",
            "There is a transcription factor that lacks a that acts as a repressor.",
            "Now we consider for this replacement case.",
            "We consider a Michaelis method, kinetically equation.",
            "So the nonlinearity in the differential equation has this form.",
            "We take the exponent of the Gaussian process becausw to impose positivity constraint.",
            "So in some sense.",
            "You have OK. We have 14 these five kinetic parameters.",
            "Evaluating six times.",
            "We discretized the differential equation using 120 points.",
            "This is the details of the MCMC we use just six control points, exactly as how many time steps we have.",
            "We put it equally spaced.",
            "So.",
            "That's pretty much it, actually.",
            "So far it works.",
            "For all the data we have worked so far we learned.",
            "Five hours takes for 2 million something iterations plus 200,000 burning the acceptance they would get 4F after the buildings around 15 to 20 or something."
        ],
        [
            "So this is the fitting of our model that the model is doing for the gene expression.",
            "So this is the first 60s with the Red Cross is are the expressions and with the blue are the prediction that the model gives about the next."
        ],
        [
            "Nation.",
            "This is the next six months."
        ],
        [
            "And."
        ],
        [
            "Last two jeans.",
            "OK, this is.",
            "This is the inference.",
            "This is the inference over the product.",
            "We see actually that is.",
            "There is a huge error bar.",
            "In this inference.",
            "Some sensors would be some kind of.",
            "Relax, we have probably the data to fuel some sense we have asserted about."
        ],
        [
            "The inference.",
            "This is the Basel rate.",
            "One thing to notice here is that the sensitivity.",
            "But sometimes this is the sensitivity.",
            "Tell you if really the protein regulates that single node.",
            "There is something here that has almost zero sensitivity and also these two things here that have sensitivity close to 0.",
            "So let's."
        ],
        [
            "Turning this disease if there is.",
            "Any increase in why this happened?",
            "OK, the first deal that has sensitivity close to 0 is this one.",
            "Was as you can see here that.",
            "When we pass the initial, the initial condition of the differential equation, the differential equation just converges to the equilibrium, just the Basel rate over the decade rate.",
            "So in some sense does not.",
            "There is no connection between the the dinner, the transcription factor, so that's why the model assumes that.",
            "Put the sensitivity equal to 0.",
            "Pretty much the same situation for this.",
            "And for this probability, because that thing is not is not repressed.",
            "It's kind of activated probably."
        ],
        [
            "This is there a bus we get that have a huge error, but actually.",
            "But however, for this in actually the error bars are very small.",
            "Obviously there is a lot of uncertainty.",
            "We have two data."
        ],
        [
            "The second example is the data used by Baranco told we have now one transcription factor that P53 protein that acts as activatur have the Michaelis Menten equation for the Activator, case 5 genes evaluating 7 times.",
            "This is MCMC."
        ],
        [
            "Sales.",
            "This as well giving."
        ],
        [
            "OK, in this slide is we have three replicas here, so the experiment is repeated three times in some sense.",
            "Hey this is the product concentrations we use on linear model and this is where we use a non linear model based on the equation.",
            "What can you observe here?",
            "Is that the mode here is a bit shifted.",
            "Shifted to the right, and it turns out that the ground truth that provided by Baranco is actually the mode that they have is between between 4:00 and 8:00.",
            "And this is pretty much what we're getting for the nonlinear case with my shows that the nonlinear models is."
        ],
        [
            "It's better I don't know.",
            "That's my, Oh yeah, this is the Basel rate and all the genetic parameters for for the nonlinear model.",
            "I just also put the other comparison and the corresponding results of baranco for with who they are.",
            "Using a linear model.",
            "Probably is not right to compare a linear and nonlinear model, but I was just curious to see.",
            "Which will be the difference where the models will agree on where they will disagree or something?",
            "What you can see is that for example, they agree in the case and probably in the buzzer raise, but.",
            "Probably there is some disagreement in the sensitivity.",
            "This kind of shows that choosing the right model.",
            "Is important because different models will give you different results, so you should care about the model and the way that you feed the model to the data.",
            "But in this case, for example, I don't know if the linear nonlinear model is the best, but.",
            "Having a way to say which is the."
        ],
        [
            "This is important.",
            "So this is.",
            "The last lies I spoke about an MCMC album for Gaussian process.",
            "This is an argument applied for classification.",
            "Other problems I.",
            "We apply this to Bayesian inference.",
            "Interesting factor network services for future resources to deal with other systems and incorporate domain loads.",
            "When you define priors over parameters.",
            "Thank you.",
            "Any questions?",
            "What do you mean the mattress?",
            "Does an exponential right because because the Gaussian process, the function can be also negative.",
            "So in some sense we want to impose the positivity constraint because you because the protein you know that is a positive quantity.",
            "Yeah.",
            "So in some sense you you, you assume that the Gaussian processes is the log of the transcription factor.",
            "Yeah, is exponential.",
            "Yeah all this error bars is for the exponential formula.",
            "Ghost.",
            "Proposal distribution is symmetrical or you have to use it.",
            "OK then.",
            "The proposal for the control points is symmetrical, is just a Gaussian.",
            "This is what you yeah it is.",
            "Yeah, I'm sending the control points.",
            "And also the rest points the remaining points.",
            "Yes, yeah.",
            "Did something going.",
            "I even just to the current points, just use those as a meeting on a GP.",
            "Rather than using specific control points.",
            "Can you repeat?",
            "Love your current scription, factor profile that you sampled so your next proposal would just be centered on that particular one, so it's a bit of a Gaussian process with a mean of effort T. So.",
            "Actually sampling.",
            "Control points and then conditioning on those control points could be just conditional and your current functional realization.",
            "But I'm not sure if we will be able to move a lot.",
            "I mean 'cause.",
            "I'm asking, yeah.",
            "Yeah, I'm not.",
            "This.",
            "Yeah, I mean.",
            "Something control points and then condition.",
            "Yeah, because with some sense you have the freedom.",
            "Yeah, to move a lot becausw assume that this control points are independent.",
            "So you want some sense you're saying to move, not not just be stacked, and you know the next next.",
            "State assumptions to be very close to the previous round because you might be able to get a very high acceptance rate, but if you don't explore if your tenant does not explore the space efficiently, then.",
            "So that probably I didn't understand exactly actually what your point actually.",
            "Square doesn't use this control point strategy sampling strategy.",
            "So you just use the functional, yeah?",
            "It goes in process proposal distribution.",
            "So I don't know actually.",
            "Yeah, it would be this.",
            "Actually this is I haven't, yeah.",
            "So now this actually works.",
            "Suppresses against presence in log space effectively.",
            "The fact is that effectively you've got small variations in log space to make traumatic differences in real space.",
            "Is this the cause of your massive error bars?",
            "I mean, we've got very large error bars in Sioux City.",
            "That's because basically got this gas and distribution, and probably.",
            "Yeah, suppose so yeah, I mean.",
            "I guess, yeah, that's also there are symmetric thereabouts, obviously because because also you measured everybody in the exponent of the.",
            "Go soon.",
            "Yeah.",
            "Thanks very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm going to talk about Gaussian process modeling of transcription factor networks using Markov chain model Carlo.",
                    "label": 0
                },
                {
                    "sent": "This work I'm doing with near Lawrence and Magnus.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I.",
                    "label": 0
                },
                {
                    "sent": "Just a brief outline and I'm going to present the new sub lingering for Gaussian process models.",
                    "label": 1
                },
                {
                    "sent": "I'm going to apply this for the problem of transcription factor, protein inference and I will show some results and there are some conclu.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A very brief overview about Gaussian processes.",
                    "label": 0
                },
                {
                    "sent": "Gaussian processes of the distribution over functions.",
                    "label": 1
                },
                {
                    "sent": "It has a main function, which typically is the zero function and a covariance function.",
                    "label": 0
                },
                {
                    "sent": "For example, with RBF.",
                    "label": 0
                },
                {
                    "sent": "OK, what does it mean?",
                    "label": 1
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Over the function.",
                    "label": 0
                },
                {
                    "sent": "Well, in practice we don't actually have to answer this question because in reality we only have.",
                    "label": 0
                },
                {
                    "sent": "We only need to evaluate a function in a set of points, then a Gaussian processes reduces to multi variate Gaussian distribution over the outputs of the function where the covariance of the distribution is defined by the kernel function on important thing for someone to notice here is that these distributions conditional we condition on the inputs.",
                    "label": 1
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "On the input OK, How can we the Gaussian process many problems when we do?",
                    "label": 0
                },
                {
                    "sent": "The modeling involves some influence over some latent or an observed function.",
                    "label": 0
                },
                {
                    "sent": "For example in classification.",
                    "label": 0
                },
                {
                    "sent": "There is a decision boundary or integration, so the Gaussian process can allow us.",
                    "label": 0
                },
                {
                    "sent": "To place a prior over function over functions and then apply Bayesian inference, we observe some data.",
                    "label": 1
                },
                {
                    "sent": "Why always associated with some inputs?",
                    "label": 0
                },
                {
                    "sent": "We assume a likelihood model with associates the data with the latent function.",
                    "label": 0
                },
                {
                    "sent": "We assume a Gaussian process prior for the latent function, and then we apply the bias rule and get the posterior over the latent function for the regression where the likelihood is Gaussian, the goal computations are tractable.",
                    "label": 1
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just to show you some pictures, we have some data.",
                    "label": 0
                },
                {
                    "sent": "We believe that there is some other line function that characterize this data.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We assume a prior over this function which just says that the function can be.",
                    "label": 0
                },
                {
                    "sent": "Pretty much arbitrary, but there is some smooth constraints that are imposed by the cannon by the covariance function, But the kernel function.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We apply the bias rule and we update the posterior.",
                    "label": 0
                },
                {
                    "sent": "This is in terms of samples.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "From the posterior.",
                    "label": 0
                },
                {
                    "sent": "OK, if the likelihood the model that associates are observations with latent functions is not Gaussian, then things become intractable.",
                    "label": 0
                },
                {
                    "sent": "Exams are in classification problems or nonlinear differential equations.",
                    "label": 1
                },
                {
                    "sent": "When we did this kind of models in systems biology in this kind of.",
                    "label": 0
                },
                {
                    "sent": "Cases we need to consider approximations.",
                    "label": 1
                },
                {
                    "sent": "MCMC offers a general and powerful framework for inference and it has.",
                    "label": 1
                },
                {
                    "sent": "Some of the properties, for example, is that it can be applied independently from the actual function and form of the likelihood.",
                    "label": 1
                },
                {
                    "sent": "Gives exact inference in the limit of many sums.",
                    "label": 1
                },
                {
                    "sent": "You can also use can be used to validate.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The terministic methods that can be faster than MCMC.",
                    "label": 0
                },
                {
                    "sent": "OK, in the context of mockery of Mark of Gaussian processes.",
                    "label": 0
                },
                {
                    "sent": "The metropolis casting gallons that we're going to use have this form.",
                    "label": 0
                },
                {
                    "sent": "We initialize the the Gaussian process latent function or this set of points.",
                    "label": 0
                },
                {
                    "sent": "We form a Markov chain.",
                    "label": 1
                },
                {
                    "sent": "Recover proposal distribution that allow us to propose, given the current state and you state and we accept or reject the new state based on the metropolis casting probability.",
                    "label": 0
                },
                {
                    "sent": "Now a very important question.",
                    "label": 0
                },
                {
                    "sent": "When we do sampling Gaussian processes that this safe is a very high dimensional.",
                    "label": 0
                },
                {
                    "sent": "We discretize a function here so this can be really can be hundreds of points.",
                    "label": 0
                },
                {
                    "sent": "So how would actually do?",
                    "label": 0
                },
                {
                    "sent": "How do we choose the proposal?",
                    "label": 1
                },
                {
                    "sent": "So OK, someone we say, let's let's let's assume the prior.",
                    "label": 0
                },
                {
                    "sent": "Let's use the price for the proposal.",
                    "label": 0
                },
                {
                    "sent": "If we do this, we actually cannot do this because the reason is that when you send from the prior is very unlikely to get a function that will feed the data.",
                    "label": 0
                },
                {
                    "sent": "So in some sense the Markov chain it will stuck in the same state forever or something.",
                    "label": 0
                },
                {
                    "sent": "You could get a zero acceptance rate, but on the other hand the prior has a very nice property because when you some from the prior you always some functions that satisfy the smoothest smoothing constraints.",
                    "label": 0
                },
                {
                    "sent": "That are imposed by the covariance function.",
                    "label": 0
                },
                {
                    "sent": "So this is really important.",
                    "label": 0
                },
                {
                    "sent": "So this is actually the motivation of our algorithm to some from the prior but but imposing some.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Behavior, so this is the definition of the algorithm.",
                    "label": 0
                },
                {
                    "sent": "We separate the points in F into two groups.",
                    "label": 1
                },
                {
                    "sent": "We have few control points.",
                    "label": 0
                },
                {
                    "sent": "This is just five or 696 points in our application, and the last majority of the remaining points would be like the whole function.",
                    "label": 0
                },
                {
                    "sent": "Then we send first the control points using this proposal.",
                    "label": 0
                },
                {
                    "sent": "Given the current value of the proposed of the of the control points with new new control points, and then we sum.",
                    "label": 1
                },
                {
                    "sent": "The remaining points using the conditional prior.",
                    "label": 0
                },
                {
                    "sent": "OK, here is a table should be T + 1, so the proposal is like this.",
                    "label": 1
                },
                {
                    "sent": "Given given the old state of the of the control points you stayed for value for the control points and then you submit all the remaining points given the values of the control points.",
                    "label": 0
                },
                {
                    "sent": "So the idea is that the same sense you something from the prior, as long as these control points are independent, you always draw a sample that that satisfy the smoothest constraints of of your Gaussian process prior.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I would just show you some pictures of this.",
                    "label": 0
                },
                {
                    "sent": "We have 120 points.",
                    "label": 0
                },
                {
                    "sent": "A regression problem with the green.",
                    "label": 0
                },
                {
                    "sent": "Here is the current Gaussian process function in the Markov saying this is the current state.",
                    "label": 1
                },
                {
                    "sent": "This is the control points, so the proposed.",
                    "label": 1
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It works as follows.",
                    "label": 0
                },
                {
                    "sent": "We Ferd we first submucosal points, which is the new red points here.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we just interpolate between between these points by drawing from the conditional prior some levels.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Taxes.",
                    "label": 0
                },
                {
                    "sent": "Another example, this is the.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "State we proposed.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "All points and with depilate between these points by drawing from the condition applier.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is a sound drawing from the during.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "CMC.",
                    "label": 0
                },
                {
                    "sent": "OK so OK always when you apply name CMC method we should really have the real problem.",
                    "label": 0
                },
                {
                    "sent": "We have to think about adoption.",
                    "label": 0
                },
                {
                    "sent": "We have to adapt.",
                    "label": 0
                },
                {
                    "sent": "In some sense the proposal during the bending period of MCMC issues that we have to solve.",
                    "label": 1
                },
                {
                    "sent": "In this algorithm is how many quadrants points we have to use, where we should put this quadrant points.",
                    "label": 0
                },
                {
                    "sent": "How can you prove the acceptance rates OK, there are.",
                    "label": 1
                },
                {
                    "sent": "There are answers to these questions.",
                    "label": 0
                },
                {
                    "sent": "For example, we can sum the control points in a blockwise manner.",
                    "label": 1
                },
                {
                    "sent": "We can keep some some control points fixed and some of the others.",
                    "label": 1
                },
                {
                    "sent": "This will increase the random behavior of the album.",
                    "label": 0
                },
                {
                    "sent": "So we improve the acceptance rates.",
                    "label": 1
                },
                {
                    "sent": "The good news is that for the application of the transcription factor modeling, when we have an order ordinary differential equation, we have a very good natural answers for all these questions.",
                    "label": 0
                },
                {
                    "sent": "We know how much how many control points we should use, and pretty much where we should place them.",
                    "label": 1
                },
                {
                    "sent": "So the only thing we're doing during the adoption is to adapt the variances of this proposal distribution that the variance with just this distribution, just a Gaussian with.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Covariance matrix.",
                    "label": 0
                },
                {
                    "sent": "So I'm just going to the application.",
                    "label": 0
                },
                {
                    "sent": "So we have some data, the data, some expression levels.",
                    "label": 0
                },
                {
                    "sent": "Of engines that are measured in two different times, the objective of modeling is that.",
                    "label": 0
                },
                {
                    "sent": "Whom I know that there is a protein that is a transcription factor that regulates disease and we want to model this this relationship this situation.",
                    "label": 1
                },
                {
                    "sent": "So we're going to use a differential equation model proposed by Branco 2006 and allows us at 20,007 having this form where T is time.",
                    "label": 0
                },
                {
                    "sent": "Why there is the expression of the Avs in FT?",
                    "label": 1
                },
                {
                    "sent": "Is the concentration of the transcription factor providing these are continuous function, overtime is unknown.",
                    "label": 0
                },
                {
                    "sent": "We don't observe this this decade 8B is the bus.",
                    "label": 0
                },
                {
                    "sent": "Relatives in South is the sensitivity Z.",
                    "label": 0
                },
                {
                    "sent": "Here is some possible nonlinear function can be defined can be for example linear can be defined by behinds magnetic equation.",
                    "label": 0
                },
                {
                    "sent": "OK, when we.",
                    "label": 0
                },
                {
                    "sent": "The way that we do in this equation here we just have the derivative of the expression overtime, while the observations actually are the the genes.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This in expressions, so we solve.",
                    "label": 0
                },
                {
                    "sent": "This equation still distinguishes tractable becausw.",
                    "label": 0
                },
                {
                    "sent": "We cannot compute in general this decade, so we use numerical decoration for exam Simpson method.",
                    "label": 0
                },
                {
                    "sent": "So at the end of the day, this ordinary differential equation defines the likelihood defines the model that associates the data with the latent function where the latent functions that concentrates the concentration of the product.",
                    "label": 0
                },
                {
                    "sent": "So then we know how how to move on.",
                    "label": 0
                },
                {
                    "sent": "We apply Bayesian inference.",
                    "label": 0
                },
                {
                    "sent": "We assume a Gaussian process prior for the transcription.",
                    "label": 1
                },
                {
                    "sent": "For the transcription factor, protein for this function.",
                    "label": 0
                },
                {
                    "sent": "If we assume priors for all this kinetic parameters which.",
                    "label": 0
                },
                {
                    "sent": "Are unknown and we apply MCMC.",
                    "label": 1
                },
                {
                    "sent": "One important thing here is that we infer the protein in a continuous matter in a continuous manner.",
                    "label": 0
                },
                {
                    "sent": "Becausw, we discretize this differential equation in agreed that is really large.",
                    "label": 0
                },
                {
                    "sent": "This P here is much larger than the number of times that we have measurements of.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Of the of the gene expressions.",
                    "label": 1
                },
                {
                    "sent": "I also just show you results in two data sets, one that I said is was considered by Rosa scanning 2007 is the equally data.",
                    "label": 1
                },
                {
                    "sent": "There is a transcription factor that lacks a that acts as a repressor.",
                    "label": 1
                },
                {
                    "sent": "Now we consider for this replacement case.",
                    "label": 0
                },
                {
                    "sent": "We consider a Michaelis method, kinetically equation.",
                    "label": 0
                },
                {
                    "sent": "So the nonlinearity in the differential equation has this form.",
                    "label": 0
                },
                {
                    "sent": "We take the exponent of the Gaussian process becausw to impose positivity constraint.",
                    "label": 0
                },
                {
                    "sent": "So in some sense.",
                    "label": 1
                },
                {
                    "sent": "You have OK. We have 14 these five kinetic parameters.",
                    "label": 0
                },
                {
                    "sent": "Evaluating six times.",
                    "label": 0
                },
                {
                    "sent": "We discretized the differential equation using 120 points.",
                    "label": 1
                },
                {
                    "sent": "This is the details of the MCMC we use just six control points, exactly as how many time steps we have.",
                    "label": 0
                },
                {
                    "sent": "We put it equally spaced.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "That's pretty much it, actually.",
                    "label": 0
                },
                {
                    "sent": "So far it works.",
                    "label": 1
                },
                {
                    "sent": "For all the data we have worked so far we learned.",
                    "label": 0
                },
                {
                    "sent": "Five hours takes for 2 million something iterations plus 200,000 burning the acceptance they would get 4F after the buildings around 15 to 20 or something.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is the fitting of our model that the model is doing for the gene expression.",
                    "label": 0
                },
                {
                    "sent": "So this is the first 60s with the Red Cross is are the expressions and with the blue are the prediction that the model gives about the next.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Nation.",
                    "label": 0
                },
                {
                    "sent": "This is the next six months.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Last two jeans.",
                    "label": 0
                },
                {
                    "sent": "OK, this is.",
                    "label": 0
                },
                {
                    "sent": "This is the inference.",
                    "label": 0
                },
                {
                    "sent": "This is the inference over the product.",
                    "label": 0
                },
                {
                    "sent": "We see actually that is.",
                    "label": 0
                },
                {
                    "sent": "There is a huge error bar.",
                    "label": 0
                },
                {
                    "sent": "In this inference.",
                    "label": 0
                },
                {
                    "sent": "Some sensors would be some kind of.",
                    "label": 0
                },
                {
                    "sent": "Relax, we have probably the data to fuel some sense we have asserted about.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The inference.",
                    "label": 0
                },
                {
                    "sent": "This is the Basel rate.",
                    "label": 0
                },
                {
                    "sent": "One thing to notice here is that the sensitivity.",
                    "label": 0
                },
                {
                    "sent": "But sometimes this is the sensitivity.",
                    "label": 0
                },
                {
                    "sent": "Tell you if really the protein regulates that single node.",
                    "label": 0
                },
                {
                    "sent": "There is something here that has almost zero sensitivity and also these two things here that have sensitivity close to 0.",
                    "label": 0
                },
                {
                    "sent": "So let's.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Turning this disease if there is.",
                    "label": 0
                },
                {
                    "sent": "Any increase in why this happened?",
                    "label": 0
                },
                {
                    "sent": "OK, the first deal that has sensitivity close to 0 is this one.",
                    "label": 0
                },
                {
                    "sent": "Was as you can see here that.",
                    "label": 0
                },
                {
                    "sent": "When we pass the initial, the initial condition of the differential equation, the differential equation just converges to the equilibrium, just the Basel rate over the decade rate.",
                    "label": 0
                },
                {
                    "sent": "So in some sense does not.",
                    "label": 0
                },
                {
                    "sent": "There is no connection between the the dinner, the transcription factor, so that's why the model assumes that.",
                    "label": 0
                },
                {
                    "sent": "Put the sensitivity equal to 0.",
                    "label": 0
                },
                {
                    "sent": "Pretty much the same situation for this.",
                    "label": 0
                },
                {
                    "sent": "And for this probability, because that thing is not is not repressed.",
                    "label": 0
                },
                {
                    "sent": "It's kind of activated probably.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is there a bus we get that have a huge error, but actually.",
                    "label": 0
                },
                {
                    "sent": "But however, for this in actually the error bars are very small.",
                    "label": 0
                },
                {
                    "sent": "Obviously there is a lot of uncertainty.",
                    "label": 0
                },
                {
                    "sent": "We have two data.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The second example is the data used by Baranco told we have now one transcription factor that P53 protein that acts as activatur have the Michaelis Menten equation for the Activator, case 5 genes evaluating 7 times.",
                    "label": 0
                },
                {
                    "sent": "This is MCMC.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sales.",
                    "label": 0
                },
                {
                    "sent": "This as well giving.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, in this slide is we have three replicas here, so the experiment is repeated three times in some sense.",
                    "label": 0
                },
                {
                    "sent": "Hey this is the product concentrations we use on linear model and this is where we use a non linear model based on the equation.",
                    "label": 0
                },
                {
                    "sent": "What can you observe here?",
                    "label": 0
                },
                {
                    "sent": "Is that the mode here is a bit shifted.",
                    "label": 0
                },
                {
                    "sent": "Shifted to the right, and it turns out that the ground truth that provided by Baranco is actually the mode that they have is between between 4:00 and 8:00.",
                    "label": 0
                },
                {
                    "sent": "And this is pretty much what we're getting for the nonlinear case with my shows that the nonlinear models is.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's better I don't know.",
                    "label": 0
                },
                {
                    "sent": "That's my, Oh yeah, this is the Basel rate and all the genetic parameters for for the nonlinear model.",
                    "label": 0
                },
                {
                    "sent": "I just also put the other comparison and the corresponding results of baranco for with who they are.",
                    "label": 0
                },
                {
                    "sent": "Using a linear model.",
                    "label": 0
                },
                {
                    "sent": "Probably is not right to compare a linear and nonlinear model, but I was just curious to see.",
                    "label": 0
                },
                {
                    "sent": "Which will be the difference where the models will agree on where they will disagree or something?",
                    "label": 0
                },
                {
                    "sent": "What you can see is that for example, they agree in the case and probably in the buzzer raise, but.",
                    "label": 0
                },
                {
                    "sent": "Probably there is some disagreement in the sensitivity.",
                    "label": 0
                },
                {
                    "sent": "This kind of shows that choosing the right model.",
                    "label": 0
                },
                {
                    "sent": "Is important because different models will give you different results, so you should care about the model and the way that you feed the model to the data.",
                    "label": 0
                },
                {
                    "sent": "But in this case, for example, I don't know if the linear nonlinear model is the best, but.",
                    "label": 0
                },
                {
                    "sent": "Having a way to say which is the.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is important.",
                    "label": 0
                },
                {
                    "sent": "So this is.",
                    "label": 0
                },
                {
                    "sent": "The last lies I spoke about an MCMC album for Gaussian process.",
                    "label": 0
                },
                {
                    "sent": "This is an argument applied for classification.",
                    "label": 0
                },
                {
                    "sent": "Other problems I.",
                    "label": 0
                },
                {
                    "sent": "We apply this to Bayesian inference.",
                    "label": 0
                },
                {
                    "sent": "Interesting factor network services for future resources to deal with other systems and incorporate domain loads.",
                    "label": 0
                },
                {
                    "sent": "When you define priors over parameters.",
                    "label": 1
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Any questions?",
                    "label": 0
                },
                {
                    "sent": "What do you mean the mattress?",
                    "label": 0
                },
                {
                    "sent": "Does an exponential right because because the Gaussian process, the function can be also negative.",
                    "label": 0
                },
                {
                    "sent": "So in some sense we want to impose the positivity constraint because you because the protein you know that is a positive quantity.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "So in some sense you you, you assume that the Gaussian processes is the log of the transcription factor.",
                    "label": 0
                },
                {
                    "sent": "Yeah, is exponential.",
                    "label": 0
                },
                {
                    "sent": "Yeah all this error bars is for the exponential formula.",
                    "label": 0
                },
                {
                    "sent": "Ghost.",
                    "label": 0
                },
                {
                    "sent": "Proposal distribution is symmetrical or you have to use it.",
                    "label": 0
                },
                {
                    "sent": "OK then.",
                    "label": 0
                },
                {
                    "sent": "The proposal for the control points is symmetrical, is just a Gaussian.",
                    "label": 0
                },
                {
                    "sent": "This is what you yeah it is.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I'm sending the control points.",
                    "label": 0
                },
                {
                    "sent": "And also the rest points the remaining points.",
                    "label": 0
                },
                {
                    "sent": "Yes, yeah.",
                    "label": 0
                },
                {
                    "sent": "Did something going.",
                    "label": 0
                },
                {
                    "sent": "I even just to the current points, just use those as a meeting on a GP.",
                    "label": 0
                },
                {
                    "sent": "Rather than using specific control points.",
                    "label": 0
                },
                {
                    "sent": "Can you repeat?",
                    "label": 0
                },
                {
                    "sent": "Love your current scription, factor profile that you sampled so your next proposal would just be centered on that particular one, so it's a bit of a Gaussian process with a mean of effort T. So.",
                    "label": 0
                },
                {
                    "sent": "Actually sampling.",
                    "label": 0
                },
                {
                    "sent": "Control points and then conditioning on those control points could be just conditional and your current functional realization.",
                    "label": 0
                },
                {
                    "sent": "But I'm not sure if we will be able to move a lot.",
                    "label": 0
                },
                {
                    "sent": "I mean 'cause.",
                    "label": 0
                },
                {
                    "sent": "I'm asking, yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I'm not.",
                    "label": 0
                },
                {
                    "sent": "This.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I mean.",
                    "label": 0
                },
                {
                    "sent": "Something control points and then condition.",
                    "label": 0
                },
                {
                    "sent": "Yeah, because with some sense you have the freedom.",
                    "label": 0
                },
                {
                    "sent": "Yeah, to move a lot becausw assume that this control points are independent.",
                    "label": 0
                },
                {
                    "sent": "So you want some sense you're saying to move, not not just be stacked, and you know the next next.",
                    "label": 0
                },
                {
                    "sent": "State assumptions to be very close to the previous round because you might be able to get a very high acceptance rate, but if you don't explore if your tenant does not explore the space efficiently, then.",
                    "label": 0
                },
                {
                    "sent": "So that probably I didn't understand exactly actually what your point actually.",
                    "label": 0
                },
                {
                    "sent": "Square doesn't use this control point strategy sampling strategy.",
                    "label": 0
                },
                {
                    "sent": "So you just use the functional, yeah?",
                    "label": 0
                },
                {
                    "sent": "It goes in process proposal distribution.",
                    "label": 0
                },
                {
                    "sent": "So I don't know actually.",
                    "label": 0
                },
                {
                    "sent": "Yeah, it would be this.",
                    "label": 0
                },
                {
                    "sent": "Actually this is I haven't, yeah.",
                    "label": 0
                },
                {
                    "sent": "So now this actually works.",
                    "label": 0
                },
                {
                    "sent": "Suppresses against presence in log space effectively.",
                    "label": 0
                },
                {
                    "sent": "The fact is that effectively you've got small variations in log space to make traumatic differences in real space.",
                    "label": 0
                },
                {
                    "sent": "Is this the cause of your massive error bars?",
                    "label": 0
                },
                {
                    "sent": "I mean, we've got very large error bars in Sioux City.",
                    "label": 0
                },
                {
                    "sent": "That's because basically got this gas and distribution, and probably.",
                    "label": 0
                },
                {
                    "sent": "Yeah, suppose so yeah, I mean.",
                    "label": 0
                },
                {
                    "sent": "I guess, yeah, that's also there are symmetric thereabouts, obviously because because also you measured everybody in the exponent of the.",
                    "label": 0
                },
                {
                    "sent": "Go soon.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Thanks very much.",
                    "label": 0
                }
            ]
        }
    }
}