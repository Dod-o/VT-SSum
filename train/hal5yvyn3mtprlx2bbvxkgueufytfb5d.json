{
    "id": "hal5yvyn3mtprlx2bbvxkgueufytfb5d",
    "title": "SmartMiner: A New Framework for Mining Large Scale Web Usage Data",
    "info": {
        "author": [
            "Murat Ali Bayir, Department of Computer Science and Engineering, University at Buffalo",
            "Ismail Hakki Toroslu, Department of Computer Engineering, Middle East Technical University",
            "Ahmet Cosar, Department of Computer Engineering, Middle East Technical University",
            "Guven Fidan, Agmlab Information Technologies"
        ],
        "published": "May 20, 2009",
        "recorded": "April 2009",
        "category": [
            "Top->Computer Science->Web Mining"
        ]
    },
    "url": "http://videolectures.net/www09_alibayir_sm/",
    "segmentation": [
        [
            "Will be presented by Moore ET al.",
            "Bashir.",
            "Which is a PhD student at University at Buffalo?",
            "And the talk is smart miner, a new framework for mining large scale web usage data.",
            "Thank you very much and welcome to everybody.",
            "And I'm a PhD student from first at Buffalo, distal joint work for with three other authors.",
            "I just heard from Middle East Technical University and you aren't done from Turkish Software Development Company."
        ],
        [
            "Here is the outline of my presentation.",
            "First, I will discuss our motivation and contribution of this work.",
            "Then I passed as smart binder framework Ann and they explained station construction problem and pattern discovery.",
            "Then I'll discuss distributed implementation of Smart Miner framework and I will give experimental results.",
            "And finally I will illustrate the benefits of our framework in terms of decision Support System application."
        ],
        [
            "So why we design the smart miner becausw mining today?",
            "Please lock is an important process for commercial websites, improve their structure and semantic way and website is to improve their website structural an semantically and due to the security reasons and change in the internal structure of the websites, some site owners want to keep their own data and they want to process their data themselves offline and in that case installation code based systems.",
            "Are not attractive for that and actually got some records for this type of records from the biggest company from the Turkey.",
            "So for the websites which large visitor population an this problem also should be handled and distributed Lee.",
            "In order to handle large size of incoming clickthrough data, also, the site owners want to execute a complex filters intelligent filters over the web users data to analyze different navigation behaviors.",
            "So in order to solve these problems, address about the proposed smart miner framework."
        ],
        [
            "This is our contributions.",
            "We implemented scalable framework, an modeled session construction problem as any graph problem and proposed a new algorithm to solve session construction problem and he proposed an efficient solution for pattern discovery by using topological constraints and we proposed vape user model for simulation purposes and we actually give the simulation of the web user.",
            "That user model and we give simulation framework to produce synthetic data and we also implemented MapReduce version of session construction pattern discovery processes and we show scalable to a framework or very large data and then we illustrate or benefits of our framework on division Support System application."
        ],
        [
            "I."
        ],
        [
            "I want to start with general overview of smart miner framework.",
            "Generally, we have a three main process in our framework.",
            "There station construction, pattern discovery and personalism post processing.",
            "In their session construction.",
            "Early this this process takes.",
            "Three data, three data sources, but the server logs are the main data source.",
            "It's contains basic information about web usage and and in the very basic form at the server logs contain URL of access page, IP of the web user, and time.",
            "The semantic data, insight, apologies, optional semantic data may contain some semantic information about web pages or some or website and site topologies given indicates where.",
            "The administrator disabled before field or some using some old of work forms which don't have re ferd information and after we obtain the web user stations we apply the pattern Discovery in order to find the frequent pattern.",
            "They are also semantic.",
            "They may be also semantically rich and stand by using by applying patterns on post processing techniques on this frequent patterns be obtaining interested knowledge about the website."
        ],
        [
            "How I want to start with this station construction problem.",
            "This is the most important phase of papers in mind, because later phases significantly depend of the sessions.",
            "This is generated by session construction process.",
            "So general definition of session and literature is that it's a sequence of web page requests on particular web domain for a specific time period there are two traditional approaches proposed for station construction problem.",
            "These are proposed by Cooley Suas Tower and still posts.",
            "Pull up all those bugs and these apples are mainly categorized divided into two categories.",
            "That time orients the approach and navigation oriented approach."
        ],
        [
            "Time oriented approach does not consider the linking formation.",
            "Two types of timer runs.",
            "Their post exists in the first one they limited duration of the total session and the time difference between the first page and the last page of the session is different than a given threshold.",
            "In the second one they restrict page state, time, page state.",
            "I'm on a single page.",
            "The additional enterprise consider linking formation and basically when adding a new page to session they checked the last page of the session.",
            "If there for example violating to PM plus one if the last page piano has linked towards Japan Post fun or it is the referral PM plus monetized at the end of the session, and if not the back put browser moments until the page PK is added.",
            "That the case that yeah nearest page to the PN plus one that refers to PSPN plus one.",
            "If no such PK exist, NPM plus one becomes the first page of the new session."
        ],
        [
            "So what are the drawbacks are of these model timer oriented approach has no link in formation so linking formation can be very important for station construction process because it gives some information about semantic relation between web pages and it gives me information about by using the link we can construct web user paths and then these paths.",
            "Can you also in formation about semantics of the website also backward movements are the major problems of navigation oriented approach because the recent studies in human computer.",
            "Scenario shows that that measures of the backward movements are accurate due to the location of page rather than its content.",
            "Also, they may cause a problem in some applications like recommender systems or webpage prefacing.",
            "Since these systems are depends on the I'm predicting the next records from server side.",
            "So we in order to solve this problem, we propose a new session model called Blink based Station model."
        ],
        [
            "In a link based session model, in each section contains a set of navigation sequences.",
            "For example in this case, if S is a link based session, it can.",
            "It may contain an navigation seconds on each navigation circles as X should satisfy the following rules in their timestamp rule that for each consecutive page where the former one should be accessed before the letter one.",
            "Also the page state, time and station duration, time, criterias of time oriented approaches should be satisfied.",
            "In topology rule that each there existed link that there must be a link between two consecutive pages or the formal one should should be refer of the later on if the referrer information exists, and in the maximality rule that for any navigation cycles in the session, there must be no other navigation cycles which the former one.",
            "Is there sub signals.",
            "Here the subsequence relation is similar to substring relation."
        ],
        [
            "So we propose a smart SRA algorithm to produce link based session from the users locks and smart Assery has mainly two phases and phase one.",
            "It construct candidate sessions.",
            "That's all based page, date, time and station duration, time criteria.",
            "In the second phase the candidate stations are partitioned into a maximal navigation sequences satisfying to properties of lead based session model.",
            "So these navigation sequences can.",
            "Overlap, but there should be a maximum.",
            "For example, for the given to Persian for the candidate session started from P1 to P23 and two navigation statements are generated.",
            "Their color does with orange and red as you see, these paths are overlap, but their pets on the web wrap and they are not maximal and they are not a substring of the each other."
        ],
        [
            "So let's come to a complexity part of this algorithm that in the search engine like behavior than the search engine like sessions.",
            "If the if this candidate session contest more than one topology more than one sets given in topological order.",
            "And of course providing that each set or at least one of them has more than one element and the number of seconds is can be exponential.",
            "And this problem is actually can be reduced to.",
            "Cycle elimination problem, but in the normal users.",
            "And usually not in search engine search engine like.",
            "We usually use website in depth that first manage and actually."
        ],
        [
            "Order of general chase.",
            "We found that the complexity is polynomial in terms of length of the sessions annels or to play in the candidate station.",
            "So this proof comes from the.",
            "Structure for algorithm.",
            "So in our algorithm, in the second phase be at each iteration be subtracted web pages from the session that doesn't have a referrer coming before them.",
            "So by assuming the random link distribution in the session you're in the given Candace session.",
            "We generate an expectation function which keeps the number of web pages at each step that is subtracted from session.",
            "So for the alterations.",
            "Where this some convergence of power series and comes quadratic constant Ann and we show that complexity is the polynomial actually in the real life they ought to praise the articular webpage in Candace station, not in the whole laptop was so this complexity is very small and we process very huge amount of data very efficiently as we will show in experimentals or section."
        ],
        [
            "Now I came to a pattern discovery part and for pattern discovery we used sequential version of April, April about some different constraints on the search space to eliminate the chance this session.",
            "So each pattern at the end that we obtain after the approval process should satisfy the topological topological constraints.",
            "Also, during core support, check this string matching constraint should be satisfied for a given pattern and given a session in order to be a support relation between them, there should be string matching relation also during the recalculation of support we also calculate the pattern specific attributes of the page in the in the corresponding."
        ],
        [
            "This is the general overview of the situation after algorithm or input.",
            "Is the sessions constructed by smart essay and then we have minimum support.",
            "So for each iteration be joined on the pattern Lattice be joined, the lancay patterns with length one patterns.",
            "Of course by looking at opposing constraints, the last page of blank a pattern should refer to length and pattern.",
            "And then for the candidate pattern like a plus one, we look at support and if it is a frequent above the threshold and it's reported as a frequent pattern.",
            "If it's not, it's intricate and is not propagated to later iterations."
        ],
        [
            "We have also implemented distributed version of our framework.",
            "Basically distributed version of Smart Miner, smart essay algorithm and pattern Discovery we have used may produce an padding over the 100 computers.",
            "So in map reduce the large computations are presented by a SEC of MapReduce operations an in order to employ the map, reduce the data should be stored in the format of key value pairs."
        ],
        [
            "And this is the basic overview of our MapReduce implementation in station construction part.",
            "We read the users data and basically we create an UK which contains the domain of the URL and IP then bye bye creating these new KV provide sent this data.",
            "We provide the sent data access record belonging belongs to same host an same IP to the same machine on the radius reports.",
            "Under Register site Reducer collects all the Access Records belong to same IP on same domain.",
            "Then be applied Smarthistory algorithm there a pattern discovery has two parts and the.",
            "Yeah, more costly process in the 1st place we in India we have two jobs and the mapper phase of the first job we distribute the navigation sequences by using random hash function to the with respect to number of idle machines and then for each machine and the reducer part the calculated breaking.",
            "So of the candidate patterns die in the second job also.",
            "Metro phase of second job.",
            "We get the candidate pattern and frequency.",
            "They are emitted an that reducer of the second job.",
            "Yet the Allfrey Kingston values for the candidate pattern.",
            "Because can they pattern is the key than be calculated frequency and and convert to fractions in the support and the reducer of the second job."
        ],
        [
            "How I came to experimental results.",
            "Part we have two main experiments by the acoustic experiments, an high performance computing experiments.",
            "In the accuracy experiments we measure the correlation between the patterns generated by sessions of the heuristics with the persons generated from or evaluation framework which are linked based sessions.",
            "So basically we accept the link based session model, real link base stations.",
            "Is that gold standard?",
            "So be we measure the similarity of the.",
            "Patterns generated by sessions of the Heuristic Smitty's real patterns.",
            "Link based patterns produced by the framework.",
            "Also, these experiments analyzed the effect of navigation behavior on sessions and then the measure how the backward movements and discarding Ninja formation affects the performance of navigation oriented theorists.",
            "Anti my runs their approaches and we have an experiment on both simulated data and real data and on.",
            "High Performance computing section.",
            "We have experiments on real."
        ],
        [
            "Later.",
            "Bob, this is our agents to me that is actually based on the five or six using model in the literature.",
            "Basically it's we used.",
            "Random random user model in the page rank algorithm.",
            "So be basically generate for user behavior this session termination behavior link from previous page to the next page behavior and link from current page behavior and the NIV initial page behavior.",
            "So in the new initial page barrier than it's.",
            "It means that I mean the current navigation service corresponds to behavior that the current navigation sequence of the user finished, but the user does not finish its interaction with the current website.",
            "It's brittle, right?",
            "Some knew URL to address bar or causing URL from maybe from search engine or other external resources in the current website, but that URL is not corresponds to previous related to previous whereas.",
            "That is accessed by the same user.",
            "The details of the agent simulator, I mean existing in given also in the paper."
        ],
        [
            "This is our evaluation framework, the agent simulator jurist synthetic data and correct link based sessions.",
            "These correct sessions generated with respect to refering formation and also been older client side of the user.",
            "We know that all actions of user on the client side.",
            "The server logs also generated by Agent Simulator.",
            "This is the yeah lowest information.",
            "This is the worst case in formation scenario in which no riford in formation.",
            "Then we apply station construction methods and then generate patterns and we also generate the correct patterns from the correct sessions that we know all information about the client at the face and then we evaluate their similarity and we get the results."
        ],
        [
            "So for evaluation of the similarity we use geometric mean of the previous in any collection is similar to F test.",
            "So the recall is calculated in terms of the number of patterns matched with heuristics patterns on real patterns over the patterns generated over the number of patterns of the agent simulator, which is the correct patterns.",
            "Producing is the number of patterns matched over the number of patterns of heuristics."
        ],
        [
            "Now of for the for first experiment, and we measure the effect of the navigation behavior of web user on the is accuracy and also on the on the first drop on the X axis you saw an IPO STP.",
            "This is the IP address that is the probability of name, initial page, probability over session termination page product India human competition.",
            "Human interaction an Indian woman.",
            "Competent computing interaction area.",
            "These behaviors are analyzed together.",
            "You know that the damping factor in their page rank and program.",
            "It says that 85% of users clicked knew page from the current page, but the remaining 15% of users stop session and stop the current session and Start request a new page from other website on the web graph but.",
            "The in there.",
            "Random user model in the page like the yeah But there is no backward movement.",
            "So be at that behaviors also at the name initial page here and then look at the ratio to cover the big probability range.",
            "2 to analyze the different user behaviors.",
            "And from this experiment we obtained that the patterns of smart Sr is 30 persons similar to the real patterns of the agent simulator.",
            "You can also think that this is the similarity of the.",
            "Link based session model and the patterns generated by the previous heuristic is around 2:30 percentage."
        ],
        [
            "We are also making experiments on the rail website.",
            "Small size real website.",
            "We replaced Agent Simulator Beta client Action tracker program than this program.",
            "Track all the actions of Web user on the client side or backward movements.",
            "Open knew links and other all of the actions.",
            "Then we use that looks to generate the real link based sessions and also to generate a very very low level data.",
            "Used usage log data.",
            "Contains only URL and IP and time time of access page and also speed with topology and on the errors also patterns generated by smart essays.",
            "Smart Miner Framework is third 5 persons is similar to real patterns.",
            "We have also divided this real data into two parts and then we in the first part training part.",
            "We apply all algorithms, previous approaches, Honore Prasanta, get frequent user patterns for the second part by using these frequent patterns, obtaining on the test data we construct hidden Markov model and on the test.",
            "On the test side, we use these hidden Markov models to predict the next page from the server, and on this experiment or frameworks at least 25% is better than the other approaches.",
            "Wichita, which shows that then or system is also a useful for especially predicting server side.",
            "Predicted the prediction of a next page from server side."
        ],
        [
            "And this is the OR experimental results related to distributed implementation.",
            "We have used a jam last data customers of Asia map including to biggest telephone service operator of Turkey having more than 35 million subscriber and a website is visited more than two 100K web user and then there are also other customers but the but in the second experiment you see 10 terabyte be copied data.",
            "Of we make a 50 copy of this 100 gigabyte data.",
            "But since this isn't the main purpose of this experiment to evaluate performance, or it doesn't matter to use other others.",
            "Other data sources are Trojans at Regina's data, so in the first experiment we measured impact of the number of nodes on the performance and the first point here you see is evaluated by is the point that gives the runtime for the real experiment.",
            "Tan line is separated to after the first point.",
            "The theoretical line in the theoretical line.",
            "Other points are calculated by using the.",
            "Experiment result between US and the number of nodes.",
            "I mean, if the number of us are doubled, the runtime is divided to an in the real.",
            "Yeah, real line is the real experimental result that we get.",
            "The second experiments also is the same be measured impact of the input size.",
            "It's 50 notes and then we see that our system is scalable and it is show similar behavior to the theoretical line."
        ],
        [
            "Now I came to this."
        ],
        [
            "Support system application to illustrate the benefits of our framework for the decision support system, we define a filter language or frequent patterns that includes these five primitives.",
            "For example, in the first primitive it says that the pattern match any or number of the given regular expressions are.",
            "These primitives are executed over the frequent patterns.",
            "If they match, Devil is true.",
            "Then it means that that frequent pattern pass that.",
            "Primitive, so a filter is defined as a collection of primitive that contains a nested structure which ends or or operations and.",
            "Then these filters are executed or the frequent patterns by using the map at this job and for each filter assets of the patterns that our list each filter through is listed as the result of the map reduce job."
        ],
        [
            "So by using our filter definition language, one can design A filter that aligns the useful things about their websites, such as navigation behavior of web users provided via external traffic, trouton advertisement, navigation behavior, web user after visiting, given a fixed page, next bench and common errors, pets at least a common errors, and that base that are less important in popular patterns in terms of elapsed time."
        ],
        [
            "I came to the end of my presentation and thank you for listening.",
            "If you have questions I can answer.",
            "Any question or comment?",
            "I haven't shared a question in one of the starting slides you were mentioning ontology.",
            "Yes, how is that incorporated ontologies incorporated by?",
            "For example, to generate semantic frequent patterns in the patterns based on web pages.",
            "For example, contains.",
            "Idea of or the name of the US as an item in the person prays.",
            "MBA pattern can contain a three page P1P2P3 but in the semantic pattern for example the the feed the system with semantic information of the web pages for the page P1 and P2 may be related to cars, for example P3 related to another vehicle plane.",
            "So the pets can be converted to current plan.",
            "These two items.",
            "So then we can.",
            "I use this semantic information to obtain semantic patterns too.",
            "And I say, yeah, navigation behavioral therapies in terms of semantics, how the semantic concepts are correlated with each other in the in that website.",
            "So is it classifying webpage based on topic?",
            "Is that what you mean?",
            "Yeah, but the information is fitted, the classifier is outside the framework that's fitted to system.",
            "It based on the ontology.",
            "Thank you, anything else.",
            "OK, let's thank the speaker again again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Will be presented by Moore ET al.",
                    "label": 0
                },
                {
                    "sent": "Bashir.",
                    "label": 0
                },
                {
                    "sent": "Which is a PhD student at University at Buffalo?",
                    "label": 0
                },
                {
                    "sent": "And the talk is smart miner, a new framework for mining large scale web usage data.",
                    "label": 1
                },
                {
                    "sent": "Thank you very much and welcome to everybody.",
                    "label": 0
                },
                {
                    "sent": "And I'm a PhD student from first at Buffalo, distal joint work for with three other authors.",
                    "label": 0
                },
                {
                    "sent": "I just heard from Middle East Technical University and you aren't done from Turkish Software Development Company.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here is the outline of my presentation.",
                    "label": 0
                },
                {
                    "sent": "First, I will discuss our motivation and contribution of this work.",
                    "label": 0
                },
                {
                    "sent": "Then I passed as smart binder framework Ann and they explained station construction problem and pattern discovery.",
                    "label": 0
                },
                {
                    "sent": "Then I'll discuss distributed implementation of Smart Miner framework and I will give experimental results.",
                    "label": 1
                },
                {
                    "sent": "And finally I will illustrate the benefits of our framework in terms of decision Support System application.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So why we design the smart miner becausw mining today?",
                    "label": 1
                },
                {
                    "sent": "Please lock is an important process for commercial websites, improve their structure and semantic way and website is to improve their website structural an semantically and due to the security reasons and change in the internal structure of the websites, some site owners want to keep their own data and they want to process their data themselves offline and in that case installation code based systems.",
                    "label": 1
                },
                {
                    "sent": "Are not attractive for that and actually got some records for this type of records from the biggest company from the Turkey.",
                    "label": 1
                },
                {
                    "sent": "So for the websites which large visitor population an this problem also should be handled and distributed Lee.",
                    "label": 1
                },
                {
                    "sent": "In order to handle large size of incoming clickthrough data, also, the site owners want to execute a complex filters intelligent filters over the web users data to analyze different navigation behaviors.",
                    "label": 0
                },
                {
                    "sent": "So in order to solve these problems, address about the proposed smart miner framework.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is our contributions.",
                    "label": 0
                },
                {
                    "sent": "We implemented scalable framework, an modeled session construction problem as any graph problem and proposed a new algorithm to solve session construction problem and he proposed an efficient solution for pattern discovery by using topological constraints and we proposed vape user model for simulation purposes and we actually give the simulation of the web user.",
                    "label": 1
                },
                {
                    "sent": "That user model and we give simulation framework to produce synthetic data and we also implemented MapReduce version of session construction pattern discovery processes and we show scalable to a framework or very large data and then we illustrate or benefits of our framework on division Support System application.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I want to start with general overview of smart miner framework.",
                    "label": 1
                },
                {
                    "sent": "Generally, we have a three main process in our framework.",
                    "label": 0
                },
                {
                    "sent": "There station construction, pattern discovery and personalism post processing.",
                    "label": 1
                },
                {
                    "sent": "In their session construction.",
                    "label": 0
                },
                {
                    "sent": "Early this this process takes.",
                    "label": 0
                },
                {
                    "sent": "Three data, three data sources, but the server logs are the main data source.",
                    "label": 0
                },
                {
                    "sent": "It's contains basic information about web usage and and in the very basic form at the server logs contain URL of access page, IP of the web user, and time.",
                    "label": 0
                },
                {
                    "sent": "The semantic data, insight, apologies, optional semantic data may contain some semantic information about web pages or some or website and site topologies given indicates where.",
                    "label": 0
                },
                {
                    "sent": "The administrator disabled before field or some using some old of work forms which don't have re ferd information and after we obtain the web user stations we apply the pattern Discovery in order to find the frequent pattern.",
                    "label": 0
                },
                {
                    "sent": "They are also semantic.",
                    "label": 0
                },
                {
                    "sent": "They may be also semantically rich and stand by using by applying patterns on post processing techniques on this frequent patterns be obtaining interested knowledge about the website.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "How I want to start with this station construction problem.",
                    "label": 0
                },
                {
                    "sent": "This is the most important phase of papers in mind, because later phases significantly depend of the sessions.",
                    "label": 1
                },
                {
                    "sent": "This is generated by session construction process.",
                    "label": 0
                },
                {
                    "sent": "So general definition of session and literature is that it's a sequence of web page requests on particular web domain for a specific time period there are two traditional approaches proposed for station construction problem.",
                    "label": 1
                },
                {
                    "sent": "These are proposed by Cooley Suas Tower and still posts.",
                    "label": 0
                },
                {
                    "sent": "Pull up all those bugs and these apples are mainly categorized divided into two categories.",
                    "label": 0
                },
                {
                    "sent": "That time orients the approach and navigation oriented approach.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Time oriented approach does not consider the linking formation.",
                    "label": 1
                },
                {
                    "sent": "Two types of timer runs.",
                    "label": 1
                },
                {
                    "sent": "Their post exists in the first one they limited duration of the total session and the time difference between the first page and the last page of the session is different than a given threshold.",
                    "label": 0
                },
                {
                    "sent": "In the second one they restrict page state, time, page state.",
                    "label": 0
                },
                {
                    "sent": "I'm on a single page.",
                    "label": 1
                },
                {
                    "sent": "The additional enterprise consider linking formation and basically when adding a new page to session they checked the last page of the session.",
                    "label": 0
                },
                {
                    "sent": "If there for example violating to PM plus one if the last page piano has linked towards Japan Post fun or it is the referral PM plus monetized at the end of the session, and if not the back put browser moments until the page PK is added.",
                    "label": 0
                },
                {
                    "sent": "That the case that yeah nearest page to the PN plus one that refers to PSPN plus one.",
                    "label": 0
                },
                {
                    "sent": "If no such PK exist, NPM plus one becomes the first page of the new session.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what are the drawbacks are of these model timer oriented approach has no link in formation so linking formation can be very important for station construction process because it gives some information about semantic relation between web pages and it gives me information about by using the link we can construct web user paths and then these paths.",
                    "label": 0
                },
                {
                    "sent": "Can you also in formation about semantics of the website also backward movements are the major problems of navigation oriented approach because the recent studies in human computer.",
                    "label": 1
                },
                {
                    "sent": "Scenario shows that that measures of the backward movements are accurate due to the location of page rather than its content.",
                    "label": 0
                },
                {
                    "sent": "Also, they may cause a problem in some applications like recommender systems or webpage prefacing.",
                    "label": 0
                },
                {
                    "sent": "Since these systems are depends on the I'm predicting the next records from server side.",
                    "label": 1
                },
                {
                    "sent": "So we in order to solve this problem, we propose a new session model called Blink based Station model.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In a link based session model, in each section contains a set of navigation sequences.",
                    "label": 1
                },
                {
                    "sent": "For example in this case, if S is a link based session, it can.",
                    "label": 0
                },
                {
                    "sent": "It may contain an navigation seconds on each navigation circles as X should satisfy the following rules in their timestamp rule that for each consecutive page where the former one should be accessed before the letter one.",
                    "label": 0
                },
                {
                    "sent": "Also the page state, time and station duration, time, criterias of time oriented approaches should be satisfied.",
                    "label": 0
                },
                {
                    "sent": "In topology rule that each there existed link that there must be a link between two consecutive pages or the formal one should should be refer of the later on if the referrer information exists, and in the maximality rule that for any navigation cycles in the session, there must be no other navigation cycles which the former one.",
                    "label": 0
                },
                {
                    "sent": "Is there sub signals.",
                    "label": 1
                },
                {
                    "sent": "Here the subsequence relation is similar to substring relation.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we propose a smart SRA algorithm to produce link based session from the users locks and smart Assery has mainly two phases and phase one.",
                    "label": 0
                },
                {
                    "sent": "It construct candidate sessions.",
                    "label": 0
                },
                {
                    "sent": "That's all based page, date, time and station duration, time criteria.",
                    "label": 1
                },
                {
                    "sent": "In the second phase the candidate stations are partitioned into a maximal navigation sequences satisfying to properties of lead based session model.",
                    "label": 1
                },
                {
                    "sent": "So these navigation sequences can.",
                    "label": 0
                },
                {
                    "sent": "Overlap, but there should be a maximum.",
                    "label": 1
                },
                {
                    "sent": "For example, for the given to Persian for the candidate session started from P1 to P23 and two navigation statements are generated.",
                    "label": 0
                },
                {
                    "sent": "Their color does with orange and red as you see, these paths are overlap, but their pets on the web wrap and they are not maximal and they are not a substring of the each other.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's come to a complexity part of this algorithm that in the search engine like behavior than the search engine like sessions.",
                    "label": 1
                },
                {
                    "sent": "If the if this candidate session contest more than one topology more than one sets given in topological order.",
                    "label": 1
                },
                {
                    "sent": "And of course providing that each set or at least one of them has more than one element and the number of seconds is can be exponential.",
                    "label": 1
                },
                {
                    "sent": "And this problem is actually can be reduced to.",
                    "label": 0
                },
                {
                    "sent": "Cycle elimination problem, but in the normal users.",
                    "label": 0
                },
                {
                    "sent": "And usually not in search engine search engine like.",
                    "label": 0
                },
                {
                    "sent": "We usually use website in depth that first manage and actually.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Order of general chase.",
                    "label": 0
                },
                {
                    "sent": "We found that the complexity is polynomial in terms of length of the sessions annels or to play in the candidate station.",
                    "label": 1
                },
                {
                    "sent": "So this proof comes from the.",
                    "label": 0
                },
                {
                    "sent": "Structure for algorithm.",
                    "label": 0
                },
                {
                    "sent": "So in our algorithm, in the second phase be at each iteration be subtracted web pages from the session that doesn't have a referrer coming before them.",
                    "label": 1
                },
                {
                    "sent": "So by assuming the random link distribution in the session you're in the given Candace session.",
                    "label": 0
                },
                {
                    "sent": "We generate an expectation function which keeps the number of web pages at each step that is subtracted from session.",
                    "label": 1
                },
                {
                    "sent": "So for the alterations.",
                    "label": 0
                },
                {
                    "sent": "Where this some convergence of power series and comes quadratic constant Ann and we show that complexity is the polynomial actually in the real life they ought to praise the articular webpage in Candace station, not in the whole laptop was so this complexity is very small and we process very huge amount of data very efficiently as we will show in experimentals or section.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now I came to a pattern discovery part and for pattern discovery we used sequential version of April, April about some different constraints on the search space to eliminate the chance this session.",
                    "label": 1
                },
                {
                    "sent": "So each pattern at the end that we obtain after the approval process should satisfy the topological topological constraints.",
                    "label": 0
                },
                {
                    "sent": "Also, during core support, check this string matching constraint should be satisfied for a given pattern and given a session in order to be a support relation between them, there should be string matching relation also during the recalculation of support we also calculate the pattern specific attributes of the page in the in the corresponding.",
                    "label": 1
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is the general overview of the situation after algorithm or input.",
                    "label": 1
                },
                {
                    "sent": "Is the sessions constructed by smart essay and then we have minimum support.",
                    "label": 1
                },
                {
                    "sent": "So for each iteration be joined on the pattern Lattice be joined, the lancay patterns with length one patterns.",
                    "label": 0
                },
                {
                    "sent": "Of course by looking at opposing constraints, the last page of blank a pattern should refer to length and pattern.",
                    "label": 0
                },
                {
                    "sent": "And then for the candidate pattern like a plus one, we look at support and if it is a frequent above the threshold and it's reported as a frequent pattern.",
                    "label": 0
                },
                {
                    "sent": "If it's not, it's intricate and is not propagated to later iterations.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We have also implemented distributed version of our framework.",
                    "label": 0
                },
                {
                    "sent": "Basically distributed version of Smart Miner, smart essay algorithm and pattern Discovery we have used may produce an padding over the 100 computers.",
                    "label": 1
                },
                {
                    "sent": "So in map reduce the large computations are presented by a SEC of MapReduce operations an in order to employ the map, reduce the data should be stored in the format of key value pairs.",
                    "label": 1
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And this is the basic overview of our MapReduce implementation in station construction part.",
                    "label": 0
                },
                {
                    "sent": "We read the users data and basically we create an UK which contains the domain of the URL and IP then bye bye creating these new KV provide sent this data.",
                    "label": 0
                },
                {
                    "sent": "We provide the sent data access record belonging belongs to same host an same IP to the same machine on the radius reports.",
                    "label": 0
                },
                {
                    "sent": "Under Register site Reducer collects all the Access Records belong to same IP on same domain.",
                    "label": 1
                },
                {
                    "sent": "Then be applied Smarthistory algorithm there a pattern discovery has two parts and the.",
                    "label": 0
                },
                {
                    "sent": "Yeah, more costly process in the 1st place we in India we have two jobs and the mapper phase of the first job we distribute the navigation sequences by using random hash function to the with respect to number of idle machines and then for each machine and the reducer part the calculated breaking.",
                    "label": 1
                },
                {
                    "sent": "So of the candidate patterns die in the second job also.",
                    "label": 0
                },
                {
                    "sent": "Metro phase of second job.",
                    "label": 0
                },
                {
                    "sent": "We get the candidate pattern and frequency.",
                    "label": 0
                },
                {
                    "sent": "They are emitted an that reducer of the second job.",
                    "label": 0
                },
                {
                    "sent": "Yet the Allfrey Kingston values for the candidate pattern.",
                    "label": 0
                },
                {
                    "sent": "Because can they pattern is the key than be calculated frequency and and convert to fractions in the support and the reducer of the second job.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "How I came to experimental results.",
                    "label": 0
                },
                {
                    "sent": "Part we have two main experiments by the acoustic experiments, an high performance computing experiments.",
                    "label": 0
                },
                {
                    "sent": "In the accuracy experiments we measure the correlation between the patterns generated by sessions of the heuristics with the persons generated from or evaluation framework which are linked based sessions.",
                    "label": 1
                },
                {
                    "sent": "So basically we accept the link based session model, real link base stations.",
                    "label": 0
                },
                {
                    "sent": "Is that gold standard?",
                    "label": 0
                },
                {
                    "sent": "So be we measure the similarity of the.",
                    "label": 1
                },
                {
                    "sent": "Patterns generated by sessions of the Heuristic Smitty's real patterns.",
                    "label": 0
                },
                {
                    "sent": "Link based patterns produced by the framework.",
                    "label": 1
                },
                {
                    "sent": "Also, these experiments analyzed the effect of navigation behavior on sessions and then the measure how the backward movements and discarding Ninja formation affects the performance of navigation oriented theorists.",
                    "label": 0
                },
                {
                    "sent": "Anti my runs their approaches and we have an experiment on both simulated data and real data and on.",
                    "label": 0
                },
                {
                    "sent": "High Performance computing section.",
                    "label": 0
                },
                {
                    "sent": "We have experiments on real.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Later.",
                    "label": 0
                },
                {
                    "sent": "Bob, this is our agents to me that is actually based on the five or six using model in the literature.",
                    "label": 0
                },
                {
                    "sent": "Basically it's we used.",
                    "label": 0
                },
                {
                    "sent": "Random random user model in the page rank algorithm.",
                    "label": 0
                },
                {
                    "sent": "So be basically generate for user behavior this session termination behavior link from previous page to the next page behavior and link from current page behavior and the NIV initial page behavior.",
                    "label": 1
                },
                {
                    "sent": "So in the new initial page barrier than it's.",
                    "label": 0
                },
                {
                    "sent": "It means that I mean the current navigation service corresponds to behavior that the current navigation sequence of the user finished, but the user does not finish its interaction with the current website.",
                    "label": 0
                },
                {
                    "sent": "It's brittle, right?",
                    "label": 1
                },
                {
                    "sent": "Some knew URL to address bar or causing URL from maybe from search engine or other external resources in the current website, but that URL is not corresponds to previous related to previous whereas.",
                    "label": 0
                },
                {
                    "sent": "That is accessed by the same user.",
                    "label": 0
                },
                {
                    "sent": "The details of the agent simulator, I mean existing in given also in the paper.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is our evaluation framework, the agent simulator jurist synthetic data and correct link based sessions.",
                    "label": 1
                },
                {
                    "sent": "These correct sessions generated with respect to refering formation and also been older client side of the user.",
                    "label": 0
                },
                {
                    "sent": "We know that all actions of user on the client side.",
                    "label": 0
                },
                {
                    "sent": "The server logs also generated by Agent Simulator.",
                    "label": 1
                },
                {
                    "sent": "This is the yeah lowest information.",
                    "label": 1
                },
                {
                    "sent": "This is the worst case in formation scenario in which no riford in formation.",
                    "label": 0
                },
                {
                    "sent": "Then we apply station construction methods and then generate patterns and we also generate the correct patterns from the correct sessions that we know all information about the client at the face and then we evaluate their similarity and we get the results.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for evaluation of the similarity we use geometric mean of the previous in any collection is similar to F test.",
                    "label": 1
                },
                {
                    "sent": "So the recall is calculated in terms of the number of patterns matched with heuristics patterns on real patterns over the patterns generated over the number of patterns of the agent simulator, which is the correct patterns.",
                    "label": 1
                },
                {
                    "sent": "Producing is the number of patterns matched over the number of patterns of heuristics.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now of for the for first experiment, and we measure the effect of the navigation behavior of web user on the is accuracy and also on the on the first drop on the X axis you saw an IPO STP.",
                    "label": 1
                },
                {
                    "sent": "This is the IP address that is the probability of name, initial page, probability over session termination page product India human competition.",
                    "label": 0
                },
                {
                    "sent": "Human interaction an Indian woman.",
                    "label": 0
                },
                {
                    "sent": "Competent computing interaction area.",
                    "label": 0
                },
                {
                    "sent": "These behaviors are analyzed together.",
                    "label": 0
                },
                {
                    "sent": "You know that the damping factor in their page rank and program.",
                    "label": 0
                },
                {
                    "sent": "It says that 85% of users clicked knew page from the current page, but the remaining 15% of users stop session and stop the current session and Start request a new page from other website on the web graph but.",
                    "label": 0
                },
                {
                    "sent": "The in there.",
                    "label": 0
                },
                {
                    "sent": "Random user model in the page like the yeah But there is no backward movement.",
                    "label": 0
                },
                {
                    "sent": "So be at that behaviors also at the name initial page here and then look at the ratio to cover the big probability range.",
                    "label": 0
                },
                {
                    "sent": "2 to analyze the different user behaviors.",
                    "label": 0
                },
                {
                    "sent": "And from this experiment we obtained that the patterns of smart Sr is 30 persons similar to the real patterns of the agent simulator.",
                    "label": 1
                },
                {
                    "sent": "You can also think that this is the similarity of the.",
                    "label": 0
                },
                {
                    "sent": "Link based session model and the patterns generated by the previous heuristic is around 2:30 percentage.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We are also making experiments on the rail website.",
                    "label": 0
                },
                {
                    "sent": "Small size real website.",
                    "label": 0
                },
                {
                    "sent": "We replaced Agent Simulator Beta client Action tracker program than this program.",
                    "label": 1
                },
                {
                    "sent": "Track all the actions of Web user on the client side or backward movements.",
                    "label": 0
                },
                {
                    "sent": "Open knew links and other all of the actions.",
                    "label": 0
                },
                {
                    "sent": "Then we use that looks to generate the real link based sessions and also to generate a very very low level data.",
                    "label": 0
                },
                {
                    "sent": "Used usage log data.",
                    "label": 0
                },
                {
                    "sent": "Contains only URL and IP and time time of access page and also speed with topology and on the errors also patterns generated by smart essays.",
                    "label": 0
                },
                {
                    "sent": "Smart Miner Framework is third 5 persons is similar to real patterns.",
                    "label": 1
                },
                {
                    "sent": "We have also divided this real data into two parts and then we in the first part training part.",
                    "label": 1
                },
                {
                    "sent": "We apply all algorithms, previous approaches, Honore Prasanta, get frequent user patterns for the second part by using these frequent patterns, obtaining on the test data we construct hidden Markov model and on the test.",
                    "label": 1
                },
                {
                    "sent": "On the test side, we use these hidden Markov models to predict the next page from the server, and on this experiment or frameworks at least 25% is better than the other approaches.",
                    "label": 0
                },
                {
                    "sent": "Wichita, which shows that then or system is also a useful for especially predicting server side.",
                    "label": 0
                },
                {
                    "sent": "Predicted the prediction of a next page from server side.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And this is the OR experimental results related to distributed implementation.",
                    "label": 1
                },
                {
                    "sent": "We have used a jam last data customers of Asia map including to biggest telephone service operator of Turkey having more than 35 million subscriber and a website is visited more than two 100K web user and then there are also other customers but the but in the second experiment you see 10 terabyte be copied data.",
                    "label": 1
                },
                {
                    "sent": "Of we make a 50 copy of this 100 gigabyte data.",
                    "label": 0
                },
                {
                    "sent": "But since this isn't the main purpose of this experiment to evaluate performance, or it doesn't matter to use other others.",
                    "label": 0
                },
                {
                    "sent": "Other data sources are Trojans at Regina's data, so in the first experiment we measured impact of the number of nodes on the performance and the first point here you see is evaluated by is the point that gives the runtime for the real experiment.",
                    "label": 0
                },
                {
                    "sent": "Tan line is separated to after the first point.",
                    "label": 0
                },
                {
                    "sent": "The theoretical line in the theoretical line.",
                    "label": 0
                },
                {
                    "sent": "Other points are calculated by using the.",
                    "label": 0
                },
                {
                    "sent": "Experiment result between US and the number of nodes.",
                    "label": 0
                },
                {
                    "sent": "I mean, if the number of us are doubled, the runtime is divided to an in the real.",
                    "label": 0
                },
                {
                    "sent": "Yeah, real line is the real experimental result that we get.",
                    "label": 0
                },
                {
                    "sent": "The second experiments also is the same be measured impact of the input size.",
                    "label": 0
                },
                {
                    "sent": "It's 50 notes and then we see that our system is scalable and it is show similar behavior to the theoretical line.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now I came to this.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Support system application to illustrate the benefits of our framework for the decision support system, we define a filter language or frequent patterns that includes these five primitives.",
                    "label": 1
                },
                {
                    "sent": "For example, in the first primitive it says that the pattern match any or number of the given regular expressions are.",
                    "label": 0
                },
                {
                    "sent": "These primitives are executed over the frequent patterns.",
                    "label": 0
                },
                {
                    "sent": "If they match, Devil is true.",
                    "label": 0
                },
                {
                    "sent": "Then it means that that frequent pattern pass that.",
                    "label": 1
                },
                {
                    "sent": "Primitive, so a filter is defined as a collection of primitive that contains a nested structure which ends or or operations and.",
                    "label": 1
                },
                {
                    "sent": "Then these filters are executed or the frequent patterns by using the map at this job and for each filter assets of the patterns that our list each filter through is listed as the result of the map reduce job.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So by using our filter definition language, one can design A filter that aligns the useful things about their websites, such as navigation behavior of web users provided via external traffic, trouton advertisement, navigation behavior, web user after visiting, given a fixed page, next bench and common errors, pets at least a common errors, and that base that are less important in popular patterns in terms of elapsed time.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I came to the end of my presentation and thank you for listening.",
                    "label": 0
                },
                {
                    "sent": "If you have questions I can answer.",
                    "label": 0
                },
                {
                    "sent": "Any question or comment?",
                    "label": 0
                },
                {
                    "sent": "I haven't shared a question in one of the starting slides you were mentioning ontology.",
                    "label": 0
                },
                {
                    "sent": "Yes, how is that incorporated ontologies incorporated by?",
                    "label": 0
                },
                {
                    "sent": "For example, to generate semantic frequent patterns in the patterns based on web pages.",
                    "label": 0
                },
                {
                    "sent": "For example, contains.",
                    "label": 0
                },
                {
                    "sent": "Idea of or the name of the US as an item in the person prays.",
                    "label": 0
                },
                {
                    "sent": "MBA pattern can contain a three page P1P2P3 but in the semantic pattern for example the the feed the system with semantic information of the web pages for the page P1 and P2 may be related to cars, for example P3 related to another vehicle plane.",
                    "label": 0
                },
                {
                    "sent": "So the pets can be converted to current plan.",
                    "label": 0
                },
                {
                    "sent": "These two items.",
                    "label": 0
                },
                {
                    "sent": "So then we can.",
                    "label": 0
                },
                {
                    "sent": "I use this semantic information to obtain semantic patterns too.",
                    "label": 0
                },
                {
                    "sent": "And I say, yeah, navigation behavioral therapies in terms of semantics, how the semantic concepts are correlated with each other in the in that website.",
                    "label": 0
                },
                {
                    "sent": "So is it classifying webpage based on topic?",
                    "label": 0
                },
                {
                    "sent": "Is that what you mean?",
                    "label": 0
                },
                {
                    "sent": "Yeah, but the information is fitted, the classifier is outside the framework that's fitted to system.",
                    "label": 0
                },
                {
                    "sent": "It based on the ontology.",
                    "label": 0
                },
                {
                    "sent": "Thank you, anything else.",
                    "label": 0
                },
                {
                    "sent": "OK, let's thank the speaker again again.",
                    "label": 0
                }
            ]
        }
    }
}