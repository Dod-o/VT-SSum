{
    "id": "laqdqpbh64rbpecoppafspv3hoci3prx",
    "title": "Statistical Knowledge Patterns: Identifying Synonymous Relations in Large Linked Datasets",
    "info": {
        "author": [
            "Anna Lisa Gentile, Department of Computer Science, University of Sheffield"
        ],
        "published": "Nov. 28, 2013",
        "recorded": "October 2013",
        "category": [
            "Top->Computer Science->Databases",
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/iswc2013_gentile_linked_datasets/",
    "segmentation": [
        [
            "Hi everybody, I'm Melissa Ann.",
            "This is so this work is together with my colleagues from University of Sheffield and also collaboration with a blank feast from University of Illinois Shipping.",
            "Anne."
        ],
        [
            "So the idea?",
            "The problem that we're tackling in this work is the eternity in the vocabulary.",
            "So when you want to access data, won't want to query link data, you have two problems.",
            "What if you don't know the vocabulary?",
            "And even if you know the vocabulary, if you know how a concept, what's the name of the concept?",
            "What if you don't know all the available properties there?"
        ],
        [
            "So as an example, I want to retrieve titles for film so I know that the concept I'm looking for is DVD Ontology film and I know that I'll have to look for property name on DVD property name and I get a bunch of results.",
            "I get a bunch of titles, but."
        ],
        [
            "If I also know that I can query fourth name to get the titles, maybe I can get some more results.",
            "I probably get the same.",
            "I can get some more, I don't know.",
            "So the idea behind behind this work is to actually is to actually give the user such information."
        ],
        [
            "The most related work to us to this, this one as one on the encyclopedic knowledge pattern.",
            "The idea behind EP is that the KP is a small piece of ontology which represents a single concept and describes all the possible relation of the concept with other with other concepts.",
            "The drawback with the KP is that they cannot be because they've been designed for visualization purpose purposes.",
            "They cannot be directly used to query data to query link data."
        ],
        [
            "So what we propose here is to generate statistical knowledge patterns.",
            "This pattern are again pieces of ontology about a specific concept, so each."
        ],
        [
            "Things in, in this case, for example, the concept is language and they encapsulates all the property.",
            "The relevant properties for that for that concept."
        ],
        [
            "What we also do is we group so we cluster together properties with have the same meaning.",
            "So in this case for example for language we have that fourth name, property name, an property language expressed the same, the same meaning.",
            "What we also in the way we cluster them is that we add askos close match relation between the properties in the in the piece of India.",
            "Escaping the other thing that we save in the escapee is the range of this property or cluster of properties."
        ],
        [
            "How do we decide that two properties are synonymous, so we start again from a concept language and we retrieve all possible instances for that concept of our language.",
            "For example, we have English language, Chinese language, Italian language and so on.",
            "For each of these instances is instances, we go on the link data and we receive all possible triples that have these instances as a subject."
        ],
        [
            "What do we do then?",
            "We define a similarity measure that.",
            "That is based on the actual usage of data and this similarity measures to decide if a pair of properties are actually synonymous or not, and this similarity measure has three components.",
            "The one, the first one is the triple overlap.",
            "Then we have the subject agreement and Cardinal iteration.",
            "The triple overlap.",
            "The idea is very simple.",
            "We have two properties, P1 MP two and we check subject how many subjects and objects are the same in sets of triples retrieved by those two properties?"
        ],
        [
            "The subject agreement, so again we have two properties, P1 and P2.",
            "We get all triples that have P1 or P2 as a relationship, and what we check is if is that every time we have the same subject, how many times we have at least this one object, which is the same.",
            "So we don't.",
            "We don't really care if all the objects are the same, but at least if there is one in the two sets, which is the same.",
            "And then."
        ],
        [
            "The last one is the cardinality Russia, so we basically check if the two properties of the same cardinality, so it's one property, one to one and the other one want one, and so on.",
            "So we have a measure for this for this value."
        ],
        [
            "So after we collect all the similarities between pair of so it's a pairwise comparison for all the properties in the concept.",
            "Once we have all these values, what we do is we cluster property property.",
            "Together we use analytic agglomerative clustering algorithm not giving detail.",
            "But if you want further detail on this particular on the particular clustering you can refer to the keys on paper."
        ],
        [
            "So again, just to recap, we start from we start from.",
            "Each escapee is about a single is context specific, and it's about a single concept we receive all the data and based on the data we collect information.",
            "So we store in this escapee all properties which are relevant to the concept.",
            "We are selective in the properties that we add because we have some cut off to decide which properties are relevant are.",
            "Characteristic of the concept in which one or not."
        ],
        [
            "We tried to three different ways, so it's it's basically we define a threshold to decide if we have threshold to decide if a property goes in the escapee or doesn't go in the escapee.",
            "We tried three different ways.",
            "One is, we check the absolute value, so we check for each property how many triples are there in the linked data using that property.",
            "So we define different absolute thresholds 1020 and so on.",
            "The other one is fractional, so we have as a threshold the average.",
            "So.",
            "The coverage of that property.",
            "So given given a concept again language, we take the property and we say how many given all the triples talking about language, how many of those are using that property and last one is a normalized normalized value.",
            "So instead of considering considering all the triples about the concept, we do it's property specific.",
            "So we calculate the average of triples for each property and then the threshold.",
            "Is is based on the average of of single properties."
        ],
        [
            "We have two evaluation, so first of all we want to know what is the descriptive power of escaping.",
            "So how much data can I access?",
            "So instead of using all the properties for concept, how much data can I access if I only use the one in the escaping and this is the first first experiment, the second experiment is an in vivo experiment, so we do a query query expansion task and we use information in the escaped to do query expansion.",
            "What we want to check is what?",
            "How can we improve the retrieval coverage.",
            "So how many more triples can we?",
            "Retrieve, given that we're using synonymous properties with respect to the fact of using a single properties to access the data, so to go back to the first experiment to the first example.",
            "Sorry if I use just property name or if I use also fourth name, how many more triples do I get?",
            "And also we check is are those triples that I get more correct or not?"
        ],
        [
            "OK, As for the first one.",
            "We use, so I said we have different thresholds.",
            "The one that performs better performance is the normalized one and the reason experiments showing the zanis by Eva blogs missed.",
            "It was at the workshop."
        ],
        [
            "So then the experiment shows that by dropping like by only using 20 on average, 27% of properties of a concept we can actually access 94% of the underlying triples."
        ],
        [
            "So basically, we're not including in the escapee 72% of properties that are out there."
        ],
        [
            "The second experiment is about as I said, the query expansion.",
            "So what do we check?",
            "We have we get all the pair of properties for a concept and we do two queries, one using just properties from a what we define as a reference ontology suffered.",
            "In this case we use DPD ontologies as reference ontology and then we do another query by using all synonymous property from the escapee for that particular property.",
            "What do we want to check is how much?",
            "How many more triples do we have, and are those triples that we get more correct?"
        ],
        [
            "The way that we track correctness for for the triples is by.",
            "We do a manual evaluation, so we ask for annotation annotator.",
            "We give them all the pair of properties and we ask them is despair Express.",
            "Are these two properties synonymous?",
            "Yes or no.",
            "Every time the annotator says they are synonymous, we consider all the data retrieved by the synonymous property correct?",
            "If they say the two properties are not synonymous, we consider the data as wrong."
        ],
        [
            "He says about interactive Internet user agreements and threshold that we use are all in the paper.",
            "So in this in this graph, well, they actually two overlapping graph, so the first one is you can follow them the sorry the black dots.",
            "Black dots indicates the similarity score between properties.",
            "I should say before that on the X axis we have old old old pair of all pair of properties, so the black dots indicates the similarity score between those two pairs an we ordered them decreasingly so on decreasing value of similarity score, the overlapping graph is the one with the green and red dots indicates how much more data do I get?",
            "For that specific pair of property.",
            "So as you can see.",
            "At the beginning we then so the dot is either green or red.",
            "It's green if the data is correct.",
            "So if the minor rotator say the specific synonymity is correct and it's red if it's been marked as incorrect.",
            "So as you can see with high similarity score, the majority of expansion are correct and sometimes we get big expansion.",
            "So by by using sometimes you can.",
            "We can have like 25 more data by adding this in the synonymous property.",
            "As the similarity score goes down, we start having noise so you can see more red dots at the end.",
            "At the end of the graph.",
            "So when the similarity score is low.",
            "Introducing the using the synonym synonymous property will introduce will give you more noise in the data."
        ],
        [
            "So to conclude, the recap, what's so escapee is a small piece of ontology which is about a single concept, a concept, an encapsulate all important information about this concept concept.",
            "It is context dependent.",
            "So if I have two properties which are synonyms synonymous in one concept, they may not be synonymous in another one.",
            "The process of generating escapes completely automatic, and although all the examples that I use up from DB pedia is very general, so you can use whatever vocabulary you want.",
            "And is general across datasets.",
            "Yes, maybe we generated them offline.",
            "You can generate them offline and then you can and this increase efficiency at the runtime.",
            "And, well, in this particular case, we proved that there are there beneficial for query expansion.",
            "Thank you, have any question.",
            "Happy to take it."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi everybody, I'm Melissa Ann.",
                    "label": 0
                },
                {
                    "sent": "This is so this work is together with my colleagues from University of Sheffield and also collaboration with a blank feast from University of Illinois Shipping.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the idea?",
                    "label": 0
                },
                {
                    "sent": "The problem that we're tackling in this work is the eternity in the vocabulary.",
                    "label": 0
                },
                {
                    "sent": "So when you want to access data, won't want to query link data, you have two problems.",
                    "label": 0
                },
                {
                    "sent": "What if you don't know the vocabulary?",
                    "label": 1
                },
                {
                    "sent": "And even if you know the vocabulary, if you know how a concept, what's the name of the concept?",
                    "label": 0
                },
                {
                    "sent": "What if you don't know all the available properties there?",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So as an example, I want to retrieve titles for film so I know that the concept I'm looking for is DVD Ontology film and I know that I'll have to look for property name on DVD property name and I get a bunch of results.",
                    "label": 0
                },
                {
                    "sent": "I get a bunch of titles, but.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If I also know that I can query fourth name to get the titles, maybe I can get some more results.",
                    "label": 0
                },
                {
                    "sent": "I probably get the same.",
                    "label": 0
                },
                {
                    "sent": "I can get some more, I don't know.",
                    "label": 0
                },
                {
                    "sent": "So the idea behind behind this work is to actually is to actually give the user such information.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The most related work to us to this, this one as one on the encyclopedic knowledge pattern.",
                    "label": 0
                },
                {
                    "sent": "The idea behind EP is that the KP is a small piece of ontology which represents a single concept and describes all the possible relation of the concept with other with other concepts.",
                    "label": 0
                },
                {
                    "sent": "The drawback with the KP is that they cannot be because they've been designed for visualization purpose purposes.",
                    "label": 0
                },
                {
                    "sent": "They cannot be directly used to query data to query link data.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what we propose here is to generate statistical knowledge patterns.",
                    "label": 0
                },
                {
                    "sent": "This pattern are again pieces of ontology about a specific concept, so each.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Things in, in this case, for example, the concept is language and they encapsulates all the property.",
                    "label": 0
                },
                {
                    "sent": "The relevant properties for that for that concept.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What we also do is we group so we cluster together properties with have the same meaning.",
                    "label": 0
                },
                {
                    "sent": "So in this case for example for language we have that fourth name, property name, an property language expressed the same, the same meaning.",
                    "label": 0
                },
                {
                    "sent": "What we also in the way we cluster them is that we add askos close match relation between the properties in the in the piece of India.",
                    "label": 0
                },
                {
                    "sent": "Escaping the other thing that we save in the escapee is the range of this property or cluster of properties.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How do we decide that two properties are synonymous, so we start again from a concept language and we retrieve all possible instances for that concept of our language.",
                    "label": 0
                },
                {
                    "sent": "For example, we have English language, Chinese language, Italian language and so on.",
                    "label": 0
                },
                {
                    "sent": "For each of these instances is instances, we go on the link data and we receive all possible triples that have these instances as a subject.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What do we do then?",
                    "label": 0
                },
                {
                    "sent": "We define a similarity measure that.",
                    "label": 0
                },
                {
                    "sent": "That is based on the actual usage of data and this similarity measures to decide if a pair of properties are actually synonymous or not, and this similarity measure has three components.",
                    "label": 0
                },
                {
                    "sent": "The one, the first one is the triple overlap.",
                    "label": 1
                },
                {
                    "sent": "Then we have the subject agreement and Cardinal iteration.",
                    "label": 0
                },
                {
                    "sent": "The triple overlap.",
                    "label": 1
                },
                {
                    "sent": "The idea is very simple.",
                    "label": 0
                },
                {
                    "sent": "We have two properties, P1 MP two and we check subject how many subjects and objects are the same in sets of triples retrieved by those two properties?",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The subject agreement, so again we have two properties, P1 and P2.",
                    "label": 1
                },
                {
                    "sent": "We get all triples that have P1 or P2 as a relationship, and what we check is if is that every time we have the same subject, how many times we have at least this one object, which is the same.",
                    "label": 0
                },
                {
                    "sent": "So we don't.",
                    "label": 0
                },
                {
                    "sent": "We don't really care if all the objects are the same, but at least if there is one in the two sets, which is the same.",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The last one is the cardinality Russia, so we basically check if the two properties of the same cardinality, so it's one property, one to one and the other one want one, and so on.",
                    "label": 0
                },
                {
                    "sent": "So we have a measure for this for this value.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So after we collect all the similarities between pair of so it's a pairwise comparison for all the properties in the concept.",
                    "label": 1
                },
                {
                    "sent": "Once we have all these values, what we do is we cluster property property.",
                    "label": 0
                },
                {
                    "sent": "Together we use analytic agglomerative clustering algorithm not giving detail.",
                    "label": 1
                },
                {
                    "sent": "But if you want further detail on this particular on the particular clustering you can refer to the keys on paper.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So again, just to recap, we start from we start from.",
                    "label": 0
                },
                {
                    "sent": "Each escapee is about a single is context specific, and it's about a single concept we receive all the data and based on the data we collect information.",
                    "label": 0
                },
                {
                    "sent": "So we store in this escapee all properties which are relevant to the concept.",
                    "label": 0
                },
                {
                    "sent": "We are selective in the properties that we add because we have some cut off to decide which properties are relevant are.",
                    "label": 0
                },
                {
                    "sent": "Characteristic of the concept in which one or not.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We tried to three different ways, so it's it's basically we define a threshold to decide if we have threshold to decide if a property goes in the escapee or doesn't go in the escapee.",
                    "label": 0
                },
                {
                    "sent": "We tried three different ways.",
                    "label": 0
                },
                {
                    "sent": "One is, we check the absolute value, so we check for each property how many triples are there in the linked data using that property.",
                    "label": 0
                },
                {
                    "sent": "So we define different absolute thresholds 1020 and so on.",
                    "label": 0
                },
                {
                    "sent": "The other one is fractional, so we have as a threshold the average.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The coverage of that property.",
                    "label": 0
                },
                {
                    "sent": "So given given a concept again language, we take the property and we say how many given all the triples talking about language, how many of those are using that property and last one is a normalized normalized value.",
                    "label": 0
                },
                {
                    "sent": "So instead of considering considering all the triples about the concept, we do it's property specific.",
                    "label": 0
                },
                {
                    "sent": "So we calculate the average of triples for each property and then the threshold.",
                    "label": 1
                },
                {
                    "sent": "Is is based on the average of of single properties.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We have two evaluation, so first of all we want to know what is the descriptive power of escaping.",
                    "label": 0
                },
                {
                    "sent": "So how much data can I access?",
                    "label": 0
                },
                {
                    "sent": "So instead of using all the properties for concept, how much data can I access if I only use the one in the escaping and this is the first first experiment, the second experiment is an in vivo experiment, so we do a query query expansion task and we use information in the escaped to do query expansion.",
                    "label": 0
                },
                {
                    "sent": "What we want to check is what?",
                    "label": 0
                },
                {
                    "sent": "How can we improve the retrieval coverage.",
                    "label": 0
                },
                {
                    "sent": "So how many more triples can we?",
                    "label": 0
                },
                {
                    "sent": "Retrieve, given that we're using synonymous properties with respect to the fact of using a single properties to access the data, so to go back to the first experiment to the first example.",
                    "label": 0
                },
                {
                    "sent": "Sorry if I use just property name or if I use also fourth name, how many more triples do I get?",
                    "label": 0
                },
                {
                    "sent": "And also we check is are those triples that I get more correct or not?",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, As for the first one.",
                    "label": 0
                },
                {
                    "sent": "We use, so I said we have different thresholds.",
                    "label": 0
                },
                {
                    "sent": "The one that performs better performance is the normalized one and the reason experiments showing the zanis by Eva blogs missed.",
                    "label": 0
                },
                {
                    "sent": "It was at the workshop.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So then the experiment shows that by dropping like by only using 20 on average, 27% of properties of a concept we can actually access 94% of the underlying triples.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So basically, we're not including in the escapee 72% of properties that are out there.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The second experiment is about as I said, the query expansion.",
                    "label": 1
                },
                {
                    "sent": "So what do we check?",
                    "label": 0
                },
                {
                    "sent": "We have we get all the pair of properties for a concept and we do two queries, one using just properties from a what we define as a reference ontology suffered.",
                    "label": 0
                },
                {
                    "sent": "In this case we use DPD ontologies as reference ontology and then we do another query by using all synonymous property from the escapee for that particular property.",
                    "label": 0
                },
                {
                    "sent": "What do we want to check is how much?",
                    "label": 0
                },
                {
                    "sent": "How many more triples do we have, and are those triples that we get more correct?",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The way that we track correctness for for the triples is by.",
                    "label": 1
                },
                {
                    "sent": "We do a manual evaluation, so we ask for annotation annotator.",
                    "label": 0
                },
                {
                    "sent": "We give them all the pair of properties and we ask them is despair Express.",
                    "label": 0
                },
                {
                    "sent": "Are these two properties synonymous?",
                    "label": 0
                },
                {
                    "sent": "Yes or no.",
                    "label": 0
                },
                {
                    "sent": "Every time the annotator says they are synonymous, we consider all the data retrieved by the synonymous property correct?",
                    "label": 1
                },
                {
                    "sent": "If they say the two properties are not synonymous, we consider the data as wrong.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "He says about interactive Internet user agreements and threshold that we use are all in the paper.",
                    "label": 0
                },
                {
                    "sent": "So in this in this graph, well, they actually two overlapping graph, so the first one is you can follow them the sorry the black dots.",
                    "label": 0
                },
                {
                    "sent": "Black dots indicates the similarity score between properties.",
                    "label": 0
                },
                {
                    "sent": "I should say before that on the X axis we have old old old pair of all pair of properties, so the black dots indicates the similarity score between those two pairs an we ordered them decreasingly so on decreasing value of similarity score, the overlapping graph is the one with the green and red dots indicates how much more data do I get?",
                    "label": 0
                },
                {
                    "sent": "For that specific pair of property.",
                    "label": 0
                },
                {
                    "sent": "So as you can see.",
                    "label": 0
                },
                {
                    "sent": "At the beginning we then so the dot is either green or red.",
                    "label": 0
                },
                {
                    "sent": "It's green if the data is correct.",
                    "label": 0
                },
                {
                    "sent": "So if the minor rotator say the specific synonymity is correct and it's red if it's been marked as incorrect.",
                    "label": 0
                },
                {
                    "sent": "So as you can see with high similarity score, the majority of expansion are correct and sometimes we get big expansion.",
                    "label": 0
                },
                {
                    "sent": "So by by using sometimes you can.",
                    "label": 0
                },
                {
                    "sent": "We can have like 25 more data by adding this in the synonymous property.",
                    "label": 0
                },
                {
                    "sent": "As the similarity score goes down, we start having noise so you can see more red dots at the end.",
                    "label": 0
                },
                {
                    "sent": "At the end of the graph.",
                    "label": 0
                },
                {
                    "sent": "So when the similarity score is low.",
                    "label": 0
                },
                {
                    "sent": "Introducing the using the synonym synonymous property will introduce will give you more noise in the data.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to conclude, the recap, what's so escapee is a small piece of ontology which is about a single concept, a concept, an encapsulate all important information about this concept concept.",
                    "label": 0
                },
                {
                    "sent": "It is context dependent.",
                    "label": 0
                },
                {
                    "sent": "So if I have two properties which are synonyms synonymous in one concept, they may not be synonymous in another one.",
                    "label": 0
                },
                {
                    "sent": "The process of generating escapes completely automatic, and although all the examples that I use up from DB pedia is very general, so you can use whatever vocabulary you want.",
                    "label": 1
                },
                {
                    "sent": "And is general across datasets.",
                    "label": 1
                },
                {
                    "sent": "Yes, maybe we generated them offline.",
                    "label": 0
                },
                {
                    "sent": "You can generate them offline and then you can and this increase efficiency at the runtime.",
                    "label": 1
                },
                {
                    "sent": "And, well, in this particular case, we proved that there are there beneficial for query expansion.",
                    "label": 0
                },
                {
                    "sent": "Thank you, have any question.",
                    "label": 0
                },
                {
                    "sent": "Happy to take it.",
                    "label": 0
                }
            ]
        }
    }
}