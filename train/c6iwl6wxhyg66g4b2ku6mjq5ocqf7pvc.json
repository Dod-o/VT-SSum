{
    "id": "c6iwl6wxhyg66g4b2ku6mjq5ocqf7pvc",
    "title": "A Generative Perspective on MRFs in Low-Level Vision",
    "info": {
        "author": [
            "Uwe Schmidt, Department of Computer Science, Darmstadt University of Technology"
        ],
        "published": "July 19, 2010",
        "recorded": "June 2010",
        "category": [
            "Top->Computer Science->Machine Learning",
            "Top->Computer Science->Computer Vision"
        ]
    },
    "url": "http://videolectures.net/cvpr2010_schmidt_gpmrf/",
    "segmentation": [
        [
            "Our first paper is a generative perspective on MRI's and it will be presented by who Schmidt?",
            "OK, thank you for introduction.",
            "Welcome everybody.",
            "OK, let's get."
        ],
        [
            "Started.",
            "OK, problems in low level vision like Super resolution, stereo, optical flow, an image restoration are frequently addressed by two different kinds of approaches.",
            "Discriminative methods often show remarkable performance, but they usually limited to a specific application like image denoising, generative models, on the other hand, can be used to model prior knowledge about natural images and scenes, their advantages versatility.",
            "So for instance, a single generic image model can be used for denoising, inpainting and super resolution.",
            "The problem is that generative models are often hard to learn and also hard to evaluate directly, as we'll see."
        ],
        [
            "And this talk is going to build generative Markov random fields, which are popular choice in low level vision to model prior knowledge and specifically."
        ],
        [
            "So we're going to focus on image priors and their application to image restaurace."
        ],
        [
            "Problems.",
            "OK, here's what we usually do to evaluate MRF priors.",
            "We pick an application.",
            "And combine the application specific likelihood with the prior to obtain the posterior distribute."
        ],
        [
            "And we pick some ground truth data and generate or measure from it what we would typically find in the real world application."
        ],
        [
            "We then perform inference on a posterior to obtain the map estimate.",
            "For instance using gradient methods or graph cuts, and finally compare the map estimate with ground truth, and we use some quantitative measure like the peak signal to noise ratio."
        ],
        [
            "The problem is that this is a rather indirect approach because there are two additional components with prior.",
            "There is the likelihood and the specific type of inference.",
            "So ideally we would."
        ],
        [
            "To take a more direct approach, an look at the purpose of MRF priors, which is to model the statistical properties of natural images and scenes.",
            "So it would be best if we could evaluate the generative properties directly.",
            "And this is what zoom Mumford in 97, and we can generally do that by.",
            "Throwing samples from the MRF prior then comparing the MF samples to the data we want to model in terms of desired statistical properties."
        ],
        [
            "The problem is that this is often difficult.",
            "Markov chain Monte Carlo sampling is largely the only choice which may be the reason why the generative properties have been neglected ever since.",
            "So."
        ],
        [
            "In this talk, we want to revisit and explore the generative aspects of M refs in low level vision.",
            "And we evaluate the different properties of common image priors 1st and since there are many pairwise and high order models.",
            "It would be really good to know which of them actually achieves our goal of modeling statistics of the data, and our analysis is based on a flexible MRF framework with an efficient."
        ],
        [
            "Author.",
            "And we surprisingly find that common image prices are not as good as one might think, so we learn.",
            "Pairwise in higher order models with improved generative prop."
        ],
        [
            "Cheese surprisingly, we find that in the context of map estimation, our models do not perform as well as expect."
        ],
        [
            "For image denoising.",
            "But we can address this problem by changing the estimators which has some additional benefits as well.",
            "Before we can do any of that, however, we need to introduce our Merev framework first."
        ],
        [
            "So this will be just a brief overview, so please bear with me.",
            "We rely on fields of experts as introduced by Ross and Black, which is a very general model that subsumes subsumes many popular pairwise and high order MoD."
        ],
        [
            "So we model the prior density of an image X given the model."
        ],
        [
            "Render Theta but taking the product over all the clicks of the image, which can be high order.",
            "And each click is modeled by a product of experts."
        ],
        [
            "And the expert functions model the responses of extended linear filters to the pixels in the clique."
        ],
        [
            "The model parameters are the linear filters J and the expert parameters Alpha."
        ],
        [
            "For the expert functions, we choose a flexible Gaussian scale mixture.",
            "Which are mixtures of 0 mean Gaussians that only difference through the variances?",
            "Which we call scales in this context.",
            "And GSM can express a wide range of heavy tailed distributions such as student ease and Laplacian.",
            "They were first popularized by Wainwright and Simoncelli.",
            "In image models and 1st using the MRF in the FO E by Wisin Freeman.",
            "Anne."
        ],
        [
            "In order.",
            "To draw samples from the MRF, it's helpful to realize that our model is basically like a big mixture of Gaussians, so we can augment the model with indicator variables Z for the mixture components and this allows us to.",
            "Naturally defined a joint distribution over the image X and the auxiliary variable Z."
        ],
        [
            "And with a strong distribution we can do Gibbs sampling by alternating between block sampling the image from P of X given Z.",
            "And auxiliary variables from P of Z given X.",
            "And in order to make sampling practical, we use the least squares method by wison levy for sampling from the Gaussian MRF P of X given Z."
        ],
        [
            "So here are two examples of the Gibbs sampler.",
            "On the left you for a pairwise MRF and on the right for a high order MF with 3 + 3 clicks.",
            "And we can achieve rapid mixing.",
            "That means subsequent image samples have little correlation.",
            "On a side note, samples on the right look more natural as compared to speckles in samples on the left."
        ],
        [
            "OK, now that we've introduced our flexible framework and the sampler, we can get back to answering the questions.",
            "How good common image parts actually are.",
            "So we first consider the simplest type of model, which is a pairwise MRF that models.",
            "The difference of neighboring pixels was a single potential function.",
            "And the derivative Marshalls of natural images, which is the histogram of image derivatives, have been shown to have a distinctive heavy tail shape.",
            "This is exactly what pairwise MRF tried to model.",
            "So what people have frequently done is to fit the potential."
        ],
        [
            "Function directly to the marginals, but when we actually use such and potential in pairs."
        ],
        [
            "MRF and draw samples.",
            "We get green derivative markets on the right, which are two peaked and this visual impression is also confirmed by looking at the marginal KL divergent.",
            "So."
        ],
        [
            "We also considered a general Laplacian.",
            "Which is another."
        ],
        [
            "Your choice, but we essentially get similar results.",
            "So now that we know that common pairwise merev don't capture the statistics of image derivatives, what about high order Markov random fields?"
        ],
        [
            "So we considered 2 common fields of experts models.",
            "First, the original FOV by Ross and Black and the FO Eva Wiseman Freeman.",
            "And both models are mainly differ through their loan Bank of linear filters.",
            "Click size is an expert functions, but both models try to model the filter statistics of the model filters which you can see for natural images at that."
        ],
        [
            "Top and four MF samples at the bottom, which are much too peaked.",
            "So surprisingly both models seem to be rather poor.",
            "Image pro."
        ],
        [
            "An, but this is an apparent contradiction given how well these MFS perform in practice.",
            "So we wanted it is so and what we what we can do to fix this and we just train better."
        ],
        [
            "And in contrast to previous work, we learn the shapes of flexibel GSM experts and the linear filters for in case of high order models we use the efficient sampler as described.",
            "And our training procedures otherwise similar to that of Ross and Black."
        ],
        [
            "And we did."
        ],
        [
            "Two models, simple pairwise, MRF with a single potential function."
        ],
        [
            "And a field of experts with three by three clicks and eight GSM experts, which includes the filters."
        ],
        [
            "When we look at our learned pairwise potential, we see that it's much more heavy tailed and derivative margins of natural images."
        ],
        [
            "And this observation also holds true when comparing or learn GSM to the previously considered considered potentials."
        ],
        [
            "But when we actually use our learned GSM potential and raw samples, we get the green derivative Marshalls on the right, which matched those of natural images very well.",
            "The Marshall killed divergences close to."
        ],
        [
            "0.",
            "And here for comparison, the margins of the previous two potentials.",
            "OK, why?",
            "Why does?",
            "Why is our model better at capturing statistics?",
            "We think it's because Gaussian scale mixture allow for wider range of shapes than previously used parametric potentials."
        ],
        [
            "We now turn to our learn three by three Fe where you can see the experts at the top and the filters at the bottom."
        ],
        [
            "And when we compare them to the other two FOS that we considered before, we see that the experts are much, much more piqued.",
            "And we also believe this is because of the flexibility of GSM's cause the student T experts were awesome.",
            "Black are limited in their flexibility and wison Freeman fixed the GSM expert to image relatives before they learn to filters."
        ],
        [
            "But when we look at the first statistics of our learned fo E we see that they are much better than previous ones.",
            "The peaks roughly correct, but the details are still not wide enough, so there clearly is room for improvement in the future.",
            "But there's still much better than previous models."
        ],
        [
            "OK, now that we've learned improved generative models, we tried an image noising application.",
            "And we assume additive white Gaussian noise with known standard deviation, which is a common benchmark to evaluate image prior."
        ],
        [
            "In this example, we combine our three by three fo E with a Gaussian likelihood model to obtain the posterior disc."
        ],
        [
            "And we perform map estimation to obtain the denoised image, which you can see is much too smooth."
        ],
        [
            "So what people are frequently done is to use a regularization way to get better performance.",
            "And while this works well in practice, it essentially changes the model and it does not very clean from a theoretical point of view."
        ],
        [
            "But we do that too and we get better results."
        ],
        [
            "But still, we're not better than previous models.",
            "So why this case that our models aren't better in applications given that they capture the statistics of natural images better than previous models?"
        ],
        [
            "Recent works of recent works have already pointed to deficiencies of map estimation and info."
        ],
        [
            "We also did an experiment experimental evaluation with the pairwise MRF and we only find the modest correlation between the image quality of the map estimate and degenerative quality of the MF.",
            "So that means for the types of model that we considered here, we generally cannot expect.",
            "Better application performance from better terms of models.",
            "So."
        ],
        [
            "Instead, we propose to use basean minimum mean squared error estimation, which is equal to the posterior mean and levy already extended the sampler to the posterior, but only use the single sample in image restoration applications.",
            "Winsted approximately MSE estimate by averaging samples from the post."
        ],
        [
            "And with that, we now find a high correlation between the image quality of the MSE estimate and the generative quality of the MRF."
        ],
        [
            "And.",
            "We did more extensive evaluation on six year test images and we compared to other popular methods."
        ],
        [
            "And with our pairwise MRF anti MSE, we can even outperform the five by five.",
            "If we were awesome black despite their larger cliques and noise adaptive regularization weight."
        ],
        [
            "And when we use our three battery fo E with the NSC, we can even outperform the discriminative 5 by 5 if we both similar and tapping which is specifically trained to maximize the Pearson R of map estimates.",
            "So the crucial difference is that we use MSE instead of map estimation, which allows us to exploit the modeling power of generative Markov random fields.",
            "And we also compared to non local means anbl GSM.",
            "And the difference is that our models are more widely applicable."
        ],
        [
            "Furthermore, there there are other advantages to the MSE.",
            "We've already mentioned that the denoising performance is highly correlated with the generative quality of the model."
        ],
        [
            "And we don't need to use a regularization way to get good."
        ],
        [
            "Performance.",
            "And Furthermore, the denoised image does not exhibit incorrect statistics, which has frequently been shown for map estimates.",
            "There on stair casing with piecewise constant regions as shown."
        ],
        [
            "Image on the left.",
            "And when we plot.",
            "The derivative margins of pristine images.",
            "We get the black curve on the right an we add noise to these images and annoys them using."
        ],
        [
            "Estimation, we get the blue derivative marginal curve.",
            "And you can see that statistics don't match very well, so this has been pointed out by Woodford and colleagues.",
            "And they replaced Ms with a different kind of model to fix this problem, but."
        ],
        [
            "When we use the MSE, we can essentially get the correct derivative statistics.",
            "With Standard MF and don't need to replace them with a different model."
        ],
        [
            "To summarize, we evaluated Markov random fields through the generative properties based on a flexible MRF framework with an efficient sampler, we find that common image priors are surprisingly poor generative models.",
            "And we address this problem by learning better generative Markov random fields, pairwise and high order.",
            "And in both cases find that we need more peak potentials.",
            "Furthermore, sampling makes MSE estimation practical and has several advantages over map estimation.",
            "With the MSE we can get excellent results from generative application neutral models."
        ],
        [
            "Our learn models, an MATLAB code will soon be available on the website and before opening up for questions.",
            "We especially want to thank you guys for sharing with us.",
            "His ideas about efficient Gibbs sampler.",
            "I thank you for your attention and please come to our poster.",
            "So I may not live in forms of Waxman Institute and Gerald.",
            "Very nice work.",
            "And maybe it's not a question.",
            "It's a comment and I was thinking that.",
            "Another way to explain the explain the problem with the.",
            "It's a difference between the samples and the marginal distribution is just that the derivatives are not independent.",
            "Because you have derivatives both in X&Y and the result, even if user powers in my life, so derivative since there was an Italian vertical directions are not independent, so supposed to even try to fit just a Gaussian model to the derivatives.",
            "So we fit just learn the variance of the of the of the Gaussian model.",
            "And then we try to sample from.",
            "This prior will get a, will get samples with half of the variance because we have derivatives both in X&Y.",
            "So in a sense, I think the main problem the main aspect which is causing all these problems independence between the horizontal and vertical derivatives, that maybe that's that's an aspect, should be added to this explanation.",
            "We have both horizontal and vertical derivative.",
            "No, I'm sure use it, but I think that the reason that they.",
            "That when you when you just feed the model and you draw simple, you don't get you don't get the same shape of file is because there are because we don't have vertical derivatives of not independent.",
            "OK, I'm not sure if I understand it correctly, but let's take it offline anyway.",
            "It's not a question, it's just another way to explain it.",
            "OK, thank you.",
            "OK, I also agree it's it's beautiful work.",
            "The my question is why do people only look at derivatives?",
            "When matching statistics?",
            "You could imagine any other statistic you could take banks of oriented filter responses you know.",
            "Second, derivatives things like that.",
            "We also considered other statistics and we evaluated random filters of various sizes and also multiscale derivative filters even though are the models are not designed to capture them.",
            "We find in both cases that.",
            "High Order MRF model statistics better than pairwise MRF, especially for the derivative filters.",
            "There was an effort to find scale like models and derivative statistics almost perfectly, but for the large scale derivative filters, the high order fo is actually better.",
            "OK, thank you.",
            "Just stop just short comment so I miss being able to talk before the end evaluation.",
            "You may want to compare yourself to the true state of the art image noising which not disguise the people from temporary in Finland.",
            "And and then you can.",
            "You can receive it's better or not.",
            "So try to look up BM 3D.",
            "OK for you suggest to compared to other methods.",
            "Yeah, because because they do better just are good methods with the updates are much better.",
            "So yeah, we're not claiming to be overall best an image sure sure.",
            "Sure I'm just saying it's good.",
            "Compare yourself to the real reason that we get much better performance even from very generic models and which are not designed to for noising only."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our first paper is a generative perspective on MRI's and it will be presented by who Schmidt?",
                    "label": 1
                },
                {
                    "sent": "OK, thank you for introduction.",
                    "label": 0
                },
                {
                    "sent": "Welcome everybody.",
                    "label": 0
                },
                {
                    "sent": "OK, let's get.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Started.",
                    "label": 0
                },
                {
                    "sent": "OK, problems in low level vision like Super resolution, stereo, optical flow, an image restoration are frequently addressed by two different kinds of approaches.",
                    "label": 1
                },
                {
                    "sent": "Discriminative methods often show remarkable performance, but they usually limited to a specific application like image denoising, generative models, on the other hand, can be used to model prior knowledge about natural images and scenes, their advantages versatility.",
                    "label": 0
                },
                {
                    "sent": "So for instance, a single generic image model can be used for denoising, inpainting and super resolution.",
                    "label": 0
                },
                {
                    "sent": "The problem is that generative models are often hard to learn and also hard to evaluate directly, as we'll see.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this talk is going to build generative Markov random fields, which are popular choice in low level vision to model prior knowledge and specifically.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we're going to focus on image priors and their application to image restaurace.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Problems.",
                    "label": 0
                },
                {
                    "sent": "OK, here's what we usually do to evaluate MRF priors.",
                    "label": 0
                },
                {
                    "sent": "We pick an application.",
                    "label": 0
                },
                {
                    "sent": "And combine the application specific likelihood with the prior to obtain the posterior distribute.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we pick some ground truth data and generate or measure from it what we would typically find in the real world application.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We then perform inference on a posterior to obtain the map estimate.",
                    "label": 0
                },
                {
                    "sent": "For instance using gradient methods or graph cuts, and finally compare the map estimate with ground truth, and we use some quantitative measure like the peak signal to noise ratio.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The problem is that this is a rather indirect approach because there are two additional components with prior.",
                    "label": 0
                },
                {
                    "sent": "There is the likelihood and the specific type of inference.",
                    "label": 0
                },
                {
                    "sent": "So ideally we would.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To take a more direct approach, an look at the purpose of MRF priors, which is to model the statistical properties of natural images and scenes.",
                    "label": 1
                },
                {
                    "sent": "So it would be best if we could evaluate the generative properties directly.",
                    "label": 0
                },
                {
                    "sent": "And this is what zoom Mumford in 97, and we can generally do that by.",
                    "label": 0
                },
                {
                    "sent": "Throwing samples from the MRF prior then comparing the MF samples to the data we want to model in terms of desired statistical properties.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The problem is that this is often difficult.",
                    "label": 0
                },
                {
                    "sent": "Markov chain Monte Carlo sampling is largely the only choice which may be the reason why the generative properties have been neglected ever since.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In this talk, we want to revisit and explore the generative aspects of M refs in low level vision.",
                    "label": 0
                },
                {
                    "sent": "And we evaluate the different properties of common image priors 1st and since there are many pairwise and high order models.",
                    "label": 0
                },
                {
                    "sent": "It would be really good to know which of them actually achieves our goal of modeling statistics of the data, and our analysis is based on a flexible MRF framework with an efficient.",
                    "label": 1
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Author.",
                    "label": 0
                },
                {
                    "sent": "And we surprisingly find that common image prices are not as good as one might think, so we learn.",
                    "label": 1
                },
                {
                    "sent": "Pairwise in higher order models with improved generative prop.",
                    "label": 1
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Cheese surprisingly, we find that in the context of map estimation, our models do not perform as well as expect.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For image denoising.",
                    "label": 0
                },
                {
                    "sent": "But we can address this problem by changing the estimators which has some additional benefits as well.",
                    "label": 1
                },
                {
                    "sent": "Before we can do any of that, however, we need to introduce our Merev framework first.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this will be just a brief overview, so please bear with me.",
                    "label": 0
                },
                {
                    "sent": "We rely on fields of experts as introduced by Ross and Black, which is a very general model that subsumes subsumes many popular pairwise and high order MoD.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we model the prior density of an image X given the model.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Render Theta but taking the product over all the clicks of the image, which can be high order.",
                    "label": 0
                },
                {
                    "sent": "And each click is modeled by a product of experts.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the expert functions model the responses of extended linear filters to the pixels in the clique.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The model parameters are the linear filters J and the expert parameters Alpha.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For the expert functions, we choose a flexible Gaussian scale mixture.",
                    "label": 0
                },
                {
                    "sent": "Which are mixtures of 0 mean Gaussians that only difference through the variances?",
                    "label": 0
                },
                {
                    "sent": "Which we call scales in this context.",
                    "label": 0
                },
                {
                    "sent": "And GSM can express a wide range of heavy tailed distributions such as student ease and Laplacian.",
                    "label": 0
                },
                {
                    "sent": "They were first popularized by Wainwright and Simoncelli.",
                    "label": 0
                },
                {
                    "sent": "In image models and 1st using the MRF in the FO E by Wisin Freeman.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In order.",
                    "label": 0
                },
                {
                    "sent": "To draw samples from the MRF, it's helpful to realize that our model is basically like a big mixture of Gaussians, so we can augment the model with indicator variables Z for the mixture components and this allows us to.",
                    "label": 1
                },
                {
                    "sent": "Naturally defined a joint distribution over the image X and the auxiliary variable Z.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And with a strong distribution we can do Gibbs sampling by alternating between block sampling the image from P of X given Z.",
                    "label": 0
                },
                {
                    "sent": "And auxiliary variables from P of Z given X.",
                    "label": 1
                },
                {
                    "sent": "And in order to make sampling practical, we use the least squares method by wison levy for sampling from the Gaussian MRF P of X given Z.",
                    "label": 1
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here are two examples of the Gibbs sampler.",
                    "label": 1
                },
                {
                    "sent": "On the left you for a pairwise MRF and on the right for a high order MF with 3 + 3 clicks.",
                    "label": 0
                },
                {
                    "sent": "And we can achieve rapid mixing.",
                    "label": 0
                },
                {
                    "sent": "That means subsequent image samples have little correlation.",
                    "label": 0
                },
                {
                    "sent": "On a side note, samples on the right look more natural as compared to speckles in samples on the left.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, now that we've introduced our flexible framework and the sampler, we can get back to answering the questions.",
                    "label": 0
                },
                {
                    "sent": "How good common image parts actually are.",
                    "label": 0
                },
                {
                    "sent": "So we first consider the simplest type of model, which is a pairwise MRF that models.",
                    "label": 0
                },
                {
                    "sent": "The difference of neighboring pixels was a single potential function.",
                    "label": 1
                },
                {
                    "sent": "And the derivative Marshalls of natural images, which is the histogram of image derivatives, have been shown to have a distinctive heavy tail shape.",
                    "label": 1
                },
                {
                    "sent": "This is exactly what pairwise MRF tried to model.",
                    "label": 0
                },
                {
                    "sent": "So what people have frequently done is to fit the potential.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Function directly to the marginals, but when we actually use such and potential in pairs.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "MRF and draw samples.",
                    "label": 0
                },
                {
                    "sent": "We get green derivative markets on the right, which are two peaked and this visual impression is also confirmed by looking at the marginal KL divergent.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We also considered a general Laplacian.",
                    "label": 0
                },
                {
                    "sent": "Which is another.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Your choice, but we essentially get similar results.",
                    "label": 0
                },
                {
                    "sent": "So now that we know that common pairwise merev don't capture the statistics of image derivatives, what about high order Markov random fields?",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we considered 2 common fields of experts models.",
                    "label": 0
                },
                {
                    "sent": "First, the original FOV by Ross and Black and the FO Eva Wiseman Freeman.",
                    "label": 0
                },
                {
                    "sent": "And both models are mainly differ through their loan Bank of linear filters.",
                    "label": 0
                },
                {
                    "sent": "Click size is an expert functions, but both models try to model the filter statistics of the model filters which you can see for natural images at that.",
                    "label": 1
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Top and four MF samples at the bottom, which are much too peaked.",
                    "label": 0
                },
                {
                    "sent": "So surprisingly both models seem to be rather poor.",
                    "label": 0
                },
                {
                    "sent": "Image pro.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "An, but this is an apparent contradiction given how well these MFS perform in practice.",
                    "label": 0
                },
                {
                    "sent": "So we wanted it is so and what we what we can do to fix this and we just train better.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in contrast to previous work, we learn the shapes of flexibel GSM experts and the linear filters for in case of high order models we use the efficient sampler as described.",
                    "label": 0
                },
                {
                    "sent": "And our training procedures otherwise similar to that of Ross and Black.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we did.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Two models, simple pairwise, MRF with a single potential function.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And a field of experts with three by three clicks and eight GSM experts, which includes the filters.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "When we look at our learned pairwise potential, we see that it's much more heavy tailed and derivative margins of natural images.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this observation also holds true when comparing or learn GSM to the previously considered considered potentials.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But when we actually use our learned GSM potential and raw samples, we get the green derivative Marshalls on the right, which matched those of natural images very well.",
                    "label": 0
                },
                {
                    "sent": "The Marshall killed divergences close to.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "0.",
                    "label": 0
                },
                {
                    "sent": "And here for comparison, the margins of the previous two potentials.",
                    "label": 0
                },
                {
                    "sent": "OK, why?",
                    "label": 0
                },
                {
                    "sent": "Why does?",
                    "label": 0
                },
                {
                    "sent": "Why is our model better at capturing statistics?",
                    "label": 0
                },
                {
                    "sent": "We think it's because Gaussian scale mixture allow for wider range of shapes than previously used parametric potentials.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We now turn to our learn three by three Fe where you can see the experts at the top and the filters at the bottom.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And when we compare them to the other two FOS that we considered before, we see that the experts are much, much more piqued.",
                    "label": 0
                },
                {
                    "sent": "And we also believe this is because of the flexibility of GSM's cause the student T experts were awesome.",
                    "label": 0
                },
                {
                    "sent": "Black are limited in their flexibility and wison Freeman fixed the GSM expert to image relatives before they learn to filters.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But when we look at the first statistics of our learned fo E we see that they are much better than previous ones.",
                    "label": 1
                },
                {
                    "sent": "The peaks roughly correct, but the details are still not wide enough, so there clearly is room for improvement in the future.",
                    "label": 1
                },
                {
                    "sent": "But there's still much better than previous models.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, now that we've learned improved generative models, we tried an image noising application.",
                    "label": 0
                },
                {
                    "sent": "And we assume additive white Gaussian noise with known standard deviation, which is a common benchmark to evaluate image prior.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In this example, we combine our three by three fo E with a Gaussian likelihood model to obtain the posterior disc.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we perform map estimation to obtain the denoised image, which you can see is much too smooth.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what people are frequently done is to use a regularization way to get better performance.",
                    "label": 0
                },
                {
                    "sent": "And while this works well in practice, it essentially changes the model and it does not very clean from a theoretical point of view.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But we do that too and we get better results.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But still, we're not better than previous models.",
                    "label": 0
                },
                {
                    "sent": "So why this case that our models aren't better in applications given that they capture the statistics of natural images better than previous models?",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Recent works of recent works have already pointed to deficiencies of map estimation and info.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We also did an experiment experimental evaluation with the pairwise MRF and we only find the modest correlation between the image quality of the map estimate and degenerative quality of the MF.",
                    "label": 1
                },
                {
                    "sent": "So that means for the types of model that we considered here, we generally cannot expect.",
                    "label": 1
                },
                {
                    "sent": "Better application performance from better terms of models.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Instead, we propose to use basean minimum mean squared error estimation, which is equal to the posterior mean and levy already extended the sampler to the posterior, but only use the single sample in image restoration applications.",
                    "label": 0
                },
                {
                    "sent": "Winsted approximately MSE estimate by averaging samples from the post.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And with that, we now find a high correlation between the image quality of the MSE estimate and the generative quality of the MRF.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "We did more extensive evaluation on six year test images and we compared to other popular methods.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And with our pairwise MRF anti MSE, we can even outperform the five by five.",
                    "label": 0
                },
                {
                    "sent": "If we were awesome black despite their larger cliques and noise adaptive regularization weight.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And when we use our three battery fo E with the NSC, we can even outperform the discriminative 5 by 5 if we both similar and tapping which is specifically trained to maximize the Pearson R of map estimates.",
                    "label": 0
                },
                {
                    "sent": "So the crucial difference is that we use MSE instead of map estimation, which allows us to exploit the modeling power of generative Markov random fields.",
                    "label": 0
                },
                {
                    "sent": "And we also compared to non local means anbl GSM.",
                    "label": 0
                },
                {
                    "sent": "And the difference is that our models are more widely applicable.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Furthermore, there there are other advantages to the MSE.",
                    "label": 0
                },
                {
                    "sent": "We've already mentioned that the denoising performance is highly correlated with the generative quality of the model.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we don't need to use a regularization way to get good.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Performance.",
                    "label": 0
                },
                {
                    "sent": "And Furthermore, the denoised image does not exhibit incorrect statistics, which has frequently been shown for map estimates.",
                    "label": 1
                },
                {
                    "sent": "There on stair casing with piecewise constant regions as shown.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Image on the left.",
                    "label": 0
                },
                {
                    "sent": "And when we plot.",
                    "label": 0
                },
                {
                    "sent": "The derivative margins of pristine images.",
                    "label": 0
                },
                {
                    "sent": "We get the black curve on the right an we add noise to these images and annoys them using.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Estimation, we get the blue derivative marginal curve.",
                    "label": 0
                },
                {
                    "sent": "And you can see that statistics don't match very well, so this has been pointed out by Woodford and colleagues.",
                    "label": 0
                },
                {
                    "sent": "And they replaced Ms with a different kind of model to fix this problem, but.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "When we use the MSE, we can essentially get the correct derivative statistics.",
                    "label": 0
                },
                {
                    "sent": "With Standard MF and don't need to replace them with a different model.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To summarize, we evaluated Markov random fields through the generative properties based on a flexible MRF framework with an efficient sampler, we find that common image priors are surprisingly poor generative models.",
                    "label": 1
                },
                {
                    "sent": "And we address this problem by learning better generative Markov random fields, pairwise and high order.",
                    "label": 0
                },
                {
                    "sent": "And in both cases find that we need more peak potentials.",
                    "label": 1
                },
                {
                    "sent": "Furthermore, sampling makes MSE estimation practical and has several advantages over map estimation.",
                    "label": 0
                },
                {
                    "sent": "With the MSE we can get excellent results from generative application neutral models.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our learn models, an MATLAB code will soon be available on the website and before opening up for questions.",
                    "label": 0
                },
                {
                    "sent": "We especially want to thank you guys for sharing with us.",
                    "label": 0
                },
                {
                    "sent": "His ideas about efficient Gibbs sampler.",
                    "label": 0
                },
                {
                    "sent": "I thank you for your attention and please come to our poster.",
                    "label": 1
                },
                {
                    "sent": "So I may not live in forms of Waxman Institute and Gerald.",
                    "label": 0
                },
                {
                    "sent": "Very nice work.",
                    "label": 0
                },
                {
                    "sent": "And maybe it's not a question.",
                    "label": 0
                },
                {
                    "sent": "It's a comment and I was thinking that.",
                    "label": 0
                },
                {
                    "sent": "Another way to explain the explain the problem with the.",
                    "label": 0
                },
                {
                    "sent": "It's a difference between the samples and the marginal distribution is just that the derivatives are not independent.",
                    "label": 0
                },
                {
                    "sent": "Because you have derivatives both in X&Y and the result, even if user powers in my life, so derivative since there was an Italian vertical directions are not independent, so supposed to even try to fit just a Gaussian model to the derivatives.",
                    "label": 0
                },
                {
                    "sent": "So we fit just learn the variance of the of the of the Gaussian model.",
                    "label": 0
                },
                {
                    "sent": "And then we try to sample from.",
                    "label": 0
                },
                {
                    "sent": "This prior will get a, will get samples with half of the variance because we have derivatives both in X&Y.",
                    "label": 0
                },
                {
                    "sent": "So in a sense, I think the main problem the main aspect which is causing all these problems independence between the horizontal and vertical derivatives, that maybe that's that's an aspect, should be added to this explanation.",
                    "label": 0
                },
                {
                    "sent": "We have both horizontal and vertical derivative.",
                    "label": 0
                },
                {
                    "sent": "No, I'm sure use it, but I think that the reason that they.",
                    "label": 0
                },
                {
                    "sent": "That when you when you just feed the model and you draw simple, you don't get you don't get the same shape of file is because there are because we don't have vertical derivatives of not independent.",
                    "label": 0
                },
                {
                    "sent": "OK, I'm not sure if I understand it correctly, but let's take it offline anyway.",
                    "label": 0
                },
                {
                    "sent": "It's not a question, it's just another way to explain it.",
                    "label": 0
                },
                {
                    "sent": "OK, thank you.",
                    "label": 0
                },
                {
                    "sent": "OK, I also agree it's it's beautiful work.",
                    "label": 0
                },
                {
                    "sent": "The my question is why do people only look at derivatives?",
                    "label": 0
                },
                {
                    "sent": "When matching statistics?",
                    "label": 0
                },
                {
                    "sent": "You could imagine any other statistic you could take banks of oriented filter responses you know.",
                    "label": 0
                },
                {
                    "sent": "Second, derivatives things like that.",
                    "label": 0
                },
                {
                    "sent": "We also considered other statistics and we evaluated random filters of various sizes and also multiscale derivative filters even though are the models are not designed to capture them.",
                    "label": 0
                },
                {
                    "sent": "We find in both cases that.",
                    "label": 0
                },
                {
                    "sent": "High Order MRF model statistics better than pairwise MRF, especially for the derivative filters.",
                    "label": 0
                },
                {
                    "sent": "There was an effort to find scale like models and derivative statistics almost perfectly, but for the large scale derivative filters, the high order fo is actually better.",
                    "label": 0
                },
                {
                    "sent": "OK, thank you.",
                    "label": 0
                },
                {
                    "sent": "Just stop just short comment so I miss being able to talk before the end evaluation.",
                    "label": 0
                },
                {
                    "sent": "You may want to compare yourself to the true state of the art image noising which not disguise the people from temporary in Finland.",
                    "label": 0
                },
                {
                    "sent": "And and then you can.",
                    "label": 0
                },
                {
                    "sent": "You can receive it's better or not.",
                    "label": 0
                },
                {
                    "sent": "So try to look up BM 3D.",
                    "label": 0
                },
                {
                    "sent": "OK for you suggest to compared to other methods.",
                    "label": 0
                },
                {
                    "sent": "Yeah, because because they do better just are good methods with the updates are much better.",
                    "label": 0
                },
                {
                    "sent": "So yeah, we're not claiming to be overall best an image sure sure.",
                    "label": 0
                },
                {
                    "sent": "Sure I'm just saying it's good.",
                    "label": 0
                },
                {
                    "sent": "Compare yourself to the real reason that we get much better performance even from very generic models and which are not designed to for noising only.",
                    "label": 0
                }
            ]
        }
    }
}