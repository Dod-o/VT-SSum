{
    "id": "vlgjnpp67vrrkqgf3764xcun6pg6iksp",
    "title": "Using the Web to Reduce Data Sparseness in Pattern-based Information",
    "info": {
        "published": "Jan. 28, 2008",
        "recorded": "September 2007",
        "category": [
            "Top->Computer Science->Information Extraction",
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/ecml07_blohm_uwr/",
    "segmentation": [
        [
            "Sparseness and these guys are passing through everything so now and Sebastian is stored in there.",
            "Thanks for the introduction and welcome to my talk.",
            "Um?"
        ],
        [
            "So the goal that we aiming at is extracting information from large data set.",
            "There's a couple of sub task information extraction, one of them being extracting named entities or identifying them entities, then extracting relations among entities in the text.",
            "And there's others like treatment of reference and more higher level tasks like learning ontologies or other.",
            "Kind of knowledge that might be there and for extraction of relations there's two types of methods that is being applied, one of them being statistical classifiers.",
            "Given a set of sentences that are kind of candidates for the classification before for mentioning a given relation, you classify them.",
            "In doing so, I'm not doing so, and the other one is applying textural patterns and on large collection."
        ],
        [
            "And we have the second collection becausw on for the second message.",
            "Then we using patterns be cause.",
            "It of the possibility to efficiently matching them on large datasets.",
            "And because we don't have enough training data to train classifiers.",
            "So when you do pattern based extractions there is.",
            "There's a couple of assumptions that you make, in particular that the occurrences of the relation instances are in some sense regular, so that the occurrences have something in common and the other assumption that is being made is that there's a redundancy in that, because if you limit yourself to a given number of patterns, then you still want to have a large coverage.",
            "And also for the induction of the patterns, the redundancy is an important issue is also in the moment.",
            "There's like the basic paradigms, either taking a set of given set of fixed patterns or inducing yourself textural patterns to learn and data sources are usually large corpora, largeness being required by these assumptions, or even the web, and for coming up with these patterns, either bootstrapping methods are being applied, or and usually in combination with with learning.",
            "Bottom up from textual occurrences.",
            "There are other options like modeling tax in vector space model, but this is not what we do here.",
            "So for the purpose of this talk you can think of this as having textual occurrences in which instances of relational curve.",
            "Here we have the city is located in country relation and we have the sentence is the happiest people in Germany live in Oxnard.",
            "The richest people in America live in Hollywood and.",
            "Patterns generated by identifying the slot fillers and replacing the occurrences by wildcards and abstracting over at other parts of texture occurrences."
        ],
        [
            "So again, given these assumptions, the problem that we are facing when going away from the web as a really huge data set to Vicky Pedia, what we're using in our scenario is that we've found out that redundancy is not that much present.",
            "Wikipedia, because it's a high quality edited thing where people take care not to repeat themselves too often.",
            "And our goal and what we achieved in this study is that we use the web as a background knowledge to help the system boot strip.",
            "And we show that we can.",
            "This adding the web as an abstraction source is equivalent to adding much more training samples of the process which we are trying to avoid because coming up with training samples in our."
        ],
        [
            "Setting is very expensive.",
            "So as of the outside of my talk, it's got a generic I'll demonstrate quickly the general method, then compare why it does not work on Wikipedia, like it works on the web, I'll show our integration methods and expose."
        ],
        [
            "Mental evaluation before concluding.",
            "So what is what we are trying to extract?",
            "We have your typical Wikipedia page and what we know what we make as an assumption.",
            "What other people have done in the past as well.",
            "Is that relevant relations of the instances instance in question.",
            "So this is Google kind of fish.",
            "Is that like, relevant relations are in the links that are on that page, and in particular we then want to use the context of these links in order to identify what type of relation is there with these."
        ],
        [
            "Thanks.",
            "So the message that we.",
            "That we use is we start with a couple of examples.",
            "This is really a very small set of examples, say 10 or something.",
            "'cause this is the knowledge we actually want to learn.",
            "We don't want to give too much information in it because we want to learn a lot of different relations.",
            "So we start like, say with some types of fish is and where the habitat is and look at that Wikipedia pages in order to extract the context in which they occur.",
            "We learn patterns from that match those again on Wikipedia pages.",
            "In order to obtain a larger set of instances which then can be fed back into the process in order to iteratively extract more information."
        ],
        [
            "So the bootstrapping effect that is behind this is that you start with a couple of instances.",
            "They give you look in which contexts they appear you extract from them by creating printing, edit, adding further further instances which lead to further patterns and then.",
            "You can repeat this until you have sufficiently much information."
        ],
        [
            "The unfortunate thing is that is not that redundant corpus, as Wikipedia.",
            "This is kind of quenched 'cause you get context from your first instances.",
            "You can create patterns from that, which again give you more instances.",
            "But as these instances occur only once or twice in the text, when you look in which context they occur, you can get back to the context that you had before, and that you cannot start to get further patterns and.",
            "The duck."
        ],
        [
            "And it kind of stopped.",
            "So we quantified this effect and look how often given relation pair for a couple of tests example occur in Wikipedia in total, and there's one of these nearly power law curves again, and they kind of show that there's some which occur very frequently and in the web, like even the median is that relation instances occur rather often, but.",
            "On Wikipedia, the median is about 15 times the things mentioned, and as we restrict the link title pairs in our current experiments, this is this number even much lower so that you can assume that maybe between two or three times it given relation instances mentioned, and this is not only to the web, Wikipedia being a small subset of the web, but also due to the fact that isn't collection which is not redundant in the sense that effects are not repeated very often."
        ],
        [
            "So what we are now trying to do is to use the less precise information from the web as a as background, background information, kind of to get the bootstrapping started, but then not using it as the output as we assume that Wikipedia is much more precise, so.",
            "What we would like to do, I compare now three conditions that we use in our experiments is like the basic process would be finding seeds on the weekly learning patterns from them, matching them on the week in order to get more instances, and then this arrow is kind of not on the picture, then repeating it intuitively in the further process we add the web to the process.",
            "As in doing the extraction first on the web.",
            "Then filtering to keep only what is also present in the wiki, match these this information here find patterns there and then go back to extract with the learned information from the wiki.",
            "Further in from instances from the web kind of doing dual extraction process here and we have an intermediate step where we do the instruct extraction from the web.",
            "Once in the beginning to start bootstrapping and then loop over further web."
        ],
        [
            "Struction iterations, so this visualized again in a different way to do will approach with the first adding looking for context context on the web, learning patterns, matching them to get instances, filter for the presence in the wiki.",
            "And get further context then on the wiki matching the information before.",
            "Adding further instances in the matching step and then you can reiterate this as many times as you like.",
            "Then like this is of course only the longer version of the initial approach, which would basically being only doing."
        ],
        [
            "On the wiki and the."
        ],
        [
            "Intermediate web Ones option would just do the 1st."
        ],
        [
            "Step one.",
            "We tested this extraction processes on 7.",
            "Non taxonomic relations, namely musicians and the album step.",
            "They published persons in the year of birth countries and their currencies, companies and their headquarters cities, in which country they lie, product names and make us where we were limited there to the automotive domain and sports persons in the country they come from.",
            "These creations are varying in different aspects.",
            "For example in size we extracted from some reliable sources.",
            "Large lists of inst."
        ],
        [
            "This is to test them and So what we did is look over the Internet iterations.",
            "How many correct extractions there were, and as we can see here.",
            "The Wikipedia extraction in the beginning is able to get a lot of get, a lot of results, but then, as expected, does not extrapolate too much in order to not get too many instances while the extraction process with the other two conditions stays alive for longer.",
            "Interestingly, for the time we sampled here using the web once is superior to being.",
            "To having it.",
            "Taking one by one, there's another interesting effect, namely that Vicki starts off with more iteration.",
            "This is be cause the Vicki is less noisy there.",
            "The extractor is of higher quality, so we end we limit the extract number of extraction in each iteration so that the number of correct extraction Vicki is first.",
            "So this is also an explanation for the web.",
            "Once being stronger than the dual approach in the first 9 iteration."
        ],
        [
            "Every display here.",
            "And in order to show that this actually leads to the possibility to reduce number of seats dramatically, we compared extraction processes from by using 10 seeds, initially 50 seeds or 100 seeds.",
            "And what we display here.",
            "I think this is hard to read, so this type of bar shows precision.",
            "This type of bar shows what we call a relative recall because we limit the number of possible expression for iteration, we call relative recall what means.",
            "Like relative to the maximum possible extractions at 1:00, correct extraction and one iteration and the F measure as the harmonic mean.",
            "Among these two values.",
            "You can see here is that in fact the only condition does not not extract anything at all, or just returns that NCS when when giving starting with 10 seeds.",
            "This is why I mark this as not cannot be taken seriously, because of course the precision is then a very high a similar effect we have here is basically the 50 seats return possible extra stuff, but it gets the extraction amount of extraction and the quality gets.",
            "Similar when starting with 100 seeds.",
            "So we have a development here and at the same.",
            "Yeah, this is basically tells us that we are able to reduce the number of seats with this."
        ],
        [
            "Method so as a conclusion.",
            "The.",
            "What we did is we analyzed why our extraction methods are not transferred to Wikipedia.",
            "Because you took the two to the lack of redundancy.",
            "She introduced a method to still do it in order by using the web to retrieve further examples.",
            "And this generalizes to saying OK, we have a.",
            "We have a noisy data about rich data set and we have a data set which is not so noisy but not not rich enough and we can combine these two, and in particular it's interesting to see that we in this way can reduce the number of seats that we start."
        ],
        [
            "With.",
            "As an outline to further investigate this subject, I would propose to analyze further properties of the corpora in more detail to see how exactly these effect depends on size and some other characteristics.",
            "We could also add for the features of Wikipedia.",
            "For example, the categories to make the process more correct and it would be interesting to investigate over more iterations, which was the limit of which was here.",
            "Computational time because they're achieving this information from the web, was a little.",
            "Tigers and other things with similar like with the overall method would be to improve the efficiency through optimizing to do use optimized machine learning algorithms for the abstraction.",
            "We had a very simple one there.",
            "At the moment I'm using original linguistic information like part of speech or even semantic annotations.",
            "The one quote also what I did not get into that there's a lot of possible parameters in the system at the moment.",
            "One could have the system tune itself automatically at this point and would be very interesting to do is take negative examples into the process, but it's not easy to say what a relevant negative example for training here would be.",
            "So."
        ],
        [
            "Thank you for your attention and I'm open for questions.",
            "Thank you for this interesting.",
            "It's funny that you might experience required students as well, almost on the same lines.",
            "It's good to hear that other people.",
            "Same miserable results.",
            "Something interesting by prices, which is a pity.",
            "So there is another.",
            "I think.",
            "More helpful, almost smooth approach by Matthew.",
            "It's not for you.",
            "Happen tomorrow night.",
            "From the University of this book.",
            "Pink.",
            "So and then determining for each entity.",
            "The preceding and.",
            "Succeeding at words and generalized by that, and so it was not a given frame, but the frame itself was learned by the moving window approach and trainer.",
            "Very large purpose OK. And then the results.",
            "Better not not at all, really.",
            "Much better, and here it is so fixed that.",
            "That's that's an interesting comment.",
            "I mean, the as you correctly pointed out, the overall performance at this point is not not very high.",
            "We did not.",
            "Like we keep the experiment, these values fixed in order to have a complicated comparison anyway.",
            "We did experiments with different windows, Windows sizes and indeed, as you say it has a big impact on the quality of the extraction.",
            "Other persons.",
            "Or if I have couple of questions, you can use the web for to increase the seat set, but we have somehow fixed because the relations have you considered taking something like watermelon?",
            "Replace the names of the relations with some synonym left, for example, more versus group of and then you see whether this increases the scene.",
            "This is this improves what we value.",
            "That we could we could get the instances of the relation from another source in order to get bootstrapping status.",
            "Synonyms of the of the instances?",
            "Yeah, that would be.",
            "That would be an approach for improving the seat set.",
            "Also, yes, that's true.",
            "Perhaps Christian?",
            "By this this desire was that person.",
            "So one thing the other thing was, without showing this kid needs to increase the number of our hypothesis which are rejected.",
            "So one thing that occurs is to type the arguments of these relations and look to see whether or not there are classes of arguments which are.",
            "Google is giving classes.",
            "Sure, seats on which he talking my window or not.",
            "You can restrict the misalignments or you instances, or do parents to be all the same classes or classes which are widely represented.",
            "Of course you need some sort of construction.",
            "Yeah, that's important issue.",
            "I have read literature on that that is an effect of very, very effective way of increasing the quality of your extraction.",
            "If you have a semantic annotations for which type can be there, there's other things.",
            "For example, if you have want to learn which cities are located in which country, you can make assumptions like saying OK each citizen only in one country, or you can make assumption that each person's only burn one.",
            "One year or something like that.",
            "This is also.",
            "Yeah, increases the quality a lot.",
            "This is what we hope for.",
            "This is why we're not crying when we see these.",
            "These results because we kind of have the hope that As for a particular application, we would be able to introduce these things, we refrain from this here to keep the general.",
            "Keep the approach of the general because we did not have the information for all relations that we were considering.",
            "But thanks for this comment.",
            "Other persons.",
            "This is not the case, so we can run without breaking it.",
            "Thank again our speaker."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sparseness and these guys are passing through everything so now and Sebastian is stored in there.",
                    "label": 0
                },
                {
                    "sent": "Thanks for the introduction and welcome to my talk.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the goal that we aiming at is extracting information from large data set.",
                    "label": 0
                },
                {
                    "sent": "There's a couple of sub task information extraction, one of them being extracting named entities or identifying them entities, then extracting relations among entities in the text.",
                    "label": 1
                },
                {
                    "sent": "And there's others like treatment of reference and more higher level tasks like learning ontologies or other.",
                    "label": 0
                },
                {
                    "sent": "Kind of knowledge that might be there and for extraction of relations there's two types of methods that is being applied, one of them being statistical classifiers.",
                    "label": 0
                },
                {
                    "sent": "Given a set of sentences that are kind of candidates for the classification before for mentioning a given relation, you classify them.",
                    "label": 0
                },
                {
                    "sent": "In doing so, I'm not doing so, and the other one is applying textural patterns and on large collection.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we have the second collection becausw on for the second message.",
                    "label": 0
                },
                {
                    "sent": "Then we using patterns be cause.",
                    "label": 0
                },
                {
                    "sent": "It of the possibility to efficiently matching them on large datasets.",
                    "label": 0
                },
                {
                    "sent": "And because we don't have enough training data to train classifiers.",
                    "label": 0
                },
                {
                    "sent": "So when you do pattern based extractions there is.",
                    "label": 0
                },
                {
                    "sent": "There's a couple of assumptions that you make, in particular that the occurrences of the relation instances are in some sense regular, so that the occurrences have something in common and the other assumption that is being made is that there's a redundancy in that, because if you limit yourself to a given number of patterns, then you still want to have a large coverage.",
                    "label": 0
                },
                {
                    "sent": "And also for the induction of the patterns, the redundancy is an important issue is also in the moment.",
                    "label": 0
                },
                {
                    "sent": "There's like the basic paradigms, either taking a set of given set of fixed patterns or inducing yourself textural patterns to learn and data sources are usually large corpora, largeness being required by these assumptions, or even the web, and for coming up with these patterns, either bootstrapping methods are being applied, or and usually in combination with with learning.",
                    "label": 0
                },
                {
                    "sent": "Bottom up from textual occurrences.",
                    "label": 0
                },
                {
                    "sent": "There are other options like modeling tax in vector space model, but this is not what we do here.",
                    "label": 0
                },
                {
                    "sent": "So for the purpose of this talk you can think of this as having textual occurrences in which instances of relational curve.",
                    "label": 0
                },
                {
                    "sent": "Here we have the city is located in country relation and we have the sentence is the happiest people in Germany live in Oxnard.",
                    "label": 1
                },
                {
                    "sent": "The richest people in America live in Hollywood and.",
                    "label": 1
                },
                {
                    "sent": "Patterns generated by identifying the slot fillers and replacing the occurrences by wildcards and abstracting over at other parts of texture occurrences.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So again, given these assumptions, the problem that we are facing when going away from the web as a really huge data set to Vicky Pedia, what we're using in our scenario is that we've found out that redundancy is not that much present.",
                    "label": 0
                },
                {
                    "sent": "Wikipedia, because it's a high quality edited thing where people take care not to repeat themselves too often.",
                    "label": 0
                },
                {
                    "sent": "And our goal and what we achieved in this study is that we use the web as a background knowledge to help the system boot strip.",
                    "label": 1
                },
                {
                    "sent": "And we show that we can.",
                    "label": 0
                },
                {
                    "sent": "This adding the web as an abstraction source is equivalent to adding much more training samples of the process which we are trying to avoid because coming up with training samples in our.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Setting is very expensive.",
                    "label": 0
                },
                {
                    "sent": "So as of the outside of my talk, it's got a generic I'll demonstrate quickly the general method, then compare why it does not work on Wikipedia, like it works on the web, I'll show our integration methods and expose.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Mental evaluation before concluding.",
                    "label": 0
                },
                {
                    "sent": "So what is what we are trying to extract?",
                    "label": 0
                },
                {
                    "sent": "We have your typical Wikipedia page and what we know what we make as an assumption.",
                    "label": 0
                },
                {
                    "sent": "What other people have done in the past as well.",
                    "label": 0
                },
                {
                    "sent": "Is that relevant relations of the instances instance in question.",
                    "label": 0
                },
                {
                    "sent": "So this is Google kind of fish.",
                    "label": 0
                },
                {
                    "sent": "Is that like, relevant relations are in the links that are on that page, and in particular we then want to use the context of these links in order to identify what type of relation is there with these.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thanks.",
                    "label": 0
                },
                {
                    "sent": "So the message that we.",
                    "label": 0
                },
                {
                    "sent": "That we use is we start with a couple of examples.",
                    "label": 0
                },
                {
                    "sent": "This is really a very small set of examples, say 10 or something.",
                    "label": 0
                },
                {
                    "sent": "'cause this is the knowledge we actually want to learn.",
                    "label": 0
                },
                {
                    "sent": "We don't want to give too much information in it because we want to learn a lot of different relations.",
                    "label": 0
                },
                {
                    "sent": "So we start like, say with some types of fish is and where the habitat is and look at that Wikipedia pages in order to extract the context in which they occur.",
                    "label": 0
                },
                {
                    "sent": "We learn patterns from that match those again on Wikipedia pages.",
                    "label": 0
                },
                {
                    "sent": "In order to obtain a larger set of instances which then can be fed back into the process in order to iteratively extract more information.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the bootstrapping effect that is behind this is that you start with a couple of instances.",
                    "label": 1
                },
                {
                    "sent": "They give you look in which contexts they appear you extract from them by creating printing, edit, adding further further instances which lead to further patterns and then.",
                    "label": 0
                },
                {
                    "sent": "You can repeat this until you have sufficiently much information.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The unfortunate thing is that is not that redundant corpus, as Wikipedia.",
                    "label": 0
                },
                {
                    "sent": "This is kind of quenched 'cause you get context from your first instances.",
                    "label": 0
                },
                {
                    "sent": "You can create patterns from that, which again give you more instances.",
                    "label": 0
                },
                {
                    "sent": "But as these instances occur only once or twice in the text, when you look in which context they occur, you can get back to the context that you had before, and that you cannot start to get further patterns and.",
                    "label": 0
                },
                {
                    "sent": "The duck.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And it kind of stopped.",
                    "label": 0
                },
                {
                    "sent": "So we quantified this effect and look how often given relation pair for a couple of tests example occur in Wikipedia in total, and there's one of these nearly power law curves again, and they kind of show that there's some which occur very frequently and in the web, like even the median is that relation instances occur rather often, but.",
                    "label": 0
                },
                {
                    "sent": "On Wikipedia, the median is about 15 times the things mentioned, and as we restrict the link title pairs in our current experiments, this is this number even much lower so that you can assume that maybe between two or three times it given relation instances mentioned, and this is not only to the web, Wikipedia being a small subset of the web, but also due to the fact that isn't collection which is not redundant in the sense that effects are not repeated very often.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what we are now trying to do is to use the less precise information from the web as a as background, background information, kind of to get the bootstrapping started, but then not using it as the output as we assume that Wikipedia is much more precise, so.",
                    "label": 0
                },
                {
                    "sent": "What we would like to do, I compare now three conditions that we use in our experiments is like the basic process would be finding seeds on the weekly learning patterns from them, matching them on the week in order to get more instances, and then this arrow is kind of not on the picture, then repeating it intuitively in the further process we add the web to the process.",
                    "label": 1
                },
                {
                    "sent": "As in doing the extraction first on the web.",
                    "label": 1
                },
                {
                    "sent": "Then filtering to keep only what is also present in the wiki, match these this information here find patterns there and then go back to extract with the learned information from the wiki.",
                    "label": 0
                },
                {
                    "sent": "Further in from instances from the web kind of doing dual extraction process here and we have an intermediate step where we do the instruct extraction from the web.",
                    "label": 0
                },
                {
                    "sent": "Once in the beginning to start bootstrapping and then loop over further web.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Struction iterations, so this visualized again in a different way to do will approach with the first adding looking for context context on the web, learning patterns, matching them to get instances, filter for the presence in the wiki.",
                    "label": 0
                },
                {
                    "sent": "And get further context then on the wiki matching the information before.",
                    "label": 0
                },
                {
                    "sent": "Adding further instances in the matching step and then you can reiterate this as many times as you like.",
                    "label": 0
                },
                {
                    "sent": "Then like this is of course only the longer version of the initial approach, which would basically being only doing.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On the wiki and the.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Intermediate web Ones option would just do the 1st.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Step one.",
                    "label": 0
                },
                {
                    "sent": "We tested this extraction processes on 7.",
                    "label": 0
                },
                {
                    "sent": "Non taxonomic relations, namely musicians and the album step.",
                    "label": 1
                },
                {
                    "sent": "They published persons in the year of birth countries and their currencies, companies and their headquarters cities, in which country they lie, product names and make us where we were limited there to the automotive domain and sports persons in the country they come from.",
                    "label": 1
                },
                {
                    "sent": "These creations are varying in different aspects.",
                    "label": 0
                },
                {
                    "sent": "For example in size we extracted from some reliable sources.",
                    "label": 0
                },
                {
                    "sent": "Large lists of inst.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is to test them and So what we did is look over the Internet iterations.",
                    "label": 0
                },
                {
                    "sent": "How many correct extractions there were, and as we can see here.",
                    "label": 1
                },
                {
                    "sent": "The Wikipedia extraction in the beginning is able to get a lot of get, a lot of results, but then, as expected, does not extrapolate too much in order to not get too many instances while the extraction process with the other two conditions stays alive for longer.",
                    "label": 0
                },
                {
                    "sent": "Interestingly, for the time we sampled here using the web once is superior to being.",
                    "label": 1
                },
                {
                    "sent": "To having it.",
                    "label": 0
                },
                {
                    "sent": "Taking one by one, there's another interesting effect, namely that Vicki starts off with more iteration.",
                    "label": 1
                },
                {
                    "sent": "This is be cause the Vicki is less noisy there.",
                    "label": 0
                },
                {
                    "sent": "The extractor is of higher quality, so we end we limit the extract number of extraction in each iteration so that the number of correct extraction Vicki is first.",
                    "label": 0
                },
                {
                    "sent": "So this is also an explanation for the web.",
                    "label": 0
                },
                {
                    "sent": "Once being stronger than the dual approach in the first 9 iteration.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Every display here.",
                    "label": 0
                },
                {
                    "sent": "And in order to show that this actually leads to the possibility to reduce number of seats dramatically, we compared extraction processes from by using 10 seeds, initially 50 seeds or 100 seeds.",
                    "label": 1
                },
                {
                    "sent": "And what we display here.",
                    "label": 0
                },
                {
                    "sent": "I think this is hard to read, so this type of bar shows precision.",
                    "label": 0
                },
                {
                    "sent": "This type of bar shows what we call a relative recall because we limit the number of possible expression for iteration, we call relative recall what means.",
                    "label": 0
                },
                {
                    "sent": "Like relative to the maximum possible extractions at 1:00, correct extraction and one iteration and the F measure as the harmonic mean.",
                    "label": 0
                },
                {
                    "sent": "Among these two values.",
                    "label": 0
                },
                {
                    "sent": "You can see here is that in fact the only condition does not not extract anything at all, or just returns that NCS when when giving starting with 10 seeds.",
                    "label": 0
                },
                {
                    "sent": "This is why I mark this as not cannot be taken seriously, because of course the precision is then a very high a similar effect we have here is basically the 50 seats return possible extra stuff, but it gets the extraction amount of extraction and the quality gets.",
                    "label": 0
                },
                {
                    "sent": "Similar when starting with 100 seeds.",
                    "label": 0
                },
                {
                    "sent": "So we have a development here and at the same.",
                    "label": 0
                },
                {
                    "sent": "Yeah, this is basically tells us that we are able to reduce the number of seats with this.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Method so as a conclusion.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "What we did is we analyzed why our extraction methods are not transferred to Wikipedia.",
                    "label": 0
                },
                {
                    "sent": "Because you took the two to the lack of redundancy.",
                    "label": 0
                },
                {
                    "sent": "She introduced a method to still do it in order by using the web to retrieve further examples.",
                    "label": 1
                },
                {
                    "sent": "And this generalizes to saying OK, we have a.",
                    "label": 1
                },
                {
                    "sent": "We have a noisy data about rich data set and we have a data set which is not so noisy but not not rich enough and we can combine these two, and in particular it's interesting to see that we in this way can reduce the number of seats that we start.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "With.",
                    "label": 0
                },
                {
                    "sent": "As an outline to further investigate this subject, I would propose to analyze further properties of the corpora in more detail to see how exactly these effect depends on size and some other characteristics.",
                    "label": 1
                },
                {
                    "sent": "We could also add for the features of Wikipedia.",
                    "label": 1
                },
                {
                    "sent": "For example, the categories to make the process more correct and it would be interesting to investigate over more iterations, which was the limit of which was here.",
                    "label": 0
                },
                {
                    "sent": "Computational time because they're achieving this information from the web, was a little.",
                    "label": 0
                },
                {
                    "sent": "Tigers and other things with similar like with the overall method would be to improve the efficiency through optimizing to do use optimized machine learning algorithms for the abstraction.",
                    "label": 0
                },
                {
                    "sent": "We had a very simple one there.",
                    "label": 0
                },
                {
                    "sent": "At the moment I'm using original linguistic information like part of speech or even semantic annotations.",
                    "label": 0
                },
                {
                    "sent": "The one quote also what I did not get into that there's a lot of possible parameters in the system at the moment.",
                    "label": 0
                },
                {
                    "sent": "One could have the system tune itself automatically at this point and would be very interesting to do is take negative examples into the process, but it's not easy to say what a relevant negative example for training here would be.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Thank you for your attention and I'm open for questions.",
                    "label": 1
                },
                {
                    "sent": "Thank you for this interesting.",
                    "label": 0
                },
                {
                    "sent": "It's funny that you might experience required students as well, almost on the same lines.",
                    "label": 0
                },
                {
                    "sent": "It's good to hear that other people.",
                    "label": 0
                },
                {
                    "sent": "Same miserable results.",
                    "label": 0
                },
                {
                    "sent": "Something interesting by prices, which is a pity.",
                    "label": 0
                },
                {
                    "sent": "So there is another.",
                    "label": 0
                },
                {
                    "sent": "I think.",
                    "label": 0
                },
                {
                    "sent": "More helpful, almost smooth approach by Matthew.",
                    "label": 0
                },
                {
                    "sent": "It's not for you.",
                    "label": 0
                },
                {
                    "sent": "Happen tomorrow night.",
                    "label": 0
                },
                {
                    "sent": "From the University of this book.",
                    "label": 0
                },
                {
                    "sent": "Pink.",
                    "label": 0
                },
                {
                    "sent": "So and then determining for each entity.",
                    "label": 0
                },
                {
                    "sent": "The preceding and.",
                    "label": 0
                },
                {
                    "sent": "Succeeding at words and generalized by that, and so it was not a given frame, but the frame itself was learned by the moving window approach and trainer.",
                    "label": 0
                },
                {
                    "sent": "Very large purpose OK. And then the results.",
                    "label": 0
                },
                {
                    "sent": "Better not not at all, really.",
                    "label": 0
                },
                {
                    "sent": "Much better, and here it is so fixed that.",
                    "label": 0
                },
                {
                    "sent": "That's that's an interesting comment.",
                    "label": 0
                },
                {
                    "sent": "I mean, the as you correctly pointed out, the overall performance at this point is not not very high.",
                    "label": 0
                },
                {
                    "sent": "We did not.",
                    "label": 0
                },
                {
                    "sent": "Like we keep the experiment, these values fixed in order to have a complicated comparison anyway.",
                    "label": 0
                },
                {
                    "sent": "We did experiments with different windows, Windows sizes and indeed, as you say it has a big impact on the quality of the extraction.",
                    "label": 0
                },
                {
                    "sent": "Other persons.",
                    "label": 0
                },
                {
                    "sent": "Or if I have couple of questions, you can use the web for to increase the seat set, but we have somehow fixed because the relations have you considered taking something like watermelon?",
                    "label": 0
                },
                {
                    "sent": "Replace the names of the relations with some synonym left, for example, more versus group of and then you see whether this increases the scene.",
                    "label": 0
                },
                {
                    "sent": "This is this improves what we value.",
                    "label": 0
                },
                {
                    "sent": "That we could we could get the instances of the relation from another source in order to get bootstrapping status.",
                    "label": 0
                },
                {
                    "sent": "Synonyms of the of the instances?",
                    "label": 0
                },
                {
                    "sent": "Yeah, that would be.",
                    "label": 0
                },
                {
                    "sent": "That would be an approach for improving the seat set.",
                    "label": 0
                },
                {
                    "sent": "Also, yes, that's true.",
                    "label": 0
                },
                {
                    "sent": "Perhaps Christian?",
                    "label": 0
                },
                {
                    "sent": "By this this desire was that person.",
                    "label": 0
                },
                {
                    "sent": "So one thing the other thing was, without showing this kid needs to increase the number of our hypothesis which are rejected.",
                    "label": 0
                },
                {
                    "sent": "So one thing that occurs is to type the arguments of these relations and look to see whether or not there are classes of arguments which are.",
                    "label": 0
                },
                {
                    "sent": "Google is giving classes.",
                    "label": 0
                },
                {
                    "sent": "Sure, seats on which he talking my window or not.",
                    "label": 0
                },
                {
                    "sent": "You can restrict the misalignments or you instances, or do parents to be all the same classes or classes which are widely represented.",
                    "label": 0
                },
                {
                    "sent": "Of course you need some sort of construction.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that's important issue.",
                    "label": 0
                },
                {
                    "sent": "I have read literature on that that is an effect of very, very effective way of increasing the quality of your extraction.",
                    "label": 0
                },
                {
                    "sent": "If you have a semantic annotations for which type can be there, there's other things.",
                    "label": 0
                },
                {
                    "sent": "For example, if you have want to learn which cities are located in which country, you can make assumptions like saying OK each citizen only in one country, or you can make assumption that each person's only burn one.",
                    "label": 0
                },
                {
                    "sent": "One year or something like that.",
                    "label": 0
                },
                {
                    "sent": "This is also.",
                    "label": 0
                },
                {
                    "sent": "Yeah, increases the quality a lot.",
                    "label": 0
                },
                {
                    "sent": "This is what we hope for.",
                    "label": 0
                },
                {
                    "sent": "This is why we're not crying when we see these.",
                    "label": 0
                },
                {
                    "sent": "These results because we kind of have the hope that As for a particular application, we would be able to introduce these things, we refrain from this here to keep the general.",
                    "label": 0
                },
                {
                    "sent": "Keep the approach of the general because we did not have the information for all relations that we were considering.",
                    "label": 0
                },
                {
                    "sent": "But thanks for this comment.",
                    "label": 0
                },
                {
                    "sent": "Other persons.",
                    "label": 0
                },
                {
                    "sent": "This is not the case, so we can run without breaking it.",
                    "label": 0
                },
                {
                    "sent": "Thank again our speaker.",
                    "label": 0
                }
            ]
        }
    }
}