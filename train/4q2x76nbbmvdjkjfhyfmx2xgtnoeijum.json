{
    "id": "4q2x76nbbmvdjkjfhyfmx2xgtnoeijum",
    "title": "A Random Forest Approach to Segmenting and Classifying Gestures",
    "info": {
        "presenter": [
            "Ajjen Joshi, Boston University"
        ],
        "published": "July 2, 2015",
        "recorded": "May 2015",
        "category": [
            "Top->Computer Science->Computer Vision",
            "Top->Computer Science->Computer Vision->Face & Gesture Analysis"
        ]
    },
    "url": "http://videolectures.net/fgconference2015_joshi_classifying_gestures/",
    "segmentation": [
        [
            "Thank you.",
            "So my name is Arjun Joshi.",
            "I'm a PhD student at Boston University's.",
            "Department computer science where I work with doctors Margaret, Becky and Stan Square off at the image and video computing research group.",
            "And the title of this work is a random forest approach to segmenting and classifying gestures."
        ],
        [
            "So let me begin by just giving a very Canonical definition of a gesture so the Oxford English Dictionary defines a gesture as a movement of part of the body, especially a hand or the head to express some idea or meaning.",
            "OK, to motivate this work in terms of the datasets that I work with here."
        ],
        [
            "Example of a gesture.",
            "These gestures are used by officers on an aircraft carrier to communicate with pilots, and they do this to facilitate the landing, takeoff, and taxiing of aircraft on board an aircraft carrier.",
            "So equipping unmanned air vehicles with computer vision systems capable of recognizing these gestures will enable them to be integrated, integrated into this current system.",
            "So here's an example of an Italian cultural gesture and understanding social cultural gestures have many, many applications because these gestures contain a lot of contextual information."
        ],
        [
            "OK, so let me just differentiate gesture spotting from gesture recognition.",
            "So spotting is the process by which you take in continuous inputs such as video and you output the start and end points of a gesture whereas gesture recognition is the process of taking an already segmented gesture and outputing a class label.",
            "So spotting and recognition can be done simultaneously which is what we attempt to do.",
            "Or it can be done sequentially were recognition.",
            "Follow spotting."
        ],
        [
            "So given the intro, I want to define the problem that I'm trying to solve.",
            "Given training set of multimodal videos with multiple examples of all gestures in a gesture vocabulary, I want to design A framework that is capable of automatically an accurately spotting as well as classifying gestures present in a separate set of test videos OK?"
        ],
        [
            "So obviously there's been a lot of work done in gesture recognition over the years, and here I list a few popular paradigms, so we've seen generative graphical models like HMM have been very popular in modeling temporal sequences such as speech and gestures.",
            "More recently, discriminative graphical models like hidden conditional random fields have been used to good effect to solve this problem.",
            "Their examples of other discriminative models that do not explicitly model the temporal nature of and gestures, but still work fairly well, so examples of this are some framework using binary classifiers like support vector machines or multiple multiclass classifier and samples such as random forest, which is what we use."
        ],
        [
            "OK, so a brief review of what random forests are.",
            "Random forests are just a collection of independent Lee build decision trees.",
            "Each decision tree is trained on a bootstrap sample of the training set.",
            "At each node, you select randomly a subset of all available features an from this randomly selected subset, you select the feature that best separates the data."
        ],
        [
            "And we use the information gain criterion to measure the goodness of a split information gain.",
            "Basically just measures the difference in entropy before an after a split.",
            "A."
        ],
        [
            "Yeah, so random forests have been used to good effect in many problems.",
            "In computer vision such as human pose recognition, object segmentation, image classification, but not so much in the classification of temporal data such as gestures.",
            "OK."
        ],
        [
            "So here I'd like to describe.",
            "In basic words, the framework that I'm using.",
            "So here's an example of a gesture.",
            "So."
        ],
        [
            "Gestures are just a sequence of images."
        ],
        [
            "This gesture sequence can be divided into a number of sub gestural sequences, each of which represents a discriminative part of the gesture."
        ],
        [
            "So we can compute feature descriptors for each of these sub sequences and then combine and combine them to."
        ],
        [
            "Form our final feature descriptor so the number of divisions that we want to make basically depends on the nature of the data set that we are working with.",
            "An can be empirically determined."
        ],
        [
            "OK.",
            "So I'd like to say a few words about how the model is trained and just to clarify segmentation and classification.",
            "Ground truth values are provided with the training data.",
            "So the training data consists of temporally segmented examples of gestures of all classes of the gesture vocabulary, as well as a randomly selected set of the non gesture class.",
            "So if there are any classes in the vocabulary we want to train an N plus one class classifier."
        ],
        [
            "And since we are working with a multimodal visual data, we have access to both RGB image data as well as a skeletal information so we can extract both joined based features and image based features from all frames.",
            "So the join based features that we use our normalized positional coordinates of joints, their rotation angles as well as their derivatives.",
            "Now the joint based features encode the spatial dynamics of how the gesture is performed, but sometimes the spatial dynamics in itself are not enough for pairs of gestures that are very similar in movement but different hand shape.",
            "So in order to encode handshape information, we compute hog features on boxes centered around the left and right arms."
        ],
        [
            "So for each frame we compute joint based features as well as imageries features and combine them to form our final descriptor.",
            "So you can think of each gesture as being represented by a matrix where each row corresponds to the number of frames or images that make up the gesture, and each column corresponds to the feature.",
            "We smooth this matrix to remove some effects of noise, and like I described previously, we divide."
        ],
        [
            "This matrix into equal size temporal segments for each temple segment, we select the median value for each each column and then concatenate them to form our final feature descriptor.",
            "So after we have computed feature descriptors for all the samples in our training set, we train our N plus one class random forest classifier.",
            "Now it's very hot."
        ],
        [
            "It's very difficult for.",
            "For a classifier to model the set of non gestures by taking just an initial random sample set of non gesture examples.",
            "So in order to strengthen the capacity of the models to recognize the non gesture or background class what we do is we run the model on the continuous input of the training set itself using a sliding window mechanism.",
            "So using a sliding window at multiple temporal scales, we apply our train model.",
            "Anne."
        ],
        [
            "We get instances where the model fails so.",
            "By collecting the set of instances where our model fails to correctly classify, we can collect this set an add it to our original training set, and using this augmented training set."
        ],
        [
            "We can retrain our random forest.",
            "So we do this for several iterations until the number of misclassifications fall below a certain threshold and we are satisfied with our classifier."
        ],
        [
            "OK, in order to test our classifier, we again extract the same set of features from every frame of our test video and use the same multi scale sliding window classification framework.",
            "So within a buffer of a certain length, we create gestural candidates at.",
            "Different temporal skills and select the gestural candidate that is classified with the highest confidence.",
            "Using on Mac suppression.",
            "By classifier confidence in this framework I just mean the percentage of trees and that vote for that particular class."
        ],
        [
            "OK.",
            "So I'd like to speak a few words about the datasets that I work with.",
            "The net OPS data set stands for national stands for Naval Air Training and operating procedures standardization.",
            "It consists of 24 unique aircraft handling signals performed by 20 subjects, each subject performing each signal 20 times and the data set includes color images, depth Maps, mask images as well as skeletal information."
        ],
        [
            "The second data set that I worked with is called the Children data Set.",
            "It consists of 20 unique Italian cultural, an anthropological science, and the data set has been divided nicely into separate development, validation and test sets.",
            "Likewise, this data set also includes RGB images DEF Maps.",
            "Mask images and schedule information."
        ],
        [
            "OK.",
            "So now I'd like to describe the results of my experiments on these datasets.",
            "Just to clarify, we only test our classification framework on the natops data set because of the absence of realistic continuous data for the children data set.",
            "We test both our classification and segmentation framework."
        ],
        [
            "So here's the confusion matrix that describes the accuracy of applying our classifier on the network data set.",
            "We get an accuracy of around 87% when averaged across all gestures and subjects.",
            "As you can see with the by the strong diagonal."
        ],
        [
            "So 1 interesting Part 1 interesting aspect of this data set is that there are certain pairs of gestures that are very similar in motion but only differ in hand shape.",
            "So for example, you can see gesture two, sorry.",
            "Gesture two consists of the user performing.",
            "Something like this and gesture three consists of a user performing something like this and the only way in which they differ is that the user is either using a thumbs up or thumbs down.",
            "So for the."
        ],
        [
            "Challenging subset of gestures.",
            "We get an average classification accuracy of around 88%, which is slightly more than.",
            "The accuracy achieved by different variants of HMMS and HCR apps."
        ],
        [
            "For the children data set, this is a confusion matrix that displays our classification accuracy.",
            "We get an average accuracy of nearly 89%.",
            "OK, so in."
        ],
        [
            "In order to evaluate.",
            "The Classifier's performance in both segmentation classification.",
            "We use something called the Jaccard score.",
            "The Jaccard score is basically just an intersection over union metric.",
            "And our classifier gets a Jaccard score of 0.68 on the children data set and the state of the art for this data set is actually very impressive.",
            "0.8 Four that is achieved by predictably using a deep net."
        ],
        [
            "OK, so to conclude, we have presented a simple and efficient random force framework.",
            "It's a reliable classifier that generalizes well to the size of the user, the distance of the user to the sensor.",
            "As well as the speed at which the gesture is performed by the user, we will also realize that the task of simultaneously detecting and classifying gestures is more difficult challenge than solely classifying correctly segmented gestures, and we've found ways to improve the score either by spending more time on engineering better features using more granular Templar scares temporal skills.",
            "At the expense of speed or using a cascade approach where you have very trained binary classifier to do the segmentation, Anna multiple multiclass classifier to do the classification.",
            "Thank."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "So my name is Arjun Joshi.",
                    "label": 0
                },
                {
                    "sent": "I'm a PhD student at Boston University's.",
                    "label": 0
                },
                {
                    "sent": "Department computer science where I work with doctors Margaret, Becky and Stan Square off at the image and video computing research group.",
                    "label": 0
                },
                {
                    "sent": "And the title of this work is a random forest approach to segmenting and classifying gestures.",
                    "label": 1
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let me begin by just giving a very Canonical definition of a gesture so the Oxford English Dictionary defines a gesture as a movement of part of the body, especially a hand or the head to express some idea or meaning.",
                    "label": 0
                },
                {
                    "sent": "OK, to motivate this work in terms of the datasets that I work with here.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Example of a gesture.",
                    "label": 0
                },
                {
                    "sent": "These gestures are used by officers on an aircraft carrier to communicate with pilots, and they do this to facilitate the landing, takeoff, and taxiing of aircraft on board an aircraft carrier.",
                    "label": 0
                },
                {
                    "sent": "So equipping unmanned air vehicles with computer vision systems capable of recognizing these gestures will enable them to be integrated, integrated into this current system.",
                    "label": 0
                },
                {
                    "sent": "So here's an example of an Italian cultural gesture and understanding social cultural gestures have many, many applications because these gestures contain a lot of contextual information.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so let me just differentiate gesture spotting from gesture recognition.",
                    "label": 1
                },
                {
                    "sent": "So spotting is the process by which you take in continuous inputs such as video and you output the start and end points of a gesture whereas gesture recognition is the process of taking an already segmented gesture and outputing a class label.",
                    "label": 1
                },
                {
                    "sent": "So spotting and recognition can be done simultaneously which is what we attempt to do.",
                    "label": 0
                },
                {
                    "sent": "Or it can be done sequentially were recognition.",
                    "label": 0
                },
                {
                    "sent": "Follow spotting.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So given the intro, I want to define the problem that I'm trying to solve.",
                    "label": 0
                },
                {
                    "sent": "Given training set of multimodal videos with multiple examples of all gestures in a gesture vocabulary, I want to design A framework that is capable of automatically an accurately spotting as well as classifying gestures present in a separate set of test videos OK?",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So obviously there's been a lot of work done in gesture recognition over the years, and here I list a few popular paradigms, so we've seen generative graphical models like HMM have been very popular in modeling temporal sequences such as speech and gestures.",
                    "label": 0
                },
                {
                    "sent": "More recently, discriminative graphical models like hidden conditional random fields have been used to good effect to solve this problem.",
                    "label": 1
                },
                {
                    "sent": "Their examples of other discriminative models that do not explicitly model the temporal nature of and gestures, but still work fairly well, so examples of this are some framework using binary classifiers like support vector machines or multiple multiclass classifier and samples such as random forest, which is what we use.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so a brief review of what random forests are.",
                    "label": 1
                },
                {
                    "sent": "Random forests are just a collection of independent Lee build decision trees.",
                    "label": 0
                },
                {
                    "sent": "Each decision tree is trained on a bootstrap sample of the training set.",
                    "label": 1
                },
                {
                    "sent": "At each node, you select randomly a subset of all available features an from this randomly selected subset, you select the feature that best separates the data.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we use the information gain criterion to measure the goodness of a split information gain.",
                    "label": 1
                },
                {
                    "sent": "Basically just measures the difference in entropy before an after a split.",
                    "label": 0
                },
                {
                    "sent": "A.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yeah, so random forests have been used to good effect in many problems.",
                    "label": 1
                },
                {
                    "sent": "In computer vision such as human pose recognition, object segmentation, image classification, but not so much in the classification of temporal data such as gestures.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here I'd like to describe.",
                    "label": 0
                },
                {
                    "sent": "In basic words, the framework that I'm using.",
                    "label": 0
                },
                {
                    "sent": "So here's an example of a gesture.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Gestures are just a sequence of images.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This gesture sequence can be divided into a number of sub gestural sequences, each of which represents a discriminative part of the gesture.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we can compute feature descriptors for each of these sub sequences and then combine and combine them to.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Form our final feature descriptor so the number of divisions that we want to make basically depends on the nature of the data set that we are working with.",
                    "label": 0
                },
                {
                    "sent": "An can be empirically determined.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So I'd like to say a few words about how the model is trained and just to clarify segmentation and classification.",
                    "label": 0
                },
                {
                    "sent": "Ground truth values are provided with the training data.",
                    "label": 0
                },
                {
                    "sent": "So the training data consists of temporally segmented examples of gestures of all classes of the gesture vocabulary, as well as a randomly selected set of the non gesture class.",
                    "label": 0
                },
                {
                    "sent": "So if there are any classes in the vocabulary we want to train an N plus one class classifier.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And since we are working with a multimodal visual data, we have access to both RGB image data as well as a skeletal information so we can extract both joined based features and image based features from all frames.",
                    "label": 0
                },
                {
                    "sent": "So the join based features that we use our normalized positional coordinates of joints, their rotation angles as well as their derivatives.",
                    "label": 1
                },
                {
                    "sent": "Now the joint based features encode the spatial dynamics of how the gesture is performed, but sometimes the spatial dynamics in itself are not enough for pairs of gestures that are very similar in movement but different hand shape.",
                    "label": 0
                },
                {
                    "sent": "So in order to encode handshape information, we compute hog features on boxes centered around the left and right arms.",
                    "label": 1
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for each frame we compute joint based features as well as imageries features and combine them to form our final descriptor.",
                    "label": 0
                },
                {
                    "sent": "So you can think of each gesture as being represented by a matrix where each row corresponds to the number of frames or images that make up the gesture, and each column corresponds to the feature.",
                    "label": 0
                },
                {
                    "sent": "We smooth this matrix to remove some effects of noise, and like I described previously, we divide.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This matrix into equal size temporal segments for each temple segment, we select the median value for each each column and then concatenate them to form our final feature descriptor.",
                    "label": 1
                },
                {
                    "sent": "So after we have computed feature descriptors for all the samples in our training set, we train our N plus one class random forest classifier.",
                    "label": 1
                },
                {
                    "sent": "Now it's very hot.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It's very difficult for.",
                    "label": 0
                },
                {
                    "sent": "For a classifier to model the set of non gestures by taking just an initial random sample set of non gesture examples.",
                    "label": 0
                },
                {
                    "sent": "So in order to strengthen the capacity of the models to recognize the non gesture or background class what we do is we run the model on the continuous input of the training set itself using a sliding window mechanism.",
                    "label": 1
                },
                {
                    "sent": "So using a sliding window at multiple temporal scales, we apply our train model.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We get instances where the model fails so.",
                    "label": 0
                },
                {
                    "sent": "By collecting the set of instances where our model fails to correctly classify, we can collect this set an add it to our original training set, and using this augmented training set.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We can retrain our random forest.",
                    "label": 0
                },
                {
                    "sent": "So we do this for several iterations until the number of misclassifications fall below a certain threshold and we are satisfied with our classifier.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, in order to test our classifier, we again extract the same set of features from every frame of our test video and use the same multi scale sliding window classification framework.",
                    "label": 0
                },
                {
                    "sent": "So within a buffer of a certain length, we create gestural candidates at.",
                    "label": 0
                },
                {
                    "sent": "Different temporal skills and select the gestural candidate that is classified with the highest confidence.",
                    "label": 0
                },
                {
                    "sent": "Using on Mac suppression.",
                    "label": 0
                },
                {
                    "sent": "By classifier confidence in this framework I just mean the percentage of trees and that vote for that particular class.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So I'd like to speak a few words about the datasets that I work with.",
                    "label": 0
                },
                {
                    "sent": "The net OPS data set stands for national stands for Naval Air Training and operating procedures standardization.",
                    "label": 1
                },
                {
                    "sent": "It consists of 24 unique aircraft handling signals performed by 20 subjects, each subject performing each signal 20 times and the data set includes color images, depth Maps, mask images as well as skeletal information.",
                    "label": 1
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The second data set that I worked with is called the Children data Set.",
                    "label": 0
                },
                {
                    "sent": "It consists of 20 unique Italian cultural, an anthropological science, and the data set has been divided nicely into separate development, validation and test sets.",
                    "label": 1
                },
                {
                    "sent": "Likewise, this data set also includes RGB images DEF Maps.",
                    "label": 0
                },
                {
                    "sent": "Mask images and schedule information.",
                    "label": 1
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So now I'd like to describe the results of my experiments on these datasets.",
                    "label": 0
                },
                {
                    "sent": "Just to clarify, we only test our classification framework on the natops data set because of the absence of realistic continuous data for the children data set.",
                    "label": 0
                },
                {
                    "sent": "We test both our classification and segmentation framework.",
                    "label": 1
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's the confusion matrix that describes the accuracy of applying our classifier on the network data set.",
                    "label": 0
                },
                {
                    "sent": "We get an accuracy of around 87% when averaged across all gestures and subjects.",
                    "label": 0
                },
                {
                    "sent": "As you can see with the by the strong diagonal.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So 1 interesting Part 1 interesting aspect of this data set is that there are certain pairs of gestures that are very similar in motion but only differ in hand shape.",
                    "label": 0
                },
                {
                    "sent": "So for example, you can see gesture two, sorry.",
                    "label": 0
                },
                {
                    "sent": "Gesture two consists of the user performing.",
                    "label": 0
                },
                {
                    "sent": "Something like this and gesture three consists of a user performing something like this and the only way in which they differ is that the user is either using a thumbs up or thumbs down.",
                    "label": 0
                },
                {
                    "sent": "So for the.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Challenging subset of gestures.",
                    "label": 0
                },
                {
                    "sent": "We get an average classification accuracy of around 88%, which is slightly more than.",
                    "label": 1
                },
                {
                    "sent": "The accuracy achieved by different variants of HMMS and HCR apps.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For the children data set, this is a confusion matrix that displays our classification accuracy.",
                    "label": 1
                },
                {
                    "sent": "We get an average accuracy of nearly 89%.",
                    "label": 0
                },
                {
                    "sent": "OK, so in.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In order to evaluate.",
                    "label": 0
                },
                {
                    "sent": "The Classifier's performance in both segmentation classification.",
                    "label": 0
                },
                {
                    "sent": "We use something called the Jaccard score.",
                    "label": 1
                },
                {
                    "sent": "The Jaccard score is basically just an intersection over union metric.",
                    "label": 0
                },
                {
                    "sent": "And our classifier gets a Jaccard score of 0.68 on the children data set and the state of the art for this data set is actually very impressive.",
                    "label": 0
                },
                {
                    "sent": "0.8 Four that is achieved by predictably using a deep net.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so to conclude, we have presented a simple and efficient random force framework.",
                    "label": 1
                },
                {
                    "sent": "It's a reliable classifier that generalizes well to the size of the user, the distance of the user to the sensor.",
                    "label": 0
                },
                {
                    "sent": "As well as the speed at which the gesture is performed by the user, we will also realize that the task of simultaneously detecting and classifying gestures is more difficult challenge than solely classifying correctly segmented gestures, and we've found ways to improve the score either by spending more time on engineering better features using more granular Templar scares temporal skills.",
                    "label": 1
                },
                {
                    "sent": "At the expense of speed or using a cascade approach where you have very trained binary classifier to do the segmentation, Anna multiple multiclass classifier to do the classification.",
                    "label": 0
                },
                {
                    "sent": "Thank.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": []
        }
    }
}