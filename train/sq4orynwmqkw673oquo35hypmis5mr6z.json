{
    "id": "sq4orynwmqkw673oquo35hypmis5mr6z",
    "title": "Opportunistic Linked Data Querying through Approximate Membership Metadata",
    "info": {
        "author": [
            "Miel Vander Sande, Multimedia Lab, Ghent University"
        ],
        "published": "Nov. 10, 2015",
        "recorded": "October 2015",
        "category": [
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/iswc2015_vander_sande_data_querying/",
    "segmentation": [
        [
            "Alright, so this is the first talk of the afternoon, so let me start with."
        ],
        [
            "Small inspirational quote for everyone to enjoy.",
            "So if you would."
        ],
        [
            "If you solve a query for a client then it will be happy for a day, but if you teach a client to sparkle then it will query happily ever after.",
            "Well, since my historical facts are probably not as good or rather talk about."
        ],
        [
            "Approximate membership metadata and how we use that to actually improve querying on the client sites.",
            "So what I'm going to talk about since this is in the context of linked data fragments, I'm going to quickly explain that.",
            "Then I'm going to tell you how to find new trade offs on the linked data fragments access, and then move into approximate membership metadata and how we can use that to opportunistically."
        ],
        [
            "Mary"
        ],
        [
            "So let me get into it.",
            "So linked data publishing has mostly been a story of two extremes, right?",
            "You have on the one side you have data dumps which are highly available because they have low server costs.",
            "And on the other hand we have sparkle endpoints where you can query live data, but where the computer computational resources are very hard to predict.",
            "So they have some availability issues, but well has been largely unexplored as."
        ],
        [
            "The whole axis between these two and actually this is very interesting.",
            "What happens between the client and the server when doing stuff like querying?",
            "Can we make the server a little bit Dumber and the client a little bit smarter to get into these new tradeoffs that fit different use cases?",
            "And so this is actually the hunt for new tradeoffs?",
            "What can we learn?"
        ],
        [
            "And so let me explain first what link data fragments are so like data fragments is a universal view.",
            "It's a uniform view on all different linked data interfaces and so."
        ],
        [
            "Basically, every link data interface gives you back one specific fragment over link data set."
        ],
        [
            "So we can correct arise this in free steps being one the data.",
            "What do I get back which triples what is the metadata?",
            "What do I know about this fragment an to controls?",
            "How can I access new fragments?",
            "How can I get more data?"
        ],
        [
            "And so to prove this with an example, for example, the data dumps the data is obviously all the data set triples.",
            "The metadata can be file size, the name and so on.",
            "And there are large.",
            "There are not really controls in there because you cannot get more data than the data set itself and for."
        ],
        [
            "Sparkle the data is actually the result that you get when you execute a query, and in general there's not a lot of metadata in this response for the clients besides the actual results and the controls do not help you to form new queries."
        ],
        [
            "But let me explain you now how we can look for these new traders.",
            "How can we find new Datsun?"
        ],
        [
            "Axis, so in general you have this axis and we set to each other.",
            "Let's let's find a starting point somewhere so."
        ],
        [
            "We started with triple pattern fragments which allow you to have linked life data for high availability and low server costs, but at the same time when you want to access spark query from the client using the server that only accepts triple patterns, then you have high bandwidths.",
            "So there's just presented."
        ],
        [
            "Last year and in general this means a triple pattern fragment means that."
        ],
        [
            "Data is actually what matches the triple pattern and this can be paged.",
            "So the first 100 triples."
        ],
        [
            "Metadata includes this is the total count of matches and can."
        ],
        [
            "Rules allow you to go to new fragments.",
            "Of course, this is HTML.",
            "This is for humans, but we can."
        ],
        [
            "Do exactly the same thing from machines where we just explain in RDF.",
            "These are the controls.",
            "This is how you query."
        ],
        [
            "Triple pattern and this is the total number of matches in the metadata."
        ],
        [
            "So how do we actually do this query?",
            "Resolvement on the cloud?"
        ],
        [
            "And so we typically give sparkle query and you have over fragmente.",
            "We look into the fragments how to access the data sets."
        ],
        [
            "And then we use the metadata that we retrieve from the fragments to plan the query."
        ],
        [
            "So to give you an example, if I want all the names of the artists that were born in patawa."
        ],
        [
            "Then I just get all the."
        ],
        [
            "Fragments from all.",
            "Every triple pattern I get back the metadata."
        ],
        [
            "Select the most selective one.",
            "At the moment I get all the mappings for this variable artist and then I."
        ],
        [
            "Use these mappings to bind them to new to the other patterns and continue my queries element.",
            "But So what we?"
        ],
        [
            "Notice that when we do that, there is actually a pattern that keeps freak reoccurs quite a lot, and that is that most of the HTTP requests that we do are actually asking is this triple part of the data set, which is also known as a membership query, so you can see that.",
            "I mean we tried all the 20, what if queries because they span over a large number of query patterns, so we gotta.",
            "A nice viewed on this and we can see that actually for some types of queries this goes up to 95%, so 95% of all HTTP requests are actually these membership requests.",
            "And for some queries they have no membership requests at all."
        ],
        [
            "So how can we explore this new axis?",
            "So we started with triple pattern fragments and we can actually move into new dimensions being we can change the selector.",
            "Do we ask simpler questions or do we ask more complex questions or we can add new metadata?",
            "How much information that might be useful to the client to resend them?",
            "And so we started with triple threat effects movie.",
            "Notice that the bandwidth was actually way too high for some of the use cases that we have.",
            "So the question is, how do?"
        ],
        [
            "We improve that.",
            "So one thing that you could do is add stuff to the selector, make the selector more complex.",
            "For example substring search.",
            "You add this and you could improve some of the query clauses and this is actually the subject of the last talk in this session."
        ],
        [
            "Right, but today I mean this talk.",
            "Of course, today I'm going to talk about moving in a meta data dimension so approximate membership functions that we added."
        ],
        [
            "So."
        ],
        [
            "What is this approximate membership metadata?",
            "So we took the trip part of friends and we wondered what if we could have a compact representation of all the possible mappings of a certain variable.",
            "Then we can use that to locally rule out some of the membership."
        ],
        [
            "Requests, so we added the Bloom filter and column coded sets too.",
            "Are triple pattern fragments response?"
        ],
        [
            "And in general, these are techniques that give you an approximate assessment of whether an item is part of a set or not, and it has a fixed false, probably false positive probability, which means that to a certain extent you can have false positives, but you at least know what the probability is."
        ],
        [
            "So the question that we asked ourselves research wise was can we reduce the number of HTTP requests?",
            "Can we reduce the total execution time?",
            "But what is also the overhead on the server?",
            "Do we keep these good behavior of the server if we do this?"
        ],
        [
            "So in to shortly explain to you how Bloom filters work, so this is fixed bitmap of ambits."
        ],
        [
            "You want to insert an items."
        ],
        [
            "And with gay distinct hashes, you just calculate random positions in the bed."
        ],
        [
            "That you flip to one.",
            "You do this for every element and then.",
            "You send this to the client, for example, and this is where the client can just do the same operation.",
            "Calculate the hash is see whether the positions are flipped to one, and then decide whether this is in this data set or not.",
            "And all these parameters can be used to calculate a certain probability that false positive will occur, and then the same."
        ],
        [
            "Thing actually happens with column coded sets.",
            "It's very very similar so."
        ],
        [
            "It's also a bit more, but instead of several hashes, we're just going to use one."
        ],
        [
            "And this actually."
        ],
        [
            "Response to geometric distribution of all the bits."
        ],
        [
            "Which we then column codes to compress or bitmap in the end which is results overall in a more compact representation than Bloomfield."
        ],
        [
            "OK, So what we actually want to do with the meta data is enabled the client to be intelligent enough to avoid these membership requests over.",
            "We just described this in RDF.",
            "Hey, this is a Bloom filter with probability X and has function Y and it represents all the bindings of all the mappings for the subject for example."
        ],
        [
            "And what we do then is just instead of just getting all the mappings, for example from our former triple Pattern artists birthplace bhaderwah and bind them directly to our other pattern and just start asking the server."
        ],
        [
            "Instead, we're just going to get the parents fragment fur."
        ],
        [
            "1st and then."
        ],
        [
            "Look into the filter.",
            "Whether this still rule out all the negative ones."
        ],
        [
            "And so we evaluated this using 250 queries using 125 whatif templates.",
            "This was a dual service set up, one with Bloom filters, one with column coded sets.",
            "We use three types of probabilities.",
            "We set the query timeout with three minutes.",
            "We use the HTTP cache Anna Real world network delays.",
            "So because we are very interested in a web setting and 100 million triples datasets."
        ],
        [
            "And so we compared all the results with the vanilla triple pattern FRAGMENTE setup, so with no modifications at all and we tried to client algorithm.",
            "So the the very first greedy algorithm, the one that I explained and and also a recent optimized joint tree algorithm which was presented on ESWC."
        ],
        [
            "So what we notice is, is that actually more than 50% of of our queries get actually a good request reduction.",
            "We also see 30%, which has no effect at all.",
            "That's what we kind of expected, because a lot of query types are not affected by membership requests.",
            "We also have a small percentage being smaller than 20%, which actually have a higher request.",
            "Wait, but I will get into that later.",
            "And the percentage.",
            "So the P values the probabilities that we tried did not really show any.",
            "Huge difference, we got a slightly higher throughput for higher values, but not enough to really be significant."
        ],
        [
            "And then if we look at the queries that were actually affected by this is that the queries that have a high number of HTTP requests really benefit from this approach because they go up to 15,000 requests out of 45,000 requests that we can save, and the same also for the optimized algorithm, where actually the absolute number of requests is lower.",
            "In general we do.",
            "Get the same ratio, more or less of requests that we can save, and then if we look at the ones that actually have more requests than we're speaking in terms of 35 requests out of thousands of requests.",
            "So which is not that relevant."
        ],
        [
            "But then if we look at the execution time, this is actually something that we did not expect is that we have no speedup at all concerning execution time, so we actually notice that a third of our queries actually increases in time, so it actually takes longer to apply this, and one of the reasons is that one the questions are quite large.",
            "The fragments that are quite large take along time to compute.",
            "And also the transfer time to transfer this meta data over the wire takes a long time, but we have some conclusions on this which I come back to."
        ],
        [
            "And then if we look at the server, we actually see just an increase of below 6%.",
            "We also see that column coded sets or have a little bit less of an increase, more steady.",
            "That's also because they use just one hash function, which is a little bit easier on the serve."
        ],
        [
            "So let me move on to opportunistic querying so another additional question that we."
        ],
        [
            "Ask yourselves is like when we're doing query execution at a certain point in time, we will have all the results, but they won't be correct yet."
        ],
        [
            "So question was, can we be opportunistic here?",
            "Can are there use cases like applications that could benefit from having imprecise results?"
        ],
        [
            "And so if we look at the execution time, then we see that 100% recall, an 100% precision is actually distinct from each other and that we can actually move this a little bit forward.",
            "And I retract results when we reached 100% precision."
        ],
        [
            "And so an additional resource question that we had was can we reduce this?"
        ],
        [
            "And so in general, all of the tests that we did suffered from the same execution time problem, so we didn't really get a real speedup.",
            "But for the queries that did get a speedup, we notice that we could get to 1/3 of the execution time if we just look at 100% Rico, and in general because of the low probability, you only have to retract zero or one result, which would be very acceptable, and in some Apple."
        ],
        [
            "So let me wrap this."
        ],
        [
            "Yup, so approximate membership matter data.",
            "It's more like a nuanced debate.",
            "So we have some issues.",
            "That I discussed.",
            "So for some query types this is really handy because it can.",
            "Decrease the band Twitter Lawton triple pattern FRAGMENTE query."
        ],
        [
            "Quetion, but for larger fragments we have this issue that real time computation is more or less hurts the execution time, and So what we suggest is that we look into more pre caching an out of band delivery of these things."
        ],
        [
            "And then opportunistic querying is also a promising direction.",
            "If we were able to fix these."
        ],
        [
            "And then for my last slide, I just want to say something that I really think is important, that you remember from this talk is that this is just one part of the meta data, but in general the messages that none, no one size fits all we have really have to explore the axis of linked data publishing look at different things than the extremes that we already know and also find the metrics that fit your use case, which could be any application in general and look more at.",
            "What does HTTP?",
            "What's the impact on HTTP?",
            "What is the request response time and what is the load on the server and the client?",
            "And in general I would like to say that we should start serving link data like a parista where you just have this basic layer of for example triple pattern fragments and you just play with the different features that you want and can support and see what they can do for your client.",
            "Thank you."
        ],
        [
            "Yeah, I check on the demo."
        ],
        [
            "Many thanks for the wood presentation.",
            "We have time for one quest.",
            "Questions OK so.",
            "Thank you first of all, thank you for a very nice talk.",
            "I'm how much selling from a KSW University of Labs in Germany.",
            "Actually I I'm just wondering like the number of endpoints request was reduced from 45,000 to 15,000.",
            "Is it because of the benchmark you use becausw the water load?",
            "This benchmark, it doesn't.",
            "It's only basic graph patterns, it doesn't contain like more than one BGP, it doesn't contain the unions, it doesn't contain filters, so I was just wondering what will be the performance of this approach while you are trying on something different.",
            "Queries which has likes.",
            "From query logs with sparkle filters and all this stuff, why in general the membership requests come from are mostly a result of the joins that we do, so the basic graph patterns are really the first thing that caused it kind of thing.",
            "For filters and unions were definitely interested in stuff like that, but we haven't looked into benchmarks that really go into detail about this.",
            "We mostly focused on the.",
            "Query types that really produce these kinds of requests.",
            "We have time for another question.",
            "I have a question.",
            "If you could explain a little bit about how many triple patterns have your queries, because if you consider complex queries.",
            "Suppose you have 50 triple patterns.",
            "Would your approach work equally that you presented here?",
            "So.",
            "It basically depends on.",
            "I mean, it basically depends on how many membership requests this would produce, so it depends on the type of.",
            "Of the basic graph pattern, how many triple patterns?",
            "And there are, and it's mostly about how they're structured and how the in which join execution.",
            "But in the queries that you tested, how many triple patterns do you have?",
            "Average maximum was was 88.",
            "Yes, for the complex complex.",
            "OK, how large were the intermediate results?",
            "I would have to check I don't have the because that's something that may impact also right because in the results that you're presenting only you are showing the deployability of these files.",
            "Results are impacting in the performance or your approach, but probably you should consider all parameters As for example the number of triple patterns in your queries, the size of intermediate results.",
            "There are many many different parameters that need to be considered.",
            "I agree, but this I mean, I think this this was more about how feasible is it to ship this kind of metadata from the server to the client rather than really doing optimized query planning, which is more in the area that you're hinting at.",
            "But I definitely agree that this is something that we have to go towards.",
            "Any other question?",
            "OK.",
            "It's more about if there is do you don't mention anything about the cost of producing the metadata.",
            "For for the client, so it is something that you do on the fly.",
            "Or is this something that is precomputed somehow?",
            "Sorry, can you.",
            "Can you describe the kind of meta data that you return to the client to perform?",
            "Are these metadata produced on the fly, but the server?",
            "Or was the cost of eaten?",
            "So at the moment yes and we notice that.",
            "At a certain point, fragments get this large that it gets really inefficient to do that, and so two ways to fix that would be.",
            "Do somehow smartly pre cache this kind of stuff or precomputed.",
            "But also allow your client to be even smarter and choose when to download this metadata and when not to so it can decide it's too large.",
            "I will not do it.",
            "And that's why I'm talking about the out of band delivery where you do not include metadata in the fragment, but rather.",
            "Do the meta data that you just can download in a separate request, because these are is also a strong relation with the terminus of the data.",
            "So if you have data with that changes frequently this approach my might be affected by it, thank you.",
            "Listen mill for this good presentation."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so this is the first talk of the afternoon, so let me start with.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Small inspirational quote for everyone to enjoy.",
                    "label": 0
                },
                {
                    "sent": "So if you would.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you solve a query for a client then it will be happy for a day, but if you teach a client to sparkle then it will query happily ever after.",
                    "label": 0
                },
                {
                    "sent": "Well, since my historical facts are probably not as good or rather talk about.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Approximate membership metadata and how we use that to actually improve querying on the client sites.",
                    "label": 1
                },
                {
                    "sent": "So what I'm going to talk about since this is in the context of linked data fragments, I'm going to quickly explain that.",
                    "label": 0
                },
                {
                    "sent": "Then I'm going to tell you how to find new trade offs on the linked data fragments access, and then move into approximate membership metadata and how we can use that to opportunistically.",
                    "label": 1
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Mary",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let me get into it.",
                    "label": 0
                },
                {
                    "sent": "So linked data publishing has mostly been a story of two extremes, right?",
                    "label": 0
                },
                {
                    "sent": "You have on the one side you have data dumps which are highly available because they have low server costs.",
                    "label": 1
                },
                {
                    "sent": "And on the other hand we have sparkle endpoints where you can query live data, but where the computer computational resources are very hard to predict.",
                    "label": 0
                },
                {
                    "sent": "So they have some availability issues, but well has been largely unexplored as.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The whole axis between these two and actually this is very interesting.",
                    "label": 0
                },
                {
                    "sent": "What happens between the client and the server when doing stuff like querying?",
                    "label": 1
                },
                {
                    "sent": "Can we make the server a little bit Dumber and the client a little bit smarter to get into these new tradeoffs that fit different use cases?",
                    "label": 0
                },
                {
                    "sent": "And so this is actually the hunt for new tradeoffs?",
                    "label": 1
                },
                {
                    "sent": "What can we learn?",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so let me explain first what link data fragments are so like data fragments is a universal view.",
                    "label": 0
                },
                {
                    "sent": "It's a uniform view on all different linked data interfaces and so.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Basically, every link data interface gives you back one specific fragment over link data set.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we can correct arise this in free steps being one the data.",
                    "label": 0
                },
                {
                    "sent": "What do I get back which triples what is the metadata?",
                    "label": 0
                },
                {
                    "sent": "What do I know about this fragment an to controls?",
                    "label": 0
                },
                {
                    "sent": "How can I access new fragments?",
                    "label": 0
                },
                {
                    "sent": "How can I get more data?",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so to prove this with an example, for example, the data dumps the data is obviously all the data set triples.",
                    "label": 0
                },
                {
                    "sent": "The metadata can be file size, the name and so on.",
                    "label": 0
                },
                {
                    "sent": "And there are large.",
                    "label": 0
                },
                {
                    "sent": "There are not really controls in there because you cannot get more data than the data set itself and for.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sparkle the data is actually the result that you get when you execute a query, and in general there's not a lot of metadata in this response for the clients besides the actual results and the controls do not help you to form new queries.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But let me explain you now how we can look for these new traders.",
                    "label": 0
                },
                {
                    "sent": "How can we find new Datsun?",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Axis, so in general you have this axis and we set to each other.",
                    "label": 0
                },
                {
                    "sent": "Let's let's find a starting point somewhere so.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We started with triple pattern fragments which allow you to have linked life data for high availability and low server costs, but at the same time when you want to access spark query from the client using the server that only accepts triple patterns, then you have high bandwidths.",
                    "label": 0
                },
                {
                    "sent": "So there's just presented.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Last year and in general this means a triple pattern fragment means that.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Data is actually what matches the triple pattern and this can be paged.",
                    "label": 0
                },
                {
                    "sent": "So the first 100 triples.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Metadata includes this is the total count of matches and can.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Rules allow you to go to new fragments.",
                    "label": 0
                },
                {
                    "sent": "Of course, this is HTML.",
                    "label": 0
                },
                {
                    "sent": "This is for humans, but we can.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Do exactly the same thing from machines where we just explain in RDF.",
                    "label": 0
                },
                {
                    "sent": "These are the controls.",
                    "label": 0
                },
                {
                    "sent": "This is how you query.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Triple pattern and this is the total number of matches in the metadata.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how do we actually do this query?",
                    "label": 0
                },
                {
                    "sent": "Resolvement on the cloud?",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so we typically give sparkle query and you have over fragmente.",
                    "label": 0
                },
                {
                    "sent": "We look into the fragments how to access the data sets.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we use the metadata that we retrieve from the fragments to plan the query.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So to give you an example, if I want all the names of the artists that were born in patawa.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then I just get all the.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Fragments from all.",
                    "label": 0
                },
                {
                    "sent": "Every triple pattern I get back the metadata.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Select the most selective one.",
                    "label": 0
                },
                {
                    "sent": "At the moment I get all the mappings for this variable artist and then I.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Use these mappings to bind them to new to the other patterns and continue my queries element.",
                    "label": 0
                },
                {
                    "sent": "But So what we?",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Notice that when we do that, there is actually a pattern that keeps freak reoccurs quite a lot, and that is that most of the HTTP requests that we do are actually asking is this triple part of the data set, which is also known as a membership query, so you can see that.",
                    "label": 1
                },
                {
                    "sent": "I mean we tried all the 20, what if queries because they span over a large number of query patterns, so we gotta.",
                    "label": 0
                },
                {
                    "sent": "A nice viewed on this and we can see that actually for some types of queries this goes up to 95%, so 95% of all HTTP requests are actually these membership requests.",
                    "label": 1
                },
                {
                    "sent": "And for some queries they have no membership requests at all.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how can we explore this new axis?",
                    "label": 0
                },
                {
                    "sent": "So we started with triple pattern fragments and we can actually move into new dimensions being we can change the selector.",
                    "label": 1
                },
                {
                    "sent": "Do we ask simpler questions or do we ask more complex questions or we can add new metadata?",
                    "label": 1
                },
                {
                    "sent": "How much information that might be useful to the client to resend them?",
                    "label": 0
                },
                {
                    "sent": "And so we started with triple threat effects movie.",
                    "label": 0
                },
                {
                    "sent": "Notice that the bandwidth was actually way too high for some of the use cases that we have.",
                    "label": 0
                },
                {
                    "sent": "So the question is, how do?",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We improve that.",
                    "label": 0
                },
                {
                    "sent": "So one thing that you could do is add stuff to the selector, make the selector more complex.",
                    "label": 0
                },
                {
                    "sent": "For example substring search.",
                    "label": 0
                },
                {
                    "sent": "You add this and you could improve some of the query clauses and this is actually the subject of the last talk in this session.",
                    "label": 1
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right, but today I mean this talk.",
                    "label": 0
                },
                {
                    "sent": "Of course, today I'm going to talk about moving in a meta data dimension so approximate membership functions that we added.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What is this approximate membership metadata?",
                    "label": 1
                },
                {
                    "sent": "So we took the trip part of friends and we wondered what if we could have a compact representation of all the possible mappings of a certain variable.",
                    "label": 1
                },
                {
                    "sent": "Then we can use that to locally rule out some of the membership.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Requests, so we added the Bloom filter and column coded sets too.",
                    "label": 0
                },
                {
                    "sent": "Are triple pattern fragments response?",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And in general, these are techniques that give you an approximate assessment of whether an item is part of a set or not, and it has a fixed false, probably false positive probability, which means that to a certain extent you can have false positives, but you at least know what the probability is.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the question that we asked ourselves research wise was can we reduce the number of HTTP requests?",
                    "label": 1
                },
                {
                    "sent": "Can we reduce the total execution time?",
                    "label": 1
                },
                {
                    "sent": "But what is also the overhead on the server?",
                    "label": 0
                },
                {
                    "sent": "Do we keep these good behavior of the server if we do this?",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in to shortly explain to you how Bloom filters work, so this is fixed bitmap of ambits.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You want to insert an items.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And with gay distinct hashes, you just calculate random positions in the bed.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That you flip to one.",
                    "label": 0
                },
                {
                    "sent": "You do this for every element and then.",
                    "label": 0
                },
                {
                    "sent": "You send this to the client, for example, and this is where the client can just do the same operation.",
                    "label": 0
                },
                {
                    "sent": "Calculate the hash is see whether the positions are flipped to one, and then decide whether this is in this data set or not.",
                    "label": 0
                },
                {
                    "sent": "And all these parameters can be used to calculate a certain probability that false positive will occur, and then the same.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thing actually happens with column coded sets.",
                    "label": 0
                },
                {
                    "sent": "It's very very similar so.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's also a bit more, but instead of several hashes, we're just going to use one.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this actually.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Response to geometric distribution of all the bits.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which we then column codes to compress or bitmap in the end which is results overall in a more compact representation than Bloomfield.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, So what we actually want to do with the meta data is enabled the client to be intelligent enough to avoid these membership requests over.",
                    "label": 0
                },
                {
                    "sent": "We just described this in RDF.",
                    "label": 0
                },
                {
                    "sent": "Hey, this is a Bloom filter with probability X and has function Y and it represents all the bindings of all the mappings for the subject for example.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And what we do then is just instead of just getting all the mappings, for example from our former triple Pattern artists birthplace bhaderwah and bind them directly to our other pattern and just start asking the server.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Instead, we're just going to get the parents fragment fur.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "1st and then.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Look into the filter.",
                    "label": 0
                },
                {
                    "sent": "Whether this still rule out all the negative ones.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so we evaluated this using 250 queries using 125 whatif templates.",
                    "label": 0
                },
                {
                    "sent": "This was a dual service set up, one with Bloom filters, one with column coded sets.",
                    "label": 0
                },
                {
                    "sent": "We use three types of probabilities.",
                    "label": 0
                },
                {
                    "sent": "We set the query timeout with three minutes.",
                    "label": 0
                },
                {
                    "sent": "We use the HTTP cache Anna Real world network delays.",
                    "label": 0
                },
                {
                    "sent": "So because we are very interested in a web setting and 100 million triples datasets.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so we compared all the results with the vanilla triple pattern FRAGMENTE setup, so with no modifications at all and we tried to client algorithm.",
                    "label": 0
                },
                {
                    "sent": "So the the very first greedy algorithm, the one that I explained and and also a recent optimized joint tree algorithm which was presented on ESWC.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what we notice is, is that actually more than 50% of of our queries get actually a good request reduction.",
                    "label": 0
                },
                {
                    "sent": "We also see 30%, which has no effect at all.",
                    "label": 0
                },
                {
                    "sent": "That's what we kind of expected, because a lot of query types are not affected by membership requests.",
                    "label": 0
                },
                {
                    "sent": "We also have a small percentage being smaller than 20%, which actually have a higher request.",
                    "label": 0
                },
                {
                    "sent": "Wait, but I will get into that later.",
                    "label": 0
                },
                {
                    "sent": "And the percentage.",
                    "label": 0
                },
                {
                    "sent": "So the P values the probabilities that we tried did not really show any.",
                    "label": 0
                },
                {
                    "sent": "Huge difference, we got a slightly higher throughput for higher values, but not enough to really be significant.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then if we look at the queries that were actually affected by this is that the queries that have a high number of HTTP requests really benefit from this approach because they go up to 15,000 requests out of 45,000 requests that we can save, and the same also for the optimized algorithm, where actually the absolute number of requests is lower.",
                    "label": 0
                },
                {
                    "sent": "In general we do.",
                    "label": 0
                },
                {
                    "sent": "Get the same ratio, more or less of requests that we can save, and then if we look at the ones that actually have more requests than we're speaking in terms of 35 requests out of thousands of requests.",
                    "label": 0
                },
                {
                    "sent": "So which is not that relevant.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But then if we look at the execution time, this is actually something that we did not expect is that we have no speedup at all concerning execution time, so we actually notice that a third of our queries actually increases in time, so it actually takes longer to apply this, and one of the reasons is that one the questions are quite large.",
                    "label": 0
                },
                {
                    "sent": "The fragments that are quite large take along time to compute.",
                    "label": 0
                },
                {
                    "sent": "And also the transfer time to transfer this meta data over the wire takes a long time, but we have some conclusions on this which I come back to.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then if we look at the server, we actually see just an increase of below 6%.",
                    "label": 0
                },
                {
                    "sent": "We also see that column coded sets or have a little bit less of an increase, more steady.",
                    "label": 0
                },
                {
                    "sent": "That's also because they use just one hash function, which is a little bit easier on the serve.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let me move on to opportunistic querying so another additional question that we.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Ask yourselves is like when we're doing query execution at a certain point in time, we will have all the results, but they won't be correct yet.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So question was, can we be opportunistic here?",
                    "label": 0
                },
                {
                    "sent": "Can are there use cases like applications that could benefit from having imprecise results?",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so if we look at the execution time, then we see that 100% recall, an 100% precision is actually distinct from each other and that we can actually move this a little bit forward.",
                    "label": 0
                },
                {
                    "sent": "And I retract results when we reached 100% precision.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so an additional resource question that we had was can we reduce this?",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so in general, all of the tests that we did suffered from the same execution time problem, so we didn't really get a real speedup.",
                    "label": 0
                },
                {
                    "sent": "But for the queries that did get a speedup, we notice that we could get to 1/3 of the execution time if we just look at 100% Rico, and in general because of the low probability, you only have to retract zero or one result, which would be very acceptable, and in some Apple.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let me wrap this.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yup, so approximate membership matter data.",
                    "label": 1
                },
                {
                    "sent": "It's more like a nuanced debate.",
                    "label": 0
                },
                {
                    "sent": "So we have some issues.",
                    "label": 0
                },
                {
                    "sent": "That I discussed.",
                    "label": 0
                },
                {
                    "sent": "So for some query types this is really handy because it can.",
                    "label": 0
                },
                {
                    "sent": "Decrease the band Twitter Lawton triple pattern FRAGMENTE query.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Quetion, but for larger fragments we have this issue that real time computation is more or less hurts the execution time, and So what we suggest is that we look into more pre caching an out of band delivery of these things.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then opportunistic querying is also a promising direction.",
                    "label": 0
                },
                {
                    "sent": "If we were able to fix these.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then for my last slide, I just want to say something that I really think is important, that you remember from this talk is that this is just one part of the meta data, but in general the messages that none, no one size fits all we have really have to explore the axis of linked data publishing look at different things than the extremes that we already know and also find the metrics that fit your use case, which could be any application in general and look more at.",
                    "label": 0
                },
                {
                    "sent": "What does HTTP?",
                    "label": 0
                },
                {
                    "sent": "What's the impact on HTTP?",
                    "label": 0
                },
                {
                    "sent": "What is the request response time and what is the load on the server and the client?",
                    "label": 0
                },
                {
                    "sent": "And in general I would like to say that we should start serving link data like a parista where you just have this basic layer of for example triple pattern fragments and you just play with the different features that you want and can support and see what they can do for your client.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, I check on the demo.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Many thanks for the wood presentation.",
                    "label": 0
                },
                {
                    "sent": "We have time for one quest.",
                    "label": 0
                },
                {
                    "sent": "Questions OK so.",
                    "label": 0
                },
                {
                    "sent": "Thank you first of all, thank you for a very nice talk.",
                    "label": 0
                },
                {
                    "sent": "I'm how much selling from a KSW University of Labs in Germany.",
                    "label": 0
                },
                {
                    "sent": "Actually I I'm just wondering like the number of endpoints request was reduced from 45,000 to 15,000.",
                    "label": 0
                },
                {
                    "sent": "Is it because of the benchmark you use becausw the water load?",
                    "label": 0
                },
                {
                    "sent": "This benchmark, it doesn't.",
                    "label": 0
                },
                {
                    "sent": "It's only basic graph patterns, it doesn't contain like more than one BGP, it doesn't contain the unions, it doesn't contain filters, so I was just wondering what will be the performance of this approach while you are trying on something different.",
                    "label": 0
                },
                {
                    "sent": "Queries which has likes.",
                    "label": 0
                },
                {
                    "sent": "From query logs with sparkle filters and all this stuff, why in general the membership requests come from are mostly a result of the joins that we do, so the basic graph patterns are really the first thing that caused it kind of thing.",
                    "label": 0
                },
                {
                    "sent": "For filters and unions were definitely interested in stuff like that, but we haven't looked into benchmarks that really go into detail about this.",
                    "label": 0
                },
                {
                    "sent": "We mostly focused on the.",
                    "label": 0
                },
                {
                    "sent": "Query types that really produce these kinds of requests.",
                    "label": 0
                },
                {
                    "sent": "We have time for another question.",
                    "label": 0
                },
                {
                    "sent": "I have a question.",
                    "label": 0
                },
                {
                    "sent": "If you could explain a little bit about how many triple patterns have your queries, because if you consider complex queries.",
                    "label": 0
                },
                {
                    "sent": "Suppose you have 50 triple patterns.",
                    "label": 0
                },
                {
                    "sent": "Would your approach work equally that you presented here?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "It basically depends on.",
                    "label": 0
                },
                {
                    "sent": "I mean, it basically depends on how many membership requests this would produce, so it depends on the type of.",
                    "label": 0
                },
                {
                    "sent": "Of the basic graph pattern, how many triple patterns?",
                    "label": 0
                },
                {
                    "sent": "And there are, and it's mostly about how they're structured and how the in which join execution.",
                    "label": 0
                },
                {
                    "sent": "But in the queries that you tested, how many triple patterns do you have?",
                    "label": 0
                },
                {
                    "sent": "Average maximum was was 88.",
                    "label": 0
                },
                {
                    "sent": "Yes, for the complex complex.",
                    "label": 0
                },
                {
                    "sent": "OK, how large were the intermediate results?",
                    "label": 0
                },
                {
                    "sent": "I would have to check I don't have the because that's something that may impact also right because in the results that you're presenting only you are showing the deployability of these files.",
                    "label": 0
                },
                {
                    "sent": "Results are impacting in the performance or your approach, but probably you should consider all parameters As for example the number of triple patterns in your queries, the size of intermediate results.",
                    "label": 0
                },
                {
                    "sent": "There are many many different parameters that need to be considered.",
                    "label": 0
                },
                {
                    "sent": "I agree, but this I mean, I think this this was more about how feasible is it to ship this kind of metadata from the server to the client rather than really doing optimized query planning, which is more in the area that you're hinting at.",
                    "label": 0
                },
                {
                    "sent": "But I definitely agree that this is something that we have to go towards.",
                    "label": 0
                },
                {
                    "sent": "Any other question?",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "It's more about if there is do you don't mention anything about the cost of producing the metadata.",
                    "label": 0
                },
                {
                    "sent": "For for the client, so it is something that you do on the fly.",
                    "label": 0
                },
                {
                    "sent": "Or is this something that is precomputed somehow?",
                    "label": 0
                },
                {
                    "sent": "Sorry, can you.",
                    "label": 0
                },
                {
                    "sent": "Can you describe the kind of meta data that you return to the client to perform?",
                    "label": 0
                },
                {
                    "sent": "Are these metadata produced on the fly, but the server?",
                    "label": 0
                },
                {
                    "sent": "Or was the cost of eaten?",
                    "label": 0
                },
                {
                    "sent": "So at the moment yes and we notice that.",
                    "label": 0
                },
                {
                    "sent": "At a certain point, fragments get this large that it gets really inefficient to do that, and so two ways to fix that would be.",
                    "label": 0
                },
                {
                    "sent": "Do somehow smartly pre cache this kind of stuff or precomputed.",
                    "label": 0
                },
                {
                    "sent": "But also allow your client to be even smarter and choose when to download this metadata and when not to so it can decide it's too large.",
                    "label": 0
                },
                {
                    "sent": "I will not do it.",
                    "label": 0
                },
                {
                    "sent": "And that's why I'm talking about the out of band delivery where you do not include metadata in the fragment, but rather.",
                    "label": 0
                },
                {
                    "sent": "Do the meta data that you just can download in a separate request, because these are is also a strong relation with the terminus of the data.",
                    "label": 0
                },
                {
                    "sent": "So if you have data with that changes frequently this approach my might be affected by it, thank you.",
                    "label": 0
                },
                {
                    "sent": "Listen mill for this good presentation.",
                    "label": 0
                }
            ]
        }
    }
}