{
    "id": "7qn7np3wextl4xukg56xszjtfcxk3yh3",
    "title": "WebIsALOD: Providing Hypernymy Relations extracted from the Web as Linked Open Data",
    "info": {
        "author": [
            "Sven Hertling, Institut f\u00fcr Informatik, University of Mannheim"
        ],
        "published": "Nov. 28, 2017",
        "recorded": "October 2017",
        "category": [
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/iswc2017_hertling_open_data/",
    "segmentation": [
        [
            "The idea is."
        ],
        [
            "That knowledge graphs like DB Pedia, Jago and Vicky data plays a central role especially for as language helps.",
            "But it also contains similar information because it most often had is based on the same source like V Pedia.",
            "And thus it does not cover the long tail entities and we want to change that a bit.",
            "So the idea is to build up knowledge graphs which are more complementary to the current ones.",
            "And if you have more information about comparing these knowledge graphs, you can also read the paper I proposed here.",
            "And in this talk I will focus."
        ],
        [
            "On hyponymy relations.",
            "So Hypernym term shares is the relationship with its hypernym.",
            "So for example, Vienna is a city, or Gmail is a web service.",
            "And these are an important asset in many applications, especially in named entity recognition disambiguation tools.",
            "And as a background knowledge for data mining tasks to enrich the features that's there."
        ],
        [
            "So one of our master students created a large database of such relations and we covered All in all 500 millions of these relations which are extracted from a common web crawl.",
            "So on all nearly 2 billion web pages an we use their very simple approach so.",
            "His patterns, which can be executed really fast with regex.",
            "And here you see an example.",
            "So still people use Gmail and other web services, so from that we can extract that Gmail is actually a web service."
        ],
        [
            "So in which information do we collect so we have at least a pre modifier ahead.",
            "Now Nana post modifier for each of the hypernym, as well as of the hyponym.",
            "So in that case, Gmail would be the head noun web service, the pre modifier in service, the corresponding had none of the hyponym.",
            "We also know from which of these 58 patterns we can extract these relation.",
            "And we also know the sentences from which we can extract these relations.",
            "So, for example, many web services these days, including Gmail and Google Calendar, Connect this handlers.",
            "So there we also can extract such information.",
            "And we also know the corresponding pay level domain, so from which actual domain and web page this information is extracted from.",
            "And also on all the absolute number of occurrences shown on how many pages this relation can be extracted."
        ],
        [
            "So because it's based on a web crawl which actually contains very much noise, we.",
            "Also created a crowdsourced survey with maximum Amazon Mechanical Turk.",
            "And we ask the participants to charge if this relation is actually correct or not.",
            "And here you can see that the actual participant just has to judge if the relation is correct or not, or if he or she is uncertain.",
            "In that case, for example, access is an application, then just click on that and we will receive the answer."
        ],
        [
            "And we have 9 annotators for each of these relations.",
            "And we estimated the quality of the data set at different thresholds.",
            "So our first assumption was to create a really, really simple approach or threshold approach where we just created a subset of the data set.",
            "Where we select those relation which appears T times.",
            "On different web pages.",
            "So the amount of pay level domains and also a tee times different patterns for which we can recognize this relation and."
        ],
        [
            "Here you see the OR basically the blue line, which corresponds to the ride wide access.",
            "Which is on log scale.",
            "You see the amount of relations.",
            "So zero corresponds to the whole data set which contains these formed million relations.",
            "And if we just choose the threshold of one, which means we have two or more different patterns and two or more different pay level domains where we can extract this relation from.",
            "It directly drops to only 10,000,000 relations, but we will also have an increase.",
            "Of the correctness which is displayed by the red line, so this is the percentage of how many relations are actually correct.",
            "And as you see, in the whole data set where we have these 400 million relations, we only have about 7% correct relations in there.",
            "So if we extrapolate these numbers, we have nearly 30 million true relations in our data set."
        ],
        [
            "So we also provide this data set is linked open data and we decided to use the verification to provide much more media data about this relation.",
            "And since we not yet know which are instances which are corresponding classes, we don't choose RDF type or RDF subclass off, but we go for Scotts product.",
            "So in that case a Gmail is cost broader than the web web service.",
            "And then for the verification we choose the named graph approach.",
            "So this triple is contained in that corresponding craft and we also have then multiple media data.",
            "In that case, we extended it with the pre modifier with the head as well as the post modifier and label which consists of those.",
            "We also have the correspondent sentences where we extracted this information and also the corresponding pattern.",
            "So in that case the pattern IDs.",
            "Also the Red X and also the paper where all these patterns come from.",
            "Because we extended these patterns and not only use a few of them but multiple one.",
            "And as a next step we also extended to have the frequency of this relation and the pattern ID spread.",
            "So how many patterns extracted this relation?",
            "The PLD spread as well as a confidence which we will.",
            "Compute and how it is computed.",
            "We will see in a few slides."
        ],
        [
            "Then we also linked our data set to the pedia for instances, as well as to Jago for classes because of the rich taxonomy.",
            "We use All in all three approaches, so a plain string matching approach which actually actually works best as well as DB pedia, surface forms and also DB pedia Spotlight.",
            "Because we already have the original sentences.",
            "But All in all, the plain string matching approach works really well in that setup."
        ],
        [
            "To evaluate that, we also use another Amazon Mechanical Turk survey where we give the corresponding sentences and also the Wikipedia page.",
            "So the actual participant has to provide us the Wikipedia page as well as the corresponding Wikipedia category page.",
            "We use that to further link 2 classes for the categories and two instances for the.",
            "Vicki page fork."
        ],
        [
            "Putting the confidence course, we trained a machine learning classifier on the labels which we actually have and did a paramedia tuning for 10 fold cross validation with All in all the six machine learning approaches."
        ],
        [
            "As a feature set, we use a binary value for each pattern.",
            "We use the frequency, the amount of patterns, an amount of pay level domains once for the relation itself and once for the relation only with the head noun.",
            "As the second feature set, we use the amount of tokens.",
            "The two average total length and the existence of a pre imposed modifier, both for Hypernym and hyponym.",
            "The third feature set consists of the total distance between the Hypernym and Hyponym.",
            "In this sentence, is where we use the minimum, maximum, and average across all sentences.",
            "And the result."
        ],
        [
            "Look like that.",
            "All in all, the random forest works best and we also focus for optimizing the area under curve because we also want to optimize our confident confidence scores."
        ],
        [
            "Now some analysis of our resulting data set.",
            "So as you see, if we don't restrict ourselves to the good good relations, we have many many relations in there and just compare a bit with the concept graph as well as with probate switches.",
            "Also, a similar data set released from Microsoft."
        ],
        [
            "And since we map to DB pedia, we can also have a first content profile on which information we actually have here.",
            "So most of them are agents, persons, organizations.",
            "But we also have a bit of some work place and some speeches and a long tail here.",
            "But it's highly biased by the DB Pedia ontology here."
        ],
        [
            "As an example entity, here you see the entity President we have on the right hand side.",
            "The narrower concepts together with the provenance information as well as the confidence values and on the left hand side the broader concept."
        ],
        [
            "And here I provide you an example queries or what you can do with this data set.",
            "For example, you can extract all singers that also act on the left hand side you see the correspondent query and on the right hand side some examples.",
            "So in the."
        ],
        [
            "This leads me to the conclusion and outlook section.",
            "So what we want to do is to create a better type hierarchy and for that we have to distinguish between subclass of an instance of.",
            "We want to clean the data a bit more to remove cycles based on some of these confidence scores we computed, we want to identify homonyms.",
            "So as an example but House is a golf band or about half is Jim School in that we only know about house as one entity and we have.",
            "To separate them and we can also create new relations.",
            "So in that case if we know a pre MoD and had we can also create a pre MoD head is ahead.",
            "So for example birth date is a date and we can also create new relations.",
            "For example, Gucha is a German writer.",
            "If we know that based on pre modifiers we can also conclude that good has the nationality German.",
            "And with that, I'd like to thank you.",
            "And if you want to use the data set and chest, please go to this website.",
            "Thank you."
        ],
        [
            "So there is a huge difference between the whole web is allowed and what you call the good one.",
            "So what is the threshold you used and what you imagine could be used for all the rest.",
            "So there are chances to to reuse part of it for even if it is considered not good or so we consider the whole data set.",
            "So these all 400 million relations.",
            "But we extrapolate based on our survey in Mechanical Turk.",
            "How many actual good relations we have valid relations we have, and this is the extra related value where I give the label.",
            "Web is a lot good.",
            "There is no threshold.",
            "There is no threshold, it's just the extrapolated based on the Mechanical Turk.",
            "So we know that nearly 7% of the whole data set should be good because of the annotated subset we give to the Mechanical Turk.",
            "So in terms of hypernyms, I would imagine there's a lot of different hypernyms for the same thing, right?",
            "I mean, Arnold Schwarzenegger is a man, he's a politician and actor.",
            "You know a lot of different things, right?",
            "So how do you choose which one?",
            "Or do you do them all?",
            "So we just list them together with confidence so everyone can choose a threshold.",
            "And if you're just interested in the first one, the most confident one, then you can just use that.",
            "So there are many possibilities in there and we just list them just a simple baseline, right?",
            "So let's see if you would.",
            "Try to compare little Wordnet Hypernym relationship, right?",
            "So how much of the word net can you reconstruct with this?",
            "So you mean how many word relations do?",
            "We also wouldn't it is you know word net, right?",
            "So word net one of the primary relationship with in Word net is hypernym, right?",
            "And this was manually created, so it's pretty much 100% correct, right?",
            "So you're extracting relations happenings from the data itself, so you should be able to replicate good part of word net.",
            "So this would be baseline right?",
            "Which is very obvious.",
            "We don't do that.",
            "We just used the Mechanical Turk surveys for that.",
            "But we could also analyze how many relations we concert 30 years forward.",
            "Nets is Mechanical Turk much better one right for free?",
            "Yeah yeah, sure.",
            "Sure, good idea.",
            "How do you distinguish between actual is a relationship and qualification.",
            "For example, is a jerk.",
            "And so you mean for a subclass of, for instance of or type relation.",
            "So what we use for that is we can create a training set.",
            "Based on DB pedia.",
            "So we actually map our entities to the ones in DB pedia and based on that we can see if there is a type relation or a subclass of relation between those entities and thus we can create in a very simple way our training and test set and drain again and machine learning classifier to choose which.",
            "Relation or which property we should choose?",
            "So maybe two very quick and naive question.",
            "One of them is maybe I missed it, but I didn't see if you qualified.",
            "The agreement between the annotator, especially on the problem of making the difference between subsumption relationship and instance relationship.",
            "Did you have that?",
            "'cause when you put people at the table and asking them is it a subclass of?",
            "Or is it an instance you can enter in very interesting discussions and do you have the the notion of agreement between your annotation?",
            "So we don't recall that measure, but that can be easily done and the data is available online.",
            "Yeah, I think it's important also because you're trying to do it automatically and you will.",
            "If the human do not agree, you cannot do better.",
            "Yeah, but also we remove relations where we are uncertain, so most of most people are uncertain, so there's also the possibility to choose that.",
            "And also if the if you have the same.",
            "Amount of people chooses yes and no, then we also remove that to get better results in there.",
            "OK, let's thank the speaker again and we're joined."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The idea is.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That knowledge graphs like DB Pedia, Jago and Vicky data plays a central role especially for as language helps.",
                    "label": 1
                },
                {
                    "sent": "But it also contains similar information because it most often had is based on the same source like V Pedia.",
                    "label": 0
                },
                {
                    "sent": "And thus it does not cover the long tail entities and we want to change that a bit.",
                    "label": 1
                },
                {
                    "sent": "So the idea is to build up knowledge graphs which are more complementary to the current ones.",
                    "label": 1
                },
                {
                    "sent": "And if you have more information about comparing these knowledge graphs, you can also read the paper I proposed here.",
                    "label": 0
                },
                {
                    "sent": "And in this talk I will focus.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "On hyponymy relations.",
                    "label": 0
                },
                {
                    "sent": "So Hypernym term shares is the relationship with its hypernym.",
                    "label": 1
                },
                {
                    "sent": "So for example, Vienna is a city, or Gmail is a web service.",
                    "label": 0
                },
                {
                    "sent": "And these are an important asset in many applications, especially in named entity recognition disambiguation tools.",
                    "label": 1
                },
                {
                    "sent": "And as a background knowledge for data mining tasks to enrich the features that's there.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So one of our master students created a large database of such relations and we covered All in all 500 millions of these relations which are extracted from a common web crawl.",
                    "label": 1
                },
                {
                    "sent": "So on all nearly 2 billion web pages an we use their very simple approach so.",
                    "label": 0
                },
                {
                    "sent": "His patterns, which can be executed really fast with regex.",
                    "label": 0
                },
                {
                    "sent": "And here you see an example.",
                    "label": 0
                },
                {
                    "sent": "So still people use Gmail and other web services, so from that we can extract that Gmail is actually a web service.",
                    "label": 1
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in which information do we collect so we have at least a pre modifier ahead.",
                    "label": 0
                },
                {
                    "sent": "Now Nana post modifier for each of the hypernym, as well as of the hyponym.",
                    "label": 0
                },
                {
                    "sent": "So in that case, Gmail would be the head noun web service, the pre modifier in service, the corresponding had none of the hyponym.",
                    "label": 0
                },
                {
                    "sent": "We also know from which of these 58 patterns we can extract these relation.",
                    "label": 0
                },
                {
                    "sent": "And we also know the sentences from which we can extract these relations.",
                    "label": 0
                },
                {
                    "sent": "So, for example, many web services these days, including Gmail and Google Calendar, Connect this handlers.",
                    "label": 1
                },
                {
                    "sent": "So there we also can extract such information.",
                    "label": 0
                },
                {
                    "sent": "And we also know the corresponding pay level domain, so from which actual domain and web page this information is extracted from.",
                    "label": 0
                },
                {
                    "sent": "And also on all the absolute number of occurrences shown on how many pages this relation can be extracted.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So because it's based on a web crawl which actually contains very much noise, we.",
                    "label": 0
                },
                {
                    "sent": "Also created a crowdsourced survey with maximum Amazon Mechanical Turk.",
                    "label": 1
                },
                {
                    "sent": "And we ask the participants to charge if this relation is actually correct or not.",
                    "label": 0
                },
                {
                    "sent": "And here you can see that the actual participant just has to judge if the relation is correct or not, or if he or she is uncertain.",
                    "label": 0
                },
                {
                    "sent": "In that case, for example, access is an application, then just click on that and we will receive the answer.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we have 9 annotators for each of these relations.",
                    "label": 0
                },
                {
                    "sent": "And we estimated the quality of the data set at different thresholds.",
                    "label": 1
                },
                {
                    "sent": "So our first assumption was to create a really, really simple approach or threshold approach where we just created a subset of the data set.",
                    "label": 0
                },
                {
                    "sent": "Where we select those relation which appears T times.",
                    "label": 0
                },
                {
                    "sent": "On different web pages.",
                    "label": 1
                },
                {
                    "sent": "So the amount of pay level domains and also a tee times different patterns for which we can recognize this relation and.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here you see the OR basically the blue line, which corresponds to the ride wide access.",
                    "label": 0
                },
                {
                    "sent": "Which is on log scale.",
                    "label": 0
                },
                {
                    "sent": "You see the amount of relations.",
                    "label": 0
                },
                {
                    "sent": "So zero corresponds to the whole data set which contains these formed million relations.",
                    "label": 0
                },
                {
                    "sent": "And if we just choose the threshold of one, which means we have two or more different patterns and two or more different pay level domains where we can extract this relation from.",
                    "label": 0
                },
                {
                    "sent": "It directly drops to only 10,000,000 relations, but we will also have an increase.",
                    "label": 0
                },
                {
                    "sent": "Of the correctness which is displayed by the red line, so this is the percentage of how many relations are actually correct.",
                    "label": 1
                },
                {
                    "sent": "And as you see, in the whole data set where we have these 400 million relations, we only have about 7% correct relations in there.",
                    "label": 0
                },
                {
                    "sent": "So if we extrapolate these numbers, we have nearly 30 million true relations in our data set.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we also provide this data set is linked open data and we decided to use the verification to provide much more media data about this relation.",
                    "label": 0
                },
                {
                    "sent": "And since we not yet know which are instances which are corresponding classes, we don't choose RDF type or RDF subclass off, but we go for Scotts product.",
                    "label": 0
                },
                {
                    "sent": "So in that case a Gmail is cost broader than the web web service.",
                    "label": 0
                },
                {
                    "sent": "And then for the verification we choose the named graph approach.",
                    "label": 0
                },
                {
                    "sent": "So this triple is contained in that corresponding craft and we also have then multiple media data.",
                    "label": 0
                },
                {
                    "sent": "In that case, we extended it with the pre modifier with the head as well as the post modifier and label which consists of those.",
                    "label": 0
                },
                {
                    "sent": "We also have the correspondent sentences where we extracted this information and also the corresponding pattern.",
                    "label": 0
                },
                {
                    "sent": "So in that case the pattern IDs.",
                    "label": 0
                },
                {
                    "sent": "Also the Red X and also the paper where all these patterns come from.",
                    "label": 0
                },
                {
                    "sent": "Because we extended these patterns and not only use a few of them but multiple one.",
                    "label": 0
                },
                {
                    "sent": "And as a next step we also extended to have the frequency of this relation and the pattern ID spread.",
                    "label": 0
                },
                {
                    "sent": "So how many patterns extracted this relation?",
                    "label": 0
                },
                {
                    "sent": "The PLD spread as well as a confidence which we will.",
                    "label": 0
                },
                {
                    "sent": "Compute and how it is computed.",
                    "label": 0
                },
                {
                    "sent": "We will see in a few slides.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then we also linked our data set to the pedia for instances, as well as to Jago for classes because of the rich taxonomy.",
                    "label": 1
                },
                {
                    "sent": "We use All in all three approaches, so a plain string matching approach which actually actually works best as well as DB pedia, surface forms and also DB pedia Spotlight.",
                    "label": 1
                },
                {
                    "sent": "Because we already have the original sentences.",
                    "label": 0
                },
                {
                    "sent": "But All in all, the plain string matching approach works really well in that setup.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To evaluate that, we also use another Amazon Mechanical Turk survey where we give the corresponding sentences and also the Wikipedia page.",
                    "label": 0
                },
                {
                    "sent": "So the actual participant has to provide us the Wikipedia page as well as the corresponding Wikipedia category page.",
                    "label": 0
                },
                {
                    "sent": "We use that to further link 2 classes for the categories and two instances for the.",
                    "label": 0
                },
                {
                    "sent": "Vicki page fork.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Putting the confidence course, we trained a machine learning classifier on the labels which we actually have and did a paramedia tuning for 10 fold cross validation with All in all the six machine learning approaches.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As a feature set, we use a binary value for each pattern.",
                    "label": 1
                },
                {
                    "sent": "We use the frequency, the amount of patterns, an amount of pay level domains once for the relation itself and once for the relation only with the head noun.",
                    "label": 1
                },
                {
                    "sent": "As the second feature set, we use the amount of tokens.",
                    "label": 0
                },
                {
                    "sent": "The two average total length and the existence of a pre imposed modifier, both for Hypernym and hyponym.",
                    "label": 1
                },
                {
                    "sent": "The third feature set consists of the total distance between the Hypernym and Hyponym.",
                    "label": 0
                },
                {
                    "sent": "In this sentence, is where we use the minimum, maximum, and average across all sentences.",
                    "label": 0
                },
                {
                    "sent": "And the result.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Look like that.",
                    "label": 0
                },
                {
                    "sent": "All in all, the random forest works best and we also focus for optimizing the area under curve because we also want to optimize our confident confidence scores.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now some analysis of our resulting data set.",
                    "label": 0
                },
                {
                    "sent": "So as you see, if we don't restrict ourselves to the good good relations, we have many many relations in there and just compare a bit with the concept graph as well as with probate switches.",
                    "label": 0
                },
                {
                    "sent": "Also, a similar data set released from Microsoft.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And since we map to DB pedia, we can also have a first content profile on which information we actually have here.",
                    "label": 1
                },
                {
                    "sent": "So most of them are agents, persons, organizations.",
                    "label": 0
                },
                {
                    "sent": "But we also have a bit of some work place and some speeches and a long tail here.",
                    "label": 0
                },
                {
                    "sent": "But it's highly biased by the DB Pedia ontology here.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As an example entity, here you see the entity President we have on the right hand side.",
                    "label": 0
                },
                {
                    "sent": "The narrower concepts together with the provenance information as well as the confidence values and on the left hand side the broader concept.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And here I provide you an example queries or what you can do with this data set.",
                    "label": 0
                },
                {
                    "sent": "For example, you can extract all singers that also act on the left hand side you see the correspondent query and on the right hand side some examples.",
                    "label": 1
                },
                {
                    "sent": "So in the.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This leads me to the conclusion and outlook section.",
                    "label": 1
                },
                {
                    "sent": "So what we want to do is to create a better type hierarchy and for that we have to distinguish between subclass of an instance of.",
                    "label": 1
                },
                {
                    "sent": "We want to clean the data a bit more to remove cycles based on some of these confidence scores we computed, we want to identify homonyms.",
                    "label": 0
                },
                {
                    "sent": "So as an example but House is a golf band or about half is Jim School in that we only know about house as one entity and we have.",
                    "label": 0
                },
                {
                    "sent": "To separate them and we can also create new relations.",
                    "label": 0
                },
                {
                    "sent": "So in that case if we know a pre MoD and had we can also create a pre MoD head is ahead.",
                    "label": 0
                },
                {
                    "sent": "So for example birth date is a date and we can also create new relations.",
                    "label": 1
                },
                {
                    "sent": "For example, Gucha is a German writer.",
                    "label": 1
                },
                {
                    "sent": "If we know that based on pre modifiers we can also conclude that good has the nationality German.",
                    "label": 0
                },
                {
                    "sent": "And with that, I'd like to thank you.",
                    "label": 0
                },
                {
                    "sent": "And if you want to use the data set and chest, please go to this website.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So there is a huge difference between the whole web is allowed and what you call the good one.",
                    "label": 0
                },
                {
                    "sent": "So what is the threshold you used and what you imagine could be used for all the rest.",
                    "label": 0
                },
                {
                    "sent": "So there are chances to to reuse part of it for even if it is considered not good or so we consider the whole data set.",
                    "label": 0
                },
                {
                    "sent": "So these all 400 million relations.",
                    "label": 0
                },
                {
                    "sent": "But we extrapolate based on our survey in Mechanical Turk.",
                    "label": 0
                },
                {
                    "sent": "How many actual good relations we have valid relations we have, and this is the extra related value where I give the label.",
                    "label": 0
                },
                {
                    "sent": "Web is a lot good.",
                    "label": 0
                },
                {
                    "sent": "There is no threshold.",
                    "label": 0
                },
                {
                    "sent": "There is no threshold, it's just the extrapolated based on the Mechanical Turk.",
                    "label": 0
                },
                {
                    "sent": "So we know that nearly 7% of the whole data set should be good because of the annotated subset we give to the Mechanical Turk.",
                    "label": 0
                },
                {
                    "sent": "So in terms of hypernyms, I would imagine there's a lot of different hypernyms for the same thing, right?",
                    "label": 0
                },
                {
                    "sent": "I mean, Arnold Schwarzenegger is a man, he's a politician and actor.",
                    "label": 0
                },
                {
                    "sent": "You know a lot of different things, right?",
                    "label": 0
                },
                {
                    "sent": "So how do you choose which one?",
                    "label": 0
                },
                {
                    "sent": "Or do you do them all?",
                    "label": 0
                },
                {
                    "sent": "So we just list them together with confidence so everyone can choose a threshold.",
                    "label": 0
                },
                {
                    "sent": "And if you're just interested in the first one, the most confident one, then you can just use that.",
                    "label": 0
                },
                {
                    "sent": "So there are many possibilities in there and we just list them just a simple baseline, right?",
                    "label": 0
                },
                {
                    "sent": "So let's see if you would.",
                    "label": 0
                },
                {
                    "sent": "Try to compare little Wordnet Hypernym relationship, right?",
                    "label": 0
                },
                {
                    "sent": "So how much of the word net can you reconstruct with this?",
                    "label": 0
                },
                {
                    "sent": "So you mean how many word relations do?",
                    "label": 0
                },
                {
                    "sent": "We also wouldn't it is you know word net, right?",
                    "label": 0
                },
                {
                    "sent": "So word net one of the primary relationship with in Word net is hypernym, right?",
                    "label": 0
                },
                {
                    "sent": "And this was manually created, so it's pretty much 100% correct, right?",
                    "label": 0
                },
                {
                    "sent": "So you're extracting relations happenings from the data itself, so you should be able to replicate good part of word net.",
                    "label": 0
                },
                {
                    "sent": "So this would be baseline right?",
                    "label": 0
                },
                {
                    "sent": "Which is very obvious.",
                    "label": 0
                },
                {
                    "sent": "We don't do that.",
                    "label": 0
                },
                {
                    "sent": "We just used the Mechanical Turk surveys for that.",
                    "label": 0
                },
                {
                    "sent": "But we could also analyze how many relations we concert 30 years forward.",
                    "label": 0
                },
                {
                    "sent": "Nets is Mechanical Turk much better one right for free?",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah, sure.",
                    "label": 0
                },
                {
                    "sent": "Sure, good idea.",
                    "label": 0
                },
                {
                    "sent": "How do you distinguish between actual is a relationship and qualification.",
                    "label": 0
                },
                {
                    "sent": "For example, is a jerk.",
                    "label": 0
                },
                {
                    "sent": "And so you mean for a subclass of, for instance of or type relation.",
                    "label": 0
                },
                {
                    "sent": "So what we use for that is we can create a training set.",
                    "label": 0
                },
                {
                    "sent": "Based on DB pedia.",
                    "label": 0
                },
                {
                    "sent": "So we actually map our entities to the ones in DB pedia and based on that we can see if there is a type relation or a subclass of relation between those entities and thus we can create in a very simple way our training and test set and drain again and machine learning classifier to choose which.",
                    "label": 0
                },
                {
                    "sent": "Relation or which property we should choose?",
                    "label": 0
                },
                {
                    "sent": "So maybe two very quick and naive question.",
                    "label": 0
                },
                {
                    "sent": "One of them is maybe I missed it, but I didn't see if you qualified.",
                    "label": 0
                },
                {
                    "sent": "The agreement between the annotator, especially on the problem of making the difference between subsumption relationship and instance relationship.",
                    "label": 0
                },
                {
                    "sent": "Did you have that?",
                    "label": 0
                },
                {
                    "sent": "'cause when you put people at the table and asking them is it a subclass of?",
                    "label": 0
                },
                {
                    "sent": "Or is it an instance you can enter in very interesting discussions and do you have the the notion of agreement between your annotation?",
                    "label": 0
                },
                {
                    "sent": "So we don't recall that measure, but that can be easily done and the data is available online.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I think it's important also because you're trying to do it automatically and you will.",
                    "label": 0
                },
                {
                    "sent": "If the human do not agree, you cannot do better.",
                    "label": 0
                },
                {
                    "sent": "Yeah, but also we remove relations where we are uncertain, so most of most people are uncertain, so there's also the possibility to choose that.",
                    "label": 0
                },
                {
                    "sent": "And also if the if you have the same.",
                    "label": 0
                },
                {
                    "sent": "Amount of people chooses yes and no, then we also remove that to get better results in there.",
                    "label": 0
                },
                {
                    "sent": "OK, let's thank the speaker again and we're joined.",
                    "label": 0
                }
            ]
        }
    }
}