{
    "id": "5zdmrusiif36do5yv5l46l32q5uamtfk",
    "title": "Transfer Learning for Item Recommendations and Knowledge Graph Completion in Item Related Domains via A Co-Factorization Model",
    "info": {
        "author": [
            "Guangyuan Piao, National University of Ireland (NUI) Galway"
        ],
        "published": "July 10, 2018",
        "recorded": "June 2018",
        "category": [
            "Top->Computer Science->Big Data",
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/eswc2018_piao_transfer_learning/",
    "segmentation": [
        [
            "Hello everyone, my name is Connie Pammy, PhD candidate at inside Centre for Data Analytics at the National University of Ireland, Galway and I'm working with Doctor John Bradley.",
            "And yet my talk is about transfer, learning for item recommendations and a knowledge graph completion in the item.",
            "Related domains.",
            "Very cool factorization model.",
            "So I will give."
        ],
        [
            "Background and about the.",
            "Into data or semantics over recommender systems and to state of the art approaches for the two tasks and our transfer learning approach for vehicle factorization model and our experiment and results and summarize the talking in the end.",
            "So."
        ],
        [
            "Commender systems is everywhere like on Facebook.",
            "System is recommending the, for example the music artist pages that you might like, or recommending books in Amazon Kindle that you might read in the future and also recommending movies on Netflix.",
            "And."
        ],
        [
            "There are three common or more typical approaches for recommender systems.",
            "One is collaborative filtering which recommend trying to get similar users and recommend items that similar users liked and also content based recommender systems which recommend items based on the features from their items descriptions and trying to map the.",
            "Generate the profiles for users and items in the same future space and to generate recommendations and the hybrid approaches.",
            "Trying to combine different approaches to overcome some disadvantages of a single recommender system approach.",
            "So for collaborative filtering, for example, it cannot deal with like new item on user problem or for content based approach.",
            "You can deal with new item.",
            "You can still recommend new item even there's no explicit feedback about users about this item because it only depends on the description, the features of the items."
        ],
        [
            "And so there's many efforts from this mental community to utilize the structured data from web data or linked open data so linked open data datasets such as DB PEDIA provides a great amount of domain knowledge and rich information about items or entities.",
            "And it's also facilitated.",
            "The step for content based recommendation techniques when you need to analyze the content and extract features like music genres or etc.",
            "But you can easily find using standard sparkle queries on the web of data to use these background knowledge about items.",
            "For recommender systems."
        ],
        [
            "So in summary, like for semantics, aware recommender systems or linked open data enabled recommender systems where trying to utilize the explicit feedback like the items the user liked before as well as the item background knowledge from our linked open data datasets.",
            "And use these two informations to improve the personalized recommendations and to utilize the background knowledge about the items or entities.",
            "There are many works have been done, so for for example, the first attempt is using or devising the semantic similarity or distance measures to measure the semantic similarity or distance between two entities and utilized these.",
            "Semantic similarity scores for recommendations and the graph based algorithms also applied an treating these heterogeneous graph such as DB pedia as a homogeneous one and applied very established graph based algorithms such as page rank algorithm to measure the similarity between two entities and use these for an item recommendations and also machine learning approaches.",
            "Trying to extract the features from.",
            "From a knowledge graph or multiple knowledge graphs and also for example, the recent work is trying to combine user item interaction history as well as the background knowledge about items to get the combined graph, then extract like the semantic passes as the features and feeding to the various stablished learning to rank frameworks."
        ],
        [
            "And the main focus of the previous studies are focused on how to consume the existing knowledge about items or entities for recommender systems.",
            "But on the other hand, knowledge graph is highly incomplete and the for example for this movie at legs of the categorical information, which might be very useful for recommender systems.",
            "But that is missing on DB pedia.",
            "And previous work does not incorporate the incompleteness of knowledge graphs, and there is a dedicated line of research trying to do deal with the Knowledge Graph completion task.",
            "So we are interested in how can we somehow incorporate the incompleteness of knowledge graphs learned from the Knowledge Graph completion task.",
            "And Secondly.",
            "The focus is only trying to use the knowledge from knowledge graphs to the item recommendation task.",
            "While there's no such studies trying to transfer the knowledge from the user item interactions in from the item recommendation task to the Knowledge Graph completion task, so we are interested in these two aspects an.",
            "So."
        ],
        [
            "These tasks can be formalized as follows, so item recommendations just given user item interactions as well as background knowledge to provide some N recommendations and knowledge.",
            "Graph completion can be also formalized into the top end object recommendations as in the previous studies.",
            "So given a subject and predicate pair, it's provided the top end object recommendations.",
            "And there's many works at and it's very popular line of research for these knowledge index knowledge Graph completion task in recent years, and there's many approaches using factorization approach or embedding approaches and also neural network based models."
        ],
        [
            "So far we use two state of the art approaches for the two tasks for item recommendations.",
            "We used factorization machines, which is a state of the art approach for.",
            "Item recommendations, so it's basically has the linear part to capturing user features and item features, and it also captures the interaction between user features.",
            "An item features based on the latent factors of each features, so these are the like latent features of each.",
            "Each item feature and the user feature and it's.",
            "It can be also seen as embedding for each feature.",
            "And the loss function is trying to get based on the idea that the positive user item interaction should have the higher score compared to the randomly sampled and negative based on negative sampling.",
            "Strategy should have higher score compared to the randomly sampled user item interaction.",
            "Training instance.",
            "And for knowledge graph completion, we see the trends E approach.",
            "So it's basically based on the idea that the sum of the subject and predicate embeddings should have the similar.",
            "Similar to the object embeddings for a valid cheapo, so the similarity can be measured in like active distance which is used in the original paper and.",
            "The loss function is also similar to the pairwise ranking approach, which trying to minimize the, and.",
            "The idea is that the valid cheapo distance to the smaller than the random triple random triple that randomly sampled within margin.",
            "So when we."
        ],
        [
            "See these two vectorization embedding approaches.",
            "There is 2 representations for the same item in two different tasks.",
            "One is the item embedding's in the factorization machines for item recommendations and the subject embeddings, which is subject embedding in the Knowledge Graph completion task."
        ],
        [
            "So we are trying to understand and formulate is the problem as transfer learning problem.",
            "So transfer learning is using one task as source task and the other as a target task and we only care about the object function of the target task by transferring knowledge from source task.",
            "And we trying to model the relationship between these two embeddings.",
            "So we just investigated two approaches, so the first one is a straightforward way to cheat.",
            "These two embeddings are exactly the same in both tasks, and Secondly is we added the regularization term which is trying to capture the idea.",
            "These two meetings in two different tasks should not reside far away from each other."
        ],
        [
            "An to putting everything together, we're trying to optimize the target task with this, partially optimizing the source task.",
            "And in terms of the item recommendations, for example, we are trying to there's some training instances and the training data set for item recommendations as target task and for each.",
            "Then we training with a stochastic gradient descent.",
            "We're trying to randomly sample for each training instance.",
            "For item recommendations, we randomly sample one training instance from the source task which has the constraint that the.",
            "Item in the index training instances.",
            "The subject in the randomly sampled training instance from the source task.",
            "So in this case we can have the same size of training instance instances for both task which can be used for stochastic gradient descent algorithm to train to learn the parameters in this index.",
            "Can factorization model.",
            "And we use."
        ],
        [
            "The two data standard data set for item recommendations using which is in movie, movie, domain and book domain and we based on these data set way further extracted the knowledge from each domain with respect to the items in two datasets.",
            "Example using extracting the predicates and objects and you can see the number of triples for each domain."
        ],
        [
            "Anne."
        ],
        [
            "For training with you for item recommendations, we used 80% for training and 20% for test and 20% for the training data set for validation and hyperparameter tuning and for knowledge graph completion, we used a.",
            "Evaluation strategy or sampling strategy in the in a previous work, which is for a given subject, we randomly choose a predicate to construct the SP pair as the test set and the other cheapos containing S as the training set.",
            "And this is the one like sampling strategy to construct the training and test sets for both tasks.",
            "And we repeat it 5 times and sampling these new training and test set and average the results to report."
        ],
        [
            "And we for recommender systems we used value established evaluation metrics such as normalized, discounted cumulative gain, which takes into account up the relevant items as well as their rank positions and the mean reciprocal rank, which measures the 1st letter print item occurs on average in recommendations and well known precision and recall measures."
        ],
        [
            "So for each task, we compared with three baselines for item recommendations, we use the K nearest enable algorithm as the baseline, and the PPRF is can be seen as our core factorization model without transferring knowledge from the other task.",
            "From the Knowledge compilation task and FML, ODI is is also using factorization machines, but extracting the knowledge enabled features.",
            "Using existing knowledge and feed it into the factorization machines and knowledge for knowledge Graph completion task we used the most frequent per predicate.",
            "It's just recommending the object most frequently occurring with the given predicate and PTF.",
            "Ann is also using factorization machines, but using the subject and predicate and objects as the features and capturing the interactions between these 3 features.",
            "And chance it can be seen as our core factorization model without transferring knowledge from item recommendations."
        ],
        [
            "And I also I only show the results on the movielens data set for the time constraint.",
            "But the first observation for remove lens data set is that when we modeling the.",
            "Two different representations in two different tasks for the item or subject to embeddings, like using regularization term, is performing better compared to aligning the embeddings that based on the assumption that these two embeddings into different tasks are exactly the same on the movielens data set, which is also in both tasks has the same results."
        ],
        [
            "And Secondly, is that.",
            "Compared to the existing like semantics, aware recommender systems consuming the existing knowledge, our model somehow incorporating the incompleteness of knowledge graph and compared to the model leveraging the existing knowledge may have some significant improvement compared to the dexis semantics aware recommender system approach."
        ],
        [
            "And certainly when we compared to the models without transferring knowledge from each task, we can see that in both Alto recommendations and the Knowledge Graph completion task, transferring knowledge can performs better compared to the model without transferring knowledge from the other task."
        ],
        [
            "So to summarize, index work.",
            "We investigated the knowledge transfer between between item recommendations and knowledge graph completion with a factorization model, and we showed that incorporating the incompleteness of knowledge graph can improve the item recommendation performance and the knowledge from the item recommendations also can be transferred to the Knowledge Graph completion task and improve its performance, which has not been studied before.",
            "An and it's it's a.",
            "Ongoing work, and there's many limitations on this work as well.",
            "So, for example, we considered the domain specific knowledge graph as the directly connected predictive predicate and object about the items.",
            "While you can apply some fine grained way to extract the sub graph of a domain specific knowledge graph from DB pedia and to improve the.",
            "Tommy specific knowledge graph for knowledge Graph completion task, and Secondly, the modeling strategy for the relationship between the two items.",
            "Item representations in two different tasks has some constraint like they need to have have the same dimensionality which she might not be necessarily that true and you can model the item and subject embeddings.",
            "Then in two different tasks with the two different dimensionality values and then trying to find a way to project these two embeddings with two different dimensionalities into the same space or etc.",
            "And we can also try other state of the art approaches for both tasks.",
            "And also we only evaluated in movie movie domain and book domain and we're currently also evaluating on the music domain to see if it can be channelized in other domains as well.",
            "So yeah, that's it, thank."
        ],
        [
            "For your attention.",
            "Thank you very much for the talk questions.",
            "Any?",
            "To myself.",
            "Thank you very much for your talk.",
            "I was just wondering maybe I missed the point, but how did you perform feature selection for your recommendation time?",
            "So did you select the you know the?",
            "Hold old properties of of an item or you know.",
            "You selected just a subset of this properties.",
            "In case how did you select this subset?",
            "For for this way just to use the user and item as the features for, like factorization machines.",
            "So it's basically is the metric factorization in this sense.",
            "I, if you mean the baselines in other approach consuming the background knowledge E. We we we we extracted the predicate and object as well as on some knowledge graph enabled features to feed into factorization machines for comparison.",
            "So it's also including some Pagerank scores of the entities for item recommendations as well.",
            "OK, more questions.",
            "OK, since there are no more questions, let's thank the speaker and all the speakers again, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Hello everyone, my name is Connie Pammy, PhD candidate at inside Centre for Data Analytics at the National University of Ireland, Galway and I'm working with Doctor John Bradley.",
                    "label": 0
                },
                {
                    "sent": "And yet my talk is about transfer, learning for item recommendations and a knowledge graph completion in the item.",
                    "label": 1
                },
                {
                    "sent": "Related domains.",
                    "label": 0
                },
                {
                    "sent": "Very cool factorization model.",
                    "label": 0
                },
                {
                    "sent": "So I will give.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Background and about the.",
                    "label": 0
                },
                {
                    "sent": "Into data or semantics over recommender systems and to state of the art approaches for the two tasks and our transfer learning approach for vehicle factorization model and our experiment and results and summarize the talking in the end.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Commender systems is everywhere like on Facebook.",
                    "label": 0
                },
                {
                    "sent": "System is recommending the, for example the music artist pages that you might like, or recommending books in Amazon Kindle that you might read in the future and also recommending movies on Netflix.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There are three common or more typical approaches for recommender systems.",
                    "label": 0
                },
                {
                    "sent": "One is collaborative filtering which recommend trying to get similar users and recommend items that similar users liked and also content based recommender systems which recommend items based on the features from their items descriptions and trying to map the.",
                    "label": 1
                },
                {
                    "sent": "Generate the profiles for users and items in the same future space and to generate recommendations and the hybrid approaches.",
                    "label": 1
                },
                {
                    "sent": "Trying to combine different approaches to overcome some disadvantages of a single recommender system approach.",
                    "label": 1
                },
                {
                    "sent": "So for collaborative filtering, for example, it cannot deal with like new item on user problem or for content based approach.",
                    "label": 0
                },
                {
                    "sent": "You can deal with new item.",
                    "label": 0
                },
                {
                    "sent": "You can still recommend new item even there's no explicit feedback about users about this item because it only depends on the description, the features of the items.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so there's many efforts from this mental community to utilize the structured data from web data or linked open data so linked open data datasets such as DB PEDIA provides a great amount of domain knowledge and rich information about items or entities.",
                    "label": 1
                },
                {
                    "sent": "And it's also facilitated.",
                    "label": 0
                },
                {
                    "sent": "The step for content based recommendation techniques when you need to analyze the content and extract features like music genres or etc.",
                    "label": 0
                },
                {
                    "sent": "But you can easily find using standard sparkle queries on the web of data to use these background knowledge about items.",
                    "label": 0
                },
                {
                    "sent": "For recommender systems.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in summary, like for semantics, aware recommender systems or linked open data enabled recommender systems where trying to utilize the explicit feedback like the items the user liked before as well as the item background knowledge from our linked open data datasets.",
                    "label": 0
                },
                {
                    "sent": "And use these two informations to improve the personalized recommendations and to utilize the background knowledge about the items or entities.",
                    "label": 1
                },
                {
                    "sent": "There are many works have been done, so for for example, the first attempt is using or devising the semantic similarity or distance measures to measure the semantic similarity or distance between two entities and utilized these.",
                    "label": 0
                },
                {
                    "sent": "Semantic similarity scores for recommendations and the graph based algorithms also applied an treating these heterogeneous graph such as DB pedia as a homogeneous one and applied very established graph based algorithms such as page rank algorithm to measure the similarity between two entities and use these for an item recommendations and also machine learning approaches.",
                    "label": 1
                },
                {
                    "sent": "Trying to extract the features from.",
                    "label": 0
                },
                {
                    "sent": "From a knowledge graph or multiple knowledge graphs and also for example, the recent work is trying to combine user item interaction history as well as the background knowledge about items to get the combined graph, then extract like the semantic passes as the features and feeding to the various stablished learning to rank frameworks.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the main focus of the previous studies are focused on how to consume the existing knowledge about items or entities for recommender systems.",
                    "label": 1
                },
                {
                    "sent": "But on the other hand, knowledge graph is highly incomplete and the for example for this movie at legs of the categorical information, which might be very useful for recommender systems.",
                    "label": 0
                },
                {
                    "sent": "But that is missing on DB pedia.",
                    "label": 0
                },
                {
                    "sent": "And previous work does not incorporate the incompleteness of knowledge graphs, and there is a dedicated line of research trying to do deal with the Knowledge Graph completion task.",
                    "label": 1
                },
                {
                    "sent": "So we are interested in how can we somehow incorporate the incompleteness of knowledge graphs learned from the Knowledge Graph completion task.",
                    "label": 0
                },
                {
                    "sent": "And Secondly.",
                    "label": 0
                },
                {
                    "sent": "The focus is only trying to use the knowledge from knowledge graphs to the item recommendation task.",
                    "label": 0
                },
                {
                    "sent": "While there's no such studies trying to transfer the knowledge from the user item interactions in from the item recommendation task to the Knowledge Graph completion task, so we are interested in these two aspects an.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "These tasks can be formalized as follows, so item recommendations just given user item interactions as well as background knowledge to provide some N recommendations and knowledge.",
                    "label": 1
                },
                {
                    "sent": "Graph completion can be also formalized into the top end object recommendations as in the previous studies.",
                    "label": 1
                },
                {
                    "sent": "So given a subject and predicate pair, it's provided the top end object recommendations.",
                    "label": 0
                },
                {
                    "sent": "And there's many works at and it's very popular line of research for these knowledge index knowledge Graph completion task in recent years, and there's many approaches using factorization approach or embedding approaches and also neural network based models.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So far we use two state of the art approaches for the two tasks for item recommendations.",
                    "label": 0
                },
                {
                    "sent": "We used factorization machines, which is a state of the art approach for.",
                    "label": 1
                },
                {
                    "sent": "Item recommendations, so it's basically has the linear part to capturing user features and item features, and it also captures the interaction between user features.",
                    "label": 0
                },
                {
                    "sent": "An item features based on the latent factors of each features, so these are the like latent features of each.",
                    "label": 1
                },
                {
                    "sent": "Each item feature and the user feature and it's.",
                    "label": 0
                },
                {
                    "sent": "It can be also seen as embedding for each feature.",
                    "label": 0
                },
                {
                    "sent": "And the loss function is trying to get based on the idea that the positive user item interaction should have the higher score compared to the randomly sampled and negative based on negative sampling.",
                    "label": 0
                },
                {
                    "sent": "Strategy should have higher score compared to the randomly sampled user item interaction.",
                    "label": 0
                },
                {
                    "sent": "Training instance.",
                    "label": 0
                },
                {
                    "sent": "And for knowledge graph completion, we see the trends E approach.",
                    "label": 0
                },
                {
                    "sent": "So it's basically based on the idea that the sum of the subject and predicate embeddings should have the similar.",
                    "label": 1
                },
                {
                    "sent": "Similar to the object embeddings for a valid cheapo, so the similarity can be measured in like active distance which is used in the original paper and.",
                    "label": 0
                },
                {
                    "sent": "The loss function is also similar to the pairwise ranking approach, which trying to minimize the, and.",
                    "label": 0
                },
                {
                    "sent": "The idea is that the valid cheapo distance to the smaller than the random triple random triple that randomly sampled within margin.",
                    "label": 0
                },
                {
                    "sent": "So when we.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "See these two vectorization embedding approaches.",
                    "label": 0
                },
                {
                    "sent": "There is 2 representations for the same item in two different tasks.",
                    "label": 1
                },
                {
                    "sent": "One is the item embedding's in the factorization machines for item recommendations and the subject embeddings, which is subject embedding in the Knowledge Graph completion task.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we are trying to understand and formulate is the problem as transfer learning problem.",
                    "label": 0
                },
                {
                    "sent": "So transfer learning is using one task as source task and the other as a target task and we only care about the object function of the target task by transferring knowledge from source task.",
                    "label": 1
                },
                {
                    "sent": "And we trying to model the relationship between these two embeddings.",
                    "label": 0
                },
                {
                    "sent": "So we just investigated two approaches, so the first one is a straightforward way to cheat.",
                    "label": 0
                },
                {
                    "sent": "These two embeddings are exactly the same in both tasks, and Secondly is we added the regularization term which is trying to capture the idea.",
                    "label": 0
                },
                {
                    "sent": "These two meetings in two different tasks should not reside far away from each other.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "An to putting everything together, we're trying to optimize the target task with this, partially optimizing the source task.",
                    "label": 1
                },
                {
                    "sent": "And in terms of the item recommendations, for example, we are trying to there's some training instances and the training data set for item recommendations as target task and for each.",
                    "label": 0
                },
                {
                    "sent": "Then we training with a stochastic gradient descent.",
                    "label": 0
                },
                {
                    "sent": "We're trying to randomly sample for each training instance.",
                    "label": 0
                },
                {
                    "sent": "For item recommendations, we randomly sample one training instance from the source task which has the constraint that the.",
                    "label": 1
                },
                {
                    "sent": "Item in the index training instances.",
                    "label": 1
                },
                {
                    "sent": "The subject in the randomly sampled training instance from the source task.",
                    "label": 0
                },
                {
                    "sent": "So in this case we can have the same size of training instance instances for both task which can be used for stochastic gradient descent algorithm to train to learn the parameters in this index.",
                    "label": 0
                },
                {
                    "sent": "Can factorization model.",
                    "label": 0
                },
                {
                    "sent": "And we use.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The two data standard data set for item recommendations using which is in movie, movie, domain and book domain and we based on these data set way further extracted the knowledge from each domain with respect to the items in two datasets.",
                    "label": 0
                },
                {
                    "sent": "Example using extracting the predicates and objects and you can see the number of triples for each domain.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For training with you for item recommendations, we used 80% for training and 20% for test and 20% for the training data set for validation and hyperparameter tuning and for knowledge graph completion, we used a.",
                    "label": 1
                },
                {
                    "sent": "Evaluation strategy or sampling strategy in the in a previous work, which is for a given subject, we randomly choose a predicate to construct the SP pair as the test set and the other cheapos containing S as the training set.",
                    "label": 0
                },
                {
                    "sent": "And this is the one like sampling strategy to construct the training and test sets for both tasks.",
                    "label": 1
                },
                {
                    "sent": "And we repeat it 5 times and sampling these new training and test set and average the results to report.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we for recommender systems we used value established evaluation metrics such as normalized, discounted cumulative gain, which takes into account up the relevant items as well as their rank positions and the mean reciprocal rank, which measures the 1st letter print item occurs on average in recommendations and well known precision and recall measures.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for each task, we compared with three baselines for item recommendations, we use the K nearest enable algorithm as the baseline, and the PPRF is can be seen as our core factorization model without transferring knowledge from the other task.",
                    "label": 0
                },
                {
                    "sent": "From the Knowledge compilation task and FML, ODI is is also using factorization machines, but extracting the knowledge enabled features.",
                    "label": 0
                },
                {
                    "sent": "Using existing knowledge and feed it into the factorization machines and knowledge for knowledge Graph completion task we used the most frequent per predicate.",
                    "label": 1
                },
                {
                    "sent": "It's just recommending the object most frequently occurring with the given predicate and PTF.",
                    "label": 0
                },
                {
                    "sent": "Ann is also using factorization machines, but using the subject and predicate and objects as the features and capturing the interactions between these 3 features.",
                    "label": 1
                },
                {
                    "sent": "And chance it can be seen as our core factorization model without transferring knowledge from item recommendations.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And I also I only show the results on the movielens data set for the time constraint.",
                    "label": 0
                },
                {
                    "sent": "But the first observation for remove lens data set is that when we modeling the.",
                    "label": 0
                },
                {
                    "sent": "Two different representations in two different tasks for the item or subject to embeddings, like using regularization term, is performing better compared to aligning the embeddings that based on the assumption that these two embeddings into different tasks are exactly the same on the movielens data set, which is also in both tasks has the same results.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And Secondly, is that.",
                    "label": 0
                },
                {
                    "sent": "Compared to the existing like semantics, aware recommender systems consuming the existing knowledge, our model somehow incorporating the incompleteness of knowledge graph and compared to the model leveraging the existing knowledge may have some significant improvement compared to the dexis semantics aware recommender system approach.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And certainly when we compared to the models without transferring knowledge from each task, we can see that in both Alto recommendations and the Knowledge Graph completion task, transferring knowledge can performs better compared to the model without transferring knowledge from the other task.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to summarize, index work.",
                    "label": 0
                },
                {
                    "sent": "We investigated the knowledge transfer between between item recommendations and knowledge graph completion with a factorization model, and we showed that incorporating the incompleteness of knowledge graph can improve the item recommendation performance and the knowledge from the item recommendations also can be transferred to the Knowledge Graph completion task and improve its performance, which has not been studied before.",
                    "label": 1
                },
                {
                    "sent": "An and it's it's a.",
                    "label": 0
                },
                {
                    "sent": "Ongoing work, and there's many limitations on this work as well.",
                    "label": 0
                },
                {
                    "sent": "So, for example, we considered the domain specific knowledge graph as the directly connected predictive predicate and object about the items.",
                    "label": 0
                },
                {
                    "sent": "While you can apply some fine grained way to extract the sub graph of a domain specific knowledge graph from DB pedia and to improve the.",
                    "label": 1
                },
                {
                    "sent": "Tommy specific knowledge graph for knowledge Graph completion task, and Secondly, the modeling strategy for the relationship between the two items.",
                    "label": 0
                },
                {
                    "sent": "Item representations in two different tasks has some constraint like they need to have have the same dimensionality which she might not be necessarily that true and you can model the item and subject embeddings.",
                    "label": 1
                },
                {
                    "sent": "Then in two different tasks with the two different dimensionality values and then trying to find a way to project these two embeddings with two different dimensionalities into the same space or etc.",
                    "label": 0
                },
                {
                    "sent": "And we can also try other state of the art approaches for both tasks.",
                    "label": 0
                },
                {
                    "sent": "And also we only evaluated in movie movie domain and book domain and we're currently also evaluating on the music domain to see if it can be channelized in other domains as well.",
                    "label": 0
                },
                {
                    "sent": "So yeah, that's it, thank.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For your attention.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much for the talk questions.",
                    "label": 0
                },
                {
                    "sent": "Any?",
                    "label": 0
                },
                {
                    "sent": "To myself.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much for your talk.",
                    "label": 1
                },
                {
                    "sent": "I was just wondering maybe I missed the point, but how did you perform feature selection for your recommendation time?",
                    "label": 0
                },
                {
                    "sent": "So did you select the you know the?",
                    "label": 0
                },
                {
                    "sent": "Hold old properties of of an item or you know.",
                    "label": 0
                },
                {
                    "sent": "You selected just a subset of this properties.",
                    "label": 0
                },
                {
                    "sent": "In case how did you select this subset?",
                    "label": 0
                },
                {
                    "sent": "For for this way just to use the user and item as the features for, like factorization machines.",
                    "label": 0
                },
                {
                    "sent": "So it's basically is the metric factorization in this sense.",
                    "label": 0
                },
                {
                    "sent": "I, if you mean the baselines in other approach consuming the background knowledge E. We we we we extracted the predicate and object as well as on some knowledge graph enabled features to feed into factorization machines for comparison.",
                    "label": 0
                },
                {
                    "sent": "So it's also including some Pagerank scores of the entities for item recommendations as well.",
                    "label": 0
                },
                {
                    "sent": "OK, more questions.",
                    "label": 0
                },
                {
                    "sent": "OK, since there are no more questions, let's thank the speaker and all the speakers again, thank you.",
                    "label": 0
                }
            ]
        }
    }
}