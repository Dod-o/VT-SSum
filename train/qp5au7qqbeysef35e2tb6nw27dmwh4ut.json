{
    "id": "qp5au7qqbeysef35e2tb6nw27dmwh4ut",
    "title": "Mining Term Association Patterns from Search Logs for Effective Query Reformulation",
    "info": {
        "author": [
            "Xuanhui Wang, University of Illinois at Urbana-Champaign"
        ],
        "published": "Nov. 19, 2008",
        "recorded": "October 2008",
        "category": [
            "Top->Computer Science->Data Mining"
        ]
    },
    "url": "http://videolectures.net/cikm08_wang_mtapf/",
    "segmentation": [
        [
            "Mining term Association patents from search logs for effective query reformulation and speakers from UIUC, the Shanghai one thank you.",
            "Can you hear me?",
            "OK, good so today I'm going to present my internal Association patterns from search logs for effective query formulation, so I'm sure home out here.",
            "So this is my job.",
            "Don't work with my advisor.",
            "Professors can die from the University of Illinois."
        ],
        [
            "OK, I think people use social social search engine every day.",
            "And people meant a lot to submit a lot of queries to the search engine.",
            "There is some queries which is very ineffectively on.",
            "On the other hand, there are some query effective.",
            "So here I just give you an example about the ineffective queries.",
            "So this query is reduced space command in the latex.",
            "Since this is 1 ineffective program at in doing my research, when I write the paper, sometimes my my content is out of space.",
            "I want to reduce it a little bit to let the let the content fit the page limit.",
            "If I included this query into the search box, what I need is that I want to find some command in the latex which could reduce the space a little bit.",
            "But if you think this query to the search engine, you'll feel disappointed because none of the result is relevant."
        ],
        [
            "But on the other hand, if you just change the query a little bit, changing the reduced to squeeze Squeeze Space command in latex, and then this quarter will be very effective and you will see that top of lots.",
            "You can find what you want.",
            "OK."
        ],
        [
            "There's more examples, so for example, if you want to wash your vehicle and you input the query, we could both are outdoors list.",
            "These courses are not as effective as car wash or trackballs.",
            "If you want to buy a car when you input the query auto quotes, this query is not specific enough to get the relevant result because there might be some content which is about the sales.",
            "There's other content which other insurance, so it's better for you to add a query at the term cell into this query, making the more specific.",
            "Then you will get a better result.",
            "So here is just more example about effective query an ineffective queries."
        ],
        [
            "OK, so then the next, next, next question is what makes a query ineffective.",
            "There might be a lot of different reasons, but as we observe that there are two types of the two type of, the reason which are predominant, the first one is vocabulary mismatch.",
            "So you can see that reduced space let command in Latex and Squeeze Space Command in the latex.",
            "They're just changing one word.",
            "Send the query is more effective because England relevant documents that people use the screens instead of reveals.",
            "So the second reason is about lack of discrimination.",
            "Auto quote is not as discriminative as auto sale codes.",
            "If you add this word in then the query quality has improved.",
            "So the next question is how can we improve help improve this query?",
            "Effective effectiveness to improve those ineffective queries.",
            "So obviously here if we substitute one keywords by the other.",
            "Substitute the screens by that reduce labor help this ineffective query.",
            "This one is term substitution.",
            "The second one is term addition.",
            "We add a term into this query and then make the term more effective.",
            "OK, so this is 2 type of approach we can take."
        ],
        [
            "To address the quarters and in this paper we cast this query reformulation as a term level pattern, term level pattern mining from the search logs.",
            "So this is a particularly different from the previous work, which which they in which the only fund the patterns in the query level, and we define two basic types.",
            "Two basic types of patterns at the team level, specifically the first one is context sensitive term substitution, so here you can see two examples.",
            "The second one is context sensitive term addition.",
            "Talking with certain Contacts, so we want to add a keyword to make the.",
            "Making the query more specific, so these are two type of pattern we defined and we propose a purple probabilistic method to mine these patterns from search logs and we also evaluate our method on the commercial search engine log to show their effect."
        ],
        [
            "Ice.",
            "OK, here is our problem formulation.",
            "So first we have a.",
            "We have a collection with such logs at contents, queries, clicks and suddenly the time that people submit this record.",
            "A lot of information.",
            "In this paper, we only take the query from the slugs, so we extract extract those queries that contains in this search log and put them into a classroom collection, and we call it the query collection based on this query collection, we analyze the term of Co occurrence patterns inside the query instead of the queries and build 2 models.",
            "Two types of models.",
            "The first one is context Rimando.",
            "This our first task I'm going to describe later.",
            "The second is the translation model an.",
            "Welcome, I'm going to just get discriminator too, so this is awful.",
            "I park.",
            "I like parks when you are input the query out towards such as model costs.",
            "This will be passed into the pattern mining and component.",
            "The server third task.",
            "So this component will take the query as input and rely on the two models context model and translation model.",
            "The output of this model.",
            "Monitor is patterns.",
            "Two types of patterns.",
            "The first pattern is term substitution pattern is term addition, so you can see that these two patterns naturally give you a refund query formally deported.",
            "So for example, the output could be Carlos too as a reformulation as a query or outdoors.",
            "OK, so this is the general picture about the content in."
        ],
        [
            "In this talk.",
            "So our first task is to build a context for model.",
            "So this model is highly related to the syntax syntagmatic relations in the natural language processing community.",
            "Basically it's capital terms which frequently Co occurs with the current term W inside the queries.",
            "So given so here I give you a sample query collection.",
            "In this collection we have a several query terms queries.",
            "So suppose currently we want to build the context model for the word car.",
            "Zambia.",
            "Different types of context.",
            "So obviously the first one is general context, which means that any keywords which crew Co occur with car instead of any queries, we take it as a key.",
            "Words in this general context.",
            "So you can think that this is the back of keywords and in our paper we model this context general contact using language model approach.",
            "So basically here is a maximum likelihood estimation for this model giving a bag or contact back for keywords.",
            "As a general context, so OK, this is of our general Contacts."
        ],
        [
            "We can build a more isthmus, more accurate, the context, which is to capture the position of the keywords.",
            "For example, this is I 01 context, which means this keyword occur on the left side of the car and also the is just adjacent to the car.",
            "So based on this bagger words we can also build a language model which is my own language model, which means the left first left context model.",
            "So you can also build level 2, L, 3 and so on.",
            "So."
        ],
        [
            "Semantically, we computed the right context R1R2R3 and so on.",
            "So basically, for each context, we have a context model, and so basically language model.",
            "OK, this is the first task building the context model."
        ],
        [
            "On this, in the second task, we are going to describe how could we build the translation model.",
            "This translation model is particularly have a very short related to the paradigmatic relations relations in the natural language processing community.",
            "Basically, it's capital terms which are near synonyms for the current world.",
            "Current word.",
            "That means they are substitute substitutable with the word W. The basic idea to build this translation model is that based on their context.",
            "So the assumption is that if the two words have similar contexts, then they are going to have a high paradigmatic relation and welcome to assign assign high translation probability to this key to these two keywords.",
            "OK, specifically, we use the translation model in the following formula.",
            "You do not need to understand that your family exactly.",
            "Basically we model the translation probability as the probability probability of generating ice the context.",
            "From a WS context model, so we have two keyboards and WI want to compute their translation probability and we utilize this utilizes formula as the probability to estimate the probability.",
            "So we have introduced several different types of context context, general counsel L1 and R1 context.",
            "In this paper we waited, combined L1 context an R1 context to build this context, build this translation model so.",
            "The formula is also at the bottom of this slide.",
            "OK, so this."
        ],
        [
            "The second task translation model, so the third task we have two or sub tasks.",
            "First task is to manage those term substitution patterns.",
            "From the from lock.",
            "So given the query Q as a single keywords, so we have consistently done keywords here the man is that we want to substitute the one of the keywords WI, but another word ice and then generating a new query Cooper Mark Q Prime at this following.",
            "Obviously we do not know which has to select.",
            "So in this paper we cast this as a probability estimation problem.",
            "So this probability is the meaning of this probability that given the context W 1 to WM, as soon as the left context W I + 1 two WN azerite context, we want to substitute choose a word as to substitute WI, so these are probably that we want to estimate if you do a little bit of derivation, you will find that this consists of two components.",
            "The first one is the global factor.",
            "Which means how WWINS are similar in the global sense.",
            "This is a global phase factor.",
            "We use our translation model to model that.",
            "The second one is a local factor.",
            "The intuition behind this probability that demonize how likely this context happens as the Contacts of the S. So this is a local factor.",
            "You can see that the global factor we have the translation model to handle that we already introduced for the center one to the local."
        ],
        [
            "After here's a method that we take it to estimate at this local matter, we basically assume the world are happened in dependently besides around eyes.",
            "So if we do this independent independence assumption then this probability can be separated.",
            "So for example.",
            "The topic I -- 1 or current Uncle just on the left side of lies.",
            "We can use the other one context model to model this probability and so on for the WN plus one.",
            "We can use our one context context models model this probability and use paper.",
            "We ignore those terms which are far away.",
            "We only consider those terms which are pretty close to the S, which means the left tool and the right tool and use this as an approximation for the local factor.",
            "OK."
        ],
        [
            "So the second part of the task is raised about path money for the term addition patterns.",
            "So here still you have a query Q as a sequence of the keywords and you want to add 1 key words just before WI this Edward R. So you come up we output a new query Q prime and also we want to know which are we should add.",
            "This is also a probability estimation problem model this this one, and if you do a little bit of division you will find this has two components.",
            "The first lines how likely this are occur occur this probability.",
            "The second one is how likely this context occurs as a context of the keyword R OK, the first one we take is that uniform the second one.",
            "This is pretty similar to the local factor estimation in the term substitute substitution pattern, so we will.",
            "I will not repeat it the estimation again.",
            "So basically this finish the second part of the task.",
            "OK."
        ],
        [
            "So next I'm going to introduce some experiment for the day to prepare preparation, we use the search logs from the Microsoft Live Labs, so this log spends one month.",
            "We take the 1st 20 days at the history log and for the other 11 days we use the future log and we construct our test cases.",
            "So in this history log we construct our queries, we extract the query and construct the query collections.",
            "Here are some statistical static.",
            "Statistical so about this.",
            "Our collection for the future longer we use them to color contrast, construct the test cases to test our algorithm."
        ],
        [
            "OK.",
            "So the first thing I want to show you in some examples about the context or model.",
            "So the word the word W here is car and we show some general context.",
            "I want Contacts are one context.",
            "If you take a look at the closed till close look at about this I want and I want you find that these two models are very different.",
            "So this means it's not it's it's good to model the Iowa left context and right context precisely.",
            "You can see that the general context is just some mixture mixed left context the right context.",
            "Together"
        ],
        [
            "OK, so for the second one is just show you some examples of other translation model.",
            "So here at least three examples of the first ones computer you can see that those trends which has high translation probability constantly, computers, laptop or PC and notebook and others legs.",
            "You have.",
            "Those stomach collects muscle so we can see that this conceptually similar keywords have very high translation probability.",
            "This confirms the effectiveness about our translation model and also you can see that those terms provide pro possibility.",
            "For exploratory search in an interactive manner so we do not want to, this can translate translation model to be very automatically in interactive manner.",
            "People can choose which words they want to substitute, select one of the suggestion."
        ],
        [
            "OK, here's some examples of other translation term substitution, so you can see that this is really context sensitive.",
            "So for example, given in the first example is given the context of wash. We want to substitute the auto buy a car, but on the other hand, if the context change as the context changes, so the current context is a trade that we want to substitute the occur by auto just in reverse direction.",
            "So this shows the pattern is really contact context sensitive.",
            "And also you can see that this is rewarding.",
            "The queries are more effective, basically based on your intuition."
        ],
        [
            "OK so here is some effective component, reasonable substitutions this our experiment design.",
            "So we take the user session as our as our ground, choose to construct the hunters.",
            "So is in each user session.",
            "User has submitted.",
            "This year we will submit the several queries.",
            "So for example people user have submitted queries.",
            "We take the first query Q1 as our input and we want to recommend some reformulated queries.",
            "Through this Q1 and users user in the session there has Q22Q K and each query has some clicked documents.",
            "So how could we evaluate our now?",
            "How well, how well our reformulated recommended query is, good or not.",
            "So we basically to see how well can I reformulate their query rank those click document on the top.",
            "So here for example.",
            "If we give him the cure for Q1, we recommend three keywords, reformulated the quirky words OK. And for each QQ one prime Q2 prime accused 3:00 PM.",
            "We have a list of documents and those are click document types are inside this ranked list.",
            "We compute the Precision 5 for each of this ranked list.",
            "So for example, president of the first one is .6 and then how to evaluate our evaluation metric?",
            "Is that the best precision fire among the three Kia?",
            "Three recommended queries?",
            "So this in this.",
            "Example, the best precision fire with a deer .6.",
            "So we use best precision five as our evaluation."
        ],
        [
            "Magic.",
            "So here's the result.",
            "We basically where is the number of the recommended queries and to compute the precision of foreach foreach foreach setting, we basically compared to three method.",
            "The first one is our words.",
            "This is Jones 06.",
            "So our method is based on term level patterns.",
            "But Jones paper is based on the query level patterns that you can see that our method reformulated queries more effectively.",
            "The intuition behind this is that our methods used some global information too.",
            "Global information to see the translation model really captures the global information.",
            "How to keywords are similar, so Jones Master is kind of just use some local information inside the session.",
            "They do not use those kind of global information, so this is some argument why our method is a little bit better than the."
        ],
        [
            "OK so here is some examples about the term additional pattern.",
            "Intuitively you can see the game where you brought query wedding.",
            "So our mind pattern could refund this query.",
            "A meaningfully so you can see that other keywords are critical in two different aspects of the of the of the query body and this term substitution pattern meaningful."
        ],
        [
            "OK, for the related work, we have three types of religion works.",
            "The first one is first Gestion.",
            "This based on the query query level patterns, dispatcher pattern as the query level and it does not consider the effectiveness.",
            "The second one is a query modification in the are basically the land, the top return the documents to modify query.",
            "Not too long, the search logs and the third one is later working.",
            "RP community and they find it synonyms or near synonyms and they do not use them for the court suggestion or query formula."
        ],
        [
            "OK, so here's the conclusion in our.",
            "In this paper, we propose a new way to mind such logs for patterns to address ineffective queries.",
            "Specifically, we address the vocabulary mismatch and like for discrete discrimination problem and we define the mind two basic patterns at term level, context sensitive term substitution patterns, and term addition patterns.",
            "And we also conduct the experiment to show the effectiveness of our method in the future.",
            "We want to utilize those relevance judgments instead.",
            "Click to evaluate which query is better.",
            "Currently user click just as appropriate approximation and these people we did not explore click information.",
            "We only run the query collection so it's in the future we can explore those click informations to find better patterns for the query formulation."
        ],
        [
            "This feature is my top.",
            "Thank you.",
            "K is for some short questions.",
            "OK, I have ice cream about.",
            "You use the query log for your training, but you also use the query log for your testing.",
            "Is there any bias?",
            "I think.",
            "Because currently we use the search logs, we use a stand by the separation, so there's some history history history collection.",
            "There is some future collection, so this these are not together based based on time, but I think in the reality when you have a lot of history search logs when the user account this is a simulation about interview scenario when people in put some queries that we want to just we want to suggest some query reformulations so we use the future log as some simulation about that.",
            "You you decided to see whether we can do it, but I think it is still reasonable to use the future queries, future logs as assimilation about the future user behavior.",
            "But if you have, you can try some human effort for the future log and have a track whether it's best for us.",
            "It should be better.",
            "Not sure so clarified, you can have some human effort and label the future future logs and check whether this there's some.",
            "Yeah yeah, I think the the most the best scenario to evaluate this message to allow the user to do it today.",
            "So give us such an interface with.",
            "Recommend some queries and let the user to decide whether it's good or not.",
            "I think this is the best scenario to evaluate this match the counter.",
            "We do some commercial approximation that's true.",
            "Any other questions?",
            "OK, I have one suggestion for you, but there is another walk in cigar this year in July and they tacked on the refund query with the term relationship in the query log.",
            "OK so you may if you still need to publish your work in the future you may still may be compared with them, thanks.",
            "Thanks to speakers."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Mining term Association patents from search logs for effective query reformulation and speakers from UIUC, the Shanghai one thank you.",
                    "label": 1
                },
                {
                    "sent": "Can you hear me?",
                    "label": 0
                },
                {
                    "sent": "OK, good so today I'm going to present my internal Association patterns from search logs for effective query formulation, so I'm sure home out here.",
                    "label": 0
                },
                {
                    "sent": "So this is my job.",
                    "label": 0
                },
                {
                    "sent": "Don't work with my advisor.",
                    "label": 0
                },
                {
                    "sent": "Professors can die from the University of Illinois.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, I think people use social social search engine every day.",
                    "label": 0
                },
                {
                    "sent": "And people meant a lot to submit a lot of queries to the search engine.",
                    "label": 0
                },
                {
                    "sent": "There is some queries which is very ineffectively on.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, there are some query effective.",
                    "label": 0
                },
                {
                    "sent": "So here I just give you an example about the ineffective queries.",
                    "label": 1
                },
                {
                    "sent": "So this query is reduced space command in the latex.",
                    "label": 1
                },
                {
                    "sent": "Since this is 1 ineffective program at in doing my research, when I write the paper, sometimes my my content is out of space.",
                    "label": 0
                },
                {
                    "sent": "I want to reduce it a little bit to let the let the content fit the page limit.",
                    "label": 0
                },
                {
                    "sent": "If I included this query into the search box, what I need is that I want to find some command in the latex which could reduce the space a little bit.",
                    "label": 0
                },
                {
                    "sent": "But if you think this query to the search engine, you'll feel disappointed because none of the result is relevant.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But on the other hand, if you just change the query a little bit, changing the reduced to squeeze Squeeze Space command in latex, and then this quarter will be very effective and you will see that top of lots.",
                    "label": 1
                },
                {
                    "sent": "You can find what you want.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There's more examples, so for example, if you want to wash your vehicle and you input the query, we could both are outdoors list.",
                    "label": 1
                },
                {
                    "sent": "These courses are not as effective as car wash or trackballs.",
                    "label": 1
                },
                {
                    "sent": "If you want to buy a car when you input the query auto quotes, this query is not specific enough to get the relevant result because there might be some content which is about the sales.",
                    "label": 0
                },
                {
                    "sent": "There's other content which other insurance, so it's better for you to add a query at the term cell into this query, making the more specific.",
                    "label": 0
                },
                {
                    "sent": "Then you will get a better result.",
                    "label": 0
                },
                {
                    "sent": "So here is just more example about effective query an ineffective queries.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so then the next, next, next question is what makes a query ineffective.",
                    "label": 1
                },
                {
                    "sent": "There might be a lot of different reasons, but as we observe that there are two types of the two type of, the reason which are predominant, the first one is vocabulary mismatch.",
                    "label": 0
                },
                {
                    "sent": "So you can see that reduced space let command in Latex and Squeeze Space Command in the latex.",
                    "label": 0
                },
                {
                    "sent": "They're just changing one word.",
                    "label": 0
                },
                {
                    "sent": "Send the query is more effective because England relevant documents that people use the screens instead of reveals.",
                    "label": 1
                },
                {
                    "sent": "So the second reason is about lack of discrimination.",
                    "label": 0
                },
                {
                    "sent": "Auto quote is not as discriminative as auto sale codes.",
                    "label": 0
                },
                {
                    "sent": "If you add this word in then the query quality has improved.",
                    "label": 0
                },
                {
                    "sent": "So the next question is how can we improve help improve this query?",
                    "label": 0
                },
                {
                    "sent": "Effective effectiveness to improve those ineffective queries.",
                    "label": 0
                },
                {
                    "sent": "So obviously here if we substitute one keywords by the other.",
                    "label": 0
                },
                {
                    "sent": "Substitute the screens by that reduce labor help this ineffective query.",
                    "label": 0
                },
                {
                    "sent": "This one is term substitution.",
                    "label": 0
                },
                {
                    "sent": "The second one is term addition.",
                    "label": 0
                },
                {
                    "sent": "We add a term into this query and then make the term more effective.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is 2 type of approach we can take.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To address the quarters and in this paper we cast this query reformulation as a term level pattern, term level pattern mining from the search logs.",
                    "label": 1
                },
                {
                    "sent": "So this is a particularly different from the previous work, which which they in which the only fund the patterns in the query level, and we define two basic types.",
                    "label": 1
                },
                {
                    "sent": "Two basic types of patterns at the team level, specifically the first one is context sensitive term substitution, so here you can see two examples.",
                    "label": 0
                },
                {
                    "sent": "The second one is context sensitive term addition.",
                    "label": 0
                },
                {
                    "sent": "Talking with certain Contacts, so we want to add a keyword to make the.",
                    "label": 0
                },
                {
                    "sent": "Making the query more specific, so these are two type of pattern we defined and we propose a purple probabilistic method to mine these patterns from search logs and we also evaluate our method on the commercial search engine log to show their effect.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Ice.",
                    "label": 0
                },
                {
                    "sent": "OK, here is our problem formulation.",
                    "label": 1
                },
                {
                    "sent": "So first we have a.",
                    "label": 0
                },
                {
                    "sent": "We have a collection with such logs at contents, queries, clicks and suddenly the time that people submit this record.",
                    "label": 0
                },
                {
                    "sent": "A lot of information.",
                    "label": 0
                },
                {
                    "sent": "In this paper, we only take the query from the slugs, so we extract extract those queries that contains in this search log and put them into a classroom collection, and we call it the query collection based on this query collection, we analyze the term of Co occurrence patterns inside the query instead of the queries and build 2 models.",
                    "label": 0
                },
                {
                    "sent": "Two types of models.",
                    "label": 0
                },
                {
                    "sent": "The first one is context Rimando.",
                    "label": 0
                },
                {
                    "sent": "This our first task I'm going to describe later.",
                    "label": 0
                },
                {
                    "sent": "The second is the translation model an.",
                    "label": 0
                },
                {
                    "sent": "Welcome, I'm going to just get discriminator too, so this is awful.",
                    "label": 0
                },
                {
                    "sent": "I park.",
                    "label": 0
                },
                {
                    "sent": "I like parks when you are input the query out towards such as model costs.",
                    "label": 1
                },
                {
                    "sent": "This will be passed into the pattern mining and component.",
                    "label": 0
                },
                {
                    "sent": "The server third task.",
                    "label": 0
                },
                {
                    "sent": "So this component will take the query as input and rely on the two models context model and translation model.",
                    "label": 0
                },
                {
                    "sent": "The output of this model.",
                    "label": 0
                },
                {
                    "sent": "Monitor is patterns.",
                    "label": 0
                },
                {
                    "sent": "Two types of patterns.",
                    "label": 0
                },
                {
                    "sent": "The first pattern is term substitution pattern is term addition, so you can see that these two patterns naturally give you a refund query formally deported.",
                    "label": 0
                },
                {
                    "sent": "So for example, the output could be Carlos too as a reformulation as a query or outdoors.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is the general picture about the content in.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In this talk.",
                    "label": 0
                },
                {
                    "sent": "So our first task is to build a context for model.",
                    "label": 0
                },
                {
                    "sent": "So this model is highly related to the syntax syntagmatic relations in the natural language processing community.",
                    "label": 0
                },
                {
                    "sent": "Basically it's capital terms which frequently Co occurs with the current term W inside the queries.",
                    "label": 1
                },
                {
                    "sent": "So given so here I give you a sample query collection.",
                    "label": 1
                },
                {
                    "sent": "In this collection we have a several query terms queries.",
                    "label": 0
                },
                {
                    "sent": "So suppose currently we want to build the context model for the word car.",
                    "label": 0
                },
                {
                    "sent": "Zambia.",
                    "label": 0
                },
                {
                    "sent": "Different types of context.",
                    "label": 0
                },
                {
                    "sent": "So obviously the first one is general context, which means that any keywords which crew Co occur with car instead of any queries, we take it as a key.",
                    "label": 1
                },
                {
                    "sent": "Words in this general context.",
                    "label": 0
                },
                {
                    "sent": "So you can think that this is the back of keywords and in our paper we model this context general contact using language model approach.",
                    "label": 0
                },
                {
                    "sent": "So basically here is a maximum likelihood estimation for this model giving a bag or contact back for keywords.",
                    "label": 0
                },
                {
                    "sent": "As a general context, so OK, this is of our general Contacts.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We can build a more isthmus, more accurate, the context, which is to capture the position of the keywords.",
                    "label": 0
                },
                {
                    "sent": "For example, this is I 01 context, which means this keyword occur on the left side of the car and also the is just adjacent to the car.",
                    "label": 0
                },
                {
                    "sent": "So based on this bagger words we can also build a language model which is my own language model, which means the left first left context model.",
                    "label": 0
                },
                {
                    "sent": "So you can also build level 2, L, 3 and so on.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Semantically, we computed the right context R1R2R3 and so on.",
                    "label": 0
                },
                {
                    "sent": "So basically, for each context, we have a context model, and so basically language model.",
                    "label": 0
                },
                {
                    "sent": "OK, this is the first task building the context model.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "On this, in the second task, we are going to describe how could we build the translation model.",
                    "label": 0
                },
                {
                    "sent": "This translation model is particularly have a very short related to the paradigmatic relations relations in the natural language processing community.",
                    "label": 0
                },
                {
                    "sent": "Basically, it's capital terms which are near synonyms for the current world.",
                    "label": 0
                },
                {
                    "sent": "Current word.",
                    "label": 0
                },
                {
                    "sent": "That means they are substitute substitutable with the word W. The basic idea to build this translation model is that based on their context.",
                    "label": 0
                },
                {
                    "sent": "So the assumption is that if the two words have similar contexts, then they are going to have a high paradigmatic relation and welcome to assign assign high translation probability to this key to these two keywords.",
                    "label": 0
                },
                {
                    "sent": "OK, specifically, we use the translation model in the following formula.",
                    "label": 0
                },
                {
                    "sent": "You do not need to understand that your family exactly.",
                    "label": 0
                },
                {
                    "sent": "Basically we model the translation probability as the probability probability of generating ice the context.",
                    "label": 1
                },
                {
                    "sent": "From a WS context model, so we have two keyboards and WI want to compute their translation probability and we utilize this utilizes formula as the probability to estimate the probability.",
                    "label": 0
                },
                {
                    "sent": "So we have introduced several different types of context context, general counsel L1 and R1 context.",
                    "label": 1
                },
                {
                    "sent": "In this paper we waited, combined L1 context an R1 context to build this context, build this translation model so.",
                    "label": 0
                },
                {
                    "sent": "The formula is also at the bottom of this slide.",
                    "label": 0
                },
                {
                    "sent": "OK, so this.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The second task translation model, so the third task we have two or sub tasks.",
                    "label": 0
                },
                {
                    "sent": "First task is to manage those term substitution patterns.",
                    "label": 0
                },
                {
                    "sent": "From the from lock.",
                    "label": 0
                },
                {
                    "sent": "So given the query Q as a single keywords, so we have consistently done keywords here the man is that we want to substitute the one of the keywords WI, but another word ice and then generating a new query Cooper Mark Q Prime at this following.",
                    "label": 0
                },
                {
                    "sent": "Obviously we do not know which has to select.",
                    "label": 0
                },
                {
                    "sent": "So in this paper we cast this as a probability estimation problem.",
                    "label": 0
                },
                {
                    "sent": "So this probability is the meaning of this probability that given the context W 1 to WM, as soon as the left context W I + 1 two WN azerite context, we want to substitute choose a word as to substitute WI, so these are probably that we want to estimate if you do a little bit of derivation, you will find that this consists of two components.",
                    "label": 0
                },
                {
                    "sent": "The first one is the global factor.",
                    "label": 0
                },
                {
                    "sent": "Which means how WWINS are similar in the global sense.",
                    "label": 0
                },
                {
                    "sent": "This is a global phase factor.",
                    "label": 0
                },
                {
                    "sent": "We use our translation model to model that.",
                    "label": 0
                },
                {
                    "sent": "The second one is a local factor.",
                    "label": 1
                },
                {
                    "sent": "The intuition behind this probability that demonize how likely this context happens as the Contacts of the S. So this is a local factor.",
                    "label": 0
                },
                {
                    "sent": "You can see that the global factor we have the translation model to handle that we already introduced for the center one to the local.",
                    "label": 1
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "After here's a method that we take it to estimate at this local matter, we basically assume the world are happened in dependently besides around eyes.",
                    "label": 0
                },
                {
                    "sent": "So if we do this independent independence assumption then this probability can be separated.",
                    "label": 0
                },
                {
                    "sent": "So for example.",
                    "label": 0
                },
                {
                    "sent": "The topic I -- 1 or current Uncle just on the left side of lies.",
                    "label": 0
                },
                {
                    "sent": "We can use the other one context model to model this probability and so on for the WN plus one.",
                    "label": 0
                },
                {
                    "sent": "We can use our one context context models model this probability and use paper.",
                    "label": 0
                },
                {
                    "sent": "We ignore those terms which are far away.",
                    "label": 1
                },
                {
                    "sent": "We only consider those terms which are pretty close to the S, which means the left tool and the right tool and use this as an approximation for the local factor.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the second part of the task is raised about path money for the term addition patterns.",
                    "label": 0
                },
                {
                    "sent": "So here still you have a query Q as a sequence of the keywords and you want to add 1 key words just before WI this Edward R. So you come up we output a new query Q prime and also we want to know which are we should add.",
                    "label": 0
                },
                {
                    "sent": "This is also a probability estimation problem model this this one, and if you do a little bit of division you will find this has two components.",
                    "label": 0
                },
                {
                    "sent": "The first lines how likely this are occur occur this probability.",
                    "label": 0
                },
                {
                    "sent": "The second one is how likely this context occurs as a context of the keyword R OK, the first one we take is that uniform the second one.",
                    "label": 0
                },
                {
                    "sent": "This is pretty similar to the local factor estimation in the term substitute substitution pattern, so we will.",
                    "label": 1
                },
                {
                    "sent": "I will not repeat it the estimation again.",
                    "label": 0
                },
                {
                    "sent": "So basically this finish the second part of the task.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So next I'm going to introduce some experiment for the day to prepare preparation, we use the search logs from the Microsoft Live Labs, so this log spends one month.",
                    "label": 1
                },
                {
                    "sent": "We take the 1st 20 days at the history log and for the other 11 days we use the future log and we construct our test cases.",
                    "label": 0
                },
                {
                    "sent": "So in this history log we construct our queries, we extract the query and construct the query collections.",
                    "label": 0
                },
                {
                    "sent": "Here are some statistical static.",
                    "label": 0
                },
                {
                    "sent": "Statistical so about this.",
                    "label": 0
                },
                {
                    "sent": "Our collection for the future longer we use them to color contrast, construct the test cases to test our algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So the first thing I want to show you in some examples about the context or model.",
                    "label": 0
                },
                {
                    "sent": "So the word the word W here is car and we show some general context.",
                    "label": 1
                },
                {
                    "sent": "I want Contacts are one context.",
                    "label": 0
                },
                {
                    "sent": "If you take a look at the closed till close look at about this I want and I want you find that these two models are very different.",
                    "label": 1
                },
                {
                    "sent": "So this means it's not it's it's good to model the Iowa left context and right context precisely.",
                    "label": 0
                },
                {
                    "sent": "You can see that the general context is just some mixture mixed left context the right context.",
                    "label": 0
                },
                {
                    "sent": "Together",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so for the second one is just show you some examples of other translation model.",
                    "label": 0
                },
                {
                    "sent": "So here at least three examples of the first ones computer you can see that those trends which has high translation probability constantly, computers, laptop or PC and notebook and others legs.",
                    "label": 0
                },
                {
                    "sent": "You have.",
                    "label": 0
                },
                {
                    "sent": "Those stomach collects muscle so we can see that this conceptually similar keywords have very high translation probability.",
                    "label": 1
                },
                {
                    "sent": "This confirms the effectiveness about our translation model and also you can see that those terms provide pro possibility.",
                    "label": 0
                },
                {
                    "sent": "For exploratory search in an interactive manner so we do not want to, this can translate translation model to be very automatically in interactive manner.",
                    "label": 1
                },
                {
                    "sent": "People can choose which words they want to substitute, select one of the suggestion.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, here's some examples of other translation term substitution, so you can see that this is really context sensitive.",
                    "label": 1
                },
                {
                    "sent": "So for example, given in the first example is given the context of wash. We want to substitute the auto buy a car, but on the other hand, if the context change as the context changes, so the current context is a trade that we want to substitute the occur by auto just in reverse direction.",
                    "label": 0
                },
                {
                    "sent": "So this shows the pattern is really contact context sensitive.",
                    "label": 0
                },
                {
                    "sent": "And also you can see that this is rewarding.",
                    "label": 0
                },
                {
                    "sent": "The queries are more effective, basically based on your intuition.",
                    "label": 1
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK so here is some effective component, reasonable substitutions this our experiment design.",
                    "label": 1
                },
                {
                    "sent": "So we take the user session as our as our ground, choose to construct the hunters.",
                    "label": 0
                },
                {
                    "sent": "So is in each user session.",
                    "label": 0
                },
                {
                    "sent": "User has submitted.",
                    "label": 0
                },
                {
                    "sent": "This year we will submit the several queries.",
                    "label": 0
                },
                {
                    "sent": "So for example people user have submitted queries.",
                    "label": 0
                },
                {
                    "sent": "We take the first query Q1 as our input and we want to recommend some reformulated queries.",
                    "label": 0
                },
                {
                    "sent": "Through this Q1 and users user in the session there has Q22Q K and each query has some clicked documents.",
                    "label": 0
                },
                {
                    "sent": "So how could we evaluate our now?",
                    "label": 0
                },
                {
                    "sent": "How well, how well our reformulated recommended query is, good or not.",
                    "label": 0
                },
                {
                    "sent": "So we basically to see how well can I reformulate their query rank those click document on the top.",
                    "label": 1
                },
                {
                    "sent": "So here for example.",
                    "label": 0
                },
                {
                    "sent": "If we give him the cure for Q1, we recommend three keywords, reformulated the quirky words OK. And for each QQ one prime Q2 prime accused 3:00 PM.",
                    "label": 0
                },
                {
                    "sent": "We have a list of documents and those are click document types are inside this ranked list.",
                    "label": 0
                },
                {
                    "sent": "We compute the Precision 5 for each of this ranked list.",
                    "label": 0
                },
                {
                    "sent": "So for example, president of the first one is .6 and then how to evaluate our evaluation metric?",
                    "label": 0
                },
                {
                    "sent": "Is that the best precision fire among the three Kia?",
                    "label": 0
                },
                {
                    "sent": "Three recommended queries?",
                    "label": 0
                },
                {
                    "sent": "So this in this.",
                    "label": 0
                },
                {
                    "sent": "Example, the best precision fire with a deer .6.",
                    "label": 0
                },
                {
                    "sent": "So we use best precision five as our evaluation.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Magic.",
                    "label": 0
                },
                {
                    "sent": "So here's the result.",
                    "label": 0
                },
                {
                    "sent": "We basically where is the number of the recommended queries and to compute the precision of foreach foreach foreach setting, we basically compared to three method.",
                    "label": 0
                },
                {
                    "sent": "The first one is our words.",
                    "label": 0
                },
                {
                    "sent": "This is Jones 06.",
                    "label": 0
                },
                {
                    "sent": "So our method is based on term level patterns.",
                    "label": 1
                },
                {
                    "sent": "But Jones paper is based on the query level patterns that you can see that our method reformulated queries more effectively.",
                    "label": 1
                },
                {
                    "sent": "The intuition behind this is that our methods used some global information too.",
                    "label": 0
                },
                {
                    "sent": "Global information to see the translation model really captures the global information.",
                    "label": 0
                },
                {
                    "sent": "How to keywords are similar, so Jones Master is kind of just use some local information inside the session.",
                    "label": 0
                },
                {
                    "sent": "They do not use those kind of global information, so this is some argument why our method is a little bit better than the.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK so here is some examples about the term additional pattern.",
                    "label": 0
                },
                {
                    "sent": "Intuitively you can see the game where you brought query wedding.",
                    "label": 0
                },
                {
                    "sent": "So our mind pattern could refund this query.",
                    "label": 0
                },
                {
                    "sent": "A meaningfully so you can see that other keywords are critical in two different aspects of the of the of the query body and this term substitution pattern meaningful.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, for the related work, we have three types of religion works.",
                    "label": 1
                },
                {
                    "sent": "The first one is first Gestion.",
                    "label": 0
                },
                {
                    "sent": "This based on the query query level patterns, dispatcher pattern as the query level and it does not consider the effectiveness.",
                    "label": 1
                },
                {
                    "sent": "The second one is a query modification in the are basically the land, the top return the documents to modify query.",
                    "label": 0
                },
                {
                    "sent": "Not too long, the search logs and the third one is later working.",
                    "label": 1
                },
                {
                    "sent": "RP community and they find it synonyms or near synonyms and they do not use them for the court suggestion or query formula.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so here's the conclusion in our.",
                    "label": 0
                },
                {
                    "sent": "In this paper, we propose a new way to mind such logs for patterns to address ineffective queries.",
                    "label": 1
                },
                {
                    "sent": "Specifically, we address the vocabulary mismatch and like for discrete discrimination problem and we define the mind two basic patterns at term level, context sensitive term substitution patterns, and term addition patterns.",
                    "label": 0
                },
                {
                    "sent": "And we also conduct the experiment to show the effectiveness of our method in the future.",
                    "label": 0
                },
                {
                    "sent": "We want to utilize those relevance judgments instead.",
                    "label": 0
                },
                {
                    "sent": "Click to evaluate which query is better.",
                    "label": 0
                },
                {
                    "sent": "Currently user click just as appropriate approximation and these people we did not explore click information.",
                    "label": 0
                },
                {
                    "sent": "We only run the query collection so it's in the future we can explore those click informations to find better patterns for the query formulation.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This feature is my top.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "K is for some short questions.",
                    "label": 0
                },
                {
                    "sent": "OK, I have ice cream about.",
                    "label": 0
                },
                {
                    "sent": "You use the query log for your training, but you also use the query log for your testing.",
                    "label": 0
                },
                {
                    "sent": "Is there any bias?",
                    "label": 0
                },
                {
                    "sent": "I think.",
                    "label": 0
                },
                {
                    "sent": "Because currently we use the search logs, we use a stand by the separation, so there's some history history history collection.",
                    "label": 0
                },
                {
                    "sent": "There is some future collection, so this these are not together based based on time, but I think in the reality when you have a lot of history search logs when the user account this is a simulation about interview scenario when people in put some queries that we want to just we want to suggest some query reformulations so we use the future log as some simulation about that.",
                    "label": 0
                },
                {
                    "sent": "You you decided to see whether we can do it, but I think it is still reasonable to use the future queries, future logs as assimilation about the future user behavior.",
                    "label": 0
                },
                {
                    "sent": "But if you have, you can try some human effort for the future log and have a track whether it's best for us.",
                    "label": 0
                },
                {
                    "sent": "It should be better.",
                    "label": 0
                },
                {
                    "sent": "Not sure so clarified, you can have some human effort and label the future future logs and check whether this there's some.",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah, I think the the most the best scenario to evaluate this message to allow the user to do it today.",
                    "label": 0
                },
                {
                    "sent": "So give us such an interface with.",
                    "label": 0
                },
                {
                    "sent": "Recommend some queries and let the user to decide whether it's good or not.",
                    "label": 0
                },
                {
                    "sent": "I think this is the best scenario to evaluate this match the counter.",
                    "label": 0
                },
                {
                    "sent": "We do some commercial approximation that's true.",
                    "label": 0
                },
                {
                    "sent": "Any other questions?",
                    "label": 0
                },
                {
                    "sent": "OK, I have one suggestion for you, but there is another walk in cigar this year in July and they tacked on the refund query with the term relationship in the query log.",
                    "label": 0
                },
                {
                    "sent": "OK so you may if you still need to publish your work in the future you may still may be compared with them, thanks.",
                    "label": 0
                },
                {
                    "sent": "Thanks to speakers.",
                    "label": 0
                }
            ]
        }
    }
}