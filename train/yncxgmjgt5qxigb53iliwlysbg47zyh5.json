{
    "id": "yncxgmjgt5qxigb53iliwlysbg47zyh5",
    "title": "Towards Robust Abstractive Multi-Document Summarization",
    "info": {
        "author": [
            "Jackie Chi Kit Cheung, Department of Computer Science, University of Toronto"
        ],
        "published": "Oct. 2, 2013",
        "recorded": "August 2013",
        "category": [
            "Top->Computer Science->Computational Linguistics"
        ]
    },
    "url": "http://videolectures.net/acl2013_cheung_summarization/",
    "segmentation": [
        [
            "So an automatic summarization."
        ],
        [
            "The idea of centrality is that a summary should contain the parts of the source text that are most representative of it.",
            "So in early work this has been explicitly modeled as part of the summarization objective.",
            "For example, in the well known model of MMR the summarization objective is defined to be a combination of a centrality term and a non redundancy term.",
            "So of course, since then there has been a lot of work within automatic summarization and centrality has been refined by more sophisticated methods.",
            "For example, one method that has been very successful is that of linen Hovey, who proposed the term weighting method and this method has become a core component of many of the most successful current summarization systems."
        ],
        [
            "So while centrality in the context of extractive summarization has served as well so far, it has long been well known that there are some limits to extractive summarization.",
            "So one of the first limits is that of compression ratio.",
            "If you're restricted to using entire sentence from the source text, there's a limit to how much you can compress the information in the source text itself.",
            "So this problem has been tackled by doing text simplification and sentence Fusion.",
            "So for a long time now people have been working on these approaches to achieve better compression ratios.",
            "Another problem, especially in multi document summarization is that of coherence.",
            "When you extract tendencies from potentially different source text documents and put them next to each other, there's no guarantee that the two sentences will flow will be coherent, but actually there are also techniques that you can use to try to overcome this issue.",
            "For example, you can simply try to avoid sentences that contain dangling reference, like pronouns or discourse cues, and recently at nacle there is a paper that focuses specifically on the issue of text structuring.",
            "For extractive summarization.",
            "But perhaps a more fundamental limit to extractive summarization is that of aggregation, an information synthesis.",
            "So we argued that key part of the potential utility of automatic summaries is that they can aggregate information that is found in multiple points in the source texts and synthesize them into some form that is more useful to the summarization system user.",
            "But unfortunately so far there has been limited work outside of specific genres and domains towards the school."
        ],
        [
            "So the key message of this paper are as follows.",
            "So whereas currently extractive centrality based summarization systems dominate in all of the summarization shared tasks, we argue that to advance towards robust abstraction across domains, we should do that not by better optimizing these centrality based measures.",
            "Instead, we need to require return to using more domain knowledge.",
            "And we provide evidence for this in a series of studies on the attack, guided summarization data set.",
            "So what we'll do is in these studies will compare the characteristics of model summaries written by humans versus state of the art summarizers which are mostly extracted."
        ],
        [
            "So first, let's talk a little bit about previous studies in summarization.",
            "So there have been studies on the best possible extractive system that you can get using word overlap measures like Rouge.",
            "So these studies find that the best possible extractive summary score as good as humans do on these word overlap measures.",
            "But it's unclear if this means that those summaries are actually as good as human written ones.",
            "So for instance, Rouge isn't really designed for the purpose of evaluating summaries at this extreme level, it was originally validated for evaluating systems at a typical level of performance.",
            "There have been other studies, so for example, you're not at all.",
            "Examine human created extractive summaries so they find that these human created extractive summaries score in between current automatic systems and abstracts on various measures such as responsiveness, linguistic quality, and the pyramid score."
        ],
        [
            "There are a couple of other related studies soaking in Mccune proposed cut and paste operations and they also performed an analysis where they found that 19% of the sentences they analyzed in the summaries cannot be explained by these processes.",
            "Sagena pound define an analyzer transformations that are necessary to convert some source text to summary text.",
            "And finally, Kopec, Inspec, Ovic find that 55% of the vocabulary items in the model summaries occur in the source text, whereas the other 45% are actually not there but they don't propose a study where we might be able to find the missing vocabulary items."
        ],
        [
            "So how are studies are novel are in the following respects.",
            "So first of all, we analyze specifically the impact of domain knowledge for multi document summarization and this is made possible by the use of recent guided summarization data which was not available before.",
            "Secondly, we take a developmental approach rather than an evaluative approach sort goal here is not to create some measure that correlates well with human judgments.",
            "Instead, we aim to distinguish model summaries and peer summaries in a useful way to guide the development of future systems.",
            "And finally, in our studies are performed at a level that is a shallow semantic level called case range, which I'll discuss in a little bit.",
            "So this contrasts with previous studies which make use of word overlap or syntactic measures."
        ],
        [
            "So I'll just present now a brief overview of the studies that we perform and the questions that we ask in a summary of the answers that we get.",
            "So in the first study we ask, how do we actually measure aggregation and we come up with a quantitative measure of sentence aggregation for summarization systems.",
            "Then in the second study, we ask, how do humans actually perform this aggregation?",
            "So what we what the answer is that the study suggests is that they don't just rely on centrality.",
            "In fact, automatic systems are already more central than human summarizers with respect to those source texts.",
            "And Thirdly, we ask how do how are we?",
            "How can automatic systems be able to generate human like summaries at all?",
            "And the answer here that we propose is that that domain knowledge is a key source of information for abstractive summarized summarization systems that we need to make more use of."
        ],
        [
            "So now I'll talk about the main unit of analysis in our studies, which is that of case frames.",
            "So what our case?",
            "Rains case frames are Gov role pairs that can be extracted from dependency parts of the sentence.",
            "So that Gov.",
            "Here is some proposition bearing units such as a verb, an event known a nominal or an adjectival predicate.",
            "And a role is semantic role which can be derived automatically from the grammatical rule.",
            "So some examples of case frames are killed, direct object, hurt, and subject and murder preposition of.",
            "And these are semantic roles because we actually transform and normalize for things like passives.",
            "Another alternations.",
            "So if you're familiar with case grammar, these case frames are, as one word is distinct from case frames as two words that can be found in case grammars.",
            "But they can be automatically extracted, and they're actually quite well suited to characterize the domain.",
            "Because case frames the abstract away from the syntactic alternations that I've discussed, and also the entity realizations."
        ],
        [
            "So here is an example of passage, summary passage and the case frames that are found in it.",
            "So the topic cluster here is that of the Unabomber trial, and in this passage we have.",
            "Theodore.",
            "Kosinski faces a federal indictment for four Mail bomb attacks attributed to the Unabomber, in which two people were killed, and so forth.",
            "So at the bottom on the left, here we have a list of slots defined by the attack in the guided summarization data set.",
            "And to the right, we see that all of these slots can be basically identified by the case frames.",
            "So, for example, the defendant slot.",
            "Can be characterized by the case frames.",
            "The subject of the verb face, and the subject of the verb lead.",
            "So here is Theodore Kaczynski who is the defendant.",
            "And so the doctor since he fills the subject of the verb face and also that later on in the pronoun.",
            "Next, other charges can be identified by the object of the verb face.",
            "The reason for the trial can be identified by the case frame indictment, Proposition 4.",
            "And we can do the same thing for all of the other slots, so the sentence.",
            "To plead with the direct object.",
            "And the judge with preside subject.",
            "So this shows that case frames are able to capture all of the slots that you find."
        ],
        [
            "So in terms of the data set that we use, we use that at 2010 guided summarization data set.",
            "So this data set contains 920 documents consisting of 46 topic clusters in five different domains.",
            "And there are templates as you saw that are provided to provide guidance to the summarization systems.",
            "So this is actually a shared task consisting of two tasks.",
            "The initial summarization task, an update summarization task where you have to provide a summary of what's different in a second set of documents compared to a first set.",
            "So in our studies will compare different summarizers.",
            "In particular will have the eight human Model summary writers and these are given ideas that are alphabetic from A to H. And there are also 43 peer summarization systems which are automatic from 1 to 43.",
            "And we removed two systems in our in our analysis that did not generate summaries for most of the topic clusters."
        ],
        [
            "So we also compare more specifically certain cure conditions that are of interest.",
            "So first is the peer average, so this is simply the average of whatever statistic we're calculating over the 41 peer summarizers.",
            "Then we also selected three of the top performing automatic systems based on various measures.",
            "So Pier 16 performed the best in responsiveness in the initial task and the best in Rouge to responsiveness and pyramid in the update task.",
            "And Pier 22 performed the best in Rouge two and Pyramid score in the initial task.",
            "And Lastly, there's Pier one.",
            "This is simply the leading baseline from the most recent document defined by NIST.",
            "But it turns out that this system, this system performs the best in linguistic quality in both tasks."
        ],
        [
            "So now we're ready to begin talking about the each of the studies in more detail.",
            "So in the first study we want to come up with some way of quantitatively measuring the degree of aggregation that are performed by various summarizers.",
            "And so we propose to do this with this measure of average sentence cover size.",
            "So we define the sentence cover size to be the minimum number of sentences from the source text that is needed to cover all of the case frames that are found in a summary sentence.",
            "For those that can be found in the source text at all.",
            "And so we compute this for each of the sentences produced by a summarizer and we take the average of this over all of those sentences.",
            "So in a purely extractive system, this score is expected to be 1.0, because every sentence in the summary can.",
            "There is a direct sentence in the source text that covers it.",
            "As an example of how to calculate this measure, suppose we're given a summary sentence with case frame ID's from one to five.",
            "And suppose we have a source text consisting of three sentences with case frames as follows.",
            "Then the minimum cover size here is 2 because if you take the first 2 sentences, you're able to cover the case frames that are found in the summary sentence.",
            "And in our study we we are able to optimally solve all of the sentence cover size problems using ilaug seaplex."
        ],
        [
            "So first I'll display some bar graphs for how the different summarizers are ranked according to this measure.",
            "So at the top we have the rankings for the initial summarization task and at the bottom the rankings for the update summarization task.",
            "So the blue bars here correspond to automatic systems, and the orange bars correspond to the human written model systems.",
            "So first one thing that immediately pops out is that, as expected, the human summary writers actually do aggregate more, so they're all found at the right hand side at the top end of the range.",
            "For both tasks.",
            "And if you look at the individual conditions that I talked about, the green arrows here point to the systems that are considered state of the art by various measures.",
            "And the Purple Arrow is the leading baseline, and you see that they are all basically extractive and that they rank lower and the scores are very close to 1.0 for both tasks.",
            "If we go and you might also have noticed that one of the peer systems seems to rank very highly, so this is actually because that system did not remove the bylines from the summary sentence is an so the automatic parsing tool which was not trained on the bylines, created a lot of incorrect parses.",
            "So that's why that score is anomalous.",
            "But that system is not actually abstractive."
        ],
        [
            "So now we can look at more quantitatively at the averages for each of the conditions.",
            "And, as shown in the previous bar graphs, the model averages higher than the peer average as well as any of the individual systems, and these differences are statistically significant."
        ],
        [
            "So that was the first study.",
            "So in the second study, now that we have a measure of sentence aggregation, we now ask how do humans actually aggregate information?",
            "So you can think of two options immediately.",
            "The first option is that humans are able to perform better compaction, but they still basically rely on centrality to do their aggregation and judgments.",
            "And the second option is that the novel sentences composed by humans actually do synthesize information in some deeper way.",
            "And so, in order to distinguish these two, we compute and identify what we call signature case frames.",
            "So we do this based on a very successful method of linen hobby, except that we extend their approach to case frames, which are our unit of analysis here.",
            "So what these signature case frames are at an intuitive level is that they're the ones that appear in the source text more often than would be expected by chance compared to a background corpus.",
            "And this is done by a log likelihood ratio tested log likelihood ratio test based on the binomial distribution.",
            "And since this is such a well known method, I'll refer you to the previous paper for the details of how to compute that.",
            "So here in this study we measured the signature case frame density of the summarization systems.",
            "So this is simply defined to be the number of signature case frames in the summaries divided by the number of words in the summaries produced by a summarizer."
        ],
        [
            "So again, we have bar graphs of the different summarization systems ranked.",
            "And what we see here is that Interestingly, the human Model Summary writers score a fairly low impact on this measure of sending turkeys from density.",
            "Whereas if you look at the automatic systems, the state of the art systems tend to score quite high, whereas the leading baseline score is quite low and is comparable to the humans.",
            "And if you look at if we look at the performance of the other automatic systems that score low, and this measure of centrality, it turns out that those are also the lower scoring ones in the shared task.",
            "So it seems, so we're not arguing that you need a lower signature case room density in order to perform well in human.",
            "Like we're just arguing that.",
            "The automatic systems are already optimizing this a lot."
        ],
        [
            "So here are the numerical averages, so the model average as you can see, is lower than the peer average as well as the Pier 16 and 22 and the asterisks show the systems that are statistically significantly different from the model average."
        ],
        [
            "I'm so one thing that you might think of is maybe humans actually do are doing the same thing, but they're actually just using some simple paraphrasing, so we repeated the study after merging distributionally similar case frames.",
            "So we trained a distributional semantic model over the case rings and merge those that are similar using an agglomerative clustering method, and then we computed the signature keyframe density from that.",
            "So we tried different thresholds for the clustering and here we just show one of the thresholds but the results are the same for the other thresholds that we tried.",
            "So basically the results are the same as before.",
            "The model average of the human summary summary writers is lower than the peer average as well as the top performing systems, and again the leading baseline scores similar to the humans."
        ],
        [
            "So what are the consequences of this study?",
            "So at the beginning of this study, I asked how do humans aggregate information?",
            "So now we have some evidence that actually what they do is they write these novel sentence is by synthesizing the information that they find.",
            "So once again, it seems that better optimizing centrality based measures is unlikely to result in a paradigm shift.",
            "And another result of this is that sentence simplification and Fusion, while useful, are only part of the answer.",
            "So."
        ],
        [
            "In study number three, we asked how can summaries be reconstructed at all the model summaries.",
            "So we want the hypothesis space that includes all of the model summaries.",
            "So we define case frame coverage to be the proportion of case frames in a summary that is contained by some reference set, and we tested two different reference sets by using the source text alone and also the source text plus some articles from the same domain.",
            "So in a sense we extend Kopec Anspacher which is analysis to answer where we can find the missing units of analysis."
        ],
        [
            "So we look solely at the source text.",
            "What we find is that, as expected, all of the automatic systems have very high scores, because they're basically extractive, whereas all of the human systems score a bit lower."
        ],
        [
            "And here are the numerical results for that.",
            "So the model averages only means that only around 75 to 77% of the case frames are found in the source text."
        ],
        [
            "Next we tried adding in domain articles, so we include all the articles from the same domain in the reference set and to make sure this is not simply a result of increasing the size of the reference set, we compare it against the alternative of adding the same number of articles from another domain.",
            "And what we see is that so the first row is the same as before, and if you add out of domain text you get an increase in coverage.",
            "But if you add in domain text you get a substantially larger increase and this difference is significant as well."
        ],
        [
            "So in conclusion, here we've proposed a series of studies on guided summarization datasets by case frames.",
            "So what we show is that we can distinguish model summary summarizers from state of the art peer summarizers by information content.",
            "So as a brief summary, human written model summaries contain more aggregation, rely less on the centrality even after accounting for paraphrasing, and cannot be reconstructed from the source text alone."
        ],
        [
            "So while aggregate statistics such as linen hobbies method have been successful so far, what we argue now is we need to return to more direct use of domain knowledge.",
            "So here are two future directions.",
            "So one is to mine in domain documents for case frames and do some kind of sentence Fusion approach with that and another is to have a more structured representation of a domain that to learn the typical slots and events and we had a paper presentation yesterday here where we begin to address this problem in the context of summer.",
            "So thanks for your attention.",
            "How did you account for paraphrasing?",
            "So the way we accounted for paraphrasing is by merging case frames that might be paraphrases.",
            "So you might have, say, kill direct object and murder direct object which are distributionally similar, so we merge them and consider them as one unit when performing the analysis.",
            "Thanks for the presentation.",
            "I just had a quick question so this was done on A tag data which is 1 sort of documents at one particular domain, right?",
            "So I was wondering if you what are your thoughts on how well would this extend to other domains of summarization?",
            "For example, I work in scientific literature summarization Ann.",
            "Do you think this case frames approach would be useful in in that area or in other areas where people might want to summarize stuff?",
            "Yeah, I think some of the results might extend.",
            "Showcase frames are actually very general and shallow approach so I don't see why it would be specific to new summarization unless you move to something like say tweet data where you might not get complete sentences and so forth.",
            "But if you talk about, say, scientific article summarization or things like that, I think the case from approach should extend thanks.",
            "So why did you take case?",
            "Perhaps not the basic elements like hate modified and relations.",
            "Yeah so.",
            "Basic elements you can talk about two different basic elements.",
            "There's the framework of just a general way of using syntactic relations.",
            "An in that in that sense, case frames can be seen as one instantiation of basic elements.",
            "Then there's the basic elements as it's actually applied.",
            "An.",
            "In that sense, how it's actually applied is quite different from case frames, and that they don't make the same decisions as we do in terms of, for example, ignoring the filler of the case frame.",
            "So the actual entity and so forth.",
            "And they also don't try.",
            "Most papers using basic elements.",
            "Don't try say, merging different units to analyze them together and so forth.",
            "So that's how they are distinct, and so you say like the case, prints are more general than the basic elements.",
            "Or put it this way, the way we use them is more a little bit more semantic, a little bit more abstract.",
            "So we count for voicing alternations over thanks.",
            "Sweet down, no questions.",
            "Let me ask.",
            "111 thing this density of case frames could be correlated to redundancy in the automatic summaries becausw probably human like summer is the models were performed.",
            "All this course were lower and automatic summaries were higher.",
            "So probably yeah so.",
            "But The thing is you could view redundancy as like kind of.",
            "Part of the centrality paradigm.",
            "So most summarization work.",
            "They redundancy as a problem because they want to add more of the central elements into the summaries.",
            "So, but human summary writers, they avoid redundancy.",
            "Not necessarily for this reason, but in order to say synthesizing information more.",
            "OK, so thanks thanks, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So an automatic summarization.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The idea of centrality is that a summary should contain the parts of the source text that are most representative of it.",
                    "label": 1
                },
                {
                    "sent": "So in early work this has been explicitly modeled as part of the summarization objective.",
                    "label": 0
                },
                {
                    "sent": "For example, in the well known model of MMR the summarization objective is defined to be a combination of a centrality term and a non redundancy term.",
                    "label": 0
                },
                {
                    "sent": "So of course, since then there has been a lot of work within automatic summarization and centrality has been refined by more sophisticated methods.",
                    "label": 0
                },
                {
                    "sent": "For example, one method that has been very successful is that of linen Hovey, who proposed the term weighting method and this method has become a core component of many of the most successful current summarization systems.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So while centrality in the context of extractive summarization has served as well so far, it has long been well known that there are some limits to extractive summarization.",
                    "label": 0
                },
                {
                    "sent": "So one of the first limits is that of compression ratio.",
                    "label": 0
                },
                {
                    "sent": "If you're restricted to using entire sentence from the source text, there's a limit to how much you can compress the information in the source text itself.",
                    "label": 0
                },
                {
                    "sent": "So this problem has been tackled by doing text simplification and sentence Fusion.",
                    "label": 1
                },
                {
                    "sent": "So for a long time now people have been working on these approaches to achieve better compression ratios.",
                    "label": 0
                },
                {
                    "sent": "Another problem, especially in multi document summarization is that of coherence.",
                    "label": 0
                },
                {
                    "sent": "When you extract tendencies from potentially different source text documents and put them next to each other, there's no guarantee that the two sentences will flow will be coherent, but actually there are also techniques that you can use to try to overcome this issue.",
                    "label": 0
                },
                {
                    "sent": "For example, you can simply try to avoid sentences that contain dangling reference, like pronouns or discourse cues, and recently at nacle there is a paper that focuses specifically on the issue of text structuring.",
                    "label": 0
                },
                {
                    "sent": "For extractive summarization.",
                    "label": 0
                },
                {
                    "sent": "But perhaps a more fundamental limit to extractive summarization is that of aggregation, an information synthesis.",
                    "label": 0
                },
                {
                    "sent": "So we argued that key part of the potential utility of automatic summaries is that they can aggregate information that is found in multiple points in the source texts and synthesize them into some form that is more useful to the summarization system user.",
                    "label": 1
                },
                {
                    "sent": "But unfortunately so far there has been limited work outside of specific genres and domains towards the school.",
                    "label": 1
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the key message of this paper are as follows.",
                    "label": 1
                },
                {
                    "sent": "So whereas currently extractive centrality based summarization systems dominate in all of the summarization shared tasks, we argue that to advance towards robust abstraction across domains, we should do that not by better optimizing these centrality based measures.",
                    "label": 1
                },
                {
                    "sent": "Instead, we need to require return to using more domain knowledge.",
                    "label": 0
                },
                {
                    "sent": "And we provide evidence for this in a series of studies on the attack, guided summarization data set.",
                    "label": 0
                },
                {
                    "sent": "So what we'll do is in these studies will compare the characteristics of model summaries written by humans versus state of the art summarizers which are mostly extracted.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So first, let's talk a little bit about previous studies in summarization.",
                    "label": 0
                },
                {
                    "sent": "So there have been studies on the best possible extractive system that you can get using word overlap measures like Rouge.",
                    "label": 1
                },
                {
                    "sent": "So these studies find that the best possible extractive summary score as good as humans do on these word overlap measures.",
                    "label": 1
                },
                {
                    "sent": "But it's unclear if this means that those summaries are actually as good as human written ones.",
                    "label": 0
                },
                {
                    "sent": "So for instance, Rouge isn't really designed for the purpose of evaluating summaries at this extreme level, it was originally validated for evaluating systems at a typical level of performance.",
                    "label": 0
                },
                {
                    "sent": "There have been other studies, so for example, you're not at all.",
                    "label": 0
                },
                {
                    "sent": "Examine human created extractive summaries so they find that these human created extractive summaries score in between current automatic systems and abstracts on various measures such as responsiveness, linguistic quality, and the pyramid score.",
                    "label": 1
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There are a couple of other related studies soaking in Mccune proposed cut and paste operations and they also performed an analysis where they found that 19% of the sentences they analyzed in the summaries cannot be explained by these processes.",
                    "label": 1
                },
                {
                    "sent": "Sagena pound define an analyzer transformations that are necessary to convert some source text to summary text.",
                    "label": 1
                },
                {
                    "sent": "And finally, Kopec, Inspec, Ovic find that 55% of the vocabulary items in the model summaries occur in the source text, whereas the other 45% are actually not there but they don't propose a study where we might be able to find the missing vocabulary items.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how are studies are novel are in the following respects.",
                    "label": 0
                },
                {
                    "sent": "So first of all, we analyze specifically the impact of domain knowledge for multi document summarization and this is made possible by the use of recent guided summarization data which was not available before.",
                    "label": 1
                },
                {
                    "sent": "Secondly, we take a developmental approach rather than an evaluative approach sort goal here is not to create some measure that correlates well with human judgments.",
                    "label": 1
                },
                {
                    "sent": "Instead, we aim to distinguish model summaries and peer summaries in a useful way to guide the development of future systems.",
                    "label": 1
                },
                {
                    "sent": "And finally, in our studies are performed at a level that is a shallow semantic level called case range, which I'll discuss in a little bit.",
                    "label": 0
                },
                {
                    "sent": "So this contrasts with previous studies which make use of word overlap or syntactic measures.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I'll just present now a brief overview of the studies that we perform and the questions that we ask in a summary of the answers that we get.",
                    "label": 0
                },
                {
                    "sent": "So in the first study we ask, how do we actually measure aggregation and we come up with a quantitative measure of sentence aggregation for summarization systems.",
                    "label": 1
                },
                {
                    "sent": "Then in the second study, we ask, how do humans actually perform this aggregation?",
                    "label": 0
                },
                {
                    "sent": "So what we what the answer is that the study suggests is that they don't just rely on centrality.",
                    "label": 0
                },
                {
                    "sent": "In fact, automatic systems are already more central than human summarizers with respect to those source texts.",
                    "label": 1
                },
                {
                    "sent": "And Thirdly, we ask how do how are we?",
                    "label": 0
                },
                {
                    "sent": "How can automatic systems be able to generate human like summaries at all?",
                    "label": 0
                },
                {
                    "sent": "And the answer here that we propose is that that domain knowledge is a key source of information for abstractive summarized summarization systems that we need to make more use of.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now I'll talk about the main unit of analysis in our studies, which is that of case frames.",
                    "label": 1
                },
                {
                    "sent": "So what our case?",
                    "label": 0
                },
                {
                    "sent": "Rains case frames are Gov role pairs that can be extracted from dependency parts of the sentence.",
                    "label": 1
                },
                {
                    "sent": "So that Gov.",
                    "label": 0
                },
                {
                    "sent": "Here is some proposition bearing units such as a verb, an event known a nominal or an adjectival predicate.",
                    "label": 0
                },
                {
                    "sent": "And a role is semantic role which can be derived automatically from the grammatical rule.",
                    "label": 0
                },
                {
                    "sent": "So some examples of case frames are killed, direct object, hurt, and subject and murder preposition of.",
                    "label": 0
                },
                {
                    "sent": "And these are semantic roles because we actually transform and normalize for things like passives.",
                    "label": 0
                },
                {
                    "sent": "Another alternations.",
                    "label": 1
                },
                {
                    "sent": "So if you're familiar with case grammar, these case frames are, as one word is distinct from case frames as two words that can be found in case grammars.",
                    "label": 1
                },
                {
                    "sent": "But they can be automatically extracted, and they're actually quite well suited to characterize the domain.",
                    "label": 0
                },
                {
                    "sent": "Because case frames the abstract away from the syntactic alternations that I've discussed, and also the entity realizations.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here is an example of passage, summary passage and the case frames that are found in it.",
                    "label": 0
                },
                {
                    "sent": "So the topic cluster here is that of the Unabomber trial, and in this passage we have.",
                    "label": 0
                },
                {
                    "sent": "Theodore.",
                    "label": 0
                },
                {
                    "sent": "Kosinski faces a federal indictment for four Mail bomb attacks attributed to the Unabomber, in which two people were killed, and so forth.",
                    "label": 1
                },
                {
                    "sent": "So at the bottom on the left, here we have a list of slots defined by the attack in the guided summarization data set.",
                    "label": 0
                },
                {
                    "sent": "And to the right, we see that all of these slots can be basically identified by the case frames.",
                    "label": 0
                },
                {
                    "sent": "So, for example, the defendant slot.",
                    "label": 0
                },
                {
                    "sent": "Can be characterized by the case frames.",
                    "label": 0
                },
                {
                    "sent": "The subject of the verb face, and the subject of the verb lead.",
                    "label": 0
                },
                {
                    "sent": "So here is Theodore Kaczynski who is the defendant.",
                    "label": 0
                },
                {
                    "sent": "And so the doctor since he fills the subject of the verb face and also that later on in the pronoun.",
                    "label": 0
                },
                {
                    "sent": "Next, other charges can be identified by the object of the verb face.",
                    "label": 0
                },
                {
                    "sent": "The reason for the trial can be identified by the case frame indictment, Proposition 4.",
                    "label": 0
                },
                {
                    "sent": "And we can do the same thing for all of the other slots, so the sentence.",
                    "label": 0
                },
                {
                    "sent": "To plead with the direct object.",
                    "label": 0
                },
                {
                    "sent": "And the judge with preside subject.",
                    "label": 0
                },
                {
                    "sent": "So this shows that case frames are able to capture all of the slots that you find.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in terms of the data set that we use, we use that at 2010 guided summarization data set.",
                    "label": 0
                },
                {
                    "sent": "So this data set contains 920 documents consisting of 46 topic clusters in five different domains.",
                    "label": 1
                },
                {
                    "sent": "And there are templates as you saw that are provided to provide guidance to the summarization systems.",
                    "label": 0
                },
                {
                    "sent": "So this is actually a shared task consisting of two tasks.",
                    "label": 0
                },
                {
                    "sent": "The initial summarization task, an update summarization task where you have to provide a summary of what's different in a second set of documents compared to a first set.",
                    "label": 0
                },
                {
                    "sent": "So in our studies will compare different summarizers.",
                    "label": 0
                },
                {
                    "sent": "In particular will have the eight human Model summary writers and these are given ideas that are alphabetic from A to H. And there are also 43 peer summarization systems which are automatic from 1 to 43.",
                    "label": 0
                },
                {
                    "sent": "And we removed two systems in our in our analysis that did not generate summaries for most of the topic clusters.",
                    "label": 1
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we also compare more specifically certain cure conditions that are of interest.",
                    "label": 0
                },
                {
                    "sent": "So first is the peer average, so this is simply the average of whatever statistic we're calculating over the 41 peer summarizers.",
                    "label": 1
                },
                {
                    "sent": "Then we also selected three of the top performing automatic systems based on various measures.",
                    "label": 0
                },
                {
                    "sent": "So Pier 16 performed the best in responsiveness in the initial task and the best in Rouge to responsiveness and pyramid in the update task.",
                    "label": 1
                },
                {
                    "sent": "And Pier 22 performed the best in Rouge two and Pyramid score in the initial task.",
                    "label": 0
                },
                {
                    "sent": "And Lastly, there's Pier one.",
                    "label": 1
                },
                {
                    "sent": "This is simply the leading baseline from the most recent document defined by NIST.",
                    "label": 1
                },
                {
                    "sent": "But it turns out that this system, this system performs the best in linguistic quality in both tasks.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now we're ready to begin talking about the each of the studies in more detail.",
                    "label": 0
                },
                {
                    "sent": "So in the first study we want to come up with some way of quantitatively measuring the degree of aggregation that are performed by various summarizers.",
                    "label": 0
                },
                {
                    "sent": "And so we propose to do this with this measure of average sentence cover size.",
                    "label": 0
                },
                {
                    "sent": "So we define the sentence cover size to be the minimum number of sentences from the source text that is needed to cover all of the case frames that are found in a summary sentence.",
                    "label": 1
                },
                {
                    "sent": "For those that can be found in the source text at all.",
                    "label": 0
                },
                {
                    "sent": "And so we compute this for each of the sentences produced by a summarizer and we take the average of this over all of those sentences.",
                    "label": 0
                },
                {
                    "sent": "So in a purely extractive system, this score is expected to be 1.0, because every sentence in the summary can.",
                    "label": 0
                },
                {
                    "sent": "There is a direct sentence in the source text that covers it.",
                    "label": 0
                },
                {
                    "sent": "As an example of how to calculate this measure, suppose we're given a summary sentence with case frame ID's from one to five.",
                    "label": 0
                },
                {
                    "sent": "And suppose we have a source text consisting of three sentences with case frames as follows.",
                    "label": 0
                },
                {
                    "sent": "Then the minimum cover size here is 2 because if you take the first 2 sentences, you're able to cover the case frames that are found in the summary sentence.",
                    "label": 0
                },
                {
                    "sent": "And in our study we we are able to optimally solve all of the sentence cover size problems using ilaug seaplex.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So first I'll display some bar graphs for how the different summarizers are ranked according to this measure.",
                    "label": 0
                },
                {
                    "sent": "So at the top we have the rankings for the initial summarization task and at the bottom the rankings for the update summarization task.",
                    "label": 0
                },
                {
                    "sent": "So the blue bars here correspond to automatic systems, and the orange bars correspond to the human written model systems.",
                    "label": 0
                },
                {
                    "sent": "So first one thing that immediately pops out is that, as expected, the human summary writers actually do aggregate more, so they're all found at the right hand side at the top end of the range.",
                    "label": 0
                },
                {
                    "sent": "For both tasks.",
                    "label": 0
                },
                {
                    "sent": "And if you look at the individual conditions that I talked about, the green arrows here point to the systems that are considered state of the art by various measures.",
                    "label": 0
                },
                {
                    "sent": "And the Purple Arrow is the leading baseline, and you see that they are all basically extractive and that they rank lower and the scores are very close to 1.0 for both tasks.",
                    "label": 0
                },
                {
                    "sent": "If we go and you might also have noticed that one of the peer systems seems to rank very highly, so this is actually because that system did not remove the bylines from the summary sentence is an so the automatic parsing tool which was not trained on the bylines, created a lot of incorrect parses.",
                    "label": 0
                },
                {
                    "sent": "So that's why that score is anomalous.",
                    "label": 0
                },
                {
                    "sent": "But that system is not actually abstractive.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now we can look at more quantitatively at the averages for each of the conditions.",
                    "label": 0
                },
                {
                    "sent": "And, as shown in the previous bar graphs, the model averages higher than the peer average as well as any of the individual systems, and these differences are statistically significant.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that was the first study.",
                    "label": 0
                },
                {
                    "sent": "So in the second study, now that we have a measure of sentence aggregation, we now ask how do humans actually aggregate information?",
                    "label": 1
                },
                {
                    "sent": "So you can think of two options immediately.",
                    "label": 0
                },
                {
                    "sent": "The first option is that humans are able to perform better compaction, but they still basically rely on centrality to do their aggregation and judgments.",
                    "label": 0
                },
                {
                    "sent": "And the second option is that the novel sentences composed by humans actually do synthesize information in some deeper way.",
                    "label": 0
                },
                {
                    "sent": "And so, in order to distinguish these two, we compute and identify what we call signature case frames.",
                    "label": 0
                },
                {
                    "sent": "So we do this based on a very successful method of linen hobby, except that we extend their approach to case frames, which are our unit of analysis here.",
                    "label": 0
                },
                {
                    "sent": "So what these signature case frames are at an intuitive level is that they're the ones that appear in the source text more often than would be expected by chance compared to a background corpus.",
                    "label": 1
                },
                {
                    "sent": "And this is done by a log likelihood ratio tested log likelihood ratio test based on the binomial distribution.",
                    "label": 0
                },
                {
                    "sent": "And since this is such a well known method, I'll refer you to the previous paper for the details of how to compute that.",
                    "label": 0
                },
                {
                    "sent": "So here in this study we measured the signature case frame density of the summarization systems.",
                    "label": 0
                },
                {
                    "sent": "So this is simply defined to be the number of signature case frames in the summaries divided by the number of words in the summaries produced by a summarizer.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So again, we have bar graphs of the different summarization systems ranked.",
                    "label": 0
                },
                {
                    "sent": "And what we see here is that Interestingly, the human Model Summary writers score a fairly low impact on this measure of sending turkeys from density.",
                    "label": 0
                },
                {
                    "sent": "Whereas if you look at the automatic systems, the state of the art systems tend to score quite high, whereas the leading baseline score is quite low and is comparable to the humans.",
                    "label": 0
                },
                {
                    "sent": "And if you look at if we look at the performance of the other automatic systems that score low, and this measure of centrality, it turns out that those are also the lower scoring ones in the shared task.",
                    "label": 0
                },
                {
                    "sent": "So it seems, so we're not arguing that you need a lower signature case room density in order to perform well in human.",
                    "label": 0
                },
                {
                    "sent": "Like we're just arguing that.",
                    "label": 0
                },
                {
                    "sent": "The automatic systems are already optimizing this a lot.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here are the numerical averages, so the model average as you can see, is lower than the peer average as well as the Pier 16 and 22 and the asterisks show the systems that are statistically significantly different from the model average.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm so one thing that you might think of is maybe humans actually do are doing the same thing, but they're actually just using some simple paraphrasing, so we repeated the study after merging distributionally similar case frames.",
                    "label": 1
                },
                {
                    "sent": "So we trained a distributional semantic model over the case rings and merge those that are similar using an agglomerative clustering method, and then we computed the signature keyframe density from that.",
                    "label": 0
                },
                {
                    "sent": "So we tried different thresholds for the clustering and here we just show one of the thresholds but the results are the same for the other thresholds that we tried.",
                    "label": 0
                },
                {
                    "sent": "So basically the results are the same as before.",
                    "label": 1
                },
                {
                    "sent": "The model average of the human summary summary writers is lower than the peer average as well as the top performing systems, and again the leading baseline scores similar to the humans.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what are the consequences of this study?",
                    "label": 0
                },
                {
                    "sent": "So at the beginning of this study, I asked how do humans aggregate information?",
                    "label": 1
                },
                {
                    "sent": "So now we have some evidence that actually what they do is they write these novel sentence is by synthesizing the information that they find.",
                    "label": 1
                },
                {
                    "sent": "So once again, it seems that better optimizing centrality based measures is unlikely to result in a paradigm shift.",
                    "label": 0
                },
                {
                    "sent": "And another result of this is that sentence simplification and Fusion, while useful, are only part of the answer.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In study number three, we asked how can summaries be reconstructed at all the model summaries.",
                    "label": 0
                },
                {
                    "sent": "So we want the hypothesis space that includes all of the model summaries.",
                    "label": 1
                },
                {
                    "sent": "So we define case frame coverage to be the proportion of case frames in a summary that is contained by some reference set, and we tested two different reference sets by using the source text alone and also the source text plus some articles from the same domain.",
                    "label": 1
                },
                {
                    "sent": "So in a sense we extend Kopec Anspacher which is analysis to answer where we can find the missing units of analysis.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we look solely at the source text.",
                    "label": 0
                },
                {
                    "sent": "What we find is that, as expected, all of the automatic systems have very high scores, because they're basically extractive, whereas all of the human systems score a bit lower.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here are the numerical results for that.",
                    "label": 0
                },
                {
                    "sent": "So the model averages only means that only around 75 to 77% of the case frames are found in the source text.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Next we tried adding in domain articles, so we include all the articles from the same domain in the reference set and to make sure this is not simply a result of increasing the size of the reference set, we compare it against the alternative of adding the same number of articles from another domain.",
                    "label": 1
                },
                {
                    "sent": "And what we see is that so the first row is the same as before, and if you add out of domain text you get an increase in coverage.",
                    "label": 0
                },
                {
                    "sent": "But if you add in domain text you get a substantially larger increase and this difference is significant as well.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in conclusion, here we've proposed a series of studies on guided summarization datasets by case frames.",
                    "label": 1
                },
                {
                    "sent": "So what we show is that we can distinguish model summary summarizers from state of the art peer summarizers by information content.",
                    "label": 0
                },
                {
                    "sent": "So as a brief summary, human written model summaries contain more aggregation, rely less on the centrality even after accounting for paraphrasing, and cannot be reconstructed from the source text alone.",
                    "label": 1
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So while aggregate statistics such as linen hobbies method have been successful so far, what we argue now is we need to return to more direct use of domain knowledge.",
                    "label": 1
                },
                {
                    "sent": "So here are two future directions.",
                    "label": 1
                },
                {
                    "sent": "So one is to mine in domain documents for case frames and do some kind of sentence Fusion approach with that and another is to have a more structured representation of a domain that to learn the typical slots and events and we had a paper presentation yesterday here where we begin to address this problem in the context of summer.",
                    "label": 0
                },
                {
                    "sent": "So thanks for your attention.",
                    "label": 0
                },
                {
                    "sent": "How did you account for paraphrasing?",
                    "label": 0
                },
                {
                    "sent": "So the way we accounted for paraphrasing is by merging case frames that might be paraphrases.",
                    "label": 0
                },
                {
                    "sent": "So you might have, say, kill direct object and murder direct object which are distributionally similar, so we merge them and consider them as one unit when performing the analysis.",
                    "label": 0
                },
                {
                    "sent": "Thanks for the presentation.",
                    "label": 0
                },
                {
                    "sent": "I just had a quick question so this was done on A tag data which is 1 sort of documents at one particular domain, right?",
                    "label": 0
                },
                {
                    "sent": "So I was wondering if you what are your thoughts on how well would this extend to other domains of summarization?",
                    "label": 0
                },
                {
                    "sent": "For example, I work in scientific literature summarization Ann.",
                    "label": 0
                },
                {
                    "sent": "Do you think this case frames approach would be useful in in that area or in other areas where people might want to summarize stuff?",
                    "label": 0
                },
                {
                    "sent": "Yeah, I think some of the results might extend.",
                    "label": 0
                },
                {
                    "sent": "Showcase frames are actually very general and shallow approach so I don't see why it would be specific to new summarization unless you move to something like say tweet data where you might not get complete sentences and so forth.",
                    "label": 0
                },
                {
                    "sent": "But if you talk about, say, scientific article summarization or things like that, I think the case from approach should extend thanks.",
                    "label": 0
                },
                {
                    "sent": "So why did you take case?",
                    "label": 0
                },
                {
                    "sent": "Perhaps not the basic elements like hate modified and relations.",
                    "label": 0
                },
                {
                    "sent": "Yeah so.",
                    "label": 0
                },
                {
                    "sent": "Basic elements you can talk about two different basic elements.",
                    "label": 0
                },
                {
                    "sent": "There's the framework of just a general way of using syntactic relations.",
                    "label": 0
                },
                {
                    "sent": "An in that in that sense, case frames can be seen as one instantiation of basic elements.",
                    "label": 0
                },
                {
                    "sent": "Then there's the basic elements as it's actually applied.",
                    "label": 0
                },
                {
                    "sent": "An.",
                    "label": 0
                },
                {
                    "sent": "In that sense, how it's actually applied is quite different from case frames, and that they don't make the same decisions as we do in terms of, for example, ignoring the filler of the case frame.",
                    "label": 0
                },
                {
                    "sent": "So the actual entity and so forth.",
                    "label": 0
                },
                {
                    "sent": "And they also don't try.",
                    "label": 0
                },
                {
                    "sent": "Most papers using basic elements.",
                    "label": 0
                },
                {
                    "sent": "Don't try say, merging different units to analyze them together and so forth.",
                    "label": 0
                },
                {
                    "sent": "So that's how they are distinct, and so you say like the case, prints are more general than the basic elements.",
                    "label": 0
                },
                {
                    "sent": "Or put it this way, the way we use them is more a little bit more semantic, a little bit more abstract.",
                    "label": 0
                },
                {
                    "sent": "So we count for voicing alternations over thanks.",
                    "label": 0
                },
                {
                    "sent": "Sweet down, no questions.",
                    "label": 0
                },
                {
                    "sent": "Let me ask.",
                    "label": 0
                },
                {
                    "sent": "111 thing this density of case frames could be correlated to redundancy in the automatic summaries becausw probably human like summer is the models were performed.",
                    "label": 0
                },
                {
                    "sent": "All this course were lower and automatic summaries were higher.",
                    "label": 0
                },
                {
                    "sent": "So probably yeah so.",
                    "label": 0
                },
                {
                    "sent": "But The thing is you could view redundancy as like kind of.",
                    "label": 0
                },
                {
                    "sent": "Part of the centrality paradigm.",
                    "label": 0
                },
                {
                    "sent": "So most summarization work.",
                    "label": 0
                },
                {
                    "sent": "They redundancy as a problem because they want to add more of the central elements into the summaries.",
                    "label": 0
                },
                {
                    "sent": "So, but human summary writers, they avoid redundancy.",
                    "label": 0
                },
                {
                    "sent": "Not necessarily for this reason, but in order to say synthesizing information more.",
                    "label": 0
                },
                {
                    "sent": "OK, so thanks thanks, thank you.",
                    "label": 0
                }
            ]
        }
    }
}