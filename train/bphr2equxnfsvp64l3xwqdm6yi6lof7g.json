{
    "id": "bphr2equxnfsvp64l3xwqdm6yi6lof7g",
    "title": "Restricted Boltzmann Machines and Deep Belief Nets",
    "info": {
        "author": [
            "Marcus Frean, School of Engineering and Computer Science, Victoria University of Wellington"
        ],
        "published": "Feb. 3, 2011",
        "recorded": "October 2010",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/mlss2010au_frean_deepbeliefnets/",
    "segmentation": [
        [
            "OK, good morning.",
            "I'm talking about deep belief Nets, deep belief Nets and ideas.",
            "Come about fairly recently.",
            "In the last four five years and it's finding something special causing some interest.",
            "So my plan here is to give you a tutorial covering essential ideas of the belief matters.",
            "Videos of China.",
            "For me it's a little story of Alana.",
            "Can't understand.",
            "You could sort of retailers and reach certain understandings by doing that, but then a common responses that I've found from other other people.",
            "There's I sort of get it, but why does it really work?",
            "And So what I wanted, but I'll be successful today.",
            "I can get it cost some notion to you why it really works and why it's taking the shape that has taken issue.",
            "Some people like to say that people leave mixer, so third wave of neural Nets first wave, which is the perceptron second wave which is that problem.",
            "So here we are in the 3rd way.",
            "His new romantic ideas seem to go on God about cycle about 20 years and reliable and we reached, you know, just going past 20 years thinking here.",
            "We are deeply missed their annual Nets, but they're intimately related to belief Nets as well.",
            "OK, so?",
            "Pfister, just a quick shower hand side so I know roughly where I'm at here.",
            "We hands up if you know what PCI is.",
            "I mean, you had a troll.",
            "OK, hang on there, but if you know where Boston machine is.",
            "They haven't even hang up if you actually 'cause one out.",
            "Right, it's a good place to eat oils, and I'm going to right spot so.",
            "Another thing I want to say, it's just kind of consolidate will connect some of the earlier tutorials and ideas, so I'm going to talk about a little bit about Gibbs sampling and a little bit about EM algorithm connections to email rhythm and other ideas.",
            "They will come in, so it's a sort of survey whatever.",
            "I'm not going to do is tell you all about the latest bells and whistles, so deep belief Nets idea came up in about 2006 I guess.",
            "And since then, I've been a few tweaks and interesting directions.",
            "It's an active field now.",
            "I'm not going to attempt to survey local latest developments is more like.",
            "Here's the basic idea.",
            "How can get it, that's great.",
            "Then you'll be able to follow these layers elements yourself and chase them up, OK?",
            "So here's rough."
        ],
        [
            "I was going to go.",
            "This plan anyway, so I'll start just by motivating idea basic idea where we're going and why we're going there by talking about a couple of applications that one would like to be able to do better.",
            "And then I want to go into sigmoid belief Nets or hands up if you know what a sigmoid believe members, not just great seeing Mom hands, that's good.",
            "So I have something to say about that.",
            "Basically I'm going to use that to reliable increments to filaments.",
            "And then I'm going to throw up their hands and I would say we need to try something different.",
            "And there's something different.",
            "Is a Super Bowl idea football to machine and I'm going to describe the Boltzmann machine is and then cut it down and make it into a leaning building machine which we're going to use to build deep belief Nets again."
        ],
        [
            "OK, he's a bad from it and hands off you know what that means?",
            "OK, so I don't know that one.",
            "I'm just going to lay my hand on my lock today.",
            "Sure, you get the idea in professor at the bottom, I'm always going to stick the input at the bottom.",
            "I really mean it is the data vector involved since will mostly be going unsupervised learning and usually no output.",
            "But here's the background.",
            "Network then goes into the bottom, goes through some hidden layers of neurons, and comes out the top as an output.",
            "Never compare the output to what it should have been.",
            "Pulling.",
            "Some transit will drop the error and I want to upgrade all the weights in this network to be able to do a better job and the form that that album takes is.",
            "You can think of it as back propagation of errors.",
            "Going back to the West, and it seems that's one way to think about it.",
            "OK, we correct from the back from the output that will be important."
        ],
        [
            "Either particular that network.",
            "Which is interesting.",
            "You stick in the input at bottom left and then you try to get the same pattern back out with the output lab.",
            "It's initially had to see how this is a good idea.",
            "You know I could do that with the identity matrix, but the trick is in between.",
            "I want to squish it through a bottleneck layer, some kind of restricted representation in the middle.",
            "So I use the first night I get ready and then it goes squish through the ball now and comes out again and I tried to reconstruct the input, only output numbers.",
            "This is interesting idea, because if you succeed in this, you have found a much reduced representation of the data, yeah?",
            "Natural conditions where we want to reconstruct the input and calculate data is it's not so much identical, so that's right.",
            "I want to try.",
            "This is just the background network, just saying is an example of that point network with the output is the input.",
            "The target is being put down, so if I succeeded this I found a room reduced representation of data and be happy.",
            "Found some interesting minimal description of data.",
            "OK, and again you're training for backups."
        ],
        [
            "Same idea.",
            "So it would be great, but they only make these things will not be fabulous.",
            "They haven't worked, despite repeal of them despite the appeal of just, you know, feeding video at one end and getting out of representation of the world on the three hidden units in the middle.",
            "That never works well.",
            "That's part of it.",
            "Like one of you want, it talks about the well.",
            "I haven't worked well really.",
            "I'm not.",
            "Can we do better?",
            "So the usual answer for why haven't worked well is something along the lines of I'm waving my hands, the hidden units all interact with one another and the gradient.",
            "The error correction gradient.",
            "The raw material for learning this credit gets tiny as you move away from the output.",
            "So the last layer weights initially have a little bit of a gradient.",
            "You can see how to fix them up.",
            "But the lab before that there's not much you can do.",
            "Fix them up because the output layer hasn't learn anything yet and they're getting garbage in from below because those are just random initial waves.",
            "And this was garbage.",
            "And you just kind of figuring it.",
            "There's no way to go.",
            "There's no gradient.",
            "So as we get deeper in the network, certainly when you get down to these lower class here, there's no gradient.",
            "Those wipes are not learning.",
            "And then everything is.",
            "OK, so that's the short story about why they haven't."
        ],
        [
            "His belief that a different kind of animal.",
            "Sorry one question.",
            "OK, so here's a belief Mail and you met the tribe.",
            "Same old thing.",
            "I just want to do it in the same way refinery puce colored that use visible effects.",
            "Download the data.",
            "And some hidden unknown causes.",
            "Madonna.",
            "I'm not going to think of those closest to cast it.",
            "In general, I pretty much going to focus on the case where they're binary.",
            "Is those things that they're not there.",
            "OK, so in the general thing is belief that it was a graph and we get to observe some of the variables but not others.",
            "Everyone could make some inference and make a guess about some of the ones that we haven't seen.",
            "That's the general picture.",
            "So we have two problems which I'm sure you're familiar with.",
            "Is the inference problem.",
            "Once you, once you know some notes, what's the value of the other nodes?",
            "And then there's the learning Hall.",
            "How do I upgrade the parameters in this system to make it fairer?",
            "Accounting put data set that happen?"
        ],
        [
            "Russia.",
            "I don't know if you if you looked at belief Nets in terms of centigrades.",
            "This is it.",
            "This is the way I think of belief.",
            "Is the mega helpful?",
            "Maybe not if it is great.",
            "There is a bipartite graph is actually two kinds of nodes in the factor.",
            "Nodes are going to joyously little square great things.",
            "And in fact, in any graphical model, not just direct, once any graphical model, the joint probability over all the nodes is a parietal factors.",
            "Yes, basically the tracker in any graphical model, it's all about factorization.",
            "Try to break up the joint delivery which is.",
            "Exponentially how to specify?",
            "And transfer spot by counting the chunks that interact only loosely normal so.",
            "Factorization is at the core.",
            "We got the model ideas.",
            "Don't believe me?",
            "Just give me a good call.",
            "Not in a belief that we have a specific factorization and I want to come later to an underrated models which use different platforms actions, so that's why I mentioned it.",
            "OK, so hopefully this is just visible nodes, so in a belief net Gray nodes are associated with each of the big round nose.",
            "Which of the variables?",
            "So he refactor each variable and this factor is a little conditional probability table which holds the probability of XI child mode given experience.",
            "Again, the little Tiger numbers."
        ],
        [
            "For everyone happy with that so far.",
            "Alright, so here we go.",
            "I want to relate this to the neural Nets now so.",
            "The fact is inner inner belief net with chopped up the joint and factorize it in an effort to give get round six natural explosion of model powerful place the number of variables goes up but we still have a problem that we want to make big belief Nets.",
            "Lots of parents who knows there still exponential in the side of the number of parents who know.",
            "So in practice, the factors often get too large.",
            "To be honest, we've learned with finite data constructs point out.",
            "He is far too much data fill in these little conditional probability tables.",
            "However, we can cut down massively again, so this is a second head at the problem as well as the factorization.",
            "We can then say, well, let's let's parametrize these conditional probability tables to factories.",
            "So let's treat them.",
            "For example, one way around twice and only one that is a handy way, is to treat them just like new neurons in the film it so that the factors are holding probably a child given the parents.",
            "Well, I could just say the way we calculate that number is you take away that some of the activities that parents you stick it through it squashing function in the sigmoid function.",
            "And outcomes a number between zero and one, and that is the conditional probability.",
            "OK, so instead of yes, what goes into one of the nodes from the parents for their probabilities of the parents know well what comes in from the parent.",
            "I'm thinking of the parents is to catch the variables deployment.",
            "They binary, yes.",
            "So this is the general model in which the gas, the coolest app binary environment variable.",
            "You don't have to be, but I think I will go there.",
            "OK, so are you replace?",
            "These factors were still going to be there, but instead of being the conditional probability tables with lots of numbers in them, they're just going to consist of a bunch of ways and the number of ways is the number of parents so well plus one for bias.",
            "So we've cut down from 2 to the number of parents would be the number of rows in the different mobility table.",
            "We cut that down.",
            "Just remember parents, and that's a massive reduction.",
            "Number three period in fact.",
            "OK, that's great, pretty grateful.",
            "But it cut it down hugely."
        ],
        [
            "We get much colace sigmoid for evening.",
            "OK, this is called a sigmoid belief.",
            "Nets just belief net where we replaced the factors by parameterized path.",
            "OK, well it really great model.",
            "Full site images look like and I just doesn't have the images anything.",
            "It would be nice to have a bunch of stochastic things happening up there in the universe that can stick things happen.",
            "They cascade causing Alice to get things to happen.",
            "Those things called other things to happen and lots of things happen and that results in the world of RC.",
            "So really rich model of sad images would be.",
            "I'm going to say deeply field.",
            "Almost casted causes lots of them in layers.",
            "And it would Furthermore be easy to sample for easy tutorial sample form.",
            "A general model may fail is not the problem.",
            "So here's an example of a well nourished and yet it's only got 2 layers.",
            "There is more than one is that this is a belief net.",
            "Sing webelieve now.",
            "With two layers of hidden causes.",
            "But as you can see, it's also a neural net.",
            "But then the same thing.",
            "We can think of them the same way, but now it's actually believing it gives us a lot of individual grant.",
            "We know whole lot about how things should be done with the next and apply them to neural Nets and beer list ad hoc available.",
            "Yeah, so there's my claim.",
            "#1A signal believed it would be a great idea if we could just figure out how to make 1.",
            "Oh here's my."
        ],
        [
            "Electric slide about signaling neurons just to spell it out is we're going to take away his son Michael at 5 signaling function is 1 / 1 plus either minus 5.",
            "Standard stuff, right?",
            "And as a learner also.",
            "So if you have some X is coming in.",
            "At the inputs and, let's see our ships.",
            "I should've said XI is coming out.",
            "After the sample from that signaling function, so it's 01 itself.",
            "Then here's the living room for making that same age, so I happen.",
            "Next time more likely happen.",
            "Sticker next.",
            "I have an output, I'll calculate.",
            "It was actually the probability of another one using signal function and then I take a sample that CSI is the learning rule that will make that exile same value more likely.",
            "Next time you only know the next size at the input, right?",
            "Yeah, so I'm saying that if I newly if I have no, this is just a learning.",
            "There's no target here.",
            "This is just a learning rule that will make whatever just happened more likely to happen there.",
            "And why aren't your gradients dictating?",
            "Again, disappearing as before.",
            "As you mentioned very early in the early side.",
            "Twice it's different now.",
            "Yeah, initially you had some neural network saying he said that they don't work because I'm great in Spanish you know that part of the target, so this is not.",
            "This is not a target driven thing, this is just I put in some inputs.",
            "Something happens at the output of this single neuron and this is.",
            "This is what I would do to make that same outlook.",
            "That was awhile.",
            "This might get more likely next time.",
            "This is how I do it.",
            "I put a minus in front of 1 to make it less likely.",
            "So we're not using this yet, I'm just pointing it out."
        ],
        [
            "OK, so in for whole network I can easily make the patterns across the whole network more likely so I can invite generator sound coming from the whole network.",
            "It's easy to make.",
            "A pattern, will likely, it doesn't mean it's easy to solve.",
            "So just to say that again, here's how we started from a belief net.",
            "It's really like if you like that one thing, let's.",
            "Text.",
            "Memorable about belief, net is.",
            "It's really, really easy to sample from.",
            "The complex distribution.",
            "Then we get visible units, but it's really easy sound.",
            "Just start at the top and you got prize given by the bias weights.",
            "Here you calculate how the signaling function you take a sample 01, and then you do that in the next layer down in the next day down and then slow down and by the end of it you've made a sample from the joint distribution of this belief net.",
            "So really easy to sample and join.",
            "And that comes down to the fact that P of X, where X is older, all the neurons just backwards into these little packets, which are probably the child could occur.",
            "That's why it's so easy."
        ],
        [
            "OK, so this seems correct.",
            "Here we got this user says the generative model.",
            "Beautiful pictures, deep belief Nets that capture all kinds of interesting structure.",
            "We just have to do the learning path.",
            "And at this point I want to step back actually from even the direct belief net graphical model and just talk about Super General view of learning in graphical models.",
            "Just because I think, OK, I hesitated almost because it's got some some lines of math and less math.",
            "It's usually good thing.",
            "In the tutorial.",
            "On the other hand, it's really good to have it in.",
            "See it once.",
            "I think some of it, everyone should know.",
            "So it's almost slides and you can take it.",
            "Take it away with you.",
            "I won't necessarily go through every line.",
            "Torture some here, but I want to point out so you can see the channel argument.",
            "'cause I think it connects a whole bunch of things first.",
            "So sorry I don't think we're going to have to CFD.",
            "I have some visible variables V and some hidden ones action, so he was there is going to be the bottom layer matches everything else above it.",
            "An arrow stochastic binary variables.",
            "And as a joint distribution of XX is just going to refer to be an actual together, how long?",
            "So there's a joint information P of X.",
            "Given the West, the parameters of the belief net.",
            "But I'm going to drop off the given W from most of what follows, just 'cause it's in everything 'cause everything is given away."
        ],
        [
            "Alright, so first thing to do is just.",
            "Be able to talk about unnormalized probabilities, so is on left there, probably in H, probably X something.",
            "Is the distribution over?",
            "Parents across the whole belief net.",
            "And it's helpful sometimes to be able to talk about and analyze probability, which means just make up another number which is positive and I'm going to call that P star.",
            "Enclosed please gonna be side by side where I defined said to be the sum of the startup all configurations.",
            "Right?",
            "I do the sisters hand.",
            "You'll see why.",
            "OK, so this is just some of his daughter overall configurations of the network, of course is exponentially.",
            "Many family hope never to have to calculate this summer.",
            "Alright.",
            "In some cases in the directed belief and directed graphical models otherwise known as weakness.",
            "This sound is automatically what?",
            "So it's another great thing about belief Nets and is that they will dramatically normalize you.",
            "Don't see stars people, but we can think of we will later, but other graphical models under rated ones.",
            "We have peace tires, not necessarily one.",
            "In fact, it's a real pain to try to attempt to make it work.",
            "Much easier just to talk about peace though, and let them take care of yourself.",
            "So that's the account I flagged here, so this is."
        ],
        [
            "Longing to hear is going to cover both cases.",
            "Oh yeah, we met problem.",
            "It's all happening and the product code.",
            "OK."
        ],
        [
            "How is just to recap what I said before actually that.",
            "In a in a belief there.",
            "If you want to take the gradient of log of the stuff we were frequently going to be very interested in this log P style.",
            "The underlying problems with the log of it.",
            "We want to take the gradient effect with respect to the weights.",
            "Just going to show up everywhere.",
            "So what is that?",
            "It looks like something kind of fierce, but if you want to keep in mind for belief net it is just this Delta rule.",
            "The same rules before the eggs lines being times table.",
            "Right WR Gabe on ways to break from J and divine.",
            "OK so far."
        ],
        [
            "See if not.",
            "Alright, so this is about I want to show you this.",
            "What we need to do is we want to calculate the the log likelihood.",
            "In fact, we want to go after its gradient.",
            "So here's the log.",
            "Likelihood is low because the data set that's a sum over V in the data set.",
            "A pig now, but they stab their line and then practice log into a different smoky style, minus log said that's all straightforward Smith.",
            "And then of course, the summer over logs here is just log said.",
            "So we got two best.",
            "The log likelihood got these two beds and this is going to be a big there's a bit the first part.",
            "Which is.",
            "Something to do with the data set.",
            "It's got the unit right, V in in Big, D for David.",
            "So structured data 1st and then there's a negative 2 minus log was there when Logan said is just this normalizing constant.",
            "Which, by the way is 1 and believe myth.",
            "Fine, now I want to take it gradient.",
            "And there's a little trick to taking this gradient which is just pending.",
            "Keep in mind, it's just that the grain of the law of P. Is one of the highest rating people.",
            "How long for crates is this helpful to keep that in mind, and his converse going around one or two down spelled it out?",
            "District um?"
        ],
        [
            "In order to do this grading.",
            "OK.",
            "So the whole talks now can be lines in math like this.",
            "Which one is right?",
            "Play the T without the stars in the life one piece tires the unnormalized one.",
            "Ha ha ha.",
            "OK, so what's the grading of Longpi style?",
            "That's the thing I I have to notice in order to make things.",
            "The pens are like more likely.",
            "OK. Well, let's see.",
            "We used to trigger first line, then use the same rules second line.",
            "Then you reorder stop third line.",
            "And then I use the trick in the opposite direction, both mine and then I use the product rule in the last month.",
            "So you could just check those out for yourself later.",
            "I'm happy with that.",
            "But I think it's gotta mastery about right.",
            "You use check one way and then use the sum rule least check the other way and use the product rule.",
            "Done everything.",
            "Once.",
            "And the bottom line is set up.",
            "Regretting of this law is that.",
            "Yeah, most probably even given visited some particular visible pattern final, so it is not Lisa this is.",
            "That's right, yes, for a given visible pen, the grading of Lucky Star involves this thing here.",
            "Just here on average over the posterior.",
            "Extra thing, it's the bit on the right is is our friend, the Delta rule great.",
            "This is why it's important very lucky star of X where X is our configuration the whole network.",
            "And what we're doing?",
            "We're sort of doing the Delta rule, but over a distribution, which is the posterior earlier page given B.",
            "So that's the first first term.",
            "Why they did it one I'm doing the 1st.",
            "All I was doing was.",
            "Here's the overall low blocks with Anna has some at a low key style, so I'm going to take a greater pressure gradient there now.",
            "Going to the second power taking agreement models here.",
            "Negative time."
        ],
        [
            "Don't want to pass.",
            "Anime apart and I won't go through a line by line, but when you do that you get something very similar.",
            "In game, reduce that rank in both directions.",
            "And we probably used assembling product for as well.",
            "It's an analogous case, but it comes out slightly differently.",
            "So in this case, now we have the same thing on the right great involved.",
            "He's got out, but the average is different.",
            "This time you take an average over the joint distribution.",
            "And not an average of the data set.",
            "Now I never posterior just an average over the joint."
        ],
        [
            "OK, so this.",
            "Please put that together and simplify it.",
            "Time to do that.",
            "So this is this is the big story.",
            "It's always.",
            "There's always two terms.",
            "We didn't take the gradient of the log likelihood, and it turns out to be these two terms.",
            "And there both involved the gradient of Longstaff.",
            "Which is why I focused on my family.",
            "Invite involved great the same thing.",
            "They're just different averages over.",
            "In the first average is a positive part and that involves the Davis here.",
            "So we go through the data and then we go through.",
            "Well, we have to average over the posterior pH given V for each element of the data set.",
            "Tony and in the six times negative.",
            "And it's an average of the joint distribution.",
            "Nothing to do with the data set.",
            "Just join.",
            "All configurations of their belief there is heaps of them.",
            "Let's meet at the same thing is being averaged right in that thing.",
            "In the case of belief, net is deductible.",
            "OK, some people like you brought about this even shorter.",
            "This is just another way of saying the same thing, so don't freak out.",
            "And that the angle brackets.",
            "The first term is positive.",
            "It involves an average over data set and posterior, and the second term is just X chosen from the joint events.",
            "But the thing inside the angle brackets is the same.",
            "OK, so one way to think of this as given names is you could call us people can call us declared awake phase.",
            "It's.",
            "It's the part of learning that if he did, learning by doing the lead, can terminate the right handling.",
            "There's a plan of learning this to do with the data set, keeping eyes open, looking at the world and taking samples from the posterior here page given V. Actually crucial.",
            "And making those all market.",
            "Phone number for getting off at H. 8 binary an extra farmers also gives, so they're vectors applying for their table.",
            "There be some overage then you have to come over to the something many things.",
            "Yes, that's right.",
            "Exactly right.",
            "So these these averages are over configuration, so the left hand one we get a V from the data set.",
            "That's great, but then we're supposed to.",
            "This says what you have to do is you have to average over the configurations of hidden units.",
            "And if there are any hidden units, then you got to the end configurations horrible.",
            "Anyone living so grateful.",
            "This is worth thinking times worse negative line.",
            "It's over everything, including the physical unit.",
            "So it's even more.",
            "OK, but the second term is negative so it's you can think of it as the first term.",
            "Is that waiting will make it more likely the data set and these hypotheses chosen from pH given the hidden lives in new configurations.",
            "And the second term is downlighting, making less likely random fantasies.",
            "If you could run shopping network that we make the dreams by the way you're treating is making less likely.",
            "And this is all I've done is just used the channel on the log likelihood, but it's kind of neat that breaks down with these two bits.",
            "Alright, OK."
        ],
        [
            "For example, in that example.",
            "Just to come back to it is the belief net where this gradient thing is the Delta rule great and the second term is zero.",
            "That's because the second term zed, is Zettel, actually guaranteed.",
            "We wanna believe mirror automagically normalized.",
            "Instead of writing them frameworks nothing.",
            "So the 2nd just completely goes away.",
            "There is not asleep phase involved in learning at belief net.",
            "Sigmoid belief, net.",
            "You just do the wake fails.",
            "Great, so this may have made you think of something called the email and if you know what that was, but I think this is actually a level net so not sure.",
            "So.",
            "So if you might remember what is Allie and goes in yesterday's Wichita, actually.",
            "OK, so the amount goes up.",
            "This is a two step process.",
            "The step we go and get some samples from the posterior.",
            "We got some data vector and then we go and get samples from the possible.",
            "This is a sample view of the email.",
            "We get samples from the posterior via vacuum V. And then the instead you might you apply the learning all the Max.",
            "Each size configuration for life.",
            "And that's what's happening here.",
            "So this all seems hunky Dory.",
            "All we have to do is get these samples from the posterior and apply the buildable."
        ],
        [
            "His cash.",
            "It's all going swimmingly well.",
            "We settle this catch.",
            "In a belief net signal development.",
            "It is easy to draw samples from the joint distribution from the product.",
            "Time, probably agent be could just make samples.",
            "I can make fantasies it's really easy.",
            "Just start talking.",
            "Look down OK.",
            "But now we don't need those.",
            "We need samples from the posterior.",
            "We need just think of the pattern on the bottom.",
            "And they make samples from.",
            "He likes giving him.",
            "And unfortunately, that's not so easy.",
            "How we can do it?",
            "One way to do it would be to.",
            "This is a bad winter.",
            "Distance is just a sample from the prior.",
            "Generate a hollow sound which is easy.",
            "Making sounds from prime and throw out the ones that don't produce.",
            "Visible pens in the data set and once you got left in samples from.",
            "Device given video.",
            "So that they will be silenced.",
            "From the right distribution, but of course, that's terribly terribly different, like throwing like everything.",
            "And there is nobody.",
            "We got a bit smarter and the Snyders is attending Gibbs sampling.",
            "So quit your hands, get familiar with Gibbs sound happy.",
            ","
        ],
        [
            "Alright, so just to recap or look at Gibbs sampling and this is a figure taken from their replies book and I recommend that the understanding give something from the way have a look at that.",
            "This is this is this figure this schematic.",
            "Perhaps this is a Gibbs sampling and continuous space.",
            "We're going to be doing give sounding in this space of binary units, but the idea is the same, so Gibbs sampling.",
            "How you doing?",
            "You gotta multi dimensional distribution.",
            "X how you do it as you choose a dimension at random, let's choose life at random.",
            "So for example, they were going to go along with the X one dimension in this example here.",
            "Hey Dora sample.",
            "I'm assuming start up at some particular eggs.",
            "Now I'm sure it's not new sample for XI from the conditional distribution.",
            "As I give it only other it's values.",
            "You could do that.",
            "And then you iterate.",
            "Keep doing this.",
            "Choosing new dimension, another dimension and then choosing from the conditional distribution game.",
            "You keeping doing this over and over again, this is called Gibbs sampling.",
            "And the name players that this is guaranteed get you samples.",
            "If you wait long enough it will give you samples and its equilibrium distribution, which are samples from P of X.",
            "It's a really simple way to sound.",
            "Phoenix do you have to run it with Michael Chaney after and we have to do this along time because the initial one obviously is corrupted by the fact that you chose some initial X which was arbitrary.",
            "Obviously the first sample wouldn't be.",
            "And by Saturday events.",
            "You gotta wait long and then you take a sound coming to little bit longer.",
            "Get another sound so it's a tedious business.",
            "But this is a way to generate samples from vehicles.",
            "So we."
        ],
        [
            "Do the same thing as working at sigmoid belief in his good sounding a sigmoidal evening, and I like this one 'cause it is just the most basic seem overly imagine it's got 2 hidden units.",
            "And one visible unit.",
            "So it's got a couple of lights and I live by myself, invisible unit and the hidden units have a little biased late coming into them.",
            "OK, 2 hidden causes if you like.",
            "Bigger than problem, no I mean.",
            "I'm.",
            "In this management, visible now is observed.",
            "That's the situation I want.",
            "I want to draw samples from here that's given V, so these been observed.",
            "You know, I looked at it and it's one.",
            "Analysts think about give starving for H1H2.",
            "How's it going?",
            "Well, if you if you write down, we can write down the joint distribution.",
            "You HMV is the amount that's a product of factors.",
            "But Even so that means I can use the rules of probability to figure out what is P of H1 given V1, and given the value of H2 initial scale.",
            "I can do it, but I get that equation on the rise is horrible.",
            "Yeah, yes, but just two hidden units.",
            "It gets more Yahoo for more.",
            "So this jacket is a big part of story, really running Gibbs sampling and sigmoid belief man is apparent.",
            "But you can do it.",
            "Yes, you can calculate it.",
            "It's it's slow.",
            "It's only this demanding and focusing on is also slow to get samples from P. Eventually image two, I have to run this Markov chain.",
            "And every time I upgrade the status of a particular hidden unit is like choosing I. I choose I an operator 5G of H. I've given everything else in the network.",
            "Then both quantity calculation.",
            "So each step involves build calculation and there are lots of steps because we had to run the giant before I want to reach equilibrium.",
            "So it's loading now.",
            "Now I have to do this well.",
            "One way to think of this as I want to connect to is this idea of explaining why and we explain it away."
        ],
        [
            "In the context of belief, mix and the classic example, lyberger is like allowing problem Brad.",
            "You have much better example.",
            "You got away with this crap.",
            "We got away from the bigger line problem.",
            "There's a trial.",
            "This is a classic example, so business price bicycles, Lamb, once the burgers and earthquakes are hopefully uncorrelated.",
            "But once the alarm is going off.",
            "Figgeurs Netflix.",
            "Micro SD card.",
            "So my belief that I've been burgled asking the llamas corner goes down when I hear this be an earthquake.",
            "So bigger meth pipes become linked.",
            "And probabilities.",
            "And that's the whole problem.",
            "So they were not playing are independent in the prior, but they are dependent in the posterior.",
            "That's the big story.",
            "Dependent on the posterior.",
            "Unfortunately what I need to sample from the exterior product.",
            "That's my sound in the posterior slow.",
            "Because these things are dependent now.",
            "I can't just not change be it changes and probably be.",
            "Umm, now have a big belief net with lots of neurons for 100 hundred 30 minutes by itself there and you know 20 alarms at the bottom as well.",
            "A decent sized network.",
            "Everything is interfering with everything else and I had to run this long.",
            "Michael Chang.",
            "OK, so the fact that Gibbs sampling is slow and ugly is directly related to this idea of explaining way in belief.",
            "Nets are the same, the root causes and sound.",
            "And it's to do with being independent prior should be independent cry.",
            "You have to be dependent on the posterior, so it's going to happen.",
            "Something went wrong.",
            "Just a consequence of being clear and being independent in the prior living independent causes tsunami.",
            "Alright.",
            "So this is really inconvenient for us.",
            "There is no quick way to draw a sample from here.",
            "Probably the hidden units.",
            "Given the visible gas, but that's what we need to do in it.",
            "OK, we make good progress here so."
        ],
        [
            "Questions you should throw them in at this point.",
            "Here's my summary slide.",
            "Sigmoid belief Nets are.",
            "Well, right now very appealing as a generative model.",
            "Buck there is the reason to sample from as a generative model, but I really have to learn and the reason for learning is tired to explain away.",
            "Incidentally, the fact that.",
            "Did this.",
            "That's how the sample compared to given V also makes them difficult to use for this class of recognition.",
            "Actually applying invisible pattern and figuring out what is the neural net of the signal admit.",
            "Think of this visible path.",
            "What is its internal representation of it?",
            "Well, we have to draw samples from P eventually to do that, and that's how it is slow.",
            "So learning is slow, and inference that recognition is slow.",
            "There's also this issue.",
            "Man big business.",
            "So if I just made a large independent that first problem is also that if I made a large network.",
            "Sigmoid belief then and try to try it out.",
            "I would have this similar problem to the background networks before, at which sort of chicken and egg problem that how the deep layers of this network in the learning anything.",
            "Then the output lab at the bottom layer wax wants to learn to make the the visible pantelakis great, but always got to do to work off as the input Commission layer above, and that layer doesn't know anything yet.",
            "And likewise it's very hard to imagine that layer about learning anything, because the lab below is just giving it garbage.",
            "It is a very much chicken egg problem.",
            "Again, you get in a deep belief net made in this way you cannot train the players even aside from all the slowness that may be used.",
            "Yeah so."
        ],
        [
            "I think I have side difficulty with standing in different locations of any of us.",
            "The eastep take samples from the Gibbs sampler samples for the hidden variables, so to update that available, yes.",
            "An Easter if you mention that we apply their talents.",
            "Sorry it at least at least now I think of the East.",
            "It is running a little map of chain doing Gibbs sampling from HTML B and then with the samples that you get by doing that.",
            "You apply the Delta rule, and that's analogous to the instinct in the MLB.",
            "The values for the hidden variables.",
            "Right?",
            "Yes, and then step.",
            "We need to apply for dental, which does not include capital variables.",
            "No, that's OK.",
            "So the Delta rule I expressed in terms of just X variables because you could apply it to anything could be visible in anything.",
            "Lyrics for it to be adventure.",
            "Japanese index covers HV yes.",
            "My ex covers by to make any other training outlook that I PM.",
            "After doing this no.",
            "Well, I guess there are other ways to do it.",
            "This is all sorts of ways to optimize things, but this is the way that follow the gradient.",
            "Incredible online.",
            "Soon.",
            "Yeah, I'm going to assume that the structure is just given.",
            "So yes for belief net, structural learning is of course a huge deal.",
            "But we're actually aiming to match large sigmoid belief Nets with lots of hidden layers and lots of nodes in those layers, and essentially we're hoping struck with the structural.",
            "Problems are gonna go away.",
            "Picnics anyway.",
            "So no worries.",
            "Sorry someone I gotta disappear.",
            "Yeah, so by learning the way some about music business apps.",
            "I'm not assuming that's gonna happen.",
            "Is sending me a lot of parameters in these in these animals?",
            "Yes, we start approval is regularization.",
            "One could have an equivalent.",
            "Yes, I haven't talked about that at all.",
            "I simply be maximizing the log likelihood.",
            "But of course, yes, you could introduce regularization Casavant be somewhere became.",
            "Very good idea.",
            "Stopping weights going able yes.",
            "What's the difference between supervised, great net and the bathroom renovation next and back off?",
            "OK, what's the difference between sigmoid belief then Anna back propagation there?",
            "In the truck we take that we.",
            "There's a bunch of differences.",
            "In about not missed one typically.",
            "Types the signal does not take samples from the signaling function.",
            "As you propagate forward through the network.",
            "Typically you just pass on the output of a sigmoid unit onto the next layer, but of course you could sample, so that's not a fundamental difference.",
            "In that process you get the target value at the output.",
            "You assist difference between that and what you wanted, and you calculate degrading.",
            "Going backwards in this layer wise fashion.",
            "Application action.",
            "Here we don't have a target out, we just this is unsupervised learning so it's a generative model.",
            "Yes, the structure is the same.",
            "Yeah, they all there made exactly the same way we got these signaling neurons in the network that Speedball.",
            "That's right.",
            "But in this case, I guess you should think of the.",
            "My visible units are like the output of a of a neural net backup, and if there's no improvement.",
            "It's just a general model of some data that you got.",
            "I know so that the vision problems differently.",
            "The learning of a. Unsupervised matching.",
            "Are they in networks where you have a certain assumption for the conditional?",
            "When you have simple assumption for the conditional probabilities, yes, OK, so she's saying it would be fair to say that the sigmoid belief net is well.",
            "It is a Bayesian network where we have a particular assumption for the.",
            "For the factors absolutely.",
            "The signal never is a Bayesian net is a belief.",
            "Net is another is a directed graphical model, is probably a bunch of other names.",
            "Is there a list and this is 1.",
            "In particular, we have made the assumption about the the wife's or sorry the factors are going to be little signal.",
            "The parameter little signal X.",
            "What's the smallest case which you can prove that things learn fast?",
            "Enjoy it or ask a lot.",
            "I'm not sure.",
            "I mean yes, yes, the visible yes.",
            "And payment and you can learn really fast.",
            "20 years for using it.",
            "It's coming up as the.",
            "I just had question makes sense of what can you practically learn.",
            "It depends on the Markov chain of Gibbs sampling and hidden units until well that chain mixes.",
            "I don't know this one.",
            "OK, yes I did ask questions.",
            "So if you say that the big pieces of Asian networking psychosocial so do you have to have at the physical layer to always be the children which were not parents?",
            "I have a question, do I always have to have the visible units as the as the child is the bottom layer?",
            "How could I have been somewhere else?",
            "I guess just like in any belief net, you could have them anywhere.",
            "That's true, you could build knows that and visible units anyway.",
            "I'm not sure why you do that.",
            "I'm trying to build a generative model of some of some data center.",
            "Today is the general offensive, so I had a visible units at beginning, OK at the top layer, and then I make a whole of India.",
            "Just a general model of 10 units that I had no data about.",
            "Yeah, totally focused on that case with a visible unit bottom layer.",
            "OK, how we doing?",
            "It's over.",
            "Yeah, I'm gonna finish this line then.",
            "I think we should go have coffee attendance at right hip against perfect timing.",
            "OK so just to summarize sound from the posteriors.",
            "Glad that makes these things had to use for recognition.",
            "We have a chicken and egg problem in the deep layer.",
            "What I wanted to do next is just ignore one.",
            "I mean, let's say we can do that.",
            "We build a super duper gives sample.",
            "Here it is.",
            "Here it runs around remotely.",
            "Clappers and that problem goes away.",
            "Imagine that went away.",
            "Could we still do the second one?",
            "I don't wanna answer that, I'm Naked.",
            "Board president, that's that's what's going to happen after the breath and then are revealed.",
            "Magic answer to all problems.",
            "OK. We got 20 minutes."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, good morning.",
                    "label": 0
                },
                {
                    "sent": "I'm talking about deep belief Nets, deep belief Nets and ideas.",
                    "label": 1
                },
                {
                    "sent": "Come about fairly recently.",
                    "label": 0
                },
                {
                    "sent": "In the last four five years and it's finding something special causing some interest.",
                    "label": 0
                },
                {
                    "sent": "So my plan here is to give you a tutorial covering essential ideas of the belief matters.",
                    "label": 0
                },
                {
                    "sent": "Videos of China.",
                    "label": 0
                },
                {
                    "sent": "For me it's a little story of Alana.",
                    "label": 0
                },
                {
                    "sent": "Can't understand.",
                    "label": 0
                },
                {
                    "sent": "You could sort of retailers and reach certain understandings by doing that, but then a common responses that I've found from other other people.",
                    "label": 0
                },
                {
                    "sent": "There's I sort of get it, but why does it really work?",
                    "label": 0
                },
                {
                    "sent": "And So what I wanted, but I'll be successful today.",
                    "label": 0
                },
                {
                    "sent": "I can get it cost some notion to you why it really works and why it's taking the shape that has taken issue.",
                    "label": 0
                },
                {
                    "sent": "Some people like to say that people leave mixer, so third wave of neural Nets first wave, which is the perceptron second wave which is that problem.",
                    "label": 0
                },
                {
                    "sent": "So here we are in the 3rd way.",
                    "label": 0
                },
                {
                    "sent": "His new romantic ideas seem to go on God about cycle about 20 years and reliable and we reached, you know, just going past 20 years thinking here.",
                    "label": 0
                },
                {
                    "sent": "We are deeply missed their annual Nets, but they're intimately related to belief Nets as well.",
                    "label": 0
                },
                {
                    "sent": "OK, so?",
                    "label": 0
                },
                {
                    "sent": "Pfister, just a quick shower hand side so I know roughly where I'm at here.",
                    "label": 0
                },
                {
                    "sent": "We hands up if you know what PCI is.",
                    "label": 0
                },
                {
                    "sent": "I mean, you had a troll.",
                    "label": 0
                },
                {
                    "sent": "OK, hang on there, but if you know where Boston machine is.",
                    "label": 0
                },
                {
                    "sent": "They haven't even hang up if you actually 'cause one out.",
                    "label": 0
                },
                {
                    "sent": "Right, it's a good place to eat oils, and I'm going to right spot so.",
                    "label": 0
                },
                {
                    "sent": "Another thing I want to say, it's just kind of consolidate will connect some of the earlier tutorials and ideas, so I'm going to talk about a little bit about Gibbs sampling and a little bit about EM algorithm connections to email rhythm and other ideas.",
                    "label": 0
                },
                {
                    "sent": "They will come in, so it's a sort of survey whatever.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to do is tell you all about the latest bells and whistles, so deep belief Nets idea came up in about 2006 I guess.",
                    "label": 0
                },
                {
                    "sent": "And since then, I've been a few tweaks and interesting directions.",
                    "label": 0
                },
                {
                    "sent": "It's an active field now.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to attempt to survey local latest developments is more like.",
                    "label": 0
                },
                {
                    "sent": "Here's the basic idea.",
                    "label": 0
                },
                {
                    "sent": "How can get it, that's great.",
                    "label": 0
                },
                {
                    "sent": "Then you'll be able to follow these layers elements yourself and chase them up, OK?",
                    "label": 0
                },
                {
                    "sent": "So here's rough.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I was going to go.",
                    "label": 0
                },
                {
                    "sent": "This plan anyway, so I'll start just by motivating idea basic idea where we're going and why we're going there by talking about a couple of applications that one would like to be able to do better.",
                    "label": 0
                },
                {
                    "sent": "And then I want to go into sigmoid belief Nets or hands up if you know what a sigmoid believe members, not just great seeing Mom hands, that's good.",
                    "label": 0
                },
                {
                    "sent": "So I have something to say about that.",
                    "label": 0
                },
                {
                    "sent": "Basically I'm going to use that to reliable increments to filaments.",
                    "label": 0
                },
                {
                    "sent": "And then I'm going to throw up their hands and I would say we need to try something different.",
                    "label": 0
                },
                {
                    "sent": "And there's something different.",
                    "label": 0
                },
                {
                    "sent": "Is a Super Bowl idea football to machine and I'm going to describe the Boltzmann machine is and then cut it down and make it into a leaning building machine which we're going to use to build deep belief Nets again.",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, he's a bad from it and hands off you know what that means?",
                    "label": 0
                },
                {
                    "sent": "OK, so I don't know that one.",
                    "label": 0
                },
                {
                    "sent": "I'm just going to lay my hand on my lock today.",
                    "label": 0
                },
                {
                    "sent": "Sure, you get the idea in professor at the bottom, I'm always going to stick the input at the bottom.",
                    "label": 0
                },
                {
                    "sent": "I really mean it is the data vector involved since will mostly be going unsupervised learning and usually no output.",
                    "label": 0
                },
                {
                    "sent": "But here's the background.",
                    "label": 0
                },
                {
                    "sent": "Network then goes into the bottom, goes through some hidden layers of neurons, and comes out the top as an output.",
                    "label": 0
                },
                {
                    "sent": "Never compare the output to what it should have been.",
                    "label": 0
                },
                {
                    "sent": "Pulling.",
                    "label": 0
                },
                {
                    "sent": "Some transit will drop the error and I want to upgrade all the weights in this network to be able to do a better job and the form that that album takes is.",
                    "label": 0
                },
                {
                    "sent": "You can think of it as back propagation of errors.",
                    "label": 0
                },
                {
                    "sent": "Going back to the West, and it seems that's one way to think about it.",
                    "label": 0
                },
                {
                    "sent": "OK, we correct from the back from the output that will be important.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Either particular that network.",
                    "label": 0
                },
                {
                    "sent": "Which is interesting.",
                    "label": 0
                },
                {
                    "sent": "You stick in the input at bottom left and then you try to get the same pattern back out with the output lab.",
                    "label": 0
                },
                {
                    "sent": "It's initially had to see how this is a good idea.",
                    "label": 0
                },
                {
                    "sent": "You know I could do that with the identity matrix, but the trick is in between.",
                    "label": 0
                },
                {
                    "sent": "I want to squish it through a bottleneck layer, some kind of restricted representation in the middle.",
                    "label": 0
                },
                {
                    "sent": "So I use the first night I get ready and then it goes squish through the ball now and comes out again and I tried to reconstruct the input, only output numbers.",
                    "label": 0
                },
                {
                    "sent": "This is interesting idea, because if you succeed in this, you have found a much reduced representation of the data, yeah?",
                    "label": 0
                },
                {
                    "sent": "Natural conditions where we want to reconstruct the input and calculate data is it's not so much identical, so that's right.",
                    "label": 0
                },
                {
                    "sent": "I want to try.",
                    "label": 0
                },
                {
                    "sent": "This is just the background network, just saying is an example of that point network with the output is the input.",
                    "label": 0
                },
                {
                    "sent": "The target is being put down, so if I succeeded this I found a room reduced representation of data and be happy.",
                    "label": 0
                },
                {
                    "sent": "Found some interesting minimal description of data.",
                    "label": 0
                },
                {
                    "sent": "OK, and again you're training for backups.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Same idea.",
                    "label": 0
                },
                {
                    "sent": "So it would be great, but they only make these things will not be fabulous.",
                    "label": 0
                },
                {
                    "sent": "They haven't worked, despite repeal of them despite the appeal of just, you know, feeding video at one end and getting out of representation of the world on the three hidden units in the middle.",
                    "label": 0
                },
                {
                    "sent": "That never works well.",
                    "label": 0
                },
                {
                    "sent": "That's part of it.",
                    "label": 0
                },
                {
                    "sent": "Like one of you want, it talks about the well.",
                    "label": 0
                },
                {
                    "sent": "I haven't worked well really.",
                    "label": 0
                },
                {
                    "sent": "I'm not.",
                    "label": 0
                },
                {
                    "sent": "Can we do better?",
                    "label": 0
                },
                {
                    "sent": "So the usual answer for why haven't worked well is something along the lines of I'm waving my hands, the hidden units all interact with one another and the gradient.",
                    "label": 0
                },
                {
                    "sent": "The error correction gradient.",
                    "label": 0
                },
                {
                    "sent": "The raw material for learning this credit gets tiny as you move away from the output.",
                    "label": 1
                },
                {
                    "sent": "So the last layer weights initially have a little bit of a gradient.",
                    "label": 0
                },
                {
                    "sent": "You can see how to fix them up.",
                    "label": 0
                },
                {
                    "sent": "But the lab before that there's not much you can do.",
                    "label": 0
                },
                {
                    "sent": "Fix them up because the output layer hasn't learn anything yet and they're getting garbage in from below because those are just random initial waves.",
                    "label": 0
                },
                {
                    "sent": "And this was garbage.",
                    "label": 0
                },
                {
                    "sent": "And you just kind of figuring it.",
                    "label": 0
                },
                {
                    "sent": "There's no way to go.",
                    "label": 0
                },
                {
                    "sent": "There's no gradient.",
                    "label": 0
                },
                {
                    "sent": "So as we get deeper in the network, certainly when you get down to these lower class here, there's no gradient.",
                    "label": 0
                },
                {
                    "sent": "Those wipes are not learning.",
                    "label": 0
                },
                {
                    "sent": "And then everything is.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's the short story about why they haven't.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "His belief that a different kind of animal.",
                    "label": 0
                },
                {
                    "sent": "Sorry one question.",
                    "label": 0
                },
                {
                    "sent": "OK, so here's a belief Mail and you met the tribe.",
                    "label": 1
                },
                {
                    "sent": "Same old thing.",
                    "label": 0
                },
                {
                    "sent": "I just want to do it in the same way refinery puce colored that use visible effects.",
                    "label": 0
                },
                {
                    "sent": "Download the data.",
                    "label": 0
                },
                {
                    "sent": "And some hidden unknown causes.",
                    "label": 0
                },
                {
                    "sent": "Madonna.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to think of those closest to cast it.",
                    "label": 0
                },
                {
                    "sent": "In general, I pretty much going to focus on the case where they're binary.",
                    "label": 0
                },
                {
                    "sent": "Is those things that they're not there.",
                    "label": 0
                },
                {
                    "sent": "OK, so in the general thing is belief that it was a graph and we get to observe some of the variables but not others.",
                    "label": 1
                },
                {
                    "sent": "Everyone could make some inference and make a guess about some of the ones that we haven't seen.",
                    "label": 1
                },
                {
                    "sent": "That's the general picture.",
                    "label": 0
                },
                {
                    "sent": "So we have two problems which I'm sure you're familiar with.",
                    "label": 0
                },
                {
                    "sent": "Is the inference problem.",
                    "label": 0
                },
                {
                    "sent": "Once you, once you know some notes, what's the value of the other nodes?",
                    "label": 1
                },
                {
                    "sent": "And then there's the learning Hall.",
                    "label": 0
                },
                {
                    "sent": "How do I upgrade the parameters in this system to make it fairer?",
                    "label": 0
                },
                {
                    "sent": "Accounting put data set that happen?",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Russia.",
                    "label": 0
                },
                {
                    "sent": "I don't know if you if you looked at belief Nets in terms of centigrades.",
                    "label": 0
                },
                {
                    "sent": "This is it.",
                    "label": 0
                },
                {
                    "sent": "This is the way I think of belief.",
                    "label": 1
                },
                {
                    "sent": "Is the mega helpful?",
                    "label": 0
                },
                {
                    "sent": "Maybe not if it is great.",
                    "label": 0
                },
                {
                    "sent": "There is a bipartite graph is actually two kinds of nodes in the factor.",
                    "label": 0
                },
                {
                    "sent": "Nodes are going to joyously little square great things.",
                    "label": 0
                },
                {
                    "sent": "And in fact, in any graphical model, not just direct, once any graphical model, the joint probability over all the nodes is a parietal factors.",
                    "label": 1
                },
                {
                    "sent": "Yes, basically the tracker in any graphical model, it's all about factorization.",
                    "label": 0
                },
                {
                    "sent": "Try to break up the joint delivery which is.",
                    "label": 0
                },
                {
                    "sent": "Exponentially how to specify?",
                    "label": 0
                },
                {
                    "sent": "And transfer spot by counting the chunks that interact only loosely normal so.",
                    "label": 0
                },
                {
                    "sent": "Factorization is at the core.",
                    "label": 0
                },
                {
                    "sent": "We got the model ideas.",
                    "label": 0
                },
                {
                    "sent": "Don't believe me?",
                    "label": 0
                },
                {
                    "sent": "Just give me a good call.",
                    "label": 0
                },
                {
                    "sent": "Not in a belief that we have a specific factorization and I want to come later to an underrated models which use different platforms actions, so that's why I mentioned it.",
                    "label": 1
                },
                {
                    "sent": "OK, so hopefully this is just visible nodes, so in a belief net Gray nodes are associated with each of the big round nose.",
                    "label": 0
                },
                {
                    "sent": "Which of the variables?",
                    "label": 0
                },
                {
                    "sent": "So he refactor each variable and this factor is a little conditional probability table which holds the probability of XI child mode given experience.",
                    "label": 0
                },
                {
                    "sent": "Again, the little Tiger numbers.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For everyone happy with that so far.",
                    "label": 0
                },
                {
                    "sent": "Alright, so here we go.",
                    "label": 0
                },
                {
                    "sent": "I want to relate this to the neural Nets now so.",
                    "label": 0
                },
                {
                    "sent": "The fact is inner inner belief net with chopped up the joint and factorize it in an effort to give get round six natural explosion of model powerful place the number of variables goes up but we still have a problem that we want to make big belief Nets.",
                    "label": 0
                },
                {
                    "sent": "Lots of parents who knows there still exponential in the side of the number of parents who know.",
                    "label": 0
                },
                {
                    "sent": "So in practice, the factors often get too large.",
                    "label": 1
                },
                {
                    "sent": "To be honest, we've learned with finite data constructs point out.",
                    "label": 1
                },
                {
                    "sent": "He is far too much data fill in these little conditional probability tables.",
                    "label": 1
                },
                {
                    "sent": "However, we can cut down massively again, so this is a second head at the problem as well as the factorization.",
                    "label": 0
                },
                {
                    "sent": "We can then say, well, let's let's parametrize these conditional probability tables to factories.",
                    "label": 0
                },
                {
                    "sent": "So let's treat them.",
                    "label": 0
                },
                {
                    "sent": "For example, one way around twice and only one that is a handy way, is to treat them just like new neurons in the film it so that the factors are holding probably a child given the parents.",
                    "label": 0
                },
                {
                    "sent": "Well, I could just say the way we calculate that number is you take away that some of the activities that parents you stick it through it squashing function in the sigmoid function.",
                    "label": 1
                },
                {
                    "sent": "And outcomes a number between zero and one, and that is the conditional probability.",
                    "label": 0
                },
                {
                    "sent": "OK, so instead of yes, what goes into one of the nodes from the parents for their probabilities of the parents know well what comes in from the parent.",
                    "label": 0
                },
                {
                    "sent": "I'm thinking of the parents is to catch the variables deployment.",
                    "label": 0
                },
                {
                    "sent": "They binary, yes.",
                    "label": 0
                },
                {
                    "sent": "So this is the general model in which the gas, the coolest app binary environment variable.",
                    "label": 0
                },
                {
                    "sent": "You don't have to be, but I think I will go there.",
                    "label": 0
                },
                {
                    "sent": "OK, so are you replace?",
                    "label": 0
                },
                {
                    "sent": "These factors were still going to be there, but instead of being the conditional probability tables with lots of numbers in them, they're just going to consist of a bunch of ways and the number of ways is the number of parents so well plus one for bias.",
                    "label": 0
                },
                {
                    "sent": "So we've cut down from 2 to the number of parents would be the number of rows in the different mobility table.",
                    "label": 0
                },
                {
                    "sent": "We cut that down.",
                    "label": 0
                },
                {
                    "sent": "Just remember parents, and that's a massive reduction.",
                    "label": 0
                },
                {
                    "sent": "Number three period in fact.",
                    "label": 0
                },
                {
                    "sent": "OK, that's great, pretty grateful.",
                    "label": 0
                },
                {
                    "sent": "But it cut it down hugely.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We get much colace sigmoid for evening.",
                    "label": 0
                },
                {
                    "sent": "OK, this is called a sigmoid belief.",
                    "label": 1
                },
                {
                    "sent": "Nets just belief net where we replaced the factors by parameterized path.",
                    "label": 0
                },
                {
                    "sent": "OK, well it really great model.",
                    "label": 0
                },
                {
                    "sent": "Full site images look like and I just doesn't have the images anything.",
                    "label": 1
                },
                {
                    "sent": "It would be nice to have a bunch of stochastic things happening up there in the universe that can stick things happen.",
                    "label": 0
                },
                {
                    "sent": "They cascade causing Alice to get things to happen.",
                    "label": 0
                },
                {
                    "sent": "Those things called other things to happen and lots of things happen and that results in the world of RC.",
                    "label": 0
                },
                {
                    "sent": "So really rich model of sad images would be.",
                    "label": 1
                },
                {
                    "sent": "I'm going to say deeply field.",
                    "label": 0
                },
                {
                    "sent": "Almost casted causes lots of them in layers.",
                    "label": 1
                },
                {
                    "sent": "And it would Furthermore be easy to sample for easy tutorial sample form.",
                    "label": 0
                },
                {
                    "sent": "A general model may fail is not the problem.",
                    "label": 0
                },
                {
                    "sent": "So here's an example of a well nourished and yet it's only got 2 layers.",
                    "label": 0
                },
                {
                    "sent": "There is more than one is that this is a belief net.",
                    "label": 0
                },
                {
                    "sent": "Sing webelieve now.",
                    "label": 0
                },
                {
                    "sent": "With two layers of hidden causes.",
                    "label": 0
                },
                {
                    "sent": "But as you can see, it's also a neural net.",
                    "label": 0
                },
                {
                    "sent": "But then the same thing.",
                    "label": 0
                },
                {
                    "sent": "We can think of them the same way, but now it's actually believing it gives us a lot of individual grant.",
                    "label": 0
                },
                {
                    "sent": "We know whole lot about how things should be done with the next and apply them to neural Nets and beer list ad hoc available.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so there's my claim.",
                    "label": 0
                },
                {
                    "sent": "#1A signal believed it would be a great idea if we could just figure out how to make 1.",
                    "label": 0
                },
                {
                    "sent": "Oh here's my.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Electric slide about signaling neurons just to spell it out is we're going to take away his son Michael at 5 signaling function is 1 / 1 plus either minus 5.",
                    "label": 0
                },
                {
                    "sent": "Standard stuff, right?",
                    "label": 0
                },
                {
                    "sent": "And as a learner also.",
                    "label": 0
                },
                {
                    "sent": "So if you have some X is coming in.",
                    "label": 0
                },
                {
                    "sent": "At the inputs and, let's see our ships.",
                    "label": 0
                },
                {
                    "sent": "I should've said XI is coming out.",
                    "label": 0
                },
                {
                    "sent": "After the sample from that signaling function, so it's 01 itself.",
                    "label": 0
                },
                {
                    "sent": "Then here's the living room for making that same age, so I happen.",
                    "label": 1
                },
                {
                    "sent": "Next time more likely happen.",
                    "label": 1
                },
                {
                    "sent": "Sticker next.",
                    "label": 0
                },
                {
                    "sent": "I have an output, I'll calculate.",
                    "label": 0
                },
                {
                    "sent": "It was actually the probability of another one using signal function and then I take a sample that CSI is the learning rule that will make that exile same value more likely.",
                    "label": 1
                },
                {
                    "sent": "Next time you only know the next size at the input, right?",
                    "label": 0
                },
                {
                    "sent": "Yeah, so I'm saying that if I newly if I have no, this is just a learning.",
                    "label": 0
                },
                {
                    "sent": "There's no target here.",
                    "label": 0
                },
                {
                    "sent": "This is just a learning rule that will make whatever just happened more likely to happen there.",
                    "label": 0
                },
                {
                    "sent": "And why aren't your gradients dictating?",
                    "label": 0
                },
                {
                    "sent": "Again, disappearing as before.",
                    "label": 0
                },
                {
                    "sent": "As you mentioned very early in the early side.",
                    "label": 0
                },
                {
                    "sent": "Twice it's different now.",
                    "label": 0
                },
                {
                    "sent": "Yeah, initially you had some neural network saying he said that they don't work because I'm great in Spanish you know that part of the target, so this is not.",
                    "label": 0
                },
                {
                    "sent": "This is not a target driven thing, this is just I put in some inputs.",
                    "label": 1
                },
                {
                    "sent": "Something happens at the output of this single neuron and this is.",
                    "label": 0
                },
                {
                    "sent": "This is what I would do to make that same outlook.",
                    "label": 0
                },
                {
                    "sent": "That was awhile.",
                    "label": 0
                },
                {
                    "sent": "This might get more likely next time.",
                    "label": 0
                },
                {
                    "sent": "This is how I do it.",
                    "label": 0
                },
                {
                    "sent": "I put a minus in front of 1 to make it less likely.",
                    "label": 0
                },
                {
                    "sent": "So we're not using this yet, I'm just pointing it out.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so in for whole network I can easily make the patterns across the whole network more likely so I can invite generator sound coming from the whole network.",
                    "label": 0
                },
                {
                    "sent": "It's easy to make.",
                    "label": 0
                },
                {
                    "sent": "A pattern, will likely, it doesn't mean it's easy to solve.",
                    "label": 0
                },
                {
                    "sent": "So just to say that again, here's how we started from a belief net.",
                    "label": 0
                },
                {
                    "sent": "It's really like if you like that one thing, let's.",
                    "label": 0
                },
                {
                    "sent": "Text.",
                    "label": 0
                },
                {
                    "sent": "Memorable about belief, net is.",
                    "label": 0
                },
                {
                    "sent": "It's really, really easy to sample from.",
                    "label": 1
                },
                {
                    "sent": "The complex distribution.",
                    "label": 1
                },
                {
                    "sent": "Then we get visible units, but it's really easy sound.",
                    "label": 0
                },
                {
                    "sent": "Just start at the top and you got prize given by the bias weights.",
                    "label": 1
                },
                {
                    "sent": "Here you calculate how the signaling function you take a sample 01, and then you do that in the next layer down in the next day down and then slow down and by the end of it you've made a sample from the joint distribution of this belief net.",
                    "label": 0
                },
                {
                    "sent": "So really easy to sample and join.",
                    "label": 0
                },
                {
                    "sent": "And that comes down to the fact that P of X, where X is older, all the neurons just backwards into these little packets, which are probably the child could occur.",
                    "label": 0
                },
                {
                    "sent": "That's why it's so easy.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so this seems correct.",
                    "label": 0
                },
                {
                    "sent": "Here we got this user says the generative model.",
                    "label": 0
                },
                {
                    "sent": "Beautiful pictures, deep belief Nets that capture all kinds of interesting structure.",
                    "label": 0
                },
                {
                    "sent": "We just have to do the learning path.",
                    "label": 0
                },
                {
                    "sent": "And at this point I want to step back actually from even the direct belief net graphical model and just talk about Super General view of learning in graphical models.",
                    "label": 1
                },
                {
                    "sent": "Just because I think, OK, I hesitated almost because it's got some some lines of math and less math.",
                    "label": 0
                },
                {
                    "sent": "It's usually good thing.",
                    "label": 0
                },
                {
                    "sent": "In the tutorial.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, it's really good to have it in.",
                    "label": 0
                },
                {
                    "sent": "See it once.",
                    "label": 0
                },
                {
                    "sent": "I think some of it, everyone should know.",
                    "label": 0
                },
                {
                    "sent": "So it's almost slides and you can take it.",
                    "label": 0
                },
                {
                    "sent": "Take it away with you.",
                    "label": 0
                },
                {
                    "sent": "I won't necessarily go through every line.",
                    "label": 0
                },
                {
                    "sent": "Torture some here, but I want to point out so you can see the channel argument.",
                    "label": 0
                },
                {
                    "sent": "'cause I think it connects a whole bunch of things first.",
                    "label": 0
                },
                {
                    "sent": "So sorry I don't think we're going to have to CFD.",
                    "label": 1
                },
                {
                    "sent": "I have some visible variables V and some hidden ones action, so he was there is going to be the bottom layer matches everything else above it.",
                    "label": 0
                },
                {
                    "sent": "An arrow stochastic binary variables.",
                    "label": 1
                },
                {
                    "sent": "And as a joint distribution of XX is just going to refer to be an actual together, how long?",
                    "label": 0
                },
                {
                    "sent": "So there's a joint information P of X.",
                    "label": 0
                },
                {
                    "sent": "Given the West, the parameters of the belief net.",
                    "label": 0
                },
                {
                    "sent": "But I'm going to drop off the given W from most of what follows, just 'cause it's in everything 'cause everything is given away.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, so first thing to do is just.",
                    "label": 0
                },
                {
                    "sent": "Be able to talk about unnormalized probabilities, so is on left there, probably in H, probably X something.",
                    "label": 0
                },
                {
                    "sent": "Is the distribution over?",
                    "label": 0
                },
                {
                    "sent": "Parents across the whole belief net.",
                    "label": 0
                },
                {
                    "sent": "And it's helpful sometimes to be able to talk about and analyze probability, which means just make up another number which is positive and I'm going to call that P star.",
                    "label": 0
                },
                {
                    "sent": "Enclosed please gonna be side by side where I defined said to be the sum of the startup all configurations.",
                    "label": 1
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "I do the sisters hand.",
                    "label": 0
                },
                {
                    "sent": "You'll see why.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is just some of his daughter overall configurations of the network, of course is exponentially.",
                    "label": 0
                },
                {
                    "sent": "Many family hope never to have to calculate this summer.",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                },
                {
                    "sent": "In some cases in the directed belief and directed graphical models otherwise known as weakness.",
                    "label": 1
                },
                {
                    "sent": "This sound is automatically what?",
                    "label": 0
                },
                {
                    "sent": "So it's another great thing about belief Nets and is that they will dramatically normalize you.",
                    "label": 0
                },
                {
                    "sent": "Don't see stars people, but we can think of we will later, but other graphical models under rated ones.",
                    "label": 0
                },
                {
                    "sent": "We have peace tires, not necessarily one.",
                    "label": 0
                },
                {
                    "sent": "In fact, it's a real pain to try to attempt to make it work.",
                    "label": 0
                },
                {
                    "sent": "Much easier just to talk about peace though, and let them take care of yourself.",
                    "label": 0
                },
                {
                    "sent": "So that's the account I flagged here, so this is.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Longing to hear is going to cover both cases.",
                    "label": 0
                },
                {
                    "sent": "Oh yeah, we met problem.",
                    "label": 0
                },
                {
                    "sent": "It's all happening and the product code.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "How is just to recap what I said before actually that.",
                    "label": 0
                },
                {
                    "sent": "In a in a belief there.",
                    "label": 0
                },
                {
                    "sent": "If you want to take the gradient of log of the stuff we were frequently going to be very interested in this log P style.",
                    "label": 1
                },
                {
                    "sent": "The underlying problems with the log of it.",
                    "label": 0
                },
                {
                    "sent": "We want to take the gradient effect with respect to the weights.",
                    "label": 0
                },
                {
                    "sent": "Just going to show up everywhere.",
                    "label": 0
                },
                {
                    "sent": "So what is that?",
                    "label": 0
                },
                {
                    "sent": "It looks like something kind of fierce, but if you want to keep in mind for belief net it is just this Delta rule.",
                    "label": 1
                },
                {
                    "sent": "The same rules before the eggs lines being times table.",
                    "label": 0
                },
                {
                    "sent": "Right WR Gabe on ways to break from J and divine.",
                    "label": 0
                },
                {
                    "sent": "OK so far.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "See if not.",
                    "label": 0
                },
                {
                    "sent": "Alright, so this is about I want to show you this.",
                    "label": 0
                },
                {
                    "sent": "What we need to do is we want to calculate the the log likelihood.",
                    "label": 0
                },
                {
                    "sent": "In fact, we want to go after its gradient.",
                    "label": 0
                },
                {
                    "sent": "So here's the log.",
                    "label": 0
                },
                {
                    "sent": "Likelihood is low because the data set that's a sum over V in the data set.",
                    "label": 0
                },
                {
                    "sent": "A pig now, but they stab their line and then practice log into a different smoky style, minus log said that's all straightforward Smith.",
                    "label": 0
                },
                {
                    "sent": "And then of course, the summer over logs here is just log said.",
                    "label": 0
                },
                {
                    "sent": "So we got two best.",
                    "label": 0
                },
                {
                    "sent": "The log likelihood got these two beds and this is going to be a big there's a bit the first part.",
                    "label": 0
                },
                {
                    "sent": "Which is.",
                    "label": 0
                },
                {
                    "sent": "Something to do with the data set.",
                    "label": 0
                },
                {
                    "sent": "It's got the unit right, V in in Big, D for David.",
                    "label": 0
                },
                {
                    "sent": "So structured data 1st and then there's a negative 2 minus log was there when Logan said is just this normalizing constant.",
                    "label": 0
                },
                {
                    "sent": "Which, by the way is 1 and believe myth.",
                    "label": 0
                },
                {
                    "sent": "Fine, now I want to take it gradient.",
                    "label": 0
                },
                {
                    "sent": "And there's a little trick to taking this gradient which is just pending.",
                    "label": 0
                },
                {
                    "sent": "Keep in mind, it's just that the grain of the law of P. Is one of the highest rating people.",
                    "label": 0
                },
                {
                    "sent": "How long for crates is this helpful to keep that in mind, and his converse going around one or two down spelled it out?",
                    "label": 0
                },
                {
                    "sent": "District um?",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In order to do this grading.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So the whole talks now can be lines in math like this.",
                    "label": 0
                },
                {
                    "sent": "Which one is right?",
                    "label": 0
                },
                {
                    "sent": "Play the T without the stars in the life one piece tires the unnormalized one.",
                    "label": 0
                },
                {
                    "sent": "Ha ha ha.",
                    "label": 0
                },
                {
                    "sent": "OK, so what's the grading of Longpi style?",
                    "label": 0
                },
                {
                    "sent": "That's the thing I I have to notice in order to make things.",
                    "label": 0
                },
                {
                    "sent": "The pens are like more likely.",
                    "label": 0
                },
                {
                    "sent": "OK. Well, let's see.",
                    "label": 0
                },
                {
                    "sent": "We used to trigger first line, then use the same rules second line.",
                    "label": 0
                },
                {
                    "sent": "Then you reorder stop third line.",
                    "label": 0
                },
                {
                    "sent": "And then I use the trick in the opposite direction, both mine and then I use the product rule in the last month.",
                    "label": 0
                },
                {
                    "sent": "So you could just check those out for yourself later.",
                    "label": 0
                },
                {
                    "sent": "I'm happy with that.",
                    "label": 0
                },
                {
                    "sent": "But I think it's gotta mastery about right.",
                    "label": 0
                },
                {
                    "sent": "You use check one way and then use the sum rule least check the other way and use the product rule.",
                    "label": 1
                },
                {
                    "sent": "Done everything.",
                    "label": 0
                },
                {
                    "sent": "Once.",
                    "label": 0
                },
                {
                    "sent": "And the bottom line is set up.",
                    "label": 0
                },
                {
                    "sent": "Regretting of this law is that.",
                    "label": 0
                },
                {
                    "sent": "Yeah, most probably even given visited some particular visible pattern final, so it is not Lisa this is.",
                    "label": 0
                },
                {
                    "sent": "That's right, yes, for a given visible pen, the grading of Lucky Star involves this thing here.",
                    "label": 0
                },
                {
                    "sent": "Just here on average over the posterior.",
                    "label": 0
                },
                {
                    "sent": "Extra thing, it's the bit on the right is is our friend, the Delta rule great.",
                    "label": 0
                },
                {
                    "sent": "This is why it's important very lucky star of X where X is our configuration the whole network.",
                    "label": 0
                },
                {
                    "sent": "And what we're doing?",
                    "label": 0
                },
                {
                    "sent": "We're sort of doing the Delta rule, but over a distribution, which is the posterior earlier page given B.",
                    "label": 0
                },
                {
                    "sent": "So that's the first first term.",
                    "label": 1
                },
                {
                    "sent": "Why they did it one I'm doing the 1st.",
                    "label": 0
                },
                {
                    "sent": "All I was doing was.",
                    "label": 0
                },
                {
                    "sent": "Here's the overall low blocks with Anna has some at a low key style, so I'm going to take a greater pressure gradient there now.",
                    "label": 0
                },
                {
                    "sent": "Going to the second power taking agreement models here.",
                    "label": 0
                },
                {
                    "sent": "Negative time.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Don't want to pass.",
                    "label": 0
                },
                {
                    "sent": "Anime apart and I won't go through a line by line, but when you do that you get something very similar.",
                    "label": 0
                },
                {
                    "sent": "In game, reduce that rank in both directions.",
                    "label": 0
                },
                {
                    "sent": "And we probably used assembling product for as well.",
                    "label": 0
                },
                {
                    "sent": "It's an analogous case, but it comes out slightly differently.",
                    "label": 0
                },
                {
                    "sent": "So in this case, now we have the same thing on the right great involved.",
                    "label": 0
                },
                {
                    "sent": "He's got out, but the average is different.",
                    "label": 0
                },
                {
                    "sent": "This time you take an average over the joint distribution.",
                    "label": 0
                },
                {
                    "sent": "And not an average of the data set.",
                    "label": 0
                },
                {
                    "sent": "Now I never posterior just an average over the joint.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so this.",
                    "label": 0
                },
                {
                    "sent": "Please put that together and simplify it.",
                    "label": 0
                },
                {
                    "sent": "Time to do that.",
                    "label": 0
                },
                {
                    "sent": "So this is this is the big story.",
                    "label": 0
                },
                {
                    "sent": "It's always.",
                    "label": 0
                },
                {
                    "sent": "There's always two terms.",
                    "label": 0
                },
                {
                    "sent": "We didn't take the gradient of the log likelihood, and it turns out to be these two terms.",
                    "label": 0
                },
                {
                    "sent": "And there both involved the gradient of Longstaff.",
                    "label": 0
                },
                {
                    "sent": "Which is why I focused on my family.",
                    "label": 0
                },
                {
                    "sent": "Invite involved great the same thing.",
                    "label": 0
                },
                {
                    "sent": "They're just different averages over.",
                    "label": 0
                },
                {
                    "sent": "In the first average is a positive part and that involves the Davis here.",
                    "label": 0
                },
                {
                    "sent": "So we go through the data and then we go through.",
                    "label": 0
                },
                {
                    "sent": "Well, we have to average over the posterior pH given V for each element of the data set.",
                    "label": 0
                },
                {
                    "sent": "Tony and in the six times negative.",
                    "label": 0
                },
                {
                    "sent": "And it's an average of the joint distribution.",
                    "label": 0
                },
                {
                    "sent": "Nothing to do with the data set.",
                    "label": 0
                },
                {
                    "sent": "Just join.",
                    "label": 0
                },
                {
                    "sent": "All configurations of their belief there is heaps of them.",
                    "label": 0
                },
                {
                    "sent": "Let's meet at the same thing is being averaged right in that thing.",
                    "label": 0
                },
                {
                    "sent": "In the case of belief, net is deductible.",
                    "label": 0
                },
                {
                    "sent": "OK, some people like you brought about this even shorter.",
                    "label": 0
                },
                {
                    "sent": "This is just another way of saying the same thing, so don't freak out.",
                    "label": 0
                },
                {
                    "sent": "And that the angle brackets.",
                    "label": 0
                },
                {
                    "sent": "The first term is positive.",
                    "label": 0
                },
                {
                    "sent": "It involves an average over data set and posterior, and the second term is just X chosen from the joint events.",
                    "label": 0
                },
                {
                    "sent": "But the thing inside the angle brackets is the same.",
                    "label": 0
                },
                {
                    "sent": "OK, so one way to think of this as given names is you could call us people can call us declared awake phase.",
                    "label": 0
                },
                {
                    "sent": "It's.",
                    "label": 0
                },
                {
                    "sent": "It's the part of learning that if he did, learning by doing the lead, can terminate the right handling.",
                    "label": 0
                },
                {
                    "sent": "There's a plan of learning this to do with the data set, keeping eyes open, looking at the world and taking samples from the posterior here page given V. Actually crucial.",
                    "label": 0
                },
                {
                    "sent": "And making those all market.",
                    "label": 0
                },
                {
                    "sent": "Phone number for getting off at H. 8 binary an extra farmers also gives, so they're vectors applying for their table.",
                    "label": 0
                },
                {
                    "sent": "There be some overage then you have to come over to the something many things.",
                    "label": 0
                },
                {
                    "sent": "Yes, that's right.",
                    "label": 0
                },
                {
                    "sent": "Exactly right.",
                    "label": 0
                },
                {
                    "sent": "So these these averages are over configuration, so the left hand one we get a V from the data set.",
                    "label": 0
                },
                {
                    "sent": "That's great, but then we're supposed to.",
                    "label": 0
                },
                {
                    "sent": "This says what you have to do is you have to average over the configurations of hidden units.",
                    "label": 0
                },
                {
                    "sent": "And if there are any hidden units, then you got to the end configurations horrible.",
                    "label": 0
                },
                {
                    "sent": "Anyone living so grateful.",
                    "label": 0
                },
                {
                    "sent": "This is worth thinking times worse negative line.",
                    "label": 0
                },
                {
                    "sent": "It's over everything, including the physical unit.",
                    "label": 0
                },
                {
                    "sent": "So it's even more.",
                    "label": 0
                },
                {
                    "sent": "OK, but the second term is negative so it's you can think of it as the first term.",
                    "label": 0
                },
                {
                    "sent": "Is that waiting will make it more likely the data set and these hypotheses chosen from pH given the hidden lives in new configurations.",
                    "label": 0
                },
                {
                    "sent": "And the second term is downlighting, making less likely random fantasies.",
                    "label": 0
                },
                {
                    "sent": "If you could run shopping network that we make the dreams by the way you're treating is making less likely.",
                    "label": 0
                },
                {
                    "sent": "And this is all I've done is just used the channel on the log likelihood, but it's kind of neat that breaks down with these two bits.",
                    "label": 0
                },
                {
                    "sent": "Alright, OK.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For example, in that example.",
                    "label": 0
                },
                {
                    "sent": "Just to come back to it is the belief net where this gradient thing is the Delta rule great and the second term is zero.",
                    "label": 1
                },
                {
                    "sent": "That's because the second term zed, is Zettel, actually guaranteed.",
                    "label": 0
                },
                {
                    "sent": "We wanna believe mirror automagically normalized.",
                    "label": 0
                },
                {
                    "sent": "Instead of writing them frameworks nothing.",
                    "label": 0
                },
                {
                    "sent": "So the 2nd just completely goes away.",
                    "label": 0
                },
                {
                    "sent": "There is not asleep phase involved in learning at belief net.",
                    "label": 0
                },
                {
                    "sent": "Sigmoid belief, net.",
                    "label": 0
                },
                {
                    "sent": "You just do the wake fails.",
                    "label": 0
                },
                {
                    "sent": "Great, so this may have made you think of something called the email and if you know what that was, but I think this is actually a level net so not sure.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So if you might remember what is Allie and goes in yesterday's Wichita, actually.",
                    "label": 0
                },
                {
                    "sent": "OK, so the amount goes up.",
                    "label": 1
                },
                {
                    "sent": "This is a two step process.",
                    "label": 0
                },
                {
                    "sent": "The step we go and get some samples from the posterior.",
                    "label": 0
                },
                {
                    "sent": "We got some data vector and then we go and get samples from the possible.",
                    "label": 1
                },
                {
                    "sent": "This is a sample view of the email.",
                    "label": 0
                },
                {
                    "sent": "We get samples from the posterior via vacuum V. And then the instead you might you apply the learning all the Max.",
                    "label": 1
                },
                {
                    "sent": "Each size configuration for life.",
                    "label": 0
                },
                {
                    "sent": "And that's what's happening here.",
                    "label": 0
                },
                {
                    "sent": "So this all seems hunky Dory.",
                    "label": 0
                },
                {
                    "sent": "All we have to do is get these samples from the posterior and apply the buildable.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "His cash.",
                    "label": 0
                },
                {
                    "sent": "It's all going swimmingly well.",
                    "label": 0
                },
                {
                    "sent": "We settle this catch.",
                    "label": 0
                },
                {
                    "sent": "In a belief net signal development.",
                    "label": 0
                },
                {
                    "sent": "It is easy to draw samples from the joint distribution from the product.",
                    "label": 0
                },
                {
                    "sent": "Time, probably agent be could just make samples.",
                    "label": 0
                },
                {
                    "sent": "I can make fantasies it's really easy.",
                    "label": 0
                },
                {
                    "sent": "Just start talking.",
                    "label": 0
                },
                {
                    "sent": "Look down OK.",
                    "label": 0
                },
                {
                    "sent": "But now we don't need those.",
                    "label": 0
                },
                {
                    "sent": "We need samples from the posterior.",
                    "label": 1
                },
                {
                    "sent": "We need just think of the pattern on the bottom.",
                    "label": 0
                },
                {
                    "sent": "And they make samples from.",
                    "label": 0
                },
                {
                    "sent": "He likes giving him.",
                    "label": 0
                },
                {
                    "sent": "And unfortunately, that's not so easy.",
                    "label": 0
                },
                {
                    "sent": "How we can do it?",
                    "label": 0
                },
                {
                    "sent": "One way to do it would be to.",
                    "label": 0
                },
                {
                    "sent": "This is a bad winter.",
                    "label": 0
                },
                {
                    "sent": "Distance is just a sample from the prior.",
                    "label": 0
                },
                {
                    "sent": "Generate a hollow sound which is easy.",
                    "label": 0
                },
                {
                    "sent": "Making sounds from prime and throw out the ones that don't produce.",
                    "label": 0
                },
                {
                    "sent": "Visible pens in the data set and once you got left in samples from.",
                    "label": 0
                },
                {
                    "sent": "Device given video.",
                    "label": 0
                },
                {
                    "sent": "So that they will be silenced.",
                    "label": 0
                },
                {
                    "sent": "From the right distribution, but of course, that's terribly terribly different, like throwing like everything.",
                    "label": 0
                },
                {
                    "sent": "And there is nobody.",
                    "label": 0
                },
                {
                    "sent": "We got a bit smarter and the Snyders is attending Gibbs sampling.",
                    "label": 0
                },
                {
                    "sent": "So quit your hands, get familiar with Gibbs sound happy.",
                    "label": 0
                },
                {
                    "sent": ",",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, so just to recap or look at Gibbs sampling and this is a figure taken from their replies book and I recommend that the understanding give something from the way have a look at that.",
                    "label": 0
                },
                {
                    "sent": "This is this is this figure this schematic.",
                    "label": 0
                },
                {
                    "sent": "Perhaps this is a Gibbs sampling and continuous space.",
                    "label": 1
                },
                {
                    "sent": "We're going to be doing give sounding in this space of binary units, but the idea is the same, so Gibbs sampling.",
                    "label": 0
                },
                {
                    "sent": "How you doing?",
                    "label": 0
                },
                {
                    "sent": "You gotta multi dimensional distribution.",
                    "label": 0
                },
                {
                    "sent": "X how you do it as you choose a dimension at random, let's choose life at random.",
                    "label": 0
                },
                {
                    "sent": "So for example, they were going to go along with the X one dimension in this example here.",
                    "label": 0
                },
                {
                    "sent": "Hey Dora sample.",
                    "label": 0
                },
                {
                    "sent": "I'm assuming start up at some particular eggs.",
                    "label": 0
                },
                {
                    "sent": "Now I'm sure it's not new sample for XI from the conditional distribution.",
                    "label": 0
                },
                {
                    "sent": "As I give it only other it's values.",
                    "label": 0
                },
                {
                    "sent": "You could do that.",
                    "label": 0
                },
                {
                    "sent": "And then you iterate.",
                    "label": 0
                },
                {
                    "sent": "Keep doing this.",
                    "label": 0
                },
                {
                    "sent": "Choosing new dimension, another dimension and then choosing from the conditional distribution game.",
                    "label": 0
                },
                {
                    "sent": "You keeping doing this over and over again, this is called Gibbs sampling.",
                    "label": 0
                },
                {
                    "sent": "And the name players that this is guaranteed get you samples.",
                    "label": 0
                },
                {
                    "sent": "If you wait long enough it will give you samples and its equilibrium distribution, which are samples from P of X.",
                    "label": 1
                },
                {
                    "sent": "It's a really simple way to sound.",
                    "label": 0
                },
                {
                    "sent": "Phoenix do you have to run it with Michael Chaney after and we have to do this along time because the initial one obviously is corrupted by the fact that you chose some initial X which was arbitrary.",
                    "label": 0
                },
                {
                    "sent": "Obviously the first sample wouldn't be.",
                    "label": 0
                },
                {
                    "sent": "And by Saturday events.",
                    "label": 0
                },
                {
                    "sent": "You gotta wait long and then you take a sound coming to little bit longer.",
                    "label": 0
                },
                {
                    "sent": "Get another sound so it's a tedious business.",
                    "label": 0
                },
                {
                    "sent": "But this is a way to generate samples from vehicles.",
                    "label": 0
                },
                {
                    "sent": "So we.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Do the same thing as working at sigmoid belief in his good sounding a sigmoidal evening, and I like this one 'cause it is just the most basic seem overly imagine it's got 2 hidden units.",
                    "label": 0
                },
                {
                    "sent": "And one visible unit.",
                    "label": 0
                },
                {
                    "sent": "So it's got a couple of lights and I live by myself, invisible unit and the hidden units have a little biased late coming into them.",
                    "label": 0
                },
                {
                    "sent": "OK, 2 hidden causes if you like.",
                    "label": 0
                },
                {
                    "sent": "Bigger than problem, no I mean.",
                    "label": 0
                },
                {
                    "sent": "I'm.",
                    "label": 0
                },
                {
                    "sent": "In this management, visible now is observed.",
                    "label": 0
                },
                {
                    "sent": "That's the situation I want.",
                    "label": 0
                },
                {
                    "sent": "I want to draw samples from here that's given V, so these been observed.",
                    "label": 0
                },
                {
                    "sent": "You know, I looked at it and it's one.",
                    "label": 0
                },
                {
                    "sent": "Analysts think about give starving for H1H2.",
                    "label": 0
                },
                {
                    "sent": "How's it going?",
                    "label": 0
                },
                {
                    "sent": "Well, if you if you write down, we can write down the joint distribution.",
                    "label": 0
                },
                {
                    "sent": "You HMV is the amount that's a product of factors.",
                    "label": 0
                },
                {
                    "sent": "But Even so that means I can use the rules of probability to figure out what is P of H1 given V1, and given the value of H2 initial scale.",
                    "label": 0
                },
                {
                    "sent": "I can do it, but I get that equation on the rise is horrible.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yes, but just two hidden units.",
                    "label": 0
                },
                {
                    "sent": "It gets more Yahoo for more.",
                    "label": 0
                },
                {
                    "sent": "So this jacket is a big part of story, really running Gibbs sampling and sigmoid belief man is apparent.",
                    "label": 1
                },
                {
                    "sent": "But you can do it.",
                    "label": 0
                },
                {
                    "sent": "Yes, you can calculate it.",
                    "label": 0
                },
                {
                    "sent": "It's it's slow.",
                    "label": 0
                },
                {
                    "sent": "It's only this demanding and focusing on is also slow to get samples from P. Eventually image two, I have to run this Markov chain.",
                    "label": 0
                },
                {
                    "sent": "And every time I upgrade the status of a particular hidden unit is like choosing I. I choose I an operator 5G of H. I've given everything else in the network.",
                    "label": 0
                },
                {
                    "sent": "Then both quantity calculation.",
                    "label": 0
                },
                {
                    "sent": "So each step involves build calculation and there are lots of steps because we had to run the giant before I want to reach equilibrium.",
                    "label": 0
                },
                {
                    "sent": "So it's loading now.",
                    "label": 0
                },
                {
                    "sent": "Now I have to do this well.",
                    "label": 0
                },
                {
                    "sent": "One way to think of this as I want to connect to is this idea of explaining why and we explain it away.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In the context of belief, mix and the classic example, lyberger is like allowing problem Brad.",
                    "label": 0
                },
                {
                    "sent": "You have much better example.",
                    "label": 0
                },
                {
                    "sent": "You got away with this crap.",
                    "label": 0
                },
                {
                    "sent": "We got away from the bigger line problem.",
                    "label": 0
                },
                {
                    "sent": "There's a trial.",
                    "label": 0
                },
                {
                    "sent": "This is a classic example, so business price bicycles, Lamb, once the burgers and earthquakes are hopefully uncorrelated.",
                    "label": 0
                },
                {
                    "sent": "But once the alarm is going off.",
                    "label": 0
                },
                {
                    "sent": "Figgeurs Netflix.",
                    "label": 0
                },
                {
                    "sent": "Micro SD card.",
                    "label": 0
                },
                {
                    "sent": "So my belief that I've been burgled asking the llamas corner goes down when I hear this be an earthquake.",
                    "label": 0
                },
                {
                    "sent": "So bigger meth pipes become linked.",
                    "label": 0
                },
                {
                    "sent": "And probabilities.",
                    "label": 0
                },
                {
                    "sent": "And that's the whole problem.",
                    "label": 0
                },
                {
                    "sent": "So they were not playing are independent in the prior, but they are dependent in the posterior.",
                    "label": 1
                },
                {
                    "sent": "That's the big story.",
                    "label": 0
                },
                {
                    "sent": "Dependent on the posterior.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately what I need to sample from the exterior product.",
                    "label": 0
                },
                {
                    "sent": "That's my sound in the posterior slow.",
                    "label": 0
                },
                {
                    "sent": "Because these things are dependent now.",
                    "label": 0
                },
                {
                    "sent": "I can't just not change be it changes and probably be.",
                    "label": 0
                },
                {
                    "sent": "Umm, now have a big belief net with lots of neurons for 100 hundred 30 minutes by itself there and you know 20 alarms at the bottom as well.",
                    "label": 0
                },
                {
                    "sent": "A decent sized network.",
                    "label": 0
                },
                {
                    "sent": "Everything is interfering with everything else and I had to run this long.",
                    "label": 0
                },
                {
                    "sent": "Michael Chang.",
                    "label": 0
                },
                {
                    "sent": "OK, so the fact that Gibbs sampling is slow and ugly is directly related to this idea of explaining way in belief.",
                    "label": 0
                },
                {
                    "sent": "Nets are the same, the root causes and sound.",
                    "label": 0
                },
                {
                    "sent": "And it's to do with being independent prior should be independent cry.",
                    "label": 0
                },
                {
                    "sent": "You have to be dependent on the posterior, so it's going to happen.",
                    "label": 0
                },
                {
                    "sent": "Something went wrong.",
                    "label": 0
                },
                {
                    "sent": "Just a consequence of being clear and being independent in the prior living independent causes tsunami.",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                },
                {
                    "sent": "So this is really inconvenient for us.",
                    "label": 0
                },
                {
                    "sent": "There is no quick way to draw a sample from here.",
                    "label": 1
                },
                {
                    "sent": "Probably the hidden units.",
                    "label": 0
                },
                {
                    "sent": "Given the visible gas, but that's what we need to do in it.",
                    "label": 0
                },
                {
                    "sent": "OK, we make good progress here so.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Questions you should throw them in at this point.",
                    "label": 0
                },
                {
                    "sent": "Here's my summary slide.",
                    "label": 0
                },
                {
                    "sent": "Sigmoid belief Nets are.",
                    "label": 0
                },
                {
                    "sent": "Well, right now very appealing as a generative model.",
                    "label": 1
                },
                {
                    "sent": "Buck there is the reason to sample from as a generative model, but I really have to learn and the reason for learning is tired to explain away.",
                    "label": 1
                },
                {
                    "sent": "Incidentally, the fact that.",
                    "label": 0
                },
                {
                    "sent": "Did this.",
                    "label": 1
                },
                {
                    "sent": "That's how the sample compared to given V also makes them difficult to use for this class of recognition.",
                    "label": 0
                },
                {
                    "sent": "Actually applying invisible pattern and figuring out what is the neural net of the signal admit.",
                    "label": 0
                },
                {
                    "sent": "Think of this visible path.",
                    "label": 1
                },
                {
                    "sent": "What is its internal representation of it?",
                    "label": 0
                },
                {
                    "sent": "Well, we have to draw samples from P eventually to do that, and that's how it is slow.",
                    "label": 0
                },
                {
                    "sent": "So learning is slow, and inference that recognition is slow.",
                    "label": 0
                },
                {
                    "sent": "There's also this issue.",
                    "label": 0
                },
                {
                    "sent": "Man big business.",
                    "label": 0
                },
                {
                    "sent": "So if I just made a large independent that first problem is also that if I made a large network.",
                    "label": 1
                },
                {
                    "sent": "Sigmoid belief then and try to try it out.",
                    "label": 0
                },
                {
                    "sent": "I would have this similar problem to the background networks before, at which sort of chicken and egg problem that how the deep layers of this network in the learning anything.",
                    "label": 0
                },
                {
                    "sent": "Then the output lab at the bottom layer wax wants to learn to make the the visible pantelakis great, but always got to do to work off as the input Commission layer above, and that layer doesn't know anything yet.",
                    "label": 0
                },
                {
                    "sent": "And likewise it's very hard to imagine that layer about learning anything, because the lab below is just giving it garbage.",
                    "label": 0
                },
                {
                    "sent": "It is a very much chicken egg problem.",
                    "label": 0
                },
                {
                    "sent": "Again, you get in a deep belief net made in this way you cannot train the players even aside from all the slowness that may be used.",
                    "label": 0
                },
                {
                    "sent": "Yeah so.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I think I have side difficulty with standing in different locations of any of us.",
                    "label": 0
                },
                {
                    "sent": "The eastep take samples from the Gibbs sampler samples for the hidden variables, so to update that available, yes.",
                    "label": 0
                },
                {
                    "sent": "An Easter if you mention that we apply their talents.",
                    "label": 0
                },
                {
                    "sent": "Sorry it at least at least now I think of the East.",
                    "label": 0
                },
                {
                    "sent": "It is running a little map of chain doing Gibbs sampling from HTML B and then with the samples that you get by doing that.",
                    "label": 1
                },
                {
                    "sent": "You apply the Delta rule, and that's analogous to the instinct in the MLB.",
                    "label": 0
                },
                {
                    "sent": "The values for the hidden variables.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "Yes, and then step.",
                    "label": 0
                },
                {
                    "sent": "We need to apply for dental, which does not include capital variables.",
                    "label": 0
                },
                {
                    "sent": "No, that's OK.",
                    "label": 0
                },
                {
                    "sent": "So the Delta rule I expressed in terms of just X variables because you could apply it to anything could be visible in anything.",
                    "label": 0
                },
                {
                    "sent": "Lyrics for it to be adventure.",
                    "label": 0
                },
                {
                    "sent": "Japanese index covers HV yes.",
                    "label": 0
                },
                {
                    "sent": "My ex covers by to make any other training outlook that I PM.",
                    "label": 0
                },
                {
                    "sent": "After doing this no.",
                    "label": 0
                },
                {
                    "sent": "Well, I guess there are other ways to do it.",
                    "label": 0
                },
                {
                    "sent": "This is all sorts of ways to optimize things, but this is the way that follow the gradient.",
                    "label": 0
                },
                {
                    "sent": "Incredible online.",
                    "label": 0
                },
                {
                    "sent": "Soon.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I'm going to assume that the structure is just given.",
                    "label": 0
                },
                {
                    "sent": "So yes for belief net, structural learning is of course a huge deal.",
                    "label": 0
                },
                {
                    "sent": "But we're actually aiming to match large sigmoid belief Nets with lots of hidden layers and lots of nodes in those layers, and essentially we're hoping struck with the structural.",
                    "label": 0
                },
                {
                    "sent": "Problems are gonna go away.",
                    "label": 0
                },
                {
                    "sent": "Picnics anyway.",
                    "label": 0
                },
                {
                    "sent": "So no worries.",
                    "label": 0
                },
                {
                    "sent": "Sorry someone I gotta disappear.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so by learning the way some about music business apps.",
                    "label": 0
                },
                {
                    "sent": "I'm not assuming that's gonna happen.",
                    "label": 0
                },
                {
                    "sent": "Is sending me a lot of parameters in these in these animals?",
                    "label": 0
                },
                {
                    "sent": "Yes, we start approval is regularization.",
                    "label": 0
                },
                {
                    "sent": "One could have an equivalent.",
                    "label": 0
                },
                {
                    "sent": "Yes, I haven't talked about that at all.",
                    "label": 0
                },
                {
                    "sent": "I simply be maximizing the log likelihood.",
                    "label": 0
                },
                {
                    "sent": "But of course, yes, you could introduce regularization Casavant be somewhere became.",
                    "label": 0
                },
                {
                    "sent": "Very good idea.",
                    "label": 0
                },
                {
                    "sent": "Stopping weights going able yes.",
                    "label": 0
                },
                {
                    "sent": "What's the difference between supervised, great net and the bathroom renovation next and back off?",
                    "label": 0
                },
                {
                    "sent": "OK, what's the difference between sigmoid belief then Anna back propagation there?",
                    "label": 0
                },
                {
                    "sent": "In the truck we take that we.",
                    "label": 0
                },
                {
                    "sent": "There's a bunch of differences.",
                    "label": 0
                },
                {
                    "sent": "In about not missed one typically.",
                    "label": 0
                },
                {
                    "sent": "Types the signal does not take samples from the signaling function.",
                    "label": 0
                },
                {
                    "sent": "As you propagate forward through the network.",
                    "label": 0
                },
                {
                    "sent": "Typically you just pass on the output of a sigmoid unit onto the next layer, but of course you could sample, so that's not a fundamental difference.",
                    "label": 0
                },
                {
                    "sent": "In that process you get the target value at the output.",
                    "label": 0
                },
                {
                    "sent": "You assist difference between that and what you wanted, and you calculate degrading.",
                    "label": 0
                },
                {
                    "sent": "Going backwards in this layer wise fashion.",
                    "label": 0
                },
                {
                    "sent": "Application action.",
                    "label": 0
                },
                {
                    "sent": "Here we don't have a target out, we just this is unsupervised learning so it's a generative model.",
                    "label": 0
                },
                {
                    "sent": "Yes, the structure is the same.",
                    "label": 0
                },
                {
                    "sent": "Yeah, they all there made exactly the same way we got these signaling neurons in the network that Speedball.",
                    "label": 0
                },
                {
                    "sent": "That's right.",
                    "label": 0
                },
                {
                    "sent": "But in this case, I guess you should think of the.",
                    "label": 0
                },
                {
                    "sent": "My visible units are like the output of a of a neural net backup, and if there's no improvement.",
                    "label": 0
                },
                {
                    "sent": "It's just a general model of some data that you got.",
                    "label": 0
                },
                {
                    "sent": "I know so that the vision problems differently.",
                    "label": 0
                },
                {
                    "sent": "The learning of a. Unsupervised matching.",
                    "label": 0
                },
                {
                    "sent": "Are they in networks where you have a certain assumption for the conditional?",
                    "label": 0
                },
                {
                    "sent": "When you have simple assumption for the conditional probabilities, yes, OK, so she's saying it would be fair to say that the sigmoid belief net is well.",
                    "label": 0
                },
                {
                    "sent": "It is a Bayesian network where we have a particular assumption for the.",
                    "label": 0
                },
                {
                    "sent": "For the factors absolutely.",
                    "label": 0
                },
                {
                    "sent": "The signal never is a Bayesian net is a belief.",
                    "label": 0
                },
                {
                    "sent": "Net is another is a directed graphical model, is probably a bunch of other names.",
                    "label": 0
                },
                {
                    "sent": "Is there a list and this is 1.",
                    "label": 0
                },
                {
                    "sent": "In particular, we have made the assumption about the the wife's or sorry the factors are going to be little signal.",
                    "label": 0
                },
                {
                    "sent": "The parameter little signal X.",
                    "label": 0
                },
                {
                    "sent": "What's the smallest case which you can prove that things learn fast?",
                    "label": 0
                },
                {
                    "sent": "Enjoy it or ask a lot.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure.",
                    "label": 0
                },
                {
                    "sent": "I mean yes, yes, the visible yes.",
                    "label": 0
                },
                {
                    "sent": "And payment and you can learn really fast.",
                    "label": 0
                },
                {
                    "sent": "20 years for using it.",
                    "label": 0
                },
                {
                    "sent": "It's coming up as the.",
                    "label": 0
                },
                {
                    "sent": "I just had question makes sense of what can you practically learn.",
                    "label": 0
                },
                {
                    "sent": "It depends on the Markov chain of Gibbs sampling and hidden units until well that chain mixes.",
                    "label": 0
                },
                {
                    "sent": "I don't know this one.",
                    "label": 0
                },
                {
                    "sent": "OK, yes I did ask questions.",
                    "label": 0
                },
                {
                    "sent": "So if you say that the big pieces of Asian networking psychosocial so do you have to have at the physical layer to always be the children which were not parents?",
                    "label": 0
                },
                {
                    "sent": "I have a question, do I always have to have the visible units as the as the child is the bottom layer?",
                    "label": 0
                },
                {
                    "sent": "How could I have been somewhere else?",
                    "label": 0
                },
                {
                    "sent": "I guess just like in any belief net, you could have them anywhere.",
                    "label": 0
                },
                {
                    "sent": "That's true, you could build knows that and visible units anyway.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure why you do that.",
                    "label": 0
                },
                {
                    "sent": "I'm trying to build a generative model of some of some data center.",
                    "label": 1
                },
                {
                    "sent": "Today is the general offensive, so I had a visible units at beginning, OK at the top layer, and then I make a whole of India.",
                    "label": 0
                },
                {
                    "sent": "Just a general model of 10 units that I had no data about.",
                    "label": 0
                },
                {
                    "sent": "Yeah, totally focused on that case with a visible unit bottom layer.",
                    "label": 0
                },
                {
                    "sent": "OK, how we doing?",
                    "label": 0
                },
                {
                    "sent": "It's over.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I'm gonna finish this line then.",
                    "label": 1
                },
                {
                    "sent": "I think we should go have coffee attendance at right hip against perfect timing.",
                    "label": 0
                },
                {
                    "sent": "OK so just to summarize sound from the posteriors.",
                    "label": 0
                },
                {
                    "sent": "Glad that makes these things had to use for recognition.",
                    "label": 1
                },
                {
                    "sent": "We have a chicken and egg problem in the deep layer.",
                    "label": 0
                },
                {
                    "sent": "What I wanted to do next is just ignore one.",
                    "label": 0
                },
                {
                    "sent": "I mean, let's say we can do that.",
                    "label": 0
                },
                {
                    "sent": "We build a super duper gives sample.",
                    "label": 0
                },
                {
                    "sent": "Here it is.",
                    "label": 0
                },
                {
                    "sent": "Here it runs around remotely.",
                    "label": 1
                },
                {
                    "sent": "Clappers and that problem goes away.",
                    "label": 0
                },
                {
                    "sent": "Imagine that went away.",
                    "label": 0
                },
                {
                    "sent": "Could we still do the second one?",
                    "label": 0
                },
                {
                    "sent": "I don't wanna answer that, I'm Naked.",
                    "label": 0
                },
                {
                    "sent": "Board president, that's that's what's going to happen after the breath and then are revealed.",
                    "label": 0
                },
                {
                    "sent": "Magic answer to all problems.",
                    "label": 0
                },
                {
                    "sent": "OK. We got 20 minutes.",
                    "label": 0
                }
            ]
        }
    }
}