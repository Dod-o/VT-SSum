{
    "id": "rdyo65xqrpa3n432xagmb64hi22ow5z7",
    "title": "Patterns in sets of points: an overview",
    "info": {
        "author": [
            "Tijl De Bie, Department of Engineering Mathematics, University of Bristol"
        ],
        "published": "Feb. 25, 2007",
        "recorded": "October 2005",
        "category": [
            "Top->Computer Science->Machine Learning->Pattern Recognition"
        ]
    },
    "url": "http://videolectures.net/aop05_bie_o/",
    "segmentation": [
        [
            "OK.",
            "Understandable.",
            "So first of all, I would like to thank all the organizers for giving me the chance to speak at this wonderful place.",
            "It's really beautiful.",
            "Very interesting, I think, so I will give a more general talk about optimization approaches in pattern analysis.",
            "And that's the first half of the talk, and to be able to do this, I will try to set the scene a bit and to give one potential working definition of what a pattern is.",
            "So it's only one of the possible ways to do it.",
            "And then the second half of this talk is about patterns in vector spaces, in particular in sets of data points.",
            "So this is the overview, the overview of the talk first.",
            "First part sorry first part will be about general pattern analysis, so the definitions, some definitions how to see pattern matching within this framework?",
            "How to see pattern discovery in this framework?"
        ],
        [
            "Then I will apply this framework a bit to patterns in discrete spaces, such as insets in strings, and I will only briefly mention patterns in graphs an hour later during the summer school, older speakers will go in great detail online.",
            "All these applications of pattern analysis or these instances of pattern analysis and then the main part of this talk is about patterns in vector spaces as Nola mentioned, which is a very well developed.",
            "Part of pattern analysis.",
            "I will not speak about statistical aspects, only about algorithmic aspects about optimization aspects.",
            "The next talk by Joshua Taylor will go more in detail about the statistical.",
            "And.",
            "Side of pattern analysis.",
            "So what is the pattern?",
            "You can have many ideas about this with two to show what I think is the definition of a pattern I will give."
        ],
        [
            "Few examples, so imagine we are given a set of points every black deltas data point in a 2 dimensional space.",
            "Then one pattern, one would immediately.",
            "Probably see is the fact that they are aligned more or less along a line like this.",
            "So if you have a vector direct arrow over there and you project all the data points on this factor, then the variance of these projections would be large.",
            "So maybe you want to do.",
            "It is then projected because we can assume that the other dimension is just noise and we want to get rid of it.",
            "So that's one example.",
            "Another example.",
            "What you see here is in Etruscan text.",
            "It comes from the liberal.",
            "In tears you might not be able to read it, but if you could read it, you would not understand it because it hasn't been deciphered, deciphered yet.",
            "Just only parts of it, and what I highlighted in this text is divert Ednam.",
            "So it consists of five letters and it turns out to be really frequent in all interesting text.",
            "And then they figured out the meaning of Adam and so.",
            "This word is fairly frequent, which is an interesting pattern we can exploit it by figuring out that.",
            "It corresponds to a stop word, namely and.",
            "Then 3rd example.",
            "Suppose we have two clouds of points.",
            "One is labeled negatively, so all these points are assigned to one class or the black points or assigned to another class.",
            "Then we can see that we can find 2 hyperplanes in 2 dimensional space, 2 lines, search that all the negative points lie on one side of these two lines positively labeled points lie on the other side, so there's no misclassification for these two lines in the last example, I think they already.",
            "Talk about this data.",
            "In this talk.",
            "It is the temperature data in the Lake Shasta area and it looks quite periodic so we could try to fit a periodic signal to this and try to find one that fits well with this data and maybe also this is a way to get rid of some noise.",
            "So what is it gonna pattern?",
            "I think we can define it in terms of a pattern function, so pattern function could be the variance over projection on a vector or the frequency of a certain given substring, and so in this pattern function it takes the data and it Maps the data to a real number.",
            "You can have several pattern functions of course, and the type of the kind.",
            "The way to define a pattern function depends on the data and so on.",
            "So depending on the data, for example, it risk in data, we can have several pattern functions."
        ],
        [
            "On pattern function for each of the substrings you can consider.",
            "And the pattern magnitude is is a value of the pattern function.",
            "So a real value or can be an integer #2 in some cases.",
            "And then we can specify pattern by equating stating that the pattern function Pi of X is equal to some number \u03c0 bar supplies than just a given given number.",
            "So this is basically the definition of the pattern I want to use, namely the equality of a pattern function which takes the data to real number to some given real number.",
            "So maybe just to illustrate what a pattern space exactly is.",
            "In this case, the pattern space."
        ],
        [
            "Is defined for or is parameterized every pattern in this pattern space is parameterized by weight factor, so this is for this weight factor.",
            "We just have one pattern function which is variance of all the projections on this data on this factor.",
            "In this case, the pattern space defines parameterized by all possible substrings.",
            "For each substring, we have a pattern function that counts how frequently this substring occurs in the data.",
            "In this case, the number of misclassifications for a given pair of planes.",
            "And in this case would be maybe the Misfits.",
            "Over periodic signal you're considering, so every periodic signal corresponds to a pattern function.",
            "So with this definition, how can we define pattern matching?",
            "It is simply nothing else in the evaluation or a computation of the value of the pattern function."
        ],
        [
            "For example, for the Etruscan text example, pattern function simply counts the frequency of the substring Atom.",
            "OK."
        ],
        [
            "So I'm pattern discovery.",
            "So want to define define pattern discovery.",
            "Within this framework we could say the pattern Discovery is just picking the best pattern function out of the pattern space.",
            "The best in terms of the value of this pattern function.",
            "For example, this better function that maximizes the pattern magnitude or that minimizes the better magnitude depending on if you want to.",
            "If you have the pattern function corresponds to some cost or to some profit.",
            "But this is not sufficient because for example in.",
            "In the case where we wanted to maximize the variance, if instead of this weight factor we take this one which is longer and we project all the data on it, then the variance of these projections will be larger than for the red arrow is still.",
            "Intuitively we prefer the red one over the blue one.",
            "In the text case, if you consider shorter string, which is meaningless, AN in this case we can see that it's actually more frequent than at namit doesn't.",
            "The difference is not that large, but it is slightly more frequent, but it doesn't have a meaning, and the reason is simply that the length of the suffering is too small.",
            "In this case, we don't just want any pair of hyper place, we prefer hyperplanes in Oras distance as possible from each other, because it's just too easy in many cases to finds separating pair of hyperplanes are very close to each other, and in this last case is preferable to find periodic signal that is smooth that is, does not follow all the tiny glitches in the periodic pattern.",
            "So pattern discovery is not."
        ],
        [
            "Just picking the pattern function from the pattern space that maximizes the pattern magnitude.",
            "Sometimes it can be, but in general we should do something more.",
            "So what you want to do is we want to add an additional restriction on how the pattern function can be chosen from the pattern space, namely, we define.",
            "A property which is defined by a functional pattern function, so it takes the pattern function to a real valued number.",
            "Anne.",
            "So we restrict the search in the pattern space by Additionally imposing a constraint on the pattern function, namely that dysfunctional, must be smaller or equal to a maximal value that we specify.",
            "So using this constraint we can actually restrict the search space, which is sometimes called regularization and.",
            "Another way to view this is to say that we restrict the capacity of our pattern Discovery search so it relates to the flexibility of this set of pattern functions that we are searching over.",
            "So with this additional constraints we can define pattern discovery as the maximization of the pattern magnitude, overall pattern functions subject to a constraint on this capacity.",
            "So saying that the capacity capacity function must be smaller than upper bounds.",
            "An alternative way to do which is a very high extent equivalent is.",
            "Saying that, we want to minimize the capacity functional, so in the end minimize the region over which we.",
            "We are searching subject subject to a lower bound constraint on the pattern magnitude, so these are two formulations you can use interchangeably.",
            "In some cases this one is more convenient, sometimes when it's more convenient.",
            "I also have to say at this point this is a maximization is minimization lower bound upper bounds depending on the context it can.",
            "It can be something else.",
            "So this can also be a minimization if the pattern magnitude if you want to be large then you want to maximize it.",
            "If you want it to be small, if it's a cost function, you want to minimize it.",
            "So this is just one example.",
            "So in fact the problem is conceptually solved with this optimization."
        ],
        [
            "Problem you just solve it, But the problem is that very often, even with this additional constraint on the capacity, the search phase is still exponentially large in a problem size.",
            "So this rules out an exhaustive search in all cases, so we need more clever algorithms, and in fact in many cases I exist.",
            "And while the search space is exponentially large, many pattern discovery algorithms actually only take a polynomial time in the problem size.",
            "So intention of remainder of this talk is to understand.",
            "As well as possible, what is it?",
            "Design principles are to achieve this exponential speedup?",
            "The pattern is coveri task.",
            "I will now first applying this to patterns in discrete spaces very briefly, just to give some ideas and.",
            "To.",
            "To make it easier for people who are more familiar with patterns in discrete spaces, such as insets, any strings to transfer these ideas to matters in continuous spaces, which will be the main part.",
            "So better than discrete spaces, I will first discuss briefly."
        ],
        [
            "Princess and mentioned a very well known algorithm.",
            "The Priory algorithm which is concept conceptually.",
            "Easy enough to explain.",
            "Without too much effort and still learns a lot about the principles and patterns in strings which use actually fairly similar IDs, and I will just mention patterns in graphs.",
            "So patterns in sets.",
            "Imagine we are gathering data from a shop or a shopkeeper is gay."
        ],
        [
            "Data and this shop has selling 6 items, chocolate, beer, apples, bread diapers and milk.",
            "And then.",
            "This shopkeeper is clever enough to maintain data from all these customers, so he's keeping transaction records.",
            "For example, saying that the first beer, breads and diapers in milliseconds, one beer, apples and diapers, and so on.",
            "So what is shopkeeper wants to do?",
            "It it is.",
            "He wants to find meaningful associations between these items.",
            "In other words, he wants to find frequent itemsets, so sets of these items, or very often bought together by different customers.",
            "The reason why he wants to do it, is because maybe he wants to lower the price and advertises lower price for one of the items.",
            "In such an item set and without saying increase the price of one of the other items in this item set.",
            "So he makes the same amount of money because people buy them together anyway.",
            "But he can advertise him and people come to him for this lower price.",
            "So he wants to find frequent item sets with.",
            "And one example is this one beer and diapers and there is a story about it that the reason that this would actually be true, that beer and diapers are associated, because very often young people have children and they buy diapers.",
            "But at the same time they want to have a beer in front of the television or whatever.",
            "OK, so.",
            "This would be an interesting idea, set also because it's compared to the side with store only.",
            "Six items is quite large because small items that doesn't mean anything.",
            "If you find a frequent itemset.",
            "Of size 1, just one item.",
            "It doesn't teach you anything.",
            "It might be a coincidence as well.",
            "So he wants to find frequent and large item sets.",
            "So explain in terms of pattern, function and capacity functionals."
        ],
        [
            "Free pattern function will be parameterized by an item set, so that's why the subscript item set an pattern function counts the frequency of this item set.",
            "And the capacity functional is the size of the item set.",
            "You know that by C of the pattern function, so.",
            "The pattern discovery problem would be."
        ],
        [
            "To maximize the size of the item set subject to lower bounds on the frequency of the United States.",
            "So maybe you want the items to occur at least four times and you want to maximize the size so it becomes to which was the case in the example.",
            "However, the problem now is that the number of items that is exponential in the items that size, so it's impossible to just enumerate all the different items and check whether this constraint is satisfied and then pick the largest one for which this is true.",
            "So efficient search strategies needs to need to be developed, and one example is your priority algorithm, which was really an important advance and.",
            "In this research, LogMeIn.",
            "So in turn for for the search strategy that is used in this case is called level by search."
        ],
        [
            "And you will immediately see why this is the case.",
            "So what I represented here is the pattern space for the case when there are four items ABC and D, only four, because for six is even much larger.",
            "It's already quite confusing now for four.",
            "So because because the size of the pattern space is exponential in the number of items.",
            "And then.",
            "The observation that is needed to make this algorithm more efficient.",
            "This pattern Discovery algorithm more efficient is that there is an interesting partial order between these items sets, namely, relation is a subset of.",
            "So we can see that B is a subset of a B subset of PC.",
            "So every arrow down represents a subset of.",
            "Now we want to find the largest frequent itemset, which means you want to go as slow as possible in this partial order, so.",
            "But it has to be frequent as well, so.",
            "OK, so we can use the second observation, which says that the pattern function.",
            "The frequency is monotonically decreasing on a partial order.",
            "So if we go down, down Arrow and then the frequency can only decrease.",
            "The reason why it isn't very intuitive if B occurs 5 * 5 times, say baseball five times, then a B together can only be bought at most five times.",
            "So it's a fact it's a very simple ID.",
            "So that means that one."
        ],
        [
            "We know that C does not satisfy the constraint on the pattern function, so it is not frequent enough.",
            "None of his descendants in this partial order can be frequent enough, so in fact.",
            "We can just ignore this entire part of the pattern space, just.",
            "Prune it away."
        ],
        [
            "And we only have to explore the remaining part.",
            "So that is the basic idea behind the a priori algorithm.",
            "There are many technical difficulties to really prune it efficiently, because this pruning stage is not as easy on itself.",
            "But this is the main ID.",
            "Now let's look at patterns in strings.",
            "The attrition text, again in a different format, so we are given along symbol sequence and we want to find out which words have a meaning.",
            "So interesting text with Adam.",
            "So we want to find frequent substrings because one that occurs only once and doesn't mean anything."
        ],
        [
            "But only if they were long at the same time, because a man was more frequent and at number doesn't mean a thing.",
            "So in this case the."
        ],
        [
            "Function is parameterized by substring at.",
            "Now for example, and it counts its frequency pattern function is equal to the frequency of substring.",
            "And the capacity functional is equal to the substrings link.",
            "'cause we want to.",
            "You will want to maximize the length, subject to constraint on the pattern function, so the resulting pattern discovery problem is given by this maximizing the length.",
            "So we have two constraints on the frequency.",
            "The longest frequent substring problem.",
            "We can use very similar principles as in your primary algorithm.",
            "Again, a level wise search.",
            "And we have to do this because the number of substrings of a certain length is exponential in this link.",
            "Again, so again, we can.",
            "We can find a partial order in."
        ],
        [
            "The pattern space, namely, for example, is a prefix of A is a prefix of a, A an of a B only drew very small part of the pattern space.",
            "Again, the length is increasing if you go down the partial order.",
            "So we want to go slow as possible, but on the other hand, the frequency is monotonically decreasing on the partial order.",
            "Since you want to impose a lower bound on the frequency.",
            "You know that once AA does not satisfy the frequency constraint, you can just ignore everything.",
            "It comes below it.",
            "Maybe you will object against using the partial order is a prefix off because it's only one of the possibilities.",
            "You could also uses a suffix, often.",
            "In fact is a substring of, would be the one to use here, but very often is prefix of is easier to use in practice.",
            "Again for technical difficulties.",
            "And I also have to say that this is definitely not the only way to attack the longest common substring problem.",
            "There are many other ways, but I wanted to show this because it illustrates some of the principles.",
            "There are many more, much more complicated patterns and just substring patterns.",
            "For example, we can try to look for palindromes for a PS4."
        ],
        [
            "Or more general Chomsky grammars, or even stochastic versions of it?",
            "The structure of the pattern space will be much more complicated in these cases, but still the same principles will be used in many of these algorithms, if not in all of them.",
            "And then of course this was just for sets and for strings with all of these ideas can also be used to find patterns in graphs and images times here is and so on.",
            "And they all rests on principles from optimization branch and bounds, dynamic programming.",
            "And other techniques and."
        ],
        [
            "Many of the lectures later on, we'll talk about this.",
            "So then.",
            "And.",
            "This is going to be the main part, the most important."
        ],
        [
            "Out of stock patterns in vector spaces.",
            "And I divided this in three subparts.",
            "The first one is about least squares problems, which is a special case of a convex optimization problem.",
            "Then I will briefly talk about more general convex optimization for pattern discovery problems.",
            "And Lastly I will briefly mention anyone eigenvalue problem.",
            "Which is a non convex optimization problem that can be solved efficiently.",
            "So let me introduce some of the data.",
            "Again, it's the data from the Lake Shasta area.",
            "So it contains a few variables measured."
        ],
        [
            "Or 454 months consecutive months and the variables are the air temperature, the two points, the cloud covered, wind speed, precipitation and inflow to Lake Shasta.",
            "So imagine one day the sensor to measure the inflow to Lake Shasta is broken and you wonder whether you should replace it.",
            "Or maybe it's just redundant.",
            "Maybe you can just predict the inflow from the first 5 variables.",
            "So you want to find this out?",
            "Maybe there is a pattern associated First 5 to the 6th.",
            "So can we guess the inflow from the other day?",
            "That's the question we want to answer, and that's basically what is known in literature by the vert regression.",
            "So I will show some equations now, so I will introduce the notation.",
            "We will make use of vectors factor."
        ],
        [
            "And or have a length of five and every entry in this vector corresponds to one of the.",
            "Things that have been measured, the temperature that you points up to the precipitation.",
            "And then there are a column, so they are represented by column.",
            "And of course we have 450, five, 5050, four such factors.",
            "Then we collect these vectors in a matrix.",
            "Every row in this matrix corresponds to one of these factors, and this matrix is represented by capital.",
            "BF X.",
            "Then the variables we want to predict, or whi I again for only 54 and these are the inflow to Lake Shasta and you arrange them in a column vector.",
            "BF why?",
            "So at the linear regression problem is a task to find a vector W or weight factor commonly called such that.",
            "X * W approximates YX times W you can see it corresponds to every data point XXI.",
            "Transpose multiplied by W so has to be approximately equal to the corresponding value of the inflowing Lake Shasta.",
            "OK, so how can we?",
            "How can we solve this problem?",
            "Let us for a moment, assume the model a model for this data.",
            "How this data has been generated.",
            "So one potential model is that the."
        ],
        [
            "Total exercise is indeed equal to X * W plus of noise, and we don't know this noise, but just because it's easy, we will assume that the noise is Gaussian and that is.",
            "And the noise on the different time points the different data points is uncorrelated and that the variance of the noise is 1 on each of the data points.",
            "An we also assume that the expectation of the noise is equal to 0.",
            "Then one can show that the maximum likelihood estimator for W is given by the W that minimizes this cost function.",
            "So we just want to minimize the sum of the squared errors for each of the data points.",
            "Then if he found W in this way, and we can estimate a new label and new inflow to Lake Shasta based on the other five measurements as X, transpose W, and maybe we solve the problem, maybe we don't have to replace the sensor.",
            "So in this case explained in terms of pattern functions, pattern function is equal to this.",
            "Sum of squared errors."
        ],
        [
            "It's parameterized by the weight vector, and now we want to minimize it because you want the errors will be as small as possible.",
            "So I just wrote it out here and to find the minimum I have to say this is a convex convex cost function convex pattern function which makes everything very easy and because of that we will be able to solve it explicitly.",
            "In fact in this case.",
            "So we equate the gradient to 0.",
            "Then we get this or W can be found as.",
            "This inversion is never carried out in practice, but you solve this set of equations and they are known as the normal equations very well know.",
            "So this is the least squares problem.",
            "If we apply this to the data so to all of the data points in the 455 fifty four data points, and then we compare the predictions of all these data points on which we learn W with."
        ],
        [
            "The label with the inflow to Lake Shasta.",
            "We get this so you see that indeed.",
            "X transpose times W is more or less equal to why I.",
            "This is the first my section by section of the first quadrant.",
            "It's not exact because there is some noise so.",
            "You have to judge whether you is sufficient or not.",
            "If you look at W. You can see that the wait for precipitation is quite large and the wait for wind is quite.",
            "Relevant to lymph flow?",
            "Maybe it makes sense.",
            "So in in that example we retrained, we found W based on all the data and we evaluated how well it predicts based on all the data as well, which is not entirely fair because of statistical reasons.",
            "Imagine we can only train W. We can only learn W based on one year of samples based on only 12 samples.",
            "In that case the noise is maybe going to be too huge and we don't have enough data to really find reasonable W that reasonable weight factor.",
            "So in that case.",
            "We need to do something else.",
            "We need to improve generalization as I call it by restricting the capacity.",
            "So now the capacity functional comes in.",
            "And the capacity functional at this very often taken and used in this kind of problems, is a square norm of."
        ],
        [
            "Over the weight factor.",
            "The reason why this one is so popular is again because it is convex, so so everything remains a convex optimization problem.",
            "Indeed, in the pattern discovery problem.",
            "Formally written is as far as like this becomes equal to this.",
            "And it is known under the name of which aggression, and this is a convex optimization problem which can be solved very efficiently.",
            "And again we can write it out.",
            "As a we can write down the solution explicitly as explained on this slide, so this is again the optimization problem.",
            "We can write out the Lagrangian with Lambda.",
            "LaGrange multiplier.",
            "We equate the gradient retrospective value to zero and this is the solution.",
            "So the difference with the least crash regression problem is just that you have to add an identity with some weight to this covariance matrix."
        ],
        [
            "So if we evaluate rich regression on the data just based on 12 data points and also least squares regression based on only 12 data points, we get this."
        ],
        [
            "Picture so.",
            "W is learn based on the first 12 months and we evaluate the performance of predicted performance based on the remaining older remaining points.",
            "So we compute in fact the error.",
            "The error of the predictions based on his W on all remaining points.",
            "Then of course if you plot this error as a function of Lambda, at least partially rationale remains the same because it was independent of Lambda.",
            "But rich aggression.",
            "Prediction error it varies a bit and you can see that there is an optimum.",
            "More or less between minus four and minus three an.",
            "That the optimum is better than the least crash prediction error.",
            "So even though we didn't search the entire space, we restricted the capacity of the search space.",
            "You can see there is an improvement.",
            "There is a huge literature about finding the optimal value of this parameter.",
            "Lambda of this regularization parameter.",
            "As this calls and will not go into that right now.",
            "This really huge domain.",
            "But there are ways to tune it.",
            "So that's where I talk about regression.",
            "Now, what about class?"
        ],
        [
            "Vacation if I making the step from regression to classification can be very easy shown on this on this slide.",
            "Let's assume that Y.",
            "The variable we want to predict is binary, so it is just a class class variable, sign or minus one, or plus one.",
            "Then by just doing this we obtain an algorithm that is known as Fisher discriminant analysis.",
            "Which is also very well known algorithm, very old 100 years old almost I think.",
            "So W is exactly found in the same way As for retrogression.",
            "Later on you will see another approach to Fisher discriminant analysis based on eigenvalue problems.",
            "So let's evaluate this on the data.",
            "Again, we train just based on the first 12 data points and the classification problem you would like to solve is to classify data from the summer months 6 summer months against the six winter months so.",
            "Around somewhere around winter then."
        ],
        [
            "You can see what it gives for least correct regression, so these are.",
            "XI transpose W for the refunds and these are my eyes you can see it indeed for negative I equal to minus one XI transpose W is most of the time below zero and four Yi equal to plus one.",
            "It's most of the time larger than zero, so simply thresholding this value will give you a reasonable prediction for the label.",
            "But again, it pays off to do some regularization, and here is a similar plot as we saw in the rich regression example here.",
            "Also, there is an optimum of the regularize Fisher discriminant analysis with Lambda equal to Lambda different from zero, which is much better than without regularization with Lambda equal to 0.",
            "So this crash aggression."
        ],
        [
            "Completely convex optimization problem an because of the particular pattern function we use, which was convex and because of the capacity function which was also convex.",
            "So yeah, the convex optimum objective and a convex constraint, we can also use different pattern functions.",
            "For example, I just name a few and the pattern discovery problem remains efficiently solvable as long as it remains convex in W as long as pattern function is convex in W. One notable example is the pattern function is equal to the sum over all the data points of F evaluated on xiy where F. This function F is given by this, so I will not go into details about this.",
            "I will just say that using this pattern function we get the support vector machine and I think but natural careful talk about support vector machines laser.",
            "In one of the next days.",
            "So and then let me talk about one last prob."
        ],
        [
            "Um, which is.",
            "Which will lead to not a convex optimization problem with an angle value problem, which can also be solved efficiently.",
            "So maybe you remember the first slide I showed where on top right of the slide that there was this cloud of points and we had a weight factor on which we projected the data points.",
            "We obtained a large variance.",
            "So how to solve this problem in practice?",
            "So we want to find weight factor direction such that the data is projected on.",
            "It has a large variance.",
            "So our pattern function is going to be equal to the variance of this projection projection is X * W. That's it, and to prevent W to go to Infinity because we could.",
            "Make this pattern function really large by just multiplying W with a very large real number.",
            "To prevent W to go to Infinity, we just impose capacity constraints.",
            "For the capacity, functional is equal to W transpose W, and this constraint can be anything just lower than or equal to 1.",
            "It doesn't matter what exactly this number is, so then the pattern discovery problem is the maximization in this case, because you want to maximize the variance subject to an upper bounds on the norm of the video.",
            "I say an upper bound, but in fact we can make it inequality because you can see that the optimum will always be reached for the inequality being strictly inequality.",
            "So this is the same optimization problem again where I immediately wrote inequalities sign instead of an inequality.",
            "Again, we are used."
        ],
        [
            "You write down the Lagrangian, which is equal to this and we create a gradient with respect to W to 0.",
            "And we obtain these as a result which is an added value problem.",
            "As you might recognize, this is the covariance matrix and this is the eigenvalue and the solution you're looking for is a W, the eigenvector corresponding to the largest negative value, so it is nonconvex as I said.",
            "But it is efficiently solvable, and I will talk more about eigenvalue problems in the next lecture in two days on Monday, I think.",
            "So an important thing about all these patterns in continuous spaces and in metric spaces or.",
            "Patterns in data sets is that the search space is actually exponential in the dimensionality of the weight vector, so the volume of the search phase exponential in the value and the dimensionality of this weight factor.",
            "But still all these algorithms that I showed all this convex optimization algorithms also designer value problem that can be solved in polynomial time polynomial in the dimensionality and polynomial in the number of data points.",
            "So this is in fact non trivial effect.",
            "But which is very often the case in the cleverly designed algorithms.",
            "So just to show principle component analysis on."
        ],
        [
            "Example, so we did principle component analysis on all of the six variables.",
            "Then when I put it here or the first principle components versus the second principle component for each of the data points.",
            "No, what you cannot see, but I can tell you is that by just using these two principal components already 676% of the variance is captured, which means that the data is actually lying very close to the hyperplane spanned by the 1st and the 2nd principle component, and the rest can be somehow considered as unimportant noise.",
            "So we can actually reduce the dimensionality of the data from 6 to 2.",
            "If you look at what these two weight factors are for the first for the second principle component.",
            "You can actually see that the first one corresponds to either bad or good weather, depending on whether you're on the left side or on the right side.",
            "As you can see, the temperature is low.",
            "Also, the Geo point was very correlated.",
            "Many clouds, rainy inflow to Lake Shasta, which is currently to the precipitation and the wind is not so important in this case.",
            "The second component it tells you how we need a wider is cause.",
            "All these are quite OK.",
            "This one is quite big, but this is really the prominent entry in the weight factor, so really tells you how windy.",
            "And so this means that we can summarize the weather type basically based on whether it's good weather and whether it's windy weather.",
            "So we can summarize the data in a very convenient way.",
            "So.",
            "To summarize, I tried to give a formalism for pattern analysis, which is of course not the best one, but it's just an attempt.",
            "Maybe it's a way to try to."
        ],
        [
            "Unified View and discrete pattern analysis and pattern analysis in continuous basis.",
            "So I try to show that it's possible to see everything in this framework and.",
            "Monday I will zoom in a bit on the eigenvalue problems.",
            "To find patterns and sets.",
            "That's it.",
            "Questions.",
            "What about your talking about?",
            "Yeah so.",
            "So for this overfitting, for example, this capacity functional, it really helps you in in reducing the search space and so in that sense it's algorithmically important, but it is also important because.",
            "It helps you against overfitting because you selected the pattern from a more limited set of patterns and the two examples I gave you go.",
            "You go to this one where I compared the scratching Russian against rich aggression.",
            "You can see that in this case W was trained on 12 points.",
            "And it was evaluated on all the other points on the test set, and you can see that indeed, please crash aggression seems to overfit a bit, while rich aggression.",
            "That's so far that's awful.",
            "Offer a small value of Lambda for small value of the regularization parameter, but does less overfitting for a non 0 value for Lambda.",
            "So in fact this capacity functional use of this constraint on the pattern space or the limitation of this pattern space to a smaller subspace helps you against overfitting.",
            "Can you work with the same framework if your function is not one dimensional that is not.",
            "Are fucking awful.",
            "So that would mean that you have several costs.",
            "You want to optimize at the same time, right?",
            "If you record yourself and report your results.",
            "Weather indicator on the earth and I want to estimate the point on the earth for lab.",
            "Yeah, yeah, I think in the end it will always boil down to minimizing a cost function, which is, which is a real number in many cases.",
            "So you know, maybe you want to minimize the difference between the prediction of two dimensional point and the two dimensional points.",
            "The true value of observational points.",
            "This will in the end be a norm or a distance, I would think.",
            "So the pattern function is really a cost and maybe you can do multi objective optimization.",
            "I don't know if.",
            "Experience their own independence.",
            "I don't want to work for the ground.",
            "Work.",
            "Yeah.",
            "Maybe we can talk about it.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Understandable.",
                    "label": 0
                },
                {
                    "sent": "So first of all, I would like to thank all the organizers for giving me the chance to speak at this wonderful place.",
                    "label": 0
                },
                {
                    "sent": "It's really beautiful.",
                    "label": 0
                },
                {
                    "sent": "Very interesting, I think, so I will give a more general talk about optimization approaches in pattern analysis.",
                    "label": 1
                },
                {
                    "sent": "And that's the first half of the talk, and to be able to do this, I will try to set the scene a bit and to give one potential working definition of what a pattern is.",
                    "label": 0
                },
                {
                    "sent": "So it's only one of the possible ways to do it.",
                    "label": 1
                },
                {
                    "sent": "And then the second half of this talk is about patterns in vector spaces, in particular in sets of data points.",
                    "label": 0
                },
                {
                    "sent": "So this is the overview, the overview of the talk first.",
                    "label": 0
                },
                {
                    "sent": "First part sorry first part will be about general pattern analysis, so the definitions, some definitions how to see pattern matching within this framework?",
                    "label": 0
                },
                {
                    "sent": "How to see pattern discovery in this framework?",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then I will apply this framework a bit to patterns in discrete spaces, such as insets in strings, and I will only briefly mention patterns in graphs an hour later during the summer school, older speakers will go in great detail online.",
                    "label": 1
                },
                {
                    "sent": "All these applications of pattern analysis or these instances of pattern analysis and then the main part of this talk is about patterns in vector spaces as Nola mentioned, which is a very well developed.",
                    "label": 0
                },
                {
                    "sent": "Part of pattern analysis.",
                    "label": 0
                },
                {
                    "sent": "I will not speak about statistical aspects, only about algorithmic aspects about optimization aspects.",
                    "label": 0
                },
                {
                    "sent": "The next talk by Joshua Taylor will go more in detail about the statistical.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Side of pattern analysis.",
                    "label": 0
                },
                {
                    "sent": "So what is the pattern?",
                    "label": 0
                },
                {
                    "sent": "You can have many ideas about this with two to show what I think is the definition of a pattern I will give.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Few examples, so imagine we are given a set of points every black deltas data point in a 2 dimensional space.",
                    "label": 0
                },
                {
                    "sent": "Then one pattern, one would immediately.",
                    "label": 0
                },
                {
                    "sent": "Probably see is the fact that they are aligned more or less along a line like this.",
                    "label": 0
                },
                {
                    "sent": "So if you have a vector direct arrow over there and you project all the data points on this factor, then the variance of these projections would be large.",
                    "label": 0
                },
                {
                    "sent": "So maybe you want to do.",
                    "label": 0
                },
                {
                    "sent": "It is then projected because we can assume that the other dimension is just noise and we want to get rid of it.",
                    "label": 0
                },
                {
                    "sent": "So that's one example.",
                    "label": 0
                },
                {
                    "sent": "Another example.",
                    "label": 0
                },
                {
                    "sent": "What you see here is in Etruscan text.",
                    "label": 0
                },
                {
                    "sent": "It comes from the liberal.",
                    "label": 0
                },
                {
                    "sent": "In tears you might not be able to read it, but if you could read it, you would not understand it because it hasn't been deciphered, deciphered yet.",
                    "label": 0
                },
                {
                    "sent": "Just only parts of it, and what I highlighted in this text is divert Ednam.",
                    "label": 0
                },
                {
                    "sent": "So it consists of five letters and it turns out to be really frequent in all interesting text.",
                    "label": 0
                },
                {
                    "sent": "And then they figured out the meaning of Adam and so.",
                    "label": 0
                },
                {
                    "sent": "This word is fairly frequent, which is an interesting pattern we can exploit it by figuring out that.",
                    "label": 0
                },
                {
                    "sent": "It corresponds to a stop word, namely and.",
                    "label": 0
                },
                {
                    "sent": "Then 3rd example.",
                    "label": 0
                },
                {
                    "sent": "Suppose we have two clouds of points.",
                    "label": 0
                },
                {
                    "sent": "One is labeled negatively, so all these points are assigned to one class or the black points or assigned to another class.",
                    "label": 0
                },
                {
                    "sent": "Then we can see that we can find 2 hyperplanes in 2 dimensional space, 2 lines, search that all the negative points lie on one side of these two lines positively labeled points lie on the other side, so there's no misclassification for these two lines in the last example, I think they already.",
                    "label": 0
                },
                {
                    "sent": "Talk about this data.",
                    "label": 0
                },
                {
                    "sent": "In this talk.",
                    "label": 0
                },
                {
                    "sent": "It is the temperature data in the Lake Shasta area and it looks quite periodic so we could try to fit a periodic signal to this and try to find one that fits well with this data and maybe also this is a way to get rid of some noise.",
                    "label": 0
                },
                {
                    "sent": "So what is it gonna pattern?",
                    "label": 0
                },
                {
                    "sent": "I think we can define it in terms of a pattern function, so pattern function could be the variance over projection on a vector or the frequency of a certain given substring, and so in this pattern function it takes the data and it Maps the data to a real number.",
                    "label": 0
                },
                {
                    "sent": "You can have several pattern functions of course, and the type of the kind.",
                    "label": 0
                },
                {
                    "sent": "The way to define a pattern function depends on the data and so on.",
                    "label": 0
                },
                {
                    "sent": "So depending on the data, for example, it risk in data, we can have several pattern functions.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On pattern function for each of the substrings you can consider.",
                    "label": 0
                },
                {
                    "sent": "And the pattern magnitude is is a value of the pattern function.",
                    "label": 0
                },
                {
                    "sent": "So a real value or can be an integer #2 in some cases.",
                    "label": 0
                },
                {
                    "sent": "And then we can specify pattern by equating stating that the pattern function Pi of X is equal to some number \u03c0 bar supplies than just a given given number.",
                    "label": 0
                },
                {
                    "sent": "So this is basically the definition of the pattern I want to use, namely the equality of a pattern function which takes the data to real number to some given real number.",
                    "label": 0
                },
                {
                    "sent": "So maybe just to illustrate what a pattern space exactly is.",
                    "label": 0
                },
                {
                    "sent": "In this case, the pattern space.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is defined for or is parameterized every pattern in this pattern space is parameterized by weight factor, so this is for this weight factor.",
                    "label": 0
                },
                {
                    "sent": "We just have one pattern function which is variance of all the projections on this data on this factor.",
                    "label": 0
                },
                {
                    "sent": "In this case, the pattern space defines parameterized by all possible substrings.",
                    "label": 0
                },
                {
                    "sent": "For each substring, we have a pattern function that counts how frequently this substring occurs in the data.",
                    "label": 0
                },
                {
                    "sent": "In this case, the number of misclassifications for a given pair of planes.",
                    "label": 0
                },
                {
                    "sent": "And in this case would be maybe the Misfits.",
                    "label": 0
                },
                {
                    "sent": "Over periodic signal you're considering, so every periodic signal corresponds to a pattern function.",
                    "label": 0
                },
                {
                    "sent": "So with this definition, how can we define pattern matching?",
                    "label": 0
                },
                {
                    "sent": "It is simply nothing else in the evaluation or a computation of the value of the pattern function.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For example, for the Etruscan text example, pattern function simply counts the frequency of the substring Atom.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I'm pattern discovery.",
                    "label": 0
                },
                {
                    "sent": "So want to define define pattern discovery.",
                    "label": 1
                },
                {
                    "sent": "Within this framework we could say the pattern Discovery is just picking the best pattern function out of the pattern space.",
                    "label": 0
                },
                {
                    "sent": "The best in terms of the value of this pattern function.",
                    "label": 0
                },
                {
                    "sent": "For example, this better function that maximizes the pattern magnitude or that minimizes the better magnitude depending on if you want to.",
                    "label": 0
                },
                {
                    "sent": "If you have the pattern function corresponds to some cost or to some profit.",
                    "label": 0
                },
                {
                    "sent": "But this is not sufficient because for example in.",
                    "label": 0
                },
                {
                    "sent": "In the case where we wanted to maximize the variance, if instead of this weight factor we take this one which is longer and we project all the data on it, then the variance of these projections will be larger than for the red arrow is still.",
                    "label": 0
                },
                {
                    "sent": "Intuitively we prefer the red one over the blue one.",
                    "label": 0
                },
                {
                    "sent": "In the text case, if you consider shorter string, which is meaningless, AN in this case we can see that it's actually more frequent than at namit doesn't.",
                    "label": 0
                },
                {
                    "sent": "The difference is not that large, but it is slightly more frequent, but it doesn't have a meaning, and the reason is simply that the length of the suffering is too small.",
                    "label": 0
                },
                {
                    "sent": "In this case, we don't just want any pair of hyper place, we prefer hyperplanes in Oras distance as possible from each other, because it's just too easy in many cases to finds separating pair of hyperplanes are very close to each other, and in this last case is preferable to find periodic signal that is smooth that is, does not follow all the tiny glitches in the periodic pattern.",
                    "label": 0
                },
                {
                    "sent": "So pattern discovery is not.",
                    "label": 1
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Just picking the pattern function from the pattern space that maximizes the pattern magnitude.",
                    "label": 0
                },
                {
                    "sent": "Sometimes it can be, but in general we should do something more.",
                    "label": 0
                },
                {
                    "sent": "So what you want to do is we want to add an additional restriction on how the pattern function can be chosen from the pattern space, namely, we define.",
                    "label": 0
                },
                {
                    "sent": "A property which is defined by a functional pattern function, so it takes the pattern function to a real valued number.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "So we restrict the search in the pattern space by Additionally imposing a constraint on the pattern function, namely that dysfunctional, must be smaller or equal to a maximal value that we specify.",
                    "label": 0
                },
                {
                    "sent": "So using this constraint we can actually restrict the search space, which is sometimes called regularization and.",
                    "label": 0
                },
                {
                    "sent": "Another way to view this is to say that we restrict the capacity of our pattern Discovery search so it relates to the flexibility of this set of pattern functions that we are searching over.",
                    "label": 0
                },
                {
                    "sent": "So with this additional constraints we can define pattern discovery as the maximization of the pattern magnitude, overall pattern functions subject to a constraint on this capacity.",
                    "label": 1
                },
                {
                    "sent": "So saying that the capacity capacity function must be smaller than upper bounds.",
                    "label": 0
                },
                {
                    "sent": "An alternative way to do which is a very high extent equivalent is.",
                    "label": 0
                },
                {
                    "sent": "Saying that, we want to minimize the capacity functional, so in the end minimize the region over which we.",
                    "label": 0
                },
                {
                    "sent": "We are searching subject subject to a lower bound constraint on the pattern magnitude, so these are two formulations you can use interchangeably.",
                    "label": 0
                },
                {
                    "sent": "In some cases this one is more convenient, sometimes when it's more convenient.",
                    "label": 0
                },
                {
                    "sent": "I also have to say at this point this is a maximization is minimization lower bound upper bounds depending on the context it can.",
                    "label": 0
                },
                {
                    "sent": "It can be something else.",
                    "label": 0
                },
                {
                    "sent": "So this can also be a minimization if the pattern magnitude if you want to be large then you want to maximize it.",
                    "label": 0
                },
                {
                    "sent": "If you want it to be small, if it's a cost function, you want to minimize it.",
                    "label": 0
                },
                {
                    "sent": "So this is just one example.",
                    "label": 0
                },
                {
                    "sent": "So in fact the problem is conceptually solved with this optimization.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Problem you just solve it, But the problem is that very often, even with this additional constraint on the capacity, the search phase is still exponentially large in a problem size.",
                    "label": 0
                },
                {
                    "sent": "So this rules out an exhaustive search in all cases, so we need more clever algorithms, and in fact in many cases I exist.",
                    "label": 0
                },
                {
                    "sent": "And while the search space is exponentially large, many pattern discovery algorithms actually only take a polynomial time in the problem size.",
                    "label": 0
                },
                {
                    "sent": "So intention of remainder of this talk is to understand.",
                    "label": 0
                },
                {
                    "sent": "As well as possible, what is it?",
                    "label": 0
                },
                {
                    "sent": "Design principles are to achieve this exponential speedup?",
                    "label": 0
                },
                {
                    "sent": "The pattern is coveri task.",
                    "label": 0
                },
                {
                    "sent": "I will now first applying this to patterns in discrete spaces very briefly, just to give some ideas and.",
                    "label": 1
                },
                {
                    "sent": "To.",
                    "label": 0
                },
                {
                    "sent": "To make it easier for people who are more familiar with patterns in discrete spaces, such as insets, any strings to transfer these ideas to matters in continuous spaces, which will be the main part.",
                    "label": 0
                },
                {
                    "sent": "So better than discrete spaces, I will first discuss briefly.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Princess and mentioned a very well known algorithm.",
                    "label": 0
                },
                {
                    "sent": "The Priory algorithm which is concept conceptually.",
                    "label": 0
                },
                {
                    "sent": "Easy enough to explain.",
                    "label": 0
                },
                {
                    "sent": "Without too much effort and still learns a lot about the principles and patterns in strings which use actually fairly similar IDs, and I will just mention patterns in graphs.",
                    "label": 1
                },
                {
                    "sent": "So patterns in sets.",
                    "label": 0
                },
                {
                    "sent": "Imagine we are gathering data from a shop or a shopkeeper is gay.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Data and this shop has selling 6 items, chocolate, beer, apples, bread diapers and milk.",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                },
                {
                    "sent": "This shopkeeper is clever enough to maintain data from all these customers, so he's keeping transaction records.",
                    "label": 0
                },
                {
                    "sent": "For example, saying that the first beer, breads and diapers in milliseconds, one beer, apples and diapers, and so on.",
                    "label": 0
                },
                {
                    "sent": "So what is shopkeeper wants to do?",
                    "label": 0
                },
                {
                    "sent": "It it is.",
                    "label": 0
                },
                {
                    "sent": "He wants to find meaningful associations between these items.",
                    "label": 0
                },
                {
                    "sent": "In other words, he wants to find frequent itemsets, so sets of these items, or very often bought together by different customers.",
                    "label": 0
                },
                {
                    "sent": "The reason why he wants to do it, is because maybe he wants to lower the price and advertises lower price for one of the items.",
                    "label": 0
                },
                {
                    "sent": "In such an item set and without saying increase the price of one of the other items in this item set.",
                    "label": 0
                },
                {
                    "sent": "So he makes the same amount of money because people buy them together anyway.",
                    "label": 0
                },
                {
                    "sent": "But he can advertise him and people come to him for this lower price.",
                    "label": 0
                },
                {
                    "sent": "So he wants to find frequent item sets with.",
                    "label": 0
                },
                {
                    "sent": "And one example is this one beer and diapers and there is a story about it that the reason that this would actually be true, that beer and diapers are associated, because very often young people have children and they buy diapers.",
                    "label": 0
                },
                {
                    "sent": "But at the same time they want to have a beer in front of the television or whatever.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "This would be an interesting idea, set also because it's compared to the side with store only.",
                    "label": 0
                },
                {
                    "sent": "Six items is quite large because small items that doesn't mean anything.",
                    "label": 0
                },
                {
                    "sent": "If you find a frequent itemset.",
                    "label": 0
                },
                {
                    "sent": "Of size 1, just one item.",
                    "label": 0
                },
                {
                    "sent": "It doesn't teach you anything.",
                    "label": 0
                },
                {
                    "sent": "It might be a coincidence as well.",
                    "label": 0
                },
                {
                    "sent": "So he wants to find frequent and large item sets.",
                    "label": 0
                },
                {
                    "sent": "So explain in terms of pattern, function and capacity functionals.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Free pattern function will be parameterized by an item set, so that's why the subscript item set an pattern function counts the frequency of this item set.",
                    "label": 0
                },
                {
                    "sent": "And the capacity functional is the size of the item set.",
                    "label": 0
                },
                {
                    "sent": "You know that by C of the pattern function, so.",
                    "label": 0
                },
                {
                    "sent": "The pattern discovery problem would be.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To maximize the size of the item set subject to lower bounds on the frequency of the United States.",
                    "label": 0
                },
                {
                    "sent": "So maybe you want the items to occur at least four times and you want to maximize the size so it becomes to which was the case in the example.",
                    "label": 0
                },
                {
                    "sent": "However, the problem now is that the number of items that is exponential in the items that size, so it's impossible to just enumerate all the different items and check whether this constraint is satisfied and then pick the largest one for which this is true.",
                    "label": 0
                },
                {
                    "sent": "So efficient search strategies needs to need to be developed, and one example is your priority algorithm, which was really an important advance and.",
                    "label": 0
                },
                {
                    "sent": "In this research, LogMeIn.",
                    "label": 0
                },
                {
                    "sent": "So in turn for for the search strategy that is used in this case is called level by search.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And you will immediately see why this is the case.",
                    "label": 0
                },
                {
                    "sent": "So what I represented here is the pattern space for the case when there are four items ABC and D, only four, because for six is even much larger.",
                    "label": 0
                },
                {
                    "sent": "It's already quite confusing now for four.",
                    "label": 0
                },
                {
                    "sent": "So because because the size of the pattern space is exponential in the number of items.",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                },
                {
                    "sent": "The observation that is needed to make this algorithm more efficient.",
                    "label": 0
                },
                {
                    "sent": "This pattern Discovery algorithm more efficient is that there is an interesting partial order between these items sets, namely, relation is a subset of.",
                    "label": 0
                },
                {
                    "sent": "So we can see that B is a subset of a B subset of PC.",
                    "label": 0
                },
                {
                    "sent": "So every arrow down represents a subset of.",
                    "label": 0
                },
                {
                    "sent": "Now we want to find the largest frequent itemset, which means you want to go as slow as possible in this partial order, so.",
                    "label": 0
                },
                {
                    "sent": "But it has to be frequent as well, so.",
                    "label": 0
                },
                {
                    "sent": "OK, so we can use the second observation, which says that the pattern function.",
                    "label": 0
                },
                {
                    "sent": "The frequency is monotonically decreasing on a partial order.",
                    "label": 0
                },
                {
                    "sent": "So if we go down, down Arrow and then the frequency can only decrease.",
                    "label": 0
                },
                {
                    "sent": "The reason why it isn't very intuitive if B occurs 5 * 5 times, say baseball five times, then a B together can only be bought at most five times.",
                    "label": 0
                },
                {
                    "sent": "So it's a fact it's a very simple ID.",
                    "label": 0
                },
                {
                    "sent": "So that means that one.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We know that C does not satisfy the constraint on the pattern function, so it is not frequent enough.",
                    "label": 0
                },
                {
                    "sent": "None of his descendants in this partial order can be frequent enough, so in fact.",
                    "label": 0
                },
                {
                    "sent": "We can just ignore this entire part of the pattern space, just.",
                    "label": 0
                },
                {
                    "sent": "Prune it away.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we only have to explore the remaining part.",
                    "label": 0
                },
                {
                    "sent": "So that is the basic idea behind the a priori algorithm.",
                    "label": 0
                },
                {
                    "sent": "There are many technical difficulties to really prune it efficiently, because this pruning stage is not as easy on itself.",
                    "label": 0
                },
                {
                    "sent": "But this is the main ID.",
                    "label": 0
                },
                {
                    "sent": "Now let's look at patterns in strings.",
                    "label": 0
                },
                {
                    "sent": "The attrition text, again in a different format, so we are given along symbol sequence and we want to find out which words have a meaning.",
                    "label": 0
                },
                {
                    "sent": "So interesting text with Adam.",
                    "label": 0
                },
                {
                    "sent": "So we want to find frequent substrings because one that occurs only once and doesn't mean anything.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But only if they were long at the same time, because a man was more frequent and at number doesn't mean a thing.",
                    "label": 0
                },
                {
                    "sent": "So in this case the.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Function is parameterized by substring at.",
                    "label": 0
                },
                {
                    "sent": "Now for example, and it counts its frequency pattern function is equal to the frequency of substring.",
                    "label": 0
                },
                {
                    "sent": "And the capacity functional is equal to the substrings link.",
                    "label": 0
                },
                {
                    "sent": "'cause we want to.",
                    "label": 0
                },
                {
                    "sent": "You will want to maximize the length, subject to constraint on the pattern function, so the resulting pattern discovery problem is given by this maximizing the length.",
                    "label": 0
                },
                {
                    "sent": "So we have two constraints on the frequency.",
                    "label": 0
                },
                {
                    "sent": "The longest frequent substring problem.",
                    "label": 0
                },
                {
                    "sent": "We can use very similar principles as in your primary algorithm.",
                    "label": 0
                },
                {
                    "sent": "Again, a level wise search.",
                    "label": 0
                },
                {
                    "sent": "And we have to do this because the number of substrings of a certain length is exponential in this link.",
                    "label": 0
                },
                {
                    "sent": "Again, so again, we can.",
                    "label": 0
                },
                {
                    "sent": "We can find a partial order in.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The pattern space, namely, for example, is a prefix of A is a prefix of a, A an of a B only drew very small part of the pattern space.",
                    "label": 0
                },
                {
                    "sent": "Again, the length is increasing if you go down the partial order.",
                    "label": 0
                },
                {
                    "sent": "So we want to go slow as possible, but on the other hand, the frequency is monotonically decreasing on the partial order.",
                    "label": 0
                },
                {
                    "sent": "Since you want to impose a lower bound on the frequency.",
                    "label": 0
                },
                {
                    "sent": "You know that once AA does not satisfy the frequency constraint, you can just ignore everything.",
                    "label": 0
                },
                {
                    "sent": "It comes below it.",
                    "label": 0
                },
                {
                    "sent": "Maybe you will object against using the partial order is a prefix off because it's only one of the possibilities.",
                    "label": 0
                },
                {
                    "sent": "You could also uses a suffix, often.",
                    "label": 0
                },
                {
                    "sent": "In fact is a substring of, would be the one to use here, but very often is prefix of is easier to use in practice.",
                    "label": 0
                },
                {
                    "sent": "Again for technical difficulties.",
                    "label": 0
                },
                {
                    "sent": "And I also have to say that this is definitely not the only way to attack the longest common substring problem.",
                    "label": 0
                },
                {
                    "sent": "There are many other ways, but I wanted to show this because it illustrates some of the principles.",
                    "label": 0
                },
                {
                    "sent": "There are many more, much more complicated patterns and just substring patterns.",
                    "label": 0
                },
                {
                    "sent": "For example, we can try to look for palindromes for a PS4.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or more general Chomsky grammars, or even stochastic versions of it?",
                    "label": 0
                },
                {
                    "sent": "The structure of the pattern space will be much more complicated in these cases, but still the same principles will be used in many of these algorithms, if not in all of them.",
                    "label": 0
                },
                {
                    "sent": "And then of course this was just for sets and for strings with all of these ideas can also be used to find patterns in graphs and images times here is and so on.",
                    "label": 0
                },
                {
                    "sent": "And they all rests on principles from optimization branch and bounds, dynamic programming.",
                    "label": 0
                },
                {
                    "sent": "And other techniques and.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Many of the lectures later on, we'll talk about this.",
                    "label": 0
                },
                {
                    "sent": "So then.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "This is going to be the main part, the most important.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Out of stock patterns in vector spaces.",
                    "label": 1
                },
                {
                    "sent": "And I divided this in three subparts.",
                    "label": 1
                },
                {
                    "sent": "The first one is about least squares problems, which is a special case of a convex optimization problem.",
                    "label": 0
                },
                {
                    "sent": "Then I will briefly talk about more general convex optimization for pattern discovery problems.",
                    "label": 0
                },
                {
                    "sent": "And Lastly I will briefly mention anyone eigenvalue problem.",
                    "label": 0
                },
                {
                    "sent": "Which is a non convex optimization problem that can be solved efficiently.",
                    "label": 0
                },
                {
                    "sent": "So let me introduce some of the data.",
                    "label": 0
                },
                {
                    "sent": "Again, it's the data from the Lake Shasta area.",
                    "label": 0
                },
                {
                    "sent": "So it contains a few variables measured.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or 454 months consecutive months and the variables are the air temperature, the two points, the cloud covered, wind speed, precipitation and inflow to Lake Shasta.",
                    "label": 0
                },
                {
                    "sent": "So imagine one day the sensor to measure the inflow to Lake Shasta is broken and you wonder whether you should replace it.",
                    "label": 0
                },
                {
                    "sent": "Or maybe it's just redundant.",
                    "label": 0
                },
                {
                    "sent": "Maybe you can just predict the inflow from the first 5 variables.",
                    "label": 0
                },
                {
                    "sent": "So you want to find this out?",
                    "label": 0
                },
                {
                    "sent": "Maybe there is a pattern associated First 5 to the 6th.",
                    "label": 0
                },
                {
                    "sent": "So can we guess the inflow from the other day?",
                    "label": 0
                },
                {
                    "sent": "That's the question we want to answer, and that's basically what is known in literature by the vert regression.",
                    "label": 0
                },
                {
                    "sent": "So I will show some equations now, so I will introduce the notation.",
                    "label": 0
                },
                {
                    "sent": "We will make use of vectors factor.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And or have a length of five and every entry in this vector corresponds to one of the.",
                    "label": 0
                },
                {
                    "sent": "Things that have been measured, the temperature that you points up to the precipitation.",
                    "label": 0
                },
                {
                    "sent": "And then there are a column, so they are represented by column.",
                    "label": 0
                },
                {
                    "sent": "And of course we have 450, five, 5050, four such factors.",
                    "label": 0
                },
                {
                    "sent": "Then we collect these vectors in a matrix.",
                    "label": 0
                },
                {
                    "sent": "Every row in this matrix corresponds to one of these factors, and this matrix is represented by capital.",
                    "label": 0
                },
                {
                    "sent": "BF X.",
                    "label": 0
                },
                {
                    "sent": "Then the variables we want to predict, or whi I again for only 54 and these are the inflow to Lake Shasta and you arrange them in a column vector.",
                    "label": 0
                },
                {
                    "sent": "BF why?",
                    "label": 0
                },
                {
                    "sent": "So at the linear regression problem is a task to find a vector W or weight factor commonly called such that.",
                    "label": 0
                },
                {
                    "sent": "X * W approximates YX times W you can see it corresponds to every data point XXI.",
                    "label": 0
                },
                {
                    "sent": "Transpose multiplied by W so has to be approximately equal to the corresponding value of the inflowing Lake Shasta.",
                    "label": 0
                },
                {
                    "sent": "OK, so how can we?",
                    "label": 0
                },
                {
                    "sent": "How can we solve this problem?",
                    "label": 0
                },
                {
                    "sent": "Let us for a moment, assume the model a model for this data.",
                    "label": 0
                },
                {
                    "sent": "How this data has been generated.",
                    "label": 0
                },
                {
                    "sent": "So one potential model is that the.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Total exercise is indeed equal to X * W plus of noise, and we don't know this noise, but just because it's easy, we will assume that the noise is Gaussian and that is.",
                    "label": 0
                },
                {
                    "sent": "And the noise on the different time points the different data points is uncorrelated and that the variance of the noise is 1 on each of the data points.",
                    "label": 0
                },
                {
                    "sent": "An we also assume that the expectation of the noise is equal to 0.",
                    "label": 0
                },
                {
                    "sent": "Then one can show that the maximum likelihood estimator for W is given by the W that minimizes this cost function.",
                    "label": 0
                },
                {
                    "sent": "So we just want to minimize the sum of the squared errors for each of the data points.",
                    "label": 0
                },
                {
                    "sent": "Then if he found W in this way, and we can estimate a new label and new inflow to Lake Shasta based on the other five measurements as X, transpose W, and maybe we solve the problem, maybe we don't have to replace the sensor.",
                    "label": 0
                },
                {
                    "sent": "So in this case explained in terms of pattern functions, pattern function is equal to this.",
                    "label": 0
                },
                {
                    "sent": "Sum of squared errors.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It's parameterized by the weight vector, and now we want to minimize it because you want the errors will be as small as possible.",
                    "label": 0
                },
                {
                    "sent": "So I just wrote it out here and to find the minimum I have to say this is a convex convex cost function convex pattern function which makes everything very easy and because of that we will be able to solve it explicitly.",
                    "label": 0
                },
                {
                    "sent": "In fact in this case.",
                    "label": 0
                },
                {
                    "sent": "So we equate the gradient to 0.",
                    "label": 0
                },
                {
                    "sent": "Then we get this or W can be found as.",
                    "label": 0
                },
                {
                    "sent": "This inversion is never carried out in practice, but you solve this set of equations and they are known as the normal equations very well know.",
                    "label": 0
                },
                {
                    "sent": "So this is the least squares problem.",
                    "label": 1
                },
                {
                    "sent": "If we apply this to the data so to all of the data points in the 455 fifty four data points, and then we compare the predictions of all these data points on which we learn W with.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The label with the inflow to Lake Shasta.",
                    "label": 0
                },
                {
                    "sent": "We get this so you see that indeed.",
                    "label": 0
                },
                {
                    "sent": "X transpose times W is more or less equal to why I.",
                    "label": 0
                },
                {
                    "sent": "This is the first my section by section of the first quadrant.",
                    "label": 0
                },
                {
                    "sent": "It's not exact because there is some noise so.",
                    "label": 0
                },
                {
                    "sent": "You have to judge whether you is sufficient or not.",
                    "label": 0
                },
                {
                    "sent": "If you look at W. You can see that the wait for precipitation is quite large and the wait for wind is quite.",
                    "label": 0
                },
                {
                    "sent": "Relevant to lymph flow?",
                    "label": 0
                },
                {
                    "sent": "Maybe it makes sense.",
                    "label": 0
                },
                {
                    "sent": "So in in that example we retrained, we found W based on all the data and we evaluated how well it predicts based on all the data as well, which is not entirely fair because of statistical reasons.",
                    "label": 0
                },
                {
                    "sent": "Imagine we can only train W. We can only learn W based on one year of samples based on only 12 samples.",
                    "label": 0
                },
                {
                    "sent": "In that case the noise is maybe going to be too huge and we don't have enough data to really find reasonable W that reasonable weight factor.",
                    "label": 0
                },
                {
                    "sent": "So in that case.",
                    "label": 0
                },
                {
                    "sent": "We need to do something else.",
                    "label": 0
                },
                {
                    "sent": "We need to improve generalization as I call it by restricting the capacity.",
                    "label": 0
                },
                {
                    "sent": "So now the capacity functional comes in.",
                    "label": 0
                },
                {
                    "sent": "And the capacity functional at this very often taken and used in this kind of problems, is a square norm of.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Over the weight factor.",
                    "label": 0
                },
                {
                    "sent": "The reason why this one is so popular is again because it is convex, so so everything remains a convex optimization problem.",
                    "label": 0
                },
                {
                    "sent": "Indeed, in the pattern discovery problem.",
                    "label": 0
                },
                {
                    "sent": "Formally written is as far as like this becomes equal to this.",
                    "label": 0
                },
                {
                    "sent": "And it is known under the name of which aggression, and this is a convex optimization problem which can be solved very efficiently.",
                    "label": 0
                },
                {
                    "sent": "And again we can write it out.",
                    "label": 0
                },
                {
                    "sent": "As a we can write down the solution explicitly as explained on this slide, so this is again the optimization problem.",
                    "label": 0
                },
                {
                    "sent": "We can write out the Lagrangian with Lambda.",
                    "label": 0
                },
                {
                    "sent": "LaGrange multiplier.",
                    "label": 0
                },
                {
                    "sent": "We equate the gradient retrospective value to zero and this is the solution.",
                    "label": 0
                },
                {
                    "sent": "So the difference with the least crash regression problem is just that you have to add an identity with some weight to this covariance matrix.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if we evaluate rich regression on the data just based on 12 data points and also least squares regression based on only 12 data points, we get this.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Picture so.",
                    "label": 0
                },
                {
                    "sent": "W is learn based on the first 12 months and we evaluate the performance of predicted performance based on the remaining older remaining points.",
                    "label": 0
                },
                {
                    "sent": "So we compute in fact the error.",
                    "label": 0
                },
                {
                    "sent": "The error of the predictions based on his W on all remaining points.",
                    "label": 0
                },
                {
                    "sent": "Then of course if you plot this error as a function of Lambda, at least partially rationale remains the same because it was independent of Lambda.",
                    "label": 0
                },
                {
                    "sent": "But rich aggression.",
                    "label": 0
                },
                {
                    "sent": "Prediction error it varies a bit and you can see that there is an optimum.",
                    "label": 0
                },
                {
                    "sent": "More or less between minus four and minus three an.",
                    "label": 0
                },
                {
                    "sent": "That the optimum is better than the least crash prediction error.",
                    "label": 0
                },
                {
                    "sent": "So even though we didn't search the entire space, we restricted the capacity of the search space.",
                    "label": 0
                },
                {
                    "sent": "You can see there is an improvement.",
                    "label": 0
                },
                {
                    "sent": "There is a huge literature about finding the optimal value of this parameter.",
                    "label": 0
                },
                {
                    "sent": "Lambda of this regularization parameter.",
                    "label": 0
                },
                {
                    "sent": "As this calls and will not go into that right now.",
                    "label": 0
                },
                {
                    "sent": "This really huge domain.",
                    "label": 0
                },
                {
                    "sent": "But there are ways to tune it.",
                    "label": 0
                },
                {
                    "sent": "So that's where I talk about regression.",
                    "label": 0
                },
                {
                    "sent": "Now, what about class?",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Vacation if I making the step from regression to classification can be very easy shown on this on this slide.",
                    "label": 0
                },
                {
                    "sent": "Let's assume that Y.",
                    "label": 0
                },
                {
                    "sent": "The variable we want to predict is binary, so it is just a class class variable, sign or minus one, or plus one.",
                    "label": 0
                },
                {
                    "sent": "Then by just doing this we obtain an algorithm that is known as Fisher discriminant analysis.",
                    "label": 0
                },
                {
                    "sent": "Which is also very well known algorithm, very old 100 years old almost I think.",
                    "label": 0
                },
                {
                    "sent": "So W is exactly found in the same way As for retrogression.",
                    "label": 0
                },
                {
                    "sent": "Later on you will see another approach to Fisher discriminant analysis based on eigenvalue problems.",
                    "label": 0
                },
                {
                    "sent": "So let's evaluate this on the data.",
                    "label": 0
                },
                {
                    "sent": "Again, we train just based on the first 12 data points and the classification problem you would like to solve is to classify data from the summer months 6 summer months against the six winter months so.",
                    "label": 0
                },
                {
                    "sent": "Around somewhere around winter then.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can see what it gives for least correct regression, so these are.",
                    "label": 0
                },
                {
                    "sent": "XI transpose W for the refunds and these are my eyes you can see it indeed for negative I equal to minus one XI transpose W is most of the time below zero and four Yi equal to plus one.",
                    "label": 0
                },
                {
                    "sent": "It's most of the time larger than zero, so simply thresholding this value will give you a reasonable prediction for the label.",
                    "label": 0
                },
                {
                    "sent": "But again, it pays off to do some regularization, and here is a similar plot as we saw in the rich regression example here.",
                    "label": 0
                },
                {
                    "sent": "Also, there is an optimum of the regularize Fisher discriminant analysis with Lambda equal to Lambda different from zero, which is much better than without regularization with Lambda equal to 0.",
                    "label": 0
                },
                {
                    "sent": "So this crash aggression.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Completely convex optimization problem an because of the particular pattern function we use, which was convex and because of the capacity function which was also convex.",
                    "label": 0
                },
                {
                    "sent": "So yeah, the convex optimum objective and a convex constraint, we can also use different pattern functions.",
                    "label": 0
                },
                {
                    "sent": "For example, I just name a few and the pattern discovery problem remains efficiently solvable as long as it remains convex in W as long as pattern function is convex in W. One notable example is the pattern function is equal to the sum over all the data points of F evaluated on xiy where F. This function F is given by this, so I will not go into details about this.",
                    "label": 0
                },
                {
                    "sent": "I will just say that using this pattern function we get the support vector machine and I think but natural careful talk about support vector machines laser.",
                    "label": 0
                },
                {
                    "sent": "In one of the next days.",
                    "label": 0
                },
                {
                    "sent": "So and then let me talk about one last prob.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um, which is.",
                    "label": 0
                },
                {
                    "sent": "Which will lead to not a convex optimization problem with an angle value problem, which can also be solved efficiently.",
                    "label": 0
                },
                {
                    "sent": "So maybe you remember the first slide I showed where on top right of the slide that there was this cloud of points and we had a weight factor on which we projected the data points.",
                    "label": 0
                },
                {
                    "sent": "We obtained a large variance.",
                    "label": 0
                },
                {
                    "sent": "So how to solve this problem in practice?",
                    "label": 0
                },
                {
                    "sent": "So we want to find weight factor direction such that the data is projected on.",
                    "label": 0
                },
                {
                    "sent": "It has a large variance.",
                    "label": 0
                },
                {
                    "sent": "So our pattern function is going to be equal to the variance of this projection projection is X * W. That's it, and to prevent W to go to Infinity because we could.",
                    "label": 0
                },
                {
                    "sent": "Make this pattern function really large by just multiplying W with a very large real number.",
                    "label": 0
                },
                {
                    "sent": "To prevent W to go to Infinity, we just impose capacity constraints.",
                    "label": 0
                },
                {
                    "sent": "For the capacity, functional is equal to W transpose W, and this constraint can be anything just lower than or equal to 1.",
                    "label": 0
                },
                {
                    "sent": "It doesn't matter what exactly this number is, so then the pattern discovery problem is the maximization in this case, because you want to maximize the variance subject to an upper bounds on the norm of the video.",
                    "label": 0
                },
                {
                    "sent": "I say an upper bound, but in fact we can make it inequality because you can see that the optimum will always be reached for the inequality being strictly inequality.",
                    "label": 0
                },
                {
                    "sent": "So this is the same optimization problem again where I immediately wrote inequalities sign instead of an inequality.",
                    "label": 0
                },
                {
                    "sent": "Again, we are used.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You write down the Lagrangian, which is equal to this and we create a gradient with respect to W to 0.",
                    "label": 0
                },
                {
                    "sent": "And we obtain these as a result which is an added value problem.",
                    "label": 0
                },
                {
                    "sent": "As you might recognize, this is the covariance matrix and this is the eigenvalue and the solution you're looking for is a W, the eigenvector corresponding to the largest negative value, so it is nonconvex as I said.",
                    "label": 0
                },
                {
                    "sent": "But it is efficiently solvable, and I will talk more about eigenvalue problems in the next lecture in two days on Monday, I think.",
                    "label": 1
                },
                {
                    "sent": "So an important thing about all these patterns in continuous spaces and in metric spaces or.",
                    "label": 1
                },
                {
                    "sent": "Patterns in data sets is that the search space is actually exponential in the dimensionality of the weight vector, so the volume of the search phase exponential in the value and the dimensionality of this weight factor.",
                    "label": 0
                },
                {
                    "sent": "But still all these algorithms that I showed all this convex optimization algorithms also designer value problem that can be solved in polynomial time polynomial in the dimensionality and polynomial in the number of data points.",
                    "label": 0
                },
                {
                    "sent": "So this is in fact non trivial effect.",
                    "label": 0
                },
                {
                    "sent": "But which is very often the case in the cleverly designed algorithms.",
                    "label": 0
                },
                {
                    "sent": "So just to show principle component analysis on.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Example, so we did principle component analysis on all of the six variables.",
                    "label": 0
                },
                {
                    "sent": "Then when I put it here or the first principle components versus the second principle component for each of the data points.",
                    "label": 0
                },
                {
                    "sent": "No, what you cannot see, but I can tell you is that by just using these two principal components already 676% of the variance is captured, which means that the data is actually lying very close to the hyperplane spanned by the 1st and the 2nd principle component, and the rest can be somehow considered as unimportant noise.",
                    "label": 0
                },
                {
                    "sent": "So we can actually reduce the dimensionality of the data from 6 to 2.",
                    "label": 0
                },
                {
                    "sent": "If you look at what these two weight factors are for the first for the second principle component.",
                    "label": 0
                },
                {
                    "sent": "You can actually see that the first one corresponds to either bad or good weather, depending on whether you're on the left side or on the right side.",
                    "label": 0
                },
                {
                    "sent": "As you can see, the temperature is low.",
                    "label": 0
                },
                {
                    "sent": "Also, the Geo point was very correlated.",
                    "label": 0
                },
                {
                    "sent": "Many clouds, rainy inflow to Lake Shasta, which is currently to the precipitation and the wind is not so important in this case.",
                    "label": 0
                },
                {
                    "sent": "The second component it tells you how we need a wider is cause.",
                    "label": 0
                },
                {
                    "sent": "All these are quite OK.",
                    "label": 0
                },
                {
                    "sent": "This one is quite big, but this is really the prominent entry in the weight factor, so really tells you how windy.",
                    "label": 0
                },
                {
                    "sent": "And so this means that we can summarize the weather type basically based on whether it's good weather and whether it's windy weather.",
                    "label": 0
                },
                {
                    "sent": "So we can summarize the data in a very convenient way.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "To summarize, I tried to give a formalism for pattern analysis, which is of course not the best one, but it's just an attempt.",
                    "label": 0
                },
                {
                    "sent": "Maybe it's a way to try to.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Unified View and discrete pattern analysis and pattern analysis in continuous basis.",
                    "label": 1
                },
                {
                    "sent": "So I try to show that it's possible to see everything in this framework and.",
                    "label": 0
                },
                {
                    "sent": "Monday I will zoom in a bit on the eigenvalue problems.",
                    "label": 0
                },
                {
                    "sent": "To find patterns and sets.",
                    "label": 0
                },
                {
                    "sent": "That's it.",
                    "label": 0
                },
                {
                    "sent": "Questions.",
                    "label": 0
                },
                {
                    "sent": "What about your talking about?",
                    "label": 0
                },
                {
                    "sent": "Yeah so.",
                    "label": 0
                },
                {
                    "sent": "So for this overfitting, for example, this capacity functional, it really helps you in in reducing the search space and so in that sense it's algorithmically important, but it is also important because.",
                    "label": 0
                },
                {
                    "sent": "It helps you against overfitting because you selected the pattern from a more limited set of patterns and the two examples I gave you go.",
                    "label": 0
                },
                {
                    "sent": "You go to this one where I compared the scratching Russian against rich aggression.",
                    "label": 0
                },
                {
                    "sent": "You can see that in this case W was trained on 12 points.",
                    "label": 0
                },
                {
                    "sent": "And it was evaluated on all the other points on the test set, and you can see that indeed, please crash aggression seems to overfit a bit, while rich aggression.",
                    "label": 0
                },
                {
                    "sent": "That's so far that's awful.",
                    "label": 0
                },
                {
                    "sent": "Offer a small value of Lambda for small value of the regularization parameter, but does less overfitting for a non 0 value for Lambda.",
                    "label": 0
                },
                {
                    "sent": "So in fact this capacity functional use of this constraint on the pattern space or the limitation of this pattern space to a smaller subspace helps you against overfitting.",
                    "label": 0
                },
                {
                    "sent": "Can you work with the same framework if your function is not one dimensional that is not.",
                    "label": 0
                },
                {
                    "sent": "Are fucking awful.",
                    "label": 0
                },
                {
                    "sent": "So that would mean that you have several costs.",
                    "label": 0
                },
                {
                    "sent": "You want to optimize at the same time, right?",
                    "label": 0
                },
                {
                    "sent": "If you record yourself and report your results.",
                    "label": 0
                },
                {
                    "sent": "Weather indicator on the earth and I want to estimate the point on the earth for lab.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah, I think in the end it will always boil down to minimizing a cost function, which is, which is a real number in many cases.",
                    "label": 0
                },
                {
                    "sent": "So you know, maybe you want to minimize the difference between the prediction of two dimensional point and the two dimensional points.",
                    "label": 0
                },
                {
                    "sent": "The true value of observational points.",
                    "label": 0
                },
                {
                    "sent": "This will in the end be a norm or a distance, I would think.",
                    "label": 0
                },
                {
                    "sent": "So the pattern function is really a cost and maybe you can do multi objective optimization.",
                    "label": 0
                },
                {
                    "sent": "I don't know if.",
                    "label": 0
                },
                {
                    "sent": "Experience their own independence.",
                    "label": 0
                },
                {
                    "sent": "I don't want to work for the ground.",
                    "label": 0
                },
                {
                    "sent": "Work.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Maybe we can talk about it.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}