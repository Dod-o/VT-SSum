{
    "id": "tibejgb543hdson7ikqgi4blbt43ny7f",
    "title": "Linear Bellman Equations: Theory and Applications",
    "info": {
        "author": [
            "Emanuel Todorov, Department of Computer Science and Engineering, University of Washington"
        ],
        "published": "Jan. 19, 2010",
        "recorded": "December 2009",
        "category": [
            "Top->Computer Science->Machine Learning->Bayesian Learning"
        ]
    },
    "url": "http://videolectures.net/nipsworkshops09_todorov_lbeta/",
    "segmentation": [
        [
            "OK, so welcome to the afternoon half of the workshop.",
            "So as you probably know, this actually two workshops that got merged into one and they sort of have related topics.",
            "The afternoon part is sort of more focused on probabilistic approaches to stochastic optimal control, which a number of people are now beginning to use, and we're going to hear several talks on that topic, so I will start with giving somewhat of an overview and then going to some of our results.",
            "OK, so stochastic optimal control linear bellman questions?",
            "Some of this stuff is already published so I will not derive anything in gradita.",
            "I'll just sort of."
        ],
        [
            "We focus on our view and summarize things so it turns out that.",
            "It's very convenient to express the results in terms of the exponent of the optimal cost to go function.",
            "We're going to call that Z, and I'm calling the desirability function 'cause when the optimal cost to go is large, this becomes small, and vice versa.",
            "So you want this thing to be big.",
            "Basically, you can formulate these problems both in discrete time, an in continuous time, and they look very different.",
            "But at the end they turn out to be similar.",
            "So in both cases you have the notion of passive dynamics.",
            "Which is what the system wants to do when you're not controlling it in continuous time is just a diffusion process.",
            "In discrete time it can be anything you want.",
            "Then you have the control dynamics in continuous time.",
            "You just put you here and you can basically get to affect the drift of the diffusion process without affecting the noise.",
            "And notice that the control and the noise have to act in the same subspace.",
            "So that's a very important requirement for getting the math to work.",
            "In the discrete case, the controller gets to choose whatever probability distribution at once.",
            "Over next states.",
            "The only requirement is that if some transition is impossible here, if P of X prime given X is 0, then this also has to be zero.",
            "OK, so the passive dynamics constrains the transitions that you can take.",
            "But over those that have non zero probability you can play with the probabilities anywhere you want, and then you're going to incur some costs, which is a state cost that's called Q of X.",
            "Later that can be anything.",
            "And then the control cost is constrained.",
            "In the continuous time is just a familiar quadratic energy cost.",
            "You have to scale it by one over the Sigma squared or Sigma is noise magnitude.",
            "So again, this is important to get the math work.",
            "In the discrete case, is the Cal divergences between what the path dynamics work wants to do and what you want the system to do.",
            "So basically the system wants to do one thing.",
            "If you're pushing it away from its default behavior, you pay a bigger customer and then in both cases you end up defining linear operators that give you linear Bellman equations.",
            "In the continuous case, this is called a generator of the of the diffusion process.",
            "It basically the 2nd order differential operator.",
            "This is the gradient is the Hessian of some function.",
            "Z.",
            "What this gives you are the expected directional derivatives and the trajectory's arising from the passive dynamics.",
            "That's what generator really does in the discrete case you define this convolution with the passive dynamics.",
            "Basically this tells you started expect at state X what's the expected Z at the next state, and so these definitions.",
            "It turns out the Bellman equation written in terms of desirability function is linear.",
            "In the continuous case you get this forum.",
            "Basically the distribution function scaled by this state cost has to be go to this operator.",
            "In the discrete case you get something similar, but it's exponentiated and then you can get the control laws in closed form.",
            "Given the solution to those.",
            "About many questions, so this is reason for first exit problems.",
            "You can also do it for average cost and discounted cost and and finite horizon.",
            "The only case where you get no linear equations is the exponential discounted cost.",
            "The other 3 three linear.",
            "So you could ask what how I mean you can see that there are very close similarities here in the sense that both of these things end up being linear when you represent them.",
            "It's actually looking for awhile to figure out how they're related.",
            "And you can hear you understand the relationship.",
            "So this is a more general thing that you can take a limit and recover this and the way you do that is you start with this and you just get the time axis and you define the passive dynamics of some Gaussian which is centered at the current state plus time step H times the passive dynamics.",
            "The drift a here.",
            "And it has a good balance of growth with time and then the control probability distribution is the same thing that you added you.",
            "Now we can show the Cal divergences between those two is just the quadratic energy cost to head before another really important thing?",
            "Actually, which is the basis of this comparison?",
            "Is that this operator G in this operator error actually related.",
            "So L is in fact the derivative of G with respect to the time step, which is what I've written here, and so that's why you can basically take a limit of this and recover this.",
            "But you can also do a lot of things here that are not Gaussian or.",
            "Don't have continuous."
        ],
        [
            "Hammocks and such.",
            "Now for the rest of this talk, I'm going to work with with the discrete time continuous state.",
            "Formulation there is no preferred.",
            "The discrete time is Becausw 1.",
            "When you're simulating things that have contact dynamics, which is what I'm very interested in, the equations of motion are not very well defined in continuous time, because column friction is really nasty thing and you like if you look at all the modern like computer game engines, they use this complementarity formulations that really work in discrete time.",
            "The other reason is that I prefer to solve integral equations and differential equations because numerically they tend to be better behaved, but you can really go back and forth.",
            "OK so.",
            "So once you have a linear bounded question, you would expect that a lot of things will speed up, and it indeed they do.",
            "This is a little Karen Hill thing.",
            "Comparison between discretizing it on a dense grid and doing an both the States and the actions and then doing policy iteration.",
            "An is what you get.",
            "Framework which is discretized in the way I showed on next slide.",
            "We basically discretizing the state space but not the actions that is, the actual space doesn't need to be discretized, so if you look computationally what needs to happen.",
            "In our case we just have to solve a linear equation.",
            "This is the first exit problem or the game ends when you hit some.",
            "State correspond to parking lot in policy iteration.",
            "You have to solve a linear equation at each.",
            "Step of the iteration or to evaluate the current policy.",
            "Then you have to include improve the policy and that changes this.",
            "And besides, you would expect this thing will be faster.",
            "This just shows you so basically it's another banquet.",
            "Fasten policy iteration here.",
            "An validation is another order bank to slower for reasons that are beyond me."
        ],
        [
            "Now what I just showed you is discrete.",
            "Of course we can't discretize high dimensional state space is, so we want to sanction approximation and that's the main sort of part of the effort that we're making right now.",
            "But we had a poster somewhere over here that gives you details.",
            "You can look at it later if you want, but here's the idea we want to solve an equation in this form.",
            "Now I've written the equation for Infinite Horizon average cost case.",
            "So here what you do is.",
            "This is the Z of X.",
            "This is at the base is passive dynamics is the state cost.",
            "Lambda is the principle eigen.",
            "Value of this equation.",
            "You can show that the the negative log of that is the average cost per stage actually, so we want to solve this equation.",
            "It's a function of equation, right?",
            "It's linear, but still the unknown lives in some infinite dimensional function space.",
            "So to do anything numerical, you have to use some function approximator with a finite number of parameters.",
            "So we pick something that has a bunch of linear parameters doubloon and then some nonlinear parameters stated that are going to determine the locations and shapes of our basis functions.",
            "Now what I'm going to mention here are Gaussian basis were not pursuing other bases as well.",
            "Which types of bases that arise in locally weighted regression an also in meshless methods for solving PDS?",
            "If you're familiar with those, but they're implicit bases that have nice properties which you can look in our upcoming papers just focusing on Gaussians for now, so get exposed for bunch of Gaussians.",
            "What F is the Gaussian?",
            "And so this becomes a mixture of Gaussians, this piece Gaussian?",
            "Then we can do this integral analytically, which is the big advantage of Gaussians.",
            "You can also match by them by polynomials and still doing analytically.",
            "But it's good to be able to do this in closed form.",
            "And then what happens is that then you choose a bunch of so called colocation states where we want to enforce this equation.",
            "Ann, you reduce it to basically linear linear algebra problem.",
            "So W is unknown vector of weights for this Gaussian slam discipline spanking value and these matrices are known so we can solve that with generalized linear eigen solvers.",
            "If you also want to adapt the basis, which is probably a good idea, then you can do some sort of gradient descent on Theta an you need to define what is the quantity that you're trying to minimize, and one possibility is to just subtract the left and right hand side and square them.",
            "Another possibility, which about that that came up with this poster is shown here is to look at the KL Divergent between disting and this thing, and actually has some nice properties.",
            "So we can do that so."
        ],
        [
            "Here's a here's a simple problem.",
            "This is an inverted pendulum with joint limits.",
            "The task is to go either that were that were constant speed so the function keys shown here.",
            "It's basically good to move it at that last regardless, is stochastic trajectory samples from the optimal control law here is a very dense discretization grid 200 by 200, so this really is the optimal solution.",
            "This is the optimal control.",
            "This is a limit cycle.",
            "Notice that this thing is perfectly happy to live with discontinuity, so the pendulum moves and then it hits and then we lost.",
            "It drops to zero instantaneously, and then the controller.",
            "Up again, does it happen?",
            "Here's a solution shown with 40 adaptive Gaussian bases that are moved around with gradient descent.",
            "So both the means and covariances have been optimized with gradient descent.",
            "It takes.",
            "Takes about 20 iterations of some contract gradient method as I remember and you get pretty good things on that poster.",
            "Over there you Val has results with only eight Gaussians.",
            "There are fitting servering.",
            "That's so should look over there.",
            "This is the correct answer.",
            "This is the thing that he gets with the eight Gaussian, so we can actually get away with very small numbers of bases.",
            "And so."
        ],
        [
            "The question is how you move them around now.",
            "More general point here is that.",
            "Depends on how you place these basis functions.",
            "You can get algorithms that really have very different flavor, but using exactly the same map.",
            "So normally we talk about basis function approximation methods were thinking of some sort of approximate dynamic programming where we try to spend the whole state space or at least a pretty large regional state space and solve some equation over it.",
            "But you can do other things as well.",
            "For example, there's a thing called differential dynamic programming, which still remains one of the best methods for doing nonlinear optimal control.",
            "So what that says is stated the current state.",
            "Started the current state.",
            "Unroll some trajectory given the controller that you're currently considering, then do dynamic programming locally around that.",
            "In the case of GDP or the LPG matters that we've developed.",
            "That's you just using quadratic approximation to value function.",
            "Then you get a new controller and then that gives you a new trajectory and then you keep going.",
            "Well, here instead of using a quadratic function approximator, what we can do is like put a bunch of basis around that trajectory.",
            "Solve the problem exactly the same order to solving it before, except now you're just getting a solution that's valid locally and you don't know what's happening globally, but that's going to give your controller and then you can get another check, so that will be another alternative to DP like methods.",
            "Really nice property of this is that you no longer have a time you no longer have a Clock right in TDP.",
            "The problem is that everything is time based, so for example, if you want to do first exit problem with GPU can't because you have to pre specify the number of time steps here, it's all based on space so.",
            "There's no Clock.",
            "Another thing you can do is if you want to find optimal limit cycles for, let's say for locomotion, you won't find optimal gate for that kind of problem.",
            "DP is really bad 'cause it's very hard to enforce the constraint that you should go back.",
            "I mean one way to do it is to run the few times.",
            "But then there are various issues with that.",
            "Actually Tom errors, who is here, who has been has been dealing with those issues recently.",
            "People have been following the protocol space optimization which is basically says parameterized.",
            "Both the state and the control trajectory.",
            "Once you parameterise them, you can evaluate the cost and then you impose constraints which basically says that the dynamics have to be consistent and then you give this thing to some large scale optimizer an miraculously it works quite well.",
            "But that's kind of disturbing because it tells you that you can forget everything you know about optimal control theory and just use general purpose optimization.",
            "But sort of works.",
            "However, it gives you open loop control log doesn't tell you anything about feedback.",
            "Here we can if we scatter those bases around something.",
            "So for example, imagine building something like a little Conan map kind of thing.",
            "That's one dimensional mostly.",
            "So there is something that keeps them in a ring and then you solve for dosing using.",
            "Again, the matter showed you before, and then that tells you how to move there.",
            "So you can be very creative, but just by spacing these basic functions differently and get all kinds of different methods."
        ],
        [
            "Now, since these equations are linear, they have a compositionality property, so let me tell you what that is before I explain this slide, so supposed to have a first exit problem.",
            "And suppose I give you some final cost on the boundary, and you can solve the zero on the interior.",
            "Now I suppose I give you different final cost on the boundary and you solve the Z.",
            "Well now if you mix, the final costs were actually exponentiate final costs.",
            "The solutions are simply going to mix because it's a linear equation.",
            "That means that you can solve a bunch of optimal control problems.",
            "For the same dynamics and same boundary set but different final costs on the boundary.",
            "And now you can interpolate them and you can get infinitely many other optimal solutions to other optimal control problems.",
            "Mathematically, the way you do this is suppose this BFK is the cost on the boundary, where K is the number of the component you're dealing with.",
            "Exponentiate them, you mix them linearly, take the log and spouse.",
            "You have a final cause that's in this form.",
            "For example this address.",
            "This is a mixture of Gaussians, the logger mixture of Gaussians and then then the solution is just mix linearly with the same ones.",
            "So in particular, what that allows us to do is to extend the family.",
            "There could be problems, so now we can solve in closed form problems that have linear dynamics, quadratic running cost, but final calls that can be pretty much anything at once has to be the log of a Gaussian mixture, but that can approximate anything.",
            "Incidentally, on Popovich and colleagues who is somewhere here sort of developed this idea in parallel, and since they do computer graphics that have much better demo, so I'll leave it to him to to impress you."
        ],
        [
            "Anne.",
            "Now you can ask what what should these components be?",
            "I mean, if you want to find a small set of components that, then you're going to combine and get lower value things, how should you choose them?",
            "And well, one answer is that whatever you happen to solve, use it 'cause it's valid.",
            "But if you want to have a small set in some sense, what you can do well, we can notice that there is basically linear mapping between.",
            "This is on the boundary which is given to you and zero on the interior, and it's in the discrete case is given by some big matrix which acts like a Green's function.",
            "Basically it's an integral equation, but same thing applies.",
            "So green function is basically a mapping from the boundary to interior and then we can just do singular value decomposition on this matrix, and that's going to give us a like if you want to ask what is the.",
            "If you only can use 10 components, which one should you pick?",
            "Will just pick the top ten single values and this is what they look like.",
            "This is a little dynamical system I made up.",
            "This is the exit condition is the circle.",
            "This is some sort of obstacle.",
            "It cannot go through.",
            "So if you look at them you see that a few of them are kind of diffuse and they have effect everywhere.",
            "And then the order ones are only modulated near the boundary.",
            "So if you carry that, let's say 10, you're going to get a lot of accuracy away from the boundary and it will basically steer you in the right direction when you get close to the boundary.",
            "Then you need a lot more components to figure out what you do.",
            "But once you close to the boundary, you can probably do other things like GDP for example.",
            "So of course, that's just discrete.",
            "We still have to put that in the basis function."
        ],
        [
            "Framework we can do it with software control quite efficiently and there is a poster there which.",
            "Gives the details, but basically given a data set of transitions generated by an optimal controller.",
            "We can compute a log likelihood which depends on the unknown value function and that log likelihood depends basically on the passive dynamics, and then these A&B are the histograms of how many times we visited every state.",
            "One really interesting thing here is that the log like who doesn't actually depend on the precise transitions you made.",
            "It only depends on the distribution of states that you started to it and distribution of states that you went to after one step.",
            "So it's kind of interesting that function turns out to be convex, so it's very fast."
        ],
        [
            "To optimize.",
            "Here's some tests on grid worlds compared to other algorithms, and we basically outperformed by very large, so some orders of magnitude.",
            "We can.",
            "Most algorithms for inverse optimal control have been tested with features, so you pick a small number of features to represent your cost or value, and then you infer their weights.",
            "We can actually do that without features, so we can put one featured every state.",
            "So here these are discrete problems that are 100 by 100 grid, so had 10,000 features and we're solving for them in less than.",
            "Minute, actually a few seconds, because these learning curves converge very quickly.",
            "You can talk to my student DJ if you want to know the details of these comparisons."
        ],
        [
            "And finally, this turns out these problems are dual to Bayesian inference problems.",
            "So here's the duality.",
            "So this control estimation there dual to each other.",
            "This continuous and discrete.",
            "OK, so the control problem is what we had before the corresponding estimation problem.",
            "That is false in continuous time.",
            "You just have the passive dynamics without do you.",
            "And you have some observation which is nonlinear function of X.",
            "That measurement function has to be related to the state cost according to this equation.",
            "In discrete time you have you.",
            "Basically you have some hidden state that involves to whatever passive dynamics you want.",
            "You generate measurements according to whatever distribution you want.",
            "And then to make this to go, you have to set this Q of X equal to negative log of the generative distribution.",
            "So if you look here, you realize that the estimation problems are completely general.",
            "I mean, these are really the most general problems people usually study.",
            "The control problems are very straight there.",
            "Part of this specific framework, so among other things, this tells you that control is a much larger problem.",
            "Question, estimation, and basically all the estimation problems people work with Maps to a narrow set of control problems, which is the ones who happen to be dealing with now.",
            "What jewel means is that the posterior and estimation problem equals the state distribution energy optimal control law.",
            "The desirability function course is proportional to the backward filtering density, or rather the conditional probability of the future data given the current state followed.",
            "Filtering density corresponds to something that we don't really have a name for in control.",
            "If you look at that poster over there, it's called R and you can see the equation for it.",
            "So the R function and when you you could probably take advantage of this by using tricks for belief propagation to."
        ],
        [
            "Imation belief networks and get control.",
            "Lawson Markdown has really nice.",
            "Poster over there playing with such tricks and getting faster convergence than LPG or DP.",
            "OK, sorry bout going over time and thanks for listening.",
            "Yes.",
            "This.",
            "About the optimization with the cycle thing, so there's only disturbing like a pro away.",
            "Everything I know about off control I think yeah, So what you So what people have done is."
        ],
        [
            "Amateur eyes the sequence of States and the sequence of controls OK and then impose constraints which basically is given the current state of the current control.",
            "I want the next state given by my dynamics function to be whatever you parameterized, so this is the constraints and now compute the cost given those States and controls and just give that whole thing to a big nonlinear optimal constrained optimizer.",
            "And that actually works.",
            "I simply could not do that with.",
            "I mean, could I do that normally under no that's why I said you don't know anything about control theory to do that.",
            "No, it's not the linear thing you need to know a lot about control theory today, so it's more reassuring in that way.",
            "Anything else?",
            "Is it possible to extend this linear insolvable market decision process?",
            "Verizon discount.",
            "Says it does.",
            "The linearity linearity preserve when actually for the discounted case it becomes nonlinear for the infinite Horizon average cost case it is linear and it looks like."
        ],
        [
            "This.",
            "So this is if it has an average cost.",
            "This is the exponent of the average cost.",
            "If you want to make it discounted, it becomes nonlinear.",
            "What happens is that this thing is raised to the power of Alpha, where Alpha is your discount factor.",
            "Actually linear cases.",
            "Is linear linear?",
            "Like a value problem has fixed point and we can just easily created.",
            "I'm find that explain what happened in the actually discover case he's asleep.",
            "You have a fixed point, we can.",
            "Is it possible so you can do the equivalent of power iteration and it seems to converge happily.",
            "I have no idea how to prove that it will converge, but it does.",
            "There is no because I read the 2006 paper and.",
            "Yeah, it's converted converge but but I want to.",
            "Yeah, I mean I haven't.",
            "I don't think we have so.",
            "Yeah, I don't think we have any analytical designs that tell you when it's going to commercialize converges.",
            "It seems to do.",
            "I mean, I. I personally don't like discounted things very much because they seem to be a gimmick that doesn't correspond to anything.",
            "I believe.",
            "I mean, if you want to do in horizon you should do average costs far as I'm concerned.",
            "'cause that's the sensible cost function.",
            "OK, next speaker is Bert Kappen who.",
            "Is."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so welcome to the afternoon half of the workshop.",
                    "label": 0
                },
                {
                    "sent": "So as you probably know, this actually two workshops that got merged into one and they sort of have related topics.",
                    "label": 0
                },
                {
                    "sent": "The afternoon part is sort of more focused on probabilistic approaches to stochastic optimal control, which a number of people are now beginning to use, and we're going to hear several talks on that topic, so I will start with giving somewhat of an overview and then going to some of our results.",
                    "label": 0
                },
                {
                    "sent": "OK, so stochastic optimal control linear bellman questions?",
                    "label": 1
                },
                {
                    "sent": "Some of this stuff is already published so I will not derive anything in gradita.",
                    "label": 0
                },
                {
                    "sent": "I'll just sort of.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We focus on our view and summarize things so it turns out that.",
                    "label": 0
                },
                {
                    "sent": "It's very convenient to express the results in terms of the exponent of the optimal cost to go function.",
                    "label": 0
                },
                {
                    "sent": "We're going to call that Z, and I'm calling the desirability function 'cause when the optimal cost to go is large, this becomes small, and vice versa.",
                    "label": 0
                },
                {
                    "sent": "So you want this thing to be big.",
                    "label": 0
                },
                {
                    "sent": "Basically, you can formulate these problems both in discrete time, an in continuous time, and they look very different.",
                    "label": 0
                },
                {
                    "sent": "But at the end they turn out to be similar.",
                    "label": 0
                },
                {
                    "sent": "So in both cases you have the notion of passive dynamics.",
                    "label": 0
                },
                {
                    "sent": "Which is what the system wants to do when you're not controlling it in continuous time is just a diffusion process.",
                    "label": 0
                },
                {
                    "sent": "In discrete time it can be anything you want.",
                    "label": 0
                },
                {
                    "sent": "Then you have the control dynamics in continuous time.",
                    "label": 0
                },
                {
                    "sent": "You just put you here and you can basically get to affect the drift of the diffusion process without affecting the noise.",
                    "label": 0
                },
                {
                    "sent": "And notice that the control and the noise have to act in the same subspace.",
                    "label": 0
                },
                {
                    "sent": "So that's a very important requirement for getting the math to work.",
                    "label": 0
                },
                {
                    "sent": "In the discrete case, the controller gets to choose whatever probability distribution at once.",
                    "label": 0
                },
                {
                    "sent": "Over next states.",
                    "label": 0
                },
                {
                    "sent": "The only requirement is that if some transition is impossible here, if P of X prime given X is 0, then this also has to be zero.",
                    "label": 0
                },
                {
                    "sent": "OK, so the passive dynamics constrains the transitions that you can take.",
                    "label": 0
                },
                {
                    "sent": "But over those that have non zero probability you can play with the probabilities anywhere you want, and then you're going to incur some costs, which is a state cost that's called Q of X.",
                    "label": 0
                },
                {
                    "sent": "Later that can be anything.",
                    "label": 0
                },
                {
                    "sent": "And then the control cost is constrained.",
                    "label": 0
                },
                {
                    "sent": "In the continuous time is just a familiar quadratic energy cost.",
                    "label": 0
                },
                {
                    "sent": "You have to scale it by one over the Sigma squared or Sigma is noise magnitude.",
                    "label": 0
                },
                {
                    "sent": "So again, this is important to get the math work.",
                    "label": 0
                },
                {
                    "sent": "In the discrete case, is the Cal divergences between what the path dynamics work wants to do and what you want the system to do.",
                    "label": 0
                },
                {
                    "sent": "So basically the system wants to do one thing.",
                    "label": 0
                },
                {
                    "sent": "If you're pushing it away from its default behavior, you pay a bigger customer and then in both cases you end up defining linear operators that give you linear Bellman equations.",
                    "label": 0
                },
                {
                    "sent": "In the continuous case, this is called a generator of the of the diffusion process.",
                    "label": 0
                },
                {
                    "sent": "It basically the 2nd order differential operator.",
                    "label": 0
                },
                {
                    "sent": "This is the gradient is the Hessian of some function.",
                    "label": 0
                },
                {
                    "sent": "Z.",
                    "label": 0
                },
                {
                    "sent": "What this gives you are the expected directional derivatives and the trajectory's arising from the passive dynamics.",
                    "label": 0
                },
                {
                    "sent": "That's what generator really does in the discrete case you define this convolution with the passive dynamics.",
                    "label": 0
                },
                {
                    "sent": "Basically this tells you started expect at state X what's the expected Z at the next state, and so these definitions.",
                    "label": 0
                },
                {
                    "sent": "It turns out the Bellman equation written in terms of desirability function is linear.",
                    "label": 0
                },
                {
                    "sent": "In the continuous case you get this forum.",
                    "label": 0
                },
                {
                    "sent": "Basically the distribution function scaled by this state cost has to be go to this operator.",
                    "label": 0
                },
                {
                    "sent": "In the discrete case you get something similar, but it's exponentiated and then you can get the control laws in closed form.",
                    "label": 0
                },
                {
                    "sent": "Given the solution to those.",
                    "label": 0
                },
                {
                    "sent": "About many questions, so this is reason for first exit problems.",
                    "label": 0
                },
                {
                    "sent": "You can also do it for average cost and discounted cost and and finite horizon.",
                    "label": 0
                },
                {
                    "sent": "The only case where you get no linear equations is the exponential discounted cost.",
                    "label": 0
                },
                {
                    "sent": "The other 3 three linear.",
                    "label": 0
                },
                {
                    "sent": "So you could ask what how I mean you can see that there are very close similarities here in the sense that both of these things end up being linear when you represent them.",
                    "label": 0
                },
                {
                    "sent": "It's actually looking for awhile to figure out how they're related.",
                    "label": 0
                },
                {
                    "sent": "And you can hear you understand the relationship.",
                    "label": 0
                },
                {
                    "sent": "So this is a more general thing that you can take a limit and recover this and the way you do that is you start with this and you just get the time axis and you define the passive dynamics of some Gaussian which is centered at the current state plus time step H times the passive dynamics.",
                    "label": 0
                },
                {
                    "sent": "The drift a here.",
                    "label": 0
                },
                {
                    "sent": "And it has a good balance of growth with time and then the control probability distribution is the same thing that you added you.",
                    "label": 0
                },
                {
                    "sent": "Now we can show the Cal divergences between those two is just the quadratic energy cost to head before another really important thing?",
                    "label": 0
                },
                {
                    "sent": "Actually, which is the basis of this comparison?",
                    "label": 0
                },
                {
                    "sent": "Is that this operator G in this operator error actually related.",
                    "label": 0
                },
                {
                    "sent": "So L is in fact the derivative of G with respect to the time step, which is what I've written here, and so that's why you can basically take a limit of this and recover this.",
                    "label": 0
                },
                {
                    "sent": "But you can also do a lot of things here that are not Gaussian or.",
                    "label": 0
                },
                {
                    "sent": "Don't have continuous.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Hammocks and such.",
                    "label": 0
                },
                {
                    "sent": "Now for the rest of this talk, I'm going to work with with the discrete time continuous state.",
                    "label": 0
                },
                {
                    "sent": "Formulation there is no preferred.",
                    "label": 0
                },
                {
                    "sent": "The discrete time is Becausw 1.",
                    "label": 0
                },
                {
                    "sent": "When you're simulating things that have contact dynamics, which is what I'm very interested in, the equations of motion are not very well defined in continuous time, because column friction is really nasty thing and you like if you look at all the modern like computer game engines, they use this complementarity formulations that really work in discrete time.",
                    "label": 0
                },
                {
                    "sent": "The other reason is that I prefer to solve integral equations and differential equations because numerically they tend to be better behaved, but you can really go back and forth.",
                    "label": 0
                },
                {
                    "sent": "OK so.",
                    "label": 0
                },
                {
                    "sent": "So once you have a linear bounded question, you would expect that a lot of things will speed up, and it indeed they do.",
                    "label": 0
                },
                {
                    "sent": "This is a little Karen Hill thing.",
                    "label": 0
                },
                {
                    "sent": "Comparison between discretizing it on a dense grid and doing an both the States and the actions and then doing policy iteration.",
                    "label": 0
                },
                {
                    "sent": "An is what you get.",
                    "label": 0
                },
                {
                    "sent": "Framework which is discretized in the way I showed on next slide.",
                    "label": 0
                },
                {
                    "sent": "We basically discretizing the state space but not the actions that is, the actual space doesn't need to be discretized, so if you look computationally what needs to happen.",
                    "label": 0
                },
                {
                    "sent": "In our case we just have to solve a linear equation.",
                    "label": 0
                },
                {
                    "sent": "This is the first exit problem or the game ends when you hit some.",
                    "label": 0
                },
                {
                    "sent": "State correspond to parking lot in policy iteration.",
                    "label": 1
                },
                {
                    "sent": "You have to solve a linear equation at each.",
                    "label": 0
                },
                {
                    "sent": "Step of the iteration or to evaluate the current policy.",
                    "label": 0
                },
                {
                    "sent": "Then you have to include improve the policy and that changes this.",
                    "label": 0
                },
                {
                    "sent": "And besides, you would expect this thing will be faster.",
                    "label": 0
                },
                {
                    "sent": "This just shows you so basically it's another banquet.",
                    "label": 0
                },
                {
                    "sent": "Fasten policy iteration here.",
                    "label": 0
                },
                {
                    "sent": "An validation is another order bank to slower for reasons that are beyond me.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now what I just showed you is discrete.",
                    "label": 0
                },
                {
                    "sent": "Of course we can't discretize high dimensional state space is, so we want to sanction approximation and that's the main sort of part of the effort that we're making right now.",
                    "label": 0
                },
                {
                    "sent": "But we had a poster somewhere over here that gives you details.",
                    "label": 0
                },
                {
                    "sent": "You can look at it later if you want, but here's the idea we want to solve an equation in this form.",
                    "label": 0
                },
                {
                    "sent": "Now I've written the equation for Infinite Horizon average cost case.",
                    "label": 0
                },
                {
                    "sent": "So here what you do is.",
                    "label": 0
                },
                {
                    "sent": "This is the Z of X.",
                    "label": 0
                },
                {
                    "sent": "This is at the base is passive dynamics is the state cost.",
                    "label": 0
                },
                {
                    "sent": "Lambda is the principle eigen.",
                    "label": 0
                },
                {
                    "sent": "Value of this equation.",
                    "label": 0
                },
                {
                    "sent": "You can show that the the negative log of that is the average cost per stage actually, so we want to solve this equation.",
                    "label": 0
                },
                {
                    "sent": "It's a function of equation, right?",
                    "label": 0
                },
                {
                    "sent": "It's linear, but still the unknown lives in some infinite dimensional function space.",
                    "label": 0
                },
                {
                    "sent": "So to do anything numerical, you have to use some function approximator with a finite number of parameters.",
                    "label": 0
                },
                {
                    "sent": "So we pick something that has a bunch of linear parameters doubloon and then some nonlinear parameters stated that are going to determine the locations and shapes of our basis functions.",
                    "label": 0
                },
                {
                    "sent": "Now what I'm going to mention here are Gaussian basis were not pursuing other bases as well.",
                    "label": 0
                },
                {
                    "sent": "Which types of bases that arise in locally weighted regression an also in meshless methods for solving PDS?",
                    "label": 0
                },
                {
                    "sent": "If you're familiar with those, but they're implicit bases that have nice properties which you can look in our upcoming papers just focusing on Gaussians for now, so get exposed for bunch of Gaussians.",
                    "label": 0
                },
                {
                    "sent": "What F is the Gaussian?",
                    "label": 0
                },
                {
                    "sent": "And so this becomes a mixture of Gaussians, this piece Gaussian?",
                    "label": 0
                },
                {
                    "sent": "Then we can do this integral analytically, which is the big advantage of Gaussians.",
                    "label": 0
                },
                {
                    "sent": "You can also match by them by polynomials and still doing analytically.",
                    "label": 0
                },
                {
                    "sent": "But it's good to be able to do this in closed form.",
                    "label": 0
                },
                {
                    "sent": "And then what happens is that then you choose a bunch of so called colocation states where we want to enforce this equation.",
                    "label": 0
                },
                {
                    "sent": "Ann, you reduce it to basically linear linear algebra problem.",
                    "label": 0
                },
                {
                    "sent": "So W is unknown vector of weights for this Gaussian slam discipline spanking value and these matrices are known so we can solve that with generalized linear eigen solvers.",
                    "label": 0
                },
                {
                    "sent": "If you also want to adapt the basis, which is probably a good idea, then you can do some sort of gradient descent on Theta an you need to define what is the quantity that you're trying to minimize, and one possibility is to just subtract the left and right hand side and square them.",
                    "label": 0
                },
                {
                    "sent": "Another possibility, which about that that came up with this poster is shown here is to look at the KL Divergent between disting and this thing, and actually has some nice properties.",
                    "label": 0
                },
                {
                    "sent": "So we can do that so.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here's a here's a simple problem.",
                    "label": 0
                },
                {
                    "sent": "This is an inverted pendulum with joint limits.",
                    "label": 0
                },
                {
                    "sent": "The task is to go either that were that were constant speed so the function keys shown here.",
                    "label": 0
                },
                {
                    "sent": "It's basically good to move it at that last regardless, is stochastic trajectory samples from the optimal control law here is a very dense discretization grid 200 by 200, so this really is the optimal solution.",
                    "label": 0
                },
                {
                    "sent": "This is the optimal control.",
                    "label": 0
                },
                {
                    "sent": "This is a limit cycle.",
                    "label": 0
                },
                {
                    "sent": "Notice that this thing is perfectly happy to live with discontinuity, so the pendulum moves and then it hits and then we lost.",
                    "label": 0
                },
                {
                    "sent": "It drops to zero instantaneously, and then the controller.",
                    "label": 0
                },
                {
                    "sent": "Up again, does it happen?",
                    "label": 0
                },
                {
                    "sent": "Here's a solution shown with 40 adaptive Gaussian bases that are moved around with gradient descent.",
                    "label": 1
                },
                {
                    "sent": "So both the means and covariances have been optimized with gradient descent.",
                    "label": 0
                },
                {
                    "sent": "It takes.",
                    "label": 0
                },
                {
                    "sent": "Takes about 20 iterations of some contract gradient method as I remember and you get pretty good things on that poster.",
                    "label": 0
                },
                {
                    "sent": "Over there you Val has results with only eight Gaussians.",
                    "label": 0
                },
                {
                    "sent": "There are fitting servering.",
                    "label": 0
                },
                {
                    "sent": "That's so should look over there.",
                    "label": 0
                },
                {
                    "sent": "This is the correct answer.",
                    "label": 0
                },
                {
                    "sent": "This is the thing that he gets with the eight Gaussian, so we can actually get away with very small numbers of bases.",
                    "label": 0
                },
                {
                    "sent": "And so.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The question is how you move them around now.",
                    "label": 0
                },
                {
                    "sent": "More general point here is that.",
                    "label": 0
                },
                {
                    "sent": "Depends on how you place these basis functions.",
                    "label": 0
                },
                {
                    "sent": "You can get algorithms that really have very different flavor, but using exactly the same map.",
                    "label": 0
                },
                {
                    "sent": "So normally we talk about basis function approximation methods were thinking of some sort of approximate dynamic programming where we try to spend the whole state space or at least a pretty large regional state space and solve some equation over it.",
                    "label": 1
                },
                {
                    "sent": "But you can do other things as well.",
                    "label": 0
                },
                {
                    "sent": "For example, there's a thing called differential dynamic programming, which still remains one of the best methods for doing nonlinear optimal control.",
                    "label": 0
                },
                {
                    "sent": "So what that says is stated the current state.",
                    "label": 0
                },
                {
                    "sent": "Started the current state.",
                    "label": 0
                },
                {
                    "sent": "Unroll some trajectory given the controller that you're currently considering, then do dynamic programming locally around that.",
                    "label": 0
                },
                {
                    "sent": "In the case of GDP or the LPG matters that we've developed.",
                    "label": 0
                },
                {
                    "sent": "That's you just using quadratic approximation to value function.",
                    "label": 0
                },
                {
                    "sent": "Then you get a new controller and then that gives you a new trajectory and then you keep going.",
                    "label": 0
                },
                {
                    "sent": "Well, here instead of using a quadratic function approximator, what we can do is like put a bunch of basis around that trajectory.",
                    "label": 0
                },
                {
                    "sent": "Solve the problem exactly the same order to solving it before, except now you're just getting a solution that's valid locally and you don't know what's happening globally, but that's going to give your controller and then you can get another check, so that will be another alternative to DP like methods.",
                    "label": 0
                },
                {
                    "sent": "Really nice property of this is that you no longer have a time you no longer have a Clock right in TDP.",
                    "label": 0
                },
                {
                    "sent": "The problem is that everything is time based, so for example, if you want to do first exit problem with GPU can't because you have to pre specify the number of time steps here, it's all based on space so.",
                    "label": 0
                },
                {
                    "sent": "There's no Clock.",
                    "label": 0
                },
                {
                    "sent": "Another thing you can do is if you want to find optimal limit cycles for, let's say for locomotion, you won't find optimal gate for that kind of problem.",
                    "label": 0
                },
                {
                    "sent": "DP is really bad 'cause it's very hard to enforce the constraint that you should go back.",
                    "label": 0
                },
                {
                    "sent": "I mean one way to do it is to run the few times.",
                    "label": 0
                },
                {
                    "sent": "But then there are various issues with that.",
                    "label": 0
                },
                {
                    "sent": "Actually Tom errors, who is here, who has been has been dealing with those issues recently.",
                    "label": 0
                },
                {
                    "sent": "People have been following the protocol space optimization which is basically says parameterized.",
                    "label": 0
                },
                {
                    "sent": "Both the state and the control trajectory.",
                    "label": 0
                },
                {
                    "sent": "Once you parameterise them, you can evaluate the cost and then you impose constraints which basically says that the dynamics have to be consistent and then you give this thing to some large scale optimizer an miraculously it works quite well.",
                    "label": 0
                },
                {
                    "sent": "But that's kind of disturbing because it tells you that you can forget everything you know about optimal control theory and just use general purpose optimization.",
                    "label": 0
                },
                {
                    "sent": "But sort of works.",
                    "label": 0
                },
                {
                    "sent": "However, it gives you open loop control log doesn't tell you anything about feedback.",
                    "label": 0
                },
                {
                    "sent": "Here we can if we scatter those bases around something.",
                    "label": 0
                },
                {
                    "sent": "So for example, imagine building something like a little Conan map kind of thing.",
                    "label": 0
                },
                {
                    "sent": "That's one dimensional mostly.",
                    "label": 0
                },
                {
                    "sent": "So there is something that keeps them in a ring and then you solve for dosing using.",
                    "label": 0
                },
                {
                    "sent": "Again, the matter showed you before, and then that tells you how to move there.",
                    "label": 0
                },
                {
                    "sent": "So you can be very creative, but just by spacing these basic functions differently and get all kinds of different methods.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now, since these equations are linear, they have a compositionality property, so let me tell you what that is before I explain this slide, so supposed to have a first exit problem.",
                    "label": 0
                },
                {
                    "sent": "And suppose I give you some final cost on the boundary, and you can solve the zero on the interior.",
                    "label": 0
                },
                {
                    "sent": "Now I suppose I give you different final cost on the boundary and you solve the Z.",
                    "label": 0
                },
                {
                    "sent": "Well now if you mix, the final costs were actually exponentiate final costs.",
                    "label": 1
                },
                {
                    "sent": "The solutions are simply going to mix because it's a linear equation.",
                    "label": 0
                },
                {
                    "sent": "That means that you can solve a bunch of optimal control problems.",
                    "label": 1
                },
                {
                    "sent": "For the same dynamics and same boundary set but different final costs on the boundary.",
                    "label": 0
                },
                {
                    "sent": "And now you can interpolate them and you can get infinitely many other optimal solutions to other optimal control problems.",
                    "label": 0
                },
                {
                    "sent": "Mathematically, the way you do this is suppose this BFK is the cost on the boundary, where K is the number of the component you're dealing with.",
                    "label": 0
                },
                {
                    "sent": "Exponentiate them, you mix them linearly, take the log and spouse.",
                    "label": 0
                },
                {
                    "sent": "You have a final cause that's in this form.",
                    "label": 0
                },
                {
                    "sent": "For example this address.",
                    "label": 0
                },
                {
                    "sent": "This is a mixture of Gaussians, the logger mixture of Gaussians and then then the solution is just mix linearly with the same ones.",
                    "label": 0
                },
                {
                    "sent": "So in particular, what that allows us to do is to extend the family.",
                    "label": 0
                },
                {
                    "sent": "There could be problems, so now we can solve in closed form problems that have linear dynamics, quadratic running cost, but final calls that can be pretty much anything at once has to be the log of a Gaussian mixture, but that can approximate anything.",
                    "label": 0
                },
                {
                    "sent": "Incidentally, on Popovich and colleagues who is somewhere here sort of developed this idea in parallel, and since they do computer graphics that have much better demo, so I'll leave it to him to to impress you.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "Now you can ask what what should these components be?",
                    "label": 0
                },
                {
                    "sent": "I mean, if you want to find a small set of components that, then you're going to combine and get lower value things, how should you choose them?",
                    "label": 0
                },
                {
                    "sent": "And well, one answer is that whatever you happen to solve, use it 'cause it's valid.",
                    "label": 0
                },
                {
                    "sent": "But if you want to have a small set in some sense, what you can do well, we can notice that there is basically linear mapping between.",
                    "label": 0
                },
                {
                    "sent": "This is on the boundary which is given to you and zero on the interior, and it's in the discrete case is given by some big matrix which acts like a Green's function.",
                    "label": 0
                },
                {
                    "sent": "Basically it's an integral equation, but same thing applies.",
                    "label": 0
                },
                {
                    "sent": "So green function is basically a mapping from the boundary to interior and then we can just do singular value decomposition on this matrix, and that's going to give us a like if you want to ask what is the.",
                    "label": 0
                },
                {
                    "sent": "If you only can use 10 components, which one should you pick?",
                    "label": 0
                },
                {
                    "sent": "Will just pick the top ten single values and this is what they look like.",
                    "label": 0
                },
                {
                    "sent": "This is a little dynamical system I made up.",
                    "label": 0
                },
                {
                    "sent": "This is the exit condition is the circle.",
                    "label": 0
                },
                {
                    "sent": "This is some sort of obstacle.",
                    "label": 0
                },
                {
                    "sent": "It cannot go through.",
                    "label": 0
                },
                {
                    "sent": "So if you look at them you see that a few of them are kind of diffuse and they have effect everywhere.",
                    "label": 0
                },
                {
                    "sent": "And then the order ones are only modulated near the boundary.",
                    "label": 0
                },
                {
                    "sent": "So if you carry that, let's say 10, you're going to get a lot of accuracy away from the boundary and it will basically steer you in the right direction when you get close to the boundary.",
                    "label": 0
                },
                {
                    "sent": "Then you need a lot more components to figure out what you do.",
                    "label": 0
                },
                {
                    "sent": "But once you close to the boundary, you can probably do other things like GDP for example.",
                    "label": 0
                },
                {
                    "sent": "So of course, that's just discrete.",
                    "label": 0
                },
                {
                    "sent": "We still have to put that in the basis function.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Framework we can do it with software control quite efficiently and there is a poster there which.",
                    "label": 0
                },
                {
                    "sent": "Gives the details, but basically given a data set of transitions generated by an optimal controller.",
                    "label": 0
                },
                {
                    "sent": "We can compute a log likelihood which depends on the unknown value function and that log likelihood depends basically on the passive dynamics, and then these A&B are the histograms of how many times we visited every state.",
                    "label": 0
                },
                {
                    "sent": "One really interesting thing here is that the log like who doesn't actually depend on the precise transitions you made.",
                    "label": 0
                },
                {
                    "sent": "It only depends on the distribution of states that you started to it and distribution of states that you went to after one step.",
                    "label": 0
                },
                {
                    "sent": "So it's kind of interesting that function turns out to be convex, so it's very fast.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To optimize.",
                    "label": 0
                },
                {
                    "sent": "Here's some tests on grid worlds compared to other algorithms, and we basically outperformed by very large, so some orders of magnitude.",
                    "label": 0
                },
                {
                    "sent": "We can.",
                    "label": 0
                },
                {
                    "sent": "Most algorithms for inverse optimal control have been tested with features, so you pick a small number of features to represent your cost or value, and then you infer their weights.",
                    "label": 0
                },
                {
                    "sent": "We can actually do that without features, so we can put one featured every state.",
                    "label": 0
                },
                {
                    "sent": "So here these are discrete problems that are 100 by 100 grid, so had 10,000 features and we're solving for them in less than.",
                    "label": 0
                },
                {
                    "sent": "Minute, actually a few seconds, because these learning curves converge very quickly.",
                    "label": 0
                },
                {
                    "sent": "You can talk to my student DJ if you want to know the details of these comparisons.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And finally, this turns out these problems are dual to Bayesian inference problems.",
                    "label": 1
                },
                {
                    "sent": "So here's the duality.",
                    "label": 0
                },
                {
                    "sent": "So this control estimation there dual to each other.",
                    "label": 1
                },
                {
                    "sent": "This continuous and discrete.",
                    "label": 0
                },
                {
                    "sent": "OK, so the control problem is what we had before the corresponding estimation problem.",
                    "label": 0
                },
                {
                    "sent": "That is false in continuous time.",
                    "label": 0
                },
                {
                    "sent": "You just have the passive dynamics without do you.",
                    "label": 0
                },
                {
                    "sent": "And you have some observation which is nonlinear function of X.",
                    "label": 0
                },
                {
                    "sent": "That measurement function has to be related to the state cost according to this equation.",
                    "label": 0
                },
                {
                    "sent": "In discrete time you have you.",
                    "label": 0
                },
                {
                    "sent": "Basically you have some hidden state that involves to whatever passive dynamics you want.",
                    "label": 0
                },
                {
                    "sent": "You generate measurements according to whatever distribution you want.",
                    "label": 0
                },
                {
                    "sent": "And then to make this to go, you have to set this Q of X equal to negative log of the generative distribution.",
                    "label": 0
                },
                {
                    "sent": "So if you look here, you realize that the estimation problems are completely general.",
                    "label": 0
                },
                {
                    "sent": "I mean, these are really the most general problems people usually study.",
                    "label": 0
                },
                {
                    "sent": "The control problems are very straight there.",
                    "label": 0
                },
                {
                    "sent": "Part of this specific framework, so among other things, this tells you that control is a much larger problem.",
                    "label": 0
                },
                {
                    "sent": "Question, estimation, and basically all the estimation problems people work with Maps to a narrow set of control problems, which is the ones who happen to be dealing with now.",
                    "label": 0
                },
                {
                    "sent": "What jewel means is that the posterior and estimation problem equals the state distribution energy optimal control law.",
                    "label": 0
                },
                {
                    "sent": "The desirability function course is proportional to the backward filtering density, or rather the conditional probability of the future data given the current state followed.",
                    "label": 1
                },
                {
                    "sent": "Filtering density corresponds to something that we don't really have a name for in control.",
                    "label": 0
                },
                {
                    "sent": "If you look at that poster over there, it's called R and you can see the equation for it.",
                    "label": 0
                },
                {
                    "sent": "So the R function and when you you could probably take advantage of this by using tricks for belief propagation to.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Imation belief networks and get control.",
                    "label": 0
                },
                {
                    "sent": "Lawson Markdown has really nice.",
                    "label": 0
                },
                {
                    "sent": "Poster over there playing with such tricks and getting faster convergence than LPG or DP.",
                    "label": 0
                },
                {
                    "sent": "OK, sorry bout going over time and thanks for listening.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "This.",
                    "label": 0
                },
                {
                    "sent": "About the optimization with the cycle thing, so there's only disturbing like a pro away.",
                    "label": 0
                },
                {
                    "sent": "Everything I know about off control I think yeah, So what you So what people have done is.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Amateur eyes the sequence of States and the sequence of controls OK and then impose constraints which basically is given the current state of the current control.",
                    "label": 0
                },
                {
                    "sent": "I want the next state given by my dynamics function to be whatever you parameterized, so this is the constraints and now compute the cost given those States and controls and just give that whole thing to a big nonlinear optimal constrained optimizer.",
                    "label": 0
                },
                {
                    "sent": "And that actually works.",
                    "label": 0
                },
                {
                    "sent": "I simply could not do that with.",
                    "label": 0
                },
                {
                    "sent": "I mean, could I do that normally under no that's why I said you don't know anything about control theory to do that.",
                    "label": 0
                },
                {
                    "sent": "No, it's not the linear thing you need to know a lot about control theory today, so it's more reassuring in that way.",
                    "label": 0
                },
                {
                    "sent": "Anything else?",
                    "label": 0
                },
                {
                    "sent": "Is it possible to extend this linear insolvable market decision process?",
                    "label": 0
                },
                {
                    "sent": "Verizon discount.",
                    "label": 0
                },
                {
                    "sent": "Says it does.",
                    "label": 0
                },
                {
                    "sent": "The linearity linearity preserve when actually for the discounted case it becomes nonlinear for the infinite Horizon average cost case it is linear and it looks like.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This.",
                    "label": 0
                },
                {
                    "sent": "So this is if it has an average cost.",
                    "label": 0
                },
                {
                    "sent": "This is the exponent of the average cost.",
                    "label": 0
                },
                {
                    "sent": "If you want to make it discounted, it becomes nonlinear.",
                    "label": 0
                },
                {
                    "sent": "What happens is that this thing is raised to the power of Alpha, where Alpha is your discount factor.",
                    "label": 0
                },
                {
                    "sent": "Actually linear cases.",
                    "label": 0
                },
                {
                    "sent": "Is linear linear?",
                    "label": 0
                },
                {
                    "sent": "Like a value problem has fixed point and we can just easily created.",
                    "label": 0
                },
                {
                    "sent": "I'm find that explain what happened in the actually discover case he's asleep.",
                    "label": 0
                },
                {
                    "sent": "You have a fixed point, we can.",
                    "label": 0
                },
                {
                    "sent": "Is it possible so you can do the equivalent of power iteration and it seems to converge happily.",
                    "label": 0
                },
                {
                    "sent": "I have no idea how to prove that it will converge, but it does.",
                    "label": 0
                },
                {
                    "sent": "There is no because I read the 2006 paper and.",
                    "label": 0
                },
                {
                    "sent": "Yeah, it's converted converge but but I want to.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I mean I haven't.",
                    "label": 0
                },
                {
                    "sent": "I don't think we have so.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I don't think we have any analytical designs that tell you when it's going to commercialize converges.",
                    "label": 0
                },
                {
                    "sent": "It seems to do.",
                    "label": 0
                },
                {
                    "sent": "I mean, I. I personally don't like discounted things very much because they seem to be a gimmick that doesn't correspond to anything.",
                    "label": 0
                },
                {
                    "sent": "I believe.",
                    "label": 0
                },
                {
                    "sent": "I mean, if you want to do in horizon you should do average costs far as I'm concerned.",
                    "label": 0
                },
                {
                    "sent": "'cause that's the sensible cost function.",
                    "label": 0
                },
                {
                    "sent": "OK, next speaker is Bert Kappen who.",
                    "label": 0
                },
                {
                    "sent": "Is.",
                    "label": 0
                }
            ]
        }
    }
}