{
    "id": "i53tdkybtww3dztsfckqudoi72ebwxjn",
    "title": "Ontology-Based Data Access Using Rewriting, OWL 2 RL Systems and Repairing",
    "info": {
        "author": [
            "Giorgos Stoilos, Computing Laboratory, Oxford University"
        ],
        "published": "July 30, 2014",
        "recorded": "May 2014",
        "category": [
            "Top->Computer Science->Semantic Web",
            "Top->Computer Science->Big Data"
        ]
    },
    "url": "http://videolectures.net/eswc2014_stoilos_data_access/",
    "segmentation": [
        [
            "Good afternoon, I'm your stylus from the National Technical University of Athens and so far this session we have heard about many great new triple stores and rule based systems which offer some inference.",
            "Support about all, but not the full of owl.",
            "So my talk today would be to show you that we can already support much much more inference, more infinites of all an using your triple store of choice.",
            "By paying a very, very small price.",
            "Hopefully and in practice."
        ],
        [
            "Yes, so I guess we all agree that query answering.",
            "Overall two ontologies are very hard problem.",
            "It is exponential with respect to the size of the schema or the tee box.",
            "And even if we restrict complexity wise to the data, the problem is still a colon we had with respect to the size of our datasets.",
            "So what people have been doing and no one can blame them is to restrict the expressivity and use triple stores or rule based systems as we heard in the previous talks.",
            "Which provides some reasoning.",
            "Support of all but not of the full.",
            "So The thing is that when you apply these systems to your apology, if autology the schema is too expressive, then these systems we are going to miss some answers, so they're going to give you some answers and do some inference, but not they're not going to support.",
            "They're not going to return all the answers.",
            "That are entailed.",
            "And in my opinion this is a bit problematic because there are many applications out there that need more expressivity, or even perhaps the full expressivity of all 2.",
            "And of course, if we are able to provide scalable query answering even over Alto Del Ontologists, it could be very beneficial for us, right?"
        ],
        [
            "Sorry.",
            "So what can we do?",
            "There is a prominent solution to scalable query answering I believe, which has been out there for quite some time and the idea of this approach is the following.",
            "So we already have very scalable data reasoning systems like the triple stores we all heard about before.",
            "So is it possible to add on top of this systems like in a preprocessing step?",
            "Modules that are going to help the system improve their completeness, but of course without affecting their favorable performance.",
            "And as I said, there have been many works on this principle since 2004, actually.",
            "I have class of them in two categories.",
            "I'm going to briefly talk about the first one because our work is mostly mostly regards to this.",
            "And the first one is I call a box independent, so the idea intuitively is to use an algorithm there in a preprocessing step to materialize inferences that this triple stores are going to miss.",
            "Right, and all these approaches here follow basically this principle and having around since 2004 and in ISWC 2011 we provided a framework of former framework that characterizes and encompass all these approaches."
        ],
        [
            "Which I'm going to show you now.",
            "So our framework works was for a box independent completeness improvement of triplestores basically.",
            "So the main notion that we defined.",
            "We we call it repair R for an ontology and a triple store, so this repair.",
            "So there is a set of actions that are computed as a preprocessing step and it satisfies two properties.",
            "The first one is that it should be entailed from the original schema.",
            "And the second one is that.",
            "For every data set and every spar QL query, if we give the Triple Store the query.",
            "That the ontology, the schema, the data as well as this said that we have preprocessed, then the Triple Store should be able to return all the certain answers.",
            "All the answers that are exist according to the semantics according to the specification of this query over our input.",
            "So the repair is a set of actions that should mostly satisfy this property here.",
            "And some interesting properties to know to remark about the repairs.",
            "Is that a repair is computed once and it is parent teologi.",
            "So if your ontology changes, you should recompute this set to.",
            "Only works for sparkle queries if you see the definition here, and it can contain complex axioms in general.",
            "So this basically means that classifying your tee box.",
            "As we saw in the previous talk, it will give you some inferences, but it will not possibly give you all the inferences."
        ],
        [
            "So let's see an example.",
            "Here we have an ontology which says that if someone takes a course, then he or she is a student.",
            "And the second option says that graduate students take a graduate course and the third one says that graduate courses are also courses and we also have this sparkle query which says retrieval students.",
            "And assume also that our a box our data set contains the fact that Tom is a student.",
            "It's very easy to see that Tom is an answer to this question.",
            "Why?",
            "Because Tom is graduate student, so he takes some graduate course.",
            "This graduate courses of course, and so by the 1st Action, Tom is also student.",
            "And to the best of my knowledge, if you give this input to some triple store like Jenna or our LTM, then the system will not be able to return this answer and the reason is because to compute this Azure system needs to be able to reason over this existential restrick shun here an this systems support.",
            "Usually all two or L and such actions are fall outside our Touareg, so they're not going to return this answer however.",
            "Using our repair approach, we can see that if we materialize this axiom which says that every graduate student is a student and which basically captures this relationship between graduate students and students through this existential quantifier here.",
            "And give this set as an input to the triplestore then.",
            "The system is going to be able to return the right answer.",
            "Uh, some."
        ],
        [
            "More about our previous work, so OK.",
            "Repairs are nice as defined, but when do they exist?",
            "So in previous work we have characterized existence and we have given a result that repairs for table stores exist when the rig there also exists a Datalog rewriting of the input box of the input schema, and what is the Datalog rewriting Datalog?",
            "Writing is a set of rules that captures from the input schema all the information relevant for answering every ground conjunctive query, so intuitively is.",
            "Something like a ground entailment preserving encoding of your input box into a set of rules, so and also, this idea was something like was done in K and two.",
            "In 2005 so let's see an example.",
            "This is the running tick box from previous slide and the Datalog rewriting for this tick box would look like that, sorry.",
            "So the first rule data local and the last one directly correspond to these two actions.",
            "However, the Datalog rewriting also for this.",
            "The box contains this axiom.",
            "Which basically captures in Datalog this relationship between a graduate student and the student right?",
            "OK, so this was a theoretical characterization and also some more concrete cases of existence we already know from previous works that Datalog Rewritings exist when the ontology is expressed.",
            "They always exist when the ontology is expressed in this description logic horn seek.",
            "And we also know from very recent works that data logger writings can even exist for arbitrary, all to DL ontologies.",
            "So this basically means that for these fragments we can already repair computer repairs."
        ],
        [
            "So how can we do that?",
            "This is an algorithm that summarizes the process.",
            "So the first step.",
            "Is to computer rewriting for your ontology and then transform it into an initial repair.",
            "So if you recall, this is the data will be writing for a running tee box and the first step is to translate this data logger writing into an equivalent ontology.",
            "So this is the initial repair.",
            "However, if you remember from the previous light there our repair only needs to contain this second axiom, so the algorithm needs to also have this cleaning apps cleaning up step, which I also called minimization.",
            "Which basically removes some actions that are not necessary to appear in the repair.",
            "And the way to do that is it uses an Alto reasoner and iterates over this initial repair.",
            "Taking various entailment relationships I don't want to get into the details of this, but the only thing you need to remember is that it is a four loop.",
            "The second one actually is a quadratic one in which we call use an Alto reasoner to do some cleaning up and throw away some actions that are not necessary.",
            "So, at the end, after the algorithm terminates, in our previous example, it is going to contain only the second action."
        ],
        [
            "Right, so I hope that all of you also agree with me that the repairing from the previous slides is a kind of a promising approach to scalable query answering over expressive description over expressive owl fragments.",
            "However, for our first approach had some limitations.",
            "And the first one was that the evaluation we did in 2011 was too preliminary.",
            "We used you high University benchmark and a tiny version of Galen and the second one was that the approach was didn't have any optimizations, so it was still not clear whether we can handle large and complex ontologies.",
            "More expressive and large.",
            "And finally that as I already commented before.",
            "Our approach could only support none.",
            "Markwell queries.",
            "So our goals and contributions for this paper is to investigate the practicality of repairing and exhaustively evaluated.",
            "Of course, we need to propose some optimizations and perform some evaluation using large and complex ontologies.",
            "And the second goal was to provide support for the non sparkle queries.",
            "So first I'm going to talk to you about the."
        ],
        [
            "Just the improvement or refinement we did in our previous work.",
            "A regards the first step of the algorithm I saw you before the first step to recall it is to compute a rewriting and transform it into an initial repair.",
            "So where is the problem in this step?",
            "The problem is in the first condition of the definition of repair, which is too strong.",
            "And why it is too strong, it is.",
            "It prohibit us to use scalable rewriting systems to compute the initially writing which this system normalize the input on policy and let me explain what I mean by normalization.",
            "So an example, so I assume that your tee box contains these complex action.",
            "So because here there is a nested complex action, these systems are going to normalize the ontology.",
            "They're going to introduce this new concept, and they're going to split this action into two actions.",
            "So the rewriting these systems are going to return would contain this Datalog rule, which also contains this new symbol here.",
            "And so the repair algorithm is going to recompute and return an axiom like that, and clearly because there is a new concept name here and you symbol.",
            "This set here is not going to be entailed from the input box, and normalization is good.",
            "We want to use these systems, 'cause it gives us performance.",
            "In computing, data, locally writings and it also gives us compactness of the computing writing.",
            "So the solution to this problem was to note that this set return here.",
            "By using this actions is not entailed from the original tee box, so it's not going to be a repair for the originality box for the system, but it is going to be a repair and it is entailed from the normalized version of the TEE box so.",
            "Uh, we have this proposition, which basically says that if we give the triplestore the normalized ontology and the set computed using these systems, then the system is going to return the right answers.",
            "We have also done."
        ],
        [
            "And an improvement regarding the second step of our algorithm.",
            "This is more software engineering oriented and to recall the 2nd.",
            "Step consists of several for loops which, over this set are one which can be exponentially larger than T. So in the special of the second set is a quadratic loop.",
            "So how we solve this problem?",
            "We solve this problem by observing that some parameters of this entailment text are fixed, so we can use.",
            "We can kind of implement an incremental approach entailment setting using the Alto reasoner, which basically means apply the calculus of the regional exhaustively and store the computation.",
            "Then, whenever we want to 2nd element this entailment, we resume the computation and then we backtrack."
        ],
        [
            "Regarding non sparkle queries, of course I mean queries which have existential variables.",
            "So the idea about supporting and on sparkle queries is more or less the same like repairing.",
            "So repairing explicates the ground entailments.",
            "Using a rewriting so the idea was to also explicate non ground entailments which are related to this existential variables and the way to do that is again to use some notion of rewriting, but a different one than before.",
            "So this rewriting is for both the T box, the input as well as the non sparkle query.",
            "So these are writings look like that the crucial difference from before is that we have this set here, which is basically a union of conjunctive queries which capture capture the non ground entailments and using that we were able to solve that.",
            "If you have a non sparkle query you can compute a rewriting.",
            "4T and Q.",
            "And then you can send to your triple stores you to your triple store.",
            "These are rare Q set which is the union of conductor queries that E books the repair and and a box and then the system is going to be able to return all the right answers.",
            "Even when Q is a non sparkly liquid.",
            "I think I don't have time, for example about the non sparkle queries."
        ],
        [
            "So our algorithm can be."
        ],
        [
            "Summarized in this three steps.",
            "So the first step is to compute the repair for the given ontology using the two step repair procedure I saw you before.",
            "Then the second step is to load the data set and the input box and the repair to your system and then your table store is going to be able to answer queries as follows for a given user query.",
            "If the query is park well, then you can simply save this query to the Triple Store.",
            "Otherwise, if the query is.",
            "Non sparkle query.",
            "You can compute rewriting, acutely writing for both 30 bucks and the query using any writing system, and evaluate this union of conjunctive queries over the triple store that you have loaded your data and we have implemented this approach into a prototype system called hydro which you can download from this link.",
            "I don't know how."
        ],
        [
            "How much time I have for results and evaluation.",
            "We have tested thoroughly or approach all the three steps to see how efficiently we can compute repairs in practice.",
            "How much these repairs affect loading of the triple store if you log the repairs together with your input, and we also want it to evaluate how efficiently we can answer non sparkle queries.",
            "We used a large set of ontologies we used also ontologies.",
            "Which come with a box is like you'll be M and we created various boxes and we also tested for for testing new sparkle queries who used to fly anatomy ontology which comes with more realistic."
        ],
        [
            "Parkwell queries.",
            "So I'm going to skip this."
        ],
        [
            "And.",
            "This is a result regarding computing repairs.",
            "And it is.",
            "These are numbers regarding very hard ontologies.",
            "So at the end of the day we were able to compute repairs even for very hard or very larger tall ontologies like this ones here, who has the usual suspects like yelling.",
            "And the repairs are quite large, because these ontologies are quite large and complex.",
            "And the time was, I would say reasonable given the size and the complexity of these ontologies.",
            "And so I guess we could compute repairs for even large and complex ontologies.",
            "These are some results."
        ],
        [
            "Regarding loading, bottom line is that we observed decreasing loading increase, increasing loading time when we also load the repairs.",
            "However, this increase was not that terrible.",
            "I mean there was there any queries but it was never exponential increase so the price to pay for loading the repairs is not that."
        ],
        [
            "Bugs.",
            "And regarding non sparkle queries, we were able to compute the right answers to all four non sparkwell queries over the Fly Anatomy Ontology almost instantaneously.",
            "So this basically means that the price to pay in loading does pay off at the end."
        ],
        [
            "An summary.",
            "Yes, I believe more now that repairing a passion ability is a highly promising approach to query answering and scalable query answering over, even expressive ontologies.",
            "We were able to compute repairs even for large ontologies in a reasonable amount of time.",
            "The size was small or average, but it was never exponential compared to the input box.",
            "The loading time it was affective affected, sometimes significantly, but again it was not exponentially worse, and we were also able to answer non sparkle queries almost instantaneously.",
            "So I guess I don't have no anymore time, so thank you.",
            "I already don't have a.",
            "Cute."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Good afternoon, I'm your stylus from the National Technical University of Athens and so far this session we have heard about many great new triple stores and rule based systems which offer some inference.",
                    "label": 1
                },
                {
                    "sent": "Support about all, but not the full of owl.",
                    "label": 0
                },
                {
                    "sent": "So my talk today would be to show you that we can already support much much more inference, more infinites of all an using your triple store of choice.",
                    "label": 0
                },
                {
                    "sent": "By paying a very, very small price.",
                    "label": 0
                },
                {
                    "sent": "Hopefully and in practice.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yes, so I guess we all agree that query answering.",
                    "label": 1
                },
                {
                    "sent": "Overall two ontologies are very hard problem.",
                    "label": 1
                },
                {
                    "sent": "It is exponential with respect to the size of the schema or the tee box.",
                    "label": 0
                },
                {
                    "sent": "And even if we restrict complexity wise to the data, the problem is still a colon we had with respect to the size of our datasets.",
                    "label": 0
                },
                {
                    "sent": "So what people have been doing and no one can blame them is to restrict the expressivity and use triple stores or rule based systems as we heard in the previous talks.",
                    "label": 0
                },
                {
                    "sent": "Which provides some reasoning.",
                    "label": 1
                },
                {
                    "sent": "Support of all but not of the full.",
                    "label": 0
                },
                {
                    "sent": "So The thing is that when you apply these systems to your apology, if autology the schema is too expressive, then these systems we are going to miss some answers, so they're going to give you some answers and do some inference, but not they're not going to support.",
                    "label": 0
                },
                {
                    "sent": "They're not going to return all the answers.",
                    "label": 0
                },
                {
                    "sent": "That are entailed.",
                    "label": 0
                },
                {
                    "sent": "And in my opinion this is a bit problematic because there are many applications out there that need more expressivity, or even perhaps the full expressivity of all 2.",
                    "label": 1
                },
                {
                    "sent": "And of course, if we are able to provide scalable query answering even over Alto Del Ontologists, it could be very beneficial for us, right?",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "So what can we do?",
                    "label": 0
                },
                {
                    "sent": "There is a prominent solution to scalable query answering I believe, which has been out there for quite some time and the idea of this approach is the following.",
                    "label": 0
                },
                {
                    "sent": "So we already have very scalable data reasoning systems like the triple stores we all heard about before.",
                    "label": 1
                },
                {
                    "sent": "So is it possible to add on top of this systems like in a preprocessing step?",
                    "label": 0
                },
                {
                    "sent": "Modules that are going to help the system improve their completeness, but of course without affecting their favorable performance.",
                    "label": 1
                },
                {
                    "sent": "And as I said, there have been many works on this principle since 2004, actually.",
                    "label": 0
                },
                {
                    "sent": "I have class of them in two categories.",
                    "label": 0
                },
                {
                    "sent": "I'm going to briefly talk about the first one because our work is mostly mostly regards to this.",
                    "label": 0
                },
                {
                    "sent": "And the first one is I call a box independent, so the idea intuitively is to use an algorithm there in a preprocessing step to materialize inferences that this triple stores are going to miss.",
                    "label": 0
                },
                {
                    "sent": "Right, and all these approaches here follow basically this principle and having around since 2004 and in ISWC 2011 we provided a framework of former framework that characterizes and encompass all these approaches.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which I'm going to show you now.",
                    "label": 0
                },
                {
                    "sent": "So our framework works was for a box independent completeness improvement of triplestores basically.",
                    "label": 0
                },
                {
                    "sent": "So the main notion that we defined.",
                    "label": 0
                },
                {
                    "sent": "We we call it repair R for an ontology and a triple store, so this repair.",
                    "label": 0
                },
                {
                    "sent": "So there is a set of actions that are computed as a preprocessing step and it satisfies two properties.",
                    "label": 0
                },
                {
                    "sent": "The first one is that it should be entailed from the original schema.",
                    "label": 0
                },
                {
                    "sent": "And the second one is that.",
                    "label": 0
                },
                {
                    "sent": "For every data set and every spar QL query, if we give the Triple Store the query.",
                    "label": 0
                },
                {
                    "sent": "That the ontology, the schema, the data as well as this said that we have preprocessed, then the Triple Store should be able to return all the certain answers.",
                    "label": 0
                },
                {
                    "sent": "All the answers that are exist according to the semantics according to the specification of this query over our input.",
                    "label": 0
                },
                {
                    "sent": "So the repair is a set of actions that should mostly satisfy this property here.",
                    "label": 0
                },
                {
                    "sent": "And some interesting properties to know to remark about the repairs.",
                    "label": 0
                },
                {
                    "sent": "Is that a repair is computed once and it is parent teologi.",
                    "label": 0
                },
                {
                    "sent": "So if your ontology changes, you should recompute this set to.",
                    "label": 0
                },
                {
                    "sent": "Only works for sparkle queries if you see the definition here, and it can contain complex axioms in general.",
                    "label": 0
                },
                {
                    "sent": "So this basically means that classifying your tee box.",
                    "label": 0
                },
                {
                    "sent": "As we saw in the previous talk, it will give you some inferences, but it will not possibly give you all the inferences.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's see an example.",
                    "label": 0
                },
                {
                    "sent": "Here we have an ontology which says that if someone takes a course, then he or she is a student.",
                    "label": 0
                },
                {
                    "sent": "And the second option says that graduate students take a graduate course and the third one says that graduate courses are also courses and we also have this sparkle query which says retrieval students.",
                    "label": 0
                },
                {
                    "sent": "And assume also that our a box our data set contains the fact that Tom is a student.",
                    "label": 0
                },
                {
                    "sent": "It's very easy to see that Tom is an answer to this question.",
                    "label": 0
                },
                {
                    "sent": "Why?",
                    "label": 0
                },
                {
                    "sent": "Because Tom is graduate student, so he takes some graduate course.",
                    "label": 0
                },
                {
                    "sent": "This graduate courses of course, and so by the 1st Action, Tom is also student.",
                    "label": 0
                },
                {
                    "sent": "And to the best of my knowledge, if you give this input to some triple store like Jenna or our LTM, then the system will not be able to return this answer and the reason is because to compute this Azure system needs to be able to reason over this existential restrick shun here an this systems support.",
                    "label": 0
                },
                {
                    "sent": "Usually all two or L and such actions are fall outside our Touareg, so they're not going to return this answer however.",
                    "label": 0
                },
                {
                    "sent": "Using our repair approach, we can see that if we materialize this axiom which says that every graduate student is a student and which basically captures this relationship between graduate students and students through this existential quantifier here.",
                    "label": 0
                },
                {
                    "sent": "And give this set as an input to the triplestore then.",
                    "label": 0
                },
                {
                    "sent": "The system is going to be able to return the right answer.",
                    "label": 0
                },
                {
                    "sent": "Uh, some.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "More about our previous work, so OK.",
                    "label": 0
                },
                {
                    "sent": "Repairs are nice as defined, but when do they exist?",
                    "label": 0
                },
                {
                    "sent": "So in previous work we have characterized existence and we have given a result that repairs for table stores exist when the rig there also exists a Datalog rewriting of the input box of the input schema, and what is the Datalog rewriting Datalog?",
                    "label": 0
                },
                {
                    "sent": "Writing is a set of rules that captures from the input schema all the information relevant for answering every ground conjunctive query, so intuitively is.",
                    "label": 0
                },
                {
                    "sent": "Something like a ground entailment preserving encoding of your input box into a set of rules, so and also, this idea was something like was done in K and two.",
                    "label": 0
                },
                {
                    "sent": "In 2005 so let's see an example.",
                    "label": 0
                },
                {
                    "sent": "This is the running tick box from previous slide and the Datalog rewriting for this tick box would look like that, sorry.",
                    "label": 0
                },
                {
                    "sent": "So the first rule data local and the last one directly correspond to these two actions.",
                    "label": 0
                },
                {
                    "sent": "However, the Datalog rewriting also for this.",
                    "label": 0
                },
                {
                    "sent": "The box contains this axiom.",
                    "label": 0
                },
                {
                    "sent": "Which basically captures in Datalog this relationship between a graduate student and the student right?",
                    "label": 0
                },
                {
                    "sent": "OK, so this was a theoretical characterization and also some more concrete cases of existence we already know from previous works that Datalog Rewritings exist when the ontology is expressed.",
                    "label": 0
                },
                {
                    "sent": "They always exist when the ontology is expressed in this description logic horn seek.",
                    "label": 0
                },
                {
                    "sent": "And we also know from very recent works that data logger writings can even exist for arbitrary, all to DL ontologies.",
                    "label": 0
                },
                {
                    "sent": "So this basically means that for these fragments we can already repair computer repairs.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how can we do that?",
                    "label": 0
                },
                {
                    "sent": "This is an algorithm that summarizes the process.",
                    "label": 0
                },
                {
                    "sent": "So the first step.",
                    "label": 0
                },
                {
                    "sent": "Is to computer rewriting for your ontology and then transform it into an initial repair.",
                    "label": 1
                },
                {
                    "sent": "So if you recall, this is the data will be writing for a running tee box and the first step is to translate this data logger writing into an equivalent ontology.",
                    "label": 0
                },
                {
                    "sent": "So this is the initial repair.",
                    "label": 0
                },
                {
                    "sent": "However, if you remember from the previous light there our repair only needs to contain this second axiom, so the algorithm needs to also have this cleaning apps cleaning up step, which I also called minimization.",
                    "label": 0
                },
                {
                    "sent": "Which basically removes some actions that are not necessary to appear in the repair.",
                    "label": 0
                },
                {
                    "sent": "And the way to do that is it uses an Alto reasoner and iterates over this initial repair.",
                    "label": 0
                },
                {
                    "sent": "Taking various entailment relationships I don't want to get into the details of this, but the only thing you need to remember is that it is a four loop.",
                    "label": 0
                },
                {
                    "sent": "The second one actually is a quadratic one in which we call use an Alto reasoner to do some cleaning up and throw away some actions that are not necessary.",
                    "label": 0
                },
                {
                    "sent": "So, at the end, after the algorithm terminates, in our previous example, it is going to contain only the second action.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right, so I hope that all of you also agree with me that the repairing from the previous slides is a kind of a promising approach to scalable query answering over expressive description over expressive owl fragments.",
                    "label": 0
                },
                {
                    "sent": "However, for our first approach had some limitations.",
                    "label": 1
                },
                {
                    "sent": "And the first one was that the evaluation we did in 2011 was too preliminary.",
                    "label": 0
                },
                {
                    "sent": "We used you high University benchmark and a tiny version of Galen and the second one was that the approach was didn't have any optimizations, so it was still not clear whether we can handle large and complex ontologies.",
                    "label": 1
                },
                {
                    "sent": "More expressive and large.",
                    "label": 0
                },
                {
                    "sent": "And finally that as I already commented before.",
                    "label": 0
                },
                {
                    "sent": "Our approach could only support none.",
                    "label": 0
                },
                {
                    "sent": "Markwell queries.",
                    "label": 0
                },
                {
                    "sent": "So our goals and contributions for this paper is to investigate the practicality of repairing and exhaustively evaluated.",
                    "label": 1
                },
                {
                    "sent": "Of course, we need to propose some optimizations and perform some evaluation using large and complex ontologies.",
                    "label": 0
                },
                {
                    "sent": "And the second goal was to provide support for the non sparkle queries.",
                    "label": 0
                },
                {
                    "sent": "So first I'm going to talk to you about the.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Just the improvement or refinement we did in our previous work.",
                    "label": 0
                },
                {
                    "sent": "A regards the first step of the algorithm I saw you before the first step to recall it is to compute a rewriting and transform it into an initial repair.",
                    "label": 1
                },
                {
                    "sent": "So where is the problem in this step?",
                    "label": 0
                },
                {
                    "sent": "The problem is in the first condition of the definition of repair, which is too strong.",
                    "label": 0
                },
                {
                    "sent": "And why it is too strong, it is.",
                    "label": 1
                },
                {
                    "sent": "It prohibit us to use scalable rewriting systems to compute the initially writing which this system normalize the input on policy and let me explain what I mean by normalization.",
                    "label": 0
                },
                {
                    "sent": "So an example, so I assume that your tee box contains these complex action.",
                    "label": 0
                },
                {
                    "sent": "So because here there is a nested complex action, these systems are going to normalize the ontology.",
                    "label": 0
                },
                {
                    "sent": "They're going to introduce this new concept, and they're going to split this action into two actions.",
                    "label": 0
                },
                {
                    "sent": "So the rewriting these systems are going to return would contain this Datalog rule, which also contains this new symbol here.",
                    "label": 0
                },
                {
                    "sent": "And so the repair algorithm is going to recompute and return an axiom like that, and clearly because there is a new concept name here and you symbol.",
                    "label": 0
                },
                {
                    "sent": "This set here is not going to be entailed from the input box, and normalization is good.",
                    "label": 0
                },
                {
                    "sent": "We want to use these systems, 'cause it gives us performance.",
                    "label": 0
                },
                {
                    "sent": "In computing, data, locally writings and it also gives us compactness of the computing writing.",
                    "label": 0
                },
                {
                    "sent": "So the solution to this problem was to note that this set return here.",
                    "label": 0
                },
                {
                    "sent": "By using this actions is not entailed from the original tee box, so it's not going to be a repair for the originality box for the system, but it is going to be a repair and it is entailed from the normalized version of the TEE box so.",
                    "label": 0
                },
                {
                    "sent": "Uh, we have this proposition, which basically says that if we give the triplestore the normalized ontology and the set computed using these systems, then the system is going to return the right answers.",
                    "label": 0
                },
                {
                    "sent": "We have also done.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And an improvement regarding the second step of our algorithm.",
                    "label": 0
                },
                {
                    "sent": "This is more software engineering oriented and to recall the 2nd.",
                    "label": 0
                },
                {
                    "sent": "Step consists of several for loops which, over this set are one which can be exponentially larger than T. So in the special of the second set is a quadratic loop.",
                    "label": 1
                },
                {
                    "sent": "So how we solve this problem?",
                    "label": 0
                },
                {
                    "sent": "We solve this problem by observing that some parameters of this entailment text are fixed, so we can use.",
                    "label": 1
                },
                {
                    "sent": "We can kind of implement an incremental approach entailment setting using the Alto reasoner, which basically means apply the calculus of the regional exhaustively and store the computation.",
                    "label": 0
                },
                {
                    "sent": "Then, whenever we want to 2nd element this entailment, we resume the computation and then we backtrack.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Regarding non sparkle queries, of course I mean queries which have existential variables.",
                    "label": 0
                },
                {
                    "sent": "So the idea about supporting and on sparkle queries is more or less the same like repairing.",
                    "label": 0
                },
                {
                    "sent": "So repairing explicates the ground entailments.",
                    "label": 0
                },
                {
                    "sent": "Using a rewriting so the idea was to also explicate non ground entailments which are related to this existential variables and the way to do that is again to use some notion of rewriting, but a different one than before.",
                    "label": 1
                },
                {
                    "sent": "So this rewriting is for both the T box, the input as well as the non sparkle query.",
                    "label": 0
                },
                {
                    "sent": "So these are writings look like that the crucial difference from before is that we have this set here, which is basically a union of conjunctive queries which capture capture the non ground entailments and using that we were able to solve that.",
                    "label": 0
                },
                {
                    "sent": "If you have a non sparkle query you can compute a rewriting.",
                    "label": 0
                },
                {
                    "sent": "4T and Q.",
                    "label": 0
                },
                {
                    "sent": "And then you can send to your triple stores you to your triple store.",
                    "label": 0
                },
                {
                    "sent": "These are rare Q set which is the union of conductor queries that E books the repair and and a box and then the system is going to be able to return all the right answers.",
                    "label": 0
                },
                {
                    "sent": "Even when Q is a non sparkly liquid.",
                    "label": 0
                },
                {
                    "sent": "I think I don't have time, for example about the non sparkle queries.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So our algorithm can be.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Summarized in this three steps.",
                    "label": 0
                },
                {
                    "sent": "So the first step is to compute the repair for the given ontology using the two step repair procedure I saw you before.",
                    "label": 1
                },
                {
                    "sent": "Then the second step is to load the data set and the input box and the repair to your system and then your table store is going to be able to answer queries as follows for a given user query.",
                    "label": 1
                },
                {
                    "sent": "If the query is park well, then you can simply save this query to the Triple Store.",
                    "label": 0
                },
                {
                    "sent": "Otherwise, if the query is.",
                    "label": 0
                },
                {
                    "sent": "Non sparkle query.",
                    "label": 0
                },
                {
                    "sent": "You can compute rewriting, acutely writing for both 30 bucks and the query using any writing system, and evaluate this union of conjunctive queries over the triple store that you have loaded your data and we have implemented this approach into a prototype system called hydro which you can download from this link.",
                    "label": 0
                },
                {
                    "sent": "I don't know how.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "How much time I have for results and evaluation.",
                    "label": 0
                },
                {
                    "sent": "We have tested thoroughly or approach all the three steps to see how efficiently we can compute repairs in practice.",
                    "label": 0
                },
                {
                    "sent": "How much these repairs affect loading of the triple store if you log the repairs together with your input, and we also want it to evaluate how efficiently we can answer non sparkle queries.",
                    "label": 1
                },
                {
                    "sent": "We used a large set of ontologies we used also ontologies.",
                    "label": 0
                },
                {
                    "sent": "Which come with a box is like you'll be M and we created various boxes and we also tested for for testing new sparkle queries who used to fly anatomy ontology which comes with more realistic.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Parkwell queries.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to skip this.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "This is a result regarding computing repairs.",
                    "label": 0
                },
                {
                    "sent": "And it is.",
                    "label": 0
                },
                {
                    "sent": "These are numbers regarding very hard ontologies.",
                    "label": 0
                },
                {
                    "sent": "So at the end of the day we were able to compute repairs even for very hard or very larger tall ontologies like this ones here, who has the usual suspects like yelling.",
                    "label": 0
                },
                {
                    "sent": "And the repairs are quite large, because these ontologies are quite large and complex.",
                    "label": 0
                },
                {
                    "sent": "And the time was, I would say reasonable given the size and the complexity of these ontologies.",
                    "label": 0
                },
                {
                    "sent": "And so I guess we could compute repairs for even large and complex ontologies.",
                    "label": 0
                },
                {
                    "sent": "These are some results.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Regarding loading, bottom line is that we observed decreasing loading increase, increasing loading time when we also load the repairs.",
                    "label": 0
                },
                {
                    "sent": "However, this increase was not that terrible.",
                    "label": 0
                },
                {
                    "sent": "I mean there was there any queries but it was never exponential increase so the price to pay for loading the repairs is not that.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Bugs.",
                    "label": 0
                },
                {
                    "sent": "And regarding non sparkle queries, we were able to compute the right answers to all four non sparkwell queries over the Fly Anatomy Ontology almost instantaneously.",
                    "label": 1
                },
                {
                    "sent": "So this basically means that the price to pay in loading does pay off at the end.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "An summary.",
                    "label": 0
                },
                {
                    "sent": "Yes, I believe more now that repairing a passion ability is a highly promising approach to query answering and scalable query answering over, even expressive ontologies.",
                    "label": 1
                },
                {
                    "sent": "We were able to compute repairs even for large ontologies in a reasonable amount of time.",
                    "label": 0
                },
                {
                    "sent": "The size was small or average, but it was never exponential compared to the input box.",
                    "label": 0
                },
                {
                    "sent": "The loading time it was affective affected, sometimes significantly, but again it was not exponentially worse, and we were also able to answer non sparkle queries almost instantaneously.",
                    "label": 0
                },
                {
                    "sent": "So I guess I don't have no anymore time, so thank you.",
                    "label": 0
                },
                {
                    "sent": "I already don't have a.",
                    "label": 0
                },
                {
                    "sent": "Cute.",
                    "label": 0
                }
            ]
        }
    }
}