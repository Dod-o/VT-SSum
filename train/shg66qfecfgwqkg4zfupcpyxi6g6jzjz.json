{
    "id": "shg66qfecfgwqkg4zfupcpyxi6g6jzjz",
    "title": "Sampling for Big Data",
    "info": {
        "author": [
            "Nick Duffield, Department of Electrical and Computer Engineering, Texas A&M University",
            "Graham Cormode, Department of Computer Science, University of Warwick"
        ],
        "published": "Oct. 8, 2014",
        "recorded": "August 2014",
        "category": [
            "Top->Computer Science->Data Mining",
            "Top->Computer Science->Knowledge Extraction"
        ]
    },
    "url": "http://videolectures.net/kdd2014_cormode_duffield_sampling_data/",
    "segmentation": [
        [
            "So today we're going to be talking about sampling for big data."
        ],
        [
            "A big data rises in many forms.",
            "If merely with physical measurements from science, physics and astronomy, medical data, genetic sequences.",
            "Activity data from networks.",
            "GPS location data.",
            "High level application level.",
            "We have social network activity data.",
            "And in businesses, customers, customer behavior.",
            "Businesses want to track at fine detail and determine who's buying with buying washing why.",
            "Some of these some of these days have been around for a comparatively long time.",
            "If we think about ISPs, for example, we've been in the big data business for a number of years.",
            "Some big data is comparatively new, and I think when people talk about big data, the the big burst of activity we've seen in big data in the last few years as a lot of that has been about these newer sources of data, and I think that's a great opportunity for all of us who are working in the Big data area.",
            "So the summary of what I just said was we have a large number of diverse sets of big data, summer older son, the manure and the newer ones in areas where data is only recently become big, a great opportunity for all of us working in this area I think.",
            "So the common themes amongst all these, the data is large and it's getting larger.",
            "And the important patterns and trends in this data and our task as data scientists is to is to determine these.",
            "But we don't know for me where to look and how to find these patterns.",
            "And one of the thesis of these.",
            "This talk is that sampling is a way to help you do what you need to do quicker.",
            "More easily.",
            "In ways which don't necessarily involve using all the resources that one could conceive throwing out this problem."
        ],
        [
            "So.",
            "Sampling is about reduction.",
            "Why do we want to reduce data?",
            "So most of the base we know his big already.",
            "But you know, it's not always possible to store this station full in many applications where you have high high rate streaming data.",
            "For example in telecoms ISP's.",
            "Or we can't.",
            "Search engines we can't keep everything, or at least we can't keep everything forever.",
            "And sometimes it's just inconvenient to work with the data and full justice we could buy.",
            "Ingeniously, throwing resources of this problem doesn't mean we should do that.",
            "And often it's faster to work with compact summary if you want to do interactive exploratory queries, explorations of the data expected to be able to explore that quickly on your laptop, then have to run extensive computations in a cluster.",
            "I don't have to wait for the answer, or you don't have cluster at your disposal.",
            "Not everybody does."
        ],
        [
            "So why why sampling there are many different forms of data in action?",
            "What are the strengths of sampling relative to other methods?",
            "Well, one nice thing about sampling is it has a very intuitive semantic.",
            "We have a large data set.",
            "And we end up with some subset of that which has the same structure, the elements of which has the same structure.",
            "And of course, we're sampling.",
            "We gotta get his acts answers most of the time we're going to get approximate answers to our queries, but this estimation that we're doing to get these approximate answers to our queries on a sample, it's often straightforward.",
            "You run the analysis on the sample.",
            "Just in the way you would or the full data, although because it's a sample, some rescaling re weighting of the points in your sample in order to draw an inference about the population from the sample itself.",
            "Some of this, some rescaling, reweighting may be necessary, and we're going to see when we talk about particular methods for that during the talk.",
            "Another really nice thing about sampling is as a general method.",
            "It's it's really agnostic to the analysis which needs to be done in the sense that.",
            "Other summary methods often only work for certain computations, or they are tide to particular analysis, particular types of aggregates of the data you're looking for.",
            "That's not to say that you don't need to match sampling to the data and will see one of the themes in this talk.",
            "Is is talking about how we can tune sampling methods to optimize somehow the combination between the data characteristics and the analysis you want to do.",
            "But this is a very general property of sampling.",
            "It makes the method very flexible.",
            "And usually For these reasons, sampling is usually easy to understand.",
            "It's so prevalent that we have an intuition about sampling.",
            "So in this picture, what we're trying to communicate is we have a number of objects of different types, and when we sample we end up with a subset.",
            "But that subset of objects also contains representatives from the different types of different color objects.",
            "But you see, we've gone.",
            "We've.",
            "We also need to wait our objects.",
            "They've been, circles have become bigger.",
            "For the objects we've selected, and by doing that we are able to.",
            "To get an estimate from the original about the original population from the samples we have."
        ],
        [
            "So I've talked about a very general level, the.",
            "The strengths of sampling.",
            "What about the alternatives?",
            "So something is not the only thing we could do.",
            "There are many other data reduction techniques available.",
            "For example, dimensionality reduction methods.",
            "If you look at PCA or singular value decomposition, I can value eigenvector decompositions.",
            "What we're trying to do here is find the dominant components.",
            "And.",
            "In essence.",
            "Agreed to ignore smaller components with low energy, which aren't going to be important for answering.",
            "Many, many questions.",
            "On the other hand, these methods can be costly computationally and therefore slow to perform on big data.",
            "Sketching techniques for streams of data have received a lot of attention.",
            "Typically we're looking at hash based summaries via random projections, and these protections can then be.",
            "Then we query to to recover information about the original population.",
            "However, compared with sampling, these are.",
            "Somewhat complex to understand.",
            "And we also.",
            "I come across a problem, but they limited in function or constraints, in particular analysis.",
            "So there's a question of generality here as opposed in comparison to sampling.",
            "And brother transform methods, wavelets for rare transforms, discrete transforms, histograms.",
            "Powerful, but.",
            "Basically not so updatable at a high overhead achieved.",
            "I mean so our view about these positions with respect to what we talk about in this tutorial is.",
            "I mean these are all very interesting methods and they have strengths and weaknesses, but we're not going to dwell on them already covered the material in this tutorial."
        ],
        [
            "So before we fully embark on the truck tutorial proper.",
            "We can have a little bit of calculation here.",
            "We again talk about probabilities and some algorithms, but not in great detail.",
            "We really want to give a high level descriptions and some intuition about what is going on, but we're going to assume some basics and concepts of probability, expectation, variances, and we get into a mood when we talk about estimation, estimation, accuracy, we're going to allude to.",
            "Turn off bounds, for example, so the measures of the concentration of our estimates around the true value.",
            "And please feel free to ask questions about technical details along the way or at the break or afterwards."
        ],
        [
            "So here's the outline of the rest of the Tauriel.",
            "So we can talk about.",
            "A lot of this talk where we're going through reference applications in large ISP networks, and I'll talk a little bit more about about why that's a good example to look at when I get onto it, we give you talk about the basics of sampling.",
            "Concepts including estimation.",
            "And then we're going to move to stream sampling, looking at uniform.",
            "The weighted case and.",
            "After the break, we're going to look at more recent work in stream sampling and a way of looking at sampling which.",
            "This has been found to be very powerful looking into cost optimization.",
            "At that point I'm going to hand over to Graham.",
            "And he's going to talk about the role of hashing and coordination in sampling.",
            "I'm.",
            "Remember, last major parts visual will concern graph sampling?",
            "I'm Ben Graham will wrap up with a conclusion.",
            "I'm talking about future directions."
        ],
        [
            "So as I go through this whole time, I'm going to, I'm going to refer back to.",
            "Examples in ISP networks.",
            "So the.",
            "The road we see for sampling is.",
            "Really, as a mediator of the constraints that you're under working with Big Data so.",
            "And we have data characteristics.",
            "For example, we can have heavy tailed distributions.",
            "We can have correlations between different variables.",
            "Then we have resource constraints and we have restraints for bandwidth to recover data for storage that the data we've gotten to collector and CPU and we want to processor for queries.",
            "And those queries themselves bring requirements themselves.",
            "We want to execute them with certain time.",
            "We're interested in certain aggregates of the data.",
            "We have certain accuracy requirements for the for our queries, and we may not know the queries in advance if we have crammed queries which are used for routine reporting, that's very simple.",
            "We might not even need sampling at all.",
            "But if you don't know what the query is in advance.",
            "Sampling is is is going to enable you to explore the data in an efficient manner, so sampling the role of sampling is to is to sort of relieve the tension between these three constraints and.",
            "A lot of good sample design comprises of trying to try to relieve this tension in an optimal manner."
        ],
        [
            "So I said that a motivating application would be data for Internet service providers.",
            "And this is going to motivate many of our results and also illustrate with applications in this domain.",
            "But at the same time, we don't want to give you the idea that the subject matter in the store, the methods are limited to ISPs.",
            "And I think one of the one of the exciting things about this field is there is a you know.",
            "Opportunity to take experience and methods which have been successful in one area and import them into other application areas, and.",
            "As I said, but I think it's a great opportunity for us as the community.",
            "Now, the reasons many reasons why you want to use some examples.",
            "One rather practical reason is that both myself and Graham until about a year ago works in the ISP world, so we're very familiar with these examples.",
            "And indeed, many of the sampling methods that we will talk about talk about here were developed in response to needs in the ISP world.",
            "This is very practically motivated as well.",
            "I mean sampling is used widely in monitoring within ISP's, and it's also built into routers and ISP's used in my network.",
            "And in fact, there's a my talked earlier about the difference between the new big data and older big Data, and ISP's have been working with many of these big data problems for for a number of years, and although not by that name.",
            "So in fact, there's quite a depth of experience working with big Data in this context.",
            "But as I said, I think there are many different places where sampling is needed, so we shouldn't regard these methods or the applications here is really limited to ISPs at all.",
            "But since we're going to be talking about ISP's, let's first.",
            "Have a little refresher on ISP networks and the sort of big data that arises in them."
        ],
        [
            "So here we see the structure of a typical large ISP network.",
            "We have city level router Centers for example in New York or Seattle or some other big city.",
            "We have a number of routers connected together.",
            "And.",
            "Routine the city is interconnected with multiple multiple links multiple backbone links.",
            "Of these city city routers.",
            "That is, in the in the in the city level router centers we have peering links to other ISPs.",
            "We have links into customer access networks such as a wireless network or the DSL just will subscriber line to consumers where people may be getting IPTV service over those lines.",
            "We also have downstream ISP's and business customers data centers where customers being hosted.",
            "But since customers being hosted and the Network Management Administration servers of the ISP itself."
        ],
        [
            "So you can't manage this networking with, you're measuring it.",
            "And in fact, there's a lot of measurement that goes on the point about this slide mainly is not so much exactly what measurement is going on, but the fact there is an awful lot of it.",
            "But just to summarize, there are lots and packet loss and latency measurements arising from either actually probing, sending, sending packets through the network and measuring their loss and latency, or through passive measurements of traffic.",
            "There are alarms and being raised by device failures and other status reports for practical level transitions.",
            "What concerns us here, mostly in terms of big data, is measurements of traffic matrices.",
            "So the routers themselves.",
            "Compile before measurements on the data flowing through them and on continuous basis and export summary the exports the measurement data it up through a collection infrastructure to a point where they could be analyzed.",
            "And.",
            "That is what that data source is one that will be talking about quite extensively in this in this talk, but it's not the only big data set.",
            "For example.",
            "Protocol monitoring if you.",
            "If you look in the wireless network, if you look at mobile devices, transmission between base stations, all those transitions are potentially potentially monitors as well, generating traffic of equivalent volume."
        ],
        [
            "To the traffic matrices.",
            "So let's focus, let's ask sort of the same questions again, but focusing on ISP data, Huawei began to summarize.",
            "Well.",
            "One reason we want to summarize is when transmission bandwidth measurements is limited.",
            "So I mentioned that the routers performing performing measurements on the traffic through them and they are exporting those measurements up a collection of infrastructure to collect collector.",
            "So historically that the bandwidth to do that was limited because it was done back later.",
            "Once done out of band, now it's not so much of a big issue.",
            "And ISP's cassette collection is done in band.",
            "In other words, it's done on the same path of the traffic takes itself.",
            "But Even so.",
            "Roy accumulation of these of these measurements is.",
            "It's not feasible.",
            "We have high stream.",
            "We have this high rate streaming data.",
            "And what we want to do is, is given that we can't accumulate it indefinitely, what's the alternative?",
            "Well, then we have to maintain some kind of summary that we can use for Baselining time series analysis.",
            "Baseline, if we for example want to do anomaly detection.",
            "If we want to compare what we see now with what we've seen historically is, is there a difference which is anomalous?",
            "We also want to facilitate fast queries.",
            "It's infeasible to run exploratory queries over the full data if we can run with the sample data set.",
            "We can.",
            "We can do this potentially interactively, and that's going to get to be a lot more powerful for the analyst in terms of getting the results they need.",
            "And all of this could be can be wrapped as part of a hierarchical query instruction infrastructure.",
            "We can think of maintaining full date even though we can't maintain it indefinitely.",
            "Maintain the full data over some limited duration window.",
            "You know a few hours, a few days, whatever.",
            "And then drill down into that full data through one or more layers of summarization so fast.",
            "Query with with with summarized data, and then when something can trigger, drill down into the full days when we see something interesting.",
            "And that can be done either at the level of an analyst working with the data or it can be done in an automated system.",
            "And.",
            "My point here is that sampling has proved to be a flexible method to accomplish all these goals."
        ],
        [
            "So let's talk more about the challenge of scale in this Jason summarize and how we going to summarize and samples.",
            "So here we go into this truck.",
            "We get into sort of going two strands.",
            "We're going to be talking about the ISP data and the methods we bought a bet on that.",
            "But we're also going to set this in the context of more general work in sampling and summarization for big data."
        ],
        [
            "So I mentioned in the previous slide that in on on ISP networks that one of the largest data sources comes from these traffic matrices.",
            "What are called Flow Records, which are the measurements which are compiled by routers on the traffic which flow through them.",
            "So let's talk a bit about water flows or water flow records so.",
            "What this diagram illustrates is a timeline in which we have packets arriving at a router."
        ],
        [
            "Answer The packets of these these rectangular boxes and the packets.",
            "We've colored them according to.",
            "A property which we call a key and we can think of the key is labeling a transaction.",
            "So a key of a packet can comprise its IP source and destination address is TCP UDP ports.",
            "It's type of service field and so on.",
            "And this these fields together comprise, you know anyway, at least 64 bits, maybe more depending on the information you want to consider included.",
            "So an IP flow is a set of packets with a common key observed closely in time.",
            "So if you think about what that means, you know why do we observe a?",
            "Why does the Rapture observer set a package for the common key?",
            "Well, there's there's a.",
            "There's an Internet transaction going on.",
            "There's somebody sitting at a computer browsing website.",
            "The request goes off to the website.",
            "AP HTTP request goes off the website, then a set of packets comes back and that request.",
            "It can be will.",
            "In this scheme we think of as one flow and then the set of packets coming back with the with the content that was requested.",
            "We think about as another flow.",
            "And what a flow record is?",
            "It's a protocol level summary of the flow compiled and exported by the routers, so.",
            "The flow record would comprise the flow key counts of the packets and bytes.",
            "If all the packets in the flow, some timing information.",
            "When was the first and last packet of fat flow observed, and some router states, for example, which interfaces the packets and the float reversed through the router.",
            "And this is realized.",
            "It's part of the operating system in Cisco.",
            "Another router vendors and also in standards in the Internet Engineering Task Force.",
            "So Netflow is the name of the operating system feature.",
            "In Cisco routers that performs this.",
            "And so the scale here.",
            "Well, we can have hundreds or even more terabytes of Flow records daily generated by a large ISP.",
            "If we did nothing about it.",
            "So if you can think of this as a sort of pre reduction number.",
            "And these flow records they used to manage the network over a range of time scales.",
            "From capacity planning, understanding the growth of traffic patterns.",
            "Overtime scales are months.",
            "You know where we get, where we want to put in a new link.",
            "For example, two detecting network attacks.",
            "The timescales are seconds, and some of these analysis tasks are relatively easy if we're looking at a time series of predetermined aggregates.",
            "For example, how much traffic flow to a given rashing prefix for.",
            "In every five minute window of the day, that's a very, very easy query and we can just do it, but essentially by accumulation.",
            "Happy.",
            "At the collector, hard charts are to do fast queries over exploratory selectors.",
            "We don't know until the moment we issue the query what which traffic want to select, which set of IP address IP addresses were interested in, or more generally, what combination of Floki fields, timely information, router state and so forth that we were interested in and we want to be able to do this.",
            "We won't be able to issue these queries historically, not just over this limited window.",
            "Full data that we have.",
            "And we're also interested not just in what I call essentially 1 dimensional queries, which is how much how much traffic.",
            "Flow in a given period of time.",
            "With a particular key, for example, how much traffic flowed from this IP address to this IP address, we're interested in communication subgraphs, patterns of communication which might indicate, for example, anomalous network activity such as anonymous service attack or a botnet.",
            "So those kind of queries in fact far harder.",
            "Try to perform auto accommodates in a sampled setting."
        ],
        [
            "So let's talk a bit about how sampling arises even in this context.",
            "In fact, there are two types of sampling that are used in practice for this Internet traffic measurement.",
            "The routers themselves actually sample the packet stream.",
            "A.",
            "Prior to forming the Flow Records and the reason they and this is Jimmy to a constraint, and this illustrates a broader point that often the way you do sampling on the need to do sampling is constrained by by by implementation factors.",
            "So every time a packet comes in.",
            "The router would have to determine which which is the flow record, which it should update, and by sampling the packet stream and only doing that update on a subset of packets, the router limits the work it has to do.",
            "And this is realized with a variant of Netflow called Packet Sample Netflow.",
            "Now, once the flow records have been.",
            "Compiled waiver without packet sampling once they being compiled, then they're exported through the through the collection infrastructure of the ISP to Alexa, and if we sample these flow records, the completed flow records can themselves be subject to sampling, either to limit transmission bandwidth or the limit storage, and these methods are also realized in ISP collection measurement infrastructure and also on the threshold of standardization in the Internet Engineering Task Force.",
            "And also we get to come more about that.",
            "Those are those two examples later.",
            "But these two cases, in fact, the way you do sampling turns out to be.",
            "Difference and these will also illustrate a general property that and the reason for that is through different underlying distributions of the of the of the objects.",
            "If you look at packets as opposed to flows, then the distribution.",
            "So for example the bytes are very different from this requires different sample designs.",
            "Anne.",
            "Although another principle we'll see is that the.",
            "We often have many design choices, and in fact there's been a lot of research work focused on this problem.",
            "How should you do sampling?",
            "Should you do it at the packet level or the flow level and?",
            "In fact, it turns out that sometimes the statistically optimal thing to do is not computationally feasible with the hardware or software you have available, so there's illustrating both.",
            "There can be a tradeoff there."
        ],
        [
            "Well, let's.",
            "Let's go back to this picture and let's restate it in abstract form.",
            "And our abstraction for these flow records.",
            "Is our data model.",
            "This is going to be keyed weights so.",
            "An object a kid wait is is an object with two 2 components await X and a key K. So here are three examples.",
            "First object first example.",
            "My objects are packets.",
            "And.",
            "My weight is the number of bytes for that packets that package contains, and the key K is just the key.",
            "As I talked about in the previous slide, the IP flow key.",
            "My second example.",
            "The objective flows.",
            "In other words, there aggregates of packets aggregate into a flow record and ex could be the number of packets in that represented in that flow record, or the number of bytes and K is the key as before, and our third example just over some non ISP example is by objects account updates in a in a financial system.",
            "So here X could be signed.",
            "It's a credit or debit for an account which is the key.",
            "And so.",
            "In this model I have a stream of these keyed weights.",
            "And the generic query concerned subset samples.",
            "So.",
            "I have, you know I had this dream event waits for some subset S. Of these, these N objects that I'm interested in.",
            "And the subset sum is just the sum of the weights of the objects in that subset through that Big S Big XS is the total weight in my index subset S. Now, in a lot of applications to you typically are subsets that S is going to be SSFC those objects whose key lies in some key set.",
            "Some subset of all possible keys, Capital K. So in this case my if I if I come back to my examples now, I can think of my subset sum X of S of K being the total bytes to a given.",
            "For example were given IP, destination address or UDP port as specified by Mikey Set K. Or in the third example, I could think of it as being the total balance change over a set of accounts over a period of time.",
            "And the aim I'm gonna set myself is to compute a fixed size summary of this stream that can be used for estimated arbitrary subset sums with known error bounds, so that's.",
            "I really quite a broad goal, so how we going to achieve this well?"
        ],
        [
            "Here's a framework we're going to use inclusion sampling and estimation, so the key method here was formalized by Hoverson Thompson in 1952.",
            "Which is that?",
            "If we just consider an object the size XI and we get a sample it with some probability P. So this is just emerging some.",
            "But this is just a marginal sampling probability.",
            "I mean I mean have independent sampling math correlated sampling.",
            "I'm not concerned with those distinctions at the moment, I'm just going to say suppose I select this object of size X with probability P. Well, I can form an unbiased estimate of X by taking.",
            "By dividing X by P. If I do sample and otherwise.",
            "My estimate is zero implicitly if I'm not sampled and.",
            "So the expectation of this of my estimate X prime.",
            "Over these two possible outcomes.",
            "Is X because I sample it with probability that the expectation is the weighted sum?",
            "Of the outcome, so I've X / P or 0 weighted by the probability I have P * X / P, which is X + 1 -- P * 0, so my which gives me X.",
            "So my average my expectation of X prime is X, so that's I have an unbiased estimate.",
            "Now one really powerful property of this type of estimation is linearity.",
            "So I can estimate a subset sum by the sum of the matching estimates.",
            "So in other words, if I have a subset sum X of S. I can estimate it by X prime of X, which is, which is just the sum of the X primes.",
            "In other words, the sum of the unbiased estimates of each of the individual excise.",
            "And because because the individual exercise.",
            "Around XI primes are unbiased.",
            "It also means that X prime of S is unbiased as well.",
            "This expectation is the true value XNS.",
            "And.",
            "As we'll see in more detail.",
            "We can compute in terms of accuracy.",
            "We can compute exponential bounds confidence intervals for these.",
            "So in other words, we can say the probability that the difference between the estimate and the true value exceeds some proportion of the true value is exponentially small, and the larger the thing we're trying to estimate is, the smaller the smaller the probability that we get error of a given amount.",
            "Well, that's that's that's a question.",
            "What is the Pi?",
            "So it's going to be up to us to select the P and so how we do that is going to be, you know what we're going to talk about if you minutes, but this this is a framework saying if we do have some peas, this is how we do estimation.",
            "And.",
            "I mean the thing about sampling.",
            "This comes back to my point about about.",
            "About household queries.",
            "We don't actually need to know what in advance the queries that we're going to do at the time of sampling.",
            "It says in the ISP context if we want to know when or where did that suspicious UDP port first become through active, or which is the most active IP address within some subset of anomalous traffic?",
            "Well, those were questions I can phrase in terms of a subset sum query and then I can go back to my samples and say I'm form an unbiased estimate from the from the object I have in my sample.",
            "Ask and I didn't need to.",
            "Didn't need to know what my subset sum my subset was at the time I did the selection."
        ],
        [
            "OK, So what are parents different parents?",
            "So what are the peas?",
            "So here are some peas.",
            "So simplest way you can do this in the stream Bernoulli sampling.",
            "Yeah, IID sampling of objects with some probability P. And in this case the sampled, if I'm sampling an object of latex, the Horvitz Thompson estimator is just X / P if I sample.",
            "The generalization of this plus on sampling where my weight XC sample with some probability P and the P the probability depends on the object.",
            "It's not uniform, but again I have my hub.",
            "It's Trump's next estimate X / P. So when do I?",
            "When do I want to use plus one versus Bernoulli?",
            "Well, that's the key.",
            "Here is we'll see is that is that if we are interested in weights an interest in their in their values and estimates of waves, we need to have a PC which is summer tunes with those weights.",
            "If we're not really interested in the waves, or if the weights.",
            "If the if the weights at the way it's real rough the same, there's no skew.",
            "The distribution then we can probably get away with uniform sampling.",
            "So in the elephants versus mice pitch, if we were interested in elephants, we better have some sampling probability, which respects the weight of the elephants.",
            "But we can generalize this.",
            "What's the best choice?",
            "The choice of sampling probabilities for a given stream."
        ],
        [
            "I'm.",
            "Well, yeah, in Bernoulli sampling, if you have any objects and we want to sample care of them uniformly, then each possible subset of K should be equally likely.",
            "So we can uniformly sample an index from from North without replacement K times.",
            "And that's how we get our sample.",
            "But there are some subtleties here, you know, do we have truly random numbers?",
            "Can we get them on our computer?",
            "People generally assume that random number generators are good enough, but of course there's been a lot of work that's gone into avoiding pitfalls of bad random random number generators.",
            "A common trick in the database world is to assign a random number to each item and then sort.",
            "And then you can pick out the top items from that random number, and we're going to see we're about lots of variants of that approach in a little while.",
            "This can be very costly if I'm number of items is very big, but then again, if we're not sorting, so is random access to go and go and find the objects.",
            "So there are tradeoffs there.",
            "So an interesting problem is.",
            "Can we take a single linear scan through the data to draw this sample?",
            "And in the streaming model of computation, we see each element in our data set once, and of course, there's an obvious application here.",
            "I hope in what we've been talking about before with these flow records, we have the stream of Flow Records and coming into our collector.",
            "If there are too many of those for us to store, at least over an extended.",
            "Then we can sample them and actually for awhile.",
            "This was a common interview for Tech positions.",
            "In other words, commonly few questions for tech positions.",
            "So how do we achieve this?"
        ],
        [
            "So.",
            "Precisely how we achieve it is through reservoir sampling and this was described by Kenneth and and enhanced by Vista.",
            "So what we want to do is find a fixed size K uniform sample from an arbitrary size upstream of size N objects in one pass.",
            "And with no need to know the stream size in advance.",
            "Well, what we're going to do is.",
            "Well, let's just take the first K items.",
            "That simple, OK will take the first K items from our stream.",
            "We got N -- K items left.",
            "So WP Abbreviates with probability, so with probability one we're going to include the first K items.",
            "Napa.",
            "Any any item any of the subsequent items we want to include it with the probability K / N. By the way, one way to achieve this is we're going to pick.",
            "I'm index J uniformly in one 2 N. And then if for any item and then if J is less than K, we're going to take that new item and swap it into the J position and discard the item which replaced.",
            "If JS Grace McKay, we do nothing, we just keep the sample as we are.",
            "So.",
            "Because there are K possible ways of being less than or equal to K chaos of the possible ways of being less than or equal to K, the probability that that new object gets swapped in is K / M. And.",
            "So why does this achieve what we want?",
            "Well, there's a fairly short proof that establishes uniformity of the sampling method.",
            "So let F sub N be the sample set I have after N arrivals.",
            "So here's a case where we have K = 7.",
            "I've taken my first.",
            "Seven items.",
            "And my.",
            "Generally, at some point later I have my empty item.",
            "And.",
            "It's selection probability where we've just just computed that it's selection probability is K / N. Which is what we want.",
            "But what about the existing something at a position M?",
            "Lesser men, which is previously sampled well.",
            "We can show that we get the right sampling probability by induction, so.",
            "Anne.",
            "Suppose.",
            "Suppose M was a member, so suppose it had been selected into the N -- 1 set with probability P N -- 1, which is K / N -- 1, which was the inclusion probability what we wanted.",
            "Then it survives to be a member of SM.",
            "The the selection set off again, vitam well.",
            "We take a product of the probability that was there in the 1st place where the complement of the probability that the next guy got swapped in.",
            "So in other words, that's the probability that I was there to start with a 10 -- 1 and I didn't get swapped, swapped out at stage N and that's probability of ice tea with some probability that I'm that I'm in the sample after end times.",
            "And if you just do the algebra and that it turns out to be PN elements K / M. So that's that's that's the proof that in fact this.",
            "This this method achieves uniform sampling.",
            "So that was that the basic idea due to use kluth and.",
            "But you gotta think about.",
            "Yeah, how costly is it to do all these steps?"
        ],
        [
            "Um?",
            "So simple approach could be very much if I just described each item comes in and I do.",
            "I do a computation I I decide at random whether or not that item should be swapped in so this I can think of this cost as sort order, one per item.",
            "Well, that's fine if the time it takes to do my computation is.",
            "Is always on average less my interarrival time between objects?",
            "But if it's not, then I'm gonna build up a computation battle backlog.",
            "So.",
            "A better approach for this problem is skip counting, which is rather ban rather than do my check for each arriving item in term.",
            "Since those those decisions are independent and actually don't depend on the objects themselves.",
            "I can find a random index of the next time a selection will take place.",
            "And in fact, the distribution function for this.",
            "So the probability that the index of my next selection M of N. After I've done the NTH selection is less than or equal to.",
            "220 particular value MI can get just by looking at the probabilities that I don't do selections in all the steps up to step M and now this the computation of of those probabilities and the generation of random variance in fact is itself fairly involved, I know, but I know that the expected number of selections I have to do.",
            "Anne.",
            "Is just the sum of of.",
            "Off of my first of K and there was number of selections they did 2 plus plus the probability that I have to make a selection of each subsequent step.",
            "In other words, the sum of PM my selection probabilities from K all the way up to N. That subject has, you know, has is is not order N. In fact it's it's far less.",
            "It's this order came into one plus log M / K and in fact Visa.",
            "One of these contributions in his 8085 paper was actually to provide an algorithm to compute the next selection index with this average running time."
        ],
        [
            "So, um.",
            "If you consider generalizations of this.",
            "I come with a number of names of order sampling, bottom case, sample min hashing and the idea is that.",
            "We going to uniformly sample.",
            "We want a uniform sample of a stream into this reservoir size K. So what we're going to do is how we actually generate those probabilities.",
            "We're going to generate are a one time Ramson variable for each each each object.",
            "Which is drawn from uniformly from the interval 01 and in different context depending on who did the work.",
            "This number is also known as a hash or rank A tag.",
            "You'll see these different terminology is applied to the same basic idea.",
            "So what we're really trying to do you can think of in reservoir sampling is is we want to store the key items with the smallest random tags.",
            "So if you think about how this works with just one item, so here's some arriving items I'm going to generate a random tag.",
            "Here comes an extra item.",
            "Comes the next item.",
            "And this is the green item has now has the smallest tag present.",
            "And now here's this is the last item.",
            "The yellow item happens to have the smallest, smallest tag of each of those uniformly so.",
            "And you can see if I'd been interested in just selecting one item from.",
            "This said, if I just maintained the item with the smallest tag throughout that evolution, then I would have I would have selected my one item and each item of course has the same chance of being the least tag having these tags.",
            "So my son could have been uniform, and in general whether it's for K = 1 or general K. This is this is very easy to implement via priority queue I'm just maintaining.",
            "CVK objects with smallest tag and one strength is if I have.",
            "I can distribute this calculation 'cause I can run this on multiple streams separately and then merge for a global minimum over my over my results."
        ],
        [
            "So so far we've been.",
            "Doing uniform sampling mystream using a reservoir, but what if?",
            "We want to do nonuniform sampling from weighted streams.",
            "Well, if we have an easy case K equals one, we can.",
            "We just say one objects I can.",
            "My objects have weight XN.",
            "Then I can have a sampling probability of my NTH objects which is.",
            "But I take my weight.",
            "My weight XL and divide it by the sum of the first N. The weights of the sum of the weights of the first 10 objects.",
            "General cases harder we can have elements with a large weight and and should this be sampled, probability one or?",
            "Alright, so we need a consistent way to handle this, and in fact there have been a number of different weighted order sampling schemes which have been proposed release to realize different distributional objectives, but they will have this.",
            "We can set them into a common framework of computing a rank which is a function both of some random number UN distributed uniformly in 01 and the weight itself.",
            "And so I'm going to get to talk about a couple of these.",
            "Now.",
            "I'm."
        ],
        [
            "So.",
            "Weighted random sampling generalizes.",
            "This mean winds minimize sampling, so here for each item we going to draw a rank uniformly in the range 01, and then compute A tag which is our end to the power 1 / X N. Or if you think about this, Robert logarithmically, it's you can think of the order properties of the same as log of our divided by XM, and then we're going to keep the items with this KK smallest tags.",
            "And it can be proved that.",
            "But this actually generates an exponential sampling distribution.",
            "And.",
            "This can also be made efficient.",
            "Fire skip counting ideas here 'cause it's a bit more complex as we need to take information about the weights, the weights of the account, not just the counts of the eye."
        ],
        [
            "Priority sampling is another order sampling scheme with which is focused on some related goals.",
            "So here.",
            "Each item XI we get a generator priority.",
            "Z, which is XI over RI where RI is uniformly random between zero and one.",
            "So this plays a role of tag, the rank and so forth.",
            "And then in the rest of our context, we're going to maintain a reservoir of K plus one items, those which have the highest priority.",
            "So here again, you can realize this as a as a as a priority queue where we are based on the priority of Z.",
            "And then how do you do estimation?",
            "Well, letter Z star be the K plus first highest priority.",
            "For the top K priority items, we're going to estimate the weight of XI by XI prime, which is the Max of XI and Z star.",
            "And all the other other items implicitly, their weight estimate is 0 because they never make they are no longer in the reservoir.",
            "And in fact, you can show that that these exercise are so defined, unbiased, and they even have zero covariance.",
            "It is a useful property because it means you can estimate the variance of a subset sum by the sum of the variance of its components.",
            "And.",
            "Also, the relative variance of any subset sum is bounded above by 1 / K -- 1, where care size for sample.",
            "So again, that's very powerful uniform result."
        ],
        [
            "Well, let's see how that works in databases.",
            "Anne.",
            "So you know, in the streaming context we had a reservoir and items were being presented at reservoir and they were making decisions to provision, include them and then possibly reject them as when their priorities were no longer in the top K priorities.",
            "Another way to look at this, and we refer to that a bit earlier when we talked about talked about order sampling in databases.",
            "In this specific case, we're going to say, well, we can do a one time preparation on all our items, so rather have a stream.",
            "This assume we have them have other items in the database, but let's pick out each item and compute our priority in the same way as we did before.",
            "Take the weight of the object and divide by the uniform random number, and then let's sort these or any sort of index in decreasing priority order, and so no discard.",
            "We're just going to do this computation and this sort.",
            "So how we do sampling and estimation is we going to estimate any subset sum excess by X prime.",
            "That should be X prime of S prime.",
            "So some some subset sum over.",
            "Ran over a subset S prime of S. All of our estimates X prime.",
            "And how we gained to form this sum is we're going to select items in decreasing priority order advert out of our ordered list of items and there are two ways of doing this depending on whether we want to bound variance or complexity in the first variance.",
            "We're just going to.",
            "Pick the first K items in decreasing priority order from original Set S. And.",
            "If we do that, then using the using the previous variance band, we know that our relative variance is going to be bounded by 1 / K -- 1.",
            "And in this case, when we do our estimation, we're going to take our X prime is going to be the maximum of X with Z star where Z star is the K plus first highest priority within S alone.",
            "Now.",
            "Of course, we all know we have control over variance here.",
            "We don't necessarily have control over the execution time 'cause we don't know how long it's going to take us to go through our walk down list of all items until we hit the Kay plus first item that happens to be in S. So if execution time is important to you, you can do it another way.",
            "You can just pick the first K items regardless of whether they are in South or not.",
            "So we know that our execution time is bounded bounded in order K. Um?",
            "And then we just pick out of those K items all those which happened to lie in SORS Prime is the items from S which happened to be in the 1st first day of all of the items.",
            "In this case we have to use the right Z star.",
            "So here we use when we do our estimates in for ex prime.",
            "Here's the Star is a K plus first highest priority anywhere in the.",
            "The data set not just not just that matching X.",
            "Matching S sorry."
        ],
        [
            "Well, can we make these stream samples?",
            "Smarter observation here is we can see the whole stream.",
            "Even if we can't store it, so can we keep more information about samples items if they are repeated?",
            "For example, if an item is sampled, carry counter repeats.",
            "So one of the one of the earlier proposal.",
            "This was counting samples where here we sample new items with some fixed probability P. So if you think of the ISP context, every time we see a new key that we haven't seen before, we're going to make a decision whether to sample it or not.",
            "And if we do, every time you see it subsequently we gained.",
            "We're not.",
            "We're going to take it with probability one.",
            "And we have to count these count.",
            "These repeats and you can get an unbiased estimate of the total count of objects, which is 1 / P. Which comes from sampling the first subject with probability P plus the total count minus one.",
            "And there was a bytewise version of this sample and hold produced by Esterna Varughese.",
            "Here we want to sample have a sort of bytewise sampling, so we get a sample when we see a new key and you flow record, we get a sample that has A contains B bytes.",
            "We got to sample it with probability 1 -- 1 minus beta B, which is in fact a sort of you can think about us as constant.",
            "By twice sampling probability of P. And this has lower variance compared with independent sampling of the objects.",
            "But the sample size does grow.",
            "So there have been a response.",
            "Responses to this has been attached a sample and hold.",
            "Let's reduce the sampling probability P when we need it in order to maintain the sample size.",
            "So one way to do this is to just geometrically decrease P, harvest caution and so forth when you need to.",
            "Or you can.",
            "There's been subsequent work where actually tuning.",
            "The decrease in P to maintain a given sample size."
        ],
        [
            "Sketch guided sampling goes further.",
            "Let's let's try just to avoid sampling the heavy keys as much in the 1st place.",
            "We know that uniform sampling will pick the heavy keys again and again and again.",
            "So if you're a large flow comprising many packets, you will tend to be represented in the sample so.",
            "So one question is, you really want to devote your sampling resources towards those those those always wanted to vote them towards these large flows preferentially, or do in fact want to have a scheme which you can adapt to devote some of your sampling resources to.",
            "Two flows which are not amongst the set of largest flows.",
            "So one idea here is to use an Oracle to tell you when a key is heavy and then adjust the sampling probability accordingly.",
            "In this sketch idea sampling proposal they used a sketch data structure to play the role of an Oracle.",
            "Can you track the probability wiki is sampled using of instruction estimators and then?",
            "Decrease the probability of.",
            "Sampling a key as it's estimated weight increases, so that's how you use or trade off and devote less resources towards something.",
            "These heavy keys, in order that you can put more of those resources towards something.",
            "The less any keys."
        ],
        [
            "So what are the challenges for this smartstream sampling?",
            "Well, part of it comes from route constraints.",
            "These flow tables where you need to do the little copies maintained in fast expensive memory which you need to do to get to look up at line.",
            "Look up the keys to find out which floor echoed update at line race in the packets coming into the interface.",
            "In someone hold you still need per packet look up.",
            "You need to figure out whether you sample this key previously mode.",
            "With sample Netflow you have this uniform sampling to reduce the look up rate.",
            "So turns out that you know here in the trade off we see the sample Netflow is actually easier to implement despite its inferior statistical properties.",
            "Now, if you're dealing with companies that produce routers in the traditional way, then we have long development time is to realize new sampling algorithms, and in fact, this is, uh, you know, I've talked about in my ISP contests, but really this is a general concern.",
            "Processing large amounts of data needs some awareness of hardware.",
            "Uniform sampling is very simple.",
            "It means there's no coordination is needed in this tribute setting.",
            "Everybody does their own independent sampling, but there are tradeoffs because it's not may not be statistically optimal.",
            "And when Graham comes on to talk about coordinated sampling and hashing, you'll see some of the advantages that can be brought to bear.",
            "If you are able to coordinate your sampling in some way, not just two independent uniform sampling."
        ],
        [
            "So the future for smarter stream sampling?",
            "Well, one future is software defined networking.",
            "Currently we have proprietary software running on special purpose vendor routers.",
            "The future the ideas will have open software and protocols running on commodity hardware, hardware miss, potentially officers for measurement and radial flexibility.",
            "We can allocate system resources to the measurement tasks as needed, dynamically reconfigure our sampling parameters and this can aid things like stateful packet inspection or something.",
            "For Network security we can.",
            "Yeah, drill down on traffic, which seems more suspicious than other traffic.",
            "Allocate dynamically allocate more sampling resources trade, but we end up with some of the same technical challenges.",
            "Now we want to high rates packet processing in software.",
            "And so we're going to need to have some transparent way of getting hardware support for those sampling operations out of our commodity hardware.",
            "So this is an emerging area.",
            "I refer you to some of the work that Milam use.",
            "Doing an open sketch.",
            "For some recent progress in this.",
            "Emphasize that although it talks about this in the context of traffic measurement, there would be same issues in other applications.",
            "How to use commodity programmable hardware."
        ],
        [
            "OK, so I think I'm going to break at this point and then when we resume, will talk about sampling as a cost optimization."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So today we're going to be talking about sampling for big data.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A big data rises in many forms.",
                    "label": 1
                },
                {
                    "sent": "If merely with physical measurements from science, physics and astronomy, medical data, genetic sequences.",
                    "label": 1
                },
                {
                    "sent": "Activity data from networks.",
                    "label": 0
                },
                {
                    "sent": "GPS location data.",
                    "label": 0
                },
                {
                    "sent": "High level application level.",
                    "label": 1
                },
                {
                    "sent": "We have social network activity data.",
                    "label": 0
                },
                {
                    "sent": "And in businesses, customers, customer behavior.",
                    "label": 0
                },
                {
                    "sent": "Businesses want to track at fine detail and determine who's buying with buying washing why.",
                    "label": 0
                },
                {
                    "sent": "Some of these some of these days have been around for a comparatively long time.",
                    "label": 0
                },
                {
                    "sent": "If we think about ISPs, for example, we've been in the big data business for a number of years.",
                    "label": 0
                },
                {
                    "sent": "Some big data is comparatively new, and I think when people talk about big data, the the big burst of activity we've seen in big data in the last few years as a lot of that has been about these newer sources of data, and I think that's a great opportunity for all of us who are working in the Big data area.",
                    "label": 0
                },
                {
                    "sent": "So the summary of what I just said was we have a large number of diverse sets of big data, summer older son, the manure and the newer ones in areas where data is only recently become big, a great opportunity for all of us working in this area I think.",
                    "label": 1
                },
                {
                    "sent": "So the common themes amongst all these, the data is large and it's getting larger.",
                    "label": 1
                },
                {
                    "sent": "And the important patterns and trends in this data and our task as data scientists is to is to determine these.",
                    "label": 0
                },
                {
                    "sent": "But we don't know for me where to look and how to find these patterns.",
                    "label": 0
                },
                {
                    "sent": "And one of the thesis of these.",
                    "label": 0
                },
                {
                    "sent": "This talk is that sampling is a way to help you do what you need to do quicker.",
                    "label": 0
                },
                {
                    "sent": "More easily.",
                    "label": 0
                },
                {
                    "sent": "In ways which don't necessarily involve using all the resources that one could conceive throwing out this problem.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Sampling is about reduction.",
                    "label": 0
                },
                {
                    "sent": "Why do we want to reduce data?",
                    "label": 0
                },
                {
                    "sent": "So most of the base we know his big already.",
                    "label": 0
                },
                {
                    "sent": "But you know, it's not always possible to store this station full in many applications where you have high high rate streaming data.",
                    "label": 1
                },
                {
                    "sent": "For example in telecoms ISP's.",
                    "label": 0
                },
                {
                    "sent": "Or we can't.",
                    "label": 1
                },
                {
                    "sent": "Search engines we can't keep everything, or at least we can't keep everything forever.",
                    "label": 0
                },
                {
                    "sent": "And sometimes it's just inconvenient to work with the data and full justice we could buy.",
                    "label": 1
                },
                {
                    "sent": "Ingeniously, throwing resources of this problem doesn't mean we should do that.",
                    "label": 0
                },
                {
                    "sent": "And often it's faster to work with compact summary if you want to do interactive exploratory queries, explorations of the data expected to be able to explore that quickly on your laptop, then have to run extensive computations in a cluster.",
                    "label": 1
                },
                {
                    "sent": "I don't have to wait for the answer, or you don't have cluster at your disposal.",
                    "label": 0
                },
                {
                    "sent": "Not everybody does.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So why why sampling there are many different forms of data in action?",
                    "label": 0
                },
                {
                    "sent": "What are the strengths of sampling relative to other methods?",
                    "label": 0
                },
                {
                    "sent": "Well, one nice thing about sampling is it has a very intuitive semantic.",
                    "label": 0
                },
                {
                    "sent": "We have a large data set.",
                    "label": 0
                },
                {
                    "sent": "And we end up with some subset of that which has the same structure, the elements of which has the same structure.",
                    "label": 0
                },
                {
                    "sent": "And of course, we're sampling.",
                    "label": 0
                },
                {
                    "sent": "We gotta get his acts answers most of the time we're going to get approximate answers to our queries, but this estimation that we're doing to get these approximate answers to our queries on a sample, it's often straightforward.",
                    "label": 0
                },
                {
                    "sent": "You run the analysis on the sample.",
                    "label": 1
                },
                {
                    "sent": "Just in the way you would or the full data, although because it's a sample, some rescaling re weighting of the points in your sample in order to draw an inference about the population from the sample itself.",
                    "label": 0
                },
                {
                    "sent": "Some of this, some rescaling, reweighting may be necessary, and we're going to see when we talk about particular methods for that during the talk.",
                    "label": 0
                },
                {
                    "sent": "Another really nice thing about sampling is as a general method.",
                    "label": 1
                },
                {
                    "sent": "It's it's really agnostic to the analysis which needs to be done in the sense that.",
                    "label": 0
                },
                {
                    "sent": "Other summary methods often only work for certain computations, or they are tide to particular analysis, particular types of aggregates of the data you're looking for.",
                    "label": 0
                },
                {
                    "sent": "That's not to say that you don't need to match sampling to the data and will see one of the themes in this talk.",
                    "label": 0
                },
                {
                    "sent": "Is is talking about how we can tune sampling methods to optimize somehow the combination between the data characteristics and the analysis you want to do.",
                    "label": 0
                },
                {
                    "sent": "But this is a very general property of sampling.",
                    "label": 0
                },
                {
                    "sent": "It makes the method very flexible.",
                    "label": 1
                },
                {
                    "sent": "And usually For these reasons, sampling is usually easy to understand.",
                    "label": 0
                },
                {
                    "sent": "It's so prevalent that we have an intuition about sampling.",
                    "label": 1
                },
                {
                    "sent": "So in this picture, what we're trying to communicate is we have a number of objects of different types, and when we sample we end up with a subset.",
                    "label": 0
                },
                {
                    "sent": "But that subset of objects also contains representatives from the different types of different color objects.",
                    "label": 0
                },
                {
                    "sent": "But you see, we've gone.",
                    "label": 0
                },
                {
                    "sent": "We've.",
                    "label": 0
                },
                {
                    "sent": "We also need to wait our objects.",
                    "label": 0
                },
                {
                    "sent": "They've been, circles have become bigger.",
                    "label": 0
                },
                {
                    "sent": "For the objects we've selected, and by doing that we are able to.",
                    "label": 0
                },
                {
                    "sent": "To get an estimate from the original about the original population from the samples we have.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I've talked about a very general level, the.",
                    "label": 0
                },
                {
                    "sent": "The strengths of sampling.",
                    "label": 0
                },
                {
                    "sent": "What about the alternatives?",
                    "label": 0
                },
                {
                    "sent": "So something is not the only thing we could do.",
                    "label": 1
                },
                {
                    "sent": "There are many other data reduction techniques available.",
                    "label": 1
                },
                {
                    "sent": "For example, dimensionality reduction methods.",
                    "label": 0
                },
                {
                    "sent": "If you look at PCA or singular value decomposition, I can value eigenvector decompositions.",
                    "label": 0
                },
                {
                    "sent": "What we're trying to do here is find the dominant components.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "In essence.",
                    "label": 0
                },
                {
                    "sent": "Agreed to ignore smaller components with low energy, which aren't going to be important for answering.",
                    "label": 0
                },
                {
                    "sent": "Many, many questions.",
                    "label": 1
                },
                {
                    "sent": "On the other hand, these methods can be costly computationally and therefore slow to perform on big data.",
                    "label": 0
                },
                {
                    "sent": "Sketching techniques for streams of data have received a lot of attention.",
                    "label": 1
                },
                {
                    "sent": "Typically we're looking at hash based summaries via random projections, and these protections can then be.",
                    "label": 0
                },
                {
                    "sent": "Then we query to to recover information about the original population.",
                    "label": 0
                },
                {
                    "sent": "However, compared with sampling, these are.",
                    "label": 0
                },
                {
                    "sent": "Somewhat complex to understand.",
                    "label": 0
                },
                {
                    "sent": "And we also.",
                    "label": 0
                },
                {
                    "sent": "I come across a problem, but they limited in function or constraints, in particular analysis.",
                    "label": 0
                },
                {
                    "sent": "So there's a question of generality here as opposed in comparison to sampling.",
                    "label": 0
                },
                {
                    "sent": "And brother transform methods, wavelets for rare transforms, discrete transforms, histograms.",
                    "label": 0
                },
                {
                    "sent": "Powerful, but.",
                    "label": 0
                },
                {
                    "sent": "Basically not so updatable at a high overhead achieved.",
                    "label": 0
                },
                {
                    "sent": "I mean so our view about these positions with respect to what we talk about in this tutorial is.",
                    "label": 0
                },
                {
                    "sent": "I mean these are all very interesting methods and they have strengths and weaknesses, but we're not going to dwell on them already covered the material in this tutorial.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So before we fully embark on the truck tutorial proper.",
                    "label": 0
                },
                {
                    "sent": "We can have a little bit of calculation here.",
                    "label": 0
                },
                {
                    "sent": "We again talk about probabilities and some algorithms, but not in great detail.",
                    "label": 0
                },
                {
                    "sent": "We really want to give a high level descriptions and some intuition about what is going on, but we're going to assume some basics and concepts of probability, expectation, variances, and we get into a mood when we talk about estimation, estimation, accuracy, we're going to allude to.",
                    "label": 1
                },
                {
                    "sent": "Turn off bounds, for example, so the measures of the concentration of our estimates around the true value.",
                    "label": 0
                },
                {
                    "sent": "And please feel free to ask questions about technical details along the way or at the break or afterwards.",
                    "label": 1
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's the outline of the rest of the Tauriel.",
                    "label": 0
                },
                {
                    "sent": "So we can talk about.",
                    "label": 0
                },
                {
                    "sent": "A lot of this talk where we're going through reference applications in large ISP networks, and I'll talk a little bit more about about why that's a good example to look at when I get onto it, we give you talk about the basics of sampling.",
                    "label": 1
                },
                {
                    "sent": "Concepts including estimation.",
                    "label": 1
                },
                {
                    "sent": "And then we're going to move to stream sampling, looking at uniform.",
                    "label": 0
                },
                {
                    "sent": "The weighted case and.",
                    "label": 0
                },
                {
                    "sent": "After the break, we're going to look at more recent work in stream sampling and a way of looking at sampling which.",
                    "label": 0
                },
                {
                    "sent": "This has been found to be very powerful looking into cost optimization.",
                    "label": 0
                },
                {
                    "sent": "At that point I'm going to hand over to Graham.",
                    "label": 1
                },
                {
                    "sent": "And he's going to talk about the role of hashing and coordination in sampling.",
                    "label": 0
                },
                {
                    "sent": "I'm.",
                    "label": 0
                },
                {
                    "sent": "Remember, last major parts visual will concern graph sampling?",
                    "label": 0
                },
                {
                    "sent": "I'm Ben Graham will wrap up with a conclusion.",
                    "label": 0
                },
                {
                    "sent": "I'm talking about future directions.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So as I go through this whole time, I'm going to, I'm going to refer back to.",
                    "label": 0
                },
                {
                    "sent": "Examples in ISP networks.",
                    "label": 0
                },
                {
                    "sent": "So the.",
                    "label": 0
                },
                {
                    "sent": "The road we see for sampling is.",
                    "label": 0
                },
                {
                    "sent": "Really, as a mediator of the constraints that you're under working with Big Data so.",
                    "label": 1
                },
                {
                    "sent": "And we have data characteristics.",
                    "label": 0
                },
                {
                    "sent": "For example, we can have heavy tailed distributions.",
                    "label": 0
                },
                {
                    "sent": "We can have correlations between different variables.",
                    "label": 0
                },
                {
                    "sent": "Then we have resource constraints and we have restraints for bandwidth to recover data for storage that the data we've gotten to collector and CPU and we want to processor for queries.",
                    "label": 0
                },
                {
                    "sent": "And those queries themselves bring requirements themselves.",
                    "label": 0
                },
                {
                    "sent": "We want to execute them with certain time.",
                    "label": 0
                },
                {
                    "sent": "We're interested in certain aggregates of the data.",
                    "label": 0
                },
                {
                    "sent": "We have certain accuracy requirements for the for our queries, and we may not know the queries in advance if we have crammed queries which are used for routine reporting, that's very simple.",
                    "label": 0
                },
                {
                    "sent": "We might not even need sampling at all.",
                    "label": 0
                },
                {
                    "sent": "But if you don't know what the query is in advance.",
                    "label": 0
                },
                {
                    "sent": "Sampling is is is going to enable you to explore the data in an efficient manner, so sampling the role of sampling is to is to sort of relieve the tension between these three constraints and.",
                    "label": 0
                },
                {
                    "sent": "A lot of good sample design comprises of trying to try to relieve this tension in an optimal manner.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I said that a motivating application would be data for Internet service providers.",
                    "label": 0
                },
                {
                    "sent": "And this is going to motivate many of our results and also illustrate with applications in this domain.",
                    "label": 0
                },
                {
                    "sent": "But at the same time, we don't want to give you the idea that the subject matter in the store, the methods are limited to ISPs.",
                    "label": 0
                },
                {
                    "sent": "And I think one of the one of the exciting things about this field is there is a you know.",
                    "label": 0
                },
                {
                    "sent": "Opportunity to take experience and methods which have been successful in one area and import them into other application areas, and.",
                    "label": 0
                },
                {
                    "sent": "As I said, but I think it's a great opportunity for us as the community.",
                    "label": 0
                },
                {
                    "sent": "Now, the reasons many reasons why you want to use some examples.",
                    "label": 0
                },
                {
                    "sent": "One rather practical reason is that both myself and Graham until about a year ago works in the ISP world, so we're very familiar with these examples.",
                    "label": 0
                },
                {
                    "sent": "And indeed, many of the sampling methods that we will talk about talk about here were developed in response to needs in the ISP world.",
                    "label": 1
                },
                {
                    "sent": "This is very practically motivated as well.",
                    "label": 0
                },
                {
                    "sent": "I mean sampling is used widely in monitoring within ISP's, and it's also built into routers and ISP's used in my network.",
                    "label": 0
                },
                {
                    "sent": "And in fact, there's a my talked earlier about the difference between the new big data and older big Data, and ISP's have been working with many of these big data problems for for a number of years, and although not by that name.",
                    "label": 0
                },
                {
                    "sent": "So in fact, there's quite a depth of experience working with big Data in this context.",
                    "label": 0
                },
                {
                    "sent": "But as I said, I think there are many different places where sampling is needed, so we shouldn't regard these methods or the applications here is really limited to ISPs at all.",
                    "label": 1
                },
                {
                    "sent": "But since we're going to be talking about ISP's, let's first.",
                    "label": 0
                },
                {
                    "sent": "Have a little refresher on ISP networks and the sort of big data that arises in them.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here we see the structure of a typical large ISP network.",
                    "label": 1
                },
                {
                    "sent": "We have city level router Centers for example in New York or Seattle or some other big city.",
                    "label": 0
                },
                {
                    "sent": "We have a number of routers connected together.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Routine the city is interconnected with multiple multiple links multiple backbone links.",
                    "label": 0
                },
                {
                    "sent": "Of these city city routers.",
                    "label": 0
                },
                {
                    "sent": "That is, in the in the in the city level router centers we have peering links to other ISPs.",
                    "label": 0
                },
                {
                    "sent": "We have links into customer access networks such as a wireless network or the DSL just will subscriber line to consumers where people may be getting IPTV service over those lines.",
                    "label": 1
                },
                {
                    "sent": "We also have downstream ISP's and business customers data centers where customers being hosted.",
                    "label": 0
                },
                {
                    "sent": "But since customers being hosted and the Network Management Administration servers of the ISP itself.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So you can't manage this networking with, you're measuring it.",
                    "label": 0
                },
                {
                    "sent": "And in fact, there's a lot of measurement that goes on the point about this slide mainly is not so much exactly what measurement is going on, but the fact there is an awful lot of it.",
                    "label": 0
                },
                {
                    "sent": "But just to summarize, there are lots and packet loss and latency measurements arising from either actually probing, sending, sending packets through the network and measuring their loss and latency, or through passive measurements of traffic.",
                    "label": 0
                },
                {
                    "sent": "There are alarms and being raised by device failures and other status reports for practical level transitions.",
                    "label": 1
                },
                {
                    "sent": "What concerns us here, mostly in terms of big data, is measurements of traffic matrices.",
                    "label": 0
                },
                {
                    "sent": "So the routers themselves.",
                    "label": 0
                },
                {
                    "sent": "Compile before measurements on the data flowing through them and on continuous basis and export summary the exports the measurement data it up through a collection infrastructure to a point where they could be analyzed.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "That is what that data source is one that will be talking about quite extensively in this in this talk, but it's not the only big data set.",
                    "label": 0
                },
                {
                    "sent": "For example.",
                    "label": 0
                },
                {
                    "sent": "Protocol monitoring if you.",
                    "label": 0
                },
                {
                    "sent": "If you look in the wireless network, if you look at mobile devices, transmission between base stations, all those transitions are potentially potentially monitors as well, generating traffic of equivalent volume.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To the traffic matrices.",
                    "label": 0
                },
                {
                    "sent": "So let's focus, let's ask sort of the same questions again, but focusing on ISP data, Huawei began to summarize.",
                    "label": 0
                },
                {
                    "sent": "Well.",
                    "label": 0
                },
                {
                    "sent": "One reason we want to summarize is when transmission bandwidth measurements is limited.",
                    "label": 1
                },
                {
                    "sent": "So I mentioned that the routers performing performing measurements on the traffic through them and they are exporting those measurements up a collection of infrastructure to collect collector.",
                    "label": 0
                },
                {
                    "sent": "So historically that the bandwidth to do that was limited because it was done back later.",
                    "label": 0
                },
                {
                    "sent": "Once done out of band, now it's not so much of a big issue.",
                    "label": 0
                },
                {
                    "sent": "And ISP's cassette collection is done in band.",
                    "label": 0
                },
                {
                    "sent": "In other words, it's done on the same path of the traffic takes itself.",
                    "label": 0
                },
                {
                    "sent": "But Even so.",
                    "label": 0
                },
                {
                    "sent": "Roy accumulation of these of these measurements is.",
                    "label": 0
                },
                {
                    "sent": "It's not feasible.",
                    "label": 0
                },
                {
                    "sent": "We have high stream.",
                    "label": 0
                },
                {
                    "sent": "We have this high rate streaming data.",
                    "label": 1
                },
                {
                    "sent": "And what we want to do is, is given that we can't accumulate it indefinitely, what's the alternative?",
                    "label": 0
                },
                {
                    "sent": "Well, then we have to maintain some kind of summary that we can use for Baselining time series analysis.",
                    "label": 0
                },
                {
                    "sent": "Baseline, if we for example want to do anomaly detection.",
                    "label": 0
                },
                {
                    "sent": "If we want to compare what we see now with what we've seen historically is, is there a difference which is anomalous?",
                    "label": 1
                },
                {
                    "sent": "We also want to facilitate fast queries.",
                    "label": 0
                },
                {
                    "sent": "It's infeasible to run exploratory queries over the full data if we can run with the sample data set.",
                    "label": 1
                },
                {
                    "sent": "We can.",
                    "label": 0
                },
                {
                    "sent": "We can do this potentially interactively, and that's going to get to be a lot more powerful for the analyst in terms of getting the results they need.",
                    "label": 0
                },
                {
                    "sent": "And all of this could be can be wrapped as part of a hierarchical query instruction infrastructure.",
                    "label": 0
                },
                {
                    "sent": "We can think of maintaining full date even though we can't maintain it indefinitely.",
                    "label": 1
                },
                {
                    "sent": "Maintain the full data over some limited duration window.",
                    "label": 0
                },
                {
                    "sent": "You know a few hours, a few days, whatever.",
                    "label": 0
                },
                {
                    "sent": "And then drill down into that full data through one or more layers of summarization so fast.",
                    "label": 1
                },
                {
                    "sent": "Query with with with summarized data, and then when something can trigger, drill down into the full days when we see something interesting.",
                    "label": 0
                },
                {
                    "sent": "And that can be done either at the level of an analyst working with the data or it can be done in an automated system.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 1
                },
                {
                    "sent": "My point here is that sampling has proved to be a flexible method to accomplish all these goals.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's talk more about the challenge of scale in this Jason summarize and how we going to summarize and samples.",
                    "label": 0
                },
                {
                    "sent": "So here we go into this truck.",
                    "label": 0
                },
                {
                    "sent": "We get into sort of going two strands.",
                    "label": 0
                },
                {
                    "sent": "We're going to be talking about the ISP data and the methods we bought a bet on that.",
                    "label": 0
                },
                {
                    "sent": "But we're also going to set this in the context of more general work in sampling and summarization for big data.",
                    "label": 1
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I mentioned in the previous slide that in on on ISP networks that one of the largest data sources comes from these traffic matrices.",
                    "label": 1
                },
                {
                    "sent": "What are called Flow Records, which are the measurements which are compiled by routers on the traffic which flow through them.",
                    "label": 1
                },
                {
                    "sent": "So let's talk a bit about water flows or water flow records so.",
                    "label": 0
                },
                {
                    "sent": "What this diagram illustrates is a timeline in which we have packets arriving at a router.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Answer The packets of these these rectangular boxes and the packets.",
                    "label": 0
                },
                {
                    "sent": "We've colored them according to.",
                    "label": 0
                },
                {
                    "sent": "A property which we call a key and we can think of the key is labeling a transaction.",
                    "label": 0
                },
                {
                    "sent": "So a key of a packet can comprise its IP source and destination address is TCP UDP ports.",
                    "label": 0
                },
                {
                    "sent": "It's type of service field and so on.",
                    "label": 0
                },
                {
                    "sent": "And this these fields together comprise, you know anyway, at least 64 bits, maybe more depending on the information you want to consider included.",
                    "label": 0
                },
                {
                    "sent": "So an IP flow is a set of packets with a common key observed closely in time.",
                    "label": 1
                },
                {
                    "sent": "So if you think about what that means, you know why do we observe a?",
                    "label": 0
                },
                {
                    "sent": "Why does the Rapture observer set a package for the common key?",
                    "label": 0
                },
                {
                    "sent": "Well, there's there's a.",
                    "label": 0
                },
                {
                    "sent": "There's an Internet transaction going on.",
                    "label": 0
                },
                {
                    "sent": "There's somebody sitting at a computer browsing website.",
                    "label": 0
                },
                {
                    "sent": "The request goes off to the website.",
                    "label": 0
                },
                {
                    "sent": "AP HTTP request goes off the website, then a set of packets comes back and that request.",
                    "label": 0
                },
                {
                    "sent": "It can be will.",
                    "label": 0
                },
                {
                    "sent": "In this scheme we think of as one flow and then the set of packets coming back with the with the content that was requested.",
                    "label": 0
                },
                {
                    "sent": "We think about as another flow.",
                    "label": 0
                },
                {
                    "sent": "And what a flow record is?",
                    "label": 1
                },
                {
                    "sent": "It's a protocol level summary of the flow compiled and exported by the routers, so.",
                    "label": 0
                },
                {
                    "sent": "The flow record would comprise the flow key counts of the packets and bytes.",
                    "label": 0
                },
                {
                    "sent": "If all the packets in the flow, some timing information.",
                    "label": 0
                },
                {
                    "sent": "When was the first and last packet of fat flow observed, and some router states, for example, which interfaces the packets and the float reversed through the router.",
                    "label": 0
                },
                {
                    "sent": "And this is realized.",
                    "label": 0
                },
                {
                    "sent": "It's part of the operating system in Cisco.",
                    "label": 0
                },
                {
                    "sent": "Another router vendors and also in standards in the Internet Engineering Task Force.",
                    "label": 0
                },
                {
                    "sent": "So Netflow is the name of the operating system feature.",
                    "label": 0
                },
                {
                    "sent": "In Cisco routers that performs this.",
                    "label": 0
                },
                {
                    "sent": "And so the scale here.",
                    "label": 1
                },
                {
                    "sent": "Well, we can have hundreds or even more terabytes of Flow records daily generated by a large ISP.",
                    "label": 0
                },
                {
                    "sent": "If we did nothing about it.",
                    "label": 1
                },
                {
                    "sent": "So if you can think of this as a sort of pre reduction number.",
                    "label": 0
                },
                {
                    "sent": "And these flow records they used to manage the network over a range of time scales.",
                    "label": 1
                },
                {
                    "sent": "From capacity planning, understanding the growth of traffic patterns.",
                    "label": 0
                },
                {
                    "sent": "Overtime scales are months.",
                    "label": 0
                },
                {
                    "sent": "You know where we get, where we want to put in a new link.",
                    "label": 0
                },
                {
                    "sent": "For example, two detecting network attacks.",
                    "label": 0
                },
                {
                    "sent": "The timescales are seconds, and some of these analysis tasks are relatively easy if we're looking at a time series of predetermined aggregates.",
                    "label": 0
                },
                {
                    "sent": "For example, how much traffic flow to a given rashing prefix for.",
                    "label": 1
                },
                {
                    "sent": "In every five minute window of the day, that's a very, very easy query and we can just do it, but essentially by accumulation.",
                    "label": 1
                },
                {
                    "sent": "Happy.",
                    "label": 0
                },
                {
                    "sent": "At the collector, hard charts are to do fast queries over exploratory selectors.",
                    "label": 0
                },
                {
                    "sent": "We don't know until the moment we issue the query what which traffic want to select, which set of IP address IP addresses were interested in, or more generally, what combination of Floki fields, timely information, router state and so forth that we were interested in and we want to be able to do this.",
                    "label": 0
                },
                {
                    "sent": "We won't be able to issue these queries historically, not just over this limited window.",
                    "label": 0
                },
                {
                    "sent": "Full data that we have.",
                    "label": 0
                },
                {
                    "sent": "And we're also interested not just in what I call essentially 1 dimensional queries, which is how much how much traffic.",
                    "label": 0
                },
                {
                    "sent": "Flow in a given period of time.",
                    "label": 0
                },
                {
                    "sent": "With a particular key, for example, how much traffic flowed from this IP address to this IP address, we're interested in communication subgraphs, patterns of communication which might indicate, for example, anomalous network activity such as anonymous service attack or a botnet.",
                    "label": 0
                },
                {
                    "sent": "So those kind of queries in fact far harder.",
                    "label": 0
                },
                {
                    "sent": "Try to perform auto accommodates in a sampled setting.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's talk a bit about how sampling arises even in this context.",
                    "label": 0
                },
                {
                    "sent": "In fact, there are two types of sampling that are used in practice for this Internet traffic measurement.",
                    "label": 1
                },
                {
                    "sent": "The routers themselves actually sample the packet stream.",
                    "label": 0
                },
                {
                    "sent": "A.",
                    "label": 1
                },
                {
                    "sent": "Prior to forming the Flow Records and the reason they and this is Jimmy to a constraint, and this illustrates a broader point that often the way you do sampling on the need to do sampling is constrained by by by implementation factors.",
                    "label": 0
                },
                {
                    "sent": "So every time a packet comes in.",
                    "label": 0
                },
                {
                    "sent": "The router would have to determine which which is the flow record, which it should update, and by sampling the packet stream and only doing that update on a subset of packets, the router limits the work it has to do.",
                    "label": 0
                },
                {
                    "sent": "And this is realized with a variant of Netflow called Packet Sample Netflow.",
                    "label": 0
                },
                {
                    "sent": "Now, once the flow records have been.",
                    "label": 0
                },
                {
                    "sent": "Compiled waiver without packet sampling once they being compiled, then they're exported through the through the collection infrastructure of the ISP to Alexa, and if we sample these flow records, the completed flow records can themselves be subject to sampling, either to limit transmission bandwidth or the limit storage, and these methods are also realized in ISP collection measurement infrastructure and also on the threshold of standardization in the Internet Engineering Task Force.",
                    "label": 0
                },
                {
                    "sent": "And also we get to come more about that.",
                    "label": 0
                },
                {
                    "sent": "Those are those two examples later.",
                    "label": 0
                },
                {
                    "sent": "But these two cases, in fact, the way you do sampling turns out to be.",
                    "label": 0
                },
                {
                    "sent": "Difference and these will also illustrate a general property that and the reason for that is through different underlying distributions of the of the of the objects.",
                    "label": 0
                },
                {
                    "sent": "If you look at packets as opposed to flows, then the distribution.",
                    "label": 0
                },
                {
                    "sent": "So for example the bytes are very different from this requires different sample designs.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "Although another principle we'll see is that the.",
                    "label": 0
                },
                {
                    "sent": "We often have many design choices, and in fact there's been a lot of research work focused on this problem.",
                    "label": 0
                },
                {
                    "sent": "How should you do sampling?",
                    "label": 0
                },
                {
                    "sent": "Should you do it at the packet level or the flow level and?",
                    "label": 0
                },
                {
                    "sent": "In fact, it turns out that sometimes the statistically optimal thing to do is not computationally feasible with the hardware or software you have available, so there's illustrating both.",
                    "label": 0
                },
                {
                    "sent": "There can be a tradeoff there.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well, let's.",
                    "label": 0
                },
                {
                    "sent": "Let's go back to this picture and let's restate it in abstract form.",
                    "label": 0
                },
                {
                    "sent": "And our abstraction for these flow records.",
                    "label": 0
                },
                {
                    "sent": "Is our data model.",
                    "label": 0
                },
                {
                    "sent": "This is going to be keyed weights so.",
                    "label": 0
                },
                {
                    "sent": "An object a kid wait is is an object with two 2 components await X and a key K. So here are three examples.",
                    "label": 0
                },
                {
                    "sent": "First object first example.",
                    "label": 0
                },
                {
                    "sent": "My objects are packets.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "My weight is the number of bytes for that packets that package contains, and the key K is just the key.",
                    "label": 0
                },
                {
                    "sent": "As I talked about in the previous slide, the IP flow key.",
                    "label": 0
                },
                {
                    "sent": "My second example.",
                    "label": 0
                },
                {
                    "sent": "The objective flows.",
                    "label": 0
                },
                {
                    "sent": "In other words, there aggregates of packets aggregate into a flow record and ex could be the number of packets in that represented in that flow record, or the number of bytes and K is the key as before, and our third example just over some non ISP example is by objects account updates in a in a financial system.",
                    "label": 0
                },
                {
                    "sent": "So here X could be signed.",
                    "label": 0
                },
                {
                    "sent": "It's a credit or debit for an account which is the key.",
                    "label": 0
                },
                {
                    "sent": "And so.",
                    "label": 0
                },
                {
                    "sent": "In this model I have a stream of these keyed weights.",
                    "label": 0
                },
                {
                    "sent": "And the generic query concerned subset samples.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "I have, you know I had this dream event waits for some subset S. Of these, these N objects that I'm interested in.",
                    "label": 0
                },
                {
                    "sent": "And the subset sum is just the sum of the weights of the objects in that subset through that Big S Big XS is the total weight in my index subset S. Now, in a lot of applications to you typically are subsets that S is going to be SSFC those objects whose key lies in some key set.",
                    "label": 0
                },
                {
                    "sent": "Some subset of all possible keys, Capital K. So in this case my if I if I come back to my examples now, I can think of my subset sum X of S of K being the total bytes to a given.",
                    "label": 0
                },
                {
                    "sent": "For example were given IP, destination address or UDP port as specified by Mikey Set K. Or in the third example, I could think of it as being the total balance change over a set of accounts over a period of time.",
                    "label": 1
                },
                {
                    "sent": "And the aim I'm gonna set myself is to compute a fixed size summary of this stream that can be used for estimated arbitrary subset sums with known error bounds, so that's.",
                    "label": 1
                },
                {
                    "sent": "I really quite a broad goal, so how we going to achieve this well?",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here's a framework we're going to use inclusion sampling and estimation, so the key method here was formalized by Hoverson Thompson in 1952.",
                    "label": 0
                },
                {
                    "sent": "Which is that?",
                    "label": 0
                },
                {
                    "sent": "If we just consider an object the size XI and we get a sample it with some probability P. So this is just emerging some.",
                    "label": 0
                },
                {
                    "sent": "But this is just a marginal sampling probability.",
                    "label": 0
                },
                {
                    "sent": "I mean I mean have independent sampling math correlated sampling.",
                    "label": 0
                },
                {
                    "sent": "I'm not concerned with those distinctions at the moment, I'm just going to say suppose I select this object of size X with probability P. Well, I can form an unbiased estimate of X by taking.",
                    "label": 0
                },
                {
                    "sent": "By dividing X by P. If I do sample and otherwise.",
                    "label": 0
                },
                {
                    "sent": "My estimate is zero implicitly if I'm not sampled and.",
                    "label": 0
                },
                {
                    "sent": "So the expectation of this of my estimate X prime.",
                    "label": 0
                },
                {
                    "sent": "Over these two possible outcomes.",
                    "label": 0
                },
                {
                    "sent": "Is X because I sample it with probability that the expectation is the weighted sum?",
                    "label": 0
                },
                {
                    "sent": "Of the outcome, so I've X / P or 0 weighted by the probability I have P * X / P, which is X + 1 -- P * 0, so my which gives me X.",
                    "label": 0
                },
                {
                    "sent": "So my average my expectation of X prime is X, so that's I have an unbiased estimate.",
                    "label": 0
                },
                {
                    "sent": "Now one really powerful property of this type of estimation is linearity.",
                    "label": 0
                },
                {
                    "sent": "So I can estimate a subset sum by the sum of the matching estimates.",
                    "label": 0
                },
                {
                    "sent": "So in other words, if I have a subset sum X of S. I can estimate it by X prime of X, which is, which is just the sum of the X primes.",
                    "label": 0
                },
                {
                    "sent": "In other words, the sum of the unbiased estimates of each of the individual excise.",
                    "label": 0
                },
                {
                    "sent": "And because because the individual exercise.",
                    "label": 0
                },
                {
                    "sent": "Around XI primes are unbiased.",
                    "label": 0
                },
                {
                    "sent": "It also means that X prime of S is unbiased as well.",
                    "label": 0
                },
                {
                    "sent": "This expectation is the true value XNS.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "As we'll see in more detail.",
                    "label": 0
                },
                {
                    "sent": "We can compute in terms of accuracy.",
                    "label": 0
                },
                {
                    "sent": "We can compute exponential bounds confidence intervals for these.",
                    "label": 0
                },
                {
                    "sent": "So in other words, we can say the probability that the difference between the estimate and the true value exceeds some proportion of the true value is exponentially small, and the larger the thing we're trying to estimate is, the smaller the smaller the probability that we get error of a given amount.",
                    "label": 0
                },
                {
                    "sent": "Well, that's that's that's a question.",
                    "label": 0
                },
                {
                    "sent": "What is the Pi?",
                    "label": 0
                },
                {
                    "sent": "So it's going to be up to us to select the P and so how we do that is going to be, you know what we're going to talk about if you minutes, but this this is a framework saying if we do have some peas, this is how we do estimation.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "I mean the thing about sampling.",
                    "label": 0
                },
                {
                    "sent": "This comes back to my point about about.",
                    "label": 0
                },
                {
                    "sent": "About household queries.",
                    "label": 0
                },
                {
                    "sent": "We don't actually need to know what in advance the queries that we're going to do at the time of sampling.",
                    "label": 0
                },
                {
                    "sent": "It says in the ISP context if we want to know when or where did that suspicious UDP port first become through active, or which is the most active IP address within some subset of anomalous traffic?",
                    "label": 1
                },
                {
                    "sent": "Well, those were questions I can phrase in terms of a subset sum query and then I can go back to my samples and say I'm form an unbiased estimate from the from the object I have in my sample.",
                    "label": 0
                },
                {
                    "sent": "Ask and I didn't need to.",
                    "label": 0
                },
                {
                    "sent": "Didn't need to know what my subset sum my subset was at the time I did the selection.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, So what are parents different parents?",
                    "label": 0
                },
                {
                    "sent": "So what are the peas?",
                    "label": 0
                },
                {
                    "sent": "So here are some peas.",
                    "label": 0
                },
                {
                    "sent": "So simplest way you can do this in the stream Bernoulli sampling.",
                    "label": 1
                },
                {
                    "sent": "Yeah, IID sampling of objects with some probability P. And in this case the sampled, if I'm sampling an object of latex, the Horvitz Thompson estimator is just X / P if I sample.",
                    "label": 1
                },
                {
                    "sent": "The generalization of this plus on sampling where my weight XC sample with some probability P and the P the probability depends on the object.",
                    "label": 0
                },
                {
                    "sent": "It's not uniform, but again I have my hub.",
                    "label": 0
                },
                {
                    "sent": "It's Trump's next estimate X / P. So when do I?",
                    "label": 1
                },
                {
                    "sent": "When do I want to use plus one versus Bernoulli?",
                    "label": 0
                },
                {
                    "sent": "Well, that's the key.",
                    "label": 0
                },
                {
                    "sent": "Here is we'll see is that is that if we are interested in weights an interest in their in their values and estimates of waves, we need to have a PC which is summer tunes with those weights.",
                    "label": 0
                },
                {
                    "sent": "If we're not really interested in the waves, or if the weights.",
                    "label": 0
                },
                {
                    "sent": "If the if the weights at the way it's real rough the same, there's no skew.",
                    "label": 0
                },
                {
                    "sent": "The distribution then we can probably get away with uniform sampling.",
                    "label": 0
                },
                {
                    "sent": "So in the elephants versus mice pitch, if we were interested in elephants, we better have some sampling probability, which respects the weight of the elephants.",
                    "label": 0
                },
                {
                    "sent": "But we can generalize this.",
                    "label": 0
                },
                {
                    "sent": "What's the best choice?",
                    "label": 1
                },
                {
                    "sent": "The choice of sampling probabilities for a given stream.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm.",
                    "label": 0
                },
                {
                    "sent": "Well, yeah, in Bernoulli sampling, if you have any objects and we want to sample care of them uniformly, then each possible subset of K should be equally likely.",
                    "label": 1
                },
                {
                    "sent": "So we can uniformly sample an index from from North without replacement K times.",
                    "label": 1
                },
                {
                    "sent": "And that's how we get our sample.",
                    "label": 0
                },
                {
                    "sent": "But there are some subtleties here, you know, do we have truly random numbers?",
                    "label": 1
                },
                {
                    "sent": "Can we get them on our computer?",
                    "label": 1
                },
                {
                    "sent": "People generally assume that random number generators are good enough, but of course there's been a lot of work that's gone into avoiding pitfalls of bad random random number generators.",
                    "label": 1
                },
                {
                    "sent": "A common trick in the database world is to assign a random number to each item and then sort.",
                    "label": 1
                },
                {
                    "sent": "And then you can pick out the top items from that random number, and we're going to see we're about lots of variants of that approach in a little while.",
                    "label": 0
                },
                {
                    "sent": "This can be very costly if I'm number of items is very big, but then again, if we're not sorting, so is random access to go and go and find the objects.",
                    "label": 1
                },
                {
                    "sent": "So there are tradeoffs there.",
                    "label": 0
                },
                {
                    "sent": "So an interesting problem is.",
                    "label": 0
                },
                {
                    "sent": "Can we take a single linear scan through the data to draw this sample?",
                    "label": 0
                },
                {
                    "sent": "And in the streaming model of computation, we see each element in our data set once, and of course, there's an obvious application here.",
                    "label": 0
                },
                {
                    "sent": "I hope in what we've been talking about before with these flow records, we have the stream of Flow Records and coming into our collector.",
                    "label": 0
                },
                {
                    "sent": "If there are too many of those for us to store, at least over an extended.",
                    "label": 0
                },
                {
                    "sent": "Then we can sample them and actually for awhile.",
                    "label": 0
                },
                {
                    "sent": "This was a common interview for Tech positions.",
                    "label": 0
                },
                {
                    "sent": "In other words, commonly few questions for tech positions.",
                    "label": 0
                },
                {
                    "sent": "So how do we achieve this?",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Precisely how we achieve it is through reservoir sampling and this was described by Kenneth and and enhanced by Vista.",
                    "label": 0
                },
                {
                    "sent": "So what we want to do is find a fixed size K uniform sample from an arbitrary size upstream of size N objects in one pass.",
                    "label": 1
                },
                {
                    "sent": "And with no need to know the stream size in advance.",
                    "label": 0
                },
                {
                    "sent": "Well, what we're going to do is.",
                    "label": 0
                },
                {
                    "sent": "Well, let's just take the first K items.",
                    "label": 0
                },
                {
                    "sent": "That simple, OK will take the first K items from our stream.",
                    "label": 0
                },
                {
                    "sent": "We got N -- K items left.",
                    "label": 0
                },
                {
                    "sent": "So WP Abbreviates with probability, so with probability one we're going to include the first K items.",
                    "label": 0
                },
                {
                    "sent": "Napa.",
                    "label": 0
                },
                {
                    "sent": "Any any item any of the subsequent items we want to include it with the probability K / N. By the way, one way to achieve this is we're going to pick.",
                    "label": 0
                },
                {
                    "sent": "I'm index J uniformly in one 2 N. And then if for any item and then if J is less than K, we're going to take that new item and swap it into the J position and discard the item which replaced.",
                    "label": 0
                },
                {
                    "sent": "If JS Grace McKay, we do nothing, we just keep the sample as we are.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Because there are K possible ways of being less than or equal to K chaos of the possible ways of being less than or equal to K, the probability that that new object gets swapped in is K / M. And.",
                    "label": 1
                },
                {
                    "sent": "So why does this achieve what we want?",
                    "label": 0
                },
                {
                    "sent": "Well, there's a fairly short proof that establishes uniformity of the sampling method.",
                    "label": 0
                },
                {
                    "sent": "So let F sub N be the sample set I have after N arrivals.",
                    "label": 0
                },
                {
                    "sent": "So here's a case where we have K = 7.",
                    "label": 0
                },
                {
                    "sent": "I've taken my first.",
                    "label": 0
                },
                {
                    "sent": "Seven items.",
                    "label": 0
                },
                {
                    "sent": "And my.",
                    "label": 0
                },
                {
                    "sent": "Generally, at some point later I have my empty item.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "It's selection probability where we've just just computed that it's selection probability is K / N. Which is what we want.",
                    "label": 0
                },
                {
                    "sent": "But what about the existing something at a position M?",
                    "label": 0
                },
                {
                    "sent": "Lesser men, which is previously sampled well.",
                    "label": 0
                },
                {
                    "sent": "We can show that we get the right sampling probability by induction, so.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "Suppose.",
                    "label": 0
                },
                {
                    "sent": "Suppose M was a member, so suppose it had been selected into the N -- 1 set with probability P N -- 1, which is K / N -- 1, which was the inclusion probability what we wanted.",
                    "label": 0
                },
                {
                    "sent": "Then it survives to be a member of SM.",
                    "label": 0
                },
                {
                    "sent": "The the selection set off again, vitam well.",
                    "label": 0
                },
                {
                    "sent": "We take a product of the probability that was there in the 1st place where the complement of the probability that the next guy got swapped in.",
                    "label": 0
                },
                {
                    "sent": "So in other words, that's the probability that I was there to start with a 10 -- 1 and I didn't get swapped, swapped out at stage N and that's probability of ice tea with some probability that I'm that I'm in the sample after end times.",
                    "label": 0
                },
                {
                    "sent": "And if you just do the algebra and that it turns out to be PN elements K / M. So that's that's that's the proof that in fact this.",
                    "label": 0
                },
                {
                    "sent": "This this method achieves uniform sampling.",
                    "label": 0
                },
                {
                    "sent": "So that was that the basic idea due to use kluth and.",
                    "label": 0
                },
                {
                    "sent": "But you gotta think about.",
                    "label": 0
                },
                {
                    "sent": "Yeah, how costly is it to do all these steps?",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So simple approach could be very much if I just described each item comes in and I do.",
                    "label": 1
                },
                {
                    "sent": "I do a computation I I decide at random whether or not that item should be swapped in so this I can think of this cost as sort order, one per item.",
                    "label": 1
                },
                {
                    "sent": "Well, that's fine if the time it takes to do my computation is.",
                    "label": 1
                },
                {
                    "sent": "Is always on average less my interarrival time between objects?",
                    "label": 0
                },
                {
                    "sent": "But if it's not, then I'm gonna build up a computation battle backlog.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 1
                },
                {
                    "sent": "A better approach for this problem is skip counting, which is rather ban rather than do my check for each arriving item in term.",
                    "label": 0
                },
                {
                    "sent": "Since those those decisions are independent and actually don't depend on the objects themselves.",
                    "label": 0
                },
                {
                    "sent": "I can find a random index of the next time a selection will take place.",
                    "label": 0
                },
                {
                    "sent": "And in fact, the distribution function for this.",
                    "label": 0
                },
                {
                    "sent": "So the probability that the index of my next selection M of N. After I've done the NTH selection is less than or equal to.",
                    "label": 0
                },
                {
                    "sent": "220 particular value MI can get just by looking at the probabilities that I don't do selections in all the steps up to step M and now this the computation of of those probabilities and the generation of random variance in fact is itself fairly involved, I know, but I know that the expected number of selections I have to do.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "Is just the sum of of.",
                    "label": 0
                },
                {
                    "sent": "Off of my first of K and there was number of selections they did 2 plus plus the probability that I have to make a selection of each subsequent step.",
                    "label": 0
                },
                {
                    "sent": "In other words, the sum of PM my selection probabilities from K all the way up to N. That subject has, you know, has is is not order N. In fact it's it's far less.",
                    "label": 0
                },
                {
                    "sent": "It's this order came into one plus log M / K and in fact Visa.",
                    "label": 0
                },
                {
                    "sent": "One of these contributions in his 8085 paper was actually to provide an algorithm to compute the next selection index with this average running time.",
                    "label": 1
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So, um.",
                    "label": 0
                },
                {
                    "sent": "If you consider generalizations of this.",
                    "label": 0
                },
                {
                    "sent": "I come with a number of names of order sampling, bottom case, sample min hashing and the idea is that.",
                    "label": 0
                },
                {
                    "sent": "We going to uniformly sample.",
                    "label": 0
                },
                {
                    "sent": "We want a uniform sample of a stream into this reservoir size K. So what we're going to do is how we actually generate those probabilities.",
                    "label": 0
                },
                {
                    "sent": "We're going to generate are a one time Ramson variable for each each each object.",
                    "label": 0
                },
                {
                    "sent": "Which is drawn from uniformly from the interval 01 and in different context depending on who did the work.",
                    "label": 0
                },
                {
                    "sent": "This number is also known as a hash or rank A tag.",
                    "label": 1
                },
                {
                    "sent": "You'll see these different terminology is applied to the same basic idea.",
                    "label": 0
                },
                {
                    "sent": "So what we're really trying to do you can think of in reservoir sampling is is we want to store the key items with the smallest random tags.",
                    "label": 1
                },
                {
                    "sent": "So if you think about how this works with just one item, so here's some arriving items I'm going to generate a random tag.",
                    "label": 0
                },
                {
                    "sent": "Here comes an extra item.",
                    "label": 0
                },
                {
                    "sent": "Comes the next item.",
                    "label": 0
                },
                {
                    "sent": "And this is the green item has now has the smallest tag present.",
                    "label": 0
                },
                {
                    "sent": "And now here's this is the last item.",
                    "label": 0
                },
                {
                    "sent": "The yellow item happens to have the smallest, smallest tag of each of those uniformly so.",
                    "label": 1
                },
                {
                    "sent": "And you can see if I'd been interested in just selecting one item from.",
                    "label": 0
                },
                {
                    "sent": "This said, if I just maintained the item with the smallest tag throughout that evolution, then I would have I would have selected my one item and each item of course has the same chance of being the least tag having these tags.",
                    "label": 1
                },
                {
                    "sent": "So my son could have been uniform, and in general whether it's for K = 1 or general K. This is this is very easy to implement via priority queue I'm just maintaining.",
                    "label": 0
                },
                {
                    "sent": "CVK objects with smallest tag and one strength is if I have.",
                    "label": 1
                },
                {
                    "sent": "I can distribute this calculation 'cause I can run this on multiple streams separately and then merge for a global minimum over my over my results.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So so far we've been.",
                    "label": 1
                },
                {
                    "sent": "Doing uniform sampling mystream using a reservoir, but what if?",
                    "label": 1
                },
                {
                    "sent": "We want to do nonuniform sampling from weighted streams.",
                    "label": 1
                },
                {
                    "sent": "Well, if we have an easy case K equals one, we can.",
                    "label": 0
                },
                {
                    "sent": "We just say one objects I can.",
                    "label": 0
                },
                {
                    "sent": "My objects have weight XN.",
                    "label": 0
                },
                {
                    "sent": "Then I can have a sampling probability of my NTH objects which is.",
                    "label": 0
                },
                {
                    "sent": "But I take my weight.",
                    "label": 1
                },
                {
                    "sent": "My weight XL and divide it by the sum of the first N. The weights of the sum of the weights of the first 10 objects.",
                    "label": 0
                },
                {
                    "sent": "General cases harder we can have elements with a large weight and and should this be sampled, probability one or?",
                    "label": 1
                },
                {
                    "sent": "Alright, so we need a consistent way to handle this, and in fact there have been a number of different weighted order sampling schemes which have been proposed release to realize different distributional objectives, but they will have this.",
                    "label": 0
                },
                {
                    "sent": "We can set them into a common framework of computing a rank which is a function both of some random number UN distributed uniformly in 01 and the weight itself.",
                    "label": 0
                },
                {
                    "sent": "And so I'm going to get to talk about a couple of these.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "I'm.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Weighted random sampling generalizes.",
                    "label": 0
                },
                {
                    "sent": "This mean winds minimize sampling, so here for each item we going to draw a rank uniformly in the range 01, and then compute A tag which is our end to the power 1 / X N. Or if you think about this, Robert logarithmically, it's you can think of the order properties of the same as log of our divided by XM, and then we're going to keep the items with this KK smallest tags.",
                    "label": 1
                },
                {
                    "sent": "And it can be proved that.",
                    "label": 1
                },
                {
                    "sent": "But this actually generates an exponential sampling distribution.",
                    "label": 1
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "This can also be made efficient.",
                    "label": 0
                },
                {
                    "sent": "Fire skip counting ideas here 'cause it's a bit more complex as we need to take information about the weights, the weights of the account, not just the counts of the eye.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Priority sampling is another order sampling scheme with which is focused on some related goals.",
                    "label": 0
                },
                {
                    "sent": "So here.",
                    "label": 0
                },
                {
                    "sent": "Each item XI we get a generator priority.",
                    "label": 1
                },
                {
                    "sent": "Z, which is XI over RI where RI is uniformly random between zero and one.",
                    "label": 0
                },
                {
                    "sent": "So this plays a role of tag, the rank and so forth.",
                    "label": 0
                },
                {
                    "sent": "And then in the rest of our context, we're going to maintain a reservoir of K plus one items, those which have the highest priority.",
                    "label": 0
                },
                {
                    "sent": "So here again, you can realize this as a as a as a priority queue where we are based on the priority of Z.",
                    "label": 0
                },
                {
                    "sent": "And then how do you do estimation?",
                    "label": 0
                },
                {
                    "sent": "Well, letter Z star be the K plus first highest priority.",
                    "label": 0
                },
                {
                    "sent": "For the top K priority items, we're going to estimate the weight of XI by XI prime, which is the Max of XI and Z star.",
                    "label": 0
                },
                {
                    "sent": "And all the other other items implicitly, their weight estimate is 0 because they never make they are no longer in the reservoir.",
                    "label": 0
                },
                {
                    "sent": "And in fact, you can show that that these exercise are so defined, unbiased, and they even have zero covariance.",
                    "label": 0
                },
                {
                    "sent": "It is a useful property because it means you can estimate the variance of a subset sum by the sum of the variance of its components.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Also, the relative variance of any subset sum is bounded above by 1 / K -- 1, where care size for sample.",
                    "label": 1
                },
                {
                    "sent": "So again, that's very powerful uniform result.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well, let's see how that works in databases.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "So you know, in the streaming context we had a reservoir and items were being presented at reservoir and they were making decisions to provision, include them and then possibly reject them as when their priorities were no longer in the top K priorities.",
                    "label": 0
                },
                {
                    "sent": "Another way to look at this, and we refer to that a bit earlier when we talked about talked about order sampling in databases.",
                    "label": 0
                },
                {
                    "sent": "In this specific case, we're going to say, well, we can do a one time preparation on all our items, so rather have a stream.",
                    "label": 0
                },
                {
                    "sent": "This assume we have them have other items in the database, but let's pick out each item and compute our priority in the same way as we did before.",
                    "label": 0
                },
                {
                    "sent": "Take the weight of the object and divide by the uniform random number, and then let's sort these or any sort of index in decreasing priority order, and so no discard.",
                    "label": 0
                },
                {
                    "sent": "We're just going to do this computation and this sort.",
                    "label": 0
                },
                {
                    "sent": "So how we do sampling and estimation is we going to estimate any subset sum excess by X prime.",
                    "label": 1
                },
                {
                    "sent": "That should be X prime of S prime.",
                    "label": 0
                },
                {
                    "sent": "So some some subset sum over.",
                    "label": 0
                },
                {
                    "sent": "Ran over a subset S prime of S. All of our estimates X prime.",
                    "label": 0
                },
                {
                    "sent": "And how we gained to form this sum is we're going to select items in decreasing priority order advert out of our ordered list of items and there are two ways of doing this depending on whether we want to bound variance or complexity in the first variance.",
                    "label": 1
                },
                {
                    "sent": "We're just going to.",
                    "label": 0
                },
                {
                    "sent": "Pick the first K items in decreasing priority order from original Set S. And.",
                    "label": 1
                },
                {
                    "sent": "If we do that, then using the using the previous variance band, we know that our relative variance is going to be bounded by 1 / K -- 1.",
                    "label": 0
                },
                {
                    "sent": "And in this case, when we do our estimation, we're going to take our X prime is going to be the maximum of X with Z star where Z star is the K plus first highest priority within S alone.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "Of course, we all know we have control over variance here.",
                    "label": 0
                },
                {
                    "sent": "We don't necessarily have control over the execution time 'cause we don't know how long it's going to take us to go through our walk down list of all items until we hit the Kay plus first item that happens to be in S. So if execution time is important to you, you can do it another way.",
                    "label": 1
                },
                {
                    "sent": "You can just pick the first K items regardless of whether they are in South or not.",
                    "label": 0
                },
                {
                    "sent": "So we know that our execution time is bounded bounded in order K. Um?",
                    "label": 0
                },
                {
                    "sent": "And then we just pick out of those K items all those which happened to lie in SORS Prime is the items from S which happened to be in the 1st first day of all of the items.",
                    "label": 0
                },
                {
                    "sent": "In this case we have to use the right Z star.",
                    "label": 0
                },
                {
                    "sent": "So here we use when we do our estimates in for ex prime.",
                    "label": 0
                },
                {
                    "sent": "Here's the Star is a K plus first highest priority anywhere in the.",
                    "label": 0
                },
                {
                    "sent": "The data set not just not just that matching X.",
                    "label": 0
                },
                {
                    "sent": "Matching S sorry.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well, can we make these stream samples?",
                    "label": 0
                },
                {
                    "sent": "Smarter observation here is we can see the whole stream.",
                    "label": 1
                },
                {
                    "sent": "Even if we can't store it, so can we keep more information about samples items if they are repeated?",
                    "label": 1
                },
                {
                    "sent": "For example, if an item is sampled, carry counter repeats.",
                    "label": 0
                },
                {
                    "sent": "So one of the one of the earlier proposal.",
                    "label": 1
                },
                {
                    "sent": "This was counting samples where here we sample new items with some fixed probability P. So if you think of the ISP context, every time we see a new key that we haven't seen before, we're going to make a decision whether to sample it or not.",
                    "label": 0
                },
                {
                    "sent": "And if we do, every time you see it subsequently we gained.",
                    "label": 0
                },
                {
                    "sent": "We're not.",
                    "label": 0
                },
                {
                    "sent": "We're going to take it with probability one.",
                    "label": 0
                },
                {
                    "sent": "And we have to count these count.",
                    "label": 0
                },
                {
                    "sent": "These repeats and you can get an unbiased estimate of the total count of objects, which is 1 / P. Which comes from sampling the first subject with probability P plus the total count minus one.",
                    "label": 0
                },
                {
                    "sent": "And there was a bytewise version of this sample and hold produced by Esterna Varughese.",
                    "label": 0
                },
                {
                    "sent": "Here we want to sample have a sort of bytewise sampling, so we get a sample when we see a new key and you flow record, we get a sample that has A contains B bytes.",
                    "label": 1
                },
                {
                    "sent": "We got to sample it with probability 1 -- 1 minus beta B, which is in fact a sort of you can think about us as constant.",
                    "label": 0
                },
                {
                    "sent": "By twice sampling probability of P. And this has lower variance compared with independent sampling of the objects.",
                    "label": 0
                },
                {
                    "sent": "But the sample size does grow.",
                    "label": 0
                },
                {
                    "sent": "So there have been a response.",
                    "label": 0
                },
                {
                    "sent": "Responses to this has been attached a sample and hold.",
                    "label": 0
                },
                {
                    "sent": "Let's reduce the sampling probability P when we need it in order to maintain the sample size.",
                    "label": 0
                },
                {
                    "sent": "So one way to do this is to just geometrically decrease P, harvest caution and so forth when you need to.",
                    "label": 0
                },
                {
                    "sent": "Or you can.",
                    "label": 0
                },
                {
                    "sent": "There's been subsequent work where actually tuning.",
                    "label": 1
                },
                {
                    "sent": "The decrease in P to maintain a given sample size.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sketch guided sampling goes further.",
                    "label": 1
                },
                {
                    "sent": "Let's let's try just to avoid sampling the heavy keys as much in the 1st place.",
                    "label": 1
                },
                {
                    "sent": "We know that uniform sampling will pick the heavy keys again and again and again.",
                    "label": 1
                },
                {
                    "sent": "So if you're a large flow comprising many packets, you will tend to be represented in the sample so.",
                    "label": 0
                },
                {
                    "sent": "So one question is, you really want to devote your sampling resources towards those those those always wanted to vote them towards these large flows preferentially, or do in fact want to have a scheme which you can adapt to devote some of your sampling resources to.",
                    "label": 0
                },
                {
                    "sent": "Two flows which are not amongst the set of largest flows.",
                    "label": 0
                },
                {
                    "sent": "So one idea here is to use an Oracle to tell you when a key is heavy and then adjust the sampling probability accordingly.",
                    "label": 1
                },
                {
                    "sent": "In this sketch idea sampling proposal they used a sketch data structure to play the role of an Oracle.",
                    "label": 0
                },
                {
                    "sent": "Can you track the probability wiki is sampled using of instruction estimators and then?",
                    "label": 0
                },
                {
                    "sent": "Decrease the probability of.",
                    "label": 0
                },
                {
                    "sent": "Sampling a key as it's estimated weight increases, so that's how you use or trade off and devote less resources towards something.",
                    "label": 0
                },
                {
                    "sent": "These heavy keys, in order that you can put more of those resources towards something.",
                    "label": 0
                },
                {
                    "sent": "The less any keys.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what are the challenges for this smartstream sampling?",
                    "label": 0
                },
                {
                    "sent": "Well, part of it comes from route constraints.",
                    "label": 0
                },
                {
                    "sent": "These flow tables where you need to do the little copies maintained in fast expensive memory which you need to do to get to look up at line.",
                    "label": 1
                },
                {
                    "sent": "Look up the keys to find out which floor echoed update at line race in the packets coming into the interface.",
                    "label": 1
                },
                {
                    "sent": "In someone hold you still need per packet look up.",
                    "label": 0
                },
                {
                    "sent": "You need to figure out whether you sample this key previously mode.",
                    "label": 0
                },
                {
                    "sent": "With sample Netflow you have this uniform sampling to reduce the look up rate.",
                    "label": 1
                },
                {
                    "sent": "So turns out that you know here in the trade off we see the sample Netflow is actually easier to implement despite its inferior statistical properties.",
                    "label": 1
                },
                {
                    "sent": "Now, if you're dealing with companies that produce routers in the traditional way, then we have long development time is to realize new sampling algorithms, and in fact, this is, uh, you know, I've talked about in my ISP contests, but really this is a general concern.",
                    "label": 0
                },
                {
                    "sent": "Processing large amounts of data needs some awareness of hardware.",
                    "label": 1
                },
                {
                    "sent": "Uniform sampling is very simple.",
                    "label": 0
                },
                {
                    "sent": "It means there's no coordination is needed in this tribute setting.",
                    "label": 0
                },
                {
                    "sent": "Everybody does their own independent sampling, but there are tradeoffs because it's not may not be statistically optimal.",
                    "label": 0
                },
                {
                    "sent": "And when Graham comes on to talk about coordinated sampling and hashing, you'll see some of the advantages that can be brought to bear.",
                    "label": 0
                },
                {
                    "sent": "If you are able to coordinate your sampling in some way, not just two independent uniform sampling.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the future for smarter stream sampling?",
                    "label": 1
                },
                {
                    "sent": "Well, one future is software defined networking.",
                    "label": 0
                },
                {
                    "sent": "Currently we have proprietary software running on special purpose vendor routers.",
                    "label": 1
                },
                {
                    "sent": "The future the ideas will have open software and protocols running on commodity hardware, hardware miss, potentially officers for measurement and radial flexibility.",
                    "label": 1
                },
                {
                    "sent": "We can allocate system resources to the measurement tasks as needed, dynamically reconfigure our sampling parameters and this can aid things like stateful packet inspection or something.",
                    "label": 1
                },
                {
                    "sent": "For Network security we can.",
                    "label": 0
                },
                {
                    "sent": "Yeah, drill down on traffic, which seems more suspicious than other traffic.",
                    "label": 0
                },
                {
                    "sent": "Allocate dynamically allocate more sampling resources trade, but we end up with some of the same technical challenges.",
                    "label": 0
                },
                {
                    "sent": "Now we want to high rates packet processing in software.",
                    "label": 0
                },
                {
                    "sent": "And so we're going to need to have some transparent way of getting hardware support for those sampling operations out of our commodity hardware.",
                    "label": 0
                },
                {
                    "sent": "So this is an emerging area.",
                    "label": 0
                },
                {
                    "sent": "I refer you to some of the work that Milam use.",
                    "label": 0
                },
                {
                    "sent": "Doing an open sketch.",
                    "label": 0
                },
                {
                    "sent": "For some recent progress in this.",
                    "label": 0
                },
                {
                    "sent": "Emphasize that although it talks about this in the context of traffic measurement, there would be same issues in other applications.",
                    "label": 0
                },
                {
                    "sent": "How to use commodity programmable hardware.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so I think I'm going to break at this point and then when we resume, will talk about sampling as a cost optimization.",
                    "label": 0
                }
            ]
        }
    }
}