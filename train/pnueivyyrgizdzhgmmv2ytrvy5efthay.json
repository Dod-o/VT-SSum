{
    "id": "pnueivyyrgizdzhgmmv2ytrvy5efthay",
    "title": "Bandit Algorithms for Online Linear Optimization",
    "info": {
        "author": [
            "Nicol\u00f2 Cesa-Bianchi, University of Milan"
        ],
        "published": "Aug. 26, 2009",
        "recorded": "June 2009",
        "category": [
            "Top->Computer Science->Optimization Methods->Linear Programming"
        ]
    },
    "url": "http://videolectures.net/icml09_cesa_bianchi_itbaolo/",
    "segmentation": [
        [
            "So this is a right?",
            "So this is a talk about online linear optimization in the bandit case, and I'm going to service some results that embarrassing, embarrassingly are due to mostly people sitting in this audience, so.",
            "Phillies please be kind to me.",
            "I sure I'm going to make mistakes but and I will also tell you about some new stuff that when we I was asked to give this talk we it was still submitted to cult.",
            "Now is also accepted too cold so will have another chance to hear it on Saturday in a shorter version.",
            "So if you don't want to hear the long version you can leave the room now and on Saturday you might be hearing this."
        ],
        [
            "OK so you know multi armed bandits are nice things that are a little scary, but it's also nice to work on them.",
            "So OK."
        ],
        [
            "And I'm glad I can.",
            "OK, this is sorry.",
            "This is the plan.",
            "So essentially I'm going to do a little bit of a survey in the area of online linear optimization.",
            "I will start by introducing this basic algorithms tree that would be extended to solve problems in here and I will especially concentrate in the case where the actions belong are corners of the dimensional hypercube.",
            "So I will concentrate on those so called combinatorial case.",
            "In which you actions are convenient are convenient Oriel objects OK, and I will argue that there are very many interesting examples where this is the case, and that will.",
            "Proposed this approach.",
            "This is especially designed for this special case of the online optimization bandit problem, and I will compare what we get with more general approaches that are the geometric edge by sham at all and the self concordant.",
            "Not sure Sean sorry.",
            "Sean Anna Self Concordant function approach by Sasha and Jake and Lab was not here OK. OK, good so."
        ],
        [
            "I'm glad I can skip lots of slow."
        ],
        [
            "It's."
        ],
        [
            "So this is like, you know."
        ],
        [
            "Remaining ready, you know all this stuff you know by now I guess."
        ],
        [
            "Otherwise, is a problem, so I'm going to focus on the non stochastic case so it is everything is going to be worse case."
        ],
        [
            "And I OK.",
            "This is the this notation an I will talk about bandit with losses, so there's going to be an unknown fixed but unknown sequence of loss functions that.",
            "Tell that tell you how, how big is the loss for playing action night empty and I will assume this stage will assume that these things are between zero and one."
        ],
        [
            "And the usual this is usually the traditional band into each select.",
            "Some action I sub T from the set of available actions and we observe the loss for the chosen action.",
            "We don't observe the other losses."
        ],
        [
            "And we're interested in minimizing the regret over a sequence of place for an arbitrary sequence of loss functions.",
            "So we're looking at the sum of the cumulative losses.",
            "Sorry, the some of the losses.",
            "That the player is incuring when it plays the sequence of actions versus the best possible single actions that can be considered.",
            "This consistently played over the over the sequence of the place we're going to looking at minimizing this regrets in expectation with respect to the randomization of the place."
        ],
        [
            "And.",
            "OK, so there's the basic.",
            "I'm playing strategy xtree.",
            "I'm going to build on you as you know, is assigning awaits to each action that are proportional to how the action did in the past so far.",
            "And then there is a mixing term that is responsible for the exploration, which just tells us that we probably some probability gamma.",
            "We should be playing an action at random among."
        ],
        [
            "A set of actions and the weights are charging each action.",
            "I buy a quantity which is a. Exponentially decreasing in the sum of the estimated past loss and the way we asked."
        ],
        [
            "Made it past loss for an action is by using this by now.",
            "Sort of a traditional estimator which says that I assign an estimated loss of zero at time T or to each action.",
            "I didn't play and I assign.",
            "I overcompensate the fact that I only observe the loss of a Nationals from time to time by dividing the servant loss of the action that I actually played that empty by the probability of plane detection."
        ],
        [
            "OK, so the properties of this is that this is an unbiased estimator and what is crucial?"
        ],
        [
            "In the analysis of this is the fact that you can actually bound the size or the variance if you like of the estimator by N over gamma becausw, these probability are served by.",
            "Certainly at least this match and the probabilities appear in the denominator of the estimator and this you know this is a 01 and this is at most one by our assumption of the losses.",
            "OK, so this is the traditional approach to bed."
        ],
        [
            "It's and what we can prove is what has been proven proven in this paper is that you can bound the regret by this term, which is at dependencies on square root of time.",
            "An square root of N, again in respect to the number of."
        ],
        [
            "Actions and this is true for any sequence of loss functions, and this factor here is necessary even when in the full information case, even when you observe the losses of the.",
            "Actually didn't play an additional factor.",
            "This additional square root of N factor is actually due to the fact that your this is the price of exploration, and this is exactly due to the fact that you are exploring at random the whole set of actions, and that sets the size of your loss estimates.",
            "OK, so so that you have this bound to control the size of your estimates.",
            "OK, so this is the analysis was known for the traditional bandit."
        ],
        [
            "Problem now we're looking at this.",
            "Special K at this more general case in which we are assuming that our actions are elements of an combinatorial space, in particular in general, in an app.",
            "Abstractly, we may look at actions are Boolean vectors in AD dimensional hypercube.",
            "So for instance this is a set of three actions that are three strict for actions for these four corners of the upper cube OK."
        ],
        [
            "And we assume that the losses now are are vectors are a sequence of fixed but unknown sequence of vectors and the loss of playing action I at some time T is just the inner product between the vector the vector associated to the action.",
            "So the coordinates of the of the corresponding corner of the hypercube inner product with the.",
            "Loss factor, so this is essentially tells you that we're going to pay for each loss vector X, which sits in the inside of the hypercube.",
            "We're going to pay some some price for each coordinate, and since the fact that the actions are overlapping because they are corners of the upper cube is the key to exploit would be a key to exploit the beat that we will exploit in the proof in order to get tight bounds on the regret.",
            "In this case, so you see, there is a clear combinatorial overlapping structure that is induced by the fact that we have actions that are corners and a linear function for losses."
        ],
        [
            "OK, and then of course you will.",
            "This is a more general occasion which will retrieve the classical bandage case whenever the set of actions is the Canonical basis of Rd.",
            "In this case N is equal to D, so this will be the and there's no overlapping in this case, because each action is is having his own code in it.",
            "OK."
        ],
        [
            "So what we do OK, Now we can."
        ],
        [
            "Serve now that you want you.",
            "Unlike the case before now we have two parameters, you have the number of dimensions D and the number of actions N and what you're interested in are in estimating this loss vectors.",
            "So your estimate estimation problem."
        ],
        [
            "Becomes dimensional, So what you expect in your regret in respect to the regret bound is.",
            "Something along these lines where the capital N which was due to the fact that you add that to estimate an N dimensional loss is now replaced by a D which is the number of coordinates in your in your loss factor.",
            "OK, this is the kind of bound we're regret bound we're looking at we are."
        ],
        [
            "Like to achieve so good?",
            "So this is, I think this combinatorial bandit setting is interesting because there are several interesting multidimensional location problems that can be cast in this framework.",
            "So for instance, in this example is if you play a standard several copies of a standard bandit problem.",
            "So we call this multitask bandits bandits.",
            "So, for instance, assume that you have two sets of three bandits, OK of three armed bandits.",
            "So in this case you can.",
            "Describe each play of this game as a point in a corner of the six dimensional hypercube."
        ],
        [
            "This is clear because for instance I can play action first Bandit.",
            "He ran the second bandit here, and this will correspond to the following corner in my 6 dimensional hypercube and the because the losses additive the loss I get here.",
            "Sorry, this is kind of strange because this is our slot machines, but you lose, but you have to play and the last that they get here is the sum of the loss of this of this machine and of that machine.",
            "So this is very easy and another interesting example is the path path selection problem on networks.",
            "So you want to route packets from the source to this destination on this graph, and now you can see each path in this network as a point in the 11 dimensional hypercube and this is."
        ],
        [
            "Clearly this is done in the same way, so each time you choose the different path and you have a different point which which is corresponds to the to putting a one in the coordinates associated to this edge.",
            "This edge and this edge and so on."
        ],
        [
            "So forces as and each time you will play a different path and each time you play a path the actual losses again, as is additive in the sense that you will pay the loss associated to each edge along the path you chose, and it shows at the losses in on each edge is exactly is exactly the."
        ],
        [
            "The loss that we associated in the coordinates to the coordinates of the applicant.",
            "So there is this very simple."
        ],
        [
            "Way of casting multidimensional allocation problems.",
            "Discrete to this combinatorial bandit setup.",
            "So there are."
        ],
        [
            "Very many examples here.",
            "There is another set of example another, I mean a long list of examples that are interested in.",
            "We think so.",
            "Actions in general are combinatorial objects.",
            "As I said, that are represented by their incidence vectors, so these are other examples.",
            "For instance, you can.",
            "You can play actions that are K sized subsets of the elements, and this will be the corresponding space that this will be the number of actions or permutations of K objects, in which case you'll have K factorial possible actions that live in this space, spanning trees of a K click, and this is the number of.",
            "This is, as you might know, this is a number of spanning trees on a click of key elements, and then you will you will.",
            "This will be corners of an applicable many dimensions balance.",
            "It cuts over 2K click Hamiltonian cycles in a K click, so these are all so you can play bandit problems in all of these cases, in which each time an action is a combinatorial is an element of this combinatorial space and you may, as you might notice, in all of these examples, the number of actions is going.",
            "Is exponential in the parameter of the of the.",
            "In the natural parameter of the example.",
            "OK."
        ],
        [
            "Good, so there have been there have been very nice algorithms that have been proposed in the past that can actually deal with the with more general settings where the actions are not necessarily corners of an upper.",
            "Cubes are just elements of a linear space.",
            "OK, so of course this is.",
            "These are more general algorithm that can be applied in even in this picture, special case or combinatorial bandits.",
            "So we're going to look at one of them that we actually build on, and we will see how to modify this strategy in order to get an edge for the specific case or combinatorial bandits.",
            "So the first observation is clearly that you cannot cannot apply directly xtree becausw if you just plug N as the number of actions here, since then is exponential in the parameters, you will have a bad dependence on the parameters of your problem.",
            "So you're clearly wrong because we are completely disregarding the overlappings of the actions in the combinatorial space.",
            "And then so in order to exploit Overlappings and I said yeah is to use the notion of barycentric barycentric spanners.",
            "So essentially you want to restrict your exploration not on the whole set of actions but on a subset which is representative in the sense that you can subset of actions that you are exploring over is a small subset of actions that are well, well, spacing in the space of the action space.",
            "So this would be going to be a good choice of spanners for the set, whereas this might be a bad choice because they're sort of two close to one corner reading.",
            "Ignoring this part here and then once you once you use this for exploration, you can estimate the losses of other actions that do not belong to this subset by interpolation, and This is why you actually would like to cover in a nice way the whole action space."
        ],
        [
            "So the other book and climber were the first to use these national spanners to apply it for the bandit problem and they proved very nice property that is holds for Spanish in general for any action in Euclidean space that that are not necessarily corners of the Boolean hypercube but can be any set of points in dimensional real space.",
            "There exists a general in orthogonal basis for their span such that the.",
            "L Infinity norm of each action is at most one for all elements of the actual space, so this is a nice property that immediately leads."
        ],
        [
            "You 2.",
            "To come up with a natural assumption for your.",
            "For your, for your run problem.",
            "So, given any any any actual space, Now you have you have to have some way of measuring the scale of your problem, so how?",
            "In the combinatorial case, that would be how long are my?",
            "How long are my paths OK?",
            "For instance, my pets.",
            "I have a maximum length of a 10, so this would be the natural scale of the problem and in the.",
            "If you use a spanners to make inspiration then this natural.",
            "And sufficient assumption to define the scale is according to treat assumption.",
            "They simply tells that the the maximum the maximum loss of any action that you play in for any loss vector is bounded by be.",
            "So you see, this is a coding it free assumption that it doesn't depend on any coordinate set and is relies on the property of this particular basis which always exists which is the recharter spanners so.",
            "Now this gets to the scale of the problem of your of your.",
            "Of your bandit problem."
        ],
        [
            "And now you can go on an analyze the algorithm, which is the natural generalization of XP and this in the name of this argument, dramatic hedge, in which you do again you do exploration using weights and you do exploration only over the spanner set and the spanner is at let's say it's D. If these span of the actual space."
        ],
        [
            "OK, now you."
        ],
        [
            "We will observe a certain loss, which is the linear.",
            "The linear loss inner product between the action and the loss vector, and then you can design A loss vector estimate.",
            "You have to estimate the vector which is the vector of the losses.",
            "You only observe this inner product, so you don't see the only vector, so you reconstruct the whole vector.",
            "You can use the least squares approach.",
            "OK, so you define a last testament in this way where this is the correlation matrix of the.",
            "Actions with respect to the current something distribution that he uses that empty."
        ],
        [
            "And this works very nicely.",
            "So now you can use this last estimates to assign weights to every action in your set.",
            "OK, and this would be so you're using, say that you're using their loss estimate vector to making a product with any other action, so you'll have an estimate for the loss of any other action at time T. OK, so this is a very nice generalization of the previous."
        ],
        [
            "Approach and again you can prove that this least squares estimator is unbiased with respect to the randomization induced by the you're the sampling of the action."
        ],
        [
            "And the size of the estimate losses can be bounded in this much more complicated now, but can be bounded in a similar way as in the previous case."
        ],
        [
            "So.",
            "Again, this so you can write out the size of the estimated losses in this way, and this species is just bounded by B because this is the scale of our losses.",
            "OK, and this part."
        ],
        [
            "Here can be bounded by using the spanner property that the Infinity norm of any in the spanner coordinates the Infinity norm of the actions is at most one and you can use this to prove that the norm of this of the pseudo inverse of the correlation matrix is bounded by this match and also to prove that the squared norm of the actions is at most this match.",
            "OK, so this is a.",
            "And ice.",
            "Approach that based on spanners."
        ],
        [
            "It is essentially gets use abound that can be written this in this way, so there are some small constants here and then.",
            "You see that.",
            "So there is a little.",
            "There is a price for the general generality of this approach, so this approach is a side is more general than the combinatorial bandits set up in the sense can deal with any finite set of actions in a in a coordinate free linear space without any reference to a specific coding at any specific basis is just using the basis.",
            "Given by the spinners and the prices that the dependence on the dimension is not what we were expecting, so we were expecting something that depended on the B sqrt D time steal again, but instead here the D is outside of square root.",
            "So we now want to do some simple modification of this approach in order to get a better bound for the combinatorial case in which actually the our actions are.",
            "Corners of an Apple cube.",
            "So we have a reference code in it set."
        ],
        [
            "We can we can use so this is again so this is the original work done jointly with GABA logo sheet that we are going to present in cult and.",
            "This is again the geometric edge algorithm and we do some very simple but crucial modification of the algorithm and then we do the analysis of the algorithm in a restricted set of the combinatorial in restricted combinatorial setup."
        ],
        [
            "So the crucial modification is that we give up using spanners because the spanners innocence are not so are rough measure of the structure of the set of our set of actions.",
            "So we are essentially again making exploration on the whole set of actions so we explore by picking a random action with some probability gamma and we are now it will be.",
            "Problem of controlling the size of these estimates and everything is the same.",
            "Apart from this small modification.",
            "So we're giving up spanners and we want to face the problem of controlling the size of the S."
        ],
        [
            "It's OK, so now since we are relying on the fact that we have a reference coordinate system, we can use a coordinate dependence.",
            "Kelly assumptions, which are saying that basically tells us that the the one norm of the actions is at most B and the Infinity norm of the losses is at most one.",
            "So this you see, this is implies that the inner product between X&V.",
            "Is it must be as was in the previous case?",
            "These are specific assumptions for."
        ],
        [
            "This communitarian case, so we now can use these scaling assumptions, that depends on the coordinates to control to get a better control of the size of our estimated."
        ],
        [
            "Losses, So what we get here is again because of this of the of the Holder inequality we have that this product is must be be times one."
        ],
        [
            "An becausw and then here we simply say that this.",
            "It's easy to see that we can bound the norm of these metrics of the pseudo inverse of this matrix by the smallest by one over gamma times the smallest eigenvalue of the correlation matrix with respect to the uniform distribution, which our which is our exploration distribution.",
            "So this is exactly the same kind of stuff that you saw in the last talk before lunch, where they were applying the least squares estimator to do the bandit.",
            "In the linear case.",
            "But under stochastic assumptions.",
            "OK, so we already we will again have a dependence on the list eigenvalue, but now we're going to look at how big this can be for our applications.",
            "OK."
        ],
        [
            "So and last, we can also bound this.",
            "Now we can we can get a better bound on this by exploiting the fact that we are essentially in a nice space where we have we have good properties because all actions are corners of this hypercube.",
            "We have a definite structure for the action set."
        ],
        [
            "OK, So what we get by doing that is that we get this kind of regret bound, which still depends on the minimum market value on the size of the actions on the dimension of the space.",
            "This is similar to what what was gotten in the in the last talk before."
        ],
        [
            "Ouch.",
            "And it turns out that in our previous in all previous examples of communal total bandits, I showed you that long list of examples, but the case of paths I will talk about that later.",
            "The condition.",
            "It turns out that the minimum value is at least be over D. So this means that this ratio is constant."
        ],
        [
            "And being this ratio constant, we get the regret becomes this match.",
            "So in all those cases of spanning trees, cuts, subsets, Hamiltonian paths, we are this.",
            "Combat algorithm gets the optimal regret in the sense that in general, for for any choice of S, you cannot improve on this, so you might be able to improve in each specific case by some, But in general this is the best possible bound.",
            "OK.",
            "So.",
            "This is a.",
            "Did the problem OK. Now, once we have this get got in this bound we can.",
            "Further explore exploit the structure of the action set."
        ],
        [
            "By looking at the efficiency of our construction, so one problem that we have here is that we have dimensional loss estimates, so we are associating estimated losses to each coordinate and we are associating weights to each coordinate.",
            "But then we have to."
        ],
        [
            "Who translates.",
            "Wait, so the coordinates into weights over actions and this is done by simply multiplying the weights of the corresponding coordinates for each action you remember.",
            "Actions are incidence vectors, so we just multiply the weight associated to the coordinates for each action.",
            "I we just multiply the weights associated to the coordinates that are one in the incident vector for that action, OK?"
        ],
        [
            "So once we get that we are left with the problem of efficiently sampling from this large set of action.",
            "This exponential set of actions.",
            "So now."
        ],
        [
            "You can go on and look at every specific case, so we already know."
        ],
        [
            "Sampling from the set of paths can be done efficiently because there is a nice structure in the in the path, so you can use a dynamic programming to compute conditional probability."
        ],
        [
            "This and similar trick can be done also for sampling from K sized subsets.",
            "Sampling for from the K. Bandit problems where you have this multitask bandit problems is also easy because you can just do independent draws from each bandit, and sampling well sampling from permutation of K objects with arbitrary weights is a little tricky, but Luckily there are very nice.",
            "Algorithms that do random sampling for perfect matchings.",
            "These are sophisticated algorithms that use a Markov chains and they so you can use this to prove that you can efficiently sample from permutations.",
            "So this is a gets the bandit version of what Manfred proved in code two years ago, I think.",
            "So you prove the way of learning permutation in the experts case efficiently.",
            "Now we can do it also in the bandit case.",
            "By using this is perfect matching gear.",
            "Sampling technique and in certain cases OK.",
            "This is another nice cases which we can apply a nice algorithm by Jerome Sinclair in Vigoda for sampling from the first magnetic Ising models.",
            "To prove that you can do sampling from balance, it cuts and some other cases are tough, so we've done that.",
            "Don't have any an efficient algorithm, but in many, many of these cases it's a very nice mathematical theory that can apply it in order to prove that you have have efficient ways of running the algorithm.",
            "OK, so this is.",
            "This is the approach we propose."
        ],
        [
            "And I want to how much time do I have left?",
            "10 minutes good.",
            "More than 10.",
            "OK, maybe I'll use that less.",
            "OK, so there's another approach, an very recently that could be used to solve this problem.",
            "Or combinatorial bandits again, is a more general approach, and that is based on online gradient descent.",
            "But I think of each and the idea here is that we make a reduction from the bandit problem, the online linear community online linear optimization for the bandit case to online gradient descent.",
            "So the basic idea here is that you walk you do a gradient descent inside the convex Hull of your set of actions.",
            "So remember to get your actions are set maybe in the corners of the hypercube or ninja.",
            "Or general case are just a set of points in the linear space, you take the convex.",
            "All of this set of points and then you do online gradient descent.",
            "Inside is inside this convex Hull, so you'll have some point PT inside the convex Hull.",
            "This is your current point and you will use this point inside the convex Hull to pick one action.",
            "So to pick one of the corners of the convex Hull it could be in the combinatorial case, will be one of the corners of the hypercube.",
            "In the general case, will be just one of the corners of of one of the actions in the.",
            "In the in the in the set of actions of the set of actions.",
            "OK and.",
            "So what we what we get here and then again in the we will suffer some loss in the bandit case, which is this and the.",
            "The this is the loss that we will suffer and the expected loss we observe will be this one which will be used to drive our gradient descent.",
            "And so basically that we will compute some again some loss vector estimate and we will perform gradient descent over this loss estimate.",
            "OK, so this is a very nice idea."
        ],
        [
            "And the issues here.",
            "There are two.",
            "First of all, you need to you have the problem of decomposing point from the convex.",
            "The interior of the convex style into a probability distribution over the set of corners.",
            "OK, over the action set in such a way that this you get an unbiased estimator, so is.",
            "If you draw IP based on P, you have to do it in such a way that your actual expected value of your actual loss is PTXT, which is what you use.",
            "You can use to do your gradient descent, which what makes sense to do gradient descent on OK, and at this point PT Maximus tensely be good to have a small loss.",
            "In order, which is the exploitation part and to lead to a good estimate of the loss vector so?",
            "This is an interesting question because you are performing this gradient descent, so you just have a single point and this single point it should again.",
            "Play double roll of doing aspiration expectation so that way you can achieve that."
        ],
        [
            "This is this very nice trick that was initially.",
            "I mean it was mentioned I guess was an older trick, but was mentioned in this paper grading descent without the gradient by Flaxman, Kalayaan, Mac Mahan, and.",
            "The idea is very well understood in a in the 1 dimensional case.",
            "So suppose this is your point.",
            "Instead of the convex Hull and you want to estimate the slope of this of this line, which is their loss vector in the 1 dimensional case, and so the idea here is that you can do that by playing a trend am not playing, not using, not playing this point, but playing at random.",
            "Either this one or that one.",
            "So in expectation the the the vector, the expectation if you play this one, this one or this one with equal probability, you will get an estimate of the slope of this of this curve.",
            "So this is a very nice trick that essentially tells you that you should perturb a little bit the point that you actually act in order to get.",
            "Good estimate of the loss, but you shouldn't perturb it too much, because otherwise you're not going.",
            "You're not doing a good explore exploitation of the your current gradient estimate.",
            "Good so and here the radius.",
            "So the distance are here is the crucial cause.",
            "We want to keep it small in order to do good exploitation.",
            "But we cannot.",
            "We also want it big because our estimate will inversely depend on the radius on this radius R. So these are is bigger than the various of our estimate will be smaller."
        ],
        [
            "So now this brings in the concept.",
            "Is that the concept of the fact that in general, if you're close to the border of your PT is close to the border of your action set of the border of your convex all, then are can be too big here because you cannot sample outside of your action set.",
            "So the idea on which now that."
        ],
        [
            "Can really exploit here is that you should use a local.",
            "The local geometry of the action set at each point PT in order to determine the optimal distance of exploration in every direction.",
            "So this is what was done."
        ],
        [
            "Then in this paper called last year on self Concordant functions.",
            "So it turns out there's a very nice and deep connection between this sampling unbiased sampling problem and the use of very functions in interior point optimization."
        ],
        [
            "And so the idea is that.",
            "The eigenvalues of the Hessian matrix of a self concordant functions for the.",
            "Convex closes set which is our convex Hull, is provides a natural system of coordinates that tell you exactly how far you can go in each direction.",
            "OK, so the now they rise the right way of doing this estimate of the Los Vectores by perturbing the current point PT, which will be here.",
            "By in in each in only in directions only in the eigen directions.",
            "So either in this ratio in this direction in this example and buy a radius which corresponds to the square root of the eigenvalue associated to the eigenvector.",
            "OK, so this is a very nice and and natural way of solving this problem expiration."
        ],
        [
            "And now we can go and see how what this gets.",
            "In our case of communitarian bandits, so this is sort of a sum up of what we got, so this is our bound.",
            "This is the geometric hedge bound that this is a self concordant bound which has worse dependence on D, but it's a different dependence.",
            "Instead of having the log of a number of actions of log of the horizon T. Gay."
        ],
        [
            "So we must say that all of these methods have the problem of sampling in the case of the of the self concordant approach, the sampling problem is the problem of.",
            "Dekova finding a way of decomposing point PT inside the convex Hull into a distribution over the corners over the action set in such a way that this holds.",
            "So this is a problem that has to be solved.",
            "This is a sampling problem for the second code and approach, and in other in the geometric hedge and in the com band case.",
            "In both cases here we had this other problem here that we saw could be solved by using this random walks techniques.",
            "OK, so this is this is about efficiency.",
            "2nd order does this additional problem that.",
            "A subcomponent function is always guaranteed to exist, but the sometimes it's hard to compute it."
        ],
        [
            "OK, so.",
            "Now, if you observe that typically the size of the in all examples that we saw the log of the number of actions is order of the square root of the number of the dimension times the log of the dimension.",
            "So if we."
        ],
        [
            "Replace this now.",
            "We see that we can compare them all on the same footing as the sense that we have now.",
            "No dependence on the number of actions in none of none of the bounds and depends on the dimension is still the best for com band in the computer bandit case, and then we have a three half ceron, 5 fourths over here.",
            "OK, so.",
            "Even when when we take out the dependence on the number of actions will we're still doing better than self concordant.",
            "I must say that these are more general algorithms that can be applied in marginal cases, so it's not completely so we this is what we compare against because there were.",
            "These are the only known algorithms that can be applied to the combinatorial bandits problem."
        ],
        [
            "OK, so to conclude, we saw that we can get essentially optimal bounds for this combinatorial bandit problem.",
            "That includes lots of nice multidimensional location problems, and we do that by exploiting the combinatorial structure of the action set in a specific way.",
            "However, in a certain problems, landed pets path selection problem we have.",
            "We don't know how to get a good lower bound on the on the minimum eigenvalue of the.",
            "Correlation matrix under the uniform distribution and we know that for the pixelation, if we explore with the uniform distribution, this gets too small and the algorithms about demand.",
            "So one route that we are trying in order to fix this problem is to perform exploration not using a uniform distribution but using a distribution that maximizes this smallest eigenvalue.",
            "And this is looks very promising and we don't know that this leads to an angry that is general, that is optimal in general for each specific.",
            "Problem this regarding computational complexity, but this is what we hope we're hoping.",
            "OK, let's let's all thanks baby.",
            "Questions yes.",
            "OK.",
            "Shut up, yeah?",
            "11 yes.",
            "Back away from the dentist setting and now look at just unloading the full information.",
            "Most people in this room understanding the rate in terms of geometric parameters that could even bonnick spaces where you have some noise, yeah.",
            "I don't want to do decision then all these problems is how the problem scales as you scale dimension or there's no.",
            "That's fine basically getting in here for a particular like we did the work.",
            "There's many different ways your problem can scale this right, which is kind of doesn't apply if you have particular problems you're pointing out because if you put it during this comment or problems, you might offer a better rate.",
            "That's right, question is what's in for the full information case, yes, very general characterization in terms of these norms, and Monica, that's right.",
            "And here you made inroad into a particular set of problems and getting better.",
            "It's.",
            "But that's your intuition in terms of, say, a more general geometric characterization.",
            "Same terms of you've got some norm of some blonded final Primal Norman, say some Banach space of your decisions, and this imposes some doing over cost functions.",
            "Or, well, oh, backspace is you don't have any products I use.",
            "You are doing on which is.",
            "Yes, but what kind of estimator will would you use?",
            "Somehow this work is going toward a better rate based on some structural additional structural assumptions.",
            "Information case, so now that kind of question is what your intuition for have a more general way of characterizing.",
            "Yeah, I mean I. Yeah.",
            "On the ice, it's it's a very nice question.",
            "I mean, in the sense that if I know the answer, I mean if I had a good intuition on that, I would be very happy.",
            "Good on this part.",
            "Highlighted in red.",
            "To think about the lock key, is it actually for both common tangent page?",
            "So if you're using a set with like has corners or whatever and then you have a finite number of N. But if you have that around set you know again that was round.",
            "You have to discretize it and then you need like you need like T to the whatever an overdue or something.",
            "Yeah yeah, you're you're.",
            "Yeah yours is oblivious to the number of points your your method is oblivious to.",
            "Number of points.",
            "That's right, yeah.",
            "Both the other ones too.",
            "If you actually had like you're doing like no, I'm starting no no, I'm assuming.",
            "I'm assuming I have.",
            "I haven't found a number of actions, so I'm looking at your methods, so I want to.",
            "I got rid of and just to make a clear comparison.",
            "Questions with case of a sphere?",
            "I think so she realized that you kind of get a different rate.",
            "That's one case if you're if you're Altoona was bounded and you can get a different rate.",
            "Again, something different.",
            "Exploration of other.",
            "So.",
            "There's two things I would say.",
            "First of all, a common is, I think this this trick with the gradients comes up in the analysis of policy gradient reinforcement learning.",
            "Yeah, I forget who first.",
            "Was it was it was it Peter?",
            "Long time ago.",
            "For the for doing the gradient descent without agreement, that's what you mean.",
            "That analysis, yeah.",
            "Question, so if you take a look at the at the form of the formula, true mark will be similar to what you get with the XP4, and so go back to the other version of combat with the yeah this one right?",
            "So that is the form of that formula is very similar with you.",
            "We give it the XP4 where you have any experts.",
            "Yeah right yeah.",
            "So what I was wondering is have you thought about whether not there's some way to embed one problem in the other or reductions?",
            "No no, no no.",
            "You're right, no, I haven't thought of it.",
            "No, no, but it's it's.",
            "It makes sense that the question.",
            "So so Tom Hayes realized that geometric edge works with export, in that you can actually change the decision set every round in a exporter kind of way.",
            "And it just goes through.",
            "And I think all of these will go through on this.",
            "So all of these are correlated.",
            "I meant the extending.",
            "Yes.",
            "Because the key is the unbiased property, you don't need that decision set to be fixed every round.",
            "Reggie Magic heads does is say export as is.",
            "It basically allows experts to change every round.",
            "And here since you're getting an unbiased estimate every round, you can have the decisions that change and kind of all of the map really good.",
            "So I think it might be an observation versus thesis.",
            "For the fish and see I mean is this the same thing the same thing?",
            "I mean, there's almost no.",
            "Are you still looking?",
            "You think that these can be proved as a corollary of this before.",
            "No, no, no no.",
            "What I'm saying is the the generalization from these two X2 to something like export does hold where the decision set can change program.",
            "OK, So what you're saying is you can previous before.",
            "As a corollary of yes, that that OK."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is a right?",
                    "label": 0
                },
                {
                    "sent": "So this is a talk about online linear optimization in the bandit case, and I'm going to service some results that embarrassing, embarrassingly are due to mostly people sitting in this audience, so.",
                    "label": 0
                },
                {
                    "sent": "Phillies please be kind to me.",
                    "label": 0
                },
                {
                    "sent": "I sure I'm going to make mistakes but and I will also tell you about some new stuff that when we I was asked to give this talk we it was still submitted to cult.",
                    "label": 0
                },
                {
                    "sent": "Now is also accepted too cold so will have another chance to hear it on Saturday in a shorter version.",
                    "label": 0
                },
                {
                    "sent": "So if you don't want to hear the long version you can leave the room now and on Saturday you might be hearing this.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK so you know multi armed bandits are nice things that are a little scary, but it's also nice to work on them.",
                    "label": 0
                },
                {
                    "sent": "So OK.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And I'm glad I can.",
                    "label": 0
                },
                {
                    "sent": "OK, this is sorry.",
                    "label": 0
                },
                {
                    "sent": "This is the plan.",
                    "label": 0
                },
                {
                    "sent": "So essentially I'm going to do a little bit of a survey in the area of online linear optimization.",
                    "label": 1
                },
                {
                    "sent": "I will start by introducing this basic algorithms tree that would be extended to solve problems in here and I will especially concentrate in the case where the actions belong are corners of the dimensional hypercube.",
                    "label": 0
                },
                {
                    "sent": "So I will concentrate on those so called combinatorial case.",
                    "label": 0
                },
                {
                    "sent": "In which you actions are convenient are convenient Oriel objects OK, and I will argue that there are very many interesting examples where this is the case, and that will.",
                    "label": 0
                },
                {
                    "sent": "Proposed this approach.",
                    "label": 0
                },
                {
                    "sent": "This is especially designed for this special case of the online optimization bandit problem, and I will compare what we get with more general approaches that are the geometric edge by sham at all and the self concordant.",
                    "label": 0
                },
                {
                    "sent": "Not sure Sean sorry.",
                    "label": 0
                },
                {
                    "sent": "Sean Anna Self Concordant function approach by Sasha and Jake and Lab was not here OK. OK, good so.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm glad I can skip lots of slow.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is like, you know.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Remaining ready, you know all this stuff you know by now I guess.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Otherwise, is a problem, so I'm going to focus on the non stochastic case so it is everything is going to be worse case.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And I OK.",
                    "label": 0
                },
                {
                    "sent": "This is the this notation an I will talk about bandit with losses, so there's going to be an unknown fixed but unknown sequence of loss functions that.",
                    "label": 1
                },
                {
                    "sent": "Tell that tell you how, how big is the loss for playing action night empty and I will assume this stage will assume that these things are between zero and one.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the usual this is usually the traditional band into each select.",
                    "label": 0
                },
                {
                    "sent": "Some action I sub T from the set of available actions and we observe the loss for the chosen action.",
                    "label": 0
                },
                {
                    "sent": "We don't observe the other losses.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we're interested in minimizing the regret over a sequence of place for an arbitrary sequence of loss functions.",
                    "label": 0
                },
                {
                    "sent": "So we're looking at the sum of the cumulative losses.",
                    "label": 0
                },
                {
                    "sent": "Sorry, the some of the losses.",
                    "label": 0
                },
                {
                    "sent": "That the player is incuring when it plays the sequence of actions versus the best possible single actions that can be considered.",
                    "label": 0
                },
                {
                    "sent": "This consistently played over the over the sequence of the place we're going to looking at minimizing this regrets in expectation with respect to the randomization of the place.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "OK, so there's the basic.",
                    "label": 0
                },
                {
                    "sent": "I'm playing strategy xtree.",
                    "label": 0
                },
                {
                    "sent": "I'm going to build on you as you know, is assigning awaits to each action that are proportional to how the action did in the past so far.",
                    "label": 0
                },
                {
                    "sent": "And then there is a mixing term that is responsible for the exploration, which just tells us that we probably some probability gamma.",
                    "label": 0
                },
                {
                    "sent": "We should be playing an action at random among.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A set of actions and the weights are charging each action.",
                    "label": 0
                },
                {
                    "sent": "I buy a quantity which is a. Exponentially decreasing in the sum of the estimated past loss and the way we asked.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Made it past loss for an action is by using this by now.",
                    "label": 0
                },
                {
                    "sent": "Sort of a traditional estimator which says that I assign an estimated loss of zero at time T or to each action.",
                    "label": 0
                },
                {
                    "sent": "I didn't play and I assign.",
                    "label": 0
                },
                {
                    "sent": "I overcompensate the fact that I only observe the loss of a Nationals from time to time by dividing the servant loss of the action that I actually played that empty by the probability of plane detection.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so the properties of this is that this is an unbiased estimator and what is crucial?",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the analysis of this is the fact that you can actually bound the size or the variance if you like of the estimator by N over gamma becausw, these probability are served by.",
                    "label": 0
                },
                {
                    "sent": "Certainly at least this match and the probabilities appear in the denominator of the estimator and this you know this is a 01 and this is at most one by our assumption of the losses.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is the traditional approach to bed.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's and what we can prove is what has been proven proven in this paper is that you can bound the regret by this term, which is at dependencies on square root of time.",
                    "label": 0
                },
                {
                    "sent": "An square root of N, again in respect to the number of.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Actions and this is true for any sequence of loss functions, and this factor here is necessary even when in the full information case, even when you observe the losses of the.",
                    "label": 1
                },
                {
                    "sent": "Actually didn't play an additional factor.",
                    "label": 0
                },
                {
                    "sent": "This additional square root of N factor is actually due to the fact that your this is the price of exploration, and this is exactly due to the fact that you are exploring at random the whole set of actions, and that sets the size of your loss estimates.",
                    "label": 0
                },
                {
                    "sent": "OK, so so that you have this bound to control the size of your estimates.",
                    "label": 1
                },
                {
                    "sent": "OK, so this is the analysis was known for the traditional bandit.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Problem now we're looking at this.",
                    "label": 0
                },
                {
                    "sent": "Special K at this more general case in which we are assuming that our actions are elements of an combinatorial space, in particular in general, in an app.",
                    "label": 0
                },
                {
                    "sent": "Abstractly, we may look at actions are Boolean vectors in AD dimensional hypercube.",
                    "label": 1
                },
                {
                    "sent": "So for instance this is a set of three actions that are three strict for actions for these four corners of the upper cube OK.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we assume that the losses now are are vectors are a sequence of fixed but unknown sequence of vectors and the loss of playing action I at some time T is just the inner product between the vector the vector associated to the action.",
                    "label": 0
                },
                {
                    "sent": "So the coordinates of the of the corresponding corner of the hypercube inner product with the.",
                    "label": 0
                },
                {
                    "sent": "Loss factor, so this is essentially tells you that we're going to pay for each loss vector X, which sits in the inside of the hypercube.",
                    "label": 0
                },
                {
                    "sent": "We're going to pay some some price for each coordinate, and since the fact that the actions are overlapping because they are corners of the upper cube is the key to exploit would be a key to exploit the beat that we will exploit in the proof in order to get tight bounds on the regret.",
                    "label": 0
                },
                {
                    "sent": "In this case, so you see, there is a clear combinatorial overlapping structure that is induced by the fact that we have actions that are corners and a linear function for losses.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, and then of course you will.",
                    "label": 0
                },
                {
                    "sent": "This is a more general occasion which will retrieve the classical bandage case whenever the set of actions is the Canonical basis of Rd.",
                    "label": 1
                },
                {
                    "sent": "In this case N is equal to D, so this will be the and there's no overlapping in this case, because each action is is having his own code in it.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what we do OK, Now we can.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Serve now that you want you.",
                    "label": 0
                },
                {
                    "sent": "Unlike the case before now we have two parameters, you have the number of dimensions D and the number of actions N and what you're interested in are in estimating this loss vectors.",
                    "label": 0
                },
                {
                    "sent": "So your estimate estimation problem.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Becomes dimensional, So what you expect in your regret in respect to the regret bound is.",
                    "label": 0
                },
                {
                    "sent": "Something along these lines where the capital N which was due to the fact that you add that to estimate an N dimensional loss is now replaced by a D which is the number of coordinates in your in your loss factor.",
                    "label": 0
                },
                {
                    "sent": "OK, this is the kind of bound we're regret bound we're looking at we are.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Like to achieve so good?",
                    "label": 0
                },
                {
                    "sent": "So this is, I think this combinatorial bandit setting is interesting because there are several interesting multidimensional location problems that can be cast in this framework.",
                    "label": 0
                },
                {
                    "sent": "So for instance, in this example is if you play a standard several copies of a standard bandit problem.",
                    "label": 0
                },
                {
                    "sent": "So we call this multitask bandits bandits.",
                    "label": 1
                },
                {
                    "sent": "So, for instance, assume that you have two sets of three bandits, OK of three armed bandits.",
                    "label": 0
                },
                {
                    "sent": "So in this case you can.",
                    "label": 0
                },
                {
                    "sent": "Describe each play of this game as a point in a corner of the six dimensional hypercube.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is clear because for instance I can play action first Bandit.",
                    "label": 0
                },
                {
                    "sent": "He ran the second bandit here, and this will correspond to the following corner in my 6 dimensional hypercube and the because the losses additive the loss I get here.",
                    "label": 0
                },
                {
                    "sent": "Sorry, this is kind of strange because this is our slot machines, but you lose, but you have to play and the last that they get here is the sum of the loss of this of this machine and of that machine.",
                    "label": 0
                },
                {
                    "sent": "So this is very easy and another interesting example is the path path selection problem on networks.",
                    "label": 1
                },
                {
                    "sent": "So you want to route packets from the source to this destination on this graph, and now you can see each path in this network as a point in the 11 dimensional hypercube and this is.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Clearly this is done in the same way, so each time you choose the different path and you have a different point which which is corresponds to the to putting a one in the coordinates associated to this edge.",
                    "label": 0
                },
                {
                    "sent": "This edge and this edge and so on.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So forces as and each time you will play a different path and each time you play a path the actual losses again, as is additive in the sense that you will pay the loss associated to each edge along the path you chose, and it shows at the losses in on each edge is exactly is exactly the.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The loss that we associated in the coordinates to the coordinates of the applicant.",
                    "label": 0
                },
                {
                    "sent": "So there is this very simple.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Way of casting multidimensional allocation problems.",
                    "label": 1
                },
                {
                    "sent": "Discrete to this combinatorial bandit setup.",
                    "label": 0
                },
                {
                    "sent": "So there are.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Very many examples here.",
                    "label": 0
                },
                {
                    "sent": "There is another set of example another, I mean a long list of examples that are interested in.",
                    "label": 0
                },
                {
                    "sent": "We think so.",
                    "label": 0
                },
                {
                    "sent": "Actions in general are combinatorial objects.",
                    "label": 1
                },
                {
                    "sent": "As I said, that are represented by their incidence vectors, so these are other examples.",
                    "label": 1
                },
                {
                    "sent": "For instance, you can.",
                    "label": 0
                },
                {
                    "sent": "You can play actions that are K sized subsets of the elements, and this will be the corresponding space that this will be the number of actions or permutations of K objects, in which case you'll have K factorial possible actions that live in this space, spanning trees of a K click, and this is the number of.",
                    "label": 1
                },
                {
                    "sent": "This is, as you might know, this is a number of spanning trees on a click of key elements, and then you will you will.",
                    "label": 0
                },
                {
                    "sent": "This will be corners of an applicable many dimensions balance.",
                    "label": 0
                },
                {
                    "sent": "It cuts over 2K click Hamiltonian cycles in a K click, so these are all so you can play bandit problems in all of these cases, in which each time an action is a combinatorial is an element of this combinatorial space and you may, as you might notice, in all of these examples, the number of actions is going.",
                    "label": 0
                },
                {
                    "sent": "Is exponential in the parameter of the of the.",
                    "label": 0
                },
                {
                    "sent": "In the natural parameter of the example.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Good, so there have been there have been very nice algorithms that have been proposed in the past that can actually deal with the with more general settings where the actions are not necessarily corners of an upper.",
                    "label": 0
                },
                {
                    "sent": "Cubes are just elements of a linear space.",
                    "label": 0
                },
                {
                    "sent": "OK, so of course this is.",
                    "label": 0
                },
                {
                    "sent": "These are more general algorithm that can be applied in even in this picture, special case or combinatorial bandits.",
                    "label": 0
                },
                {
                    "sent": "So we're going to look at one of them that we actually build on, and we will see how to modify this strategy in order to get an edge for the specific case or combinatorial bandits.",
                    "label": 0
                },
                {
                    "sent": "So the first observation is clearly that you cannot cannot apply directly xtree becausw if you just plug N as the number of actions here, since then is exponential in the parameters, you will have a bad dependence on the parameters of your problem.",
                    "label": 0
                },
                {
                    "sent": "So you're clearly wrong because we are completely disregarding the overlappings of the actions in the combinatorial space.",
                    "label": 1
                },
                {
                    "sent": "And then so in order to exploit Overlappings and I said yeah is to use the notion of barycentric barycentric spanners.",
                    "label": 0
                },
                {
                    "sent": "So essentially you want to restrict your exploration not on the whole set of actions but on a subset which is representative in the sense that you can subset of actions that you are exploring over is a small subset of actions that are well, well, spacing in the space of the action space.",
                    "label": 1
                },
                {
                    "sent": "So this would be going to be a good choice of spanners for the set, whereas this might be a bad choice because they're sort of two close to one corner reading.",
                    "label": 0
                },
                {
                    "sent": "Ignoring this part here and then once you once you use this for exploration, you can estimate the losses of other actions that do not belong to this subset by interpolation, and This is why you actually would like to cover in a nice way the whole action space.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the other book and climber were the first to use these national spanners to apply it for the bandit problem and they proved very nice property that is holds for Spanish in general for any action in Euclidean space that that are not necessarily corners of the Boolean hypercube but can be any set of points in dimensional real space.",
                    "label": 0
                },
                {
                    "sent": "There exists a general in orthogonal basis for their span such that the.",
                    "label": 1
                },
                {
                    "sent": "L Infinity norm of each action is at most one for all elements of the actual space, so this is a nice property that immediately leads.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You 2.",
                    "label": 0
                },
                {
                    "sent": "To come up with a natural assumption for your.",
                    "label": 0
                },
                {
                    "sent": "For your, for your run problem.",
                    "label": 0
                },
                {
                    "sent": "So, given any any any actual space, Now you have you have to have some way of measuring the scale of your problem, so how?",
                    "label": 0
                },
                {
                    "sent": "In the combinatorial case, that would be how long are my?",
                    "label": 0
                },
                {
                    "sent": "How long are my paths OK?",
                    "label": 0
                },
                {
                    "sent": "For instance, my pets.",
                    "label": 0
                },
                {
                    "sent": "I have a maximum length of a 10, so this would be the natural scale of the problem and in the.",
                    "label": 0
                },
                {
                    "sent": "If you use a spanners to make inspiration then this natural.",
                    "label": 0
                },
                {
                    "sent": "And sufficient assumption to define the scale is according to treat assumption.",
                    "label": 0
                },
                {
                    "sent": "They simply tells that the the maximum the maximum loss of any action that you play in for any loss vector is bounded by be.",
                    "label": 0
                },
                {
                    "sent": "So you see, this is a coding it free assumption that it doesn't depend on any coordinate set and is relies on the property of this particular basis which always exists which is the recharter spanners so.",
                    "label": 0
                },
                {
                    "sent": "Now this gets to the scale of the problem of your of your.",
                    "label": 0
                },
                {
                    "sent": "Of your bandit problem.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And now you can go on an analyze the algorithm, which is the natural generalization of XP and this in the name of this argument, dramatic hedge, in which you do again you do exploration using weights and you do exploration only over the spanner set and the spanner is at let's say it's D. If these span of the actual space.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, now you.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We will observe a certain loss, which is the linear.",
                    "label": 0
                },
                {
                    "sent": "The linear loss inner product between the action and the loss vector, and then you can design A loss vector estimate.",
                    "label": 1
                },
                {
                    "sent": "You have to estimate the vector which is the vector of the losses.",
                    "label": 0
                },
                {
                    "sent": "You only observe this inner product, so you don't see the only vector, so you reconstruct the whole vector.",
                    "label": 1
                },
                {
                    "sent": "You can use the least squares approach.",
                    "label": 0
                },
                {
                    "sent": "OK, so you define a last testament in this way where this is the correlation matrix of the.",
                    "label": 0
                },
                {
                    "sent": "Actions with respect to the current something distribution that he uses that empty.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this works very nicely.",
                    "label": 0
                },
                {
                    "sent": "So now you can use this last estimates to assign weights to every action in your set.",
                    "label": 0
                },
                {
                    "sent": "OK, and this would be so you're using, say that you're using their loss estimate vector to making a product with any other action, so you'll have an estimate for the loss of any other action at time T. OK, so this is a very nice generalization of the previous.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Approach and again you can prove that this least squares estimator is unbiased with respect to the randomization induced by the you're the sampling of the action.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the size of the estimate losses can be bounded in this much more complicated now, but can be bounded in a similar way as in the previous case.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Again, this so you can write out the size of the estimated losses in this way, and this species is just bounded by B because this is the scale of our losses.",
                    "label": 1
                },
                {
                    "sent": "OK, and this part.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here can be bounded by using the spanner property that the Infinity norm of any in the spanner coordinates the Infinity norm of the actions is at most one and you can use this to prove that the norm of this of the pseudo inverse of the correlation matrix is bounded by this match and also to prove that the squared norm of the actions is at most this match.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is a.",
                    "label": 0
                },
                {
                    "sent": "And ice.",
                    "label": 0
                },
                {
                    "sent": "Approach that based on spanners.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It is essentially gets use abound that can be written this in this way, so there are some small constants here and then.",
                    "label": 0
                },
                {
                    "sent": "You see that.",
                    "label": 0
                },
                {
                    "sent": "So there is a little.",
                    "label": 0
                },
                {
                    "sent": "There is a price for the general generality of this approach, so this approach is a side is more general than the combinatorial bandits set up in the sense can deal with any finite set of actions in a in a coordinate free linear space without any reference to a specific coding at any specific basis is just using the basis.",
                    "label": 0
                },
                {
                    "sent": "Given by the spinners and the prices that the dependence on the dimension is not what we were expecting, so we were expecting something that depended on the B sqrt D time steal again, but instead here the D is outside of square root.",
                    "label": 0
                },
                {
                    "sent": "So we now want to do some simple modification of this approach in order to get a better bound for the combinatorial case in which actually the our actions are.",
                    "label": 0
                },
                {
                    "sent": "Corners of an Apple cube.",
                    "label": 0
                },
                {
                    "sent": "So we have a reference code in it set.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We can we can use so this is again so this is the original work done jointly with GABA logo sheet that we are going to present in cult and.",
                    "label": 0
                },
                {
                    "sent": "This is again the geometric edge algorithm and we do some very simple but crucial modification of the algorithm and then we do the analysis of the algorithm in a restricted set of the combinatorial in restricted combinatorial setup.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the crucial modification is that we give up using spanners because the spanners innocence are not so are rough measure of the structure of the set of our set of actions.",
                    "label": 0
                },
                {
                    "sent": "So we are essentially again making exploration on the whole set of actions so we explore by picking a random action with some probability gamma and we are now it will be.",
                    "label": 0
                },
                {
                    "sent": "Problem of controlling the size of these estimates and everything is the same.",
                    "label": 0
                },
                {
                    "sent": "Apart from this small modification.",
                    "label": 0
                },
                {
                    "sent": "So we're giving up spanners and we want to face the problem of controlling the size of the S.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's OK, so now since we are relying on the fact that we have a reference coordinate system, we can use a coordinate dependence.",
                    "label": 0
                },
                {
                    "sent": "Kelly assumptions, which are saying that basically tells us that the the one norm of the actions is at most B and the Infinity norm of the losses is at most one.",
                    "label": 0
                },
                {
                    "sent": "So this you see, this is implies that the inner product between X&V.",
                    "label": 0
                },
                {
                    "sent": "Is it must be as was in the previous case?",
                    "label": 0
                },
                {
                    "sent": "These are specific assumptions for.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This communitarian case, so we now can use these scaling assumptions, that depends on the coordinates to control to get a better control of the size of our estimated.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Losses, So what we get here is again because of this of the of the Holder inequality we have that this product is must be be times one.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "An becausw and then here we simply say that this.",
                    "label": 0
                },
                {
                    "sent": "It's easy to see that we can bound the norm of these metrics of the pseudo inverse of this matrix by the smallest by one over gamma times the smallest eigenvalue of the correlation matrix with respect to the uniform distribution, which our which is our exploration distribution.",
                    "label": 0
                },
                {
                    "sent": "So this is exactly the same kind of stuff that you saw in the last talk before lunch, where they were applying the least squares estimator to do the bandit.",
                    "label": 0
                },
                {
                    "sent": "In the linear case.",
                    "label": 0
                },
                {
                    "sent": "But under stochastic assumptions.",
                    "label": 0
                },
                {
                    "sent": "OK, so we already we will again have a dependence on the list eigenvalue, but now we're going to look at how big this can be for our applications.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So and last, we can also bound this.",
                    "label": 0
                },
                {
                    "sent": "Now we can we can get a better bound on this by exploiting the fact that we are essentially in a nice space where we have we have good properties because all actions are corners of this hypercube.",
                    "label": 0
                },
                {
                    "sent": "We have a definite structure for the action set.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, So what we get by doing that is that we get this kind of regret bound, which still depends on the minimum market value on the size of the actions on the dimension of the space.",
                    "label": 0
                },
                {
                    "sent": "This is similar to what what was gotten in the in the last talk before.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Ouch.",
                    "label": 0
                },
                {
                    "sent": "And it turns out that in our previous in all previous examples of communal total bandits, I showed you that long list of examples, but the case of paths I will talk about that later.",
                    "label": 1
                },
                {
                    "sent": "The condition.",
                    "label": 0
                },
                {
                    "sent": "It turns out that the minimum value is at least be over D. So this means that this ratio is constant.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And being this ratio constant, we get the regret becomes this match.",
                    "label": 1
                },
                {
                    "sent": "So in all those cases of spanning trees, cuts, subsets, Hamiltonian paths, we are this.",
                    "label": 0
                },
                {
                    "sent": "Combat algorithm gets the optimal regret in the sense that in general, for for any choice of S, you cannot improve on this, so you might be able to improve in each specific case by some, But in general this is the best possible bound.",
                    "label": 1
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "This is a.",
                    "label": 0
                },
                {
                    "sent": "Did the problem OK. Now, once we have this get got in this bound we can.",
                    "label": 0
                },
                {
                    "sent": "Further explore exploit the structure of the action set.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "By looking at the efficiency of our construction, so one problem that we have here is that we have dimensional loss estimates, so we are associating estimated losses to each coordinate and we are associating weights to each coordinate.",
                    "label": 0
                },
                {
                    "sent": "But then we have to.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Who translates.",
                    "label": 0
                },
                {
                    "sent": "Wait, so the coordinates into weights over actions and this is done by simply multiplying the weights of the corresponding coordinates for each action you remember.",
                    "label": 1
                },
                {
                    "sent": "Actions are incidence vectors, so we just multiply the weight associated to the coordinates for each action.",
                    "label": 0
                },
                {
                    "sent": "I we just multiply the weights associated to the coordinates that are one in the incident vector for that action, OK?",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So once we get that we are left with the problem of efficiently sampling from this large set of action.",
                    "label": 0
                },
                {
                    "sent": "This exponential set of actions.",
                    "label": 0
                },
                {
                    "sent": "So now.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can go on and look at every specific case, so we already know.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sampling from the set of paths can be done efficiently because there is a nice structure in the in the path, so you can use a dynamic programming to compute conditional probability.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This and similar trick can be done also for sampling from K sized subsets.",
                    "label": 0
                },
                {
                    "sent": "Sampling for from the K. Bandit problems where you have this multitask bandit problems is also easy because you can just do independent draws from each bandit, and sampling well sampling from permutation of K objects with arbitrary weights is a little tricky, but Luckily there are very nice.",
                    "label": 1
                },
                {
                    "sent": "Algorithms that do random sampling for perfect matchings.",
                    "label": 0
                },
                {
                    "sent": "These are sophisticated algorithms that use a Markov chains and they so you can use this to prove that you can efficiently sample from permutations.",
                    "label": 0
                },
                {
                    "sent": "So this is a gets the bandit version of what Manfred proved in code two years ago, I think.",
                    "label": 0
                },
                {
                    "sent": "So you prove the way of learning permutation in the experts case efficiently.",
                    "label": 0
                },
                {
                    "sent": "Now we can do it also in the bandit case.",
                    "label": 0
                },
                {
                    "sent": "By using this is perfect matching gear.",
                    "label": 0
                },
                {
                    "sent": "Sampling technique and in certain cases OK.",
                    "label": 0
                },
                {
                    "sent": "This is another nice cases which we can apply a nice algorithm by Jerome Sinclair in Vigoda for sampling from the first magnetic Ising models.",
                    "label": 0
                },
                {
                    "sent": "To prove that you can do sampling from balance, it cuts and some other cases are tough, so we've done that.",
                    "label": 0
                },
                {
                    "sent": "Don't have any an efficient algorithm, but in many, many of these cases it's a very nice mathematical theory that can apply it in order to prove that you have have efficient ways of running the algorithm.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is.",
                    "label": 0
                },
                {
                    "sent": "This is the approach we propose.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And I want to how much time do I have left?",
                    "label": 0
                },
                {
                    "sent": "10 minutes good.",
                    "label": 0
                },
                {
                    "sent": "More than 10.",
                    "label": 0
                },
                {
                    "sent": "OK, maybe I'll use that less.",
                    "label": 0
                },
                {
                    "sent": "OK, so there's another approach, an very recently that could be used to solve this problem.",
                    "label": 0
                },
                {
                    "sent": "Or combinatorial bandits again, is a more general approach, and that is based on online gradient descent.",
                    "label": 1
                },
                {
                    "sent": "But I think of each and the idea here is that we make a reduction from the bandit problem, the online linear community online linear optimization for the bandit case to online gradient descent.",
                    "label": 1
                },
                {
                    "sent": "So the basic idea here is that you walk you do a gradient descent inside the convex Hull of your set of actions.",
                    "label": 0
                },
                {
                    "sent": "So remember to get your actions are set maybe in the corners of the hypercube or ninja.",
                    "label": 0
                },
                {
                    "sent": "Or general case are just a set of points in the linear space, you take the convex.",
                    "label": 0
                },
                {
                    "sent": "All of this set of points and then you do online gradient descent.",
                    "label": 0
                },
                {
                    "sent": "Inside is inside this convex Hull, so you'll have some point PT inside the convex Hull.",
                    "label": 0
                },
                {
                    "sent": "This is your current point and you will use this point inside the convex Hull to pick one action.",
                    "label": 0
                },
                {
                    "sent": "So to pick one of the corners of the convex Hull it could be in the combinatorial case, will be one of the corners of the hypercube.",
                    "label": 0
                },
                {
                    "sent": "In the general case, will be just one of the corners of of one of the actions in the.",
                    "label": 0
                },
                {
                    "sent": "In the in the in the set of actions of the set of actions.",
                    "label": 0
                },
                {
                    "sent": "OK and.",
                    "label": 0
                },
                {
                    "sent": "So what we what we get here and then again in the we will suffer some loss in the bandit case, which is this and the.",
                    "label": 0
                },
                {
                    "sent": "The this is the loss that we will suffer and the expected loss we observe will be this one which will be used to drive our gradient descent.",
                    "label": 0
                },
                {
                    "sent": "And so basically that we will compute some again some loss vector estimate and we will perform gradient descent over this loss estimate.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is a very nice idea.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the issues here.",
                    "label": 0
                },
                {
                    "sent": "There are two.",
                    "label": 0
                },
                {
                    "sent": "First of all, you need to you have the problem of decomposing point from the convex.",
                    "label": 1
                },
                {
                    "sent": "The interior of the convex style into a probability distribution over the set of corners.",
                    "label": 0
                },
                {
                    "sent": "OK, over the action set in such a way that this you get an unbiased estimator, so is.",
                    "label": 0
                },
                {
                    "sent": "If you draw IP based on P, you have to do it in such a way that your actual expected value of your actual loss is PTXT, which is what you use.",
                    "label": 1
                },
                {
                    "sent": "You can use to do your gradient descent, which what makes sense to do gradient descent on OK, and at this point PT Maximus tensely be good to have a small loss.",
                    "label": 0
                },
                {
                    "sent": "In order, which is the exploitation part and to lead to a good estimate of the loss vector so?",
                    "label": 1
                },
                {
                    "sent": "This is an interesting question because you are performing this gradient descent, so you just have a single point and this single point it should again.",
                    "label": 0
                },
                {
                    "sent": "Play double roll of doing aspiration expectation so that way you can achieve that.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is this very nice trick that was initially.",
                    "label": 0
                },
                {
                    "sent": "I mean it was mentioned I guess was an older trick, but was mentioned in this paper grading descent without the gradient by Flaxman, Kalayaan, Mac Mahan, and.",
                    "label": 0
                },
                {
                    "sent": "The idea is very well understood in a in the 1 dimensional case.",
                    "label": 0
                },
                {
                    "sent": "So suppose this is your point.",
                    "label": 0
                },
                {
                    "sent": "Instead of the convex Hull and you want to estimate the slope of this of this line, which is their loss vector in the 1 dimensional case, and so the idea here is that you can do that by playing a trend am not playing, not using, not playing this point, but playing at random.",
                    "label": 0
                },
                {
                    "sent": "Either this one or that one.",
                    "label": 0
                },
                {
                    "sent": "So in expectation the the the vector, the expectation if you play this one, this one or this one with equal probability, you will get an estimate of the slope of this of this curve.",
                    "label": 0
                },
                {
                    "sent": "So this is a very nice trick that essentially tells you that you should perturb a little bit the point that you actually act in order to get.",
                    "label": 0
                },
                {
                    "sent": "Good estimate of the loss, but you shouldn't perturb it too much, because otherwise you're not going.",
                    "label": 0
                },
                {
                    "sent": "You're not doing a good explore exploitation of the your current gradient estimate.",
                    "label": 0
                },
                {
                    "sent": "Good so and here the radius.",
                    "label": 0
                },
                {
                    "sent": "So the distance are here is the crucial cause.",
                    "label": 0
                },
                {
                    "sent": "We want to keep it small in order to do good exploitation.",
                    "label": 0
                },
                {
                    "sent": "But we cannot.",
                    "label": 0
                },
                {
                    "sent": "We also want it big because our estimate will inversely depend on the radius on this radius R. So these are is bigger than the various of our estimate will be smaller.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now this brings in the concept.",
                    "label": 0
                },
                {
                    "sent": "Is that the concept of the fact that in general, if you're close to the border of your PT is close to the border of your action set of the border of your convex all, then are can be too big here because you cannot sample outside of your action set.",
                    "label": 1
                },
                {
                    "sent": "So the idea on which now that.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Can really exploit here is that you should use a local.",
                    "label": 0
                },
                {
                    "sent": "The local geometry of the action set at each point PT in order to determine the optimal distance of exploration in every direction.",
                    "label": 1
                },
                {
                    "sent": "So this is what was done.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then in this paper called last year on self Concordant functions.",
                    "label": 0
                },
                {
                    "sent": "So it turns out there's a very nice and deep connection between this sampling unbiased sampling problem and the use of very functions in interior point optimization.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so the idea is that.",
                    "label": 0
                },
                {
                    "sent": "The eigenvalues of the Hessian matrix of a self concordant functions for the.",
                    "label": 1
                },
                {
                    "sent": "Convex closes set which is our convex Hull, is provides a natural system of coordinates that tell you exactly how far you can go in each direction.",
                    "label": 0
                },
                {
                    "sent": "OK, so the now they rise the right way of doing this estimate of the Los Vectores by perturbing the current point PT, which will be here.",
                    "label": 0
                },
                {
                    "sent": "By in in each in only in directions only in the eigen directions.",
                    "label": 0
                },
                {
                    "sent": "So either in this ratio in this direction in this example and buy a radius which corresponds to the square root of the eigenvalue associated to the eigenvector.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is a very nice and and natural way of solving this problem expiration.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And now we can go and see how what this gets.",
                    "label": 0
                },
                {
                    "sent": "In our case of communitarian bandits, so this is sort of a sum up of what we got, so this is our bound.",
                    "label": 0
                },
                {
                    "sent": "This is the geometric hedge bound that this is a self concordant bound which has worse dependence on D, but it's a different dependence.",
                    "label": 0
                },
                {
                    "sent": "Instead of having the log of a number of actions of log of the horizon T. Gay.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we must say that all of these methods have the problem of sampling in the case of the of the self concordant approach, the sampling problem is the problem of.",
                    "label": 1
                },
                {
                    "sent": "Dekova finding a way of decomposing point PT inside the convex Hull into a distribution over the corners over the action set in such a way that this holds.",
                    "label": 0
                },
                {
                    "sent": "So this is a problem that has to be solved.",
                    "label": 0
                },
                {
                    "sent": "This is a sampling problem for the second code and approach, and in other in the geometric hedge and in the com band case.",
                    "label": 0
                },
                {
                    "sent": "In both cases here we had this other problem here that we saw could be solved by using this random walks techniques.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is this is about efficiency.",
                    "label": 0
                },
                {
                    "sent": "2nd order does this additional problem that.",
                    "label": 0
                },
                {
                    "sent": "A subcomponent function is always guaranteed to exist, but the sometimes it's hard to compute it.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Now, if you observe that typically the size of the in all examples that we saw the log of the number of actions is order of the square root of the number of the dimension times the log of the dimension.",
                    "label": 0
                },
                {
                    "sent": "So if we.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Replace this now.",
                    "label": 0
                },
                {
                    "sent": "We see that we can compare them all on the same footing as the sense that we have now.",
                    "label": 0
                },
                {
                    "sent": "No dependence on the number of actions in none of none of the bounds and depends on the dimension is still the best for com band in the computer bandit case, and then we have a three half ceron, 5 fourths over here.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Even when when we take out the dependence on the number of actions will we're still doing better than self concordant.",
                    "label": 0
                },
                {
                    "sent": "I must say that these are more general algorithms that can be applied in marginal cases, so it's not completely so we this is what we compare against because there were.",
                    "label": 0
                },
                {
                    "sent": "These are the only known algorithms that can be applied to the combinatorial bandits problem.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so to conclude, we saw that we can get essentially optimal bounds for this combinatorial bandit problem.",
                    "label": 0
                },
                {
                    "sent": "That includes lots of nice multidimensional location problems, and we do that by exploiting the combinatorial structure of the action set in a specific way.",
                    "label": 1
                },
                {
                    "sent": "However, in a certain problems, landed pets path selection problem we have.",
                    "label": 0
                },
                {
                    "sent": "We don't know how to get a good lower bound on the on the minimum eigenvalue of the.",
                    "label": 0
                },
                {
                    "sent": "Correlation matrix under the uniform distribution and we know that for the pixelation, if we explore with the uniform distribution, this gets too small and the algorithms about demand.",
                    "label": 1
                },
                {
                    "sent": "So one route that we are trying in order to fix this problem is to perform exploration not using a uniform distribution but using a distribution that maximizes this smallest eigenvalue.",
                    "label": 1
                },
                {
                    "sent": "And this is looks very promising and we don't know that this leads to an angry that is general, that is optimal in general for each specific.",
                    "label": 0
                },
                {
                    "sent": "Problem this regarding computational complexity, but this is what we hope we're hoping.",
                    "label": 0
                },
                {
                    "sent": "OK, let's let's all thanks baby.",
                    "label": 0
                },
                {
                    "sent": "Questions yes.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Shut up, yeah?",
                    "label": 0
                },
                {
                    "sent": "11 yes.",
                    "label": 0
                },
                {
                    "sent": "Back away from the dentist setting and now look at just unloading the full information.",
                    "label": 0
                },
                {
                    "sent": "Most people in this room understanding the rate in terms of geometric parameters that could even bonnick spaces where you have some noise, yeah.",
                    "label": 0
                },
                {
                    "sent": "I don't want to do decision then all these problems is how the problem scales as you scale dimension or there's no.",
                    "label": 0
                },
                {
                    "sent": "That's fine basically getting in here for a particular like we did the work.",
                    "label": 0
                },
                {
                    "sent": "There's many different ways your problem can scale this right, which is kind of doesn't apply if you have particular problems you're pointing out because if you put it during this comment or problems, you might offer a better rate.",
                    "label": 0
                },
                {
                    "sent": "That's right, question is what's in for the full information case, yes, very general characterization in terms of these norms, and Monica, that's right.",
                    "label": 0
                },
                {
                    "sent": "And here you made inroad into a particular set of problems and getting better.",
                    "label": 0
                },
                {
                    "sent": "It's.",
                    "label": 0
                },
                {
                    "sent": "But that's your intuition in terms of, say, a more general geometric characterization.",
                    "label": 0
                },
                {
                    "sent": "Same terms of you've got some norm of some blonded final Primal Norman, say some Banach space of your decisions, and this imposes some doing over cost functions.",
                    "label": 0
                },
                {
                    "sent": "Or, well, oh, backspace is you don't have any products I use.",
                    "label": 0
                },
                {
                    "sent": "You are doing on which is.",
                    "label": 0
                },
                {
                    "sent": "Yes, but what kind of estimator will would you use?",
                    "label": 0
                },
                {
                    "sent": "Somehow this work is going toward a better rate based on some structural additional structural assumptions.",
                    "label": 0
                },
                {
                    "sent": "Information case, so now that kind of question is what your intuition for have a more general way of characterizing.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I mean I. Yeah.",
                    "label": 0
                },
                {
                    "sent": "On the ice, it's it's a very nice question.",
                    "label": 0
                },
                {
                    "sent": "I mean, in the sense that if I know the answer, I mean if I had a good intuition on that, I would be very happy.",
                    "label": 0
                },
                {
                    "sent": "Good on this part.",
                    "label": 0
                },
                {
                    "sent": "Highlighted in red.",
                    "label": 0
                },
                {
                    "sent": "To think about the lock key, is it actually for both common tangent page?",
                    "label": 0
                },
                {
                    "sent": "So if you're using a set with like has corners or whatever and then you have a finite number of N. But if you have that around set you know again that was round.",
                    "label": 0
                },
                {
                    "sent": "You have to discretize it and then you need like you need like T to the whatever an overdue or something.",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah, you're you're.",
                    "label": 0
                },
                {
                    "sent": "Yeah yours is oblivious to the number of points your your method is oblivious to.",
                    "label": 0
                },
                {
                    "sent": "Number of points.",
                    "label": 0
                },
                {
                    "sent": "That's right, yeah.",
                    "label": 0
                },
                {
                    "sent": "Both the other ones too.",
                    "label": 0
                },
                {
                    "sent": "If you actually had like you're doing like no, I'm starting no no, I'm assuming.",
                    "label": 0
                },
                {
                    "sent": "I'm assuming I have.",
                    "label": 0
                },
                {
                    "sent": "I haven't found a number of actions, so I'm looking at your methods, so I want to.",
                    "label": 0
                },
                {
                    "sent": "I got rid of and just to make a clear comparison.",
                    "label": 0
                },
                {
                    "sent": "Questions with case of a sphere?",
                    "label": 0
                },
                {
                    "sent": "I think so she realized that you kind of get a different rate.",
                    "label": 0
                },
                {
                    "sent": "That's one case if you're if you're Altoona was bounded and you can get a different rate.",
                    "label": 0
                },
                {
                    "sent": "Again, something different.",
                    "label": 0
                },
                {
                    "sent": "Exploration of other.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "There's two things I would say.",
                    "label": 0
                },
                {
                    "sent": "First of all, a common is, I think this this trick with the gradients comes up in the analysis of policy gradient reinforcement learning.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I forget who first.",
                    "label": 0
                },
                {
                    "sent": "Was it was it was it Peter?",
                    "label": 0
                },
                {
                    "sent": "Long time ago.",
                    "label": 0
                },
                {
                    "sent": "For the for doing the gradient descent without agreement, that's what you mean.",
                    "label": 0
                },
                {
                    "sent": "That analysis, yeah.",
                    "label": 0
                },
                {
                    "sent": "Question, so if you take a look at the at the form of the formula, true mark will be similar to what you get with the XP4, and so go back to the other version of combat with the yeah this one right?",
                    "label": 0
                },
                {
                    "sent": "So that is the form of that formula is very similar with you.",
                    "label": 0
                },
                {
                    "sent": "We give it the XP4 where you have any experts.",
                    "label": 0
                },
                {
                    "sent": "Yeah right yeah.",
                    "label": 0
                },
                {
                    "sent": "So what I was wondering is have you thought about whether not there's some way to embed one problem in the other or reductions?",
                    "label": 0
                },
                {
                    "sent": "No no, no no.",
                    "label": 0
                },
                {
                    "sent": "You're right, no, I haven't thought of it.",
                    "label": 0
                },
                {
                    "sent": "No, no, but it's it's.",
                    "label": 0
                },
                {
                    "sent": "It makes sense that the question.",
                    "label": 0
                },
                {
                    "sent": "So so Tom Hayes realized that geometric edge works with export, in that you can actually change the decision set every round in a exporter kind of way.",
                    "label": 0
                },
                {
                    "sent": "And it just goes through.",
                    "label": 0
                },
                {
                    "sent": "And I think all of these will go through on this.",
                    "label": 0
                },
                {
                    "sent": "So all of these are correlated.",
                    "label": 0
                },
                {
                    "sent": "I meant the extending.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Because the key is the unbiased property, you don't need that decision set to be fixed every round.",
                    "label": 0
                },
                {
                    "sent": "Reggie Magic heads does is say export as is.",
                    "label": 0
                },
                {
                    "sent": "It basically allows experts to change every round.",
                    "label": 0
                },
                {
                    "sent": "And here since you're getting an unbiased estimate every round, you can have the decisions that change and kind of all of the map really good.",
                    "label": 0
                },
                {
                    "sent": "So I think it might be an observation versus thesis.",
                    "label": 0
                },
                {
                    "sent": "For the fish and see I mean is this the same thing the same thing?",
                    "label": 0
                },
                {
                    "sent": "I mean, there's almost no.",
                    "label": 0
                },
                {
                    "sent": "Are you still looking?",
                    "label": 0
                },
                {
                    "sent": "You think that these can be proved as a corollary of this before.",
                    "label": 0
                },
                {
                    "sent": "No, no, no no.",
                    "label": 0
                },
                {
                    "sent": "What I'm saying is the the generalization from these two X2 to something like export does hold where the decision set can change program.",
                    "label": 0
                },
                {
                    "sent": "OK, So what you're saying is you can previous before.",
                    "label": 0
                },
                {
                    "sent": "As a corollary of yes, that that OK.",
                    "label": 0
                }
            ]
        }
    }
}