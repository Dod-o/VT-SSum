{
    "id": "osbgxhkr5osnbmjkce3qezgwdvcx4ruy",
    "title": "Constructing visual models with a latent space approach",
    "info": {
        "author": [
            "Florent Monay, IDIAP Research Institute"
        ],
        "published": "Feb. 25, 2007",
        "recorded": "February 2005",
        "category": [
            "Top->Computer Science->Computer Vision"
        ]
    },
    "url": "http://videolectures.net/slsfs05_monay_cvmls/",
    "segmentation": [
        [
            "This work is joint work with those three peoples and one of them is here federal chaos.",
            "And just a few and knowledge Minton's too."
        ],
        [
            "Start with.",
            "This has been done in the framework of the Carter Project, which is a Pascal network project that we are involved in.",
            "And the data I'm reporting results on are from another.",
            "European project which is the learning for that table.",
            "Visual assistance level.",
            "This is where the data are from."
        ],
        [
            "So as usual first outline, I'll say what's my task is.",
            "What image representation we use for building the visual models from?",
            "This is by doing latent structural analysis that we're going to have visual models.",
            "I'll show you some classification results and then a conclusion to an the talk."
        ],
        [
            "So what's the task?",
            "Assume you have several object categories represented by images.",
            "We would like to be able to say that.",
            "This is, let's say, the tree category.",
            "And this is different from this these two images, which are obviously two other categories.",
            "And same for this building category, which is different from the other one.",
            "So that's the task.",
            "Would like to be able to have a framework where we can take advantage of not labeled data, because this is quite common in vision problems that you have data, but you don't have labeled data, you just have a few labeled data and would be good to be.",
            "Able to use those non label data to improve your system.",
            "And another important thing is we would like to have.",
            "Non class specific features.",
            "So if we want to recognize this type of object category, we don't want to be building specific features for this and then not the specific features for finding what's the other category.",
            "So those are the three main points.",
            "No breakfast."
        ],
        [
            "Options of what the seven objects are.",
            "So objects first, our faces with different face orientation.",
            "So it's not only frontal faces or.",
            "You can have any scale almost in the image and any type of background.",
            "First class, so it's quite challenging of course.",
            "Then we we have 150 buildings images.",
            "Where ranging from normal houses or.",
            "More standard buildings tackle things with sometime trees in front of it which becomes a problem.",
            "Of course, given that one of the class then is trees again with different type close up or.",
            "Any kind of tree basically.",
            "Um?",
            "Then 216 phones.",
            "OK. Those one are quite uniform background and.",
            "Seem to be quite.",
            "Easy with respect to the other one maybe?",
            "Then Cass.",
            "And car images are not only I mean one main car in the image, it can be from the rear from the front with some occlusion.",
            "And you can have more than one car, and again different scales and so on.",
            "Then we have the bike one different type of backgrounds.",
            "It can be in front of buildings, can be from the front.",
            "Site.",
            "And then we have another object category which are books and again can be bookshelf or book close up or any type of orientation.",
            "So those are the data and.",
            "These numbers.",
            "Actually.",
            "Advocates for having something.",
            "Able to use non labeled data because we don't have so few images because we want to have a few images.",
            "It's just not easy to get a lot of labeled images.",
            "So if we have something that might help this then."
        ],
        [
            "It's really good.",
            "So it's the image representation we're using."
        ],
        [
            "This is based on local image descriptors, which has been mainly discussed in the.",
            "Previous in a previous Pascal workshop in 2004.",
            "Um?",
            "The idea is the following.",
            "You have an image.",
            "You first find if you sort of sample the image by finding interest points which.",
            "The this is using different different solutions for our experiments.",
            "You're trying to find local consistent type of parents in the image.",
            "So it looks quite random, but it's not so.",
            "So we found we found interest points.",
            "And then for each of those and you can detect those at different scales.",
            "This is why you have different sizes here.",
            "Really smaller, bigger.",
            "For each point and at the scale it has been detected and you compute 4 by 4 eight directions histogram.",
            "For each point and you end up with the SIFT local descriptors which have been proposed by David Lowe.",
            "2003 so this is 128 dimension long vector.",
            "And then."
        ],
        [
            "What has been recently proposed to do object categorization or classification is to contact those sift descriptors.",
            "So you have an image set to extract all the SIFT local descriptors from it.",
            "And then you quantize them into so-called victims, which stands for visual terms.",
            "And those systems are local image patterns which.",
            "Just a way of describing the image as a set of different image patterns at different scales.",
            "So you have sampled the image and you have different local descriptors for it.",
            "So here you can expect this to be quite accurate to describe maybe 3 structures.",
            "This might be more related to window type of structures, which might help to find buildings.",
            "This is more a step function that could maybe discard anything.",
            "But that has been found by the Cummins algorithm."
        ],
        [
            "And then this lets you.",
            "Describe the image by so called bag of distance, so this is a clear analogy of.",
            "Pull the text experiments we've heard so far, so bag of words representation.",
            "And the analogy is quite nice.",
            "I think 'cause in the bag of words you just remove all the world word ordering information in that was in the text and then throw everything into the back.",
            "And here we just don't encode the special relationship between the systems we found in the image.",
            "So it's the bag of distance representation.",
            "So just to remind you, it's Doug Difference of Goshen finding interest points, then sift descriptors, then quantization of those by a came in smaller.",
            "You've learned somewhere, and then you end up with this vector space representation of an image.",
            "Which has shown already good performance to do this object categorization object classification.",
            "So again, here you have building, but you can see the trees and.",
            "So this is something we have to.",
            "Handling the data anyway."
        ],
        [
            "Now, given that.",
            "This representation is quite similar to."
        ],
        [
            "The one you use for text.",
            "The idea is using this sort of Thomas Hoffman described yesterday.",
            "This latent semantic analysis to see and find some latent structure in this data, so use this representation and see what happens.",
            "So I just redescribe you what it is.",
            "So you observe document pairs of document and terms.",
            "So victims in our case.",
            "The assumption is there is latent variable somewhere that.",
            "Is hidden.",
            "So now the joint probability of the system, the latent aspect K and the document E is given by this.",
            "So this is a direct translation of.",
            "Yeah, it's getting weak of what are the.",
            "Independence assumptions here.",
            "And given that is not observed, then you have to marginalise over the hidden variable.",
            "And if you base on.",
            "Likelihood of the data on this joint probability.",
            "Then you can learn.",
            "Those parameters which are the probability of.",
            "In our case, the victims given the aspect.",
            "And the probability of the aspect given a document that was in the training set.",
            "Or you can even infer this new test document.",
            "And this is what we are using.",
            "So this last probability to use this both for unsupervised ranking of images and we want to use this as a. Dimensional dimensionality reduction from the bag of distance to this aspect based representation and do the classification on on these features."
        ],
        [
            "So first, just because we have this set of images, we have extracted policy descriptors, then we can run PSA on it.",
            "But we want to have an idea of what.",
            "The aspects that we are capturing in the data so you can rank images based on these parameters.",
            "You just you just learn.",
            "And you know that the probability of the document given an aspect going to be proportional to this.",
            "If you assume the probability of document is uniform and you are in a given expecting.",
            "And this is something you cannot do with text, because if you display if you rank.",
            "If you just rank the text with respect to one aspect, then.",
            "It's not easy to see if.",
            "This aspect means something quickly while for images if you see ranked images can assume.",
            "And yeah, you can see if this means anything so.",
            "Of course.",
            "So this is 1 aspect of so again, we're not using color or whatever, you just local parents of the image.",
            "And this is completely unsupervised.",
            "And in this data we can find some significant significant clusters.",
            "That means something.",
            "So for example this one.",
            "I'll show you soon.",
            "So this one is clearly related to trees.",
            "So for this display I've just asked for 20 aspects in the data because it's easier to visualize.",
            "If you ask for 100 aspects, then it's sort of mixed things that you cannot really.",
            "So this one is bike related as well.",
            "If you go down.",
            "Well, when you go down it's getting worse and.",
            "But you can feel this one is is related to buy like somehow, even if it's completely unsupervised so.",
            "Well, this is enough for examples.",
            "There are others that are garbage, of course.",
            "Maybe not this one.",
            "No.",
            "I'm going to find 1.",
            "Well, you have things where it's more mixed than some others.",
            "I can get.",
            "I cannot find them right now, but you have you have it.",
            "So if instead of just looking at."
        ],
        [
            "The aspect as illustration.",
            "You can compute numbers of course.",
            "If you assume this is a retrieval process, you can say that the ranking based of on aspect is the response to your query.",
            "So assuming faces faces the query.",
            "This is the precision recall curves you get for all the 20 aspects we've seen before.",
            "So aspects 1317 and three seem to be obviously related to the.",
            "Face object.",
            "Cuss is less, only one might be related, but not as clearly as the face case."
        ],
        [
            "The entries aspect #7 clearly.",
            "And bikes.",
            "Aspect #8 again, it's unsupervised so.",
            "It's interesting results."
        ],
        [
            "So now if we look at the aspect based representation.",
            "So we had a bug of word of Wisdom for this one.",
            "We have calculated the probabilistic latent semantic model and now we have a aspect based representation which is only the P of Z given D for this image.",
            "So again aspect #5.",
            "Is the one that is most related with building in the data and you can see that this image of course.",
            "As a high probability of this aspect, given this image.",
            "This one is just interesting as well because.",
            "Again, a Spec 5 is also buildings, but Aspect 7 which is.",
            "Related to trees.",
            "Is also.",
            "Highly probable given this one.",
            "So.",
            "It's true, it's a way of.",
            "Having you can see that there are mixtures of aspects in an image which is not always obvious to observe in other models.",
            "Again, this one aspect 7 is quite."
        ],
        [
            "Highly probable because you have some tree like structure behind.",
            "Bikes, which is number 8.",
            "Here is highly probable.",
            "So those are of course just illustrations, but this is the images you can see all over across.",
            "The data is not really picked up and selected hours.",
            "And this one is where aspect number 12 is quite related to cars and you also have trees like structures so #7.",
            "And building, which was five, is quite high.",
            "So this image again is.",
            "Is labeled as car only, but of course we cannot say it's not.",
            "It's not three or there is some building as well in the image.",
            "So now.",
            "Um?"
        ],
        [
            "I said that."
        ],
        [
            "One of the ideas trying to use this and take advantage of non labeled data that you might have.",
            "And this is the way we would assess the method so.",
            "We have non test.",
            "Images or bag of victims.",
            "This is 90% of.",
            "All the images we have.",
            "This is where we train the PSA model on.",
            "And then from this PSA model, we just extract a few.",
            "Either all the 90% or 5030 ten percent 5% of the data to do the SVM training.",
            "So this is the only way this is the only place where we actually use the label in the data.",
            "And for the test data, so we have the PC model we can.",
            "Infer from the P of the given Z we can infer the.",
            "Pfc given different new test images.",
            "Because we have the chemist model from elsewhere.",
            "So we have the bag of distance representation again.",
            "And this is the way we can say.",
            "See if using the non labeled data might help the SVM classification.",
            "Four things and we are.",
            "We are doing this 10 times with non overlapping test sets.",
            "To have more than one measure for this experiment."
        ],
        [
            "Just a few words about the multi class SVM.",
            "We're using Gaussian kernel.",
            "We have one SVM classifier per class, with one against all the strategy and.",
            "We are finding the standard deviation by cross fivefold cross validation on.",
            "On the data.",
            "And we're going to compare the rollback of distance representation with the aspects based representation."
        ],
        [
            "We've picked up 60 aspect.",
            "We've tried with less, which was worse, and we've tried with more, which wasn't really worse.",
            "But yeah, this is just number to show you what the potential of this approach.",
            "So this role is bag of victims.",
            "Destroy his PSA features.",
            "And this is using so all the time 90% of the data is used for finding the PSA model.",
            "If using all the data as well for training the SVM, we can see that.",
            "Bag of victims is better, but it's not significant across the 10.",
            "Runs, we run.",
            "For 50% then people say well, and here we still have the 1260 dimensionality reduction.",
            "And we have comparable results.",
            "For the 50% case, then police say improves, but it's not significant.",
            "Then we have the 30% amount of data for SVM training.",
            "Where Peerlessly actually significantly beats bug of victims.",
            "Then 10%.",
            "It also beats significantly in 5%, which doesn't make any more sense because it's 80% eighty images for training and 170 for testing it still.",
            "Still better than the rollback of instance representation."
        ],
        [
            "Looking at the confusion matrix so.",
            "So this is the input image and this is what the system says.",
            "The image is OK. And we can see that for almost any type of image we have.",
            "Quite high confusion with cars here.",
            "OK. And otherwise.",
            "Of course, the main diagonal is high numbers because the classification is still good for any almost any type of objects in the database.",
            "OK.",
            "So."
        ],
        [
            "As a conclusion.",
            "We could show that.",
            "Using the latent structure approach.",
            "Even on images we could we could have an efficient use of unlabeled data to improve the classification performance and SVM's.",
            "Of course, this should be assessed with.",
            "Not reducing.",
            "Within the training set with having hopefully more images from somewhere else and then trying to build the bug of these terms on.",
            "The training data using 90% for SVM training but.",
            "Then, as I've shown on the web page, the latent structure you can find in this data might be useful for browsing.",
            "I mean, assuming you have really no no label for you data for your images, you can.",
            "Learn this policy model on them and then have a way of displaying what is actually in this data set.",
            "And it's interesting was to see that images can be seen as a mixture of aspects as well.",
            "Like when we have the.",
            "The bike and then some tree structure like behind it.",
            "It's interesting to have the mixture of aspect approach for this data.",
            "And the last point is, given that.",
            "Saying that an image is one place class only is not.",
            "Possible any.",
            "Whenever you increase the number of classes then you're going to have more overlap so it would be interesting to have a way to.",
            "Access multilabel to those images instead of only one.",
            "And see what the results are."
        ],
        [
            "Do you see your your face?",
            "Stuff, is it continuous?",
            "Yeah.",
            "BLS no no.",
            "Has been compromised by the.",
            "And it's it's really similar to words or.",
            "So of course, when I do would be to not contest those features but feel yeah, problem being that it's 128 dimensions.",
            "Might be worth the trouble.",
            "Maybe he thought about this.",
            "What would happen if you just use PCA to reduce it down to 60 dimension?",
            "When did the K means on the 60 days?",
            "Well, we haven't compatible Surface book.",
            "Yes, yeah, this would be is not.",
            "Maybe the rebaseline compared to that.",
            "OK, I think."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This work is joint work with those three peoples and one of them is here federal chaos.",
                    "label": 0
                },
                {
                    "sent": "And just a few and knowledge Minton's too.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Start with.",
                    "label": 0
                },
                {
                    "sent": "This has been done in the framework of the Carter Project, which is a Pascal network project that we are involved in.",
                    "label": 0
                },
                {
                    "sent": "And the data I'm reporting results on are from another.",
                    "label": 0
                },
                {
                    "sent": "European project which is the learning for that table.",
                    "label": 1
                },
                {
                    "sent": "Visual assistance level.",
                    "label": 0
                },
                {
                    "sent": "This is where the data are from.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So as usual first outline, I'll say what's my task is.",
                    "label": 0
                },
                {
                    "sent": "What image representation we use for building the visual models from?",
                    "label": 1
                },
                {
                    "sent": "This is by doing latent structural analysis that we're going to have visual models.",
                    "label": 1
                },
                {
                    "sent": "I'll show you some classification results and then a conclusion to an the talk.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what's the task?",
                    "label": 0
                },
                {
                    "sent": "Assume you have several object categories represented by images.",
                    "label": 1
                },
                {
                    "sent": "We would like to be able to say that.",
                    "label": 0
                },
                {
                    "sent": "This is, let's say, the tree category.",
                    "label": 0
                },
                {
                    "sent": "And this is different from this these two images, which are obviously two other categories.",
                    "label": 0
                },
                {
                    "sent": "And same for this building category, which is different from the other one.",
                    "label": 0
                },
                {
                    "sent": "So that's the task.",
                    "label": 0
                },
                {
                    "sent": "Would like to be able to have a framework where we can take advantage of not labeled data, because this is quite common in vision problems that you have data, but you don't have labeled data, you just have a few labeled data and would be good to be.",
                    "label": 0
                },
                {
                    "sent": "Able to use those non label data to improve your system.",
                    "label": 0
                },
                {
                    "sent": "And another important thing is we would like to have.",
                    "label": 0
                },
                {
                    "sent": "Non class specific features.",
                    "label": 0
                },
                {
                    "sent": "So if we want to recognize this type of object category, we don't want to be building specific features for this and then not the specific features for finding what's the other category.",
                    "label": 0
                },
                {
                    "sent": "So those are the three main points.",
                    "label": 0
                },
                {
                    "sent": "No breakfast.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Options of what the seven objects are.",
                    "label": 0
                },
                {
                    "sent": "So objects first, our faces with different face orientation.",
                    "label": 0
                },
                {
                    "sent": "So it's not only frontal faces or.",
                    "label": 0
                },
                {
                    "sent": "You can have any scale almost in the image and any type of background.",
                    "label": 0
                },
                {
                    "sent": "First class, so it's quite challenging of course.",
                    "label": 0
                },
                {
                    "sent": "Then we we have 150 buildings images.",
                    "label": 1
                },
                {
                    "sent": "Where ranging from normal houses or.",
                    "label": 0
                },
                {
                    "sent": "More standard buildings tackle things with sometime trees in front of it which becomes a problem.",
                    "label": 0
                },
                {
                    "sent": "Of course, given that one of the class then is trees again with different type close up or.",
                    "label": 0
                },
                {
                    "sent": "Any kind of tree basically.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Then 216 phones.",
                    "label": 0
                },
                {
                    "sent": "OK. Those one are quite uniform background and.",
                    "label": 0
                },
                {
                    "sent": "Seem to be quite.",
                    "label": 0
                },
                {
                    "sent": "Easy with respect to the other one maybe?",
                    "label": 0
                },
                {
                    "sent": "Then Cass.",
                    "label": 0
                },
                {
                    "sent": "And car images are not only I mean one main car in the image, it can be from the rear from the front with some occlusion.",
                    "label": 0
                },
                {
                    "sent": "And you can have more than one car, and again different scales and so on.",
                    "label": 0
                },
                {
                    "sent": "Then we have the bike one different type of backgrounds.",
                    "label": 0
                },
                {
                    "sent": "It can be in front of buildings, can be from the front.",
                    "label": 0
                },
                {
                    "sent": "Site.",
                    "label": 0
                },
                {
                    "sent": "And then we have another object category which are books and again can be bookshelf or book close up or any type of orientation.",
                    "label": 0
                },
                {
                    "sent": "So those are the data and.",
                    "label": 0
                },
                {
                    "sent": "These numbers.",
                    "label": 0
                },
                {
                    "sent": "Actually.",
                    "label": 0
                },
                {
                    "sent": "Advocates for having something.",
                    "label": 0
                },
                {
                    "sent": "Able to use non labeled data because we don't have so few images because we want to have a few images.",
                    "label": 0
                },
                {
                    "sent": "It's just not easy to get a lot of labeled images.",
                    "label": 0
                },
                {
                    "sent": "So if we have something that might help this then.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's really good.",
                    "label": 0
                },
                {
                    "sent": "So it's the image representation we're using.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is based on local image descriptors, which has been mainly discussed in the.",
                    "label": 1
                },
                {
                    "sent": "Previous in a previous Pascal workshop in 2004.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "The idea is the following.",
                    "label": 0
                },
                {
                    "sent": "You have an image.",
                    "label": 0
                },
                {
                    "sent": "You first find if you sort of sample the image by finding interest points which.",
                    "label": 0
                },
                {
                    "sent": "The this is using different different solutions for our experiments.",
                    "label": 0
                },
                {
                    "sent": "You're trying to find local consistent type of parents in the image.",
                    "label": 0
                },
                {
                    "sent": "So it looks quite random, but it's not so.",
                    "label": 0
                },
                {
                    "sent": "So we found we found interest points.",
                    "label": 0
                },
                {
                    "sent": "And then for each of those and you can detect those at different scales.",
                    "label": 0
                },
                {
                    "sent": "This is why you have different sizes here.",
                    "label": 0
                },
                {
                    "sent": "Really smaller, bigger.",
                    "label": 0
                },
                {
                    "sent": "For each point and at the scale it has been detected and you compute 4 by 4 eight directions histogram.",
                    "label": 1
                },
                {
                    "sent": "For each point and you end up with the SIFT local descriptors which have been proposed by David Lowe.",
                    "label": 0
                },
                {
                    "sent": "2003 so this is 128 dimension long vector.",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What has been recently proposed to do object categorization or classification is to contact those sift descriptors.",
                    "label": 0
                },
                {
                    "sent": "So you have an image set to extract all the SIFT local descriptors from it.",
                    "label": 1
                },
                {
                    "sent": "And then you quantize them into so-called victims, which stands for visual terms.",
                    "label": 1
                },
                {
                    "sent": "And those systems are local image patterns which.",
                    "label": 0
                },
                {
                    "sent": "Just a way of describing the image as a set of different image patterns at different scales.",
                    "label": 0
                },
                {
                    "sent": "So you have sampled the image and you have different local descriptors for it.",
                    "label": 0
                },
                {
                    "sent": "So here you can expect this to be quite accurate to describe maybe 3 structures.",
                    "label": 0
                },
                {
                    "sent": "This might be more related to window type of structures, which might help to find buildings.",
                    "label": 0
                },
                {
                    "sent": "This is more a step function that could maybe discard anything.",
                    "label": 0
                },
                {
                    "sent": "But that has been found by the Cummins algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then this lets you.",
                    "label": 0
                },
                {
                    "sent": "Describe the image by so called bag of distance, so this is a clear analogy of.",
                    "label": 0
                },
                {
                    "sent": "Pull the text experiments we've heard so far, so bag of words representation.",
                    "label": 0
                },
                {
                    "sent": "And the analogy is quite nice.",
                    "label": 0
                },
                {
                    "sent": "I think 'cause in the bag of words you just remove all the world word ordering information in that was in the text and then throw everything into the back.",
                    "label": 0
                },
                {
                    "sent": "And here we just don't encode the special relationship between the systems we found in the image.",
                    "label": 0
                },
                {
                    "sent": "So it's the bag of distance representation.",
                    "label": 0
                },
                {
                    "sent": "So just to remind you, it's Doug Difference of Goshen finding interest points, then sift descriptors, then quantization of those by a came in smaller.",
                    "label": 0
                },
                {
                    "sent": "You've learned somewhere, and then you end up with this vector space representation of an image.",
                    "label": 0
                },
                {
                    "sent": "Which has shown already good performance to do this object categorization object classification.",
                    "label": 0
                },
                {
                    "sent": "So again, here you have building, but you can see the trees and.",
                    "label": 0
                },
                {
                    "sent": "So this is something we have to.",
                    "label": 0
                },
                {
                    "sent": "Handling the data anyway.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now, given that.",
                    "label": 0
                },
                {
                    "sent": "This representation is quite similar to.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The one you use for text.",
                    "label": 0
                },
                {
                    "sent": "The idea is using this sort of Thomas Hoffman described yesterday.",
                    "label": 0
                },
                {
                    "sent": "This latent semantic analysis to see and find some latent structure in this data, so use this representation and see what happens.",
                    "label": 0
                },
                {
                    "sent": "So I just redescribe you what it is.",
                    "label": 0
                },
                {
                    "sent": "So you observe document pairs of document and terms.",
                    "label": 0
                },
                {
                    "sent": "So victims in our case.",
                    "label": 0
                },
                {
                    "sent": "The assumption is there is latent variable somewhere that.",
                    "label": 0
                },
                {
                    "sent": "Is hidden.",
                    "label": 0
                },
                {
                    "sent": "So now the joint probability of the system, the latent aspect K and the document E is given by this.",
                    "label": 1
                },
                {
                    "sent": "So this is a direct translation of.",
                    "label": 0
                },
                {
                    "sent": "Yeah, it's getting weak of what are the.",
                    "label": 0
                },
                {
                    "sent": "Independence assumptions here.",
                    "label": 0
                },
                {
                    "sent": "And given that is not observed, then you have to marginalise over the hidden variable.",
                    "label": 0
                },
                {
                    "sent": "And if you base on.",
                    "label": 0
                },
                {
                    "sent": "Likelihood of the data on this joint probability.",
                    "label": 0
                },
                {
                    "sent": "Then you can learn.",
                    "label": 0
                },
                {
                    "sent": "Those parameters which are the probability of.",
                    "label": 0
                },
                {
                    "sent": "In our case, the victims given the aspect.",
                    "label": 0
                },
                {
                    "sent": "And the probability of the aspect given a document that was in the training set.",
                    "label": 0
                },
                {
                    "sent": "Or you can even infer this new test document.",
                    "label": 0
                },
                {
                    "sent": "And this is what we are using.",
                    "label": 0
                },
                {
                    "sent": "So this last probability to use this both for unsupervised ranking of images and we want to use this as a. Dimensional dimensionality reduction from the bag of distance to this aspect based representation and do the classification on on these features.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So first, just because we have this set of images, we have extracted policy descriptors, then we can run PSA on it.",
                    "label": 0
                },
                {
                    "sent": "But we want to have an idea of what.",
                    "label": 0
                },
                {
                    "sent": "The aspects that we are capturing in the data so you can rank images based on these parameters.",
                    "label": 0
                },
                {
                    "sent": "You just you just learn.",
                    "label": 0
                },
                {
                    "sent": "And you know that the probability of the document given an aspect going to be proportional to this.",
                    "label": 1
                },
                {
                    "sent": "If you assume the probability of document is uniform and you are in a given expecting.",
                    "label": 0
                },
                {
                    "sent": "And this is something you cannot do with text, because if you display if you rank.",
                    "label": 0
                },
                {
                    "sent": "If you just rank the text with respect to one aspect, then.",
                    "label": 1
                },
                {
                    "sent": "It's not easy to see if.",
                    "label": 0
                },
                {
                    "sent": "This aspect means something quickly while for images if you see ranked images can assume.",
                    "label": 0
                },
                {
                    "sent": "And yeah, you can see if this means anything so.",
                    "label": 0
                },
                {
                    "sent": "Of course.",
                    "label": 0
                },
                {
                    "sent": "So this is 1 aspect of so again, we're not using color or whatever, you just local parents of the image.",
                    "label": 0
                },
                {
                    "sent": "And this is completely unsupervised.",
                    "label": 0
                },
                {
                    "sent": "And in this data we can find some significant significant clusters.",
                    "label": 0
                },
                {
                    "sent": "That means something.",
                    "label": 0
                },
                {
                    "sent": "So for example this one.",
                    "label": 0
                },
                {
                    "sent": "I'll show you soon.",
                    "label": 0
                },
                {
                    "sent": "So this one is clearly related to trees.",
                    "label": 0
                },
                {
                    "sent": "So for this display I've just asked for 20 aspects in the data because it's easier to visualize.",
                    "label": 0
                },
                {
                    "sent": "If you ask for 100 aspects, then it's sort of mixed things that you cannot really.",
                    "label": 0
                },
                {
                    "sent": "So this one is bike related as well.",
                    "label": 0
                },
                {
                    "sent": "If you go down.",
                    "label": 0
                },
                {
                    "sent": "Well, when you go down it's getting worse and.",
                    "label": 0
                },
                {
                    "sent": "But you can feel this one is is related to buy like somehow, even if it's completely unsupervised so.",
                    "label": 0
                },
                {
                    "sent": "Well, this is enough for examples.",
                    "label": 0
                },
                {
                    "sent": "There are others that are garbage, of course.",
                    "label": 0
                },
                {
                    "sent": "Maybe not this one.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "I'm going to find 1.",
                    "label": 0
                },
                {
                    "sent": "Well, you have things where it's more mixed than some others.",
                    "label": 0
                },
                {
                    "sent": "I can get.",
                    "label": 0
                },
                {
                    "sent": "I cannot find them right now, but you have you have it.",
                    "label": 0
                },
                {
                    "sent": "So if instead of just looking at.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The aspect as illustration.",
                    "label": 0
                },
                {
                    "sent": "You can compute numbers of course.",
                    "label": 0
                },
                {
                    "sent": "If you assume this is a retrieval process, you can say that the ranking based of on aspect is the response to your query.",
                    "label": 0
                },
                {
                    "sent": "So assuming faces faces the query.",
                    "label": 0
                },
                {
                    "sent": "This is the precision recall curves you get for all the 20 aspects we've seen before.",
                    "label": 0
                },
                {
                    "sent": "So aspects 1317 and three seem to be obviously related to the.",
                    "label": 0
                },
                {
                    "sent": "Face object.",
                    "label": 0
                },
                {
                    "sent": "Cuss is less, only one might be related, but not as clearly as the face case.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The entries aspect #7 clearly.",
                    "label": 0
                },
                {
                    "sent": "And bikes.",
                    "label": 0
                },
                {
                    "sent": "Aspect #8 again, it's unsupervised so.",
                    "label": 0
                },
                {
                    "sent": "It's interesting results.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now if we look at the aspect based representation.",
                    "label": 0
                },
                {
                    "sent": "So we had a bug of word of Wisdom for this one.",
                    "label": 0
                },
                {
                    "sent": "We have calculated the probabilistic latent semantic model and now we have a aspect based representation which is only the P of Z given D for this image.",
                    "label": 0
                },
                {
                    "sent": "So again aspect #5.",
                    "label": 0
                },
                {
                    "sent": "Is the one that is most related with building in the data and you can see that this image of course.",
                    "label": 0
                },
                {
                    "sent": "As a high probability of this aspect, given this image.",
                    "label": 0
                },
                {
                    "sent": "This one is just interesting as well because.",
                    "label": 0
                },
                {
                    "sent": "Again, a Spec 5 is also buildings, but Aspect 7 which is.",
                    "label": 0
                },
                {
                    "sent": "Related to trees.",
                    "label": 0
                },
                {
                    "sent": "Is also.",
                    "label": 0
                },
                {
                    "sent": "Highly probable given this one.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "It's true, it's a way of.",
                    "label": 0
                },
                {
                    "sent": "Having you can see that there are mixtures of aspects in an image which is not always obvious to observe in other models.",
                    "label": 0
                },
                {
                    "sent": "Again, this one aspect 7 is quite.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Highly probable because you have some tree like structure behind.",
                    "label": 0
                },
                {
                    "sent": "Bikes, which is number 8.",
                    "label": 0
                },
                {
                    "sent": "Here is highly probable.",
                    "label": 0
                },
                {
                    "sent": "So those are of course just illustrations, but this is the images you can see all over across.",
                    "label": 0
                },
                {
                    "sent": "The data is not really picked up and selected hours.",
                    "label": 0
                },
                {
                    "sent": "And this one is where aspect number 12 is quite related to cars and you also have trees like structures so #7.",
                    "label": 0
                },
                {
                    "sent": "And building, which was five, is quite high.",
                    "label": 0
                },
                {
                    "sent": "So this image again is.",
                    "label": 0
                },
                {
                    "sent": "Is labeled as car only, but of course we cannot say it's not.",
                    "label": 0
                },
                {
                    "sent": "It's not three or there is some building as well in the image.",
                    "label": 0
                },
                {
                    "sent": "So now.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I said that.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "One of the ideas trying to use this and take advantage of non labeled data that you might have.",
                    "label": 0
                },
                {
                    "sent": "And this is the way we would assess the method so.",
                    "label": 0
                },
                {
                    "sent": "We have non test.",
                    "label": 0
                },
                {
                    "sent": "Images or bag of victims.",
                    "label": 0
                },
                {
                    "sent": "This is 90% of.",
                    "label": 0
                },
                {
                    "sent": "All the images we have.",
                    "label": 0
                },
                {
                    "sent": "This is where we train the PSA model on.",
                    "label": 0
                },
                {
                    "sent": "And then from this PSA model, we just extract a few.",
                    "label": 0
                },
                {
                    "sent": "Either all the 90% or 5030 ten percent 5% of the data to do the SVM training.",
                    "label": 0
                },
                {
                    "sent": "So this is the only way this is the only place where we actually use the label in the data.",
                    "label": 0
                },
                {
                    "sent": "And for the test data, so we have the PC model we can.",
                    "label": 0
                },
                {
                    "sent": "Infer from the P of the given Z we can infer the.",
                    "label": 0
                },
                {
                    "sent": "Pfc given different new test images.",
                    "label": 0
                },
                {
                    "sent": "Because we have the chemist model from elsewhere.",
                    "label": 0
                },
                {
                    "sent": "So we have the bag of distance representation again.",
                    "label": 0
                },
                {
                    "sent": "And this is the way we can say.",
                    "label": 0
                },
                {
                    "sent": "See if using the non labeled data might help the SVM classification.",
                    "label": 0
                },
                {
                    "sent": "Four things and we are.",
                    "label": 0
                },
                {
                    "sent": "We are doing this 10 times with non overlapping test sets.",
                    "label": 0
                },
                {
                    "sent": "To have more than one measure for this experiment.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Just a few words about the multi class SVM.",
                    "label": 0
                },
                {
                    "sent": "We're using Gaussian kernel.",
                    "label": 0
                },
                {
                    "sent": "We have one SVM classifier per class, with one against all the strategy and.",
                    "label": 1
                },
                {
                    "sent": "We are finding the standard deviation by cross fivefold cross validation on.",
                    "label": 0
                },
                {
                    "sent": "On the data.",
                    "label": 0
                },
                {
                    "sent": "And we're going to compare the rollback of distance representation with the aspects based representation.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We've picked up 60 aspect.",
                    "label": 0
                },
                {
                    "sent": "We've tried with less, which was worse, and we've tried with more, which wasn't really worse.",
                    "label": 0
                },
                {
                    "sent": "But yeah, this is just number to show you what the potential of this approach.",
                    "label": 0
                },
                {
                    "sent": "So this role is bag of victims.",
                    "label": 0
                },
                {
                    "sent": "Destroy his PSA features.",
                    "label": 0
                },
                {
                    "sent": "And this is using so all the time 90% of the data is used for finding the PSA model.",
                    "label": 0
                },
                {
                    "sent": "If using all the data as well for training the SVM, we can see that.",
                    "label": 0
                },
                {
                    "sent": "Bag of victims is better, but it's not significant across the 10.",
                    "label": 0
                },
                {
                    "sent": "Runs, we run.",
                    "label": 0
                },
                {
                    "sent": "For 50% then people say well, and here we still have the 1260 dimensionality reduction.",
                    "label": 0
                },
                {
                    "sent": "And we have comparable results.",
                    "label": 0
                },
                {
                    "sent": "For the 50% case, then police say improves, but it's not significant.",
                    "label": 0
                },
                {
                    "sent": "Then we have the 30% amount of data for SVM training.",
                    "label": 0
                },
                {
                    "sent": "Where Peerlessly actually significantly beats bug of victims.",
                    "label": 0
                },
                {
                    "sent": "Then 10%.",
                    "label": 0
                },
                {
                    "sent": "It also beats significantly in 5%, which doesn't make any more sense because it's 80% eighty images for training and 170 for testing it still.",
                    "label": 0
                },
                {
                    "sent": "Still better than the rollback of instance representation.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Looking at the confusion matrix so.",
                    "label": 0
                },
                {
                    "sent": "So this is the input image and this is what the system says.",
                    "label": 0
                },
                {
                    "sent": "The image is OK. And we can see that for almost any type of image we have.",
                    "label": 0
                },
                {
                    "sent": "Quite high confusion with cars here.",
                    "label": 0
                },
                {
                    "sent": "OK. And otherwise.",
                    "label": 0
                },
                {
                    "sent": "Of course, the main diagonal is high numbers because the classification is still good for any almost any type of objects in the database.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As a conclusion.",
                    "label": 0
                },
                {
                    "sent": "We could show that.",
                    "label": 0
                },
                {
                    "sent": "Using the latent structure approach.",
                    "label": 1
                },
                {
                    "sent": "Even on images we could we could have an efficient use of unlabeled data to improve the classification performance and SVM's.",
                    "label": 1
                },
                {
                    "sent": "Of course, this should be assessed with.",
                    "label": 0
                },
                {
                    "sent": "Not reducing.",
                    "label": 0
                },
                {
                    "sent": "Within the training set with having hopefully more images from somewhere else and then trying to build the bug of these terms on.",
                    "label": 0
                },
                {
                    "sent": "The training data using 90% for SVM training but.",
                    "label": 0
                },
                {
                    "sent": "Then, as I've shown on the web page, the latent structure you can find in this data might be useful for browsing.",
                    "label": 0
                },
                {
                    "sent": "I mean, assuming you have really no no label for you data for your images, you can.",
                    "label": 0
                },
                {
                    "sent": "Learn this policy model on them and then have a way of displaying what is actually in this data set.",
                    "label": 0
                },
                {
                    "sent": "And it's interesting was to see that images can be seen as a mixture of aspects as well.",
                    "label": 0
                },
                {
                    "sent": "Like when we have the.",
                    "label": 0
                },
                {
                    "sent": "The bike and then some tree structure like behind it.",
                    "label": 0
                },
                {
                    "sent": "It's interesting to have the mixture of aspect approach for this data.",
                    "label": 0
                },
                {
                    "sent": "And the last point is, given that.",
                    "label": 0
                },
                {
                    "sent": "Saying that an image is one place class only is not.",
                    "label": 0
                },
                {
                    "sent": "Possible any.",
                    "label": 0
                },
                {
                    "sent": "Whenever you increase the number of classes then you're going to have more overlap so it would be interesting to have a way to.",
                    "label": 0
                },
                {
                    "sent": "Access multilabel to those images instead of only one.",
                    "label": 0
                },
                {
                    "sent": "And see what the results are.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Do you see your your face?",
                    "label": 0
                },
                {
                    "sent": "Stuff, is it continuous?",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "BLS no no.",
                    "label": 0
                },
                {
                    "sent": "Has been compromised by the.",
                    "label": 0
                },
                {
                    "sent": "And it's it's really similar to words or.",
                    "label": 0
                },
                {
                    "sent": "So of course, when I do would be to not contest those features but feel yeah, problem being that it's 128 dimensions.",
                    "label": 0
                },
                {
                    "sent": "Might be worth the trouble.",
                    "label": 0
                },
                {
                    "sent": "Maybe he thought about this.",
                    "label": 0
                },
                {
                    "sent": "What would happen if you just use PCA to reduce it down to 60 dimension?",
                    "label": 0
                },
                {
                    "sent": "When did the K means on the 60 days?",
                    "label": 0
                },
                {
                    "sent": "Well, we haven't compatible Surface book.",
                    "label": 0
                },
                {
                    "sent": "Yes, yeah, this would be is not.",
                    "label": 0
                },
                {
                    "sent": "Maybe the rebaseline compared to that.",
                    "label": 0
                },
                {
                    "sent": "OK, I think.",
                    "label": 0
                }
            ]
        }
    }
}