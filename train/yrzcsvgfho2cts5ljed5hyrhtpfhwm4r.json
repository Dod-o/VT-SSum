{
    "id": "yrzcsvgfho2cts5ljed5hyrhtpfhwm4r",
    "title": "Discussion of Alex Smola's talk: Remarks on parallelised MCMC",
    "info": {
        "author": [
            "Yee Whye Teh, Department of Statistics, University of Oxford"
        ],
        "published": "Jan. 24, 2012",
        "recorded": "December 2011",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/nipsworkshops2011_teh_discussant/",
    "segmentation": [
        [
            "So for the discussion, I really only have.",
            "A few remarks on various ways that people have thought about MCMC sampling in paralyzing MCMC.",
            "And really, I just have lots of questions to ponder about, really.",
            "So let's start with parallel."
        ],
        [
            "MCMC, so I think in the paper by Jeff Jeff Rosenthal.",
            "He claimed that Mkes embarrassingly parallelizable, so.",
            "Imagine that you have some model.",
            "This is one of your Markov chains, right?",
            "So if you're paralyzed, you want to get more samples, simply run.",
            "Individual independent Markov chains, one on every machine.",
            "This is works great, right?",
            "But if you are modeling your data, can each of them can be fit into one single machine and that's it, right?",
            "So."
        ],
        [
            "Have of course lots of variations on things like this, right?",
            "So one of the issues is that each of these chains might be taking a long time to converge.",
            "So what can you do with that?",
            "So another way of doing parallelization is to do Metropolis coupled MCMC sampling.",
            "So on every machine now you may have, you may run a different Markov chain at different temperatures, so the idea is that at high temperatures this Markov chains should converge faster, but then to kind of.",
            "Equilibrium distributions that is not your posterior distribution that you're interested in, which is the one here.",
            "So basically, using this auxiliary chains as ways of mixing across different modes of your posterior distribution.",
            "So then the idea is if we want to.",
            "You can use things like Metropolis Hastings moves where you propose swapping the states of your two Markov chains at neighboring temperatures so that.",
            "Basically, think of this as you have a highway right where you have slow moving traffic here and high moving traffic here and once in a while you may want to swap lanes basically OK.",
            "So that's nice, but again.",
            "Really, you're spending a lot of computations just so that you can get one single chain to mix well.",
            "So one of the issues that Alex brought up is.",
            "Nowadays when we think about scalable large scale models and large scale data, we can't really fit this single models or your whole data set into one single computer anymore.",
            "So what can you do so?"
        ],
        [
            "Simple thing you could do right is that.",
            "Now imagine that you have one Markov chain.",
            "This kind of running, but within each step of your Markov chain what you do is you split your data set across multiple machines, right?",
            "And then you can compute do independent computations on each machine on basically different parts of your data set, and then you have to synchronize and send all this results to some some master against Master.",
            "Server that then counter synchronizes all your computations, updates your chain and then go to the next step and so forth.",
            "OK, so this allows us to kind of scale up to cases where.",
            "Where your datasets is so large you can fit onto a single machine.",
            "Or maybe it takes a long time to simply iterate over your data set.",
            "OK, well, of course the problem here is that there's a lot of synchronization that has to be done here, so it's very expensive.",
            "With all of these methods, including the soft methods that Alex talked about, you still.",
            "You still have to run a Markov chain where basically you know the runtime of algorithm is going to be related to the length of your Markov chain.",
            "So what interesting question might be, how can you use parallelization to actually?",
            "Spend less time.",
            "Machine.",
            "But still at the same time have some self idea where the overall computation is actually.",
            "Let me redo this.",
            "Let's imagine that you want to run your MCMC sampler for 10,000 iterations, and suppose that you have 100 machines.",
            "Is it possible to split your 10,000 iterations across the 100 machines so that search at each machine runs, say, on the order of a few 100 iterations?",
            "So you would think that it's kind of impossible, right?",
            "Because the output of the starting state of.",
            "Say the no.",
            "So basically you simply have a Markov chain and they are dependent on the previous state, so it's almost impossible that you could think of paralyzing across that, so it turns out that that is actually a nice little trick that actually Radford.",
            "Neal has to actually thought about.",
            "I'm not sure as there's been further development along this line, but I'd like to just tell you about it."
        ],
        [
            "And what this thing is called circularly coupled MCMC let's.",
            "Start with a very simple example for how this might work.",
            "OK, so.",
            "Let's imagine that we're going to start our Markov chain at two possible states.",
            "One is X1 didn't set, 1X1 is going to be sample from an initial distribution, P not.",
            "But Zed, one, let's imagine that is a sample from our equilibrium distribution.",
            "And now this is our Markov chain.",
            "OK, so.",
            "Whenever, at each step would like to update from XI minus one XI and the way we can do this update is that we can imagine sampling some some.",
            "Use a random number generator to generate a random number and then pass that through some fixed function which basically implements our transition probability from one state of the Markov chain to another.",
            "And we do this for the chain started from X1 and we do this from with the chain started at that one, but the idea is that we are going to use the exactly the same random number seeds.",
            "OK."
        ],
        [
            "Now suppose that after we've run this T iterations.",
            "OK, and suppose that.",
            "Zetty, so I'll final state of this two chains is actually going to be equal at the end of this.",
            "Mercy sampling right then, since that one started from the equilibrium distribution annex one started from our initial distribution, but they ended up in the same state.",
            "Then we can more or less kind of say that maybe probably our Markov chain has kind of probably converged.",
            "So, so this is kind of in the idea of coupling from the past, so the idea is that if you use reuse your same random number seeds and if you have started off at all possible states, an all of them has convinced to the same state by the end of your MCMC iteration then.",
            "Ways in which you could make that?",
            "You can actually construct an algorithm that will actually say that that single sample that you get is going to be an exact sample from your posterior distribution.",
            "But of course we can't.",
            "This thing is not quite doable because that one is a sample from equilibrium distribution to begin with.",
            "So."
        ],
        [
            "The idea now is that.",
            "In let's suppose that instead of sampling from a posterior distribution, we start off at the last state of our MCMC algorithm, OK?",
            "As a proxy for our equilibrium distribution.",
            "Right, so now this if we do believe that MCMC would have converged after T iterations, then this is probably a good sample from the posterior.",
            "And if you plug it in an if they have coalesced by this point.",
            "Then out.",
            "A Markov chain has probably converged to OK, so it's a bit of a circular argument.",
            "OK, so just."
        ],
        [
            "To graphically show you what's happening.",
            "So basically we're going to.",
            "Start off stuff at X1.",
            "Right now, Michael Chan too XD and then reuse the same random number seeds.",
            "And then run a Markov chain an if we end up at exactly the same state.",
            "Then we kind of more or less converged.",
            "OK, so this is the basic idea.",
            "It doesn't seem like parallel paralyzable yet, right?",
            "So now the trick is that."
        ],
        [
            "We have our circular backup chain here in the middle.",
            "And let's imagine that we actually start off.",
            "At different parts of the.",
            "Four different machines, so each of these squares is going to be a machine, and each of them is going to start off at some initial state.",
            "And we run it for a bit and then we run it.",
            "Actually, no, we run.",
            "Machine for a bit and then we also take the last.",
            "So for this machine we've arrived at this state.",
            "We pass that as.",
            "To be the initial states as our equilibrated, that one sample from the posterior distribution right and then we start from that.",
            "And if this two has coalesced, and if those two has collapsed and those Tesco last, then we've probably we do believe that this thing should should have.",
            "Calf converge to the equal kind of the equilibrium distribution, and there's a bit of theory on this.",
            "OK, so now our Markov chain has length, which is kind of.",
            "That the circumference of this circle but each machine only needs to run for a small segment of this circle.",
            "So it's kind of a cute little idea that I don't think has been explored yet, but maybe we can use this to paralyze or even one single MCMC chain."
        ],
        [
            "This is just a little diagram to see this from Radford newspaper.",
            "Where the?",
            "Both.",
            "Plot here is actually the circular Markov chain, and then each of this is the starting point of a different.",
            "Alpha of a different machine.",
            "That kind of coalesces with this single circular chain.",
            "This is kind of a cute little idea.",
            "Right so."
        ],
        [
            "End this with lots of questions to ponder about really OK, so let's start off with MCMC sampling.",
            "Um?",
            "So in I guess at the end when Alex was talking about how you can.",
            "Make this.",
            "Paralyzed sample are more efficient.",
            "One of the things is that.",
            "Is that you don't want to have too much synchronization because they can't kill you in terms of the amount of time it takes to synchronize across all the different machines.",
            "So then the question.",
            "Then the issue then is that the theory of MCMC sampling doesn't really hold anymore, so that I think would be very interesting if you could.",
            "Caffe understand what the this paralyzed asynchronous MCMC chain is converging to?",
            "Can we somehow show under certain circumstances whether there is some bound on how far away we are from the true posterior distribution?",
            "Another issue is of course, how do we know that we have converged?",
            "I think this kind of diagnostics in MCMC is difficult, OK?",
            "Another issue that comes out as related to the theories.",
            "How can we develop paralyzed MCMC?",
            "Um?",
            "Techniques that will be more robust against unreliable hardware, right?",
            "So in a lot of these large scale computational architectures.",
            "Is never fully reliable, so there's always something that might fail.",
            "Is a switch or or a?",
            "Compute node and so forth.",
            "OK, so can we develop some theory which shows along with some method which allows us to kind of God to be more robust against this hardware failures.",
            "I think there will be something that's very interesting to think about, I think.",
            "OK."
        ],
        [
            "Lots of questions regarding modeling.",
            "OK, so one of the things that I guess.",
            "Is assumed in Alexis talk, but is of course we are in the basin on Perfex workshop.",
            "So the question is.",
            "Should we be thinking about large parametric models or nonparametric models so a latent rich location is a parametric model?",
            "You may say that OK, that's 100,000 topics, and there's probably as large as you ever need.",
            "OK, so maybe it's kind of effectively nonparametric, so there's all this theory on based on Perma fix really help when at the end of the day maybe we're only.",
            "We only become working with large parametric models to begin with, so I guess this question has come up a few times.",
            "I've had various people come up to me and say, oh, you know I have this state data perhaps?",
            "Do you think I should try one of these infinite star star models on my data?",
            "Maybe infinite hierarchical distributed?",
            "He did Markov model or something like that OK?",
            "And often.",
            "My answer might be well, maybe you should try a finite model first.",
            "OK, so if on the one hand for a beginner coming into the field we would recommend finite models and then on the other hand people who actually use this in large flat screen industry applications, we're going to stick with finite models.",
            "What is the point of basic nonparametric theory?",
            "I think.",
            "Well, there's some partial answers to that.",
            "I think, at least in my own work, I think thinking about Nonparametrics and thinking about.",
            "How can we define models that are sensible in the infinite limit actually allows at least myself to two?",
            "2.",
            "Think about so if you're.",
            "If your large finite model doesn't have a proper infinite limit that maybe you should start worrying about whether that large finite model is actually expressing some prior, which is sensible, basically, OK.",
            "In my experience, I've always found that.",
            "Priors for finite models that are sensible often have sensible infinite limits basically.",
            "Basically what happens is that if it doesn't have sensible infinite limits, then there's kind of saying that your prior is kind of going.",
            "Your prior is too strong.",
            "As you, as you increase the model size, basically.",
            "OK.",
            "So one of the reasons why we're interested in based on project is that you know we live in a complex world, so perhaps we need to complex model for this, right so?",
            "The issue is.",
            "How can we learn this of complex models efficiently?",
            "Since since it's a complex models we need lots of data and how can we learn this efficiently and how can we make sure that our models are don't count like Buckle on the counter weight of the computational cost that we have to pay to actually get to learn from large amounts of data?",
            "I think this is.",
            "Something that we really have to think about when we actually apply this of models to kind of kind of.",
            "Kind of too soft, counter problems that are difficult I think.",
            "Another question is, do we really need so much data, so perhaps?",
            "You know, I?",
            "I guess you didn't really talk about how you use your topic models in downstream applications, so but maybe it's the case that you know you have 100,000 topics.",
            "Say maybe the first 10,000 is actually quite.",
            "Topics that occur regularly, but maybe the last 90,000 topics are just so rare that perhaps it's not useful to actually even try to model it.",
            "Is this coming from the tail of the model?",
            "Right and finally, I guess even for a model as simple as latent allocation, we already see that there's a lot of engineering to be done just to scale up this very simple model to large scale data.",
            "Is it feasible or is it possible?",
            "I guess there's not that many people like Alex, so can we have some more structured models?",
            "Can we scale it to large scale data?",
            "I think that's something.",
            "It's not.",
            "There's no easy solution to this, isn't it so?"
        ],
        [
            "Right, so in summary.",
            "I think there's lots of things that we should think about in terms of computational concerns.",
            "So and.",
            "I guess I've brought up most of the points really, so one thing I'd like to say is probabilistic models don't just exist by themselves, but they are often.",
            "Part of a larger system.",
            "So when we when we develop this based nonprofit models or probabilistic models, we have to think about what we want to achieve with our model downstream and think about whether there's computational constraints or static constraints.",
            "About this OK.",
            "I think we still haven't really.",
            "I think we've already developed lots of good inference solutions for probabilistic models like MCMC.",
            "Very large classes of models that MCMC variational and expectation propagation so forth.",
            "There's certain circumstances.",
            "Variational or expectation propagation will do better than MCMC and vice versa.",
            "And in the case of topic models and clustering, it does seem that I guess MCMC sampling is better.",
            "But I think there's still a lot of scope to be done to actually develop better inference algorithms here.",
            "Basically, I think, at least for variational MCMC.",
            "The way this algorithms work is that you make local changes to your model, fixing the rest.",
            "And if you have a cover.",
            "Highly dependent latent variables.",
            "Then if you fix the rest, then you're going to come get stuck in some local mode when you update the bit of your model that you're updating.",
            "So the last little thing that I'd like to say is the warning is basically to avoid bloatware, right I guess.",
            "And I remember back in the 80s and 90s you always have two more like the 90s.",
            "I guess every few years you always have to update your computer because Microsoft Windows would become.",
            "It cover it.",
            "Takes more and more computation just to do the same thing, and you can upgrade to the next version of Windows without having to buy a new hardware.",
            "And I think that this is true for basic nonparametric models as well, I think.",
            "I guess when I first learned about based nonprofit models is a bit like a kid getting a brand new Lego set from my parents and I'm like, yeah, I can build really big models and solve all the problems in the world and they're like so fun, but.",
            "The problem is, you know we can.",
            "It's very easy in basin Nonparametrics to build big complicated models, but maybe it's not that easy to build models that are slim and kind of like this.",
            "Exactly what you wanted to do.",
            "And I think that you know we need to have better understanding of this, models more math or maybe just more intuition about how these models work, but I think it's very important in terms of applications of these models to avoid bloated models.",
            "Basically, yeah, thanks."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for the discussion, I really only have.",
                    "label": 0
                },
                {
                    "sent": "A few remarks on various ways that people have thought about MCMC sampling in paralyzing MCMC.",
                    "label": 0
                },
                {
                    "sent": "And really, I just have lots of questions to ponder about, really.",
                    "label": 1
                },
                {
                    "sent": "So let's start with parallel.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "MCMC, so I think in the paper by Jeff Jeff Rosenthal.",
                    "label": 0
                },
                {
                    "sent": "He claimed that Mkes embarrassingly parallelizable, so.",
                    "label": 0
                },
                {
                    "sent": "Imagine that you have some model.",
                    "label": 0
                },
                {
                    "sent": "This is one of your Markov chains, right?",
                    "label": 0
                },
                {
                    "sent": "So if you're paralyzed, you want to get more samples, simply run.",
                    "label": 0
                },
                {
                    "sent": "Individual independent Markov chains, one on every machine.",
                    "label": 0
                },
                {
                    "sent": "This is works great, right?",
                    "label": 0
                },
                {
                    "sent": "But if you are modeling your data, can each of them can be fit into one single machine and that's it, right?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Have of course lots of variations on things like this, right?",
                    "label": 0
                },
                {
                    "sent": "So one of the issues is that each of these chains might be taking a long time to converge.",
                    "label": 0
                },
                {
                    "sent": "So what can you do with that?",
                    "label": 0
                },
                {
                    "sent": "So another way of doing parallelization is to do Metropolis coupled MCMC sampling.",
                    "label": 0
                },
                {
                    "sent": "So on every machine now you may have, you may run a different Markov chain at different temperatures, so the idea is that at high temperatures this Markov chains should converge faster, but then to kind of.",
                    "label": 0
                },
                {
                    "sent": "Equilibrium distributions that is not your posterior distribution that you're interested in, which is the one here.",
                    "label": 0
                },
                {
                    "sent": "So basically, using this auxiliary chains as ways of mixing across different modes of your posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "So then the idea is if we want to.",
                    "label": 0
                },
                {
                    "sent": "You can use things like Metropolis Hastings moves where you propose swapping the states of your two Markov chains at neighboring temperatures so that.",
                    "label": 0
                },
                {
                    "sent": "Basically, think of this as you have a highway right where you have slow moving traffic here and high moving traffic here and once in a while you may want to swap lanes basically OK.",
                    "label": 0
                },
                {
                    "sent": "So that's nice, but again.",
                    "label": 0
                },
                {
                    "sent": "Really, you're spending a lot of computations just so that you can get one single chain to mix well.",
                    "label": 0
                },
                {
                    "sent": "So one of the issues that Alex brought up is.",
                    "label": 0
                },
                {
                    "sent": "Nowadays when we think about scalable large scale models and large scale data, we can't really fit this single models or your whole data set into one single computer anymore.",
                    "label": 0
                },
                {
                    "sent": "So what can you do so?",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Simple thing you could do right is that.",
                    "label": 0
                },
                {
                    "sent": "Now imagine that you have one Markov chain.",
                    "label": 0
                },
                {
                    "sent": "This kind of running, but within each step of your Markov chain what you do is you split your data set across multiple machines, right?",
                    "label": 0
                },
                {
                    "sent": "And then you can compute do independent computations on each machine on basically different parts of your data set, and then you have to synchronize and send all this results to some some master against Master.",
                    "label": 0
                },
                {
                    "sent": "Server that then counter synchronizes all your computations, updates your chain and then go to the next step and so forth.",
                    "label": 0
                },
                {
                    "sent": "OK, so this allows us to kind of scale up to cases where.",
                    "label": 0
                },
                {
                    "sent": "Where your datasets is so large you can fit onto a single machine.",
                    "label": 0
                },
                {
                    "sent": "Or maybe it takes a long time to simply iterate over your data set.",
                    "label": 0
                },
                {
                    "sent": "OK, well, of course the problem here is that there's a lot of synchronization that has to be done here, so it's very expensive.",
                    "label": 0
                },
                {
                    "sent": "With all of these methods, including the soft methods that Alex talked about, you still.",
                    "label": 0
                },
                {
                    "sent": "You still have to run a Markov chain where basically you know the runtime of algorithm is going to be related to the length of your Markov chain.",
                    "label": 0
                },
                {
                    "sent": "So what interesting question might be, how can you use parallelization to actually?",
                    "label": 0
                },
                {
                    "sent": "Spend less time.",
                    "label": 0
                },
                {
                    "sent": "Machine.",
                    "label": 0
                },
                {
                    "sent": "But still at the same time have some self idea where the overall computation is actually.",
                    "label": 0
                },
                {
                    "sent": "Let me redo this.",
                    "label": 0
                },
                {
                    "sent": "Let's imagine that you want to run your MCMC sampler for 10,000 iterations, and suppose that you have 100 machines.",
                    "label": 0
                },
                {
                    "sent": "Is it possible to split your 10,000 iterations across the 100 machines so that search at each machine runs, say, on the order of a few 100 iterations?",
                    "label": 0
                },
                {
                    "sent": "So you would think that it's kind of impossible, right?",
                    "label": 0
                },
                {
                    "sent": "Because the output of the starting state of.",
                    "label": 0
                },
                {
                    "sent": "Say the no.",
                    "label": 0
                },
                {
                    "sent": "So basically you simply have a Markov chain and they are dependent on the previous state, so it's almost impossible that you could think of paralyzing across that, so it turns out that that is actually a nice little trick that actually Radford.",
                    "label": 0
                },
                {
                    "sent": "Neal has to actually thought about.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure as there's been further development along this line, but I'd like to just tell you about it.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And what this thing is called circularly coupled MCMC let's.",
                    "label": 0
                },
                {
                    "sent": "Start with a very simple example for how this might work.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Let's imagine that we're going to start our Markov chain at two possible states.",
                    "label": 0
                },
                {
                    "sent": "One is X1 didn't set, 1X1 is going to be sample from an initial distribution, P not.",
                    "label": 0
                },
                {
                    "sent": "But Zed, one, let's imagine that is a sample from our equilibrium distribution.",
                    "label": 0
                },
                {
                    "sent": "And now this is our Markov chain.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Whenever, at each step would like to update from XI minus one XI and the way we can do this update is that we can imagine sampling some some.",
                    "label": 0
                },
                {
                    "sent": "Use a random number generator to generate a random number and then pass that through some fixed function which basically implements our transition probability from one state of the Markov chain to another.",
                    "label": 0
                },
                {
                    "sent": "And we do this for the chain started from X1 and we do this from with the chain started at that one, but the idea is that we are going to use the exactly the same random number seeds.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now suppose that after we've run this T iterations.",
                    "label": 0
                },
                {
                    "sent": "OK, and suppose that.",
                    "label": 0
                },
                {
                    "sent": "Zetty, so I'll final state of this two chains is actually going to be equal at the end of this.",
                    "label": 0
                },
                {
                    "sent": "Mercy sampling right then, since that one started from the equilibrium distribution annex one started from our initial distribution, but they ended up in the same state.",
                    "label": 0
                },
                {
                    "sent": "Then we can more or less kind of say that maybe probably our Markov chain has kind of probably converged.",
                    "label": 0
                },
                {
                    "sent": "So, so this is kind of in the idea of coupling from the past, so the idea is that if you use reuse your same random number seeds and if you have started off at all possible states, an all of them has convinced to the same state by the end of your MCMC iteration then.",
                    "label": 0
                },
                {
                    "sent": "Ways in which you could make that?",
                    "label": 0
                },
                {
                    "sent": "You can actually construct an algorithm that will actually say that that single sample that you get is going to be an exact sample from your posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "But of course we can't.",
                    "label": 0
                },
                {
                    "sent": "This thing is not quite doable because that one is a sample from equilibrium distribution to begin with.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The idea now is that.",
                    "label": 0
                },
                {
                    "sent": "In let's suppose that instead of sampling from a posterior distribution, we start off at the last state of our MCMC algorithm, OK?",
                    "label": 0
                },
                {
                    "sent": "As a proxy for our equilibrium distribution.",
                    "label": 0
                },
                {
                    "sent": "Right, so now this if we do believe that MCMC would have converged after T iterations, then this is probably a good sample from the posterior.",
                    "label": 0
                },
                {
                    "sent": "And if you plug it in an if they have coalesced by this point.",
                    "label": 0
                },
                {
                    "sent": "Then out.",
                    "label": 0
                },
                {
                    "sent": "A Markov chain has probably converged to OK, so it's a bit of a circular argument.",
                    "label": 0
                },
                {
                    "sent": "OK, so just.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To graphically show you what's happening.",
                    "label": 0
                },
                {
                    "sent": "So basically we're going to.",
                    "label": 0
                },
                {
                    "sent": "Start off stuff at X1.",
                    "label": 0
                },
                {
                    "sent": "Right now, Michael Chan too XD and then reuse the same random number seeds.",
                    "label": 0
                },
                {
                    "sent": "And then run a Markov chain an if we end up at exactly the same state.",
                    "label": 0
                },
                {
                    "sent": "Then we kind of more or less converged.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is the basic idea.",
                    "label": 0
                },
                {
                    "sent": "It doesn't seem like parallel paralyzable yet, right?",
                    "label": 0
                },
                {
                    "sent": "So now the trick is that.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We have our circular backup chain here in the middle.",
                    "label": 0
                },
                {
                    "sent": "And let's imagine that we actually start off.",
                    "label": 0
                },
                {
                    "sent": "At different parts of the.",
                    "label": 0
                },
                {
                    "sent": "Four different machines, so each of these squares is going to be a machine, and each of them is going to start off at some initial state.",
                    "label": 0
                },
                {
                    "sent": "And we run it for a bit and then we run it.",
                    "label": 0
                },
                {
                    "sent": "Actually, no, we run.",
                    "label": 0
                },
                {
                    "sent": "Machine for a bit and then we also take the last.",
                    "label": 0
                },
                {
                    "sent": "So for this machine we've arrived at this state.",
                    "label": 0
                },
                {
                    "sent": "We pass that as.",
                    "label": 0
                },
                {
                    "sent": "To be the initial states as our equilibrated, that one sample from the posterior distribution right and then we start from that.",
                    "label": 0
                },
                {
                    "sent": "And if this two has coalesced, and if those two has collapsed and those Tesco last, then we've probably we do believe that this thing should should have.",
                    "label": 0
                },
                {
                    "sent": "Calf converge to the equal kind of the equilibrium distribution, and there's a bit of theory on this.",
                    "label": 0
                },
                {
                    "sent": "OK, so now our Markov chain has length, which is kind of.",
                    "label": 0
                },
                {
                    "sent": "That the circumference of this circle but each machine only needs to run for a small segment of this circle.",
                    "label": 0
                },
                {
                    "sent": "So it's kind of a cute little idea that I don't think has been explored yet, but maybe we can use this to paralyze or even one single MCMC chain.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is just a little diagram to see this from Radford newspaper.",
                    "label": 0
                },
                {
                    "sent": "Where the?",
                    "label": 0
                },
                {
                    "sent": "Both.",
                    "label": 0
                },
                {
                    "sent": "Plot here is actually the circular Markov chain, and then each of this is the starting point of a different.",
                    "label": 0
                },
                {
                    "sent": "Alpha of a different machine.",
                    "label": 0
                },
                {
                    "sent": "That kind of coalesces with this single circular chain.",
                    "label": 0
                },
                {
                    "sent": "This is kind of a cute little idea.",
                    "label": 0
                },
                {
                    "sent": "Right so.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "End this with lots of questions to ponder about really OK, so let's start off with MCMC sampling.",
                    "label": 1
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So in I guess at the end when Alex was talking about how you can.",
                    "label": 0
                },
                {
                    "sent": "Make this.",
                    "label": 0
                },
                {
                    "sent": "Paralyzed sample are more efficient.",
                    "label": 0
                },
                {
                    "sent": "One of the things is that.",
                    "label": 0
                },
                {
                    "sent": "Is that you don't want to have too much synchronization because they can't kill you in terms of the amount of time it takes to synchronize across all the different machines.",
                    "label": 0
                },
                {
                    "sent": "So then the question.",
                    "label": 0
                },
                {
                    "sent": "Then the issue then is that the theory of MCMC sampling doesn't really hold anymore, so that I think would be very interesting if you could.",
                    "label": 0
                },
                {
                    "sent": "Caffe understand what the this paralyzed asynchronous MCMC chain is converging to?",
                    "label": 1
                },
                {
                    "sent": "Can we somehow show under certain circumstances whether there is some bound on how far away we are from the true posterior distribution?",
                    "label": 0
                },
                {
                    "sent": "Another issue is of course, how do we know that we have converged?",
                    "label": 1
                },
                {
                    "sent": "I think this kind of diagnostics in MCMC is difficult, OK?",
                    "label": 0
                },
                {
                    "sent": "Another issue that comes out as related to the theories.",
                    "label": 0
                },
                {
                    "sent": "How can we develop paralyzed MCMC?",
                    "label": 1
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Techniques that will be more robust against unreliable hardware, right?",
                    "label": 0
                },
                {
                    "sent": "So in a lot of these large scale computational architectures.",
                    "label": 0
                },
                {
                    "sent": "Is never fully reliable, so there's always something that might fail.",
                    "label": 0
                },
                {
                    "sent": "Is a switch or or a?",
                    "label": 0
                },
                {
                    "sent": "Compute node and so forth.",
                    "label": 0
                },
                {
                    "sent": "OK, so can we develop some theory which shows along with some method which allows us to kind of God to be more robust against this hardware failures.",
                    "label": 0
                },
                {
                    "sent": "I think there will be something that's very interesting to think about, I think.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Lots of questions regarding modeling.",
                    "label": 1
                },
                {
                    "sent": "OK, so one of the things that I guess.",
                    "label": 0
                },
                {
                    "sent": "Is assumed in Alexis talk, but is of course we are in the basin on Perfex workshop.",
                    "label": 0
                },
                {
                    "sent": "So the question is.",
                    "label": 0
                },
                {
                    "sent": "Should we be thinking about large parametric models or nonparametric models so a latent rich location is a parametric model?",
                    "label": 0
                },
                {
                    "sent": "You may say that OK, that's 100,000 topics, and there's probably as large as you ever need.",
                    "label": 0
                },
                {
                    "sent": "OK, so maybe it's kind of effectively nonparametric, so there's all this theory on based on Perma fix really help when at the end of the day maybe we're only.",
                    "label": 0
                },
                {
                    "sent": "We only become working with large parametric models to begin with, so I guess this question has come up a few times.",
                    "label": 0
                },
                {
                    "sent": "I've had various people come up to me and say, oh, you know I have this state data perhaps?",
                    "label": 0
                },
                {
                    "sent": "Do you think I should try one of these infinite star star models on my data?",
                    "label": 0
                },
                {
                    "sent": "Maybe infinite hierarchical distributed?",
                    "label": 0
                },
                {
                    "sent": "He did Markov model or something like that OK?",
                    "label": 0
                },
                {
                    "sent": "And often.",
                    "label": 0
                },
                {
                    "sent": "My answer might be well, maybe you should try a finite model first.",
                    "label": 0
                },
                {
                    "sent": "OK, so if on the one hand for a beginner coming into the field we would recommend finite models and then on the other hand people who actually use this in large flat screen industry applications, we're going to stick with finite models.",
                    "label": 0
                },
                {
                    "sent": "What is the point of basic nonparametric theory?",
                    "label": 0
                },
                {
                    "sent": "I think.",
                    "label": 0
                },
                {
                    "sent": "Well, there's some partial answers to that.",
                    "label": 0
                },
                {
                    "sent": "I think, at least in my own work, I think thinking about Nonparametrics and thinking about.",
                    "label": 0
                },
                {
                    "sent": "How can we define models that are sensible in the infinite limit actually allows at least myself to two?",
                    "label": 0
                },
                {
                    "sent": "2.",
                    "label": 0
                },
                {
                    "sent": "Think about so if you're.",
                    "label": 0
                },
                {
                    "sent": "If your large finite model doesn't have a proper infinite limit that maybe you should start worrying about whether that large finite model is actually expressing some prior, which is sensible, basically, OK.",
                    "label": 0
                },
                {
                    "sent": "In my experience, I've always found that.",
                    "label": 0
                },
                {
                    "sent": "Priors for finite models that are sensible often have sensible infinite limits basically.",
                    "label": 0
                },
                {
                    "sent": "Basically what happens is that if it doesn't have sensible infinite limits, then there's kind of saying that your prior is kind of going.",
                    "label": 0
                },
                {
                    "sent": "Your prior is too strong.",
                    "label": 0
                },
                {
                    "sent": "As you, as you increase the model size, basically.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So one of the reasons why we're interested in based on project is that you know we live in a complex world, so perhaps we need to complex model for this, right so?",
                    "label": 0
                },
                {
                    "sent": "The issue is.",
                    "label": 0
                },
                {
                    "sent": "How can we learn this of complex models efficiently?",
                    "label": 0
                },
                {
                    "sent": "Since since it's a complex models we need lots of data and how can we learn this efficiently and how can we make sure that our models are don't count like Buckle on the counter weight of the computational cost that we have to pay to actually get to learn from large amounts of data?",
                    "label": 0
                },
                {
                    "sent": "I think this is.",
                    "label": 0
                },
                {
                    "sent": "Something that we really have to think about when we actually apply this of models to kind of kind of.",
                    "label": 0
                },
                {
                    "sent": "Kind of too soft, counter problems that are difficult I think.",
                    "label": 0
                },
                {
                    "sent": "Another question is, do we really need so much data, so perhaps?",
                    "label": 1
                },
                {
                    "sent": "You know, I?",
                    "label": 0
                },
                {
                    "sent": "I guess you didn't really talk about how you use your topic models in downstream applications, so but maybe it's the case that you know you have 100,000 topics.",
                    "label": 0
                },
                {
                    "sent": "Say maybe the first 10,000 is actually quite.",
                    "label": 0
                },
                {
                    "sent": "Topics that occur regularly, but maybe the last 90,000 topics are just so rare that perhaps it's not useful to actually even try to model it.",
                    "label": 0
                },
                {
                    "sent": "Is this coming from the tail of the model?",
                    "label": 0
                },
                {
                    "sent": "Right and finally, I guess even for a model as simple as latent allocation, we already see that there's a lot of engineering to be done just to scale up this very simple model to large scale data.",
                    "label": 1
                },
                {
                    "sent": "Is it feasible or is it possible?",
                    "label": 0
                },
                {
                    "sent": "I guess there's not that many people like Alex, so can we have some more structured models?",
                    "label": 0
                },
                {
                    "sent": "Can we scale it to large scale data?",
                    "label": 0
                },
                {
                    "sent": "I think that's something.",
                    "label": 0
                },
                {
                    "sent": "It's not.",
                    "label": 0
                },
                {
                    "sent": "There's no easy solution to this, isn't it so?",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right, so in summary.",
                    "label": 0
                },
                {
                    "sent": "I think there's lots of things that we should think about in terms of computational concerns.",
                    "label": 0
                },
                {
                    "sent": "So and.",
                    "label": 0
                },
                {
                    "sent": "I guess I've brought up most of the points really, so one thing I'd like to say is probabilistic models don't just exist by themselves, but they are often.",
                    "label": 0
                },
                {
                    "sent": "Part of a larger system.",
                    "label": 0
                },
                {
                    "sent": "So when we when we develop this based nonprofit models or probabilistic models, we have to think about what we want to achieve with our model downstream and think about whether there's computational constraints or static constraints.",
                    "label": 0
                },
                {
                    "sent": "About this OK.",
                    "label": 0
                },
                {
                    "sent": "I think we still haven't really.",
                    "label": 0
                },
                {
                    "sent": "I think we've already developed lots of good inference solutions for probabilistic models like MCMC.",
                    "label": 1
                },
                {
                    "sent": "Very large classes of models that MCMC variational and expectation propagation so forth.",
                    "label": 0
                },
                {
                    "sent": "There's certain circumstances.",
                    "label": 0
                },
                {
                    "sent": "Variational or expectation propagation will do better than MCMC and vice versa.",
                    "label": 0
                },
                {
                    "sent": "And in the case of topic models and clustering, it does seem that I guess MCMC sampling is better.",
                    "label": 0
                },
                {
                    "sent": "But I think there's still a lot of scope to be done to actually develop better inference algorithms here.",
                    "label": 0
                },
                {
                    "sent": "Basically, I think, at least for variational MCMC.",
                    "label": 0
                },
                {
                    "sent": "The way this algorithms work is that you make local changes to your model, fixing the rest.",
                    "label": 1
                },
                {
                    "sent": "And if you have a cover.",
                    "label": 0
                },
                {
                    "sent": "Highly dependent latent variables.",
                    "label": 0
                },
                {
                    "sent": "Then if you fix the rest, then you're going to come get stuck in some local mode when you update the bit of your model that you're updating.",
                    "label": 0
                },
                {
                    "sent": "So the last little thing that I'd like to say is the warning is basically to avoid bloatware, right I guess.",
                    "label": 0
                },
                {
                    "sent": "And I remember back in the 80s and 90s you always have two more like the 90s.",
                    "label": 0
                },
                {
                    "sent": "I guess every few years you always have to update your computer because Microsoft Windows would become.",
                    "label": 0
                },
                {
                    "sent": "It cover it.",
                    "label": 0
                },
                {
                    "sent": "Takes more and more computation just to do the same thing, and you can upgrade to the next version of Windows without having to buy a new hardware.",
                    "label": 0
                },
                {
                    "sent": "And I think that this is true for basic nonparametric models as well, I think.",
                    "label": 0
                },
                {
                    "sent": "I guess when I first learned about based nonprofit models is a bit like a kid getting a brand new Lego set from my parents and I'm like, yeah, I can build really big models and solve all the problems in the world and they're like so fun, but.",
                    "label": 0
                },
                {
                    "sent": "The problem is, you know we can.",
                    "label": 0
                },
                {
                    "sent": "It's very easy in basin Nonparametrics to build big complicated models, but maybe it's not that easy to build models that are slim and kind of like this.",
                    "label": 0
                },
                {
                    "sent": "Exactly what you wanted to do.",
                    "label": 0
                },
                {
                    "sent": "And I think that you know we need to have better understanding of this, models more math or maybe just more intuition about how these models work, but I think it's very important in terms of applications of these models to avoid bloated models.",
                    "label": 0
                },
                {
                    "sent": "Basically, yeah, thanks.",
                    "label": 0
                }
            ]
        }
    }
}