{
    "id": "ynhjkrfjswkmbl6u4yvbkwdkflloz6yn",
    "title": "Extracting Meta Statements from the Blogosphere",
    "info": {
        "author": [
            "Filipe Mesquita, Department of Computing Science, University of Alberta"
        ],
        "published": "Aug. 18, 2011",
        "recorded": "July 2011",
        "category": [
            "Top->Computer Science->Web Mining"
        ]
    },
    "url": "http://videolectures.net/icwsm2011_mesquita_blogosphere/",
    "segmentation": [
        [
            "Good afternoon.",
            "This work was was done with my supervisor.",
            "The new Super Bowls are.",
            "And the work is on extracting marriage statements and we're going to explain what marriage statements are.",
            "From blog posts."
        ],
        [
            "So the blogosphere has seen a great increase on the number of blog posts published every hour.",
            "The less starts we have from spinner, which is a crawler for the blogosphere.",
            "Is that there?",
            "Indexing over 1,000,000 parts an hour and.",
            "These adds up to 1 billion parts every 45 days.",
            "One deck, their goal.",
            "This was the size of the whole web, right?",
            "And then as a consequence, users have to cope with the information.",
            "Overload problem which is.",
            "People expect you to baking forma decisions about all the data that's available.",
            "Even though you cannot read everything, so we need new ways to summarize what this story is or what information that's conveyed on the blogosphere."
        ],
        [
            "One way to do this is through information networks, and we've been studying how to extract information networks.",
            "For natural language text, this is actually a. I formation network we extract from the logs up on the blog data set from this conference and in this network we have nodes that are entities.",
            "Such as people.",
            "Organizations are location.",
            "You also have relations between these entities.",
            "We have different colors and shapes for different types of entities and we have different thickness according to how often our relation is cited on the blogosphere."
        ],
        [
            "Information networks are great, but of course there are shortcomings and.",
            "One The thing is, they can only represent direct statements and by statement I mean.",
            "A relation between two entities.",
            "So into one relation Entity 2.",
            "So we have for example that Russia has or is in conflict with Georgia, and this is real data from the.",
            "I see that I see that was Sam Block data set.",
            "What information networks cannot represent are more subtle relations or more subtle statements such as that the sociative press.",
            "Reported on this conflict.",
            "There is no direct connection between AP and Russia, neither between AP and Georgia.",
            "We have what we have is the social pressures talking about the conflict and the conflict here is actually a statement.",
            "So one wage represent these relation between Associated Press."
        ],
        [
            "The conflict is is through marriage statements.",
            "Also known as verification in a knowledge representation community.",
            "So many statements are statements about other statements are statements.",
            "The container the statement.",
            "So for example, if I want to say Associated Press reported the conflict we have.",
            "AP is a node and you have the conflict, which is a statement as a node as well."
        ],
        [
            "So we extend.",
            "The traditional information network and we call these are ified information network where nodes can be either entities.",
            "Or statements.",
            "Um?",
            "And we believe this provider even richer more useful network where you can find what's the context for the conflict, for example, so you know where the conflict was happening and when he started.",
            "When it ends, you can have what were the consequences of the conflict.",
            "So for example, the United States was going to punish most call because of the conflict, and you can have.",
            "Several different information associated, not only two entities, but also two statements."
        ],
        [
            "So in summary, our problem is, given a collection of natural language tags, found the blogosphere, how can you produce these reefside information networks?"
        ],
        [
            "Um?",
            "Our little work on relation extraction basically falls into categories.",
            "The first one is traditional or close.",
            "Relation extraction where?",
            "We are looking for one relation only we provide.",
            "Relation specific training for this relation, and if you want to scale the number of relations we can extract.",
            "This is the cost of doing this.",
            "It is linear on the number of relations.",
            "This, of course, is infeasible for us because we want to extract all relations that you can find on the blogosphere.",
            "To construct these networks.",
            "So we follow the second paradigm and the newer paradigm, which is the open relation extraction when you're not looking for one specific relation, but for any relation that the corpse may give you.",
            "And we are not required to provide specific relation specific training.",
            "And therefore your cost to extract more and more relations is constant.",
            "Do not do not depend on the number of relations in this state of the art in this paradigm is a text runner.",
            "In particular, the method based on CRF, but they use is called all CRF of open SRF.",
            "And this method.",
            "It's proposed to do to extract direct statements.",
            "Our work on like.",
            "Text runner extracts both the direct in the marriage statements everything before.",
            "And believe that this is the first."
        ],
        [
            "To do this?",
            "So of course we do some preprocessing.",
            "We get a text out of the blog post.",
            "We speech the text sentences.",
            "We find entities on those sentences.",
            "And we also find entities that actually refer to the same real world entity.",
            "For example, Russia in Russian Federation are the same thing, so we consider that."
        ],
        [
            "And those playing.",
            "Now how old CRF works in how we extend all CRF to extract meta statements.",
            "The model text Mary statement.",
            "So CFCS?",
            "Relation extraction at the frequency labeling problem when you have.",
            "A sequence of tokens, in particular the tokens there are in between the two entities.",
            "So for example we have Russia.",
            "In Georgia there are two entries there in a sentence and it talks in between Georgia is definitely in conflict with.",
            "I.",
            "This sequence of tokens are then labeled.",
            "As either relational tokens to talk is that describe a relation between this pair or non relational talks, talks that do not belong to the relation of between these two pairs.",
            "So for example we have the East definitely in in red are non relational tokens and conflict wealth in blue.",
            "Our relation to continuing to use these color scheme for the rest of the presentation.",
            "Read for non relation.",
            "Blue correlation.",
            "Once, once you have the relation extracted from The Chew.",
            "In between the two entities, we can then create these statements.",
            "And block them in a net."
        ],
        [
            "So conditional random fields.",
            "Is the method.",
            "The Sheriff is based on.",
            "These are graphical model.",
            "That, given a sequence of tokens X.",
            "Will produce a sequence of labels, why?",
            "And the sequence of labels Y is such that maximum maximize a conditional probability.",
            "PY given X.",
            "In this probability, distribution is learned from tokens and labels.",
            "There are provide provided by user so someone have to manually tag some tokens so that the CRF model can predict these probabilities.",
            "The features used Bio CRF are basically talking, but not all tokens, just tokens in closed classes such as prepositions in the terminus.",
            "Um?",
            "They claim that they are trying to figure out what's the structure of the sentence.",
            "So how people say relations in English, not what relation the exchange.",
            "So if you use functional words like verbs announce, you're basically.",
            "Find the specific relations they are looking more for the for the structure of this sentence and they also rely rather heavily on part of speech.",
            "Uh."
        ],
        [
            "Our approach then extends this idea.",
            "By not only extracting relation between entities, but also extract between.",
            "Entity in a statement or between two statements.",
            "So for example, you have the sentence that Associated Press reported Russia's conflict with Georgia.",
            "The first steps on the system is the first step in the system is strict structure relations between entities.",
            "So for example, start relations between Russia.",
            "In Georgia.",
            "And once there sucker statement, you can create another new argument.",
            "Which is the statement Russia's conflict with Georgia and this argument?",
            "Can be used with other entities or all these statements to create meta statements.",
            "So.",
            "Once we have a point where you're comparing, the talk is between.",
            "Associated Press in this statement, Russia's conflict with Georgia.",
            "We can then define.",
            "There's a statement there's the marriage statement here, and this becomes a marriage statement on the network."
        ],
        [
            "The network.",
            "One of our most important findings is that part of speech alone.",
            "Is actually not enough to extract these marriage statements, and I'm going to show this with one example.",
            "Which she.",
            "We have the same error statement as before that are so Sheated Press reported the conflict.",
            "And in the same sentence we have another two pairs of entities.",
            "Associated Press in Russia.",
            "Such that they have the same word, or the same token in between them.",
            "But in the first case, the word reported is a relational term.",
            "You do the word reported.",
            "Do have a relation.",
            "Between Associated Press in the conflict, but in the second.",
            "Example, there is no statement there, so that the word reported should be classified as a non relational token.",
            "In summary, what the problem here is?",
            "You have the same features.",
            "Four reported in both cases.",
            "But different labels?",
            "And.",
            "No more.",
            "They're going to going to give this the model.",
            "We're going to either give you both.",
            "Both are relational or both and non relational.",
            "So this shows the lack of.",
            "Information that the part of speech tags give you.",
            "And when you learn this with both CRF, what you're basically doing is you're confusing the model.",
            "Because we're giving giving the same features and then two different labels.",
            "And the solution find for this.",
            "Um?",
            "What's useful parser and I'm going to show what how?"
        ],
        [
            "Um?",
            "So we use a pass three independency tree in a such way.",
            "We look at the path in between the token, in this case reported.",
            "In the argument, for example Russia.",
            "See that the this path in red.",
            "There is the size of four.",
            "And.",
            "And the other hand, if you look at this, the best path length between reported in the conflict, which is represented by the Now phase four.",
            "You have only two nodes.",
            "The path length is just true, so our observation was.",
            "The shorter, the shorter the path.",
            "More likely, this word is a relational word.",
            "And.",
            "And this this is true.",
            "We're going to show this.",
            "We also use the argument type, so instead of just saying we have two arguments in the end of the.",
            "The sequence of tokens we say we have a special feature saying whether the argument is identity or a statement, and these additional feature."
        ],
        [
            "R. What our method uses.",
            "So for the experiment, we collect 100 sentences.",
            "From the blog data set.",
            "From these hundred sentences we find 5.",
            "Hundreds of bears, roughly their user XX examples.",
            "So from this 500 to have.",
            "For example, 100 that our marriage statements another hundred.",
            "There are direct statements and about 300 that there is no statements in between them.",
            "And we manually label those tokens.",
            "For the experiments, another thing is worth noting is.",
            "About 70% of the tokens are non relational and only 3% of relational tokens."
        ],
        [
            "So our baseline is all CRF.",
            "Will show it off.",
            "In this case is trained using only tokens in part of speech in our method or our system CRF.",
            "Use all the features included.",
            "The past three.",
            "The dependency tree in the types of documents and the metric use we use.",
            "It's accuracy.",
            "On the token level, so we have the number of tokens we find the correct label over the total number of tokens we've done 10 fold cross validation.",
            "We train on 90% of the.",
            "The examples in testing 10%.",
            "We have 10 rounds and we get there."
        ],
        [
            "Average under 10 rounds.",
            "Um?",
            "So the 1st result I want to show.",
            "Is there two to see?",
            "For individual features we add into the model we see that the video features do improve the accuracy, but the combinations is the one who performs the best.",
            "Which is a desirable property."
        ],
        [
            "And.",
            "And as we would expect, we're outperformed.",
            "All CRF on marriage statements, so this graph gives you the accuracy for different types of statements.",
            "In marriage statements we almost triple.",
            "The accuracy.",
            "As in direct statements for our surprise, we also have a great improve improvement, even though we are.",
            "Focus on on marriage statements.",
            "We have we almost doubled our policy for the tax statement.",
            "We do have the small decrease on on no statement on pairs that don't have any statement.",
            "And because non relational terms are more frequent.",
            "We have overall 20% of.",
            "Improvement."
        ],
        [
            "So basically in conclusion, we.",
            "We've seen that many statements allow for richer, more useful networks.",
            "Their part of speech is not enough for extracting many statements.",
            "But the full parsley helps, and we have shown one way to do this.",
            "Um?",
            "Our method have shown great improvement overall, CRF with doubled accuracy, for direct statements with triple accuracy formatted statements.",
            "And our results indicate that.",
            "A method is aware of many statements may perform better in direct statements, and this is actually feature feature work for us too.",
            "Do you have more experience on this?"
        ],
        [
            "So we also working on collecting statistics automatic statements, how, how often we see many statements on the blogosphere.",
            "Should should we care?",
            "Overstacking medicines?",
            "We think so.",
            "But we should back up these numbers.",
            "We want to also do reduce the 4th to produce training examples.",
            "Next one has one method to provide.",
            "A training example automatically automatically.",
            "We could look into how to adapt these to our model, and we also looking at.",
            "All the features we can extract from full parsing to improve the accuracy.",
            "And you ought to be.",
            "To scale better.",
            "Replace the heavyweight full parsing by a shallow parsing."
        ],
        [
            "And that's it.",
            "Thank you.",
            "I'll start it off so.",
            "You know you made the claim that you made the claim that you know relational tokens have shorter path.",
            "Link was that.",
            "Was that an outcome or was that an intuition?",
            "Well, that intuition and other papers have also observed this.",
            "So we have.",
            "Citations on the on the on the paper, and but what the different way to do?",
            "What would find differently was how to use this information on open.",
            "Relation extraction was not straightforward.",
            "You know, I was also curious about the full parsing part, so.",
            "You mentioned shallow parsing.",
            "Do you think you can get away with even less than shallow parsing?",
            "So you would want the most minimal thing possible.",
            "I'm just curious what your thoughts on the features are.",
            "Yeah, this is the.",
            "The biggest problem here is that with full parsing you have a syntactic structure of the sentence, so you basically.",
            "Can observe.",
            "Which which tokens are related structurally if.",
            "As far as you go far from it, it's hard to take these observation into account, but it's definitely in terms of scale.",
            "If you could use less formation, still get good results would be great.",
            "Did you consider using frames or resources like Framenet to Individuate?",
            "Because metal statement usually refers to precise frames like those indicating beliefs or assertion Anson, no, we haven't.",
            "We haven't looked into that.",
            "I would like to hear about it.",
            "I actually don't know frames."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Good afternoon.",
                    "label": 0
                },
                {
                    "sent": "This work was was done with my supervisor.",
                    "label": 0
                },
                {
                    "sent": "The new Super Bowls are.",
                    "label": 0
                },
                {
                    "sent": "And the work is on extracting marriage statements and we're going to explain what marriage statements are.",
                    "label": 0
                },
                {
                    "sent": "From blog posts.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the blogosphere has seen a great increase on the number of blog posts published every hour.",
                    "label": 0
                },
                {
                    "sent": "The less starts we have from spinner, which is a crawler for the blogosphere.",
                    "label": 1
                },
                {
                    "sent": "Is that there?",
                    "label": 0
                },
                {
                    "sent": "Indexing over 1,000,000 parts an hour and.",
                    "label": 0
                },
                {
                    "sent": "These adds up to 1 billion parts every 45 days.",
                    "label": 1
                },
                {
                    "sent": "One deck, their goal.",
                    "label": 0
                },
                {
                    "sent": "This was the size of the whole web, right?",
                    "label": 0
                },
                {
                    "sent": "And then as a consequence, users have to cope with the information.",
                    "label": 1
                },
                {
                    "sent": "Overload problem which is.",
                    "label": 0
                },
                {
                    "sent": "People expect you to baking forma decisions about all the data that's available.",
                    "label": 0
                },
                {
                    "sent": "Even though you cannot read everything, so we need new ways to summarize what this story is or what information that's conveyed on the blogosphere.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "One way to do this is through information networks, and we've been studying how to extract information networks.",
                    "label": 1
                },
                {
                    "sent": "For natural language text, this is actually a. I formation network we extract from the logs up on the blog data set from this conference and in this network we have nodes that are entities.",
                    "label": 1
                },
                {
                    "sent": "Such as people.",
                    "label": 0
                },
                {
                    "sent": "Organizations are location.",
                    "label": 0
                },
                {
                    "sent": "You also have relations between these entities.",
                    "label": 0
                },
                {
                    "sent": "We have different colors and shapes for different types of entities and we have different thickness according to how often our relation is cited on the blogosphere.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Information networks are great, but of course there are shortcomings and.",
                    "label": 0
                },
                {
                    "sent": "One The thing is, they can only represent direct statements and by statement I mean.",
                    "label": 0
                },
                {
                    "sent": "A relation between two entities.",
                    "label": 0
                },
                {
                    "sent": "So into one relation Entity 2.",
                    "label": 0
                },
                {
                    "sent": "So we have for example that Russia has or is in conflict with Georgia, and this is real data from the.",
                    "label": 1
                },
                {
                    "sent": "I see that I see that was Sam Block data set.",
                    "label": 0
                },
                {
                    "sent": "What information networks cannot represent are more subtle relations or more subtle statements such as that the sociative press.",
                    "label": 1
                },
                {
                    "sent": "Reported on this conflict.",
                    "label": 0
                },
                {
                    "sent": "There is no direct connection between AP and Russia, neither between AP and Georgia.",
                    "label": 0
                },
                {
                    "sent": "We have what we have is the social pressures talking about the conflict and the conflict here is actually a statement.",
                    "label": 0
                },
                {
                    "sent": "So one wage represent these relation between Associated Press.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The conflict is is through marriage statements.",
                    "label": 0
                },
                {
                    "sent": "Also known as verification in a knowledge representation community.",
                    "label": 1
                },
                {
                    "sent": "So many statements are statements about other statements are statements.",
                    "label": 0
                },
                {
                    "sent": "The container the statement.",
                    "label": 0
                },
                {
                    "sent": "So for example, if I want to say Associated Press reported the conflict we have.",
                    "label": 0
                },
                {
                    "sent": "AP is a node and you have the conflict, which is a statement as a node as well.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we extend.",
                    "label": 0
                },
                {
                    "sent": "The traditional information network and we call these are ified information network where nodes can be either entities.",
                    "label": 1
                },
                {
                    "sent": "Or statements.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 1
                },
                {
                    "sent": "And we believe this provider even richer more useful network where you can find what's the context for the conflict, for example, so you know where the conflict was happening and when he started.",
                    "label": 0
                },
                {
                    "sent": "When it ends, you can have what were the consequences of the conflict.",
                    "label": 0
                },
                {
                    "sent": "So for example, the United States was going to punish most call because of the conflict, and you can have.",
                    "label": 0
                },
                {
                    "sent": "Several different information associated, not only two entities, but also two statements.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in summary, our problem is, given a collection of natural language tags, found the blogosphere, how can you produce these reefside information networks?",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Our little work on relation extraction basically falls into categories.",
                    "label": 0
                },
                {
                    "sent": "The first one is traditional or close.",
                    "label": 0
                },
                {
                    "sent": "Relation extraction where?",
                    "label": 0
                },
                {
                    "sent": "We are looking for one relation only we provide.",
                    "label": 0
                },
                {
                    "sent": "Relation specific training for this relation, and if you want to scale the number of relations we can extract.",
                    "label": 0
                },
                {
                    "sent": "This is the cost of doing this.",
                    "label": 0
                },
                {
                    "sent": "It is linear on the number of relations.",
                    "label": 1
                },
                {
                    "sent": "This, of course, is infeasible for us because we want to extract all relations that you can find on the blogosphere.",
                    "label": 0
                },
                {
                    "sent": "To construct these networks.",
                    "label": 0
                },
                {
                    "sent": "So we follow the second paradigm and the newer paradigm, which is the open relation extraction when you're not looking for one specific relation, but for any relation that the corpse may give you.",
                    "label": 0
                },
                {
                    "sent": "And we are not required to provide specific relation specific training.",
                    "label": 0
                },
                {
                    "sent": "And therefore your cost to extract more and more relations is constant.",
                    "label": 0
                },
                {
                    "sent": "Do not do not depend on the number of relations in this state of the art in this paradigm is a text runner.",
                    "label": 0
                },
                {
                    "sent": "In particular, the method based on CRF, but they use is called all CRF of open SRF.",
                    "label": 0
                },
                {
                    "sent": "And this method.",
                    "label": 1
                },
                {
                    "sent": "It's proposed to do to extract direct statements.",
                    "label": 0
                },
                {
                    "sent": "Our work on like.",
                    "label": 0
                },
                {
                    "sent": "Text runner extracts both the direct in the marriage statements everything before.",
                    "label": 1
                },
                {
                    "sent": "And believe that this is the first.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To do this?",
                    "label": 0
                },
                {
                    "sent": "So of course we do some preprocessing.",
                    "label": 0
                },
                {
                    "sent": "We get a text out of the blog post.",
                    "label": 0
                },
                {
                    "sent": "We speech the text sentences.",
                    "label": 0
                },
                {
                    "sent": "We find entities on those sentences.",
                    "label": 0
                },
                {
                    "sent": "And we also find entities that actually refer to the same real world entity.",
                    "label": 0
                },
                {
                    "sent": "For example, Russia in Russian Federation are the same thing, so we consider that.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And those playing.",
                    "label": 0
                },
                {
                    "sent": "Now how old CRF works in how we extend all CRF to extract meta statements.",
                    "label": 0
                },
                {
                    "sent": "The model text Mary statement.",
                    "label": 0
                },
                {
                    "sent": "So CFCS?",
                    "label": 0
                },
                {
                    "sent": "Relation extraction at the frequency labeling problem when you have.",
                    "label": 0
                },
                {
                    "sent": "A sequence of tokens, in particular the tokens there are in between the two entities.",
                    "label": 1
                },
                {
                    "sent": "So for example we have Russia.",
                    "label": 0
                },
                {
                    "sent": "In Georgia there are two entries there in a sentence and it talks in between Georgia is definitely in conflict with.",
                    "label": 1
                },
                {
                    "sent": "I.",
                    "label": 0
                },
                {
                    "sent": "This sequence of tokens are then labeled.",
                    "label": 0
                },
                {
                    "sent": "As either relational tokens to talk is that describe a relation between this pair or non relational talks, talks that do not belong to the relation of between these two pairs.",
                    "label": 0
                },
                {
                    "sent": "So for example we have the East definitely in in red are non relational tokens and conflict wealth in blue.",
                    "label": 0
                },
                {
                    "sent": "Our relation to continuing to use these color scheme for the rest of the presentation.",
                    "label": 0
                },
                {
                    "sent": "Read for non relation.",
                    "label": 0
                },
                {
                    "sent": "Blue correlation.",
                    "label": 0
                },
                {
                    "sent": "Once, once you have the relation extracted from The Chew.",
                    "label": 0
                },
                {
                    "sent": "In between the two entities, we can then create these statements.",
                    "label": 0
                },
                {
                    "sent": "And block them in a net.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So conditional random fields.",
                    "label": 0
                },
                {
                    "sent": "Is the method.",
                    "label": 0
                },
                {
                    "sent": "The Sheriff is based on.",
                    "label": 0
                },
                {
                    "sent": "These are graphical model.",
                    "label": 0
                },
                {
                    "sent": "That, given a sequence of tokens X.",
                    "label": 1
                },
                {
                    "sent": "Will produce a sequence of labels, why?",
                    "label": 0
                },
                {
                    "sent": "And the sequence of labels Y is such that maximum maximize a conditional probability.",
                    "label": 1
                },
                {
                    "sent": "PY given X.",
                    "label": 0
                },
                {
                    "sent": "In this probability, distribution is learned from tokens and labels.",
                    "label": 0
                },
                {
                    "sent": "There are provide provided by user so someone have to manually tag some tokens so that the CRF model can predict these probabilities.",
                    "label": 0
                },
                {
                    "sent": "The features used Bio CRF are basically talking, but not all tokens, just tokens in closed classes such as prepositions in the terminus.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "They claim that they are trying to figure out what's the structure of the sentence.",
                    "label": 0
                },
                {
                    "sent": "So how people say relations in English, not what relation the exchange.",
                    "label": 0
                },
                {
                    "sent": "So if you use functional words like verbs announce, you're basically.",
                    "label": 0
                },
                {
                    "sent": "Find the specific relations they are looking more for the for the structure of this sentence and they also rely rather heavily on part of speech.",
                    "label": 0
                },
                {
                    "sent": "Uh.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our approach then extends this idea.",
                    "label": 0
                },
                {
                    "sent": "By not only extracting relation between entities, but also extract between.",
                    "label": 0
                },
                {
                    "sent": "Entity in a statement or between two statements.",
                    "label": 0
                },
                {
                    "sent": "So for example, you have the sentence that Associated Press reported Russia's conflict with Georgia.",
                    "label": 1
                },
                {
                    "sent": "The first steps on the system is the first step in the system is strict structure relations between entities.",
                    "label": 0
                },
                {
                    "sent": "So for example, start relations between Russia.",
                    "label": 0
                },
                {
                    "sent": "In Georgia.",
                    "label": 0
                },
                {
                    "sent": "And once there sucker statement, you can create another new argument.",
                    "label": 0
                },
                {
                    "sent": "Which is the statement Russia's conflict with Georgia and this argument?",
                    "label": 0
                },
                {
                    "sent": "Can be used with other entities or all these statements to create meta statements.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Once we have a point where you're comparing, the talk is between.",
                    "label": 0
                },
                {
                    "sent": "Associated Press in this statement, Russia's conflict with Georgia.",
                    "label": 0
                },
                {
                    "sent": "We can then define.",
                    "label": 0
                },
                {
                    "sent": "There's a statement there's the marriage statement here, and this becomes a marriage statement on the network.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The network.",
                    "label": 0
                },
                {
                    "sent": "One of our most important findings is that part of speech alone.",
                    "label": 0
                },
                {
                    "sent": "Is actually not enough to extract these marriage statements, and I'm going to show this with one example.",
                    "label": 0
                },
                {
                    "sent": "Which she.",
                    "label": 0
                },
                {
                    "sent": "We have the same error statement as before that are so Sheated Press reported the conflict.",
                    "label": 0
                },
                {
                    "sent": "And in the same sentence we have another two pairs of entities.",
                    "label": 0
                },
                {
                    "sent": "Associated Press in Russia.",
                    "label": 0
                },
                {
                    "sent": "Such that they have the same word, or the same token in between them.",
                    "label": 0
                },
                {
                    "sent": "But in the first case, the word reported is a relational term.",
                    "label": 0
                },
                {
                    "sent": "You do the word reported.",
                    "label": 0
                },
                {
                    "sent": "Do have a relation.",
                    "label": 0
                },
                {
                    "sent": "Between Associated Press in the conflict, but in the second.",
                    "label": 0
                },
                {
                    "sent": "Example, there is no statement there, so that the word reported should be classified as a non relational token.",
                    "label": 0
                },
                {
                    "sent": "In summary, what the problem here is?",
                    "label": 0
                },
                {
                    "sent": "You have the same features.",
                    "label": 0
                },
                {
                    "sent": "Four reported in both cases.",
                    "label": 0
                },
                {
                    "sent": "But different labels?",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "No more.",
                    "label": 0
                },
                {
                    "sent": "They're going to going to give this the model.",
                    "label": 1
                },
                {
                    "sent": "We're going to either give you both.",
                    "label": 0
                },
                {
                    "sent": "Both are relational or both and non relational.",
                    "label": 0
                },
                {
                    "sent": "So this shows the lack of.",
                    "label": 0
                },
                {
                    "sent": "Information that the part of speech tags give you.",
                    "label": 1
                },
                {
                    "sent": "And when you learn this with both CRF, what you're basically doing is you're confusing the model.",
                    "label": 0
                },
                {
                    "sent": "Because we're giving giving the same features and then two different labels.",
                    "label": 1
                },
                {
                    "sent": "And the solution find for this.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "What's useful parser and I'm going to show what how?",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So we use a pass three independency tree in a such way.",
                    "label": 0
                },
                {
                    "sent": "We look at the path in between the token, in this case reported.",
                    "label": 0
                },
                {
                    "sent": "In the argument, for example Russia.",
                    "label": 0
                },
                {
                    "sent": "See that the this path in red.",
                    "label": 0
                },
                {
                    "sent": "There is the size of four.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "And the other hand, if you look at this, the best path length between reported in the conflict, which is represented by the Now phase four.",
                    "label": 1
                },
                {
                    "sent": "You have only two nodes.",
                    "label": 0
                },
                {
                    "sent": "The path length is just true, so our observation was.",
                    "label": 0
                },
                {
                    "sent": "The shorter, the shorter the path.",
                    "label": 0
                },
                {
                    "sent": "More likely, this word is a relational word.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "And this this is true.",
                    "label": 0
                },
                {
                    "sent": "We're going to show this.",
                    "label": 0
                },
                {
                    "sent": "We also use the argument type, so instead of just saying we have two arguments in the end of the.",
                    "label": 1
                },
                {
                    "sent": "The sequence of tokens we say we have a special feature saying whether the argument is identity or a statement, and these additional feature.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "R. What our method uses.",
                    "label": 0
                },
                {
                    "sent": "So for the experiment, we collect 100 sentences.",
                    "label": 1
                },
                {
                    "sent": "From the blog data set.",
                    "label": 0
                },
                {
                    "sent": "From these hundred sentences we find 5.",
                    "label": 0
                },
                {
                    "sent": "Hundreds of bears, roughly their user XX examples.",
                    "label": 0
                },
                {
                    "sent": "So from this 500 to have.",
                    "label": 0
                },
                {
                    "sent": "For example, 100 that our marriage statements another hundred.",
                    "label": 0
                },
                {
                    "sent": "There are direct statements and about 300 that there is no statements in between them.",
                    "label": 0
                },
                {
                    "sent": "And we manually label those tokens.",
                    "label": 0
                },
                {
                    "sent": "For the experiments, another thing is worth noting is.",
                    "label": 0
                },
                {
                    "sent": "About 70% of the tokens are non relational and only 3% of relational tokens.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So our baseline is all CRF.",
                    "label": 0
                },
                {
                    "sent": "Will show it off.",
                    "label": 0
                },
                {
                    "sent": "In this case is trained using only tokens in part of speech in our method or our system CRF.",
                    "label": 1
                },
                {
                    "sent": "Use all the features included.",
                    "label": 0
                },
                {
                    "sent": "The past three.",
                    "label": 0
                },
                {
                    "sent": "The dependency tree in the types of documents and the metric use we use.",
                    "label": 0
                },
                {
                    "sent": "It's accuracy.",
                    "label": 1
                },
                {
                    "sent": "On the token level, so we have the number of tokens we find the correct label over the total number of tokens we've done 10 fold cross validation.",
                    "label": 0
                },
                {
                    "sent": "We train on 90% of the.",
                    "label": 0
                },
                {
                    "sent": "The examples in testing 10%.",
                    "label": 0
                },
                {
                    "sent": "We have 10 rounds and we get there.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Average under 10 rounds.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So the 1st result I want to show.",
                    "label": 0
                },
                {
                    "sent": "Is there two to see?",
                    "label": 0
                },
                {
                    "sent": "For individual features we add into the model we see that the video features do improve the accuracy, but the combinations is the one who performs the best.",
                    "label": 0
                },
                {
                    "sent": "Which is a desirable property.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "And as we would expect, we're outperformed.",
                    "label": 0
                },
                {
                    "sent": "All CRF on marriage statements, so this graph gives you the accuracy for different types of statements.",
                    "label": 1
                },
                {
                    "sent": "In marriage statements we almost triple.",
                    "label": 0
                },
                {
                    "sent": "The accuracy.",
                    "label": 1
                },
                {
                    "sent": "As in direct statements for our surprise, we also have a great improve improvement, even though we are.",
                    "label": 0
                },
                {
                    "sent": "Focus on on marriage statements.",
                    "label": 0
                },
                {
                    "sent": "We have we almost doubled our policy for the tax statement.",
                    "label": 0
                },
                {
                    "sent": "We do have the small decrease on on no statement on pairs that don't have any statement.",
                    "label": 0
                },
                {
                    "sent": "And because non relational terms are more frequent.",
                    "label": 0
                },
                {
                    "sent": "We have overall 20% of.",
                    "label": 0
                },
                {
                    "sent": "Improvement.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So basically in conclusion, we.",
                    "label": 0
                },
                {
                    "sent": "We've seen that many statements allow for richer, more useful networks.",
                    "label": 1
                },
                {
                    "sent": "Their part of speech is not enough for extracting many statements.",
                    "label": 0
                },
                {
                    "sent": "But the full parsley helps, and we have shown one way to do this.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 1
                },
                {
                    "sent": "Our method have shown great improvement overall, CRF with doubled accuracy, for direct statements with triple accuracy formatted statements.",
                    "label": 1
                },
                {
                    "sent": "And our results indicate that.",
                    "label": 0
                },
                {
                    "sent": "A method is aware of many statements may perform better in direct statements, and this is actually feature feature work for us too.",
                    "label": 0
                },
                {
                    "sent": "Do you have more experience on this?",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we also working on collecting statistics automatic statements, how, how often we see many statements on the blogosphere.",
                    "label": 0
                },
                {
                    "sent": "Should should we care?",
                    "label": 0
                },
                {
                    "sent": "Overstacking medicines?",
                    "label": 0
                },
                {
                    "sent": "We think so.",
                    "label": 0
                },
                {
                    "sent": "But we should back up these numbers.",
                    "label": 0
                },
                {
                    "sent": "We want to also do reduce the 4th to produce training examples.",
                    "label": 1
                },
                {
                    "sent": "Next one has one method to provide.",
                    "label": 0
                },
                {
                    "sent": "A training example automatically automatically.",
                    "label": 0
                },
                {
                    "sent": "We could look into how to adapt these to our model, and we also looking at.",
                    "label": 1
                },
                {
                    "sent": "All the features we can extract from full parsing to improve the accuracy.",
                    "label": 0
                },
                {
                    "sent": "And you ought to be.",
                    "label": 0
                },
                {
                    "sent": "To scale better.",
                    "label": 0
                },
                {
                    "sent": "Replace the heavyweight full parsing by a shallow parsing.",
                    "label": 1
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And that's it.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "I'll start it off so.",
                    "label": 0
                },
                {
                    "sent": "You know you made the claim that you made the claim that you know relational tokens have shorter path.",
                    "label": 0
                },
                {
                    "sent": "Link was that.",
                    "label": 0
                },
                {
                    "sent": "Was that an outcome or was that an intuition?",
                    "label": 0
                },
                {
                    "sent": "Well, that intuition and other papers have also observed this.",
                    "label": 0
                },
                {
                    "sent": "So we have.",
                    "label": 0
                },
                {
                    "sent": "Citations on the on the on the paper, and but what the different way to do?",
                    "label": 0
                },
                {
                    "sent": "What would find differently was how to use this information on open.",
                    "label": 0
                },
                {
                    "sent": "Relation extraction was not straightforward.",
                    "label": 0
                },
                {
                    "sent": "You know, I was also curious about the full parsing part, so.",
                    "label": 0
                },
                {
                    "sent": "You mentioned shallow parsing.",
                    "label": 0
                },
                {
                    "sent": "Do you think you can get away with even less than shallow parsing?",
                    "label": 0
                },
                {
                    "sent": "So you would want the most minimal thing possible.",
                    "label": 0
                },
                {
                    "sent": "I'm just curious what your thoughts on the features are.",
                    "label": 0
                },
                {
                    "sent": "Yeah, this is the.",
                    "label": 0
                },
                {
                    "sent": "The biggest problem here is that with full parsing you have a syntactic structure of the sentence, so you basically.",
                    "label": 0
                },
                {
                    "sent": "Can observe.",
                    "label": 0
                },
                {
                    "sent": "Which which tokens are related structurally if.",
                    "label": 0
                },
                {
                    "sent": "As far as you go far from it, it's hard to take these observation into account, but it's definitely in terms of scale.",
                    "label": 0
                },
                {
                    "sent": "If you could use less formation, still get good results would be great.",
                    "label": 0
                },
                {
                    "sent": "Did you consider using frames or resources like Framenet to Individuate?",
                    "label": 0
                },
                {
                    "sent": "Because metal statement usually refers to precise frames like those indicating beliefs or assertion Anson, no, we haven't.",
                    "label": 0
                },
                {
                    "sent": "We haven't looked into that.",
                    "label": 0
                },
                {
                    "sent": "I would like to hear about it.",
                    "label": 0
                },
                {
                    "sent": "I actually don't know frames.",
                    "label": 0
                }
            ]
        }
    }
}