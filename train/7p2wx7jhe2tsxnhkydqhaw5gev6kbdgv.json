{
    "id": "7p2wx7jhe2tsxnhkydqhaw5gev6kbdgv",
    "title": "Mining Positive and Negative Patterns for Relevance Feature Discovery",
    "info": {
        "author": [
            "Yuefeng Li, Faculty of Science and Technology, Queensland University of Technology"
        ],
        "published": "Oct. 1, 2010",
        "recorded": "July 2010",
        "category": [
            "Top->Computer Science->Information Retrieval"
        ]
    },
    "url": "http://videolectures.net/kdd2010_li_mpn/",
    "segmentation": [
        [
            "Only we."
        ],
        [
            "Have two kind of definition.",
            "Once topical relevance discuss is a document relevance to a given query.",
            "And the second one is user relevance.",
            "Discuss is documents relevance to a user.",
            "So the objective of relevance feature discovery is funny, useful features available in the training site.",
            "I include both positive and negative documents for describing what users want."
        ],
        [
            "Normally we have a mania term based method.",
            "Especially developed in the information retrieval and such like the.",
            "Rocio algorithm probabilistic models BM.",
            "25 also language models.",
            "So these models are very efficient.",
            "And also a very simple for the computation.",
            "And also some model already used phrases.",
            "In the event remodels.",
            "And the cause of fries are more discriminative and care more semantic than words.",
            "And also some people prove that frees are useful and crucial for query expansion in building good ranking functions.",
            "So are its very important topic for describ relevance information.",
            "And it's very difficult to make a breakthrough for the traditional air models.",
            "Because they they describ the.",
            "Terms distribution in the document and frequencies perfectly.",
            "So for that money we normally use pattern.",
            "So we think about why Titan very important.",
            "Could be a good.",
            "Alternative for turn based method.",
            "So one thing only talk about using."
        ],
        [
            "Freeze.",
            "Under there some important task how to find useful freeze in the text document?",
            "Becauses fries have infer statistical property towards and their large number of redundant and noisy phrase among them.",
            "So the questions we understand sometimes not all.",
            "Contents in the document are relevant, but what kind of information could be relevant?",
            "So we think about the pattern could be a promising alternative or phrase.",
            "There are several reasons we consider using patterns like word height and enjoy good statistical properties and also.",
            "That money had developed some techniques like Maximo.",
            "Patterns closed patterns must patterns for removing redundant and noisy patterns.",
            "So data mining provides strong background for finding useful information in the text document.",
            "But quit."
        ],
        [
            "Can a patent effective for relevant feature discovery?",
            "So for this question we are researching using pattern for the text document since 2004 and in the beginning we use our pattern Taxonomy model PDF.",
            "It used a close sequential pattern.",
            "And also I if directly is pattern.",
            "The performance is worse and then we use the diploid method and show a certain extent improvement and effectiveness compare with the term based models.",
            "So there are two challenges issue for using pattern takes money.",
            "The first one is the law support problem.",
            "Give a topic large patterns of more specific for the topic but with no support.",
            "If we describ decrease the minimum support, there are a lot of noise patterns would be discovered.",
            "That's the first issue.",
            "The second one's misinterpretation problem.",
            "That means the measure used impact money.",
            "For example, support and confidence throughout to be no suitable in using discovered patterns for answer what users were.",
            "For example, a highly frequent pattern.",
            "Is usually a general pattern for topic.",
            "Because can be used by both positive or negative documents."
        ],
        [
            "So in this paper we provide the new solution.",
            "We view features in the document in the two levels low level terms and higher level patterns.",
            "And then we provide a new idea to evaluate width of terms according to both their specificity and their distribution.",
            "In the high level features.",
            "So we use Halo feature.",
            "Include both positive and net."
        ],
        [
            "Patterns.",
            "So before we try to use 2 features, we need to give the method to map Hello feature to the low level terms.",
            "We call the method deploying method.",
            "Which evaluate with of low level terms based on their distribution in high level patterns.",
            "Under this method.",
            "Provide a new idea for interpreting discovered pattern that.",
            "Can be provide a new method for waiting terms.",
            "The difference to the waiting nicer using the IR currently.",
            "And also it provides efficient and effective way for using patterns in solving problems, especially for using larger patterns.",
            "Normally large pattern is rarely occur in the testing document."
        ],
        [
            "So for the deploying we usually talk about first data set of discovered close patterns from.",
            "Many positive document.",
            "And we we we represent the set of discovered close pattern as SP1 to SP N. And then we calculate the support for term in the positive document training site.",
            "And consider.",
            "The pattern includes terms and also the length of pattern."
        ],
        [
            "And also we can understand the Iraqi about pattern use either relation and normally if the top is a short pattern and bottom large ones and at the bottom plate are more specific.",
            "And then we think about give a map between the.",
            "High level patterns and low level term."
        ],
        [
            "And also in the low level features we consider specificity terms with visited describe the extent of term to which the topic focus on what users want.",
            "For example, JDK is more specific than term left.",
            "For Discribing Java programming languages, Becausw lab can be frequently used in both.",
            "Java and C++.",
            "Basically, the specificity of term based on their position in the concept hierarchy.",
            "For example, if we use, else SH, most libraries site structure.",
            "And the.",
            "Give the term in the bottom there most specific, but in many cases.",
            "For him being a terms with 50 is measured based on what topic you were talking about.",
            "For example, North Discovery would be a general term.",
            "In that data mining community.",
            "However, it may be a specific term.",
            "When we talk about information technology in general."
        ],
        [
            "So the concept of relevance is subjective.",
            "And also the safety is subjective.",
            "So it is easy for human being to do so for the defender.",
            "Specificity of documental terms.",
            "However, it is very difficult to use this concept for interpreting relevant.",
            "Features in text document.",
            "In this paper we find this misfit scale given term in the training site.",
            "Consider the coverage of terms in both.",
            "Positive document and negative document.",
            "On the wiki for function code SP to describe the specificity of term."
        ],
        [
            "And based on this definition, now we can give the classification rules for the terms.",
            "In the patents.",
            "So usually we can use three groups.",
            "The first ones generator.",
            "And based on the specific value between C1 and C2 and also the T plus.",
            "The specific positive terms and team manage the specific negative terms.",
            "And in our experiment we give the setting statewide 0.262 zero point 3 and also we have the SP value between one the Men's 0.5."
        ],
        [
            "So when we define this facility, we need both positive and negative.",
            "And usually we think about how to effectively use negative feedback in this paper.",
            "Under the question, when we use painting, the beginning is difficult to consider the negative information.",
            "Because the positive document and the negative document share some background knowledge is and also noises.",
            "So in this case there tour difficult task when use negative relevance feedback.",
            "The first one how to select constructive negative samples to reduce the noisy and space of negative example is well.",
            "Becauses negative documents.",
            "There is very low.",
            "And how do you selected negative sample to refund the current knowledge?",
            "And also another important issue."
        ],
        [
            "So in this time we use the often the document.",
            "To represent the constructive negative samples for the training.",
            "Under use this picture we can check about the offender document.",
            "Are mostly an active document that are mostly likely to be classified as positive.",
            "So there should be a.",
            "We don't do too much."
        ],
        [
            "And also we give the procedure for the select constructive negative.",
            "Examples.",
            "Rewrite the negative example used to extract the low level features.",
            "Account to the term support and select top care document.",
            "And we can not use too much negative one because we try to describe the features for positive document.",
            "And then extract the high level patterns and other features from selecting negative example that use similar methods for money in positive document.",
            "And then."
        ],
        [
            "Give the weighting revision of low level features.",
            "The basic rule here is specific terms are more important.",
            "And therefore we gave more weight.",
            "So for the general one, we keep the support here and for the negative specific term we reduce the weight."
        ],
        [
            "And then we use the.",
            "RC we want to test the proposed method.",
            "Under the data from 1996 to 1997.",
            "And also we used 50 track assessed topics for the fuel filter in track 2002.",
            "And all documents are treated as plan text document by pre processing.",
            "Removing stopwords and using Porter stemming every."
        ],
        [
            "Under the result.",
            "This picture shows the result.",
            "We use several baseline models, Rocio algorithm.",
            "Dinner at the M and BM25 and also Peter.",
            "Home old is called RFD.",
            "So in this figure show.",
            "The model is the best one and the improvement is significant.",
            "For all 50."
        ],
        [
            "Sizing topics we also give some analysis according to the result and 1st the percentage change is obvious.",
            "Very significant.",
            "And also we check about using the.",
            "The number of officers.",
            "Under we believe K equal half of the number of positive document can be a past one.",
            "And also another amazing of funding funding for the this experiment we found we can largely reduce the positive terms.",
            "From the PDF, the PDF and the term average is 156.",
            "If we use the same minimum support.",
            "And PM fund the term from positive document and then we are decided about 23.",
            "Positive specific terms."
        ],
        [
            "And then we are.",
            "I'll give some results for the analysis.",
            "Often this election.",
            "It's obviously a.",
            "Use half is the best one if you use all of the.",
            "Negative document the performance very.",
            "Fat"
        ],
        [
            "And also we show you using the different combination of general term specific term and normally the PTM.",
            "Is here.",
            "And we use the.",
            "Unlike general term, the performance not good.",
            "And if you use only the.",
            "Positive specific term.",
            "Few terms better than the PT.",
            "A little bit.",
            "And use both.",
            "At.",
            "Positive specific term and general term.",
            "Better and then use all three categories is the best one.",
            "I'm."
        ],
        [
            "Also show you this picture show you the.",
            "The change of the terms the weighting change after use the revision and normally if the term have heist specific will get large weight after."
        ],
        [
            "With the revision.",
            "So this paper we compare with the some models.",
            "Under the proposed model is consistent and very significant on all far measures.",
            "About 50 topics.",
            "And also the negative selection approach is satisfactory.",
            "Under the use of negative relevant relevance feedback is very significant for the relevant feature discovery.",
            "Because it can balance the percentage of specific terms and general term to reduce noises."
        ],
        [
            "So these are my talk.",
            "Thank you very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Only we.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Have two kind of definition.",
                    "label": 0
                },
                {
                    "sent": "Once topical relevance discuss is a document relevance to a given query.",
                    "label": 1
                },
                {
                    "sent": "And the second one is user relevance.",
                    "label": 1
                },
                {
                    "sent": "Discuss is documents relevance to a user.",
                    "label": 0
                },
                {
                    "sent": "So the objective of relevance feature discovery is funny, useful features available in the training site.",
                    "label": 1
                },
                {
                    "sent": "I include both positive and negative documents for describing what users want.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Normally we have a mania term based method.",
                    "label": 0
                },
                {
                    "sent": "Especially developed in the information retrieval and such like the.",
                    "label": 0
                },
                {
                    "sent": "Rocio algorithm probabilistic models BM.",
                    "label": 0
                },
                {
                    "sent": "25 also language models.",
                    "label": 0
                },
                {
                    "sent": "So these models are very efficient.",
                    "label": 0
                },
                {
                    "sent": "And also a very simple for the computation.",
                    "label": 0
                },
                {
                    "sent": "And also some model already used phrases.",
                    "label": 0
                },
                {
                    "sent": "In the event remodels.",
                    "label": 0
                },
                {
                    "sent": "And the cause of fries are more discriminative and care more semantic than words.",
                    "label": 0
                },
                {
                    "sent": "And also some people prove that frees are useful and crucial for query expansion in building good ranking functions.",
                    "label": 0
                },
                {
                    "sent": "So are its very important topic for describ relevance information.",
                    "label": 0
                },
                {
                    "sent": "And it's very difficult to make a breakthrough for the traditional air models.",
                    "label": 0
                },
                {
                    "sent": "Because they they describ the.",
                    "label": 0
                },
                {
                    "sent": "Terms distribution in the document and frequencies perfectly.",
                    "label": 0
                },
                {
                    "sent": "So for that money we normally use pattern.",
                    "label": 0
                },
                {
                    "sent": "So we think about why Titan very important.",
                    "label": 0
                },
                {
                    "sent": "Could be a good.",
                    "label": 0
                },
                {
                    "sent": "Alternative for turn based method.",
                    "label": 0
                },
                {
                    "sent": "So one thing only talk about using.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Freeze.",
                    "label": 0
                },
                {
                    "sent": "Under there some important task how to find useful freeze in the text document?",
                    "label": 0
                },
                {
                    "sent": "Becauses fries have infer statistical property towards and their large number of redundant and noisy phrase among them.",
                    "label": 1
                },
                {
                    "sent": "So the questions we understand sometimes not all.",
                    "label": 0
                },
                {
                    "sent": "Contents in the document are relevant, but what kind of information could be relevant?",
                    "label": 0
                },
                {
                    "sent": "So we think about the pattern could be a promising alternative or phrase.",
                    "label": 1
                },
                {
                    "sent": "There are several reasons we consider using patterns like word height and enjoy good statistical properties and also.",
                    "label": 0
                },
                {
                    "sent": "That money had developed some techniques like Maximo.",
                    "label": 0
                },
                {
                    "sent": "Patterns closed patterns must patterns for removing redundant and noisy patterns.",
                    "label": 1
                },
                {
                    "sent": "So data mining provides strong background for finding useful information in the text document.",
                    "label": 0
                },
                {
                    "sent": "But quit.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Can a patent effective for relevant feature discovery?",
                    "label": 0
                },
                {
                    "sent": "So for this question we are researching using pattern for the text document since 2004 and in the beginning we use our pattern Taxonomy model PDF.",
                    "label": 0
                },
                {
                    "sent": "It used a close sequential pattern.",
                    "label": 0
                },
                {
                    "sent": "And also I if directly is pattern.",
                    "label": 0
                },
                {
                    "sent": "The performance is worse and then we use the diploid method and show a certain extent improvement and effectiveness compare with the term based models.",
                    "label": 0
                },
                {
                    "sent": "So there are two challenges issue for using pattern takes money.",
                    "label": 0
                },
                {
                    "sent": "The first one is the law support problem.",
                    "label": 0
                },
                {
                    "sent": "Give a topic large patterns of more specific for the topic but with no support.",
                    "label": 1
                },
                {
                    "sent": "If we describ decrease the minimum support, there are a lot of noise patterns would be discovered.",
                    "label": 1
                },
                {
                    "sent": "That's the first issue.",
                    "label": 0
                },
                {
                    "sent": "The second one's misinterpretation problem.",
                    "label": 1
                },
                {
                    "sent": "That means the measure used impact money.",
                    "label": 1
                },
                {
                    "sent": "For example, support and confidence throughout to be no suitable in using discovered patterns for answer what users were.",
                    "label": 0
                },
                {
                    "sent": "For example, a highly frequent pattern.",
                    "label": 0
                },
                {
                    "sent": "Is usually a general pattern for topic.",
                    "label": 0
                },
                {
                    "sent": "Because can be used by both positive or negative documents.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in this paper we provide the new solution.",
                    "label": 0
                },
                {
                    "sent": "We view features in the document in the two levels low level terms and higher level patterns.",
                    "label": 1
                },
                {
                    "sent": "And then we provide a new idea to evaluate width of terms according to both their specificity and their distribution.",
                    "label": 1
                },
                {
                    "sent": "In the high level features.",
                    "label": 1
                },
                {
                    "sent": "So we use Halo feature.",
                    "label": 0
                },
                {
                    "sent": "Include both positive and net.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Patterns.",
                    "label": 0
                },
                {
                    "sent": "So before we try to use 2 features, we need to give the method to map Hello feature to the low level terms.",
                    "label": 0
                },
                {
                    "sent": "We call the method deploying method.",
                    "label": 0
                },
                {
                    "sent": "Which evaluate with of low level terms based on their distribution in high level patterns.",
                    "label": 0
                },
                {
                    "sent": "Under this method.",
                    "label": 0
                },
                {
                    "sent": "Provide a new idea for interpreting discovered pattern that.",
                    "label": 0
                },
                {
                    "sent": "Can be provide a new method for waiting terms.",
                    "label": 0
                },
                {
                    "sent": "The difference to the waiting nicer using the IR currently.",
                    "label": 0
                },
                {
                    "sent": "And also it provides efficient and effective way for using patterns in solving problems, especially for using larger patterns.",
                    "label": 0
                },
                {
                    "sent": "Normally large pattern is rarely occur in the testing document.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for the deploying we usually talk about first data set of discovered close patterns from.",
                    "label": 0
                },
                {
                    "sent": "Many positive document.",
                    "label": 0
                },
                {
                    "sent": "And we we we represent the set of discovered close pattern as SP1 to SP N. And then we calculate the support for term in the positive document training site.",
                    "label": 0
                },
                {
                    "sent": "And consider.",
                    "label": 0
                },
                {
                    "sent": "The pattern includes terms and also the length of pattern.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And also we can understand the Iraqi about pattern use either relation and normally if the top is a short pattern and bottom large ones and at the bottom plate are more specific.",
                    "label": 0
                },
                {
                    "sent": "And then we think about give a map between the.",
                    "label": 0
                },
                {
                    "sent": "High level patterns and low level term.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And also in the low level features we consider specificity terms with visited describe the extent of term to which the topic focus on what users want.",
                    "label": 1
                },
                {
                    "sent": "For example, JDK is more specific than term left.",
                    "label": 0
                },
                {
                    "sent": "For Discribing Java programming languages, Becausw lab can be frequently used in both.",
                    "label": 0
                },
                {
                    "sent": "Java and C++.",
                    "label": 1
                },
                {
                    "sent": "Basically, the specificity of term based on their position in the concept hierarchy.",
                    "label": 0
                },
                {
                    "sent": "For example, if we use, else SH, most libraries site structure.",
                    "label": 0
                },
                {
                    "sent": "And the.",
                    "label": 0
                },
                {
                    "sent": "Give the term in the bottom there most specific, but in many cases.",
                    "label": 0
                },
                {
                    "sent": "For him being a terms with 50 is measured based on what topic you were talking about.",
                    "label": 0
                },
                {
                    "sent": "For example, North Discovery would be a general term.",
                    "label": 1
                },
                {
                    "sent": "In that data mining community.",
                    "label": 0
                },
                {
                    "sent": "However, it may be a specific term.",
                    "label": 0
                },
                {
                    "sent": "When we talk about information technology in general.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the concept of relevance is subjective.",
                    "label": 1
                },
                {
                    "sent": "And also the safety is subjective.",
                    "label": 0
                },
                {
                    "sent": "So it is easy for human being to do so for the defender.",
                    "label": 1
                },
                {
                    "sent": "Specificity of documental terms.",
                    "label": 1
                },
                {
                    "sent": "However, it is very difficult to use this concept for interpreting relevant.",
                    "label": 0
                },
                {
                    "sent": "Features in text document.",
                    "label": 0
                },
                {
                    "sent": "In this paper we find this misfit scale given term in the training site.",
                    "label": 0
                },
                {
                    "sent": "Consider the coverage of terms in both.",
                    "label": 0
                },
                {
                    "sent": "Positive document and negative document.",
                    "label": 0
                },
                {
                    "sent": "On the wiki for function code SP to describe the specificity of term.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And based on this definition, now we can give the classification rules for the terms.",
                    "label": 0
                },
                {
                    "sent": "In the patents.",
                    "label": 0
                },
                {
                    "sent": "So usually we can use three groups.",
                    "label": 0
                },
                {
                    "sent": "The first ones generator.",
                    "label": 0
                },
                {
                    "sent": "And based on the specific value between C1 and C2 and also the T plus.",
                    "label": 0
                },
                {
                    "sent": "The specific positive terms and team manage the specific negative terms.",
                    "label": 0
                },
                {
                    "sent": "And in our experiment we give the setting statewide 0.262 zero point 3 and also we have the SP value between one the Men's 0.5.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So when we define this facility, we need both positive and negative.",
                    "label": 0
                },
                {
                    "sent": "And usually we think about how to effectively use negative feedback in this paper.",
                    "label": 1
                },
                {
                    "sent": "Under the question, when we use painting, the beginning is difficult to consider the negative information.",
                    "label": 1
                },
                {
                    "sent": "Because the positive document and the negative document share some background knowledge is and also noises.",
                    "label": 0
                },
                {
                    "sent": "So in this case there tour difficult task when use negative relevance feedback.",
                    "label": 0
                },
                {
                    "sent": "The first one how to select constructive negative samples to reduce the noisy and space of negative example is well.",
                    "label": 1
                },
                {
                    "sent": "Becauses negative documents.",
                    "label": 0
                },
                {
                    "sent": "There is very low.",
                    "label": 0
                },
                {
                    "sent": "And how do you selected negative sample to refund the current knowledge?",
                    "label": 0
                },
                {
                    "sent": "And also another important issue.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in this time we use the often the document.",
                    "label": 0
                },
                {
                    "sent": "To represent the constructive negative samples for the training.",
                    "label": 0
                },
                {
                    "sent": "Under use this picture we can check about the offender document.",
                    "label": 0
                },
                {
                    "sent": "Are mostly an active document that are mostly likely to be classified as positive.",
                    "label": 1
                },
                {
                    "sent": "So there should be a.",
                    "label": 0
                },
                {
                    "sent": "We don't do too much.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And also we give the procedure for the select constructive negative.",
                    "label": 1
                },
                {
                    "sent": "Examples.",
                    "label": 1
                },
                {
                    "sent": "Rewrite the negative example used to extract the low level features.",
                    "label": 0
                },
                {
                    "sent": "Account to the term support and select top care document.",
                    "label": 0
                },
                {
                    "sent": "And we can not use too much negative one because we try to describe the features for positive document.",
                    "label": 0
                },
                {
                    "sent": "And then extract the high level patterns and other features from selecting negative example that use similar methods for money in positive document.",
                    "label": 1
                },
                {
                    "sent": "And then.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Give the weighting revision of low level features.",
                    "label": 1
                },
                {
                    "sent": "The basic rule here is specific terms are more important.",
                    "label": 1
                },
                {
                    "sent": "And therefore we gave more weight.",
                    "label": 0
                },
                {
                    "sent": "So for the general one, we keep the support here and for the negative specific term we reduce the weight.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then we use the.",
                    "label": 0
                },
                {
                    "sent": "RC we want to test the proposed method.",
                    "label": 1
                },
                {
                    "sent": "Under the data from 1996 to 1997.",
                    "label": 0
                },
                {
                    "sent": "And also we used 50 track assessed topics for the fuel filter in track 2002.",
                    "label": 1
                },
                {
                    "sent": "And all documents are treated as plan text document by pre processing.",
                    "label": 0
                },
                {
                    "sent": "Removing stopwords and using Porter stemming every.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Under the result.",
                    "label": 0
                },
                {
                    "sent": "This picture shows the result.",
                    "label": 0
                },
                {
                    "sent": "We use several baseline models, Rocio algorithm.",
                    "label": 1
                },
                {
                    "sent": "Dinner at the M and BM25 and also Peter.",
                    "label": 0
                },
                {
                    "sent": "Home old is called RFD.",
                    "label": 0
                },
                {
                    "sent": "So in this figure show.",
                    "label": 0
                },
                {
                    "sent": "The model is the best one and the improvement is significant.",
                    "label": 0
                },
                {
                    "sent": "For all 50.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sizing topics we also give some analysis according to the result and 1st the percentage change is obvious.",
                    "label": 0
                },
                {
                    "sent": "Very significant.",
                    "label": 0
                },
                {
                    "sent": "And also we check about using the.",
                    "label": 0
                },
                {
                    "sent": "The number of officers.",
                    "label": 0
                },
                {
                    "sent": "Under we believe K equal half of the number of positive document can be a past one.",
                    "label": 0
                },
                {
                    "sent": "And also another amazing of funding funding for the this experiment we found we can largely reduce the positive terms.",
                    "label": 0
                },
                {
                    "sent": "From the PDF, the PDF and the term average is 156.",
                    "label": 0
                },
                {
                    "sent": "If we use the same minimum support.",
                    "label": 0
                },
                {
                    "sent": "And PM fund the term from positive document and then we are decided about 23.",
                    "label": 0
                },
                {
                    "sent": "Positive specific terms.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we are.",
                    "label": 0
                },
                {
                    "sent": "I'll give some results for the analysis.",
                    "label": 0
                },
                {
                    "sent": "Often this election.",
                    "label": 0
                },
                {
                    "sent": "It's obviously a.",
                    "label": 0
                },
                {
                    "sent": "Use half is the best one if you use all of the.",
                    "label": 0
                },
                {
                    "sent": "Negative document the performance very.",
                    "label": 0
                },
                {
                    "sent": "Fat",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And also we show you using the different combination of general term specific term and normally the PTM.",
                    "label": 0
                },
                {
                    "sent": "Is here.",
                    "label": 0
                },
                {
                    "sent": "And we use the.",
                    "label": 0
                },
                {
                    "sent": "Unlike general term, the performance not good.",
                    "label": 0
                },
                {
                    "sent": "And if you use only the.",
                    "label": 0
                },
                {
                    "sent": "Positive specific term.",
                    "label": 0
                },
                {
                    "sent": "Few terms better than the PT.",
                    "label": 0
                },
                {
                    "sent": "A little bit.",
                    "label": 0
                },
                {
                    "sent": "And use both.",
                    "label": 0
                },
                {
                    "sent": "At.",
                    "label": 0
                },
                {
                    "sent": "Positive specific term and general term.",
                    "label": 0
                },
                {
                    "sent": "Better and then use all three categories is the best one.",
                    "label": 0
                },
                {
                    "sent": "I'm.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Also show you this picture show you the.",
                    "label": 0
                },
                {
                    "sent": "The change of the terms the weighting change after use the revision and normally if the term have heist specific will get large weight after.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With the revision.",
                    "label": 0
                },
                {
                    "sent": "So this paper we compare with the some models.",
                    "label": 0
                },
                {
                    "sent": "Under the proposed model is consistent and very significant on all far measures.",
                    "label": 0
                },
                {
                    "sent": "About 50 topics.",
                    "label": 0
                },
                {
                    "sent": "And also the negative selection approach is satisfactory.",
                    "label": 0
                },
                {
                    "sent": "Under the use of negative relevant relevance feedback is very significant for the relevant feature discovery.",
                    "label": 0
                },
                {
                    "sent": "Because it can balance the percentage of specific terms and general term to reduce noises.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So these are my talk.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                }
            ]
        }
    }
}