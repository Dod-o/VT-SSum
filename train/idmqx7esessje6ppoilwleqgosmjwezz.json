{
    "id": "idmqx7esessje6ppoilwleqgosmjwezz",
    "title": "Wheat or chaff - Practically feasible inferactive ontology revision",
    "info": {
        "author": [
            "Nadeschda Nikitina, Department of Computer Science, University of Oxford"
        ],
        "published": "Nov. 25, 2011",
        "recorded": "October 2011",
        "category": [
            "Top->Computer Science->Semantic Web->Ontologies"
        ]
    },
    "url": "http://videolectures.net/iswc2011_nikitina_revision/",
    "segmentation": [
        [
            "And I'm going to present.",
            "An extension of our work on interactive on Television, which is basically about how we can automatize quality control for ontologies.",
            "This is a joint work with Berta Glim from University of Room and Sebastian orders also from Katie."
        ],
        [
            "Um, so there are many different scenarios in which the quality of an ontology are its suitability for a particular application.",
            "Scenario needs to be verified, and it actually doesn't matter where you ontology has been processed by some heuristic tools such as ontology matching or ontology learning or text on rotation based on machine learning, or whether you're just trying to adopt your ontology tenyu applications scenario.",
            "The problem is still the same and can be addressed in the same way, so you have a set of axioms and you have to.",
            "You need to separate it into the set of correct ones and the set of incorrect ones.",
            "So within the Interactive Ontology revision, the domain expert decides for each axiom where it should be a consequence of the target ontology where the target Ontology models particular application contexts.",
            "Such a revision process of course can require a lot of effort, and our goal is to.",
            "Try to partially automatize as much as possible of this decision taking process."
        ],
        [
            "Um, the whole work is based on a very simple assumption which says that the deductive closure of intendent consequences must not contain unintended consequences, so you should be able to deduce incorrect statements from your set of correct statements.",
            "Here we have an example where we can see how based on this assumption, we can partially automatize this decision taking process.",
            "So on on the right hand side you see a subsumption hierarchy consisting of two subsumption axioms.",
            "Let's assume that this tools assumption axioms are correct and on the left hand side we have three another axioms, alphabet and gamma, and we need to verify.",
            "This three axioms.",
            "So if we decide that the last one is correct, so the concept decision is subconcept of mental object.",
            "Then we see that it's actually not possible anymore to reject the 1st and the 2nd one because this two axioms are already consequent of the set of valid statements.",
            "So we can just.",
            "We can just automatically accept those.",
            "This is a nice nice case where you can take two or three decisions automatically, but of course this is not always the case, and another important observation in this example is actually that the evaluation order.",
            "Can pretty much influence the effectiveness of the support, so when we."
        ],
        [
            "Start with the first axiom and decide that it's correct.",
            "Then we see that we cannot deduce anything automatically, so we have to evaluate the second axiom manually and also the third one.",
            "So in this case it wasn't possible to take any or to automatic."
        ],
        [
            "Decisions so two important points in this example are that signal evaluation decision can predetermine several other evaluation decisions, and of course that evaluation order can really influence the effectiveness of this method."
        ],
        [
            "So now we can generalize this observations and we introduce the notion of revision states.",
            "So we have just a set of axioms in knowledge Base K and we have two subsets of it K models.",
            "And key models, not K models, represents the set of desired consequences and K models not represents the set of undesired consequences.",
            "And of course, intuitively, these two sets have to be disjoined.",
            "When we start with the division, does two sets can be empty and when we are finished then the whole knowledge base should be a disjoint union of."
        ],
        [
            "Two sets.",
            "Additionally, in order to make our assumption hold at anytime, we introduce consistency of division State.",
            "Well, so um division state is consistent.",
            "If the deductive closure of K models and the set key models not are disjoint.",
            "So we we cannot deduce any of the incorrect statements from the set of correct statements."
        ],
        [
            "During the process of revision, these two sets grow of course.",
            "And we see that the new revision state is refinement of the old one, and in particular we say that the refinement is elementary if it's just a single axiom that we have added to either the set.",
            "Um of intended consequences, consequences, or the set of unintended consequences.",
            "So this exactly corresponds to the case where domain expert takes another decision."
        ],
        [
            "Um?",
            "We have seen previously that a single evaluation decision can predetermine several other evaluation decisions and now we summarize such predetermined evaluation decisions, but it means of revision closure, so it simply tells us which axioms we can automatically accept based on the currently taken evaluation decisions and which axioms we can automatically reject."
        ],
        [
            "So there are two goals.",
            "No, for interactive Ontology division on the one hand, we would like to obtain a consistent revision state in the end of the revision and on the other hand we would also like to reduce the number of manually taken decisions and Interestingly revision closure allows us to do both, so we.",
            "On the one hand, when we apply division closure after each expert decision, then it's guaranteed that the final revision state is consistent, and of course it also allows us to partially automatize this decision taking process.",
            "Computing division closure can be quite expensive, of course, and in our previous work we have also.",
            "We took a look at that and introduced auxiliary data structures, decision spaces which allow us to efficiently compute such dependencies between axioms and avoid unnecessary reason."
        ],
        [
            "He calls.",
            "So now we have seen how the decision taking process can be automatized, but how about?",
            "How about the order of evaluation?",
            "How can we determine beneficial evaluation order?",
            "He will introduce.",
            "First we introduce two impact measures.",
            "Approval impact.",
            "For a particular axiom tells us how many axioms can we automatically evaluate, in case this we accept this axiom.",
            "And the decline impact tells us how many axioms we can automatically evaluate if we decline this axiom.",
            "So obviously, if we expect many axioms to be accepted, then it's better to use approval impact for ranking then, and if we accept the expect many exams to be declined, then we should take decline impact.",
            "And if we don't know anything.",
            "About the quality, the expected quality of the data set, or it's rather medium, then we just proposed guaranteed impact, which is.",
            "While I salute one possible solution, maybe not the optimal one where you just take the minimum of these two measures."
        ],
        [
            "So here we see our example again and we see actually that the approval impact.",
            "Sam is the highest for the last axiom because we are able to evaluate two axioms automatically and the decline impact is the highest for the first one, because if we decline it then we are able to decline two axioms automatically.",
            "Yes, and a guaranteed impact us the highest for the extreme in the middle.",
            "Um, from our previous experiements, we have experienced that this simple impact measures work well for datasets with a very high quality or very low quality, but for datasets of a medium quality, it's well there is still some some space for improvement, so it's still possible to throw maximize the amount of automatically taken decisions."
        ],
        [
            "And the reason for that is that these two impact measures, approval and decline impact.",
            "I, in some sense tailored towards validity ratios of 100% and 0% where the validity ratio is just the proportion of approved axioms in the data set.",
            "And here we have an example to see why this is not optimal.",
            "So we have 8 axioms with dependencies between them.",
            "Where the edges represent entailment dependencies between these axioms and the green nodes represent incorrect excellence, while the white notes represent correct ones.",
            "So here the validity ratio is 75%.",
            "When we use approval impact for ranking this axioms, then we will start with the first one and then proceed with the second one and only when we when we reach the third one we are able to evaluate the whole set of axioms.",
            "So we require three decisions to evaluate the whole set.",
            "If we take decline impact then the situation is even worse because we need 7 decisions to evaluate this eight axioms.",
            "And the number of decisions for guaranteed lies between two and three depending on the random choice between the axioms with the same ranking value.",
            "But in in this example, we can clearly see that it should be possible just to evaluate two axioms, the second one and part one, and then the remaining axioms can be evaluated automatically.",
            "Um?",
            "Yes, so this is exactly the behavior of our knew improved ranking function where we take into account the actual expected validity version.",
            "So what we do is.",
            "Well in this, in this case you just see that it makes no sense to start with the first axiom when we actually expect the validity ratio to be 75%, because we then we don't actually expect this axiom to be expected to be accepted.",
            "Then why should we use the approval impact?",
            "And yes, so the goal is to identify interesting axioms so that.",
            "From the deviation of the achieved proportion of accepted and declined axioms from the expected proportion of accepted and declined axioms is rather small, so in this case we see that when we consider the second axiom, then the proportion of rejected axioms corresponds to the expected proportion of reject axioms, and in case of the third.",
            "Axiom the proportion of expected of accepted axioms corresponds to the proportion of to the expected proportion of accepted axioms, and this what makes this two axioms interesting."
        ],
        [
            "How can we determine such interesting axioms?",
            "Well, first we compute we have to compute this proportions of accepted and declined axioms.",
            "Um?",
            "Here we have three different values, two values for for the keys at Axiom is accepted and just one value for the case where an axiom was declined, because in case we decline an axiom we are not able to automatically accept any axioms.",
            "So in this case we don't have to consider the proportion of accepted axioms.",
            "So here we compute.",
            "The proportion of accepted axioms for well for the keys when the axiom is accepted, and we compute two times the proportion of projective axioms.",
            "Ann, now for each of this normalized values we can compute the deviation from the expected proportions.",
            "So we obtain three different values and we can.",
            "When we rank axioms, we can compute the.",
            "We can consider the maximum of these three values and then privilege axioms with the highest one.",
            "So this is how the new ranking function works actually."
        ],
        [
            "Um, here we see some evaluation results on the vertical.",
            "On the vertical scale you see the proportion of automatically taken decisions and on the horizontal scale you see the validity ratios of different datasets.",
            "And here we have six different experimental settings.",
            "We have a baseline where we don't rank seems at all.",
            "We have a hypothetical maximum which will compute by by perfectly guessing which which of the impact measures to use.",
            "Because we know which Axiom will be accepted and which action will be declined.",
            "So we can compute the hypothetical maximum that we can achieve.",
            "And we also have this values for the simple impact measures and the one with the.",
            "The Blue X is the new one, so we see that the values of the optimal experimental setting and the newly introduced one, they actually almost coincide, which is good, and we see that.",
            "The results for for experimental settings without ranking significantly lower and we also see that the impact that the approval impact and decline impact perform.",
            "Well, differently for different validity ratios, and this was the problem which we now solved."
        ],
        [
            "Um, yes, but there is still an open in open problem because now we are dependent on this expected validity ratio.",
            "And in previous work we didn't consider this problem at all.",
            "We just assumed that domain expert can provide an expectation value, but this is of course not realistic in practice, so possible solution is just to learn to learn this expected validity ratio over the course of revision.",
            "So the idea is quite simple.",
            "We start with with an initial value and then after each each time we compute revision closure.",
            "We just update the value so we will set the expected validity ratio to the current validity ratio.",
            "Um and the results were quite good for even for small datasets you see that it's better to use that this learned validity ratio and drank axioms then not ranking axioms at all.",
            "And for larger datasets this works really well."
        ],
        [
            "Here we have the results in more details.",
            "So on the on the vertical scale you see the deviation from the optimal scenario where you perfectly guess the corresponding impact measure.",
            "And on the horizontal one you see that we have used datasets with different size.",
            "So we had small datasets with about 50 axioms and we had medium datasets with something you know around 500 axioms and we also had quite large datasets with around 5000 axioms and we had five different experimental settings.",
            "We have again the random setting where we don't rank axioms at all.",
            "We have this.",
            "Then you parameterized ranking function, but with the assumption that we already know the validity ratio, which is called norm here, and they do.",
            "Norm is the parameterized ranking function, but based on the learned validity ratio.",
            "And here we use three different initial values.",
            "We used under percent 50% and 0% and we see that for already, for small datasets it's better to rank axioms based on this long validity ratio.",
            "But of course there you just don't have the time.",
            "The enough data to learn this value and for medium size datasets this works better.",
            "It's almost it almost coincides, and for large datasets there is almost no difference.",
            "And another important reason why this works well is because the parameterized ranking function is not very sensitive to the value of expected validity ratio.",
            "So if you have a deviation of something like 30%, then you see difference.",
            "But if it's just 5%, then there's almost no difference."
        ],
        [
            "OK, so to summarize, the contribution there were still some problems left.",
            "But in particular, problems that you need to solve to make interactive Ontology division feasible in practice.",
            "So in particular.",
            "We didn't have an optimal solution for datasets with medium quality and we didn't have a solution for not knowing in advance to the validity of Russia, and he was solved this problems.",
            "So we introduced the new ranking function, which is which actually takes into account the expected validity Russia and we also.",
            "Investigate how we can effectively learn the expected validity ratio and then the paper also contains some optimizations.",
            "And for example, partitioning, in order to reduce the computational effort.",
            "Because this is an experimental setting, so it's really important.",
            "Oh so thanks for your attention.",
            "Which datasets that you used for evaluation?",
            "What were these artificial ones?",
            "'cause I would guess that in natural ones you could have.",
            "Some areas are much lower validity ratio in some parts and much higher in other parts.",
            "And then we might not have such a good prediction.",
            "We just used the data that we had from a project.",
            "Project is about.",
            "An automatic annotation auto ontology based automatic annotation of natural language texts using ontology and.",
            "Well yeah, so we actually had the use case and natural use case.",
            "OK then I have a question so you you it's called practically infeasible.",
            "Interactive ontology revisions or since this is a user interaction set, I'm going to ask you about the interactive feature.",
            "So you had this.",
            "Figure in your paper with the you know for with the axioms and you have these options.",
            "How do you see real users actually interacting with this in a in a practical setting?",
            "I mean, would this be ontology engineers or being made aware?",
            "I mean what is the?",
            "What is the interaction setup in which people would actually be interacting with this well?",
            "Actually we have.",
            "We have a group of domain experts and of course they know their ontology quite quite well, so this is probably helpful so you don't need anything else.",
            "You just can use the tool and then you see the different axioms and you can take your decisions and choose different ranking strategies and take decisions back.",
            "So I assume the domain experts would be reading the axioms and interpreting them.",
            "Of course you have to optimize the.",
            "Spend the whole day axioms are displayed.",
            "You have to make them somehow shorter.",
            "Or I mean you can also this can be extended of course because it's an independent problem.",
            "How you in general expose knowledge to users?",
            "You could even probably generate natural language from that and then.",
            "Presented."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And I'm going to present.",
                    "label": 0
                },
                {
                    "sent": "An extension of our work on interactive on Television, which is basically about how we can automatize quality control for ontologies.",
                    "label": 0
                },
                {
                    "sent": "This is a joint work with Berta Glim from University of Room and Sebastian orders also from Katie.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um, so there are many different scenarios in which the quality of an ontology are its suitability for a particular application.",
                    "label": 0
                },
                {
                    "sent": "Scenario needs to be verified, and it actually doesn't matter where you ontology has been processed by some heuristic tools such as ontology matching or ontology learning or text on rotation based on machine learning, or whether you're just trying to adopt your ontology tenyu applications scenario.",
                    "label": 0
                },
                {
                    "sent": "The problem is still the same and can be addressed in the same way, so you have a set of axioms and you have to.",
                    "label": 0
                },
                {
                    "sent": "You need to separate it into the set of correct ones and the set of incorrect ones.",
                    "label": 0
                },
                {
                    "sent": "So within the Interactive Ontology revision, the domain expert decides for each axiom where it should be a consequence of the target ontology where the target Ontology models particular application contexts.",
                    "label": 1
                },
                {
                    "sent": "Such a revision process of course can require a lot of effort, and our goal is to.",
                    "label": 0
                },
                {
                    "sent": "Try to partially automatize as much as possible of this decision taking process.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um, the whole work is based on a very simple assumption which says that the deductive closure of intendent consequences must not contain unintended consequences, so you should be able to deduce incorrect statements from your set of correct statements.",
                    "label": 1
                },
                {
                    "sent": "Here we have an example where we can see how based on this assumption, we can partially automatize this decision taking process.",
                    "label": 0
                },
                {
                    "sent": "So on on the right hand side you see a subsumption hierarchy consisting of two subsumption axioms.",
                    "label": 0
                },
                {
                    "sent": "Let's assume that this tools assumption axioms are correct and on the left hand side we have three another axioms, alphabet and gamma, and we need to verify.",
                    "label": 0
                },
                {
                    "sent": "This three axioms.",
                    "label": 0
                },
                {
                    "sent": "So if we decide that the last one is correct, so the concept decision is subconcept of mental object.",
                    "label": 0
                },
                {
                    "sent": "Then we see that it's actually not possible anymore to reject the 1st and the 2nd one because this two axioms are already consequent of the set of valid statements.",
                    "label": 0
                },
                {
                    "sent": "So we can just.",
                    "label": 0
                },
                {
                    "sent": "We can just automatically accept those.",
                    "label": 0
                },
                {
                    "sent": "This is a nice nice case where you can take two or three decisions automatically, but of course this is not always the case, and another important observation in this example is actually that the evaluation order.",
                    "label": 0
                },
                {
                    "sent": "Can pretty much influence the effectiveness of the support, so when we.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Start with the first axiom and decide that it's correct.",
                    "label": 0
                },
                {
                    "sent": "Then we see that we cannot deduce anything automatically, so we have to evaluate the second axiom manually and also the third one.",
                    "label": 0
                },
                {
                    "sent": "So in this case it wasn't possible to take any or to automatic.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Decisions so two important points in this example are that signal evaluation decision can predetermine several other evaluation decisions, and of course that evaluation order can really influence the effectiveness of this method.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now we can generalize this observations and we introduce the notion of revision states.",
                    "label": 0
                },
                {
                    "sent": "So we have just a set of axioms in knowledge Base K and we have two subsets of it K models.",
                    "label": 0
                },
                {
                    "sent": "And key models, not K models, represents the set of desired consequences and K models not represents the set of undesired consequences.",
                    "label": 1
                },
                {
                    "sent": "And of course, intuitively, these two sets have to be disjoined.",
                    "label": 0
                },
                {
                    "sent": "When we start with the division, does two sets can be empty and when we are finished then the whole knowledge base should be a disjoint union of.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Two sets.",
                    "label": 0
                },
                {
                    "sent": "Additionally, in order to make our assumption hold at anytime, we introduce consistency of division State.",
                    "label": 0
                },
                {
                    "sent": "Well, so um division state is consistent.",
                    "label": 1
                },
                {
                    "sent": "If the deductive closure of K models and the set key models not are disjoint.",
                    "label": 0
                },
                {
                    "sent": "So we we cannot deduce any of the incorrect statements from the set of correct statements.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "During the process of revision, these two sets grow of course.",
                    "label": 0
                },
                {
                    "sent": "And we see that the new revision state is refinement of the old one, and in particular we say that the refinement is elementary if it's just a single axiom that we have added to either the set.",
                    "label": 0
                },
                {
                    "sent": "Um of intended consequences, consequences, or the set of unintended consequences.",
                    "label": 0
                },
                {
                    "sent": "So this exactly corresponds to the case where domain expert takes another decision.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "We have seen previously that a single evaluation decision can predetermine several other evaluation decisions and now we summarize such predetermined evaluation decisions, but it means of revision closure, so it simply tells us which axioms we can automatically accept based on the currently taken evaluation decisions and which axioms we can automatically reject.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So there are two goals.",
                    "label": 0
                },
                {
                    "sent": "No, for interactive Ontology division on the one hand, we would like to obtain a consistent revision state in the end of the revision and on the other hand we would also like to reduce the number of manually taken decisions and Interestingly revision closure allows us to do both, so we.",
                    "label": 1
                },
                {
                    "sent": "On the one hand, when we apply division closure after each expert decision, then it's guaranteed that the final revision state is consistent, and of course it also allows us to partially automatize this decision taking process.",
                    "label": 0
                },
                {
                    "sent": "Computing division closure can be quite expensive, of course, and in our previous work we have also.",
                    "label": 1
                },
                {
                    "sent": "We took a look at that and introduced auxiliary data structures, decision spaces which allow us to efficiently compute such dependencies between axioms and avoid unnecessary reason.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "He calls.",
                    "label": 0
                },
                {
                    "sent": "So now we have seen how the decision taking process can be automatized, but how about?",
                    "label": 0
                },
                {
                    "sent": "How about the order of evaluation?",
                    "label": 0
                },
                {
                    "sent": "How can we determine beneficial evaluation order?",
                    "label": 0
                },
                {
                    "sent": "He will introduce.",
                    "label": 0
                },
                {
                    "sent": "First we introduce two impact measures.",
                    "label": 0
                },
                {
                    "sent": "Approval impact.",
                    "label": 0
                },
                {
                    "sent": "For a particular axiom tells us how many axioms can we automatically evaluate, in case this we accept this axiom.",
                    "label": 0
                },
                {
                    "sent": "And the decline impact tells us how many axioms we can automatically evaluate if we decline this axiom.",
                    "label": 0
                },
                {
                    "sent": "So obviously, if we expect many axioms to be accepted, then it's better to use approval impact for ranking then, and if we accept the expect many exams to be declined, then we should take decline impact.",
                    "label": 0
                },
                {
                    "sent": "And if we don't know anything.",
                    "label": 0
                },
                {
                    "sent": "About the quality, the expected quality of the data set, or it's rather medium, then we just proposed guaranteed impact, which is.",
                    "label": 0
                },
                {
                    "sent": "While I salute one possible solution, maybe not the optimal one where you just take the minimum of these two measures.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here we see our example again and we see actually that the approval impact.",
                    "label": 0
                },
                {
                    "sent": "Sam is the highest for the last axiom because we are able to evaluate two axioms automatically and the decline impact is the highest for the first one, because if we decline it then we are able to decline two axioms automatically.",
                    "label": 0
                },
                {
                    "sent": "Yes, and a guaranteed impact us the highest for the extreme in the middle.",
                    "label": 0
                },
                {
                    "sent": "Um, from our previous experiements, we have experienced that this simple impact measures work well for datasets with a very high quality or very low quality, but for datasets of a medium quality, it's well there is still some some space for improvement, so it's still possible to throw maximize the amount of automatically taken decisions.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the reason for that is that these two impact measures, approval and decline impact.",
                    "label": 0
                },
                {
                    "sent": "I, in some sense tailored towards validity ratios of 100% and 0% where the validity ratio is just the proportion of approved axioms in the data set.",
                    "label": 1
                },
                {
                    "sent": "And here we have an example to see why this is not optimal.",
                    "label": 0
                },
                {
                    "sent": "So we have 8 axioms with dependencies between them.",
                    "label": 0
                },
                {
                    "sent": "Where the edges represent entailment dependencies between these axioms and the green nodes represent incorrect excellence, while the white notes represent correct ones.",
                    "label": 1
                },
                {
                    "sent": "So here the validity ratio is 75%.",
                    "label": 0
                },
                {
                    "sent": "When we use approval impact for ranking this axioms, then we will start with the first one and then proceed with the second one and only when we when we reach the third one we are able to evaluate the whole set of axioms.",
                    "label": 0
                },
                {
                    "sent": "So we require three decisions to evaluate the whole set.",
                    "label": 0
                },
                {
                    "sent": "If we take decline impact then the situation is even worse because we need 7 decisions to evaluate this eight axioms.",
                    "label": 0
                },
                {
                    "sent": "And the number of decisions for guaranteed lies between two and three depending on the random choice between the axioms with the same ranking value.",
                    "label": 0
                },
                {
                    "sent": "But in in this example, we can clearly see that it should be possible just to evaluate two axioms, the second one and part one, and then the remaining axioms can be evaluated automatically.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Yes, so this is exactly the behavior of our knew improved ranking function where we take into account the actual expected validity version.",
                    "label": 0
                },
                {
                    "sent": "So what we do is.",
                    "label": 0
                },
                {
                    "sent": "Well in this, in this case you just see that it makes no sense to start with the first axiom when we actually expect the validity ratio to be 75%, because we then we don't actually expect this axiom to be expected to be accepted.",
                    "label": 0
                },
                {
                    "sent": "Then why should we use the approval impact?",
                    "label": 0
                },
                {
                    "sent": "And yes, so the goal is to identify interesting axioms so that.",
                    "label": 0
                },
                {
                    "sent": "From the deviation of the achieved proportion of accepted and declined axioms from the expected proportion of accepted and declined axioms is rather small, so in this case we see that when we consider the second axiom, then the proportion of rejected axioms corresponds to the expected proportion of reject axioms, and in case of the third.",
                    "label": 1
                },
                {
                    "sent": "Axiom the proportion of expected of accepted axioms corresponds to the proportion of to the expected proportion of accepted axioms, and this what makes this two axioms interesting.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How can we determine such interesting axioms?",
                    "label": 0
                },
                {
                    "sent": "Well, first we compute we have to compute this proportions of accepted and declined axioms.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Here we have three different values, two values for for the keys at Axiom is accepted and just one value for the case where an axiom was declined, because in case we decline an axiom we are not able to automatically accept any axioms.",
                    "label": 0
                },
                {
                    "sent": "So in this case we don't have to consider the proportion of accepted axioms.",
                    "label": 0
                },
                {
                    "sent": "So here we compute.",
                    "label": 0
                },
                {
                    "sent": "The proportion of accepted axioms for well for the keys when the axiom is accepted, and we compute two times the proportion of projective axioms.",
                    "label": 0
                },
                {
                    "sent": "Ann, now for each of this normalized values we can compute the deviation from the expected proportions.",
                    "label": 0
                },
                {
                    "sent": "So we obtain three different values and we can.",
                    "label": 0
                },
                {
                    "sent": "When we rank axioms, we can compute the.",
                    "label": 0
                },
                {
                    "sent": "We can consider the maximum of these three values and then privilege axioms with the highest one.",
                    "label": 0
                },
                {
                    "sent": "So this is how the new ranking function works actually.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um, here we see some evaluation results on the vertical.",
                    "label": 0
                },
                {
                    "sent": "On the vertical scale you see the proportion of automatically taken decisions and on the horizontal scale you see the validity ratios of different datasets.",
                    "label": 0
                },
                {
                    "sent": "And here we have six different experimental settings.",
                    "label": 0
                },
                {
                    "sent": "We have a baseline where we don't rank seems at all.",
                    "label": 0
                },
                {
                    "sent": "We have a hypothetical maximum which will compute by by perfectly guessing which which of the impact measures to use.",
                    "label": 0
                },
                {
                    "sent": "Because we know which Axiom will be accepted and which action will be declined.",
                    "label": 0
                },
                {
                    "sent": "So we can compute the hypothetical maximum that we can achieve.",
                    "label": 0
                },
                {
                    "sent": "And we also have this values for the simple impact measures and the one with the.",
                    "label": 0
                },
                {
                    "sent": "The Blue X is the new one, so we see that the values of the optimal experimental setting and the newly introduced one, they actually almost coincide, which is good, and we see that.",
                    "label": 0
                },
                {
                    "sent": "The results for for experimental settings without ranking significantly lower and we also see that the impact that the approval impact and decline impact perform.",
                    "label": 0
                },
                {
                    "sent": "Well, differently for different validity ratios, and this was the problem which we now solved.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um, yes, but there is still an open in open problem because now we are dependent on this expected validity ratio.",
                    "label": 0
                },
                {
                    "sent": "And in previous work we didn't consider this problem at all.",
                    "label": 0
                },
                {
                    "sent": "We just assumed that domain expert can provide an expectation value, but this is of course not realistic in practice, so possible solution is just to learn to learn this expected validity ratio over the course of revision.",
                    "label": 0
                },
                {
                    "sent": "So the idea is quite simple.",
                    "label": 0
                },
                {
                    "sent": "We start with with an initial value and then after each each time we compute revision closure.",
                    "label": 1
                },
                {
                    "sent": "We just update the value so we will set the expected validity ratio to the current validity ratio.",
                    "label": 1
                },
                {
                    "sent": "Um and the results were quite good for even for small datasets you see that it's better to use that this learned validity ratio and drank axioms then not ranking axioms at all.",
                    "label": 0
                },
                {
                    "sent": "And for larger datasets this works really well.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here we have the results in more details.",
                    "label": 0
                },
                {
                    "sent": "So on the on the vertical scale you see the deviation from the optimal scenario where you perfectly guess the corresponding impact measure.",
                    "label": 0
                },
                {
                    "sent": "And on the horizontal one you see that we have used datasets with different size.",
                    "label": 0
                },
                {
                    "sent": "So we had small datasets with about 50 axioms and we had medium datasets with something you know around 500 axioms and we also had quite large datasets with around 5000 axioms and we had five different experimental settings.",
                    "label": 0
                },
                {
                    "sent": "We have again the random setting where we don't rank axioms at all.",
                    "label": 0
                },
                {
                    "sent": "We have this.",
                    "label": 0
                },
                {
                    "sent": "Then you parameterized ranking function, but with the assumption that we already know the validity ratio, which is called norm here, and they do.",
                    "label": 0
                },
                {
                    "sent": "Norm is the parameterized ranking function, but based on the learned validity ratio.",
                    "label": 0
                },
                {
                    "sent": "And here we use three different initial values.",
                    "label": 0
                },
                {
                    "sent": "We used under percent 50% and 0% and we see that for already, for small datasets it's better to rank axioms based on this long validity ratio.",
                    "label": 0
                },
                {
                    "sent": "But of course there you just don't have the time.",
                    "label": 0
                },
                {
                    "sent": "The enough data to learn this value and for medium size datasets this works better.",
                    "label": 0
                },
                {
                    "sent": "It's almost it almost coincides, and for large datasets there is almost no difference.",
                    "label": 0
                },
                {
                    "sent": "And another important reason why this works well is because the parameterized ranking function is not very sensitive to the value of expected validity ratio.",
                    "label": 0
                },
                {
                    "sent": "So if you have a deviation of something like 30%, then you see difference.",
                    "label": 0
                },
                {
                    "sent": "But if it's just 5%, then there's almost no difference.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so to summarize, the contribution there were still some problems left.",
                    "label": 0
                },
                {
                    "sent": "But in particular, problems that you need to solve to make interactive Ontology division feasible in practice.",
                    "label": 1
                },
                {
                    "sent": "So in particular.",
                    "label": 0
                },
                {
                    "sent": "We didn't have an optimal solution for datasets with medium quality and we didn't have a solution for not knowing in advance to the validity of Russia, and he was solved this problems.",
                    "label": 1
                },
                {
                    "sent": "So we introduced the new ranking function, which is which actually takes into account the expected validity Russia and we also.",
                    "label": 0
                },
                {
                    "sent": "Investigate how we can effectively learn the expected validity ratio and then the paper also contains some optimizations.",
                    "label": 1
                },
                {
                    "sent": "And for example, partitioning, in order to reduce the computational effort.",
                    "label": 0
                },
                {
                    "sent": "Because this is an experimental setting, so it's really important.",
                    "label": 0
                },
                {
                    "sent": "Oh so thanks for your attention.",
                    "label": 0
                },
                {
                    "sent": "Which datasets that you used for evaluation?",
                    "label": 0
                },
                {
                    "sent": "What were these artificial ones?",
                    "label": 1
                },
                {
                    "sent": "'cause I would guess that in natural ones you could have.",
                    "label": 0
                },
                {
                    "sent": "Some areas are much lower validity ratio in some parts and much higher in other parts.",
                    "label": 0
                },
                {
                    "sent": "And then we might not have such a good prediction.",
                    "label": 0
                },
                {
                    "sent": "We just used the data that we had from a project.",
                    "label": 0
                },
                {
                    "sent": "Project is about.",
                    "label": 0
                },
                {
                    "sent": "An automatic annotation auto ontology based automatic annotation of natural language texts using ontology and.",
                    "label": 0
                },
                {
                    "sent": "Well yeah, so we actually had the use case and natural use case.",
                    "label": 0
                },
                {
                    "sent": "OK then I have a question so you you it's called practically infeasible.",
                    "label": 0
                },
                {
                    "sent": "Interactive ontology revisions or since this is a user interaction set, I'm going to ask you about the interactive feature.",
                    "label": 0
                },
                {
                    "sent": "So you had this.",
                    "label": 0
                },
                {
                    "sent": "Figure in your paper with the you know for with the axioms and you have these options.",
                    "label": 0
                },
                {
                    "sent": "How do you see real users actually interacting with this in a in a practical setting?",
                    "label": 0
                },
                {
                    "sent": "I mean, would this be ontology engineers or being made aware?",
                    "label": 0
                },
                {
                    "sent": "I mean what is the?",
                    "label": 0
                },
                {
                    "sent": "What is the interaction setup in which people would actually be interacting with this well?",
                    "label": 0
                },
                {
                    "sent": "Actually we have.",
                    "label": 0
                },
                {
                    "sent": "We have a group of domain experts and of course they know their ontology quite quite well, so this is probably helpful so you don't need anything else.",
                    "label": 0
                },
                {
                    "sent": "You just can use the tool and then you see the different axioms and you can take your decisions and choose different ranking strategies and take decisions back.",
                    "label": 0
                },
                {
                    "sent": "So I assume the domain experts would be reading the axioms and interpreting them.",
                    "label": 0
                },
                {
                    "sent": "Of course you have to optimize the.",
                    "label": 0
                },
                {
                    "sent": "Spend the whole day axioms are displayed.",
                    "label": 0
                },
                {
                    "sent": "You have to make them somehow shorter.",
                    "label": 0
                },
                {
                    "sent": "Or I mean you can also this can be extended of course because it's an independent problem.",
                    "label": 0
                },
                {
                    "sent": "How you in general expose knowledge to users?",
                    "label": 0
                },
                {
                    "sent": "You could even probably generate natural language from that and then.",
                    "label": 0
                },
                {
                    "sent": "Presented.",
                    "label": 0
                }
            ]
        }
    }
}