{
    "id": "udd6oibdbmqcq7rkobbf7ufvn4gdil52",
    "title": "Dynamic Provenance for SPARQL Updates",
    "info": {
        "author": [
            "Harry Reeves Halpin, World Wide Web Consortium (W3C)"
        ],
        "published": "Dec. 19, 2014",
        "recorded": "October 2014",
        "category": [
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/iswc2014_halpin_dynamic_provenance/",
    "segmentation": [
        [
            "So this is sort of now for something completely different affectively.",
            "There's always a sort of awkward problem.",
            "At least I had.",
            "So this was research done on University Edinburgh.",
            "I'm now W 3C MIT and I was done with James Chaney who's at the database Research Group in Edinburgh, and I was always having these sort of problems with RDF usual problems of reasoning being slow, things breaking triple stores not being very fast, and we were doing sort of research on search engines and how they could use triple, some of which eventually worked its way into the.",
            "Yahoo stuff, but at that same point we had this problem we couldn't.",
            "It was very hard to track the changes in these triple sets and we really wanted an easy way to do that an we basically began discussing with the database community and the office next door what to do and this is the result affectively occur."
        ],
        [
            "To us that the semantic web is."
        ],
        [
            "Great for many things, but it doesn't have a way to track provenance.",
            "And when I say provinces problems can mean many different things to many different people, but I think what we're looking for is how can we track changes in the RDF data set.",
            "Overtime right?",
            "So not who did what?",
            "Where will go through this in a bit more detail, but if some triples are added, how can I find the state of the data set?",
            "Windows triples were added and how can I find the state before and after and track this through?",
            "Sort of infinite amount changes and you know we looked at the RDF Providence Working Group and it seemed like they were very interesting stuff, but it wasn't exactly what we wanted and we didn't find any very good off the shelf software that did this, and our hypothesis was that we probably could just didn't seem impossible, but it's sort of simple vocabulary composed of insert, delete, copy what is known and the database research literature as the Peter Boumans cut and paste model of Providence would probably be sufficient.",
            "For the semantic web, and it's a very exciting area of research.",
            "Currently an relational databases and there's no reason why I just couldn't port those findings over to RDF, and there's actually some interesting advantages to the approach in database community that we kind of put forward here, which essentially is, you know, you want.",
            "You don't want to store your Prof necessarily in the same place you're doing all your operations, so generally people want the latest version of the Triple Store and they want to run fast and they want it to run, you know?",
            "And sort of the same way.",
            "They don't want to change any of their current tooling.",
            "However, there are cases you know, such as you know any science.",
            "But also, let's say you know your triple store got hacked and someone changed all your triples where you would want to go back into very careful analysis of who did what change when, so it would be useful to capture that information and put it in another triple store or somewhere offsite affectively where wouldn't interfere with your current work but could still be.",
            "Access when needed in using the same tool, set an we wouldn't.",
            "We didn't also want to build a custom kind of Providence database.",
            "One of our design criteria we should be able to use basically two triple stores, one triple store for the current version of the triples of the triples that you're interested in, and another store triple store to capture all of the Providence data, which is all the changes in that trip in the original Triple Store.",
            "So we think that's that.",
            "Would basically save a lot of time and effort.",
            "Legacy stuff will keep working, and it would generally be the smoothest possible.",
            "A solution so you know the problem is you know, particularly with reviewers.",
            "As people get very confused over Providence mean.",
            "So we're just going to go over a little bit of detail.",
            "So generally what W 3C provinces doing the open problems model and all of this workflowy, science, Providence stuff, which is what most people use the word for in this community is they basically mean we're describing data, often a atomic artifact of some type, like the result of a scientific process at a particular point in time.",
            "And that's what the database community is focused on.",
            "So focus on dynamic problems that's making changes in data set that basically have some sort of complex internal structures or speaking collections.",
            "You know there's a relational algebra of some sort versus atomic artifacts, and that's kind of process where we do at the same point, we want to allow whatever we have to take advantage of the great work that the problem is working Group has done.",
            "So there's a lot of very good vocabularies open Providence model, which is sort of filtered into the W. 3C Providence work, and we won't be able take advantage of that work, but we don't want to bind ourselves to it, so we want people to use whatever metadata for Providence they want, and we basically follow Boumans original 2001 definition of Providence, where we say there's two, basically 2, maybe three kinds.",
            "Men who you talk to these weird Providence, which is the location in the source databases from which the data was extracted, and there's a wide province which is the source of data that had some influence.",
            "On the existence of data.",
            "And finally, there's the how profits, which is the exact order of operations used to produce any derived data annotations.",
            "An who produce them at what time, and there's been a lot of interesting work.",
            "Illiterates review it, but more in the paper.",
            "But you know, there's a great work on Temple RDF when really wonderful work using coloring over RDF, preserving our DFS inference maintenance.",
            "However, all of that work.",
            "We really wanted something just more like GIT.",
            "For RDF, we just want to say give us rollback this change give us.",
            "How this triplestore look two years ago, that sort of very basic stuff, and we found that actually while the research using really wonderful complex stuff involving inference, we were not able to find any off the shelf working software.",
            "The basic stuff.",
            "And so if you understand this graph that you understand the whole point of."
        ],
        [
            "What we're doing, so we have a graph, so the graphs on top are effectively the quote, unquote real graph.",
            "There are the main graph which we're trying to track the provenance of their changes, and you can see that there are timestamps here.",
            "There's three timestamps, version zero.",
            "There's a version.",
            "One is a version 2, and you can see that what happened in between the first version is that there was a delete operation were sort of deleted the the sorry that the ACD at the bottom and then we just had the ABR left.",
            "So James did that.",
            "So we have a metadata.",
            "Vocabulary you can see this operation.",
            "We label all the operations we type them, so we have you one which is a type delete.",
            "Let's update one of type delete it points to the provenance graphs or points to the.",
            "Also a copy of the exact operation ran various metadata such as who ran it, so James ran it at 4:00 PM.",
            "Then you can sort of see next.",
            "Then I run another query.",
            "I insert some more triples in an that I do that 5:00 PM and that's captured and that all of those triples all the.",
            "Other than caption and what's called the provenance graph, or in these particular?",
            "Subgraphs of the problems graph are the sort of what we call the auxiliary records, and it sounds complicated, but it's actually."
        ],
        [
            "Seating Lee simple, and that's kind of why we like this solution.",
            "'cause we find that simple issues work and overly complex ones to be quite messy.",
            "So we record the insertion deletion of every triple.",
            "We keep this problem scrap updated with these auxiliary name graphs, so each of the cervix Zillow graphs is its own graph as well.",
            "We sort of.",
            "We formalize things using fairly standard notation, all taken from awareness is great, formal semantics sparkle, and the new Sparkle update semantics.",
            "I don't know if we really necessary to go over this, but effectively.",
            "We the key thing we do with sparkles because it guitar."
        ],
        [
            "All of these other systems your essential gateway into the data is a text editor Anne in a lot of the database work, your gateway is, you know the SQL queries and essentially the nice thing about RDF, which actually you could say is even superior to the SQL work.",
            "Have a very well structured, formally defined gateway into making any change in the data and that is Sparkle update.",
            "So all you really have to do to get problems working for this sort of dynamic datasets and sparkle update is you just have to add these provenance graphs.",
            "Annotations to make the auxiliary graphs with every sort of Sparkle update command.",
            "You can see that there's actually not that many delete, insert, load, clear, create, drop, and they're all fairly standard formal definitions, so all we really have to do."
        ],
        [
            "Is we just have to define for each of these exactly how to create the auxiliary graph so the XR graphs pretty easy.",
            "We just basically in addition to running your normal Sparkle update command, you just run another Sparkle Update command and this sparkle update updates the provenance graph and so you can sort of see that you can basically take any set of arbitrary sparkle updates using our source.",
            "I would say formalism is sort of thing.",
            "In this paper you can expand their sparkle updates to Providence Aware.",
            "And then create this province graph for each step.",
            "So we have we will just creates really easy so you have a new graph, you give a new version.",
            "You've given the current pointer you say hey look, it's a crate type.",
            "Here's a pointer to output an.",
            "You had some metadata in and that creates a new sequence of versions and then."
        ],
        [
            "Also delete them.",
            "You can clear the graph and it's all sort of done the same way."
        ],
        [
            "Low."
        ],
        [
            "Voting graphs are slightly interesting, but you basically keep that version index intact, right?",
            "Because you're not actually.",
            "Killing and creating a new graph, but otherwise is the same and."
        ],
        [
            "The most interesting is probably insert right so inserts the one that mostly we want to track and effectively where we insert.",
            "The new graph will follow the condition of whatever those new triples are adding.",
            "We create the new version that you load that you can delete and then just basically add in the input the output, the type insert, and then you keep all the sources.",
            "In line, so it's effectively exceedingly simple."
        ],
        [
            "Plan for delete.",
            "You basically just do the reverse.",
            "When you delete the triples and again you have to keep track of the index, the version number, the input, the output, the type, the sources of data which you're deleting from an whatever meta data which we let be optional, but we're imagining that metadata people will use opium, an W 3 prong of.",
            "So again, it's really straightforward.",
            "The nice thing about this method is it works with current systems over current triple stores."
        ],
        [
            "And then you know it's again, it's you can you, can we just you can't you have to create a little tiny bit of a vocabulary to manage all of this?",
            "And we sort of list that out in the paper we can see again.",
            "It's all fairly trivial.",
            "Insert, delete, load, clear data and all the interesting stuff is basically keeping a current index to the latest index, which you won't be running your actual off your queries off your live index versions, typing sources and metadata.",
            "I think so."
        ],
        [
            "So effectively we agree it's a really challenging solution, and I've had a few minutes.",
            "I'll show you why it's so challenging, but we do think that you know sort of dumb.",
            "Quick solutions are effective in this space rather than rebuilding sparkle update, you can just basically you spark up to generate even more sparkle updates and keep track of provenance.",
            "Anna secondary triplestore, where maybe you don't have so many performance concerns and also it's going to get quite big, which we discussed in one minute an the metadata carried by technique is compatible numbers park requires no changes.",
            "Sparkle update.",
            "We can use W3C problem.",
            "We can use existing triple stores.",
            "Now the problem is which I'll see if I can poke up.",
            "So I think I have.",
            "I have a few minutes right?",
            "OK so I did that a little bit too quick, but the real issues.",
            "Let's see if I can just get that over.",
            "So this is some stuff we haven't.",
            "I'm sorry I have to get out of it.",
            "Yeah, so this is some stuff we didn't put in the paper.",
            "Craft space is formal.",
            "Semantics takes so much time so affectively there's a lot of really hard issues that we're looking for feedback on.",
            "Because this is the stuff we started implementing.",
            "So there's a Google funded project at University Edinburgh which is kind of not really running right now, but was running were just looking at all of these Providence or related stuff in terms of looking at SQL XML and then we kind of added at the last minute RDF and I think the problem is if you if you sort of.",
            "Implement our system in a dumb way.",
            "We're just always recording every single triple is going in and out, and you're recording all the metadata for it.",
            "You immediately have.",
            "I should be fairly obvious or explosion of triples in your province graph, so it's really out of hand.",
            "So the question is, how can you basically keep this data smaller so you don't have this sort of triple explosion?",
            "Although we are getting very big triple stores, maybe we can keep all of these huge triples, and there's sort of three or four different standard ways to deal with that.",
            "One way to deal with it is a transaction based method where you basically don't copy.",
            "You basically have certain amounts of periods and you only copy the profits after.",
            "You run through so many operations, so it's a very dumb way, but it works pretty simple, simply an another thing which is quite useful for conserving space is a lot of the triple patterns are repeated, so bit trickier to sort out technically, but you can imagine that, for example, someone concerning some triples.",
            "Some parts of triples back end, they put them back out.",
            "They put it back in, and eventually it doesn't.",
            "You basically can just refer to just those set of triples instead of storing them by value.",
            "You basically store them via reference.",
            "Now the problem is that the amount of possible referred to triples is very large, so actually sorting out your references in.",
            "So just being another sort of terrible problem.",
            "So right now we generally just sort of do things that dumb way, but we're very interested in future research and how we could actually do this in a more intelligent way in a more optimal way.",
            "And there's a lot of work around database community.",
            "We've been running this.",
            "A few different options and I'll see if I can make it slightly more legible.",
            "This is a for a poster awhile back, but you could sort of the best graph ever.",
            "This is more interesting.",
            "Well now it's not pretty interesting either, but effectively what was happening here?",
            "You almost can't see it, but you can sort of see that when we're doing transactions over a very small data set, storing things by value.",
            "That's the blue, which is bearish, basically illegible at the bottom, but it's much smaller than we started storing things by storing the whole triple, which is red and just got this or combinatorial explosion.",
            "And that really essentially damages the utility of the technique and practice.",
            "Unless you're capable of dealing with a big triple store.",
            "Or you have a simply small set of data and you are curated very carefully.",
            "So if you don't expect your so, I think this method effectively if you wanted to ask me when does this method work, I would say right now it works on large triple stores which change infrequently, or small triple stores which change frequently.",
            "You don't want to use it on a large triple store which is changing frequently because of this sort of explosion of possible problems you have by storing all the metadata, and that's where there's some really probably interesting work would happen, and optimizing these sort of change of references that point to various triples.",
            "But that stuff that's quite tricky.",
            "We haven't got around to doing that yet.",
            "So.",
            "Thank you very much.",
            "Did you map your UDP vocabulary to prove?",
            "Yeah, some of it map so it doesn't?",
            "I think it's in the paper.",
            "OK, so that would be cool to do that, and then the second thing is for you should really look at Boris Glavic's work using audit logs and time travel in the relational database rule to track all this 'cause he does this with no overhead at all.",
            "If you have any time travel based database, I find what do you mean by no overhead.",
            "So you have to store something, yeah, but they have extremely if you Oracle and Postgres I think implement time travel which is a very fine grained versioning system of your database and it's.",
            "Oh, so they have it.",
            "They basically have a problem.",
            "Is enabled relational database underneath.",
            "So there is overhead in but the over it's pushed off.",
            "Yeah.",
            "Just check out this work OK.",
            "I mean it.",
            "It just sounds like what's happened is that Oracle just did the snapshot work for you, which is fine.",
            "And that's cool and we can just take advantage of that by the same point, doesn't it doesn't stop the fact that the snapshot.",
            "Thanks tricky, so there's probably a lot of hard work by Oracle, and doing the snapshots right if they keep the overhead processing, but this whole version database audit log databases in the relational world have just been study to.",
            "They said nonsense right?",
            "So I just take what you have and dump it on there.",
            "It would be very cool.",
            "Yeah yeah, I mean all of this work is coming from Boumans work, which I think probably I would assume the Oracle folks use.",
            "So speaking about 10 years, that branch of research.",
            "So, have you considered using spin to encode the sparkle update that does the the actual update rather than store 2 snapshots of the underlying triples?",
            "'cause then you could just have these kind of keyframes where you say well, here was the data, some known point and then hear a bunch of sparkle operations that were performed on it, which sounds very similar to this time travel idea, so you would just kind of say, well, we go back to the closest point and then we can reply if we want the updates to get to some intermediary point which is similar to what Git does, right?",
            "So it has all these diffs.",
            "Represent all the source code changes and then if you say to go to a specific tag, you have to go and play back and it essentially placed back the gifts for you.",
            "So so yeah, so so that's why I'm in transaction.",
            "You basically you snapshot the actual problem stated in the data at one point and then you keep so you won't be able to get to changes in between your transaction.",
            "So just again your replay the queries.",
            "So in our system that's a very good point.",
            "We don't really know too much spent really using it.",
            "We were replaying the actual with our transaction so replaying actual sparkle queries.",
            "We weren't really laying on top of a relational database.",
            "We were playing them on top of a triple storage, probably part of why it's so messy, so we should look at relational databases and we could snapshot using spin.",
            "I think that would be fine.",
            "Maybe it's much faster.",
            "It would be nice to look at that."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is sort of now for something completely different affectively.",
                    "label": 0
                },
                {
                    "sent": "There's always a sort of awkward problem.",
                    "label": 0
                },
                {
                    "sent": "At least I had.",
                    "label": 0
                },
                {
                    "sent": "So this was research done on University Edinburgh.",
                    "label": 0
                },
                {
                    "sent": "I'm now W 3C MIT and I was done with James Chaney who's at the database Research Group in Edinburgh, and I was always having these sort of problems with RDF usual problems of reasoning being slow, things breaking triple stores not being very fast, and we were doing sort of research on search engines and how they could use triple, some of which eventually worked its way into the.",
                    "label": 0
                },
                {
                    "sent": "Yahoo stuff, but at that same point we had this problem we couldn't.",
                    "label": 0
                },
                {
                    "sent": "It was very hard to track the changes in these triple sets and we really wanted an easy way to do that an we basically began discussing with the database community and the office next door what to do and this is the result affectively occur.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To us that the semantic web is.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Great for many things, but it doesn't have a way to track provenance.",
                    "label": 1
                },
                {
                    "sent": "And when I say provinces problems can mean many different things to many different people, but I think what we're looking for is how can we track changes in the RDF data set.",
                    "label": 0
                },
                {
                    "sent": "Overtime right?",
                    "label": 0
                },
                {
                    "sent": "So not who did what?",
                    "label": 0
                },
                {
                    "sent": "Where will go through this in a bit more detail, but if some triples are added, how can I find the state of the data set?",
                    "label": 0
                },
                {
                    "sent": "Windows triples were added and how can I find the state before and after and track this through?",
                    "label": 1
                },
                {
                    "sent": "Sort of infinite amount changes and you know we looked at the RDF Providence Working Group and it seemed like they were very interesting stuff, but it wasn't exactly what we wanted and we didn't find any very good off the shelf software that did this, and our hypothesis was that we probably could just didn't seem impossible, but it's sort of simple vocabulary composed of insert, delete, copy what is known and the database research literature as the Peter Boumans cut and paste model of Providence would probably be sufficient.",
                    "label": 1
                },
                {
                    "sent": "For the semantic web, and it's a very exciting area of research.",
                    "label": 0
                },
                {
                    "sent": "Currently an relational databases and there's no reason why I just couldn't port those findings over to RDF, and there's actually some interesting advantages to the approach in database community that we kind of put forward here, which essentially is, you know, you want.",
                    "label": 0
                },
                {
                    "sent": "You don't want to store your Prof necessarily in the same place you're doing all your operations, so generally people want the latest version of the Triple Store and they want to run fast and they want it to run, you know?",
                    "label": 0
                },
                {
                    "sent": "And sort of the same way.",
                    "label": 0
                },
                {
                    "sent": "They don't want to change any of their current tooling.",
                    "label": 0
                },
                {
                    "sent": "However, there are cases you know, such as you know any science.",
                    "label": 0
                },
                {
                    "sent": "But also, let's say you know your triple store got hacked and someone changed all your triples where you would want to go back into very careful analysis of who did what change when, so it would be useful to capture that information and put it in another triple store or somewhere offsite affectively where wouldn't interfere with your current work but could still be.",
                    "label": 0
                },
                {
                    "sent": "Access when needed in using the same tool, set an we wouldn't.",
                    "label": 0
                },
                {
                    "sent": "We didn't also want to build a custom kind of Providence database.",
                    "label": 1
                },
                {
                    "sent": "One of our design criteria we should be able to use basically two triple stores, one triple store for the current version of the triples of the triples that you're interested in, and another store triple store to capture all of the Providence data, which is all the changes in that trip in the original Triple Store.",
                    "label": 0
                },
                {
                    "sent": "So we think that's that.",
                    "label": 0
                },
                {
                    "sent": "Would basically save a lot of time and effort.",
                    "label": 0
                },
                {
                    "sent": "Legacy stuff will keep working, and it would generally be the smoothest possible.",
                    "label": 0
                },
                {
                    "sent": "A solution so you know the problem is you know, particularly with reviewers.",
                    "label": 0
                },
                {
                    "sent": "As people get very confused over Providence mean.",
                    "label": 0
                },
                {
                    "sent": "So we're just going to go over a little bit of detail.",
                    "label": 0
                },
                {
                    "sent": "So generally what W 3C provinces doing the open problems model and all of this workflowy, science, Providence stuff, which is what most people use the word for in this community is they basically mean we're describing data, often a atomic artifact of some type, like the result of a scientific process at a particular point in time.",
                    "label": 0
                },
                {
                    "sent": "And that's what the database community is focused on.",
                    "label": 0
                },
                {
                    "sent": "So focus on dynamic problems that's making changes in data set that basically have some sort of complex internal structures or speaking collections.",
                    "label": 0
                },
                {
                    "sent": "You know there's a relational algebra of some sort versus atomic artifacts, and that's kind of process where we do at the same point, we want to allow whatever we have to take advantage of the great work that the problem is working Group has done.",
                    "label": 0
                },
                {
                    "sent": "So there's a lot of very good vocabularies open Providence model, which is sort of filtered into the W. 3C Providence work, and we won't be able take advantage of that work, but we don't want to bind ourselves to it, so we want people to use whatever metadata for Providence they want, and we basically follow Boumans original 2001 definition of Providence, where we say there's two, basically 2, maybe three kinds.",
                    "label": 0
                },
                {
                    "sent": "Men who you talk to these weird Providence, which is the location in the source databases from which the data was extracted, and there's a wide province which is the source of data that had some influence.",
                    "label": 0
                },
                {
                    "sent": "On the existence of data.",
                    "label": 0
                },
                {
                    "sent": "And finally, there's the how profits, which is the exact order of operations used to produce any derived data annotations.",
                    "label": 0
                },
                {
                    "sent": "An who produce them at what time, and there's been a lot of interesting work.",
                    "label": 0
                },
                {
                    "sent": "Illiterates review it, but more in the paper.",
                    "label": 0
                },
                {
                    "sent": "But you know, there's a great work on Temple RDF when really wonderful work using coloring over RDF, preserving our DFS inference maintenance.",
                    "label": 0
                },
                {
                    "sent": "However, all of that work.",
                    "label": 0
                },
                {
                    "sent": "We really wanted something just more like GIT.",
                    "label": 0
                },
                {
                    "sent": "For RDF, we just want to say give us rollback this change give us.",
                    "label": 0
                },
                {
                    "sent": "How this triplestore look two years ago, that sort of very basic stuff, and we found that actually while the research using really wonderful complex stuff involving inference, we were not able to find any off the shelf working software.",
                    "label": 0
                },
                {
                    "sent": "The basic stuff.",
                    "label": 0
                },
                {
                    "sent": "And so if you understand this graph that you understand the whole point of.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What we're doing, so we have a graph, so the graphs on top are effectively the quote, unquote real graph.",
                    "label": 0
                },
                {
                    "sent": "There are the main graph which we're trying to track the provenance of their changes, and you can see that there are timestamps here.",
                    "label": 0
                },
                {
                    "sent": "There's three timestamps, version zero.",
                    "label": 0
                },
                {
                    "sent": "There's a version.",
                    "label": 0
                },
                {
                    "sent": "One is a version 2, and you can see that what happened in between the first version is that there was a delete operation were sort of deleted the the sorry that the ACD at the bottom and then we just had the ABR left.",
                    "label": 0
                },
                {
                    "sent": "So James did that.",
                    "label": 0
                },
                {
                    "sent": "So we have a metadata.",
                    "label": 0
                },
                {
                    "sent": "Vocabulary you can see this operation.",
                    "label": 0
                },
                {
                    "sent": "We label all the operations we type them, so we have you one which is a type delete.",
                    "label": 0
                },
                {
                    "sent": "Let's update one of type delete it points to the provenance graphs or points to the.",
                    "label": 0
                },
                {
                    "sent": "Also a copy of the exact operation ran various metadata such as who ran it, so James ran it at 4:00 PM.",
                    "label": 0
                },
                {
                    "sent": "Then you can sort of see next.",
                    "label": 0
                },
                {
                    "sent": "Then I run another query.",
                    "label": 0
                },
                {
                    "sent": "I insert some more triples in an that I do that 5:00 PM and that's captured and that all of those triples all the.",
                    "label": 0
                },
                {
                    "sent": "Other than caption and what's called the provenance graph, or in these particular?",
                    "label": 0
                },
                {
                    "sent": "Subgraphs of the problems graph are the sort of what we call the auxiliary records, and it sounds complicated, but it's actually.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Seating Lee simple, and that's kind of why we like this solution.",
                    "label": 0
                },
                {
                    "sent": "'cause we find that simple issues work and overly complex ones to be quite messy.",
                    "label": 0
                },
                {
                    "sent": "So we record the insertion deletion of every triple.",
                    "label": 0
                },
                {
                    "sent": "We keep this problem scrap updated with these auxiliary name graphs, so each of the cervix Zillow graphs is its own graph as well.",
                    "label": 0
                },
                {
                    "sent": "We sort of.",
                    "label": 0
                },
                {
                    "sent": "We formalize things using fairly standard notation, all taken from awareness is great, formal semantics sparkle, and the new Sparkle update semantics.",
                    "label": 0
                },
                {
                    "sent": "I don't know if we really necessary to go over this, but effectively.",
                    "label": 0
                },
                {
                    "sent": "We the key thing we do with sparkles because it guitar.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "All of these other systems your essential gateway into the data is a text editor Anne in a lot of the database work, your gateway is, you know the SQL queries and essentially the nice thing about RDF, which actually you could say is even superior to the SQL work.",
                    "label": 0
                },
                {
                    "sent": "Have a very well structured, formally defined gateway into making any change in the data and that is Sparkle update.",
                    "label": 0
                },
                {
                    "sent": "So all you really have to do to get problems working for this sort of dynamic datasets and sparkle update is you just have to add these provenance graphs.",
                    "label": 0
                },
                {
                    "sent": "Annotations to make the auxiliary graphs with every sort of Sparkle update command.",
                    "label": 0
                },
                {
                    "sent": "You can see that there's actually not that many delete, insert, load, clear, create, drop, and they're all fairly standard formal definitions, so all we really have to do.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is we just have to define for each of these exactly how to create the auxiliary graph so the XR graphs pretty easy.",
                    "label": 0
                },
                {
                    "sent": "We just basically in addition to running your normal Sparkle update command, you just run another Sparkle Update command and this sparkle update updates the provenance graph and so you can sort of see that you can basically take any set of arbitrary sparkle updates using our source.",
                    "label": 0
                },
                {
                    "sent": "I would say formalism is sort of thing.",
                    "label": 0
                },
                {
                    "sent": "In this paper you can expand their sparkle updates to Providence Aware.",
                    "label": 0
                },
                {
                    "sent": "And then create this province graph for each step.",
                    "label": 0
                },
                {
                    "sent": "So we have we will just creates really easy so you have a new graph, you give a new version.",
                    "label": 1
                },
                {
                    "sent": "You've given the current pointer you say hey look, it's a crate type.",
                    "label": 0
                },
                {
                    "sent": "Here's a pointer to output an.",
                    "label": 0
                },
                {
                    "sent": "You had some metadata in and that creates a new sequence of versions and then.",
                    "label": 1
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Also delete them.",
                    "label": 0
                },
                {
                    "sent": "You can clear the graph and it's all sort of done the same way.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Low.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Voting graphs are slightly interesting, but you basically keep that version index intact, right?",
                    "label": 0
                },
                {
                    "sent": "Because you're not actually.",
                    "label": 0
                },
                {
                    "sent": "Killing and creating a new graph, but otherwise is the same and.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The most interesting is probably insert right so inserts the one that mostly we want to track and effectively where we insert.",
                    "label": 0
                },
                {
                    "sent": "The new graph will follow the condition of whatever those new triples are adding.",
                    "label": 0
                },
                {
                    "sent": "We create the new version that you load that you can delete and then just basically add in the input the output, the type insert, and then you keep all the sources.",
                    "label": 0
                },
                {
                    "sent": "In line, so it's effectively exceedingly simple.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Plan for delete.",
                    "label": 0
                },
                {
                    "sent": "You basically just do the reverse.",
                    "label": 0
                },
                {
                    "sent": "When you delete the triples and again you have to keep track of the index, the version number, the input, the output, the type, the sources of data which you're deleting from an whatever meta data which we let be optional, but we're imagining that metadata people will use opium, an W 3 prong of.",
                    "label": 0
                },
                {
                    "sent": "So again, it's really straightforward.",
                    "label": 0
                },
                {
                    "sent": "The nice thing about this method is it works with current systems over current triple stores.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then you know it's again, it's you can you, can we just you can't you have to create a little tiny bit of a vocabulary to manage all of this?",
                    "label": 0
                },
                {
                    "sent": "And we sort of list that out in the paper we can see again.",
                    "label": 0
                },
                {
                    "sent": "It's all fairly trivial.",
                    "label": 0
                },
                {
                    "sent": "Insert, delete, load, clear data and all the interesting stuff is basically keeping a current index to the latest index, which you won't be running your actual off your queries off your live index versions, typing sources and metadata.",
                    "label": 0
                },
                {
                    "sent": "I think so.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So effectively we agree it's a really challenging solution, and I've had a few minutes.",
                    "label": 0
                },
                {
                    "sent": "I'll show you why it's so challenging, but we do think that you know sort of dumb.",
                    "label": 0
                },
                {
                    "sent": "Quick solutions are effective in this space rather than rebuilding sparkle update, you can just basically you spark up to generate even more sparkle updates and keep track of provenance.",
                    "label": 0
                },
                {
                    "sent": "Anna secondary triplestore, where maybe you don't have so many performance concerns and also it's going to get quite big, which we discussed in one minute an the metadata carried by technique is compatible numbers park requires no changes.",
                    "label": 1
                },
                {
                    "sent": "Sparkle update.",
                    "label": 1
                },
                {
                    "sent": "We can use W3C problem.",
                    "label": 1
                },
                {
                    "sent": "We can use existing triple stores.",
                    "label": 0
                },
                {
                    "sent": "Now the problem is which I'll see if I can poke up.",
                    "label": 0
                },
                {
                    "sent": "So I think I have.",
                    "label": 0
                },
                {
                    "sent": "I have a few minutes right?",
                    "label": 0
                },
                {
                    "sent": "OK so I did that a little bit too quick, but the real issues.",
                    "label": 0
                },
                {
                    "sent": "Let's see if I can just get that over.",
                    "label": 0
                },
                {
                    "sent": "So this is some stuff we haven't.",
                    "label": 0
                },
                {
                    "sent": "I'm sorry I have to get out of it.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so this is some stuff we didn't put in the paper.",
                    "label": 0
                },
                {
                    "sent": "Craft space is formal.",
                    "label": 0
                },
                {
                    "sent": "Semantics takes so much time so affectively there's a lot of really hard issues that we're looking for feedback on.",
                    "label": 0
                },
                {
                    "sent": "Because this is the stuff we started implementing.",
                    "label": 0
                },
                {
                    "sent": "So there's a Google funded project at University Edinburgh which is kind of not really running right now, but was running were just looking at all of these Providence or related stuff in terms of looking at SQL XML and then we kind of added at the last minute RDF and I think the problem is if you if you sort of.",
                    "label": 0
                },
                {
                    "sent": "Implement our system in a dumb way.",
                    "label": 0
                },
                {
                    "sent": "We're just always recording every single triple is going in and out, and you're recording all the metadata for it.",
                    "label": 0
                },
                {
                    "sent": "You immediately have.",
                    "label": 0
                },
                {
                    "sent": "I should be fairly obvious or explosion of triples in your province graph, so it's really out of hand.",
                    "label": 1
                },
                {
                    "sent": "So the question is, how can you basically keep this data smaller so you don't have this sort of triple explosion?",
                    "label": 0
                },
                {
                    "sent": "Although we are getting very big triple stores, maybe we can keep all of these huge triples, and there's sort of three or four different standard ways to deal with that.",
                    "label": 0
                },
                {
                    "sent": "One way to deal with it is a transaction based method where you basically don't copy.",
                    "label": 0
                },
                {
                    "sent": "You basically have certain amounts of periods and you only copy the profits after.",
                    "label": 0
                },
                {
                    "sent": "You run through so many operations, so it's a very dumb way, but it works pretty simple, simply an another thing which is quite useful for conserving space is a lot of the triple patterns are repeated, so bit trickier to sort out technically, but you can imagine that, for example, someone concerning some triples.",
                    "label": 0
                },
                {
                    "sent": "Some parts of triples back end, they put them back out.",
                    "label": 0
                },
                {
                    "sent": "They put it back in, and eventually it doesn't.",
                    "label": 0
                },
                {
                    "sent": "You basically can just refer to just those set of triples instead of storing them by value.",
                    "label": 0
                },
                {
                    "sent": "You basically store them via reference.",
                    "label": 0
                },
                {
                    "sent": "Now the problem is that the amount of possible referred to triples is very large, so actually sorting out your references in.",
                    "label": 0
                },
                {
                    "sent": "So just being another sort of terrible problem.",
                    "label": 0
                },
                {
                    "sent": "So right now we generally just sort of do things that dumb way, but we're very interested in future research and how we could actually do this in a more intelligent way in a more optimal way.",
                    "label": 0
                },
                {
                    "sent": "And there's a lot of work around database community.",
                    "label": 0
                },
                {
                    "sent": "We've been running this.",
                    "label": 0
                },
                {
                    "sent": "A few different options and I'll see if I can make it slightly more legible.",
                    "label": 0
                },
                {
                    "sent": "This is a for a poster awhile back, but you could sort of the best graph ever.",
                    "label": 0
                },
                {
                    "sent": "This is more interesting.",
                    "label": 0
                },
                {
                    "sent": "Well now it's not pretty interesting either, but effectively what was happening here?",
                    "label": 0
                },
                {
                    "sent": "You almost can't see it, but you can sort of see that when we're doing transactions over a very small data set, storing things by value.",
                    "label": 0
                },
                {
                    "sent": "That's the blue, which is bearish, basically illegible at the bottom, but it's much smaller than we started storing things by storing the whole triple, which is red and just got this or combinatorial explosion.",
                    "label": 0
                },
                {
                    "sent": "And that really essentially damages the utility of the technique and practice.",
                    "label": 0
                },
                {
                    "sent": "Unless you're capable of dealing with a big triple store.",
                    "label": 0
                },
                {
                    "sent": "Or you have a simply small set of data and you are curated very carefully.",
                    "label": 0
                },
                {
                    "sent": "So if you don't expect your so, I think this method effectively if you wanted to ask me when does this method work, I would say right now it works on large triple stores which change infrequently, or small triple stores which change frequently.",
                    "label": 0
                },
                {
                    "sent": "You don't want to use it on a large triple store which is changing frequently because of this sort of explosion of possible problems you have by storing all the metadata, and that's where there's some really probably interesting work would happen, and optimizing these sort of change of references that point to various triples.",
                    "label": 0
                },
                {
                    "sent": "But that stuff that's quite tricky.",
                    "label": 0
                },
                {
                    "sent": "We haven't got around to doing that yet.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                },
                {
                    "sent": "Did you map your UDP vocabulary to prove?",
                    "label": 0
                },
                {
                    "sent": "Yeah, some of it map so it doesn't?",
                    "label": 0
                },
                {
                    "sent": "I think it's in the paper.",
                    "label": 0
                },
                {
                    "sent": "OK, so that would be cool to do that, and then the second thing is for you should really look at Boris Glavic's work using audit logs and time travel in the relational database rule to track all this 'cause he does this with no overhead at all.",
                    "label": 0
                },
                {
                    "sent": "If you have any time travel based database, I find what do you mean by no overhead.",
                    "label": 0
                },
                {
                    "sent": "So you have to store something, yeah, but they have extremely if you Oracle and Postgres I think implement time travel which is a very fine grained versioning system of your database and it's.",
                    "label": 0
                },
                {
                    "sent": "Oh, so they have it.",
                    "label": 0
                },
                {
                    "sent": "They basically have a problem.",
                    "label": 0
                },
                {
                    "sent": "Is enabled relational database underneath.",
                    "label": 0
                },
                {
                    "sent": "So there is overhead in but the over it's pushed off.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 1
                },
                {
                    "sent": "Just check out this work OK.",
                    "label": 0
                },
                {
                    "sent": "I mean it.",
                    "label": 0
                },
                {
                    "sent": "It just sounds like what's happened is that Oracle just did the snapshot work for you, which is fine.",
                    "label": 0
                },
                {
                    "sent": "And that's cool and we can just take advantage of that by the same point, doesn't it doesn't stop the fact that the snapshot.",
                    "label": 0
                },
                {
                    "sent": "Thanks tricky, so there's probably a lot of hard work by Oracle, and doing the snapshots right if they keep the overhead processing, but this whole version database audit log databases in the relational world have just been study to.",
                    "label": 0
                },
                {
                    "sent": "They said nonsense right?",
                    "label": 0
                },
                {
                    "sent": "So I just take what you have and dump it on there.",
                    "label": 0
                },
                {
                    "sent": "It would be very cool.",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah, I mean all of this work is coming from Boumans work, which I think probably I would assume the Oracle folks use.",
                    "label": 0
                },
                {
                    "sent": "So speaking about 10 years, that branch of research.",
                    "label": 0
                },
                {
                    "sent": "So, have you considered using spin to encode the sparkle update that does the the actual update rather than store 2 snapshots of the underlying triples?",
                    "label": 0
                },
                {
                    "sent": "'cause then you could just have these kind of keyframes where you say well, here was the data, some known point and then hear a bunch of sparkle operations that were performed on it, which sounds very similar to this time travel idea, so you would just kind of say, well, we go back to the closest point and then we can reply if we want the updates to get to some intermediary point which is similar to what Git does, right?",
                    "label": 0
                },
                {
                    "sent": "So it has all these diffs.",
                    "label": 0
                },
                {
                    "sent": "Represent all the source code changes and then if you say to go to a specific tag, you have to go and play back and it essentially placed back the gifts for you.",
                    "label": 0
                },
                {
                    "sent": "So so yeah, so so that's why I'm in transaction.",
                    "label": 0
                },
                {
                    "sent": "You basically you snapshot the actual problem stated in the data at one point and then you keep so you won't be able to get to changes in between your transaction.",
                    "label": 0
                },
                {
                    "sent": "So just again your replay the queries.",
                    "label": 0
                },
                {
                    "sent": "So in our system that's a very good point.",
                    "label": 0
                },
                {
                    "sent": "We don't really know too much spent really using it.",
                    "label": 0
                },
                {
                    "sent": "We were replaying the actual with our transaction so replaying actual sparkle queries.",
                    "label": 0
                },
                {
                    "sent": "We weren't really laying on top of a relational database.",
                    "label": 0
                },
                {
                    "sent": "We were playing them on top of a triple storage, probably part of why it's so messy, so we should look at relational databases and we could snapshot using spin.",
                    "label": 0
                },
                {
                    "sent": "I think that would be fine.",
                    "label": 0
                },
                {
                    "sent": "Maybe it's much faster.",
                    "label": 0
                },
                {
                    "sent": "It would be nice to look at that.",
                    "label": 0
                }
            ]
        }
    }
}