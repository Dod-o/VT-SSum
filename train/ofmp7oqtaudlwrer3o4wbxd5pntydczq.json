{
    "id": "ofmp7oqtaudlwrer3o4wbxd5pntydczq",
    "title": "Learning with Marginalized Corrupted Features",
    "info": {
        "author": [
            "Laurens van der Maaten, Delft University of Technology (TU Delft)"
        ],
        "published": "Aug. 26, 2013",
        "recorded": "July 2013",
        "category": [
            "Top->Computer Science->Compressed Sensing",
            "Top->Computer Science->Machine Learning->Regularization",
            "Top->Computer Science->Optimization Methods",
            "Top->Computer Science->Machine Learning->Kernel Methods->Support Vector Machines"
        ]
    },
    "url": "http://videolectures.net/roks2013_maaten_features/",
    "segmentation": [
        [
            "So in this talk I'll I'll try to explain to you why corruption may be a good thing.",
            "If you're if you're trying to learn.",
            "As you mentioned, this is joint work with Clean Weinberger at Washington University in Saint Louis and two PhD students, Minmin Chen and Stephen Tyree, who did a lot of the experiments."
        ],
        [
            "So in this talk I'm I'm interested in doing classification.",
            "For instance, I want to classify documents by topic.",
            "Or maybe I want to classify documents by by sentiment.",
            "Or maybe I want to classify images by, you know, the objects that are present in these in these images.",
            "A man."
        ],
        [
            "So a standard way of going about and solving this problem is you extract some features from the documents or or the images and these features are called X up in here and you try and learn a classifier based on these features.",
            "You do this in an empirical risk minimization framework.",
            "Better Business.",
            "Alright, so I want to classify documents or images and the way I'm going to do it is I'm going to extract some features called X here.",
            "And then I'm going to train a classifier on these features to predict the corresponding labels.",
            "Why Anna Common way of going about this is by using an empirical risk minimization framework where to find some loss function and you're going to minimize basically the loss function over your annotated training sets.",
            "And so typical loss functions.",
            "We've seen many of them already earlier during the workshop would be maybe logistic loss or hinge loss or quadratic loss.",
            "In the case where you're interested in regression."
        ],
        [
            "Now, a key problem if you if you use this, this empirical risk minimization framework is of course going to be overfitting, right?",
            "You're going to fit well on your training set, but predictions in our test set may not may not be so good, and the typical way of dealing with that is by introducing a regularizer into your model.",
            "Regularizer are here, and so instead of minimizing your empirical loss, you're going to minimize your empirical loss plus some some term that basically measures the complexity of your model.",
            "An common choices for these regularizers are maybe the L2 Norm O'Neill, One norm of the parameter factor.",
            "In this talk.",
            "I'll assume that we're working with linear models just to keep everything easy.",
            "Or maybe if you're if you're beige and you would maybe say, well, this is sort of a map approximation to what you really want to do, which is introduce a prior over parameters W. We're kind of the posterior over these over these parameters, given your annotated training sets, and then make predictions by averaging over his posterior."
        ],
        [
            "Now the key motivation for this work is is that I think that getting the right regularizer is actually tricky.",
            "It's actually a difficult problem, and if we if we look at the workshop also also hear people typically use like L1 and L2 regularizers an you could ask the question well why right?",
            "So if you're if you're beige and then you would say, well, this this prior over models.",
            "This gives you sort of an ability to put in a lot of domain knowledge into your.",
            "Enter your model, but in practice we don't really exploit that that ability right.",
            "In practice, we just go for L1 or L2 or maybe for conjugate priors if we're if we're Beijing and sort of the motivation that we used to choose.",
            "These regularizers are sort of computational convenience, right?",
            "We like a 1L2 because their convex, or maybe because we can prove stuff about it and we like on you get priors because their posterior remains in the same in the same family.",
            "So inferences, tractable.",
            "Um and and with the question if it is this, is this the right way of going about it, and in particular what I think?",
            "Well I can only speak for myself, but I have pretty bad intuitions about models or model parameters.",
            "I have a pretty bad intuition for, you know, this direction of W. That's a good direction apriori in this direction is a is a bad direction, and I think this is true for many many practitioners.",
            "The observation that sort of sort of the motivation underlying this work is that practitioners may have.",
            "May not understand their model parameters so well, but they may have a good understanding of what their data is, how their data is generated, or what they what they can do with their data."
        ],
        [
            "And so the question we ask in his work is basically instead of doing regularization by restrictive model parameters, can we incorporate knowledge about the data instead to do the regularization?"
        ],
        [
            "So let me let me give you an example.",
            "So let's say we're classifying movie reviews into positive or negative reviews.",
            "So here we have four reviews and we can see that this is a negative review because the word boring appears.",
            "This one is clearly a very positive review.",
            "It was a great movie.",
            "That's what it says.",
            "And so so the question is what?",
            "Well how do we see it?",
            "Or can we do something with this data?",
            "In such a way that.",
            "What can?"
        ],
        [
            "We can we somehow basically perturber data in such a way that we were not really going to change the label of this data.",
            "So one thing you could say is I'm going to make a bunch of copies of my of my data and I'm going to remove some random words.",
            "And now if you look at these mover reviews in the middle and on the right, you would probably still be able to tell that you know this is a positive review and this is a negative review because this has the word creating.",
            "It's for instance.",
            "And So what you have is.",
            "As a as a practitioner is you have some sort of idea on how you can corrupt how you can perturb your data in such a way that the label that is associated with the data doesn't change.",
            "And that intuition we're going to try and exploit.",
            "So this is what I call regularization by corruption here."
        ],
        [
            "So the key idea of this work is we're going to define corruptions, that of which we assume that they leave the label invariants, and then we're basically going to use this disk corruption.",
            "So generate additional data, and if we train on such additional data, we basically get robustness to this type of corruption through these perturbations, right?",
            "And search search robustness, that's very closely related to regularization, because if we basically what regularization means is that you want to be sure that if you sort of slightly perturb your data.",
            "That your prediction will not change drastically right?",
            "Because if it does, then you've overfitted.",
            "And in particular, we show is that you can do this very efficiently by basically marginalizing over corruptions of the data."
        ],
        [
            "So let's try and formalize this a little bit.",
            "So what we need is we need to define a corrupting distribution.",
            "So some model that tells us that basically takes as input a real observation X real sample from the data distribution, and that produces some corrupted version XX~ and in such a way that we believe that the label of the of basically Excel there will be the same as the label off of X, and the only assumption we're going to make is that the corruption model is factorizing across features across dimensions, right?",
            "So that's the product.",
            "Here we needed in order to basically remain tractable later on.",
            "I'm So what?",
            "What kind of corruption models can you then think about?",
            "Well, of course you can think about Gaussian noise that would make it maybe sort of your first pick.",
            "This is what you use and I don't know in parts and density estimation or things like that.",
            "But we've also looked at other models, for instance blank out noise, which is a noise model where you say with probability Q. I'm going to remove my feature.",
            "I'm going to set it to zero and would probably 1 -- Q. I'm going to keep the original feature.",
            "So this basically corresponds to randomly removing words from documents, but you can also think about, for instance posts on corruption.",
            "So if your input features had the form of basically word counts, you could say, well, it doesn't really matter whether I see the word amazing 7 times or five times, right?",
            "It's still an indicator of a positive review.",
            "So what I could say is, well, maybe I use this seven here as a rate in a person distribution.",
            "I'm going to sample from this person distribution to generate extra data."
        ],
        [
            "Now, how can you use such a corruption distribution?",
            "Well, of course a simple approach would be you just sample from it, right?",
            "You just sample from the corrupting distribution.",
            "This gives you additional samples.",
            "I column X up an M here and you're basically going to minimize your loss over these corrupted examples as well.",
            "And this is what people do, for instance in deep learning.",
            "People like to do this.",
            "Also an online learning it happens in computer vision.",
            "People do this where they basically sort of do small affine transformations on their other images and train on those.",
            "So this is an approach that has been that has been used and that works or can work, but it has one sort of downside, which is that you're basically increasing the size of your training sets, right?",
            "So it's becoming computationally more expensive to do the training.",
            "So the observation we make is that basically only."
        ],
        [
            "Happens unless."
        ],
        [
            "We make M so the number of corrupted examples that we get from our corrupting distribution.",
            "Unless we make that go to Infinity because in that case what we get is basically not an average over the corrupted examples, but we get an expected value, right?",
            "So what we get?",
            "And this is what we refer to as marginalized.",
            "Corrupted Features is an expected value of the loss function of interest under the correct.",
            "Another question is, well when can we?",
            "When can we actually compute this thing right?",
            "Because if we can compute this thing then we can very efficiently work with lots of.",
            "Corrupted data, or actually, you know, Infinites corrupted data."
        ],
        [
            "So let's look at some examples.",
            "So very simple loss would be quadratic loss, right?",
            "So we're interested in the expected value of the quadratic loss under a corrupting distribution an if you work that out, you basically get the following form where you can see that all you need to be able to compute is basically the mean and the variance of X of your features under the corrupting distribution.",
            "And you can imagine that this is possible for a wide range of models.",
            "The nice thing here is actually that your if you if you look at this form, you can see that you still have a quadratic function in W, which means that this function is still convex and you also still have an optimal solution that you can compute in closed form right in a very similar way should do will do regular linear least squares."
        ],
        [
            "Now, if you workout the means and variances for some of these, these corrupting distributions that we've looked at, you can basically plug those in and you can find interesting special cases.",
            "So for instance, if you do Gaussian corruption around your data and then minimize basically expect it's quadratic loss, what you get is this.",
            "So this you can basically regularizes recognizes standard quadratic loss and here you see an L2 regularizer.",
            "Where does Sigma squared is basically the variance of the of the Gaussian.",
            "So in that case you recover rich regression.",
            "What's interesting, when I first looked at this, I was expecting when I would use Laplace noise that it would recover Lesu, but that doesn't really happen.",
            "If I if I use Laplace noise then basically also get rich regression except the Sigma squared here will be replaced by two left that squared.",
            "So, OK, that's maybe not so interesting, right?",
            "So I mean, it's it's at best sort of a, you know, a different way of thinking about what Ridge regression is doing."
        ],
        [
            "Let's move on to some more interesting losses.",
            "So let's look at exponential loss.",
            "For instance, it is what you use when you do add a boost, for instance.",
            "So again, we're interested in the expected value under the corrupting distribution in this case of the exponential loss.",
            "And now remember that we assume that this thing that is corrupting distribution that it factorized across dimensions, right?",
            "And as a result we can rewrite this as a product over all features.",
            "Overall dimensions of these these expectations of these individual terms.",
            "And now this is interesting, because this you can recognize as a product of moment generating functions, right?",
            "This is exactly a moment generating function where T is equal to minus y * W. So what this means is that for any model for which we can derive moment generating function or that has such a function, we can actually workout this expected exponential loss, right?",
            "So we can just go and we."
        ],
        [
            "Ipedia and we can look up for which distributions is works.",
            "And it turns out to be the natural exponential family, which is still a fairly large family of distributions."
        ],
        [
            "Now, if you if you go and work this out.",
            "So for instance for blank out you can get interesting interpretations.",
            "So for instance if you do this blank out corruption so where you randomly remove features with probability Q which what you end up with is with the formulation that looks something like this.",
            "What you can see here."
        ],
        [
            "Is here you see.",
            "So this is an example where we only had two input features.",
            "Basically what you see here is basically the exponential loss on just the first feature."
        ],
        [
            "The exponential loss on some other feature subset in this case, just the second feature."
        ],
        [
            "And here you get basically the exponential loss on the full feature sets, so and these are sort of you basically take away that some of these right?",
            "So what you're essentially doing issue sort of training an ensemble of models on different feature subsets.",
            "Actually on all 2 to the power of the possible subsets, but you're doing a bit of weight sharing there, right?",
            "Like all the weights in these innocent sample has to be the same and you sort of train it simultaneously.",
            "Which it also sees that there is no regularizer anymore, right?",
            "There's not sort of an additional term that penalize model complexity.",
            "The regularization is going sort of through different sample interpretation through this wage here.",
            "I also hear this this MTF exponential loss.",
            "Well, I mean, it's an expected value of a convex function, so it's going to remain convex, right?",
            "It's a convex combination of convex functions."
        ],
        [
            "So let's look at logistic loss, because in practice people so don't really use exponential loss.",
            "Well, in logistic loss it gets a bit harder, writes this expected value of lock one plus, and then basically exponential loss.",
            "We don't really know how to deal with the expected value of the lock here, but what we can do is we can upper bound this quantity using Jensen's inequality, which basically allows us to pull the expectation in words and then what we get here again is the expected value of the exponential loss, right?",
            "So again, we end up with this product over.",
            "Moment generating functions, and if you think about this model in terms of sort of a small base network, then it turns out that this is actually a very sensible or bound to be looking at.",
            "The only downside of the upper bound is that it's not always convex anymore.",
            "Depends a bit on the corrupting distribution that you use, whether convex these maintains."
        ],
        [
            "Alright, so So what do you need to do in practice when you want to sort of try and regularize models by MCF?",
            "Well you need to choose a loss.",
            "You need to define some corrupting distribution of which you think that if you do these corruptions to your data, they won't change the label and then you basically workout the expected value and this gives you a new loss function which are called the MCF loss here."
        ],
        [
            "So let's see if this works.",
            "So we did three sets of experiments, so a document classification experiments on bag of words, features and image classification experiments on beneficial words, and we did experiments in a domain shift scenario which is called nightmare.",
            "at Test time.",
            "We're basically a test, I'm randomly features or observed.",
            "And what I want you to keep in mind when it presented results is that in all our predictors we also add in L2 regularization and we sort of properly cross validate over the L2 regularization parameter."
        ],
        [
            "So the first experiment is document classification experiments where we look at three different datasets and all these datasets have in the order of 20,000 features, so their bag of words, features, and about 6000 training examples, and we look at two different corrupting distributions.",
            "So the first distribution we look at is this distribution, where we would probably take you basically remove words from the document altogether, and the second corrupting distributions.",
            "Is this person distribution where we basically use the word count as rates.",
            "In a person distribution and this one is interesting because it doesn't have any hyperparameters, right?",
            "There's nothing you can you can set here.",
            "Basically, because the variance of a person distribution is equal to its mean.",
            "So then these."
        ],
        [
            "The results that we get.",
            "So on the Y axis here you see the classification error, so lower is better, and on the X axis you see the amount of blank out corruption.",
            "So basically this value of Q in."
        ],
        [
            "In this previous slides."
        ],
        [
            "And so the the dashed lines here are the results we obtained with when we do classification with posts on corruption and the solid lines.",
            "Here are the results that we obtained when we use blank out corruption and because we also do cross validation over L2 regularization.",
            "Basically the case where Q is 0.",
            "So these little squares here they correspond to sort of the standard case right where you only have L2 regularization, right?",
            "So this would be a properly regularised.",
            "L2L2 regularizer logistic regression.",
            "And So what you see is that as you add sort of his blank out noise that you actually get improved improved performance rights and actually quite often the the optimal blank out rates are very high, right?",
            "So at this point corresponds to is.",
            "Basically we made infinitely many copies of our data.",
            "We set 70% of the features to zero, and then we train our model on that.",
            "What's also interesting is that if you look at the optimal value of the L2 regularization parameter in this case is always going to be 0.",
            "Right, so the regularization is purely coming from the blank out.",
            "It doesn't need L2 regularization anymore.",
            "Also, for the persona you can see that you can get quite nice improvements.",
            "It's not everywhere, but in quite a few datasets you do get improvements which is quite nice since you don't have a an extra sort of parameter to optimize over."
        ],
        [
            "So one question that's interesting is of course, well.",
            "How does this compare to explicit sampling, right?",
            "How does it compare to explicitly gathering samples from your sampling from your corrupting distribution, and then just training on a larger datasets?",
            "So we did a little experiment where here on the X axis you see the number of corrupted copies that we sample from.",
            "In this case a blank out distribution, and again here you see the classification error and what you see is that if you are sort of.",
            "If you sample from this corrupting distribution and you get more samples than you ever indeed starts coming down, but it never quite get to get Studium CF case where you basically have infinite samples, you have to keep in mind of course, that that training this model is 256 times more expensive than training this mode right because you just have much more data trainer."
        ],
        [
            "The second experiment was an image classification experiments where on the data set goal to see for 10 datasets.",
            "So this is a data set of 32 by 32 pixel images and we built a sort of standard bag of visual words feature representation that's commonly used in computer vision, and we train models on these images to basically predict these 10 classes again using MCF or without using MCF, right?",
            "So only L2 regularization?",
            "And then we also use for so MCF and Blank out MCF and also here we can in particular, in the case of logistic regression we can get quite nice performance improvements."
        ],
        [
            "The third experiment we looked at is what is called a nightmare.",
            "At this time scenario.",
            "So in this scenario what we get is we have a type of domain shift where at training time we basically see the full feature set.",
            "So in this case the features are pixels of updated images, but at Test time randomly some of the features will be an observed in this quick kind of happened.",
            "For instance, if you're dealing with a lot of sensors and sensors breakdown without telling you or it also happens a lot in sort of distributed computing environments where you send out a lot of feature extraction tasks and only some of them will run.",
            "Sort of randomly be finished in time, but I just want, right?",
            "So what we do here is we train classifiers on the original full feature set.",
            "So in the full digit images, but then we go and and perform classification on these perturbed these these images in which random subsets over features are an observed."
        ],
        [
            "So here are the results we got.",
            "So again on the Y axis we have a classification error, so lower is better, and on the X axis now we have the amount of test corruption right?",
            "So the amount of sort of the percentage of features that is randomly delete it at at Test time and so these three lines here are sort of your standard L2 regularizer classifiers.",
            "Ann was expected they get much worse really, really quickly, right?",
            "Because they're?",
            "I mean they're tested on a completely different distribution is what they were trained on.",
            "The black line here is this medical def drop, which is.",
            "Or was the state of the arts in this in this learning scenario until now it minimizes a type of worst case hinge loss, so it's a very complex sort of minimax from formulation, and the three solid lines here are the results you get with MCF in particular.",
            "So this is the one with logistic loss, which I guess is the most reasonable classification loss and you can see that it performs quite well even for pretty high levels of test corruption, right?",
            "So if we remove 70% of our features at Test time?",
            "And we still get a performance of like 15% error even though we started with 7% error on the full feature sets."
        ],
        [
            "So it's a conclude, I hope that I've maybe convince you that adding corrupted examples to your training data could be a good way to try and regularize your predictors, and MCF can make this sufficient for a range of models and a range of corrupting distributions, and that this may improve your results in certain learning settings, and in particular in learning settings where you understand a little bit about how your data works, and in particular where that happens, is in sort of domain shift.",
            "A domain shift scenarios where you just know that your test distribution is going to be very different from your training distribution and you can set your corrupting distribution in such a way to sort of reflect this changing between source and target domain."
        ],
        [
            "So these are my my coauthors.",
            "There's code online.",
            "You can also find the paper on my websites and with that.",
            "Thank you very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in this talk I'll I'll try to explain to you why corruption may be a good thing.",
                    "label": 0
                },
                {
                    "sent": "If you're if you're trying to learn.",
                    "label": 0
                },
                {
                    "sent": "As you mentioned, this is joint work with Clean Weinberger at Washington University in Saint Louis and two PhD students, Minmin Chen and Stephen Tyree, who did a lot of the experiments.",
                    "label": 1
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in this talk I'm I'm interested in doing classification.",
                    "label": 0
                },
                {
                    "sent": "For instance, I want to classify documents by topic.",
                    "label": 1
                },
                {
                    "sent": "Or maybe I want to classify documents by by sentiment.",
                    "label": 0
                },
                {
                    "sent": "Or maybe I want to classify images by, you know, the objects that are present in these in these images.",
                    "label": 0
                },
                {
                    "sent": "A man.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So a standard way of going about and solving this problem is you extract some features from the documents or or the images and these features are called X up in here and you try and learn a classifier based on these features.",
                    "label": 0
                },
                {
                    "sent": "You do this in an empirical risk minimization framework.",
                    "label": 1
                },
                {
                    "sent": "Better Business.",
                    "label": 0
                },
                {
                    "sent": "Alright, so I want to classify documents or images and the way I'm going to do it is I'm going to extract some features called X here.",
                    "label": 0
                },
                {
                    "sent": "And then I'm going to train a classifier on these features to predict the corresponding labels.",
                    "label": 0
                },
                {
                    "sent": "Why Anna Common way of going about this is by using an empirical risk minimization framework where to find some loss function and you're going to minimize basically the loss function over your annotated training sets.",
                    "label": 0
                },
                {
                    "sent": "And so typical loss functions.",
                    "label": 0
                },
                {
                    "sent": "We've seen many of them already earlier during the workshop would be maybe logistic loss or hinge loss or quadratic loss.",
                    "label": 0
                },
                {
                    "sent": "In the case where you're interested in regression.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now, a key problem if you if you use this, this empirical risk minimization framework is of course going to be overfitting, right?",
                    "label": 0
                },
                {
                    "sent": "You're going to fit well on your training set, but predictions in our test set may not may not be so good, and the typical way of dealing with that is by introducing a regularizer into your model.",
                    "label": 0
                },
                {
                    "sent": "Regularizer are here, and so instead of minimizing your empirical loss, you're going to minimize your empirical loss plus some some term that basically measures the complexity of your model.",
                    "label": 0
                },
                {
                    "sent": "An common choices for these regularizers are maybe the L2 Norm O'Neill, One norm of the parameter factor.",
                    "label": 0
                },
                {
                    "sent": "In this talk.",
                    "label": 0
                },
                {
                    "sent": "I'll assume that we're working with linear models just to keep everything easy.",
                    "label": 0
                },
                {
                    "sent": "Or maybe if you're if you're beige and you would maybe say, well, this is sort of a map approximation to what you really want to do, which is introduce a prior over parameters W. We're kind of the posterior over these over these parameters, given your annotated training sets, and then make predictions by averaging over his posterior.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now the key motivation for this work is is that I think that getting the right regularizer is actually tricky.",
                    "label": 1
                },
                {
                    "sent": "It's actually a difficult problem, and if we if we look at the workshop also also hear people typically use like L1 and L2 regularizers an you could ask the question well why right?",
                    "label": 0
                },
                {
                    "sent": "So if you're if you're beige and then you would say, well, this this prior over models.",
                    "label": 0
                },
                {
                    "sent": "This gives you sort of an ability to put in a lot of domain knowledge into your.",
                    "label": 0
                },
                {
                    "sent": "Enter your model, but in practice we don't really exploit that that ability right.",
                    "label": 0
                },
                {
                    "sent": "In practice, we just go for L1 or L2 or maybe for conjugate priors if we're if we're Beijing and sort of the motivation that we used to choose.",
                    "label": 0
                },
                {
                    "sent": "These regularizers are sort of computational convenience, right?",
                    "label": 0
                },
                {
                    "sent": "We like a 1L2 because their convex, or maybe because we can prove stuff about it and we like on you get priors because their posterior remains in the same in the same family.",
                    "label": 0
                },
                {
                    "sent": "So inferences, tractable.",
                    "label": 0
                },
                {
                    "sent": "Um and and with the question if it is this, is this the right way of going about it, and in particular what I think?",
                    "label": 0
                },
                {
                    "sent": "Well I can only speak for myself, but I have pretty bad intuitions about models or model parameters.",
                    "label": 0
                },
                {
                    "sent": "I have a pretty bad intuition for, you know, this direction of W. That's a good direction apriori in this direction is a is a bad direction, and I think this is true for many many practitioners.",
                    "label": 0
                },
                {
                    "sent": "The observation that sort of sort of the motivation underlying this work is that practitioners may have.",
                    "label": 0
                },
                {
                    "sent": "May not understand their model parameters so well, but they may have a good understanding of what their data is, how their data is generated, or what they what they can do with their data.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so the question we ask in his work is basically instead of doing regularization by restrictive model parameters, can we incorporate knowledge about the data instead to do the regularization?",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let me let me give you an example.",
                    "label": 0
                },
                {
                    "sent": "So let's say we're classifying movie reviews into positive or negative reviews.",
                    "label": 1
                },
                {
                    "sent": "So here we have four reviews and we can see that this is a negative review because the word boring appears.",
                    "label": 0
                },
                {
                    "sent": "This one is clearly a very positive review.",
                    "label": 0
                },
                {
                    "sent": "It was a great movie.",
                    "label": 0
                },
                {
                    "sent": "That's what it says.",
                    "label": 0
                },
                {
                    "sent": "And so so the question is what?",
                    "label": 0
                },
                {
                    "sent": "Well how do we see it?",
                    "label": 0
                },
                {
                    "sent": "Or can we do something with this data?",
                    "label": 0
                },
                {
                    "sent": "In such a way that.",
                    "label": 0
                },
                {
                    "sent": "What can?",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We can we somehow basically perturber data in such a way that we were not really going to change the label of this data.",
                    "label": 0
                },
                {
                    "sent": "So one thing you could say is I'm going to make a bunch of copies of my of my data and I'm going to remove some random words.",
                    "label": 0
                },
                {
                    "sent": "And now if you look at these mover reviews in the middle and on the right, you would probably still be able to tell that you know this is a positive review and this is a negative review because this has the word creating.",
                    "label": 0
                },
                {
                    "sent": "It's for instance.",
                    "label": 0
                },
                {
                    "sent": "And So what you have is.",
                    "label": 0
                },
                {
                    "sent": "As a as a practitioner is you have some sort of idea on how you can corrupt how you can perturb your data in such a way that the label that is associated with the data doesn't change.",
                    "label": 0
                },
                {
                    "sent": "And that intuition we're going to try and exploit.",
                    "label": 0
                },
                {
                    "sent": "So this is what I call regularization by corruption here.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the key idea of this work is we're going to define corruptions, that of which we assume that they leave the label invariants, and then we're basically going to use this disk corruption.",
                    "label": 0
                },
                {
                    "sent": "So generate additional data, and if we train on such additional data, we basically get robustness to this type of corruption through these perturbations, right?",
                    "label": 0
                },
                {
                    "sent": "And search search robustness, that's very closely related to regularization, because if we basically what regularization means is that you want to be sure that if you sort of slightly perturb your data.",
                    "label": 0
                },
                {
                    "sent": "That your prediction will not change drastically right?",
                    "label": 0
                },
                {
                    "sent": "Because if it does, then you've overfitted.",
                    "label": 0
                },
                {
                    "sent": "And in particular, we show is that you can do this very efficiently by basically marginalizing over corruptions of the data.",
                    "label": 1
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's try and formalize this a little bit.",
                    "label": 0
                },
                {
                    "sent": "So what we need is we need to define a corrupting distribution.",
                    "label": 1
                },
                {
                    "sent": "So some model that tells us that basically takes as input a real observation X real sample from the data distribution, and that produces some corrupted version XX~ and in such a way that we believe that the label of the of basically Excel there will be the same as the label off of X, and the only assumption we're going to make is that the corruption model is factorizing across features across dimensions, right?",
                    "label": 1
                },
                {
                    "sent": "So that's the product.",
                    "label": 0
                },
                {
                    "sent": "Here we needed in order to basically remain tractable later on.",
                    "label": 0
                },
                {
                    "sent": "I'm So what?",
                    "label": 1
                },
                {
                    "sent": "What kind of corruption models can you then think about?",
                    "label": 0
                },
                {
                    "sent": "Well, of course you can think about Gaussian noise that would make it maybe sort of your first pick.",
                    "label": 0
                },
                {
                    "sent": "This is what you use and I don't know in parts and density estimation or things like that.",
                    "label": 0
                },
                {
                    "sent": "But we've also looked at other models, for instance blank out noise, which is a noise model where you say with probability Q. I'm going to remove my feature.",
                    "label": 0
                },
                {
                    "sent": "I'm going to set it to zero and would probably 1 -- Q. I'm going to keep the original feature.",
                    "label": 0
                },
                {
                    "sent": "So this basically corresponds to randomly removing words from documents, but you can also think about, for instance posts on corruption.",
                    "label": 0
                },
                {
                    "sent": "So if your input features had the form of basically word counts, you could say, well, it doesn't really matter whether I see the word amazing 7 times or five times, right?",
                    "label": 0
                },
                {
                    "sent": "It's still an indicator of a positive review.",
                    "label": 0
                },
                {
                    "sent": "So what I could say is, well, maybe I use this seven here as a rate in a person distribution.",
                    "label": 0
                },
                {
                    "sent": "I'm going to sample from this person distribution to generate extra data.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now, how can you use such a corruption distribution?",
                    "label": 0
                },
                {
                    "sent": "Well, of course a simple approach would be you just sample from it, right?",
                    "label": 0
                },
                {
                    "sent": "You just sample from the corrupting distribution.",
                    "label": 0
                },
                {
                    "sent": "This gives you additional samples.",
                    "label": 0
                },
                {
                    "sent": "I column X up an M here and you're basically going to minimize your loss over these corrupted examples as well.",
                    "label": 0
                },
                {
                    "sent": "And this is what people do, for instance in deep learning.",
                    "label": 0
                },
                {
                    "sent": "People like to do this.",
                    "label": 0
                },
                {
                    "sent": "Also an online learning it happens in computer vision.",
                    "label": 0
                },
                {
                    "sent": "People do this where they basically sort of do small affine transformations on their other images and train on those.",
                    "label": 0
                },
                {
                    "sent": "So this is an approach that has been that has been used and that works or can work, but it has one sort of downside, which is that you're basically increasing the size of your training sets, right?",
                    "label": 0
                },
                {
                    "sent": "So it's becoming computationally more expensive to do the training.",
                    "label": 0
                },
                {
                    "sent": "So the observation we make is that basically only.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Happens unless.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We make M so the number of corrupted examples that we get from our corrupting distribution.",
                    "label": 0
                },
                {
                    "sent": "Unless we make that go to Infinity because in that case what we get is basically not an average over the corrupted examples, but we get an expected value, right?",
                    "label": 0
                },
                {
                    "sent": "So what we get?",
                    "label": 0
                },
                {
                    "sent": "And this is what we refer to as marginalized.",
                    "label": 0
                },
                {
                    "sent": "Corrupted Features is an expected value of the loss function of interest under the correct.",
                    "label": 1
                },
                {
                    "sent": "Another question is, well when can we?",
                    "label": 0
                },
                {
                    "sent": "When can we actually compute this thing right?",
                    "label": 0
                },
                {
                    "sent": "Because if we can compute this thing then we can very efficiently work with lots of.",
                    "label": 0
                },
                {
                    "sent": "Corrupted data, or actually, you know, Infinites corrupted data.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's look at some examples.",
                    "label": 0
                },
                {
                    "sent": "So very simple loss would be quadratic loss, right?",
                    "label": 0
                },
                {
                    "sent": "So we're interested in the expected value of the quadratic loss under a corrupting distribution an if you work that out, you basically get the following form where you can see that all you need to be able to compute is basically the mean and the variance of X of your features under the corrupting distribution.",
                    "label": 1
                },
                {
                    "sent": "And you can imagine that this is possible for a wide range of models.",
                    "label": 0
                },
                {
                    "sent": "The nice thing here is actually that your if you if you look at this form, you can see that you still have a quadratic function in W, which means that this function is still convex and you also still have an optimal solution that you can compute in closed form right in a very similar way should do will do regular linear least squares.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now, if you workout the means and variances for some of these, these corrupting distributions that we've looked at, you can basically plug those in and you can find interesting special cases.",
                    "label": 0
                },
                {
                    "sent": "So for instance, if you do Gaussian corruption around your data and then minimize basically expect it's quadratic loss, what you get is this.",
                    "label": 0
                },
                {
                    "sent": "So this you can basically regularizes recognizes standard quadratic loss and here you see an L2 regularizer.",
                    "label": 0
                },
                {
                    "sent": "Where does Sigma squared is basically the variance of the of the Gaussian.",
                    "label": 0
                },
                {
                    "sent": "So in that case you recover rich regression.",
                    "label": 0
                },
                {
                    "sent": "What's interesting, when I first looked at this, I was expecting when I would use Laplace noise that it would recover Lesu, but that doesn't really happen.",
                    "label": 0
                },
                {
                    "sent": "If I if I use Laplace noise then basically also get rich regression except the Sigma squared here will be replaced by two left that squared.",
                    "label": 0
                },
                {
                    "sent": "So, OK, that's maybe not so interesting, right?",
                    "label": 0
                },
                {
                    "sent": "So I mean, it's it's at best sort of a, you know, a different way of thinking about what Ridge regression is doing.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let's move on to some more interesting losses.",
                    "label": 0
                },
                {
                    "sent": "So let's look at exponential loss.",
                    "label": 1
                },
                {
                    "sent": "For instance, it is what you use when you do add a boost, for instance.",
                    "label": 0
                },
                {
                    "sent": "So again, we're interested in the expected value under the corrupting distribution in this case of the exponential loss.",
                    "label": 0
                },
                {
                    "sent": "And now remember that we assume that this thing that is corrupting distribution that it factorized across dimensions, right?",
                    "label": 0
                },
                {
                    "sent": "And as a result we can rewrite this as a product over all features.",
                    "label": 0
                },
                {
                    "sent": "Overall dimensions of these these expectations of these individual terms.",
                    "label": 0
                },
                {
                    "sent": "And now this is interesting, because this you can recognize as a product of moment generating functions, right?",
                    "label": 1
                },
                {
                    "sent": "This is exactly a moment generating function where T is equal to minus y * W. So what this means is that for any model for which we can derive moment generating function or that has such a function, we can actually workout this expected exponential loss, right?",
                    "label": 0
                },
                {
                    "sent": "So we can just go and we.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Ipedia and we can look up for which distributions is works.",
                    "label": 0
                },
                {
                    "sent": "And it turns out to be the natural exponential family, which is still a fairly large family of distributions.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now, if you if you go and work this out.",
                    "label": 0
                },
                {
                    "sent": "So for instance for blank out you can get interesting interpretations.",
                    "label": 0
                },
                {
                    "sent": "So for instance if you do this blank out corruption so where you randomly remove features with probability Q which what you end up with is with the formulation that looks something like this.",
                    "label": 0
                },
                {
                    "sent": "What you can see here.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is here you see.",
                    "label": 0
                },
                {
                    "sent": "So this is an example where we only had two input features.",
                    "label": 1
                },
                {
                    "sent": "Basically what you see here is basically the exponential loss on just the first feature.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The exponential loss on some other feature subset in this case, just the second feature.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And here you get basically the exponential loss on the full feature sets, so and these are sort of you basically take away that some of these right?",
                    "label": 1
                },
                {
                    "sent": "So what you're essentially doing issue sort of training an ensemble of models on different feature subsets.",
                    "label": 0
                },
                {
                    "sent": "Actually on all 2 to the power of the possible subsets, but you're doing a bit of weight sharing there, right?",
                    "label": 0
                },
                {
                    "sent": "Like all the weights in these innocent sample has to be the same and you sort of train it simultaneously.",
                    "label": 0
                },
                {
                    "sent": "Which it also sees that there is no regularizer anymore, right?",
                    "label": 0
                },
                {
                    "sent": "There's not sort of an additional term that penalize model complexity.",
                    "label": 0
                },
                {
                    "sent": "The regularization is going sort of through different sample interpretation through this wage here.",
                    "label": 0
                },
                {
                    "sent": "I also hear this this MTF exponential loss.",
                    "label": 0
                },
                {
                    "sent": "Well, I mean, it's an expected value of a convex function, so it's going to remain convex, right?",
                    "label": 0
                },
                {
                    "sent": "It's a convex combination of convex functions.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's look at logistic loss, because in practice people so don't really use exponential loss.",
                    "label": 1
                },
                {
                    "sent": "Well, in logistic loss it gets a bit harder, writes this expected value of lock one plus, and then basically exponential loss.",
                    "label": 0
                },
                {
                    "sent": "We don't really know how to deal with the expected value of the lock here, but what we can do is we can upper bound this quantity using Jensen's inequality, which basically allows us to pull the expectation in words and then what we get here again is the expected value of the exponential loss, right?",
                    "label": 0
                },
                {
                    "sent": "So again, we end up with this product over.",
                    "label": 0
                },
                {
                    "sent": "Moment generating functions, and if you think about this model in terms of sort of a small base network, then it turns out that this is actually a very sensible or bound to be looking at.",
                    "label": 0
                },
                {
                    "sent": "The only downside of the upper bound is that it's not always convex anymore.",
                    "label": 1
                },
                {
                    "sent": "Depends a bit on the corrupting distribution that you use, whether convex these maintains.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so So what do you need to do in practice when you want to sort of try and regularize models by MCF?",
                    "label": 0
                },
                {
                    "sent": "Well you need to choose a loss.",
                    "label": 0
                },
                {
                    "sent": "You need to define some corrupting distribution of which you think that if you do these corruptions to your data, they won't change the label and then you basically workout the expected value and this gives you a new loss function which are called the MCF loss here.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's see if this works.",
                    "label": 0
                },
                {
                    "sent": "So we did three sets of experiments, so a document classification experiments on bag of words, features and image classification experiments on beneficial words, and we did experiments in a domain shift scenario which is called nightmare.",
                    "label": 1
                },
                {
                    "sent": "at Test time.",
                    "label": 0
                },
                {
                    "sent": "We're basically a test, I'm randomly features or observed.",
                    "label": 0
                },
                {
                    "sent": "And what I want you to keep in mind when it presented results is that in all our predictors we also add in L2 regularization and we sort of properly cross validate over the L2 regularization parameter.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the first experiment is document classification experiments where we look at three different datasets and all these datasets have in the order of 20,000 features, so their bag of words, features, and about 6000 training examples, and we look at two different corrupting distributions.",
                    "label": 1
                },
                {
                    "sent": "So the first distribution we look at is this distribution, where we would probably take you basically remove words from the document altogether, and the second corrupting distributions.",
                    "label": 0
                },
                {
                    "sent": "Is this person distribution where we basically use the word count as rates.",
                    "label": 0
                },
                {
                    "sent": "In a person distribution and this one is interesting because it doesn't have any hyperparameters, right?",
                    "label": 0
                },
                {
                    "sent": "There's nothing you can you can set here.",
                    "label": 0
                },
                {
                    "sent": "Basically, because the variance of a person distribution is equal to its mean.",
                    "label": 0
                },
                {
                    "sent": "So then these.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The results that we get.",
                    "label": 0
                },
                {
                    "sent": "So on the Y axis here you see the classification error, so lower is better, and on the X axis you see the amount of blank out corruption.",
                    "label": 0
                },
                {
                    "sent": "So basically this value of Q in.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In this previous slides.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so the the dashed lines here are the results we obtained with when we do classification with posts on corruption and the solid lines.",
                    "label": 0
                },
                {
                    "sent": "Here are the results that we obtained when we use blank out corruption and because we also do cross validation over L2 regularization.",
                    "label": 0
                },
                {
                    "sent": "Basically the case where Q is 0.",
                    "label": 0
                },
                {
                    "sent": "So these little squares here they correspond to sort of the standard case right where you only have L2 regularization, right?",
                    "label": 0
                },
                {
                    "sent": "So this would be a properly regularised.",
                    "label": 0
                },
                {
                    "sent": "L2L2 regularizer logistic regression.",
                    "label": 0
                },
                {
                    "sent": "And So what you see is that as you add sort of his blank out noise that you actually get improved improved performance rights and actually quite often the the optimal blank out rates are very high, right?",
                    "label": 0
                },
                {
                    "sent": "So at this point corresponds to is.",
                    "label": 0
                },
                {
                    "sent": "Basically we made infinitely many copies of our data.",
                    "label": 0
                },
                {
                    "sent": "We set 70% of the features to zero, and then we train our model on that.",
                    "label": 0
                },
                {
                    "sent": "What's also interesting is that if you look at the optimal value of the L2 regularization parameter in this case is always going to be 0.",
                    "label": 0
                },
                {
                    "sent": "Right, so the regularization is purely coming from the blank out.",
                    "label": 0
                },
                {
                    "sent": "It doesn't need L2 regularization anymore.",
                    "label": 0
                },
                {
                    "sent": "Also, for the persona you can see that you can get quite nice improvements.",
                    "label": 0
                },
                {
                    "sent": "It's not everywhere, but in quite a few datasets you do get improvements which is quite nice since you don't have a an extra sort of parameter to optimize over.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So one question that's interesting is of course, well.",
                    "label": 0
                },
                {
                    "sent": "How does this compare to explicit sampling, right?",
                    "label": 0
                },
                {
                    "sent": "How does it compare to explicitly gathering samples from your sampling from your corrupting distribution, and then just training on a larger datasets?",
                    "label": 0
                },
                {
                    "sent": "So we did a little experiment where here on the X axis you see the number of corrupted copies that we sample from.",
                    "label": 1
                },
                {
                    "sent": "In this case a blank out distribution, and again here you see the classification error and what you see is that if you are sort of.",
                    "label": 0
                },
                {
                    "sent": "If you sample from this corrupting distribution and you get more samples than you ever indeed starts coming down, but it never quite get to get Studium CF case where you basically have infinite samples, you have to keep in mind of course, that that training this model is 256 times more expensive than training this mode right because you just have much more data trainer.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The second experiment was an image classification experiments where on the data set goal to see for 10 datasets.",
                    "label": 0
                },
                {
                    "sent": "So this is a data set of 32 by 32 pixel images and we built a sort of standard bag of visual words feature representation that's commonly used in computer vision, and we train models on these images to basically predict these 10 classes again using MCF or without using MCF, right?",
                    "label": 0
                },
                {
                    "sent": "So only L2 regularization?",
                    "label": 0
                },
                {
                    "sent": "And then we also use for so MCF and Blank out MCF and also here we can in particular, in the case of logistic regression we can get quite nice performance improvements.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The third experiment we looked at is what is called a nightmare.",
                    "label": 0
                },
                {
                    "sent": "At this time scenario.",
                    "label": 0
                },
                {
                    "sent": "So in this scenario what we get is we have a type of domain shift where at training time we basically see the full feature set.",
                    "label": 0
                },
                {
                    "sent": "So in this case the features are pixels of updated images, but at Test time randomly some of the features will be an observed in this quick kind of happened.",
                    "label": 1
                },
                {
                    "sent": "For instance, if you're dealing with a lot of sensors and sensors breakdown without telling you or it also happens a lot in sort of distributed computing environments where you send out a lot of feature extraction tasks and only some of them will run.",
                    "label": 0
                },
                {
                    "sent": "Sort of randomly be finished in time, but I just want, right?",
                    "label": 0
                },
                {
                    "sent": "So what we do here is we train classifiers on the original full feature set.",
                    "label": 1
                },
                {
                    "sent": "So in the full digit images, but then we go and and perform classification on these perturbed these these images in which random subsets over features are an observed.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here are the results we got.",
                    "label": 0
                },
                {
                    "sent": "So again on the Y axis we have a classification error, so lower is better, and on the X axis now we have the amount of test corruption right?",
                    "label": 0
                },
                {
                    "sent": "So the amount of sort of the percentage of features that is randomly delete it at at Test time and so these three lines here are sort of your standard L2 regularizer classifiers.",
                    "label": 1
                },
                {
                    "sent": "Ann was expected they get much worse really, really quickly, right?",
                    "label": 0
                },
                {
                    "sent": "Because they're?",
                    "label": 0
                },
                {
                    "sent": "I mean they're tested on a completely different distribution is what they were trained on.",
                    "label": 0
                },
                {
                    "sent": "The black line here is this medical def drop, which is.",
                    "label": 0
                },
                {
                    "sent": "Or was the state of the arts in this in this learning scenario until now it minimizes a type of worst case hinge loss, so it's a very complex sort of minimax from formulation, and the three solid lines here are the results you get with MCF in particular.",
                    "label": 0
                },
                {
                    "sent": "So this is the one with logistic loss, which I guess is the most reasonable classification loss and you can see that it performs quite well even for pretty high levels of test corruption, right?",
                    "label": 0
                },
                {
                    "sent": "So if we remove 70% of our features at Test time?",
                    "label": 0
                },
                {
                    "sent": "And we still get a performance of like 15% error even though we started with 7% error on the full feature sets.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So it's a conclude, I hope that I've maybe convince you that adding corrupted examples to your training data could be a good way to try and regularize your predictors, and MCF can make this sufficient for a range of models and a range of corrupting distributions, and that this may improve your results in certain learning settings, and in particular in learning settings where you understand a little bit about how your data works, and in particular where that happens, is in sort of domain shift.",
                    "label": 0
                },
                {
                    "sent": "A domain shift scenarios where you just know that your test distribution is going to be very different from your training distribution and you can set your corrupting distribution in such a way to sort of reflect this changing between source and target domain.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So these are my my coauthors.",
                    "label": 0
                },
                {
                    "sent": "There's code online.",
                    "label": 0
                },
                {
                    "sent": "You can also find the paper on my websites and with that.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                }
            ]
        }
    }
}