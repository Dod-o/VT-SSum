{
    "id": "nwoqqoqutyvnjmhityquwunykwxbb6bf",
    "title": "Accuracy test for genome wide selection of bio-markers",
    "info": {
        "author": [
            "Adam Kowalczyk, National ICT Australia"
        ],
        "published": "Jan. 23, 2012",
        "recorded": "December 2011",
        "category": [
            "Top->Biology->Genetics",
            "Top->Computer Science->Machine Learning->Statistical Learning"
        ]
    },
    "url": "http://videolectures.net/nipsworkshops2011_kowalczyk_biomarkers/",
    "segmentation": [
        [
            "OK, so this is a more technical part of a wider activity which we have in our lab in the area of jewels.",
            "And here we just were intending to talk about some statistical aspects of this, but probably I will talk less about March and try to actually put more perspective.",
            "Actually, why we're doing what we're doing, which is probably more interesting.",
            "For us here."
        ],
        [
            "OK, so that's how I was trying to sort of structure this.",
            "So actually what the problem is and actually we heard this already in previous presentation, so I have some sort of a different metaphor to showing what is actually a real difficulty, which we have to cope with in this type of research.",
            "And then this is this particular statistical tests which we have developed.",
            "But this is one of the many in the family and.",
            "Say I think that actually in order to formally and so on rigorously to address issues of significance, we need actually new statistical tests.",
            "We have to bite the bullet and do this, and it's possible what I'm showing that actually is feasible.",
            "It could be done.",
            "Yeah, but it will be a little bit about how we relate this statistic to actually to quantification of interaction effect.",
            "I call it interaction rather than epistaxis cause epistaxis has a lot of specific meaning interaction.",
            "I want to feel this rather broadly because what I believe we're doing we're doing a pre filtering of a candidate's red spots saying that something which is worthwhile checking.",
            "That's all what we can do on this level and then we have to check it and a few words about empirical validation of what we.",
            "Doing"
        ],
        [
            "OK, so what's the?",
            "What's the problem in the main problem is really a what I called here cosmic size over third space, which we have to deal with, and I will explain where this cosmic size comes from.",
            "So of course first thing is actually genome.",
            "Human genome itself is 3 billion of basis, right?",
            "If you take a grain of science 1 millimeter across an put them in the line so you could see this by naked eye, that's length is 3000 kilometers, right?",
            "So if you put here?",
            "Your center in Warsaw, in central Europe that you have all the lot, including Spain within this radius, and this is Australian equivalent of it.",
            "This is really big, so on this scale you should examine every millimeter and this is twice because we have two arraylists, so it's it's complicated.",
            "Obviously that's not what we're doing in due as we do at the moment.",
            "Very coarse sampling.",
            "We say half a million or million probes.",
            "Only right?",
            "So very core sampling, which in principle that reduces the whole problem."
        ],
        [
            "Right, so our son at the moment most of the time we're looking on Snips, but we should look.",
            "We could look also on metalation or copy number variation and so on, so.",
            "But anyway, let's talk about Snip, so we have always."
        ],
        [
            "Snips now.",
            "OK, so now we have only 1 million snips to look at in the sample.",
            "However, once you start looking for epistaxis for interactions, that everything blows after proportion, and we've seen some number today.",
            "So again, if I use my metaphor with one millimeter, so for every pair I have to look here and here in every sample of my 2000 samples, which I have over here.",
            "So if I put them in line, this is a land, and then blank of this is point.",
            "8 astronomical union.",
            "This is more or less distance between Earth and sun, and on this way you have to check every millimeter to check what was in there to solve the problem.",
            "If you go to Turner interactions through interactions, that goes to something like 2.6 million astronomical units, right?",
            "So if you examine this with the speed of Voyager, which is 15 kilometers per second, it takes you almost million years.",
            "Does the size of search which we are doing in this search is now my claim here?",
            "Is that actually this task could be done at the moment in four months on GPU cluster, so actually becomes feasible that one it could be done on GPU in one hour.",
            "This is 1 one million snips.",
            "All the binary interactions checked, right?"
        ],
        [
            "So, So what it means?",
            "But if you compare this technology event of this GPU with this, you know multi billion task or Voyager two which took only.",
            "And 30 years to travel.",
            "100 astronomical units.",
            "In our case, we have something really, really impressive our tools which are given to us are really great.",
            "Hopefully we can make some use."
        ],
        [
            "Now, how that translates to actually analysis of jewels.",
            "So here I have a table which which I was trying to compare those things.",
            "So in this column I show different tasks like 300,000 snaps, two interactions, half a million million.",
            "Again, freeway interactions.",
            "In each role here are sitting a, let's say classical algorithms, which some people compared for us.",
            "So the quickest overload was taking hundred days, roughly 3 months.",
            "If you apply playing to this task, this is 300 K2 way it's three years on single CPU, so you see immediately why we don't see that much epistaxis analyzed, 'cause it's difficult.",
            "Tools which were developed for our other purposes don't work.",
            "Don't scale up now if you use this column for through interactions, this is a million years right?",
            "Forget it out of the question.",
            "Now here you could use OK, so if you use G Boost this is so again that that drops to 45 minutes and so on.",
            "Sketch nicely, this is a.",
            "This is a bunch of algorithms which we have developed and we claim we can do now this task in 5 minutes.",
            "So that allows us to think seriously about freeway interactions and our estimate is that this this particular 3,000,000 freeway, we should be able to do in free months.",
            "On 200 GPU clusters, so that cost you OK half a million if you if you try to hire this from the from the Amazon GPU cloud, but it's doable and this course is dropping right?",
            "So again, my conclusion that with some simplifications and good algorithms that actually becomes feasible and obviously other people will come with other methods, and there's plenty of room for improvement here.",
            "But OK."
        ],
        [
            "So that was computational aspect of this, right?",
            "So we can do it computationally more or less question, but the next issue which we have to deal with is statistiques, right.",
            "This results, which we filtering we are doing many, many choices right.",
            "Let's say take 10 to 18, roughly choices in in three way interactions.",
            "How can we ensure that we actually doing something which makes sense?",
            "You have to design filters which actually gives you something.",
            "At the time, because you can't return the results, you have to discard most of them right?",
            "Even on this scale, even if you do 1% of error rate, that will be, you know you blow any possible storage which you have for memory.",
            "You have to be far more precise and so on.",
            "But also that means that that our safety values which we need now to consider are not 5% but 10 to minus 15 or something like that.",
            "Implication is that you cannot use statistical methodology which was based on Central Limit Theorem anymore.",
            "'cause we have to go to very far tails of the distribution.",
            "So even simple tests which we have, we have to rethink and re calibrate to computing exactly tails of the distribution because all these approximations are invalid in there.",
            "Of course you could do it if you want but that.",
            "It would be nice actually to know what is really happening and when you do these calculations you find that actually results are far better than what normal distribution will provide, so that perhaps is one of the reasons why people don't see significant results because they don't have significant P values because they use very gross statistics which are extremely conservative.",
            "And and so on.",
            "One way or the other that has to be looked at.",
            "It's no way to escape, and that's what we were trying to address with our."
        ],
        [
            "Statistics so we call it by normal margin, and that's of course in machine learning everybody everybody in this community hurt about margin.",
            "This is Sam."
        ],
        [
            "Different to average an and there is a reason for that.",
            "So the main.",
            "So the main difference in what we doing with respect to other methods is that we don't look on the regression.",
            "I mean everybody else is looking on the regression, so we do something else.",
            "We look on binary classification.",
            "We take our contingency table, we collapse them 2 two by two.",
            "Tables and then work with such tables so everything on a sort of level of machine learning is reduced to evaluating performance of binary classifiers.",
            "OK, So what we have?",
            "This is a space of.",
            "Space, I mean population our this is controls.",
            "In this we have say subset of cases.",
            "And then we have a sample, so we actually can't see this.",
            "We have only sample and on a basis of this sample we're trying to estimate what is a probability of observing, for example accuracy in our training data equal or higher than what we observe.",
            "If we sample this from the whole population, so we try to find P value related to the null hypothesis that actually something in the."
        ],
        [
            "Large is much worse than what we have observed, and here I would like to quickly to introduce what is an idea.",
            "So the main equation is here, which I try to explain what we have in here.",
            "So we look for probability Now a head.",
            "A head is actually empirical accuracy.",
            "So what we have in our data, we have cases and controls and then we have this binary classifier or this binali.",
            "Binary genotype which splits this into two subsets, so into two by two contingency.",
            "Table and then using this this genotype or this classifier we can determine a our our final type with setting accuracy.",
            "So actually what we after is.",
            "This is true accuracy in population which is defined in that way.",
            "So this is so.",
            "G is our genotype.",
            "Our classifier which please the population.",
            "And we take average of accuracy in cases and controls.",
            "So this is a balanced accuracy.",
            "And then in our sample we can't see this.",
            "We see only certain cards, so again, this is empirical estimate of that.",
            "So we have two concepts.",
            "Empirical estimate from the data and this one which we actually would like to know what it is, except we can observe it.",
            "And now our.",
            "So what we have in our test.",
            "So this is a probability.",
            "Of observing empirical accuracy higher or equal to this, a hat number which was actually on the sample under assumption that we sampled from binomial distribution with this particular true proportions which we don't know.",
            "But we don't know what this true proportion proportions are.",
            "So in order to compensate for this we take supremum.",
            "So we take the worst possible case, the highest value.",
            "Of of probability among all possible values of P which satisfy this condition.",
            "This condition here says that true accuracy was Rezvan parameter a not.",
            "So in our test we have two parameters right?",
            "This is a not null hypothesis parameter.",
            "This is what was observed in the sample and sensible expectation is that this is higher than this one right?",
            "And this is size of samples.",
            "So these are two constants and not very important.",
            "Again, you take this.",
            "You could work with those numbers, but this is a basic definition of what we're doing and this a not could be tuned.",
            "So if we take a not equal point, half that corresponds to a situation where actually there was no difference between 2, two to populate the Pheno types in the real population.",
            "But by chance we observe something else in our sample.",
            "But we have freedom here.",
            "Changing this a note to actually some other things.",
            "So for example, we can take a note which corresponds to odds ratio like 1.5.",
            "We observe free and we asking what is probability.",
            "But we observe this sort of high accuracy or whatever under assumption that actually it was much lower accuracy and we have enough room to manipulate this parameter and that could be easily translated into null hypothesis, right?",
            "This is so.",
            "That give us opportunity to specify that.",
            "If observed is bigger than a head, then we're rejecting null hypothesis that actually that was smaller than a minus and so on.",
            "So it's sort of straightforward.",
            "Translation the point is, though, that this generic definition which we have here that Supreme moments on actually could be computed.",
            "So it's computable, that's that."
        ],
        [
            "Critical path and this is 1 formal result here, showing that you could solve this and it's still interesting.",
            "This is explicit formula and so on.",
            "You have to solve.",
            "Find the roots of some cubic equation plugged in and that gives you estimate lower and upper estimate on the on this binomial margin which we have."
        ],
        [
            "Define and then you could go and generate more results, more complicate."
        ],
        [
            "It results in."
        ],
        [
            "And more results and so on.",
            "So it's all in the paper, right?",
            "It's mechanics innocence.",
            "Once we have definition and you patient enough, you should be able to recover.",
            "But of course it's easier to read paper an even easier to use somebody software which somebody has written.",
            "So we've written software that will be released.",
            "So that could be computed."
        ],
        [
            "Here is a plot showing how these things work, so of course we cannot.",
            "Actually, we cannot compute this this this binomial margin, but we can estimate.",
            "So here we have a bunch of lower and upper bounds and you'll see that there are actually quite tight to each other.",
            "So actually you could use bands quite safely and this is some relative bands and so on.",
            "But important thing is that this is actually tight and it goes actually down here.",
            "It was cut it in minus 100, but actually in real data in some real data we go to something like minus 506 hundred, so that's what it is.",
            "If you have big population, that's what happens.",
            "Anne."
        ],
        [
            "One could say, alright, so you've done something which is provided you inflating inflated P values, so this is something telling you that.",
            "Actually that's not the case if you use Fisher exact test to the two, apply to these two by two table, you get always lower P value when it comes from our test.",
            "So we actually conservative, which is good on this occasion because it tells us up that in spite of being conservative with seeing significant P values in real data, that's exactly where you want to be."
        ],
        [
            "OK so so far I introduce some particular magic test which is taking a data and provides you a P value.",
            "How to use this P value in case of epistaxis?",
            "So that was I think hinted today.",
            "An idea is reasonably straightforward so if I take a single snip that stratifies my data into three different strata, right?",
            "Like in here.",
            "And then cases and controls are stratified in certain proportions.",
            "And here you have percentages 5239 and so on.",
            "This is for cases and this is for controls is pretty even.",
            "This is another snip.",
            "Again, looks like pretty even if you combine them together all of a sudden, you end up with.",
            "If a.",
            "A 2 by 9 contingency table and all of sudden be splits because becoming not even this is actually a real case from breast cancer data and now effect.",
            "We define effect epistatic effect.",
            "In this case by taking P value associated with this table and subtracting from it P value from from any of the margins.",
            "So if you have a way around right, so you take the.",
            "Should be probably been.",
            "That should be mean rather than Marks and with minors.",
            "But anyway we take difference between logs associated with with this 2 by 9 table and the best possible for a single one.",
            "And that's our our size of effect, so this is similar to what many other people are doing.",
            "Like in both they doing something similar in MDR is something very similar, but what we're providing here is this.",
            "Additional this calibration by the P value.",
            "So we actually use.",
            "Calibration because it's very easy to improve fraud, say from 50% to 70.",
            "That's easy, but from 8200 is rather impossible.",
            "So calibration gives you this additional difficulty because say if I'm talking about accuracy, accuracy cannot be bigger than 100%.",
            "But this improvement between 90 and 100 should be weighted differently from improvement between 50 and 60, so this calibration.",
            "This is some sort of one way or formal way of calibrating this increment, and that's really what we what we used, and that actually makes a lot of difference to the result."
        ],
        [
            "OK so now go.",
            "Oh well, I'm out of time, right?",
            "OK, so now a few words about results.",
            "So we're doing all this epistaxis.",
            "It exhaustively question is, do you need to do it exhaustively?",
            "Why not to prefilter your snips to some small proportion and only use this essential ones and discard something which is useless?",
            "So here we have real data with showing that this is fine, except how to find which snips I use useful and better and showed one example here already.",
            "And here very small.",
            "OK, So what we have here?",
            "These are P values on this.",
            "Log minus log of P value so low ever better blue dots corresponds to P values associated with a pair.",
            "An green is the best P value, smallest value for a single for each single snake, right?",
            "So this particular pair which is giving us 10 to minus 13 or something came out of a snips which on their own are only 10 to minus one, right?",
            "So on video not completely flat, all of sudden in epistaxis in interaction becomes significant.",
            "Here you have epilepsy data.",
            "Do as showing the same thing.",
            "We are sorted by the size of that effect and so on.",
            "So many other data set showed that it means that actually is not easy to decide which snips should be discarded.",
            "It desirable, except we don't know how to do it at this point of."
        ],
        [
            "This is a double result when we're trying to show replication.",
            "So what we have we're dealing here with a 5 different cohorts for celiac data and we were using this celiac one.",
            "This is UK cohort on which we detected certain number of interacting snips.",
            "Then we went to the second cohort, which is this, for example, that one is again UK cohort, which lets was done later on different array and was 6000 samples.",
            "Or actually it's almost 7000 and then we took top say 10 to power four 10,000 pairs from one another analysis and we look for overlap and that shows you a percentage of overlap right?",
            "This is 70 to 80%.",
            "Among 10,000 pairs were replicated in another data.",
            "When we went to the Dutch cohort, that dropped to 60% that was finished cohort, it's about 50%, and that's Italian cohort.",
            "It's only 10%, so that shows you that actually there are ethnic differences, and so on.",
            "As you expected, this RP values associated with this and so on.",
            "But anyway, some results, at least in this case, replicated quite significantly.",
            "But also we see here that we have big number of these interactions.",
            "And this is not a single or two passes, just many of them.",
            "And that is actually next problem what?"
        ],
        [
            "Do with it.",
            "That's another replication plot, which I have no time to discuss, so this was UK cohorts.",
            "One and UK UK cohort two, and actually symmetric shows you interaction.",
            "So if you look replication.",
            "So if you look on this green Patch here, it's replicated in this UK too quite nicely here.",
            "If you could see there are some outliers right which came from outliers over here.",
            "So even outliers replicated it's one here and one here and so on.",
            "It's something is happening right.",
            "Different cohort is showing."
        ],
        [
            "Of similarities and so on.",
            "That's here, this is again, some run on the UK.",
            "One data.",
            "We only interesting thing is OK, there are no results are very rapid.",
            "Rapid is a method which people develop which is not doing exhaustive search by doing some sort of principle component model and uses these models and it runs very nicely.",
            "10 minutes except nothing comes out of it.",
            "So that's more.",
            "Or is that we have to still learn how to reduce this?",
            "We don't know at this."
        ],
        [
            "Point of time at all.",
            "And here you could see I don't know P values and so on their differences between type 2 diabetes and celiac right?",
            "So here it shows you.",
            "That's a single best pair in type 2 diabetics.",
            "Is able to achieve is, let's say 56% of accuracy while in Syriac single best purse giving you 80% classification accuracy.",
            "So immediately you see that something is really being captured in this silly act disease.",
            "Obviously this is.",
            "Perhaps easier G was then."
        ],
        [
            "Type 2 diabetics.",
            "This is summer replication.",
            "When we use different algorithms, so this is again we do.",
            "Replication between celiac one and celiac 2 red line corresponds to our approach blue line.",
            "It shows you boost right?",
            "So boost is having fair bit of replication.",
            "When we applied K squared test where replication dropdown results for playing here are shown by zero but I think they are wrong is it took three months to run plink.",
            "In the amount of fast epistasis right?",
            "And this person, she's very Chloe.",
            "How to do it?",
            "And I think we didn't got replication, but basically we didn't know how to run it.",
            "It didn't run after three months.",
            "God knows what we have to somehow replicate.",
            "It's tough, but we need to do something."
        ],
        [
            "For the paper, here is just when student was playing with different criteria for quantifying epistasis.",
            "And again you see that in a this replication drops and changes, so it's plenty of room for improving how to define this effect and whatever we've done this is is just only one way and probably more."
        ],
        [
            "To be divided on this plot, what we're seeing is something else we have say.",
            "On this plot, if you look there is up to a million of epistatic pairs detected above Bonferroni correction.",
            "This is this red line at this is shows you buffer P value.",
            "Now you know this is actually accuracy and at the red line corresponds to Bonferroni correction and then that was broke down into different models of interaction and not going into this colors shows you that there are different models are nonstandard models present in this data.",
            "So again, that gives you plenty of room for actually analyzing what's going on, because our mode method is completely model free, so any mode, any mode of interaction has a room, and any other method of detecting which assumes particular model of interaction could be doing something wrong."
        ],
        [
            "And looking on on this type of data, we definitely see differences.",
            "This is just another plot after he removed some 500 most significant marginal snips.",
            "And again we see plenty of interaction, and different modes are taking over and so on.",
            "So again, it's very complicated."
        ],
        [
            "That picture which we don't understand at the moment is just room for more research.",
            "OK with that let me try to conclude.",
            "So there are some obvious that you know we need a.",
            "You know computation and static and so on has to be fused with really biologic to get somewhere in this human disease area.",
            "It's too complicated.",
            "Too much stuff in there and so on.",
            "And finally, all what I've said, let me emphasize at this point over here, but we personally consider these techniques and what we're doing as a pre filtering step.",
            "Even if we can claim that these statistics make some sense, the biggest value is that we're reducing the whole space to manageable size like say 1,000,000 or 10,000,000 snips, and then we can use any other method.",
            "So we try to throw away something which is hopefully.",
            "Of low potential and then we can use all other techniques because there's plenty of room for better analysis than what we've done so far."
        ],
        [
            "And OK acknowledgement to people.",
            "And there are some stuff which are used from welcome.",
            "Trust from David van here, who provided us with celiac data and John Hopper and Terry O'Brien which provided us with other jewels.",
            "So this idea of, you know we can use GPU's and like tricky algorithms, it's going to run out eventually, right?",
            "You can't have 1 million 5 weight studies.",
            "Don't matter how many pieces you put it, so wondering in your data you showed that single the P value of single step interaction was not at all protective.",
            "You know those would show up in their two way interactions.",
            "Have you looked at if like combinations of two way interactions predict?",
            "3 way interactions.",
            "OK, so we didn't go to through interactions at this point of time.",
            "What we?",
            "I think what we will do in the next month.",
            "Actually we run real through interactions except on somewhat reduced data set.",
            "It's very curious to see what new will come from through interactions.",
            "I'm very curious.",
            "Of course I would like to see something coming out of nothing and pop up in 3 way interactions, but I don't know at this point of time also that I believe is heavily dependent.",
            "On your G Watson on disease, right?",
            "So again will be limited to whatever we apply data to, but we haven't done it yet.",
            "Questions.",
            "I am not a specialist of classification, but you know the NDR method wiki.",
            "Yeah, yeah.",
            "Yeah, so that's yeah various.",
            "Yeah, so if you look what I presented here on in this formulation is MDR method differences only in one thing.",
            "But in MDR, in order to determine whether this particular pair is significant, they do cross validation right, which is slow.",
            "We use statistique, which is look up table, and that gives us speed.",
            "So the same principle, but done differently because we can take advantage of statistique and and so and this particular statistic is suited to this, and we are sort of setting, yeah.",
            "This is more maybe in addition to what you said.",
            "Very nicely, but then that should be looked at.",
            "This is the paper by Culverhouse and limits on Epistar, securitized assets, models, and ratios that are purely at the study model of.",
            "Of two loci can exist without any modern effect, and it can also still exist for three low sign, but there should be a balance on the amount of variance to be explained.",
            "So actually it's not.",
            "Well, it's simple that if you don't have anything in two or three, the chance of finding something purely epistatic, saying nothing in one, nothing in doing it, 3.",
            "So cardinality, one minds when you're looking at is severely limited, and this is purely analytical result.",
            "So how much?",
            "However, we can close the gap upward is a big step forward, because then I could find it even though it can exist, is much reduced.",
            "It was covered with the American Journal in genetics.",
            "Yeah, it's it's very interesting because.",
            "You see that give us a hope that if we go two and three and we cannot find anything, probably there is not much which is very encouraging, I must say.",
            "Evolutionary biology is staying young seven.",
            "It's getting unlikely that something can exist.",
            "Stately as a Model 7.",
            "Magic #7 right?",
            "That's gonna be rather closely, otherwise just ahead of time for.",
            "So let's thank Adam.",
            "Yeah, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so this is a more technical part of a wider activity which we have in our lab in the area of jewels.",
                    "label": 0
                },
                {
                    "sent": "And here we just were intending to talk about some statistical aspects of this, but probably I will talk less about March and try to actually put more perspective.",
                    "label": 0
                },
                {
                    "sent": "Actually, why we're doing what we're doing, which is probably more interesting.",
                    "label": 0
                },
                {
                    "sent": "For us here.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so that's how I was trying to sort of structure this.",
                    "label": 0
                },
                {
                    "sent": "So actually what the problem is and actually we heard this already in previous presentation, so I have some sort of a different metaphor to showing what is actually a real difficulty, which we have to cope with in this type of research.",
                    "label": 0
                },
                {
                    "sent": "And then this is this particular statistical tests which we have developed.",
                    "label": 0
                },
                {
                    "sent": "But this is one of the many in the family and.",
                    "label": 0
                },
                {
                    "sent": "Say I think that actually in order to formally and so on rigorously to address issues of significance, we need actually new statistical tests.",
                    "label": 0
                },
                {
                    "sent": "We have to bite the bullet and do this, and it's possible what I'm showing that actually is feasible.",
                    "label": 0
                },
                {
                    "sent": "It could be done.",
                    "label": 0
                },
                {
                    "sent": "Yeah, but it will be a little bit about how we relate this statistic to actually to quantification of interaction effect.",
                    "label": 1
                },
                {
                    "sent": "I call it interaction rather than epistaxis cause epistaxis has a lot of specific meaning interaction.",
                    "label": 0
                },
                {
                    "sent": "I want to feel this rather broadly because what I believe we're doing we're doing a pre filtering of a candidate's red spots saying that something which is worthwhile checking.",
                    "label": 0
                },
                {
                    "sent": "That's all what we can do on this level and then we have to check it and a few words about empirical validation of what we.",
                    "label": 0
                },
                {
                    "sent": "Doing",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so what's the?",
                    "label": 0
                },
                {
                    "sent": "What's the problem in the main problem is really a what I called here cosmic size over third space, which we have to deal with, and I will explain where this cosmic size comes from.",
                    "label": 0
                },
                {
                    "sent": "So of course first thing is actually genome.",
                    "label": 0
                },
                {
                    "sent": "Human genome itself is 3 billion of basis, right?",
                    "label": 0
                },
                {
                    "sent": "If you take a grain of science 1 millimeter across an put them in the line so you could see this by naked eye, that's length is 3000 kilometers, right?",
                    "label": 0
                },
                {
                    "sent": "So if you put here?",
                    "label": 0
                },
                {
                    "sent": "Your center in Warsaw, in central Europe that you have all the lot, including Spain within this radius, and this is Australian equivalent of it.",
                    "label": 0
                },
                {
                    "sent": "This is really big, so on this scale you should examine every millimeter and this is twice because we have two arraylists, so it's it's complicated.",
                    "label": 0
                },
                {
                    "sent": "Obviously that's not what we're doing in due as we do at the moment.",
                    "label": 0
                },
                {
                    "sent": "Very coarse sampling.",
                    "label": 0
                },
                {
                    "sent": "We say half a million or million probes.",
                    "label": 0
                },
                {
                    "sent": "Only right?",
                    "label": 0
                },
                {
                    "sent": "So very core sampling, which in principle that reduces the whole problem.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right, so our son at the moment most of the time we're looking on Snips, but we should look.",
                    "label": 0
                },
                {
                    "sent": "We could look also on metalation or copy number variation and so on, so.",
                    "label": 0
                },
                {
                    "sent": "But anyway, let's talk about Snip, so we have always.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Snips now.",
                    "label": 0
                },
                {
                    "sent": "OK, so now we have only 1 million snips to look at in the sample.",
                    "label": 0
                },
                {
                    "sent": "However, once you start looking for epistaxis for interactions, that everything blows after proportion, and we've seen some number today.",
                    "label": 0
                },
                {
                    "sent": "So again, if I use my metaphor with one millimeter, so for every pair I have to look here and here in every sample of my 2000 samples, which I have over here.",
                    "label": 0
                },
                {
                    "sent": "So if I put them in line, this is a land, and then blank of this is point.",
                    "label": 0
                },
                {
                    "sent": "8 astronomical union.",
                    "label": 0
                },
                {
                    "sent": "This is more or less distance between Earth and sun, and on this way you have to check every millimeter to check what was in there to solve the problem.",
                    "label": 0
                },
                {
                    "sent": "If you go to Turner interactions through interactions, that goes to something like 2.6 million astronomical units, right?",
                    "label": 0
                },
                {
                    "sent": "So if you examine this with the speed of Voyager, which is 15 kilometers per second, it takes you almost million years.",
                    "label": 0
                },
                {
                    "sent": "Does the size of search which we are doing in this search is now my claim here?",
                    "label": 0
                },
                {
                    "sent": "Is that actually this task could be done at the moment in four months on GPU cluster, so actually becomes feasible that one it could be done on GPU in one hour.",
                    "label": 0
                },
                {
                    "sent": "This is 1 one million snips.",
                    "label": 0
                },
                {
                    "sent": "All the binary interactions checked, right?",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So, So what it means?",
                    "label": 0
                },
                {
                    "sent": "But if you compare this technology event of this GPU with this, you know multi billion task or Voyager two which took only.",
                    "label": 0
                },
                {
                    "sent": "And 30 years to travel.",
                    "label": 0
                },
                {
                    "sent": "100 astronomical units.",
                    "label": 0
                },
                {
                    "sent": "In our case, we have something really, really impressive our tools which are given to us are really great.",
                    "label": 0
                },
                {
                    "sent": "Hopefully we can make some use.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now, how that translates to actually analysis of jewels.",
                    "label": 0
                },
                {
                    "sent": "So here I have a table which which I was trying to compare those things.",
                    "label": 0
                },
                {
                    "sent": "So in this column I show different tasks like 300,000 snaps, two interactions, half a million million.",
                    "label": 0
                },
                {
                    "sent": "Again, freeway interactions.",
                    "label": 0
                },
                {
                    "sent": "In each role here are sitting a, let's say classical algorithms, which some people compared for us.",
                    "label": 0
                },
                {
                    "sent": "So the quickest overload was taking hundred days, roughly 3 months.",
                    "label": 0
                },
                {
                    "sent": "If you apply playing to this task, this is 300 K2 way it's three years on single CPU, so you see immediately why we don't see that much epistaxis analyzed, 'cause it's difficult.",
                    "label": 0
                },
                {
                    "sent": "Tools which were developed for our other purposes don't work.",
                    "label": 0
                },
                {
                    "sent": "Don't scale up now if you use this column for through interactions, this is a million years right?",
                    "label": 0
                },
                {
                    "sent": "Forget it out of the question.",
                    "label": 0
                },
                {
                    "sent": "Now here you could use OK, so if you use G Boost this is so again that that drops to 45 minutes and so on.",
                    "label": 0
                },
                {
                    "sent": "Sketch nicely, this is a.",
                    "label": 0
                },
                {
                    "sent": "This is a bunch of algorithms which we have developed and we claim we can do now this task in 5 minutes.",
                    "label": 0
                },
                {
                    "sent": "So that allows us to think seriously about freeway interactions and our estimate is that this this particular 3,000,000 freeway, we should be able to do in free months.",
                    "label": 0
                },
                {
                    "sent": "On 200 GPU clusters, so that cost you OK half a million if you if you try to hire this from the from the Amazon GPU cloud, but it's doable and this course is dropping right?",
                    "label": 0
                },
                {
                    "sent": "So again, my conclusion that with some simplifications and good algorithms that actually becomes feasible and obviously other people will come with other methods, and there's plenty of room for improvement here.",
                    "label": 0
                },
                {
                    "sent": "But OK.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that was computational aspect of this, right?",
                    "label": 0
                },
                {
                    "sent": "So we can do it computationally more or less question, but the next issue which we have to deal with is statistiques, right.",
                    "label": 0
                },
                {
                    "sent": "This results, which we filtering we are doing many, many choices right.",
                    "label": 0
                },
                {
                    "sent": "Let's say take 10 to 18, roughly choices in in three way interactions.",
                    "label": 0
                },
                {
                    "sent": "How can we ensure that we actually doing something which makes sense?",
                    "label": 0
                },
                {
                    "sent": "You have to design filters which actually gives you something.",
                    "label": 0
                },
                {
                    "sent": "At the time, because you can't return the results, you have to discard most of them right?",
                    "label": 0
                },
                {
                    "sent": "Even on this scale, even if you do 1% of error rate, that will be, you know you blow any possible storage which you have for memory.",
                    "label": 0
                },
                {
                    "sent": "You have to be far more precise and so on.",
                    "label": 0
                },
                {
                    "sent": "But also that means that that our safety values which we need now to consider are not 5% but 10 to minus 15 or something like that.",
                    "label": 0
                },
                {
                    "sent": "Implication is that you cannot use statistical methodology which was based on Central Limit Theorem anymore.",
                    "label": 0
                },
                {
                    "sent": "'cause we have to go to very far tails of the distribution.",
                    "label": 0
                },
                {
                    "sent": "So even simple tests which we have, we have to rethink and re calibrate to computing exactly tails of the distribution because all these approximations are invalid in there.",
                    "label": 0
                },
                {
                    "sent": "Of course you could do it if you want but that.",
                    "label": 0
                },
                {
                    "sent": "It would be nice actually to know what is really happening and when you do these calculations you find that actually results are far better than what normal distribution will provide, so that perhaps is one of the reasons why people don't see significant results because they don't have significant P values because they use very gross statistics which are extremely conservative.",
                    "label": 0
                },
                {
                    "sent": "And and so on.",
                    "label": 0
                },
                {
                    "sent": "One way or the other that has to be looked at.",
                    "label": 0
                },
                {
                    "sent": "It's no way to escape, and that's what we were trying to address with our.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Statistics so we call it by normal margin, and that's of course in machine learning everybody everybody in this community hurt about margin.",
                    "label": 0
                },
                {
                    "sent": "This is Sam.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Different to average an and there is a reason for that.",
                    "label": 0
                },
                {
                    "sent": "So the main.",
                    "label": 0
                },
                {
                    "sent": "So the main difference in what we doing with respect to other methods is that we don't look on the regression.",
                    "label": 0
                },
                {
                    "sent": "I mean everybody else is looking on the regression, so we do something else.",
                    "label": 0
                },
                {
                    "sent": "We look on binary classification.",
                    "label": 0
                },
                {
                    "sent": "We take our contingency table, we collapse them 2 two by two.",
                    "label": 0
                },
                {
                    "sent": "Tables and then work with such tables so everything on a sort of level of machine learning is reduced to evaluating performance of binary classifiers.",
                    "label": 0
                },
                {
                    "sent": "OK, So what we have?",
                    "label": 0
                },
                {
                    "sent": "This is a space of.",
                    "label": 0
                },
                {
                    "sent": "Space, I mean population our this is controls.",
                    "label": 0
                },
                {
                    "sent": "In this we have say subset of cases.",
                    "label": 0
                },
                {
                    "sent": "And then we have a sample, so we actually can't see this.",
                    "label": 0
                },
                {
                    "sent": "We have only sample and on a basis of this sample we're trying to estimate what is a probability of observing, for example accuracy in our training data equal or higher than what we observe.",
                    "label": 0
                },
                {
                    "sent": "If we sample this from the whole population, so we try to find P value related to the null hypothesis that actually something in the.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Large is much worse than what we have observed, and here I would like to quickly to introduce what is an idea.",
                    "label": 0
                },
                {
                    "sent": "So the main equation is here, which I try to explain what we have in here.",
                    "label": 0
                },
                {
                    "sent": "So we look for probability Now a head.",
                    "label": 0
                },
                {
                    "sent": "A head is actually empirical accuracy.",
                    "label": 0
                },
                {
                    "sent": "So what we have in our data, we have cases and controls and then we have this binary classifier or this binali.",
                    "label": 0
                },
                {
                    "sent": "Binary genotype which splits this into two subsets, so into two by two contingency.",
                    "label": 0
                },
                {
                    "sent": "Table and then using this this genotype or this classifier we can determine a our our final type with setting accuracy.",
                    "label": 0
                },
                {
                    "sent": "So actually what we after is.",
                    "label": 0
                },
                {
                    "sent": "This is true accuracy in population which is defined in that way.",
                    "label": 0
                },
                {
                    "sent": "So this is so.",
                    "label": 0
                },
                {
                    "sent": "G is our genotype.",
                    "label": 0
                },
                {
                    "sent": "Our classifier which please the population.",
                    "label": 0
                },
                {
                    "sent": "And we take average of accuracy in cases and controls.",
                    "label": 0
                },
                {
                    "sent": "So this is a balanced accuracy.",
                    "label": 0
                },
                {
                    "sent": "And then in our sample we can't see this.",
                    "label": 0
                },
                {
                    "sent": "We see only certain cards, so again, this is empirical estimate of that.",
                    "label": 0
                },
                {
                    "sent": "So we have two concepts.",
                    "label": 0
                },
                {
                    "sent": "Empirical estimate from the data and this one which we actually would like to know what it is, except we can observe it.",
                    "label": 0
                },
                {
                    "sent": "And now our.",
                    "label": 0
                },
                {
                    "sent": "So what we have in our test.",
                    "label": 0
                },
                {
                    "sent": "So this is a probability.",
                    "label": 0
                },
                {
                    "sent": "Of observing empirical accuracy higher or equal to this, a hat number which was actually on the sample under assumption that we sampled from binomial distribution with this particular true proportions which we don't know.",
                    "label": 0
                },
                {
                    "sent": "But we don't know what this true proportion proportions are.",
                    "label": 0
                },
                {
                    "sent": "So in order to compensate for this we take supremum.",
                    "label": 0
                },
                {
                    "sent": "So we take the worst possible case, the highest value.",
                    "label": 0
                },
                {
                    "sent": "Of of probability among all possible values of P which satisfy this condition.",
                    "label": 0
                },
                {
                    "sent": "This condition here says that true accuracy was Rezvan parameter a not.",
                    "label": 0
                },
                {
                    "sent": "So in our test we have two parameters right?",
                    "label": 0
                },
                {
                    "sent": "This is a not null hypothesis parameter.",
                    "label": 0
                },
                {
                    "sent": "This is what was observed in the sample and sensible expectation is that this is higher than this one right?",
                    "label": 0
                },
                {
                    "sent": "And this is size of samples.",
                    "label": 0
                },
                {
                    "sent": "So these are two constants and not very important.",
                    "label": 0
                },
                {
                    "sent": "Again, you take this.",
                    "label": 0
                },
                {
                    "sent": "You could work with those numbers, but this is a basic definition of what we're doing and this a not could be tuned.",
                    "label": 0
                },
                {
                    "sent": "So if we take a not equal point, half that corresponds to a situation where actually there was no difference between 2, two to populate the Pheno types in the real population.",
                    "label": 0
                },
                {
                    "sent": "But by chance we observe something else in our sample.",
                    "label": 0
                },
                {
                    "sent": "But we have freedom here.",
                    "label": 0
                },
                {
                    "sent": "Changing this a note to actually some other things.",
                    "label": 0
                },
                {
                    "sent": "So for example, we can take a note which corresponds to odds ratio like 1.5.",
                    "label": 0
                },
                {
                    "sent": "We observe free and we asking what is probability.",
                    "label": 0
                },
                {
                    "sent": "But we observe this sort of high accuracy or whatever under assumption that actually it was much lower accuracy and we have enough room to manipulate this parameter and that could be easily translated into null hypothesis, right?",
                    "label": 0
                },
                {
                    "sent": "This is so.",
                    "label": 0
                },
                {
                    "sent": "That give us opportunity to specify that.",
                    "label": 0
                },
                {
                    "sent": "If observed is bigger than a head, then we're rejecting null hypothesis that actually that was smaller than a minus and so on.",
                    "label": 0
                },
                {
                    "sent": "So it's sort of straightforward.",
                    "label": 0
                },
                {
                    "sent": "Translation the point is, though, that this generic definition which we have here that Supreme moments on actually could be computed.",
                    "label": 0
                },
                {
                    "sent": "So it's computable, that's that.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Critical path and this is 1 formal result here, showing that you could solve this and it's still interesting.",
                    "label": 0
                },
                {
                    "sent": "This is explicit formula and so on.",
                    "label": 0
                },
                {
                    "sent": "You have to solve.",
                    "label": 0
                },
                {
                    "sent": "Find the roots of some cubic equation plugged in and that gives you estimate lower and upper estimate on the on this binomial margin which we have.",
                    "label": 1
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Define and then you could go and generate more results, more complicate.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It results in.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And more results and so on.",
                    "label": 0
                },
                {
                    "sent": "So it's all in the paper, right?",
                    "label": 0
                },
                {
                    "sent": "It's mechanics innocence.",
                    "label": 0
                },
                {
                    "sent": "Once we have definition and you patient enough, you should be able to recover.",
                    "label": 0
                },
                {
                    "sent": "But of course it's easier to read paper an even easier to use somebody software which somebody has written.",
                    "label": 0
                },
                {
                    "sent": "So we've written software that will be released.",
                    "label": 0
                },
                {
                    "sent": "So that could be computed.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here is a plot showing how these things work, so of course we cannot.",
                    "label": 0
                },
                {
                    "sent": "Actually, we cannot compute this this this binomial margin, but we can estimate.",
                    "label": 1
                },
                {
                    "sent": "So here we have a bunch of lower and upper bounds and you'll see that there are actually quite tight to each other.",
                    "label": 0
                },
                {
                    "sent": "So actually you could use bands quite safely and this is some relative bands and so on.",
                    "label": 0
                },
                {
                    "sent": "But important thing is that this is actually tight and it goes actually down here.",
                    "label": 0
                },
                {
                    "sent": "It was cut it in minus 100, but actually in real data in some real data we go to something like minus 506 hundred, so that's what it is.",
                    "label": 0
                },
                {
                    "sent": "If you have big population, that's what happens.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "One could say, alright, so you've done something which is provided you inflating inflated P values, so this is something telling you that.",
                    "label": 0
                },
                {
                    "sent": "Actually that's not the case if you use Fisher exact test to the two, apply to these two by two table, you get always lower P value when it comes from our test.",
                    "label": 1
                },
                {
                    "sent": "So we actually conservative, which is good on this occasion because it tells us up that in spite of being conservative with seeing significant P values in real data, that's exactly where you want to be.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK so so far I introduce some particular magic test which is taking a data and provides you a P value.",
                    "label": 0
                },
                {
                    "sent": "How to use this P value in case of epistaxis?",
                    "label": 0
                },
                {
                    "sent": "So that was I think hinted today.",
                    "label": 0
                },
                {
                    "sent": "An idea is reasonably straightforward so if I take a single snip that stratifies my data into three different strata, right?",
                    "label": 0
                },
                {
                    "sent": "Like in here.",
                    "label": 0
                },
                {
                    "sent": "And then cases and controls are stratified in certain proportions.",
                    "label": 0
                },
                {
                    "sent": "And here you have percentages 5239 and so on.",
                    "label": 0
                },
                {
                    "sent": "This is for cases and this is for controls is pretty even.",
                    "label": 0
                },
                {
                    "sent": "This is another snip.",
                    "label": 0
                },
                {
                    "sent": "Again, looks like pretty even if you combine them together all of a sudden, you end up with.",
                    "label": 0
                },
                {
                    "sent": "If a.",
                    "label": 0
                },
                {
                    "sent": "A 2 by 9 contingency table and all of sudden be splits because becoming not even this is actually a real case from breast cancer data and now effect.",
                    "label": 0
                },
                {
                    "sent": "We define effect epistatic effect.",
                    "label": 0
                },
                {
                    "sent": "In this case by taking P value associated with this table and subtracting from it P value from from any of the margins.",
                    "label": 0
                },
                {
                    "sent": "So if you have a way around right, so you take the.",
                    "label": 0
                },
                {
                    "sent": "Should be probably been.",
                    "label": 0
                },
                {
                    "sent": "That should be mean rather than Marks and with minors.",
                    "label": 0
                },
                {
                    "sent": "But anyway we take difference between logs associated with with this 2 by 9 table and the best possible for a single one.",
                    "label": 0
                },
                {
                    "sent": "And that's our our size of effect, so this is similar to what many other people are doing.",
                    "label": 0
                },
                {
                    "sent": "Like in both they doing something similar in MDR is something very similar, but what we're providing here is this.",
                    "label": 0
                },
                {
                    "sent": "Additional this calibration by the P value.",
                    "label": 0
                },
                {
                    "sent": "So we actually use.",
                    "label": 0
                },
                {
                    "sent": "Calibration because it's very easy to improve fraud, say from 50% to 70.",
                    "label": 0
                },
                {
                    "sent": "That's easy, but from 8200 is rather impossible.",
                    "label": 0
                },
                {
                    "sent": "So calibration gives you this additional difficulty because say if I'm talking about accuracy, accuracy cannot be bigger than 100%.",
                    "label": 0
                },
                {
                    "sent": "But this improvement between 90 and 100 should be weighted differently from improvement between 50 and 60, so this calibration.",
                    "label": 0
                },
                {
                    "sent": "This is some sort of one way or formal way of calibrating this increment, and that's really what we what we used, and that actually makes a lot of difference to the result.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK so now go.",
                    "label": 0
                },
                {
                    "sent": "Oh well, I'm out of time, right?",
                    "label": 0
                },
                {
                    "sent": "OK, so now a few words about results.",
                    "label": 0
                },
                {
                    "sent": "So we're doing all this epistaxis.",
                    "label": 0
                },
                {
                    "sent": "It exhaustively question is, do you need to do it exhaustively?",
                    "label": 0
                },
                {
                    "sent": "Why not to prefilter your snips to some small proportion and only use this essential ones and discard something which is useless?",
                    "label": 0
                },
                {
                    "sent": "So here we have real data with showing that this is fine, except how to find which snips I use useful and better and showed one example here already.",
                    "label": 0
                },
                {
                    "sent": "And here very small.",
                    "label": 0
                },
                {
                    "sent": "OK, So what we have here?",
                    "label": 0
                },
                {
                    "sent": "These are P values on this.",
                    "label": 0
                },
                {
                    "sent": "Log minus log of P value so low ever better blue dots corresponds to P values associated with a pair.",
                    "label": 0
                },
                {
                    "sent": "An green is the best P value, smallest value for a single for each single snake, right?",
                    "label": 0
                },
                {
                    "sent": "So this particular pair which is giving us 10 to minus 13 or something came out of a snips which on their own are only 10 to minus one, right?",
                    "label": 0
                },
                {
                    "sent": "So on video not completely flat, all of sudden in epistaxis in interaction becomes significant.",
                    "label": 0
                },
                {
                    "sent": "Here you have epilepsy data.",
                    "label": 0
                },
                {
                    "sent": "Do as showing the same thing.",
                    "label": 0
                },
                {
                    "sent": "We are sorted by the size of that effect and so on.",
                    "label": 0
                },
                {
                    "sent": "So many other data set showed that it means that actually is not easy to decide which snips should be discarded.",
                    "label": 0
                },
                {
                    "sent": "It desirable, except we don't know how to do it at this point of.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is a double result when we're trying to show replication.",
                    "label": 0
                },
                {
                    "sent": "So what we have we're dealing here with a 5 different cohorts for celiac data and we were using this celiac one.",
                    "label": 0
                },
                {
                    "sent": "This is UK cohort on which we detected certain number of interacting snips.",
                    "label": 0
                },
                {
                    "sent": "Then we went to the second cohort, which is this, for example, that one is again UK cohort, which lets was done later on different array and was 6000 samples.",
                    "label": 0
                },
                {
                    "sent": "Or actually it's almost 7000 and then we took top say 10 to power four 10,000 pairs from one another analysis and we look for overlap and that shows you a percentage of overlap right?",
                    "label": 0
                },
                {
                    "sent": "This is 70 to 80%.",
                    "label": 0
                },
                {
                    "sent": "Among 10,000 pairs were replicated in another data.",
                    "label": 0
                },
                {
                    "sent": "When we went to the Dutch cohort, that dropped to 60% that was finished cohort, it's about 50%, and that's Italian cohort.",
                    "label": 0
                },
                {
                    "sent": "It's only 10%, so that shows you that actually there are ethnic differences, and so on.",
                    "label": 0
                },
                {
                    "sent": "As you expected, this RP values associated with this and so on.",
                    "label": 0
                },
                {
                    "sent": "But anyway, some results, at least in this case, replicated quite significantly.",
                    "label": 0
                },
                {
                    "sent": "But also we see here that we have big number of these interactions.",
                    "label": 0
                },
                {
                    "sent": "And this is not a single or two passes, just many of them.",
                    "label": 0
                },
                {
                    "sent": "And that is actually next problem what?",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Do with it.",
                    "label": 0
                },
                {
                    "sent": "That's another replication plot, which I have no time to discuss, so this was UK cohorts.",
                    "label": 0
                },
                {
                    "sent": "One and UK UK cohort two, and actually symmetric shows you interaction.",
                    "label": 0
                },
                {
                    "sent": "So if you look replication.",
                    "label": 0
                },
                {
                    "sent": "So if you look on this green Patch here, it's replicated in this UK too quite nicely here.",
                    "label": 0
                },
                {
                    "sent": "If you could see there are some outliers right which came from outliers over here.",
                    "label": 0
                },
                {
                    "sent": "So even outliers replicated it's one here and one here and so on.",
                    "label": 0
                },
                {
                    "sent": "It's something is happening right.",
                    "label": 0
                },
                {
                    "sent": "Different cohort is showing.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of similarities and so on.",
                    "label": 0
                },
                {
                    "sent": "That's here, this is again, some run on the UK.",
                    "label": 0
                },
                {
                    "sent": "One data.",
                    "label": 0
                },
                {
                    "sent": "We only interesting thing is OK, there are no results are very rapid.",
                    "label": 0
                },
                {
                    "sent": "Rapid is a method which people develop which is not doing exhaustive search by doing some sort of principle component model and uses these models and it runs very nicely.",
                    "label": 0
                },
                {
                    "sent": "10 minutes except nothing comes out of it.",
                    "label": 0
                },
                {
                    "sent": "So that's more.",
                    "label": 0
                },
                {
                    "sent": "Or is that we have to still learn how to reduce this?",
                    "label": 0
                },
                {
                    "sent": "We don't know at this.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Point of time at all.",
                    "label": 0
                },
                {
                    "sent": "And here you could see I don't know P values and so on their differences between type 2 diabetes and celiac right?",
                    "label": 1
                },
                {
                    "sent": "So here it shows you.",
                    "label": 0
                },
                {
                    "sent": "That's a single best pair in type 2 diabetics.",
                    "label": 0
                },
                {
                    "sent": "Is able to achieve is, let's say 56% of accuracy while in Syriac single best purse giving you 80% classification accuracy.",
                    "label": 0
                },
                {
                    "sent": "So immediately you see that something is really being captured in this silly act disease.",
                    "label": 0
                },
                {
                    "sent": "Obviously this is.",
                    "label": 0
                },
                {
                    "sent": "Perhaps easier G was then.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Type 2 diabetics.",
                    "label": 0
                },
                {
                    "sent": "This is summer replication.",
                    "label": 0
                },
                {
                    "sent": "When we use different algorithms, so this is again we do.",
                    "label": 1
                },
                {
                    "sent": "Replication between celiac one and celiac 2 red line corresponds to our approach blue line.",
                    "label": 0
                },
                {
                    "sent": "It shows you boost right?",
                    "label": 0
                },
                {
                    "sent": "So boost is having fair bit of replication.",
                    "label": 0
                },
                {
                    "sent": "When we applied K squared test where replication dropdown results for playing here are shown by zero but I think they are wrong is it took three months to run plink.",
                    "label": 0
                },
                {
                    "sent": "In the amount of fast epistasis right?",
                    "label": 0
                },
                {
                    "sent": "And this person, she's very Chloe.",
                    "label": 0
                },
                {
                    "sent": "How to do it?",
                    "label": 0
                },
                {
                    "sent": "And I think we didn't got replication, but basically we didn't know how to run it.",
                    "label": 0
                },
                {
                    "sent": "It didn't run after three months.",
                    "label": 0
                },
                {
                    "sent": "God knows what we have to somehow replicate.",
                    "label": 0
                },
                {
                    "sent": "It's tough, but we need to do something.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For the paper, here is just when student was playing with different criteria for quantifying epistasis.",
                    "label": 0
                },
                {
                    "sent": "And again you see that in a this replication drops and changes, so it's plenty of room for improving how to define this effect and whatever we've done this is is just only one way and probably more.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To be divided on this plot, what we're seeing is something else we have say.",
                    "label": 0
                },
                {
                    "sent": "On this plot, if you look there is up to a million of epistatic pairs detected above Bonferroni correction.",
                    "label": 0
                },
                {
                    "sent": "This is this red line at this is shows you buffer P value.",
                    "label": 0
                },
                {
                    "sent": "Now you know this is actually accuracy and at the red line corresponds to Bonferroni correction and then that was broke down into different models of interaction and not going into this colors shows you that there are different models are nonstandard models present in this data.",
                    "label": 1
                },
                {
                    "sent": "So again, that gives you plenty of room for actually analyzing what's going on, because our mode method is completely model free, so any mode, any mode of interaction has a room, and any other method of detecting which assumes particular model of interaction could be doing something wrong.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And looking on on this type of data, we definitely see differences.",
                    "label": 0
                },
                {
                    "sent": "This is just another plot after he removed some 500 most significant marginal snips.",
                    "label": 0
                },
                {
                    "sent": "And again we see plenty of interaction, and different modes are taking over and so on.",
                    "label": 1
                },
                {
                    "sent": "So again, it's very complicated.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That picture which we don't understand at the moment is just room for more research.",
                    "label": 0
                },
                {
                    "sent": "OK with that let me try to conclude.",
                    "label": 0
                },
                {
                    "sent": "So there are some obvious that you know we need a.",
                    "label": 0
                },
                {
                    "sent": "You know computation and static and so on has to be fused with really biologic to get somewhere in this human disease area.",
                    "label": 0
                },
                {
                    "sent": "It's too complicated.",
                    "label": 0
                },
                {
                    "sent": "Too much stuff in there and so on.",
                    "label": 0
                },
                {
                    "sent": "And finally, all what I've said, let me emphasize at this point over here, but we personally consider these techniques and what we're doing as a pre filtering step.",
                    "label": 0
                },
                {
                    "sent": "Even if we can claim that these statistics make some sense, the biggest value is that we're reducing the whole space to manageable size like say 1,000,000 or 10,000,000 snips, and then we can use any other method.",
                    "label": 0
                },
                {
                    "sent": "So we try to throw away something which is hopefully.",
                    "label": 0
                },
                {
                    "sent": "Of low potential and then we can use all other techniques because there's plenty of room for better analysis than what we've done so far.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And OK acknowledgement to people.",
                    "label": 0
                },
                {
                    "sent": "And there are some stuff which are used from welcome.",
                    "label": 0
                },
                {
                    "sent": "Trust from David van here, who provided us with celiac data and John Hopper and Terry O'Brien which provided us with other jewels.",
                    "label": 0
                },
                {
                    "sent": "So this idea of, you know we can use GPU's and like tricky algorithms, it's going to run out eventually, right?",
                    "label": 0
                },
                {
                    "sent": "You can't have 1 million 5 weight studies.",
                    "label": 0
                },
                {
                    "sent": "Don't matter how many pieces you put it, so wondering in your data you showed that single the P value of single step interaction was not at all protective.",
                    "label": 0
                },
                {
                    "sent": "You know those would show up in their two way interactions.",
                    "label": 0
                },
                {
                    "sent": "Have you looked at if like combinations of two way interactions predict?",
                    "label": 0
                },
                {
                    "sent": "3 way interactions.",
                    "label": 0
                },
                {
                    "sent": "OK, so we didn't go to through interactions at this point of time.",
                    "label": 0
                },
                {
                    "sent": "What we?",
                    "label": 0
                },
                {
                    "sent": "I think what we will do in the next month.",
                    "label": 0
                },
                {
                    "sent": "Actually we run real through interactions except on somewhat reduced data set.",
                    "label": 0
                },
                {
                    "sent": "It's very curious to see what new will come from through interactions.",
                    "label": 0
                },
                {
                    "sent": "I'm very curious.",
                    "label": 0
                },
                {
                    "sent": "Of course I would like to see something coming out of nothing and pop up in 3 way interactions, but I don't know at this point of time also that I believe is heavily dependent.",
                    "label": 0
                },
                {
                    "sent": "On your G Watson on disease, right?",
                    "label": 0
                },
                {
                    "sent": "So again will be limited to whatever we apply data to, but we haven't done it yet.",
                    "label": 0
                },
                {
                    "sent": "Questions.",
                    "label": 0
                },
                {
                    "sent": "I am not a specialist of classification, but you know the NDR method wiki.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so that's yeah various.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so if you look what I presented here on in this formulation is MDR method differences only in one thing.",
                    "label": 0
                },
                {
                    "sent": "But in MDR, in order to determine whether this particular pair is significant, they do cross validation right, which is slow.",
                    "label": 0
                },
                {
                    "sent": "We use statistique, which is look up table, and that gives us speed.",
                    "label": 0
                },
                {
                    "sent": "So the same principle, but done differently because we can take advantage of statistique and and so and this particular statistic is suited to this, and we are sort of setting, yeah.",
                    "label": 0
                },
                {
                    "sent": "This is more maybe in addition to what you said.",
                    "label": 0
                },
                {
                    "sent": "Very nicely, but then that should be looked at.",
                    "label": 0
                },
                {
                    "sent": "This is the paper by Culverhouse and limits on Epistar, securitized assets, models, and ratios that are purely at the study model of.",
                    "label": 0
                },
                {
                    "sent": "Of two loci can exist without any modern effect, and it can also still exist for three low sign, but there should be a balance on the amount of variance to be explained.",
                    "label": 0
                },
                {
                    "sent": "So actually it's not.",
                    "label": 0
                },
                {
                    "sent": "Well, it's simple that if you don't have anything in two or three, the chance of finding something purely epistatic, saying nothing in one, nothing in doing it, 3.",
                    "label": 0
                },
                {
                    "sent": "So cardinality, one minds when you're looking at is severely limited, and this is purely analytical result.",
                    "label": 0
                },
                {
                    "sent": "So how much?",
                    "label": 0
                },
                {
                    "sent": "However, we can close the gap upward is a big step forward, because then I could find it even though it can exist, is much reduced.",
                    "label": 0
                },
                {
                    "sent": "It was covered with the American Journal in genetics.",
                    "label": 0
                },
                {
                    "sent": "Yeah, it's it's very interesting because.",
                    "label": 0
                },
                {
                    "sent": "You see that give us a hope that if we go two and three and we cannot find anything, probably there is not much which is very encouraging, I must say.",
                    "label": 0
                },
                {
                    "sent": "Evolutionary biology is staying young seven.",
                    "label": 0
                },
                {
                    "sent": "It's getting unlikely that something can exist.",
                    "label": 0
                },
                {
                    "sent": "Stately as a Model 7.",
                    "label": 0
                },
                {
                    "sent": "Magic #7 right?",
                    "label": 0
                },
                {
                    "sent": "That's gonna be rather closely, otherwise just ahead of time for.",
                    "label": 0
                },
                {
                    "sent": "So let's thank Adam.",
                    "label": 0
                },
                {
                    "sent": "Yeah, thank you.",
                    "label": 0
                }
            ]
        }
    }
}