{
    "id": "z2sq2eldmcxyviue655dp7ym6xhj65hn",
    "title": "Active Kernel Learning",
    "info": {
        "author": [
            "Rong Jin, Department of Computer Science, KU Leuven"
        ],
        "published": "July 28, 2008",
        "recorded": "July 2008",
        "category": [
            "Top->Computer Science->Machine Learning->Active Learning",
            "Top->Computer Science->Machine Learning->Kernel Methods"
        ]
    },
    "url": "http://videolectures.net/icml08_jin_acl/",
    "segmentation": [
        [
            "Now work on active kernel running and this is joint work with.",
            "Steven Hawley from Nanyang Technology Nanotechnological University."
        ],
        [
            "OK, so it's well known that the kernel playing a critical role in machine learning.",
            "Many learning mechanisms involves and kernels.",
            "Now so recently there have been a lot of study devoted to learning the Colonel from the data.",
            "So in general, the approach for current learning can be categorized into two categories.",
            "The first one is to learn a particular parameter involving kernel function.",
            "For instance, you can learn the kernel weights in RBF function.",
            "You also could win the parameters involving the kernel division Colonel.",
            "Now a different approach.",
            "Attorney approach for kernel earnings is too and contact this number magic coloring.",
            "So in this case that you don't make any assumption about the parametric form, the kernel and so instead of learning a kernel function, then you focus on learning a kernel matrix."
        ],
        [
            "So here I'm listing a few I believe are very important to work in this kind of learning, and this by no means the exhaust lists.",
            "And so while the first one that the present is this kernel line, when the goal is to identify the optimal kernel that align well with the class labels.",
            "I'm so this worker learning kernel is the same definite programming.",
            "Essentially you identified opting kernel by maximizing your classification margin.",
            "There's a lot of work being inspired by this for the multiple kernel learning.",
            "OK and then this non parametric graph kernel running essentially adding additional constraint to the kernel alignment approach.",
            "And then this work of learning the low rank kernel matrix.",
            "So essentially you start with some initial guess, the kernel and then you have additional class labels.",
            "So your goal is to identify the kernel that on one hand that are consistent with your initial guest kernel matrix.",
            "On the other hand, also consistent with your translate.",
            "Oops, sorry.",
            "OK, so so our work active cooling essentially is built on the last work, which is our work published in last years.",
            "I see ICM L I'm so."
        ],
        [
            "So.",
            "This week all the nonparametric kernel running and essentially you been given two things.",
            "One is you been given a similarity matrix, so in this case you don't require any positive Sam.",
            "Definitely property of this similarity matrix an 2nd instead of given the label examples to be given the pairwise constraints.",
            "So for instance you have lost link versus cannot link those become the guidance for you to identify the optimal kernel matrix."
        ],
        [
            "Now, although there has been an extensive study on both the methodology for the kernel learning and the efficient learning algorithm towards identified optimal kernel, however, I know that most of those works can be labeled as a passive kernel.",
            "Learning other words that all the existing work assume that label the information at the labor examples or labeled pairs being given before hand, and then after that kernel learning method will take.",
            "Those label the information as input and generate appropriate kernel.",
            "My parent has all the active learning researcher.",
            "Would argue this may not be the most efficient means to build up to an kernel matrix, so therefore the straightforward process should be.",
            "How about we turn the passive kernel learning into active one?",
            "So like any active learning approach, you like to an active select and those labeled examples are labeled pairs.",
            "That should be mostly informative to the target kernel matrix that you aim to learn."
        ],
        [
            "So as I emphasized that our work is essentially build on last year's nonparametric kernel, learning that we did.",
            "OK, now again, as first speaker being discussed extensively, which for any kernel active learning, the key issue here is what are the right criterion for selective sampling.",
            "The example in this case is example pairs.",
            "Now if we follow the conventional approach of active learning, essentially try to reduce the variance of the classifier, then we pretty well follow this.",
            "I could uncertainty principle that essentially you would like to select those example or example pairs that are most uncertain to be classified.",
            "Now in our case we aim to select the example page.",
            "Now if we believe our elements in the kernel matrix are very well adjusted.",
            "In other words, if we assume that the large positive value of kij indicates the two, the pair excellent actually are likely to be in the same class.",
            "While the large negative kij indicates there likely to be in the different class, then we probably can use the absolute value of the kij as the indicator of uncertainty.",
            "Therefore, the very first approach that you can think about by following this uncertain uncertainty principle is to identify those example pair that has the least absolute value of the Kij case.",
            "The Colonel you learned and those become.",
            "Those become the informative example pairs.",
            "Now I should argue that although this seems to be various.",
            "A straightforward an intuitive approach to go with, however one that there have been a few drawback with this approach.",
            "One empirically we find out that turns out this approach tends to select a certain type appears.",
            "In particular, we find that must link pairs tends to be more likely be selected by."
        ],
        [
            "This approach so for instance, if I'm looking at this.",
            "Example here.",
            "So let the panel shows the exam.",
            "The double Sparrow examples and the fuel line segment indicates either the mass Lincoln Muscle Link, so those are being the pairwise constraint being given to the learning errors, so the right right Colonel right panel shows that.",
            "Example pairs being selected by this simple.",
            "And so then the principles.",
            "So as you can see, the line segment there are also solid indicates that most appears these select by these algorithms tends to be the.",
            "Mathlinks, so we at least we empirically find that this approach seems to favor the mathlink pairs versus cannot link."
        ],
        [
            "OK, so the main contribution of this work is when we try to present a slightly more principle framework.",
            "We called min Max principle for the active learning and we extended to the kernel learning active current learning and we also shows convex relaxation of the proposed framework."
        ],
        [
            "For active kernel learning.",
            "So I have to spend a few minutes reviewing my our previous work on the kernel running.",
            "So as I said, the idea is trying to learn the kernel from two things.",
            "The first one is this pairwise constraints, and so we have this matrix T which is in cocoa, encodes all the pairwise constraints.",
            "Whenever the excellent extra in the same class which is called must link, there's a one value assigned to the corresponding element.",
            "And then there will be the negative form whenever decks either J in a different class and this is called the cannot link for all those element pairs that hasn't been labeled.",
            "We give the zero value, so that's the way we encode this pairwise constraint.",
            "An additional information is this similarity measurement, so we assume this initial similarity measurement tells you how similar or different to example.",
            "And that is encoded in the matrix."
        ],
        [
            "S so go here is to combine these two quantity S&T to getting a proper kernel image."
        ],
        [
            "Chicks.",
            "OK, so so this is our single framework for kernel learning.",
            "So here the capital J here is the target kernel.",
            "We aim to find.",
            "So in the very first determine object function which is a trace of LJ.",
            "So error here is a Laplace grapher processing of the similarity matrix.",
            "So therefore that race between the air and Jay is essentially to measure the consistency between.",
            "The target occur and the similarity measurement, and we have this second and try to minimize the upstream square.",
            "So if so here is again try to measure the inconsistency between the target kernel and the pairwise constraints.",
            "That largely this then more disagreement.",
            "These two things are.",
            "So that's roughly our.",
            "Simba"
        ],
        [
            "Framework.",
            "OK, so so in order to extend this simple framework to the active learning, and as we said, the key question here is try to measure the inform list of any pairs.",
            "So to that end, they'll consider, in addition to a number of pairwise constraints have been given.",
            "Now consider you have a additional pairs X, XC and XL.",
            "Now if some details you the class labels, let's say why.",
            "OK so the one way to see that how informative is PDX KXL together with this class?",
            "Labels is just by measuring how this additional pair well affect the overall objective function.",
            "Now if this additional pair an can be very well predicted by the existing.",
            "On pairwise constraints, then, you don't expect it.",
            "The object function will change significantly only when these additional pair are not very well predicted by the existing pairwise constraints, then you expect the overall object function will be.",
            "Be influence substantially, so that's actually the fundamental star that we have to handle this informative management.",
            "So here that given a pair XK&X error, we introduce this quantity.",
            "We called Omega KLY and this is the quantity essentially just measure the optimal value after object function that with using the existing pairwise constraints.",
            "And together with this new pairwise constraint, which is XKXL and then with the label Y. OK, so as you can see I highlighted by the red rectangles and that is the additional constraint introduced by this additional pairwise constraints."
        ],
        [
            "This is as I had before, that essentially, if you have if this pair XKXLR, ferry, quote, unquote, consistent with all the pairs, that pairwise concern that you have, then.",
            "You will always can find a proper choice of class label right such that this Omega function will not change too much.",
            "And in the meantime, if actually choosing the inop inappropriate and class label right, then you expect this Omega KLY will change significantly, so."
        ],
        [
            "One way to summarize this simple intuitive as the way to measure the the in form lists of the example pair is to consider worst case scenarios.",
            "So that is you have the pair and then you measure the Omega K error versus some class labels because you have no idea what is the property cast members.",
            "Now you can see the the class members that leads to the largest jump of the.",
            "Object function.",
            "So, as I argued that if a pairwise if this picks K&X error.",
            "I consistent with the existing pairwise constraints, then by choosing the wrong class labels.",
            "Indeed, well, very significantly change the object function.",
            "Therefore, and you expect that the discard this cutter and care will be very large for any pair that already been consistent with the pairwise constraint proof."
        ],
        [
            "Alright, so.",
            "So anyway, if you believe this is right into it, if I have no good theoretic argument for that, but then there will be a simple I mean Max framework for choosing the pairs.",
            "So we have this carpet care which essentially tells you how I informed him that the example it is.",
            "Therefore I would like to choose the pairwise pairs that has the list in formless or the most uninformed people.",
            "Now if we replace the cap with.",
            "The maximization of Omega over right.",
            "Then you can see we have a mix of magician problem here.",
            "OK, so I want to emphasize that one this is not trivial optimization problem because essentially is a big Macs and the 2nd and that's this.",
            "Omega is actually not closed form function is actually output from some object function.",
            "Now, as the very first step of the simplification, you can easily show that you can indeed eliminate this maximization.",
            "This mean Max is essentially is just.",
            "Illusion is not so."
        ],
        [
            "This is fundamental, so by some simple algebra you can show that previous min Max problem is equivalent to the problems.",
            "I so on the screen, which is nothing, just a simple intimidation problem.",
            "Now one thing I want to point out is that if you looking at the problem, P1 parent is too.",
            "Busy so you don't have to look at anyway, so so the P1.",
            "If in the P1 that you actually fix the variable Z, which is the target kernel matrix, you aim to find.",
            "Then turns out you have a very interesting results that we showing on the second panel of the screen.",
            "So so that means that if you fix the AC turns out you're going to get the heuristic of searching the pairs that exactly as the uncertainty principle pointed out."
        ],
        [
            "OK, so.",
            "Now, so solving this P1 problem is quite expensive.",
            "The reason is that you have to solve it for every single pair.",
            "So I highlight this.",
            "Index scale right?",
            "So here you really have to consider all the post prepare Karen the computer quantity for every single page and that is way too much so the various tree for the way you can think about to eliminate this computational challenges by introducing some additional variables.",
            "For instance, you can introduce the continuous variables PKL and to indicate how likely that each pair."
        ],
        [
            "Robbie Select and you can relax your problem by using this variable P care.",
            "So here PKL is a continuous variable in the case, the chance of selecting certain variables and as I highlighted in the red rectangle and as you see that you can essentially aggregate all the pairwise computation into one single optimization problems.",
            "Well, the bad news is you can prove this is non convex so.",
            "And that essentially you will learn some local maximum.",
            "So what I did is I relax this problem into a convex optimization problem."
        ],
        [
            "OK, so.",
            "OK, so the key observation is the follows that is the big travel here indeed is this linear constraints together with the terms in object function, relates to this federal P care.",
            "I'm so the first thing I do is I replace this linear constraints with another.",
            "Seems to be much more complicated constraints, so here are utilizing.",
            "The simple fact that arithmetic mean should always be largely couldn't the harmonic mean?",
            "So if I view this linear constraint essentially bound constraint on the arithmetic mean, then I can replace it with the harmonic mean, which will strengthen the constraints.",
            "OK, so."
        ],
        [
            "So if you do that, then essential resources you're going to replace.",
            "The variable P care with another variable which is HK and this age care is essentially the inverse of the PKL.",
            "Now, the reason we want to do this is because you can show by this replacement to inside.",
            "The problem becomes perfect convex optimization problem indeed is essentially same definite programming problem.",
            "Now the only thing I want to point out is that this version of replacement is not exactly equivalent to the problem that you aim to solve before.",
            "However, you can always show that output value option value that output by this optimization problem is always be the the upper bound of the previous one.",
            "Therefore, by minimize this subject function, essentially reduced object function of the previous language."
        ],
        [
            "Speed.",
            "OK, and then we have a few more discussion in the paper about how can you solve this more efficiently from the viewpoint of duality."
        ],
        [
            "OK, so maybe.",
            "Quickly goes to the pad of the experiments, so we have run this over the nine different data set.",
            "As you can see now in a very large data set, and all this because the SDP is something that nobody likes, but essentially you have the server, so the two datasets are the 1st two are the.",
            "Synthetic data set and the remaining 7 datasets from the."
        ],
        [
            "UI.",
            "So we have this problem.",
            "The experiment setup with the two different.",
            "The baseline very first line, just the random sample, the pairs and the second one is one that we discussed at the beginning.",
            "You select the example pair that has the least absolute value of the elements in your compute kernel matrix and we called it the akl mean at dash mean Dash A through Z and.",
            "The approach that we have here is we denote by a KL dash, mean dash H. So the way we evaluate the estimated kernel is by the class ring.",
            "So the belief that is that if you have a good kernel matrix, you aim to get a better clustering results, so they were using the conventional question accuracy as the way to measure the quality of clustering."
        ],
        [
            "OK, so here I only just show you the results over the three data set remaining you can find in the in the paper.",
            "So the horizontal axis here is the number of iteration you have and the vertical axis at accuracy of class ring and you see there's a 3 lines of.",
            "Let me point out the the set up the experiment.",
            "So initially these three experiment these three data set being given 100.",
            "Random Select appears and then each iteration additional 20 pairs will be selected based on different criteria.",
            "So there's three lines correspond with three different methods, and the red line corresponds to the method that proposed in this paper, and as you can see, for all the cases that we have some noticeable improvement compared to both the random selection and the selection based on the least absolute value of.",
            "The elements in the estimate Colonel.",
            "OK, and would surprise in some case.",
            "First.",
            "For instance, if you look at the results for the solid result, random selection is not a bad choice at all, and I think this probably to some degree confirm the.",
            "Discussion that you've seen for."
        ],
        [
            "The tag.",
            "OK, OK, so let me just conclude my talk.",
            "So basically we present a min Max framework as the way to handle the active kernel learning and we have a convex relaxation allows us to solving the problem, quote, unquote, efficiently and then we show some encouraging results occur over rather small relative modest size dates.",
            "Thank you.",
            "Very good question.",
            "I have no idea I was origin should cannot link should be the one dominate because it has much higher prior so that he has something to do with the learning.",
            "The kernel learning mechanics is but I don't have clear reasons."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now work on active kernel running and this is joint work with.",
                    "label": 0
                },
                {
                    "sent": "Steven Hawley from Nanyang Technology Nanotechnological University.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so it's well known that the kernel playing a critical role in machine learning.",
                    "label": 0
                },
                {
                    "sent": "Many learning mechanisms involves and kernels.",
                    "label": 1
                },
                {
                    "sent": "Now so recently there have been a lot of study devoted to learning the Colonel from the data.",
                    "label": 0
                },
                {
                    "sent": "So in general, the approach for current learning can be categorized into two categories.",
                    "label": 0
                },
                {
                    "sent": "The first one is to learn a particular parameter involving kernel function.",
                    "label": 0
                },
                {
                    "sent": "For instance, you can learn the kernel weights in RBF function.",
                    "label": 0
                },
                {
                    "sent": "You also could win the parameters involving the kernel division Colonel.",
                    "label": 0
                },
                {
                    "sent": "Now a different approach.",
                    "label": 0
                },
                {
                    "sent": "Attorney approach for kernel earnings is too and contact this number magic coloring.",
                    "label": 0
                },
                {
                    "sent": "So in this case that you don't make any assumption about the parametric form, the kernel and so instead of learning a kernel function, then you focus on learning a kernel matrix.",
                    "label": 1
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here I'm listing a few I believe are very important to work in this kind of learning, and this by no means the exhaust lists.",
                    "label": 0
                },
                {
                    "sent": "And so while the first one that the present is this kernel line, when the goal is to identify the optimal kernel that align well with the class labels.",
                    "label": 1
                },
                {
                    "sent": "I'm so this worker learning kernel is the same definite programming.",
                    "label": 1
                },
                {
                    "sent": "Essentially you identified opting kernel by maximizing your classification margin.",
                    "label": 0
                },
                {
                    "sent": "There's a lot of work being inspired by this for the multiple kernel learning.",
                    "label": 0
                },
                {
                    "sent": "OK and then this non parametric graph kernel running essentially adding additional constraint to the kernel alignment approach.",
                    "label": 1
                },
                {
                    "sent": "And then this work of learning the low rank kernel matrix.",
                    "label": 1
                },
                {
                    "sent": "So essentially you start with some initial guess, the kernel and then you have additional class labels.",
                    "label": 0
                },
                {
                    "sent": "So your goal is to identify the kernel that on one hand that are consistent with your initial guest kernel matrix.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, also consistent with your translate.",
                    "label": 0
                },
                {
                    "sent": "Oops, sorry.",
                    "label": 0
                },
                {
                    "sent": "OK, so so our work active cooling essentially is built on the last work, which is our work published in last years.",
                    "label": 0
                },
                {
                    "sent": "I see ICM L I'm so.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "This week all the nonparametric kernel running and essentially you been given two things.",
                    "label": 1
                },
                {
                    "sent": "One is you been given a similarity matrix, so in this case you don't require any positive Sam.",
                    "label": 0
                },
                {
                    "sent": "Definitely property of this similarity matrix an 2nd instead of given the label examples to be given the pairwise constraints.",
                    "label": 1
                },
                {
                    "sent": "So for instance you have lost link versus cannot link those become the guidance for you to identify the optimal kernel matrix.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now, although there has been an extensive study on both the methodology for the kernel learning and the efficient learning algorithm towards identified optimal kernel, however, I know that most of those works can be labeled as a passive kernel.",
                    "label": 0
                },
                {
                    "sent": "Learning other words that all the existing work assume that label the information at the labor examples or labeled pairs being given before hand, and then after that kernel learning method will take.",
                    "label": 1
                },
                {
                    "sent": "Those label the information as input and generate appropriate kernel.",
                    "label": 0
                },
                {
                    "sent": "My parent has all the active learning researcher.",
                    "label": 0
                },
                {
                    "sent": "Would argue this may not be the most efficient means to build up to an kernel matrix, so therefore the straightforward process should be.",
                    "label": 1
                },
                {
                    "sent": "How about we turn the passive kernel learning into active one?",
                    "label": 1
                },
                {
                    "sent": "So like any active learning approach, you like to an active select and those labeled examples are labeled pairs.",
                    "label": 0
                },
                {
                    "sent": "That should be mostly informative to the target kernel matrix that you aim to learn.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So as I emphasized that our work is essentially build on last year's nonparametric kernel, learning that we did.",
                    "label": 1
                },
                {
                    "sent": "OK, now again, as first speaker being discussed extensively, which for any kernel active learning, the key issue here is what are the right criterion for selective sampling.",
                    "label": 0
                },
                {
                    "sent": "The example in this case is example pairs.",
                    "label": 0
                },
                {
                    "sent": "Now if we follow the conventional approach of active learning, essentially try to reduce the variance of the classifier, then we pretty well follow this.",
                    "label": 0
                },
                {
                    "sent": "I could uncertainty principle that essentially you would like to select those example or example pairs that are most uncertain to be classified.",
                    "label": 0
                },
                {
                    "sent": "Now in our case we aim to select the example page.",
                    "label": 0
                },
                {
                    "sent": "Now if we believe our elements in the kernel matrix are very well adjusted.",
                    "label": 1
                },
                {
                    "sent": "In other words, if we assume that the large positive value of kij indicates the two, the pair excellent actually are likely to be in the same class.",
                    "label": 0
                },
                {
                    "sent": "While the large negative kij indicates there likely to be in the different class, then we probably can use the absolute value of the kij as the indicator of uncertainty.",
                    "label": 0
                },
                {
                    "sent": "Therefore, the very first approach that you can think about by following this uncertain uncertainty principle is to identify those example pair that has the least absolute value of the Kij case.",
                    "label": 1
                },
                {
                    "sent": "The Colonel you learned and those become.",
                    "label": 1
                },
                {
                    "sent": "Those become the informative example pairs.",
                    "label": 0
                },
                {
                    "sent": "Now I should argue that although this seems to be various.",
                    "label": 0
                },
                {
                    "sent": "A straightforward an intuitive approach to go with, however one that there have been a few drawback with this approach.",
                    "label": 0
                },
                {
                    "sent": "One empirically we find out that turns out this approach tends to select a certain type appears.",
                    "label": 0
                },
                {
                    "sent": "In particular, we find that must link pairs tends to be more likely be selected by.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This approach so for instance, if I'm looking at this.",
                    "label": 0
                },
                {
                    "sent": "Example here.",
                    "label": 0
                },
                {
                    "sent": "So let the panel shows the exam.",
                    "label": 0
                },
                {
                    "sent": "The double Sparrow examples and the fuel line segment indicates either the mass Lincoln Muscle Link, so those are being the pairwise constraint being given to the learning errors, so the right right Colonel right panel shows that.",
                    "label": 0
                },
                {
                    "sent": "Example pairs being selected by this simple.",
                    "label": 0
                },
                {
                    "sent": "And so then the principles.",
                    "label": 0
                },
                {
                    "sent": "So as you can see, the line segment there are also solid indicates that most appears these select by these algorithms tends to be the.",
                    "label": 0
                },
                {
                    "sent": "Mathlinks, so we at least we empirically find that this approach seems to favor the mathlink pairs versus cannot link.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so the main contribution of this work is when we try to present a slightly more principle framework.",
                    "label": 0
                },
                {
                    "sent": "We called min Max principle for the active learning and we extended to the kernel learning active current learning and we also shows convex relaxation of the proposed framework.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For active kernel learning.",
                    "label": 0
                },
                {
                    "sent": "So I have to spend a few minutes reviewing my our previous work on the kernel running.",
                    "label": 0
                },
                {
                    "sent": "So as I said, the idea is trying to learn the kernel from two things.",
                    "label": 0
                },
                {
                    "sent": "The first one is this pairwise constraints, and so we have this matrix T which is in cocoa, encodes all the pairwise constraints.",
                    "label": 1
                },
                {
                    "sent": "Whenever the excellent extra in the same class which is called must link, there's a one value assigned to the corresponding element.",
                    "label": 1
                },
                {
                    "sent": "And then there will be the negative form whenever decks either J in a different class and this is called the cannot link for all those element pairs that hasn't been labeled.",
                    "label": 0
                },
                {
                    "sent": "We give the zero value, so that's the way we encode this pairwise constraint.",
                    "label": 0
                },
                {
                    "sent": "An additional information is this similarity measurement, so we assume this initial similarity measurement tells you how similar or different to example.",
                    "label": 0
                },
                {
                    "sent": "And that is encoded in the matrix.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "S so go here is to combine these two quantity S&T to getting a proper kernel image.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Chicks.",
                    "label": 0
                },
                {
                    "sent": "OK, so so this is our single framework for kernel learning.",
                    "label": 1
                },
                {
                    "sent": "So here the capital J here is the target kernel.",
                    "label": 1
                },
                {
                    "sent": "We aim to find.",
                    "label": 1
                },
                {
                    "sent": "So in the very first determine object function which is a trace of LJ.",
                    "label": 0
                },
                {
                    "sent": "So error here is a Laplace grapher processing of the similarity matrix.",
                    "label": 0
                },
                {
                    "sent": "So therefore that race between the air and Jay is essentially to measure the consistency between.",
                    "label": 0
                },
                {
                    "sent": "The target occur and the similarity measurement, and we have this second and try to minimize the upstream square.",
                    "label": 0
                },
                {
                    "sent": "So if so here is again try to measure the inconsistency between the target kernel and the pairwise constraints.",
                    "label": 0
                },
                {
                    "sent": "That largely this then more disagreement.",
                    "label": 0
                },
                {
                    "sent": "These two things are.",
                    "label": 0
                },
                {
                    "sent": "So that's roughly our.",
                    "label": 0
                },
                {
                    "sent": "Simba",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Framework.",
                    "label": 0
                },
                {
                    "sent": "OK, so so in order to extend this simple framework to the active learning, and as we said, the key question here is try to measure the inform list of any pairs.",
                    "label": 0
                },
                {
                    "sent": "So to that end, they'll consider, in addition to a number of pairwise constraints have been given.",
                    "label": 0
                },
                {
                    "sent": "Now consider you have a additional pairs X, XC and XL.",
                    "label": 0
                },
                {
                    "sent": "Now if some details you the class labels, let's say why.",
                    "label": 0
                },
                {
                    "sent": "OK so the one way to see that how informative is PDX KXL together with this class?",
                    "label": 0
                },
                {
                    "sent": "Labels is just by measuring how this additional pair well affect the overall objective function.",
                    "label": 1
                },
                {
                    "sent": "Now if this additional pair an can be very well predicted by the existing.",
                    "label": 0
                },
                {
                    "sent": "On pairwise constraints, then, you don't expect it.",
                    "label": 0
                },
                {
                    "sent": "The object function will change significantly only when these additional pair are not very well predicted by the existing pairwise constraints, then you expect the overall object function will be.",
                    "label": 0
                },
                {
                    "sent": "Be influence substantially, so that's actually the fundamental star that we have to handle this informative management.",
                    "label": 0
                },
                {
                    "sent": "So here that given a pair XK&X error, we introduce this quantity.",
                    "label": 0
                },
                {
                    "sent": "We called Omega KLY and this is the quantity essentially just measure the optimal value after object function that with using the existing pairwise constraints.",
                    "label": 0
                },
                {
                    "sent": "And together with this new pairwise constraint, which is XKXL and then with the label Y. OK, so as you can see I highlighted by the red rectangles and that is the additional constraint introduced by this additional pairwise constraints.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is as I had before, that essentially, if you have if this pair XKXLR, ferry, quote, unquote, consistent with all the pairs, that pairwise concern that you have, then.",
                    "label": 0
                },
                {
                    "sent": "You will always can find a proper choice of class label right such that this Omega function will not change too much.",
                    "label": 0
                },
                {
                    "sent": "And in the meantime, if actually choosing the inop inappropriate and class label right, then you expect this Omega KLY will change significantly, so.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "One way to summarize this simple intuitive as the way to measure the the in form lists of the example pair is to consider worst case scenarios.",
                    "label": 1
                },
                {
                    "sent": "So that is you have the pair and then you measure the Omega K error versus some class labels because you have no idea what is the property cast members.",
                    "label": 0
                },
                {
                    "sent": "Now you can see the the class members that leads to the largest jump of the.",
                    "label": 0
                },
                {
                    "sent": "Object function.",
                    "label": 0
                },
                {
                    "sent": "So, as I argued that if a pairwise if this picks K&X error.",
                    "label": 1
                },
                {
                    "sent": "I consistent with the existing pairwise constraints, then by choosing the wrong class labels.",
                    "label": 0
                },
                {
                    "sent": "Indeed, well, very significantly change the object function.",
                    "label": 0
                },
                {
                    "sent": "Therefore, and you expect that the discard this cutter and care will be very large for any pair that already been consistent with the pairwise constraint proof.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, so.",
                    "label": 0
                },
                {
                    "sent": "So anyway, if you believe this is right into it, if I have no good theoretic argument for that, but then there will be a simple I mean Max framework for choosing the pairs.",
                    "label": 0
                },
                {
                    "sent": "So we have this carpet care which essentially tells you how I informed him that the example it is.",
                    "label": 0
                },
                {
                    "sent": "Therefore I would like to choose the pairwise pairs that has the list in formless or the most uninformed people.",
                    "label": 0
                },
                {
                    "sent": "Now if we replace the cap with.",
                    "label": 0
                },
                {
                    "sent": "The maximization of Omega over right.",
                    "label": 0
                },
                {
                    "sent": "Then you can see we have a mix of magician problem here.",
                    "label": 0
                },
                {
                    "sent": "OK, so I want to emphasize that one this is not trivial optimization problem because essentially is a big Macs and the 2nd and that's this.",
                    "label": 1
                },
                {
                    "sent": "Omega is actually not closed form function is actually output from some object function.",
                    "label": 0
                },
                {
                    "sent": "Now, as the very first step of the simplification, you can easily show that you can indeed eliminate this maximization.",
                    "label": 0
                },
                {
                    "sent": "This mean Max is essentially is just.",
                    "label": 0
                },
                {
                    "sent": "Illusion is not so.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is fundamental, so by some simple algebra you can show that previous min Max problem is equivalent to the problems.",
                    "label": 0
                },
                {
                    "sent": "I so on the screen, which is nothing, just a simple intimidation problem.",
                    "label": 0
                },
                {
                    "sent": "Now one thing I want to point out is that if you looking at the problem, P1 parent is too.",
                    "label": 0
                },
                {
                    "sent": "Busy so you don't have to look at anyway, so so the P1.",
                    "label": 0
                },
                {
                    "sent": "If in the P1 that you actually fix the variable Z, which is the target kernel matrix, you aim to find.",
                    "label": 0
                },
                {
                    "sent": "Then turns out you have a very interesting results that we showing on the second panel of the screen.",
                    "label": 0
                },
                {
                    "sent": "So so that means that if you fix the AC turns out you're going to get the heuristic of searching the pairs that exactly as the uncertainty principle pointed out.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Now, so solving this P1 problem is quite expensive.",
                    "label": 0
                },
                {
                    "sent": "The reason is that you have to solve it for every single pair.",
                    "label": 0
                },
                {
                    "sent": "So I highlight this.",
                    "label": 0
                },
                {
                    "sent": "Index scale right?",
                    "label": 0
                },
                {
                    "sent": "So here you really have to consider all the post prepare Karen the computer quantity for every single page and that is way too much so the various tree for the way you can think about to eliminate this computational challenges by introducing some additional variables.",
                    "label": 0
                },
                {
                    "sent": "For instance, you can introduce the continuous variables PKL and to indicate how likely that each pair.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Robbie Select and you can relax your problem by using this variable P care.",
                    "label": 0
                },
                {
                    "sent": "So here PKL is a continuous variable in the case, the chance of selecting certain variables and as I highlighted in the red rectangle and as you see that you can essentially aggregate all the pairwise computation into one single optimization problems.",
                    "label": 0
                },
                {
                    "sent": "Well, the bad news is you can prove this is non convex so.",
                    "label": 0
                },
                {
                    "sent": "And that essentially you will learn some local maximum.",
                    "label": 0
                },
                {
                    "sent": "So what I did is I relax this problem into a convex optimization problem.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "OK, so the key observation is the follows that is the big travel here indeed is this linear constraints together with the terms in object function, relates to this federal P care.",
                    "label": 0
                },
                {
                    "sent": "I'm so the first thing I do is I replace this linear constraints with another.",
                    "label": 0
                },
                {
                    "sent": "Seems to be much more complicated constraints, so here are utilizing.",
                    "label": 0
                },
                {
                    "sent": "The simple fact that arithmetic mean should always be largely couldn't the harmonic mean?",
                    "label": 0
                },
                {
                    "sent": "So if I view this linear constraint essentially bound constraint on the arithmetic mean, then I can replace it with the harmonic mean, which will strengthen the constraints.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if you do that, then essential resources you're going to replace.",
                    "label": 0
                },
                {
                    "sent": "The variable P care with another variable which is HK and this age care is essentially the inverse of the PKL.",
                    "label": 0
                },
                {
                    "sent": "Now, the reason we want to do this is because you can show by this replacement to inside.",
                    "label": 0
                },
                {
                    "sent": "The problem becomes perfect convex optimization problem indeed is essentially same definite programming problem.",
                    "label": 0
                },
                {
                    "sent": "Now the only thing I want to point out is that this version of replacement is not exactly equivalent to the problem that you aim to solve before.",
                    "label": 0
                },
                {
                    "sent": "However, you can always show that output value option value that output by this optimization problem is always be the the upper bound of the previous one.",
                    "label": 0
                },
                {
                    "sent": "Therefore, by minimize this subject function, essentially reduced object function of the previous language.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Speed.",
                    "label": 0
                },
                {
                    "sent": "OK, and then we have a few more discussion in the paper about how can you solve this more efficiently from the viewpoint of duality.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so maybe.",
                    "label": 0
                },
                {
                    "sent": "Quickly goes to the pad of the experiments, so we have run this over the nine different data set.",
                    "label": 0
                },
                {
                    "sent": "As you can see now in a very large data set, and all this because the SDP is something that nobody likes, but essentially you have the server, so the two datasets are the 1st two are the.",
                    "label": 0
                },
                {
                    "sent": "Synthetic data set and the remaining 7 datasets from the.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "UI.",
                    "label": 0
                },
                {
                    "sent": "So we have this problem.",
                    "label": 0
                },
                {
                    "sent": "The experiment setup with the two different.",
                    "label": 0
                },
                {
                    "sent": "The baseline very first line, just the random sample, the pairs and the second one is one that we discussed at the beginning.",
                    "label": 0
                },
                {
                    "sent": "You select the example pair that has the least absolute value of the elements in your compute kernel matrix and we called it the akl mean at dash mean Dash A through Z and.",
                    "label": 0
                },
                {
                    "sent": "The approach that we have here is we denote by a KL dash, mean dash H. So the way we evaluate the estimated kernel is by the class ring.",
                    "label": 0
                },
                {
                    "sent": "So the belief that is that if you have a good kernel matrix, you aim to get a better clustering results, so they were using the conventional question accuracy as the way to measure the quality of clustering.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so here I only just show you the results over the three data set remaining you can find in the in the paper.",
                    "label": 0
                },
                {
                    "sent": "So the horizontal axis here is the number of iteration you have and the vertical axis at accuracy of class ring and you see there's a 3 lines of.",
                    "label": 1
                },
                {
                    "sent": "Let me point out the the set up the experiment.",
                    "label": 0
                },
                {
                    "sent": "So initially these three experiment these three data set being given 100.",
                    "label": 0
                },
                {
                    "sent": "Random Select appears and then each iteration additional 20 pairs will be selected based on different criteria.",
                    "label": 1
                },
                {
                    "sent": "So there's three lines correspond with three different methods, and the red line corresponds to the method that proposed in this paper, and as you can see, for all the cases that we have some noticeable improvement compared to both the random selection and the selection based on the least absolute value of.",
                    "label": 0
                },
                {
                    "sent": "The elements in the estimate Colonel.",
                    "label": 0
                },
                {
                    "sent": "OK, and would surprise in some case.",
                    "label": 0
                },
                {
                    "sent": "First.",
                    "label": 0
                },
                {
                    "sent": "For instance, if you look at the results for the solid result, random selection is not a bad choice at all, and I think this probably to some degree confirm the.",
                    "label": 0
                },
                {
                    "sent": "Discussion that you've seen for.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The tag.",
                    "label": 0
                },
                {
                    "sent": "OK, OK, so let me just conclude my talk.",
                    "label": 0
                },
                {
                    "sent": "So basically we present a min Max framework as the way to handle the active kernel learning and we have a convex relaxation allows us to solving the problem, quote, unquote, efficiently and then we show some encouraging results occur over rather small relative modest size dates.",
                    "label": 1
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Very good question.",
                    "label": 0
                },
                {
                    "sent": "I have no idea I was origin should cannot link should be the one dominate because it has much higher prior so that he has something to do with the learning.",
                    "label": 1
                },
                {
                    "sent": "The kernel learning mechanics is but I don't have clear reasons.",
                    "label": 0
                }
            ]
        }
    }
}