{
    "id": "acos65anycftjuzi5rtvybuqhxbbmlvu",
    "title": "Averaging algorithms and distributed optimization",
    "info": {
        "author": [
            "John N. Tsitsiklis, Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, MIT"
        ],
        "published": "Jan. 13, 2011",
        "recorded": "December 2010",
        "category": [
            "Top->Computer Science->Algorithms and Data Structures"
        ]
    },
    "url": "http://videolectures.net/nipsworkshops2010_tsitsiklis_aad/",
    "segmentation": [
        [
            "OK, good morning.",
            "I would like to thank the organizers for inviting me.",
            "It's great to be, it's to be here.",
            "It's been a long time since I last came to NIPS and of course the location is wonderful.",
            "I would like to add to thank you, specially John Duchi for making all sorts of arrangements and making sure I'm having a great time here.",
            "So I'm going to talk about the subjects that hopefully is at least tangentially related to the subject of this workshop.",
            "And it's a topic on which I accidentally run into about 30 years ago.",
            "Then the topic kind of went out of fashion and then has reappeared these days."
        ],
        [
            "And lots of people being interested in it and doing work on it.",
            "So what I'm going to be talking about is.",
            "Algorithms that have to do with optimization, distributed optimization and at the same time be behind the algorithm.",
            "There's also sort of averaging algorithm running simultaneously that tries to reconcile the results of different processors, so I'm going to start quickly with some motivation and applications going to discuss how averaging and consensus algorithms show up specifically within the context of distributed optimization.",
            "And then taking that as further motivation will focus just on the subject of consensus and averaging algorithms and try to say as much as we can about the time they take to converge.",
            "Talk about a few different variations and come up and eventually conclude with a couple of open problems in this area."
        ],
        [
            "So what's this setting?",
            "It's a trivial problem embarrassing to talk about.",
            "It's basically elementary school math.",
            "You have a bunch of agents or processors, or where you want to call them.",
            "Each one starts with a certain initial value and they need want to exchange some messages and come up with consensus or agree on the final value that falls somewhere in the range of the different values.",
            "So think of XR as being just a weighted average of the initial values that everyone is having.",
            "A special case of this is if you're interested not just in agreement, but you also want this agreement to happen on the average of the initial values of each agent and the further special case of this is if you want to do voting so everybody starts with a value that's either plus plus or minus one.",
            "So think of these voice votes in favor or against the something, and you want to see what fraction of the all of them is in favor or against.",
            "So the problem is pretty trivial.",
            "But what?"
        ],
        [
            "We're interested in is in doing it in a truly distributed way without necessarily synchronizing the agents or the processors, and without doing the sort of trivial solution which is to set up a spanning tree, communicate messages along the spine, it 3 add up the axis and divide by N, so there's clearly trivial solutions to this problem, but in some contexts these are considered to be undesirable, so this takes us."
        ],
        [
            "To try to solve the problem by doing simple updates of the following type, I'm sitting in network I'm node I. I talked to a neighbor whose Ji tell him I tell her my values.",
            "It tells me her value and each one of us resets their own value to the average of the two.",
            "Now everybody keeps doing this simultaneously.",
            "You hope that in the end basically differences between different processors will start shrinking.",
            "And eventually you will get convergence performance value.",
            "So this is the type of methods we were interested in.",
            "OK, so this is."
        ],
        [
            "Pretty trivial yet so many people seem to be interested in it.",
            "This type of models have started showing up for lots in the social Sciences and sort in all sorts of areas you could imagine.",
            "People sometimes think that perhaps when experts sit in a room and they try to come up with some estimate of something and they keep discussing perhaps the evolution of their discussion is described by a simple mechanism like the one I suggested at the end of the previous slide."
        ],
        [
            "And basically, social scientists sometimes say that humans are not necessarily as rational as most economists pretend them to be, so they actually behave by certain simple rules of thumb, and maybe a very simple mechanism like the one that I described could be a description of what?"
        ],
        [
            "Happening so social scientists can get excited with this.",
            "Basically they write down models of this kind and then try to analyze them.",
            "Come up with descriptive theories and of course add narratives to it.",
            "That is, you make a mathematical model.",
            "You saw that the model that something, and then you start making stories about what might be happening in the real world."
        ],
        [
            "Closer to our interests is the engineering context and the simple, trivial method that I described two slides ago that basically check with your neighbor and take the common average have shown up in the last few years all over the place in lots of different applications from distributed computation, networking, an people in control theory have also caught up.",
            "So for example, in Clock synchronization every processor.",
            "Has its own Clock you would like blocks of different processors to agree what you do.",
            "I check my Clock, check the Clock of my neighbor if there's a discrepancy.",
            "We try to set our clocks A little closer to each other, so this is an instance of a consensus type of problem where we basically want our clocks to agree, not necessarily on the correct value, but at least to agree.",
            "Different setting might be load balancing where we start with unequal loads and we want to loads to be balanced so that every processor ends up having.",
            "The average of the initial loads of all processors.",
            "So easy way to do this is you check with your neighbor if your neighbor has less load than you do, then you kind of split the difference and the relative loads become closer to each other.",
            "If everybody is doing this simultaneously, you hope that in the end loads will end up being balanced.",
            "OK."
        ],
        [
            "So the let me add.",
            "Take the simple method.",
            "They described a little while ago.",
            "Love you.",
            "Check with your neighbors and everybody.",
            "Move the two of them.",
            "You and your neighbor moved to the average of your value so you get closer.",
            "Let's generalize this a little bit, and this apparently first showed up in the literature in 1974 when the group suggested a model of how people might reconcile opinions.",
            "And here's the model that the group proposed.",
            "Every person person I has certain value.",
            "XI of tea and each time everybody think of these as opinions about something, everybody updates their own opinion by by looking at the opinions of the others and forming a convex combination or a weighted average of the opinions of the others.",
            "These AI Jays are the weights that you give to your neighbors.",
            "AJ is the weight you give to neighbor J, but you can think also that the agents are interacting through a certain communication graph.",
            "Who are not all pairs are present?",
            "In that case, AIJ is going to be 0 if an edge is absent from the network.",
            "AIJ can be non zero only if there is an edge.",
            "So the idea is that J sends a message to Y through an edge of the network and then Agent I updates its own opinion by taking a convex combination of the opinions of all other agents.",
            "So this is a convex combination or weighted average.",
            "So the sum of the AI JS has to be equal to 1.",
            "If you write this iteration in matrix form, it's it's just this and the a matrix has a lot of special structure.",
            "It's what we call a stochastic matrix, and you can think of this a matrix.",
            "Well, it's the metrics that you would get if you were describing a Markov chain, and in particular a is the metrics.",
            "Think of it as the metrics of transition probabilities for Markov chain on the different nodes of the graph.",
            "So think of AIJ as a probability of jumping from I to J.",
            "Now, there's no randomness, there's nothing Markoff.",
            "About the consensus process that's happening up here, but mathematically the model is isomorphic to one involving Markov chains, and this means that you can bring to bear all the tools from Markov chains to this setting and the particular Markov chain theory tells you that as long as this graph is reasonably connected, the products of a two of the a matrix with the powers of that matrix converge to a matrix that has equal rows and the elements.",
            "On those rows are the steady state probabilities of the Markov chain, and when you translate that statement to this problem, it basically tells you that all the excise the opinions held by the different agents, they all converge to a common value and that common value is a weighted average of the initial values that the agents had when the process started, and those by Jays the weight that is given to each one of the initial values that can be interpreted or.",
            "It is essentially the steady state probability of state J in the Markov chain view of this process.",
            "You can also leverage on Markov chain theory to get estimates about the."
        ],
        [
            "Virgins rate or time until this method converges to near consensus.",
            "OK, special case of this is the case of averaging.",
            "So if we actually want to compute the averages instead of just obtaining consensus, then you have to put some restrictions in the types of weights that are being given here that are used here.",
            "So what one does to get an averaging algorithm is to use a metrics A, which is doubly stochastic.",
            "What that means is that so in a in a transition probability matrix there's some of the entries are longer, roll have to be equal to 1 because their probabilities.",
            "We say that the metrics is doubly stochastic if at the same time the some of the entries in each column is equal to 1.",
            "So from the left multiply with the old one vector times the metrics a must give you again the vector of all ones.",
            "So one's times a column must give you one.",
            "What happens in this case is that no matter what X you have the some of the entries of the X vector.",
            "After you do an update, the sum is preserved.",
            "So by taking A to be doubly stochastic matrix, this iteration conserves the sum of the values of the axis, and so if you have convergence and the sum is preserved, the only thing that you could converge to is the average.",
            "So we have stochastic matrices for the case of when we want to get consensus, we have double stochastic matrices.",
            "If we want to get averaging.",
            "Alright, so this is the basic structure of the.",
            "Averaging or consensus."
        ],
        [
            "Algorithms I'm going to be looking at, so now let's with this as background.",
            "Let's start talking about distributed optimization algorithms, and I'm going to start from the pretty trivial and basic and add."
        ],
        [
            "A little bit of bells and whistles as you as we go on, so we're going to talk about gradient like methods people in nonlinear optimization felt kind of snob gradient type methods for a long, long time because there are just two simple and we're probably favor more complex methods like Newton method and so on.",
            "But when you're dealing with huge problems and lots of variables and lots of data, one really wants to use simple methods, so gradient type methods have had a little bit of a resurgence lately.",
            "So going to look at the simple problem minimum, you want to minimize cost function, which is we assume throughout it's a convex function to keep discussion simple and the special case of particular interest is when this cost function is actually a sum of many individual cost functions.",
            "In the context of this session, you could think of the eyes as being loss functions associated with blocks of data.",
            "SO1 processor might have a big block of data.",
            "Write down the associated loss function.",
            "That's the FI you want to minimize the total loss.",
            "That would be the sum of the FIS the way gradient like method tries to optimize this function is to use the gradient of the function and do an update of the form.",
            "You are at a certain place and make an update by moving in the direction of the negative gradient.",
            "So this is a direction of dissent.",
            "It's a direction along which the cost function decreases and you make a step in that in that direction.",
            "Of interest also, our methods were one measures the gradients, not exactly, but who?",
            "In the presence of some noise.",
            "For example, if you're getting noisy data about a certain situation and you're trying to estimate some parameters, you might think you might get situations of this kind.",
            "So the data that I'm using at a certain point is the gradient of my cost function plus some noise, and they make step again in the direction of the measurement that I got.",
            "When I say noise, I always think of something that's zero mean plus a few extra technical assumptions that I will not get into.",
            "But so in the sense of expected values, you are still moving in a direction that decreases your cost function.",
            "On the other hand, you cannot really absolutely sure if you are moving in that direction because there is noise, but in expectation you're doing the right thing in order to kill the effects of the noise.",
            "At least in theory, what one has to do in this context is to let the step size change with time and use a smaller and smaller step size as you go.",
            "So when the."
        ],
        [
            "Community, I guess you would say that the learning rate has to decrease as you go as time goes in order to get 0 error in the limit.",
            "Elf interest is also the case when the function F is not smooth, in which case you'd cannot form the gradient.",
            "Then you work with subgradients of the costs of the cost function.",
            "Well, what's the subgradient?",
            "Well, if you have a convex function, the gradient is basically the slope of the convex function at a point.",
            "If you have a non smooth function, so let's say it has a corner at some place, the subgradient would be any slope that's kind of compatible with that corner in the sense that it sits below.",
            "So it's just the natural generalization of the notion of a gradient for the smooth, nonsmooth case.",
            "So in this case, you want does again the same you update by moving in the negative direction of the of subgradient, and if there's noise, you can still run a method of this kind.",
            "Are the simplest, simplest versions.",
            "There's more a lot and more sophisticated stuff out there in the optimization literature that I will not."
        ],
        [
            "We get to let's we can start thinking just about in terms of these very simple models.",
            "So how can one start parallelizing or distributing a computation such as the one with the gradient methods?",
            "Very simple way of doing things is to if the vector X is kind of high dimensional and you assign a different components of the X vector to different processors or agents.",
            "As I have been calling them now in order to do the optimization when I'm process or I and I'm going to be updating the ice component.",
            "But I also need to take into account where everybody else is so I need to keep track of the components that have been calculated by others.",
            "So let's think about the following situation.",
            "Every agent keeps an entire vector.",
            "Call it X superscript I.",
            "And keeps track of the components of all agents.",
            "So these components are indexed by J.",
            "Now XI agent I is the master for the ice components.",
            "So Agent I goes ahead and updates that I've component in the direction of the gradient where the gradient is evaluated on the vector.",
            "That agent I currently has now that vector of Agent I have the correct value for the ice component and has what for the other components for the JSF components he has whatever he last heard.",
            "From the other agent J.",
            "So we do not assume that the agents communicate and think change results each time, but just once in awhile.",
            "So once in awhile Agent J sends a message to Agent I with the value that J has for the J component.",
            "An agent I takes that value and will use it in subsequent computations.",
            "And let's assume that this happens not every time, but occasionally, let's assume that it happens once every capital B time units were B is.",
            "Upper bound it has to do with our communication network architecture and."
        ],
        [
            "So one, so how will this method behave?",
            "This is very much like the textbook gradient methods, except that the gradients that an agent is using in order to have an iteration is evaluated at, sorted at the wrong place at an inconsistent vector.",
            "So everybody has a different vector X superscript I becauses I just heard from everyone.",
            "But maybe somebody else has not yet heard from everyone.",
            "So we may be updating with outdated Val.",
            "Use so in general the JS components possessed by Agent I could be up to be time steps out of date.",
            "So how do we analyze this?",
            "Well, let's keep track of a vector that has sort of the official values, not the outdated values component one as possessed by Agent, One who is in charge component an as possessed by agent, and who is in charge, and so on.",
            "So this is sort of the the official.",
            "Current result from the method.",
            "Now be cause an agent.",
            "Maybe it may have been some time before I heard from everyone else.",
            "My vector that I have might be a bit out of date compared to this Y vector.",
            "How far out of date could it be?",
            "Let's assume that the gradients are bounded by some constant.",
            "Then how far out of date can agree it's being bit time steps since I last heard from another agent during those big time steps, that agent may have done.",
            "Be updates and during each update that other agents moved at.",
            "By by order of Gamma, which is the step size.",
            "So this is how much another agent may have moved its own value since I last heard from them.",
            "So I'm out of date by this amount.",
            "So this means that everyone is computing using an incorrect gradient because it's a valuated at the wrong place, but it's the same as if it was evaluated in the right place except for some error term.",
            "How big is the error term?",
            "Well, the difference is due to the fact that XI is different than Y.",
            "This difference is order of big gamma and because the steps are order of gamma, the difference, the resulting difference in the update is order of.",
            "Be gamma squared.",
            "So what's important here?",
            "What's important is that the effects of this kind of a synchronism that we have our of 2nd order in gamma.",
            "So when gamma is reasonably small, the 2nd order term will be will be less than the 1st order term.",
            "So up to 1st order the method still behaves as a correct gradient method and that basically shows that such a gradient type method, but where you have outdated and delayed information about what the other processors have done.",
            "Such a method will still behave properly, so."
        ],
        [
            "Whatever theorem you can prove under your favorite assumptions for gradient methods in the standard nonlinear programming textbook setting, these results will also go through in this case and you get convergence to convergence to a point where the gradient is equal to 0.",
            "So for convex functions, that would be an optimum point.",
            "Something to notice is that in order to get the let the argument go through, what we need is this term to be.",
            "No bigger than the dominant term that is the gradient.",
            "So for this to happen, we basically need B times gamma to be less less than a constant.",
            "So the so in particular the step size has to become smaller and smaller.",
            "If the communication delays are larger and larger, Yep.",
            "I'm not showing that dependence, but of course there would be.",
            "OK."
        ],
        [
            "So whatever theorem there is for centralized gradient methods in nonlinear programming texts and whatever theorems there are also for the stochastic case, these are so called stochastic approximation algorithms.",
            "These will also do go through and such a method convergence even with this bit of chaos in the way processors coordinate.",
            "Yep.",
            "What is it considered I mentioned?",
            "Because if if the darkness is for example linear, then you have to decrease, to solar rate record or probably don't get compilers.",
            "I.",
            "Yes.",
            "Yeah, there will be independent dimension, but then one has to start.",
            "You have Sir becoming a lot more specific about assumptions about the structure of your function F and so on, and this would take me somewhere different tangent from what I'm looking at here.",
            "So.",
            "So let's just keep that in mind that there is dependence of the dimension, but I want to concentrate more on the effects of the communications on this.",
            "OK, so now instead of having every agent being in control of a single component, you could think of an alternative setting where everybody is interested in the same vector.",
            "Everybody is going to update the entire vector, but for some reason we my, our computations might turn out to be a little different and then we want to reconcile them.",
            "Together so suppose that every agent now I will indicate agent, not component.",
            "Suppose that everyone does upstairs and nabla, and there's a gradient at Del missing from there.",
            "So everybody doesn't update if everything is deterministic, everybody is using the same cost function.",
            "Everybody does the same update, so there's nothing to be reconciled here.",
            "So that would be an uninteresting situation.",
            "But if you have updates that involve noise."
        ],
        [
            "Is then it does make sense to proceed, this follows.",
            "Everybody is interested in that vector in that vector processor.",
            "I has a vector XI, gets a measurement and carries out an update, and then you reconcile the updates of everyone by taking the average.",
            "What the such an average does is?",
            "It smooths out the effects of the noise is it reduces the noise variance.",
            "So this could actually be useful and."
        ],
        [
            "The the that's my favorite picture from my PhD thesis from last century, where the idea was that you have some process here that generates noisy data and you're trying to identify the parameters of the process and you have two processors and these processors they do updates of the usual type that you have in system identification, so one, but they exchange their estimates and they keep reconciling them.",
            "So there's a legitimate story that comes for this case."
        ],
        [
            "So how would the analysis of such a method goal?",
            "Well, let's think of running this method in a two phase version.",
            "Everybody doesn't update of the ice component using gradient like step, plus some noise, and then everybody pauses and they run a consensus algorithm.",
            "A consensus algorithm involves the iteration that I introduced some time before.",
            "A is a stochastic matrix.",
            "You keep forming convex combinations of everybody else.",
            "What's going to happen in the limit we all converge to a common value.",
            "And that common value is going to be a weighted combination of the values of the different processors.",
            "OK, and so that's 11.",
            "Basically round of the two phase method.",
            "What happened at the end 12th?",
            "We end up with the common value if we started with a common vector, we're going to end up with the.",
            "OK, now if we start with different vectors X is we have the updates that everyone is doing.",
            "But then because we reconcile the results and we form equated average, we end up with essentially having carried out an update which is a weighted average of the updates of the different processors.",
            "I think there is something slightly wrong with the way I'm using exercise there.",
            "Well, I think you get the idea.",
            "We start with a common vector.",
            "We do our respective updates that take us to slightly different places and then we run the consensus algorithm so we end up again with the common vector.",
            "Net result is that we did an update that was that weighted average of the individual updates that each agent had done.",
            "So."
        ],
        [
            "So is this algorithm sort of doing the right thing?",
            "Yes, it is.",
            "Why the important thing for convergence of gradient methods is that the update that we do is in a direction of dissent with respect to our cost function.",
            "By adding lots of terms, each one of which is in a direction along which the cost function is going down, we still have a method with that property.",
            "So in listing the expected sense, we're making updates that are in a decent direction, and so this thing will still will still converge."
        ],
        [
            "But now let's look at an interesting version of this.",
            "Instead of having two phases where we update, then run consensus, then update, then run consensus, let's do the two simultaneously.",
            "So processor I has a component has a vector XI.",
            "Actually, to make things easier to visualize and parse the slides, let's just think of X as being a scalar.",
            "So we're optimizing a function F of a single variable.",
            "Agents I has his own estimate of what that single variable should be gets messages from the other agents and forms a convex combination.",
            "This is towards the purpose of eventually agreeing on a common value, but also gets his own measurement and makes an update in."
        ],
        [
            "The direction of improvement.",
            "So the two things are now interleaved.",
            "How do we analyze this?",
            "We can analyze this by keeping track of a summary of the values of the different agents, and as a summary I'm going to take the convex combination of the values of the different agents, where the way it's Pi.",
            "I are going to be those pie eyes that show up in the consensus algorithm, so the consensus algorithm associated with the AI JS.",
            "Ends up producing a weighted combination of the XYZ and those weights are the pie eyes.",
            "So why is the vector on which the agents would agree if they stopped updating and just run the consensus algorithm for computing the gradient at a different point?",
            "That point we're updating from?",
            "That's the work.",
            "Computing well agent.",
            "I has a value XI so he can compute the gradient at the point that he knows.",
            "And it makes an update.",
            "The intricacy is that different agents have different XYZ, so they're computing gradients at different places.",
            "Which is sort of incorrect.",
            "And then we want to argue that although it's incorrect, the incorrectness is kind of small and doesn't matter.",
            "Sorry.",
            "No, no one has access to PII, but defining now this quantities and mathematical tool for the purpose of analyzing it, so to keep track of what's happening in this algorithm, it's convenient to look at this quantity Y, which is sort of a summary of what everybody is doing and work with this.",
            "Now the.",
            "Because the Pi eyes are steady state probabilities for the Markov chain associated with the iij's simple algebra tells you that weighted average of this of these terms is the weighted average of the initial values, so.",
            "So do you.",
            "So becausw of when you carry out just the consensus iteration, WHI is not going to change?",
            "And why is only going to change because of that + up?",
            "There should be a minus so.",
            "Huawei does change only because of the updates of the gradient type terms introduced by the different agents, so this is what we would agree on.",
            "If the consensus algorithm was running infinitely fast.",
            "If we don't do any updates, then what we will agree on doesn't change, but if we do updates, then what we will end up agreeing on will be something a little different.",
            "So what happens?"
        ],
        [
            "How do we analyze this?",
            "Well again, let's keep track of how far is the value of a typical agent from the summary value.",
            "OK, well the consensus algorithm has a sort of natural timescale on how quickly it converges.",
            "So basically my being wrong has to do is affected by what happened since.",
            "Let's say I think maybe in terms of sort of phases where we had consensus at some point, But then we kind of lost it and 40 times steps things have been happening and they have not already taken them into account.",
            "So during the time scale of the consensus algorithm, everybody else is updating.",
            "They do so many updates with this step size, and this is roughly the size of their update.",
            "So this is how much everybody else has drifted from me before.",
            "The consensus algorithm had a chance to take effect.",
            "So throw it in here to do the error analysis.",
            "Be 'cause if I put in here the gradient at Y instead of the gradient X, then I'm introducing an error of this order of magnitude where there's an extractor gamma term because my step size is of the order of gamma, and I guess that's the wrong + has made its way his way here.",
            "This should have been a - So basically what I'm trying to argue here is that the.",
            "This message distributed algorithm behaves approximately like a centralized algorithm when you keep track of the vector Y, except for some error terms that have to do with the amount of disagreement and those error terms will have in them the time that it takes for consensus to happen on the.",
            "According to our consensus algorithm, because again, we have second order terms in the step size, it means that if we have to have."
        ],
        [
            "All step sizes.",
            "This method as well, does converge to the place where you would like it to converge under sort of standard assumptions.",
            "OK, so."
        ],
        [
            "Now, let's complicate things just a little bit more.",
            "Suppose now that the cost function is additive.",
            "It consists of several terms.",
            "In which case the optimality conditions would be that the sum of the gradients is equal to 0.",
            "What would you do in this case?",
            "Well, let's start thinking again from the simple version.",
            "If you were to run the algorithm in phases, what you would do?",
            "Now think of the case worth agent.",
            "I has access to the function FI so think of FI is corresponding to the large block of data.",
            "So agents I calculates a gradient based only on its local cost function.",
            "That agent knows.",
            "So this means that even if we all started with the same vector, we would be moving in different directions.",
            "But we want a common vector X, so after that we reconcile our axis by running a consensus algorithm, which convergence once more too.",
            "To some value which is a weighted average of the values of the different agents altogether.",
            "Taken altogether, what would these methods do?",
            "It would do an update in the direction where the gradients or the updates terms of each agent are weighted by \u03c0. I is this the right thing to do?",
            "Well.",
            "If this method converges, what does it converge to?",
            "It will converge to a place where this sum of the gradients is equal to 0.",
            "But this is the wrong optimality condition, so the algorithm is doing the wrong thing.",
            "In this case, what would we need in order to make it do the right thing?",
            "What we need to do?"
        ],
        [
            "Is to have the pie eyes to be all equal, which means that in this particular case we need to run an averaging algorithm.",
            "The metrics a should have a special property of being doubly stochastic, so in the previous version of optimization of distributed optimization, just any stochastic matrix would do to get consensus.",
            "Here we need to make sure that the consensus algorithm we're using is."
        ],
        [
            "Is an averaging algorithm.",
            "So this was the two phased version, now repeating the steps as I was discussing before.",
            "Let us think of an interleaved version where we do both things simultaneously.",
            "That is, we both run an averaging algorithm or that + is still there.",
            "OK, so that of course has to be a - up there, so we run the consensus algorithm and at the same time and then the parenthesis missing gamma also multiplies the step size and we are making updates in the direction of negative.",
            "Of direction of dissent."
        ],
        [
            "Let's see thing."
        ],
        [
            "OK. Alright, how are we going to analyze this one?",
            "How could one analyze this algorithm?",
            "Well, again, you want to keep track of summary of the state of the algorithm, which in this case, since we're running an averaging algorithm, it should be the average of the values of the different agents.",
            "And that's what we would agree if we were to stop updating.",
            "But if you do, if we do an update.",
            "If we do an update, we would do an update in that direction and after running the averaging algorithm, those updates would get an equal weight.",
            "So this is sort of an approximate description of what the algorithm does."
        ],
        [
            "And how do the axes differ from the wise, so the value possessed by a particular agent is going to differ from the summary of the state of the algorithm it's going to differ by factor that has to do with how much have the others done.",
            "Before the consensus algorithm managed to take effect and deliver to similar argument is the one I went through before, but now it has termed that here.",
            "That would involve the sum of the absolute of the magnitudes of the different gradients.",
            "Because these terms have to do with how much everybody else is moving.",
            "And now even if we were to converge to an optimum so that the gradient of the overall function goes to 0.",
            "This term would not go to 0.",
            "And so we this thing would fail to converge to 0 even if the algorithm converges.",
            "And that's clear, it's clear what's happened.",
            "Suppose we are at an optimum, even if we're at the optimum, the gradients of the different FI terms would be non zero.",
            "The gradients adapt to zero at an optimum, but each one of the gradients of the FIS is non 0.",
            "So even if we're at the optimum, everybody would take a step away and then the consensus algorithm might kind of bring them back.",
            "But because they're stepping taking steps away, that means they do not converge.",
            "So for this reason, this in this setting where we're dealing with the sum of the FIS, all the existing literature basically looks at cases where you have an excuse for taking the step size to 0 so that this term actually will will vanish.",
            "And when do we take the step size to zero?",
            "The typical cases are either when we have non smooth cost functions, in which case won't use the subgradient methods which does require a step sizes to go to zero.",
            "Or the case where you have noise which is the stochastic approximation case."
        ],
        [
            "OK. Alright, so once you put throwing the all the right assumptions and so on is this work and Addison's dog Lauren then?",
            "John Ducey and coauthors.",
            "They have results for a variation of this method is slightly more sophisticated version of subgradient methods that shows that these methods will indeed converge and do the right thing.",
            "Now let's look at the big picture.",
            "If you were to start thinking about convergence times, how long doesn't any of the algorithms of the type that we discuss?",
            "How long does it take to deliver a solution that's kind of epsilon close to the optimum?",
            "Well, there's basically two things that are at play here.",
            "You're running a convergent consensus algorithm.",
            "That, and if you think about how much consensus algorithm takes in order to converge to consensus within some accuracy epsilon, this is going to be a function of your epsilon of the number of nodes and the topology of your network.",
            "The dependence on epsilon is kind of trivial.",
            "Becausw consensus algorithms are basically linear systems, so they converge at the rate of a geometric progression.",
            "That means you're going to get the term.",
            "That's basically like log, log, epsilon.",
            "I guess I need an absolute value of in my log.",
            "Or rather it's log one over epsilon, yeah?",
            "OK, so basically that dependence on epsilon is kind of generic, so we're interested in how does the consensus time depends on the number of nodes.",
            "And then there is the optimization side.",
            "If you were to look at the gradient or subgradient algorithm just by itself in a centralized, centralized version of that algorithm, how long does it take to converge?",
            "And in general that has some dependence on the number of nodes and the accuracy that you want.",
            "Now typically these estimates for convergence times of an optimization algorithm have a lot more hidden in there.",
            "You need to make specific assumptions about the structure of your functions put bounds on 1st and 2nd derivatives and all that, and this would somehow show up now.",
            "But nevertheless one way or another people in mathematical programming do their homework and they come up with the rate of convergence of specific optimization algorithms.",
            "If you were to run the two phase version.",
            "Of any of the algorithms I described before, what's two phase?",
            "Do a gradient update, then run a consensus algorithm?",
            "Attila converges?",
            "Do a gradient update, run consensus algorithm until updates?",
            "Then basically we have the gradient algorithm, but each phase of the gradient algorithm needs to take so much time for the consensus algorithm to converge, so this would be the generic convergence time estimate.",
            "The funny thing is that even when we look at Internet."
        ],
        [
            "Live versions of this algorithm when we're trying to do both simultaneously.",
            "That is, while you're updating, also run your consensus algorithm.",
            "The whole the convergence time estimates that I can see in the literature basically have this kind of dependence.",
            "OK, given that we can do that now, the following outsource this to people in mathematical programming and focus on that.",
            "Basically I'm trying to say that there's sort of two separate challenges here.",
            "One is to improve the optimization algorithm.",
            "The other is to improve the convergence times of consensus algorithms and any results that you can get to improve the convergence time of a consensus algorithm automatically will translate to a converge to a faster convergence result.",
            "For a distributed optimization."
        ],
        [
            "So this takes me to the second half of the talk, which will be of course less than 1/2."
        ],
        [
            "And start moving a little faster.",
            "So recall what consensus algorithm does.",
            "But we're taking convex combinations of the values of different agents."
        ],
        [
            "How long do these take to converge?",
            "While you can come up, it's easiest here to think in terms of Markov chains.",
            "You can easily come up with Markov chains whose time until they reach steady state, grows exponentially with the number of nodes.",
            "Think of consensus algorithms.",
            "The most interesting case perhaps is 1, where you give equal weight to all your neighbors.",
            "That is, you get messages from 5 people and you take their values, take my values well, divide by 6 in terms of Markov chains.",
            "That basically corresponds to doing a random walk on, do a random walk on a graph.",
            "So depending on the graph, convergence times will change.",
            "So for general random walks on directed graphs.",
            "It takes an exponential amount for random walks to converge.",
            "That's bad news for directed graphs, things that cannot be 2 buds in the worst cases, order of and tube, and the worst graph happens to be a so called dumbbell graph.",
            "Of course, if you have special cases of graphs, things become better and better on a line consensus or a random walk takes order of N squared to converge, and if you look at even more special case of graph then the convergence time can be even smaller and smaller.",
            "Even going down to Logan in some key."
        ],
        [
            "This is OK. No, already did that."
        ],
        [
            "OK, now."
        ],
        [
            "It happens to the for in the case of averaging algorithm."
        ],
        [
            "For the case of."
        ],
        [
            "Averaging algorithms on BI directional."
        ],
        [
            "Graphs and if you take it, turns out that the convergence time is generically kind of good order of N squared divided by Alpha, where Alpha is a constant.",
            "It's a lower bound on the non negative on the positive entries of the emetrics so positive that Alpha means the following.",
            "Whenever I get a message from somebody else and I take that message into account in my updating, I'm going to give a weight of at least.",
            "For to that neighbor.",
            "Now what should Alpha be?",
            "Well, in case I have neighbors and I'm giving a weight of Alpha to each one of them, my Alpha has to be one over North or smaller.",
            "So in the worst case for graphs that have high degree, my Alpha would be 1 / N and this would give you convergence time of order of Ncube.",
            "The interesting thing is that this is valid for any kind of graph.",
            "We didn't need to make any any assumptions.",
            "Averaging algorithms always take Ncube time to converge, assuming of course that you have connectivity in your graph.",
            "If you have these two disconnected sets of agents, you wouldn't get."
        ],
        [
            "Alright, so that might sort of close the chapter, but here's why.",
            "Don't quite exactly if this framework is not that fully satisfying.",
            "If your deal, if you're running consensus algorithm of this form, X gets updated to aex.",
            "So the coefficients AIJR constant.",
            "We're basically assuming that we have a fixed graph in our network.",
            "Now if you have a fixed graph, why in the world would you run a consensus algorithm by iterating any?",
            "Let you do is take one of the nodes quality leader uniform spanning tree send messages to accumulate values, send them to that leader and then the leader tells the results.",
            "There's absolutely no reason who I I iterate and use a messy and slow method.",
            "If you have fixed graphs.",
            "So this takes us to."
        ],
        [
            "But I believe is a context where things could be interesting.",
            "Or one could make an argument in favor of running a consensus algorithm, and that would be a chaotic or time varying environment in which the consensus algorithm has coefficients that change with time.",
            "Who I do, they change with time.",
            "Suppose that our interconnection graph keeps changing, so links are up and down.",
            "I have a connection, but then the connection is off for some time.",
            "What does that mean?",
            "When the connection is off, AIJ has to be 0, but when the connection is on and I get a message and you take it to that into account, aij of tea is non 0, so the AIJ naturally will have to change with time.",
            "If we have time varying topology.",
            "So this takes us to an iteration of this kind.",
            "So a of Tia metrics now starts depending on time, and we're now dealing with inhomogeneous Markov chains.",
            "If you want to visualize this thing probabilistically.",
            "So now that once we allow variations in the graph, there's basically two ways that you can go.",
            "One is to assume to say yes, we have variations, but these variations are generated according to a very regular.",
            "And time invariant mechanism.",
            "So for example graphs are generated in in dependently identically distributed manner, every time.",
            "So every time step you get a random graph.",
            "Next time you get a random graph, the graphs are changing, but the statistics of the graphs are constant.",
            "So in some sense in terms of expected values, this is not very different from the case of a fixed graph.",
            "Think of a random graph as being a fixed graph plus noise in some sense.",
            "So the expected value.",
            "The a metrics is the expected a metrics plus an error term.",
            "So things go through pretty nicely here and the same traditional analysis by looking at mixing times of Markov chains does work here as well.",
            "No completely regular mechanism for generating those communication graphs would be a bit implausible in settings where you think of.",
            "Some quite disconnected processors who do their own thing and decide to communicate once in awhile, so I'll take the different route and basically let the a matrices."
        ],
        [
            "Changed arbitrarily with time, so I want my algorithm to work for any sequence of topologies.",
            "Now.",
            "Any sequence of topologies, but with some restrictions once in there should be enough ways of everybody to influence everybody else, and we capture this in an assumption that says that every B time steps were B is some constant.",
            "The communications that have happened over those big time steps give you strongly connected graph.",
            "I guess in plain English that basically says that over B time steps there are there's a sequence of arcs that could have been used during these steps that would let Agent I influence Agent J Overby time steps.",
            "There is a path of indirect influences that everybody can influence everybody else.",
            "Now these influences do not need to happen at the same time.",
            "So it's sometimes these are comes in, so this one can influence that one next time another arc comes in and this guy can influence that guy and so on.",
            "OK, so under this assumption, the algorithm, the consensus algorithm still converges and we get consensus.",
            "In the limit.",
            "The news in general tend to be bad.",
            "31 can make an example where the convergence time of this is going to be exponential even if we have a symmetric graph at each time.",
            "Remember in the case of without time variations, I said before that when you have bidirectional or symmetric graphs, the result by Lando Delisco tells us that.",
            "Order of N Cube is the worst case convergence time, but if you allow the time variations then things become much worse and can take exponential time to converge."
        ],
        [
            "On the other hand, the good news is that if you restrict to the case of averaging so the a matrix is a stochastic matrix at."
        ],
        [
            "Each point in time, then magically the convergence rate becomes the same one as the estimate that we had for the time invariant case.",
            "So even though we allow time variations for doubly stochastic matrices, convergence times do not get worse.",
            "It's again one order N squared over Alpha and Alpha.",
            "Again, remember is that number is the minimal weight that you give to anybody that you do take into account.",
            "As I said before, Alpha might have to be 1 / N. In case you have neighbors.",
            "So if you want to improve this estimate and get rid of that Alpha, what would you do?",
            "Kind of artificially forced the degree of your graph to be small by talking only to two neighbors at the time, and there is a trick of how to do this locally and this gives us a convergence time of order of North Square."
        ],
        [
            "And Yep.",
            "OB, of course, comes in yes.",
            "And it comes in linearly, so it's B N ^2.",
            "So amazingly, the case of time variations and arbitrary time variations is not much is no worse than what we can achieve on."
        ],
        [
            "Fixed graphs.",
            "Now, once you have this result, you can just take it and capitalize it in various forms.",
            "What I'm refering to here is that Jillian edits and as well as the glare had done some work showing the convergence of the subgradient algorithm.",
            "Distributed version of it using all estimates for convergence times.",
            "And they gave convergence time that was exponentially North as soon as we got that result about the speed of convergence algorithm, then you just take the result in their paper.",
            "And basically scale down the constants, Yep.",
            "Sure, that doesn't.",
            "Again stick when you're constrained by this small.",
            "OK, so theoretically.",
            "OK, are you refering to how do I make sure that it is double stochastic in general or in the trick?",
            "The side that I kind of skipped?",
            "So to make it doubly stochastic you can you have that property whenever you have pairwise exchanges that is somehow two nodes.",
            "Decide and agree.",
            "We're going to exchange values and we look.",
            "You have eight.",
            "I have 6 where 2 apart and now the two of us moved to 7 seven.",
            "So the little trick that comes in here is basically a small protocol for four nodes to choose pairs of interactions and you have to do that in a local way."
        ],
        [
            "OK, so the.",
            "After doing all this work and playing with all those convergence times and so on, the I think the intellectual question that shows up and perhaps practical as well, is whether this order of N squared that keeps showing up all the time is something that we can beat.",
            "Can we get convergence or consensus algorithms to be faster?",
            "OK and 1st let's try to understand that question for the case of static graphs, can we get the convergence time for consensus?",
            "That's faster?",
            "Of course yes.",
            "If we have special static graphs.",
            "If you have a geometric random graph or if you have a small world graph, consensus times are smaller.",
            "But here opposing the question in the in the worst case overall graphs.",
            "Well if you try to run nonlinear updates, may perhaps linearity was what was slowing down the algorithm.",
            "Senior updates do not help if you look at update rules of this kind.",
            "As long as F is smooth, non linearity does not help becausw locali near the point of convergence.",
            "Whatever F you use will look as approximately linear.",
            "Think of the random.",
            "Let's take a random walk on the line which takes N squared to converge, but start playing with the probabilities that you use in that random walk and make them a little different.",
            "Cannot help.",
            "It turns out that this cannot help.",
            "So on the line your any kind of random walk will have an square and you will get stuck."
        ],
        [
            "Of course we can beat N squared if we do the trivial solution.",
            "Set up a spanning tree, add the values, and you're done.",
            "That's takes time order of the day of the diameter of the network, so if we can beat it.",
            "So in this simple way who I care about, everything else well, to get a meaningful discussion going, we need to put down a model of computation that does not allow spanning trees.",
            "What would be this case?",
            "This case would be a case of unstructured."
        ],
        [
            "Problems.",
            "We are unstructured.",
            "Unstructured networks where do you do not?"
        ],
        [
            "Have a clear way of setting up a leader and so on.",
            "So think of sensor networks or sensor network with anonymous nodes for example, so we have come up with a model that we believe is reasonable and basically rules out spanning tree solutions and the model is the following.",
            "First, we don't want to have IDs at the nodes because then you can elect a leader and get the spanning tree to avoid having ideas, we basically need to have nodes be anonymous, everybody doing the same thing.",
            "And we prohibit randomization because if you use randomization you can generate ID's.",
            "And within that model, the model is quite restrictive in what it can do."
        ],
        [
            "But we have managed to show after quite a bit of struggle that we can solve some types of consensus problems in order of North Squared time.",
            "So the model is restrictive but not too restrictive.",
            "And skipping details, but."
        ],
        [
            "In the end, the sort of conclusion concluding point is that is N ^2, a fundamental lower bound, and I may be hard, but perhaps there is a hope of showing such a lower bound under this particular model that we have here, which would be kind of bad news.",
            "This is for bidirectional graphs or symmetric graphs.",
            "Then there's questions for the directed case, and then what exactly happens when the time varying case under such restrictive models of computation?",
            "Is not so clear.",
            "So basically the point I want to make here is that they eventually were interested in finding what are the fundamental limitations of such consensus algorithms and but in order to address questions of this time one needs to be clear about what kind of model computation one is using.",
            "And here one starts interacting with what happens in the distributed algorithms area in theoretical computer science sort of divisions, and one needs to adopt a little bit of that way of thinking.",
            "OK, so this is."
        ],
        [
            "Conclude, thank you very much.",
            "OK, so now is the coffee break, but if there's maybe a couple of questions for you that so you have a pretty convincing story about what happens with edge deletion.",
            "But if you run kind of a big enough complication on enough machines for enough time, some of those machines are going to die.",
            "If you say anything about robustness to actually agents dropping out of the computation.",
            "OK, so if you think of the case of F eyes that are the block of data, so I guess I dies and the date of I dive together right?",
            "So this is the OK.",
            "So this is more of a statistical issue I guess, so you're optimal.",
            "Your optimal estimator based on fewer data.",
            "How does it perform compared to the optimal based on all data?",
            "I think it's interesting practical questions, probably tangential to what we've talked about.",
            "You totally out of the storage complexity, so it seems like you're still having to store some of that statement for the excited just died on other machines.",
            "This is, I get very large problems, my problems bigger because it's poorly machine model.",
            "OK, so the XI might not be so hard to store, so the data are massive.",
            "That means that my functions FI might be hard to compute, but the excise are sort of my parameter estimates that I'm trying to learn and so this might be much more manageable.",
            "As you pointed out, for even these algorithms that run sort of interleaved consensus plus optimization, there's this disappointing aspect that the convergence rate is pretty much the the product of the two which the algorithm already gives.",
            "You have an intuition about whether that's a fundamental restriction, or that's just a limitation of the analysis.",
            "Have a sense that it's you cannot improve it, but I think this is a really good question to actually resolve.",
            "If one could somehow could prove a negative result of this type, it would be interesting.",
            "But to prove negative results, the trouble is that you need to become very specific about your models of computations and classes of algorithms that are allowed.",
            "You must not distribute it.",
            "Distributed way.",
            "Yes.",
            "What's the progress for them?",
            "What's the progress?",
            "Well, to the extent that it overlaps with what I mentioned here.",
            "Basically, distributed reinforcement learning is at least some of the algorithms have the flavor of distributed gradient like algorithms.",
            "An so if you have a distributor reinforcement learning algorithm that would fall in this type of setting, then you could kind of transfer some of the results.",
            "On the other hand.",
            "So that having followed very much the latest what's happening in that field.",
            "My sense is that there are people really want to get things to work, and so there may be some ad hoc features in and out that are useful, but are less easy to analyze theoretically.",
            "Close.",
            "I think we'll take the coffee break now, so if you have more questions I'm sure.",
            "Let's thank John."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, good morning.",
                    "label": 0
                },
                {
                    "sent": "I would like to thank the organizers for inviting me.",
                    "label": 0
                },
                {
                    "sent": "It's great to be, it's to be here.",
                    "label": 0
                },
                {
                    "sent": "It's been a long time since I last came to NIPS and of course the location is wonderful.",
                    "label": 0
                },
                {
                    "sent": "I would like to add to thank you, specially John Duchi for making all sorts of arrangements and making sure I'm having a great time here.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to talk about the subjects that hopefully is at least tangentially related to the subject of this workshop.",
                    "label": 0
                },
                {
                    "sent": "And it's a topic on which I accidentally run into about 30 years ago.",
                    "label": 0
                },
                {
                    "sent": "Then the topic kind of went out of fashion and then has reappeared these days.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And lots of people being interested in it and doing work on it.",
                    "label": 0
                },
                {
                    "sent": "So what I'm going to be talking about is.",
                    "label": 0
                },
                {
                    "sent": "Algorithms that have to do with optimization, distributed optimization and at the same time be behind the algorithm.",
                    "label": 0
                },
                {
                    "sent": "There's also sort of averaging algorithm running simultaneously that tries to reconcile the results of different processors, so I'm going to start quickly with some motivation and applications going to discuss how averaging and consensus algorithms show up specifically within the context of distributed optimization.",
                    "label": 1
                },
                {
                    "sent": "And then taking that as further motivation will focus just on the subject of consensus and averaging algorithms and try to say as much as we can about the time they take to converge.",
                    "label": 0
                },
                {
                    "sent": "Talk about a few different variations and come up and eventually conclude with a couple of open problems in this area.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what's this setting?",
                    "label": 0
                },
                {
                    "sent": "It's a trivial problem embarrassing to talk about.",
                    "label": 0
                },
                {
                    "sent": "It's basically elementary school math.",
                    "label": 0
                },
                {
                    "sent": "You have a bunch of agents or processors, or where you want to call them.",
                    "label": 0
                },
                {
                    "sent": "Each one starts with a certain initial value and they need want to exchange some messages and come up with consensus or agree on the final value that falls somewhere in the range of the different values.",
                    "label": 0
                },
                {
                    "sent": "So think of XR as being just a weighted average of the initial values that everyone is having.",
                    "label": 0
                },
                {
                    "sent": "A special case of this is if you're interested not just in agreement, but you also want this agreement to happen on the average of the initial values of each agent and the further special case of this is if you want to do voting so everybody starts with a value that's either plus plus or minus one.",
                    "label": 0
                },
                {
                    "sent": "So think of these voice votes in favor or against the something, and you want to see what fraction of the all of them is in favor or against.",
                    "label": 0
                },
                {
                    "sent": "So the problem is pretty trivial.",
                    "label": 0
                },
                {
                    "sent": "But what?",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We're interested in is in doing it in a truly distributed way without necessarily synchronizing the agents or the processors, and without doing the sort of trivial solution which is to set up a spanning tree, communicate messages along the spine, it 3 add up the axis and divide by N, so there's clearly trivial solutions to this problem, but in some contexts these are considered to be undesirable, so this takes us.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To try to solve the problem by doing simple updates of the following type, I'm sitting in network I'm node I. I talked to a neighbor whose Ji tell him I tell her my values.",
                    "label": 0
                },
                {
                    "sent": "It tells me her value and each one of us resets their own value to the average of the two.",
                    "label": 0
                },
                {
                    "sent": "Now everybody keeps doing this simultaneously.",
                    "label": 0
                },
                {
                    "sent": "You hope that in the end basically differences between different processors will start shrinking.",
                    "label": 0
                },
                {
                    "sent": "And eventually you will get convergence performance value.",
                    "label": 0
                },
                {
                    "sent": "So this is the type of methods we were interested in.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Pretty trivial yet so many people seem to be interested in it.",
                    "label": 1
                },
                {
                    "sent": "This type of models have started showing up for lots in the social Sciences and sort in all sorts of areas you could imagine.",
                    "label": 0
                },
                {
                    "sent": "People sometimes think that perhaps when experts sit in a room and they try to come up with some estimate of something and they keep discussing perhaps the evolution of their discussion is described by a simple mechanism like the one I suggested at the end of the previous slide.",
                    "label": 1
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And basically, social scientists sometimes say that humans are not necessarily as rational as most economists pretend them to be, so they actually behave by certain simple rules of thumb, and maybe a very simple mechanism like the one that I described could be a description of what?",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Happening so social scientists can get excited with this.",
                    "label": 0
                },
                {
                    "sent": "Basically they write down models of this kind and then try to analyze them.",
                    "label": 0
                },
                {
                    "sent": "Come up with descriptive theories and of course add narratives to it.",
                    "label": 0
                },
                {
                    "sent": "That is, you make a mathematical model.",
                    "label": 0
                },
                {
                    "sent": "You saw that the model that something, and then you start making stories about what might be happening in the real world.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Closer to our interests is the engineering context and the simple, trivial method that I described two slides ago that basically check with your neighbor and take the common average have shown up in the last few years all over the place in lots of different applications from distributed computation, networking, an people in control theory have also caught up.",
                    "label": 0
                },
                {
                    "sent": "So for example, in Clock synchronization every processor.",
                    "label": 0
                },
                {
                    "sent": "Has its own Clock you would like blocks of different processors to agree what you do.",
                    "label": 0
                },
                {
                    "sent": "I check my Clock, check the Clock of my neighbor if there's a discrepancy.",
                    "label": 0
                },
                {
                    "sent": "We try to set our clocks A little closer to each other, so this is an instance of a consensus type of problem where we basically want our clocks to agree, not necessarily on the correct value, but at least to agree.",
                    "label": 0
                },
                {
                    "sent": "Different setting might be load balancing where we start with unequal loads and we want to loads to be balanced so that every processor ends up having.",
                    "label": 0
                },
                {
                    "sent": "The average of the initial loads of all processors.",
                    "label": 0
                },
                {
                    "sent": "So easy way to do this is you check with your neighbor if your neighbor has less load than you do, then you kind of split the difference and the relative loads become closer to each other.",
                    "label": 0
                },
                {
                    "sent": "If everybody is doing this simultaneously, you hope that in the end loads will end up being balanced.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the let me add.",
                    "label": 0
                },
                {
                    "sent": "Take the simple method.",
                    "label": 0
                },
                {
                    "sent": "They described a little while ago.",
                    "label": 0
                },
                {
                    "sent": "Love you.",
                    "label": 0
                },
                {
                    "sent": "Check with your neighbors and everybody.",
                    "label": 0
                },
                {
                    "sent": "Move the two of them.",
                    "label": 0
                },
                {
                    "sent": "You and your neighbor moved to the average of your value so you get closer.",
                    "label": 0
                },
                {
                    "sent": "Let's generalize this a little bit, and this apparently first showed up in the literature in 1974 when the group suggested a model of how people might reconcile opinions.",
                    "label": 0
                },
                {
                    "sent": "And here's the model that the group proposed.",
                    "label": 0
                },
                {
                    "sent": "Every person person I has certain value.",
                    "label": 0
                },
                {
                    "sent": "XI of tea and each time everybody think of these as opinions about something, everybody updates their own opinion by by looking at the opinions of the others and forming a convex combination or a weighted average of the opinions of the others.",
                    "label": 0
                },
                {
                    "sent": "These AI Jays are the weights that you give to your neighbors.",
                    "label": 0
                },
                {
                    "sent": "AJ is the weight you give to neighbor J, but you can think also that the agents are interacting through a certain communication graph.",
                    "label": 0
                },
                {
                    "sent": "Who are not all pairs are present?",
                    "label": 0
                },
                {
                    "sent": "In that case, AIJ is going to be 0 if an edge is absent from the network.",
                    "label": 0
                },
                {
                    "sent": "AIJ can be non zero only if there is an edge.",
                    "label": 0
                },
                {
                    "sent": "So the idea is that J sends a message to Y through an edge of the network and then Agent I updates its own opinion by taking a convex combination of the opinions of all other agents.",
                    "label": 0
                },
                {
                    "sent": "So this is a convex combination or weighted average.",
                    "label": 0
                },
                {
                    "sent": "So the sum of the AI JS has to be equal to 1.",
                    "label": 0
                },
                {
                    "sent": "If you write this iteration in matrix form, it's it's just this and the a matrix has a lot of special structure.",
                    "label": 0
                },
                {
                    "sent": "It's what we call a stochastic matrix, and you can think of this a matrix.",
                    "label": 0
                },
                {
                    "sent": "Well, it's the metrics that you would get if you were describing a Markov chain, and in particular a is the metrics.",
                    "label": 0
                },
                {
                    "sent": "Think of it as the metrics of transition probabilities for Markov chain on the different nodes of the graph.",
                    "label": 0
                },
                {
                    "sent": "So think of AIJ as a probability of jumping from I to J.",
                    "label": 0
                },
                {
                    "sent": "Now, there's no randomness, there's nothing Markoff.",
                    "label": 0
                },
                {
                    "sent": "About the consensus process that's happening up here, but mathematically the model is isomorphic to one involving Markov chains, and this means that you can bring to bear all the tools from Markov chains to this setting and the particular Markov chain theory tells you that as long as this graph is reasonably connected, the products of a two of the a matrix with the powers of that matrix converge to a matrix that has equal rows and the elements.",
                    "label": 1
                },
                {
                    "sent": "On those rows are the steady state probabilities of the Markov chain, and when you translate that statement to this problem, it basically tells you that all the excise the opinions held by the different agents, they all converge to a common value and that common value is a weighted average of the initial values that the agents had when the process started, and those by Jays the weight that is given to each one of the initial values that can be interpreted or.",
                    "label": 0
                },
                {
                    "sent": "It is essentially the steady state probability of state J in the Markov chain view of this process.",
                    "label": 0
                },
                {
                    "sent": "You can also leverage on Markov chain theory to get estimates about the.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Virgins rate or time until this method converges to near consensus.",
                    "label": 0
                },
                {
                    "sent": "OK, special case of this is the case of averaging.",
                    "label": 0
                },
                {
                    "sent": "So if we actually want to compute the averages instead of just obtaining consensus, then you have to put some restrictions in the types of weights that are being given here that are used here.",
                    "label": 0
                },
                {
                    "sent": "So what one does to get an averaging algorithm is to use a metrics A, which is doubly stochastic.",
                    "label": 0
                },
                {
                    "sent": "What that means is that so in a in a transition probability matrix there's some of the entries are longer, roll have to be equal to 1 because their probabilities.",
                    "label": 0
                },
                {
                    "sent": "We say that the metrics is doubly stochastic if at the same time the some of the entries in each column is equal to 1.",
                    "label": 0
                },
                {
                    "sent": "So from the left multiply with the old one vector times the metrics a must give you again the vector of all ones.",
                    "label": 0
                },
                {
                    "sent": "So one's times a column must give you one.",
                    "label": 0
                },
                {
                    "sent": "What happens in this case is that no matter what X you have the some of the entries of the X vector.",
                    "label": 0
                },
                {
                    "sent": "After you do an update, the sum is preserved.",
                    "label": 0
                },
                {
                    "sent": "So by taking A to be doubly stochastic matrix, this iteration conserves the sum of the values of the axis, and so if you have convergence and the sum is preserved, the only thing that you could converge to is the average.",
                    "label": 0
                },
                {
                    "sent": "So we have stochastic matrices for the case of when we want to get consensus, we have double stochastic matrices.",
                    "label": 0
                },
                {
                    "sent": "If we want to get averaging.",
                    "label": 0
                },
                {
                    "sent": "Alright, so this is the basic structure of the.",
                    "label": 0
                },
                {
                    "sent": "Averaging or consensus.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Algorithms I'm going to be looking at, so now let's with this as background.",
                    "label": 0
                },
                {
                    "sent": "Let's start talking about distributed optimization algorithms, and I'm going to start from the pretty trivial and basic and add.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A little bit of bells and whistles as you as we go on, so we're going to talk about gradient like methods people in nonlinear optimization felt kind of snob gradient type methods for a long, long time because there are just two simple and we're probably favor more complex methods like Newton method and so on.",
                    "label": 0
                },
                {
                    "sent": "But when you're dealing with huge problems and lots of variables and lots of data, one really wants to use simple methods, so gradient type methods have had a little bit of a resurgence lately.",
                    "label": 0
                },
                {
                    "sent": "So going to look at the simple problem minimum, you want to minimize cost function, which is we assume throughout it's a convex function to keep discussion simple and the special case of particular interest is when this cost function is actually a sum of many individual cost functions.",
                    "label": 0
                },
                {
                    "sent": "In the context of this session, you could think of the eyes as being loss functions associated with blocks of data.",
                    "label": 0
                },
                {
                    "sent": "SO1 processor might have a big block of data.",
                    "label": 0
                },
                {
                    "sent": "Write down the associated loss function.",
                    "label": 0
                },
                {
                    "sent": "That's the FI you want to minimize the total loss.",
                    "label": 0
                },
                {
                    "sent": "That would be the sum of the FIS the way gradient like method tries to optimize this function is to use the gradient of the function and do an update of the form.",
                    "label": 0
                },
                {
                    "sent": "You are at a certain place and make an update by moving in the direction of the negative gradient.",
                    "label": 0
                },
                {
                    "sent": "So this is a direction of dissent.",
                    "label": 0
                },
                {
                    "sent": "It's a direction along which the cost function decreases and you make a step in that in that direction.",
                    "label": 0
                },
                {
                    "sent": "Of interest also, our methods were one measures the gradients, not exactly, but who?",
                    "label": 0
                },
                {
                    "sent": "In the presence of some noise.",
                    "label": 0
                },
                {
                    "sent": "For example, if you're getting noisy data about a certain situation and you're trying to estimate some parameters, you might think you might get situations of this kind.",
                    "label": 0
                },
                {
                    "sent": "So the data that I'm using at a certain point is the gradient of my cost function plus some noise, and they make step again in the direction of the measurement that I got.",
                    "label": 0
                },
                {
                    "sent": "When I say noise, I always think of something that's zero mean plus a few extra technical assumptions that I will not get into.",
                    "label": 0
                },
                {
                    "sent": "But so in the sense of expected values, you are still moving in a direction that decreases your cost function.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, you cannot really absolutely sure if you are moving in that direction because there is noise, but in expectation you're doing the right thing in order to kill the effects of the noise.",
                    "label": 0
                },
                {
                    "sent": "At least in theory, what one has to do in this context is to let the step size change with time and use a smaller and smaller step size as you go.",
                    "label": 0
                },
                {
                    "sent": "So when the.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Community, I guess you would say that the learning rate has to decrease as you go as time goes in order to get 0 error in the limit.",
                    "label": 0
                },
                {
                    "sent": "Elf interest is also the case when the function F is not smooth, in which case you'd cannot form the gradient.",
                    "label": 0
                },
                {
                    "sent": "Then you work with subgradients of the costs of the cost function.",
                    "label": 0
                },
                {
                    "sent": "Well, what's the subgradient?",
                    "label": 0
                },
                {
                    "sent": "Well, if you have a convex function, the gradient is basically the slope of the convex function at a point.",
                    "label": 0
                },
                {
                    "sent": "If you have a non smooth function, so let's say it has a corner at some place, the subgradient would be any slope that's kind of compatible with that corner in the sense that it sits below.",
                    "label": 0
                },
                {
                    "sent": "So it's just the natural generalization of the notion of a gradient for the smooth, nonsmooth case.",
                    "label": 0
                },
                {
                    "sent": "So in this case, you want does again the same you update by moving in the negative direction of the of subgradient, and if there's noise, you can still run a method of this kind.",
                    "label": 0
                },
                {
                    "sent": "Are the simplest, simplest versions.",
                    "label": 0
                },
                {
                    "sent": "There's more a lot and more sophisticated stuff out there in the optimization literature that I will not.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We get to let's we can start thinking just about in terms of these very simple models.",
                    "label": 0
                },
                {
                    "sent": "So how can one start parallelizing or distributing a computation such as the one with the gradient methods?",
                    "label": 0
                },
                {
                    "sent": "Very simple way of doing things is to if the vector X is kind of high dimensional and you assign a different components of the X vector to different processors or agents.",
                    "label": 0
                },
                {
                    "sent": "As I have been calling them now in order to do the optimization when I'm process or I and I'm going to be updating the ice component.",
                    "label": 0
                },
                {
                    "sent": "But I also need to take into account where everybody else is so I need to keep track of the components that have been calculated by others.",
                    "label": 0
                },
                {
                    "sent": "So let's think about the following situation.",
                    "label": 0
                },
                {
                    "sent": "Every agent keeps an entire vector.",
                    "label": 0
                },
                {
                    "sent": "Call it X superscript I.",
                    "label": 0
                },
                {
                    "sent": "And keeps track of the components of all agents.",
                    "label": 0
                },
                {
                    "sent": "So these components are indexed by J.",
                    "label": 0
                },
                {
                    "sent": "Now XI agent I is the master for the ice components.",
                    "label": 0
                },
                {
                    "sent": "So Agent I goes ahead and updates that I've component in the direction of the gradient where the gradient is evaluated on the vector.",
                    "label": 0
                },
                {
                    "sent": "That agent I currently has now that vector of Agent I have the correct value for the ice component and has what for the other components for the JSF components he has whatever he last heard.",
                    "label": 0
                },
                {
                    "sent": "From the other agent J.",
                    "label": 0
                },
                {
                    "sent": "So we do not assume that the agents communicate and think change results each time, but just once in awhile.",
                    "label": 0
                },
                {
                    "sent": "So once in awhile Agent J sends a message to Agent I with the value that J has for the J component.",
                    "label": 0
                },
                {
                    "sent": "An agent I takes that value and will use it in subsequent computations.",
                    "label": 0
                },
                {
                    "sent": "And let's assume that this happens not every time, but occasionally, let's assume that it happens once every capital B time units were B is.",
                    "label": 0
                },
                {
                    "sent": "Upper bound it has to do with our communication network architecture and.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So one, so how will this method behave?",
                    "label": 0
                },
                {
                    "sent": "This is very much like the textbook gradient methods, except that the gradients that an agent is using in order to have an iteration is evaluated at, sorted at the wrong place at an inconsistent vector.",
                    "label": 0
                },
                {
                    "sent": "So everybody has a different vector X superscript I becauses I just heard from everyone.",
                    "label": 0
                },
                {
                    "sent": "But maybe somebody else has not yet heard from everyone.",
                    "label": 0
                },
                {
                    "sent": "So we may be updating with outdated Val.",
                    "label": 0
                },
                {
                    "sent": "Use so in general the JS components possessed by Agent I could be up to be time steps out of date.",
                    "label": 0
                },
                {
                    "sent": "So how do we analyze this?",
                    "label": 0
                },
                {
                    "sent": "Well, let's keep track of a vector that has sort of the official values, not the outdated values component one as possessed by Agent, One who is in charge component an as possessed by agent, and who is in charge, and so on.",
                    "label": 0
                },
                {
                    "sent": "So this is sort of the the official.",
                    "label": 0
                },
                {
                    "sent": "Current result from the method.",
                    "label": 0
                },
                {
                    "sent": "Now be cause an agent.",
                    "label": 0
                },
                {
                    "sent": "Maybe it may have been some time before I heard from everyone else.",
                    "label": 0
                },
                {
                    "sent": "My vector that I have might be a bit out of date compared to this Y vector.",
                    "label": 0
                },
                {
                    "sent": "How far out of date could it be?",
                    "label": 0
                },
                {
                    "sent": "Let's assume that the gradients are bounded by some constant.",
                    "label": 0
                },
                {
                    "sent": "Then how far out of date can agree it's being bit time steps since I last heard from another agent during those big time steps, that agent may have done.",
                    "label": 0
                },
                {
                    "sent": "Be updates and during each update that other agents moved at.",
                    "label": 0
                },
                {
                    "sent": "By by order of Gamma, which is the step size.",
                    "label": 0
                },
                {
                    "sent": "So this is how much another agent may have moved its own value since I last heard from them.",
                    "label": 0
                },
                {
                    "sent": "So I'm out of date by this amount.",
                    "label": 0
                },
                {
                    "sent": "So this means that everyone is computing using an incorrect gradient because it's a valuated at the wrong place, but it's the same as if it was evaluated in the right place except for some error term.",
                    "label": 0
                },
                {
                    "sent": "How big is the error term?",
                    "label": 0
                },
                {
                    "sent": "Well, the difference is due to the fact that XI is different than Y.",
                    "label": 0
                },
                {
                    "sent": "This difference is order of big gamma and because the steps are order of gamma, the difference, the resulting difference in the update is order of.",
                    "label": 0
                },
                {
                    "sent": "Be gamma squared.",
                    "label": 0
                },
                {
                    "sent": "So what's important here?",
                    "label": 0
                },
                {
                    "sent": "What's important is that the effects of this kind of a synchronism that we have our of 2nd order in gamma.",
                    "label": 0
                },
                {
                    "sent": "So when gamma is reasonably small, the 2nd order term will be will be less than the 1st order term.",
                    "label": 0
                },
                {
                    "sent": "So up to 1st order the method still behaves as a correct gradient method and that basically shows that such a gradient type method, but where you have outdated and delayed information about what the other processors have done.",
                    "label": 0
                },
                {
                    "sent": "Such a method will still behave properly, so.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Whatever theorem you can prove under your favorite assumptions for gradient methods in the standard nonlinear programming textbook setting, these results will also go through in this case and you get convergence to convergence to a point where the gradient is equal to 0.",
                    "label": 0
                },
                {
                    "sent": "So for convex functions, that would be an optimum point.",
                    "label": 0
                },
                {
                    "sent": "Something to notice is that in order to get the let the argument go through, what we need is this term to be.",
                    "label": 0
                },
                {
                    "sent": "No bigger than the dominant term that is the gradient.",
                    "label": 0
                },
                {
                    "sent": "So for this to happen, we basically need B times gamma to be less less than a constant.",
                    "label": 0
                },
                {
                    "sent": "So the so in particular the step size has to become smaller and smaller.",
                    "label": 0
                },
                {
                    "sent": "If the communication delays are larger and larger, Yep.",
                    "label": 0
                },
                {
                    "sent": "I'm not showing that dependence, but of course there would be.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So whatever theorem there is for centralized gradient methods in nonlinear programming texts and whatever theorems there are also for the stochastic case, these are so called stochastic approximation algorithms.",
                    "label": 0
                },
                {
                    "sent": "These will also do go through and such a method convergence even with this bit of chaos in the way processors coordinate.",
                    "label": 0
                },
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "What is it considered I mentioned?",
                    "label": 0
                },
                {
                    "sent": "Because if if the darkness is for example linear, then you have to decrease, to solar rate record or probably don't get compilers.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Yeah, there will be independent dimension, but then one has to start.",
                    "label": 0
                },
                {
                    "sent": "You have Sir becoming a lot more specific about assumptions about the structure of your function F and so on, and this would take me somewhere different tangent from what I'm looking at here.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So let's just keep that in mind that there is dependence of the dimension, but I want to concentrate more on the effects of the communications on this.",
                    "label": 0
                },
                {
                    "sent": "OK, so now instead of having every agent being in control of a single component, you could think of an alternative setting where everybody is interested in the same vector.",
                    "label": 0
                },
                {
                    "sent": "Everybody is going to update the entire vector, but for some reason we my, our computations might turn out to be a little different and then we want to reconcile them.",
                    "label": 0
                },
                {
                    "sent": "Together so suppose that every agent now I will indicate agent, not component.",
                    "label": 0
                },
                {
                    "sent": "Suppose that everyone does upstairs and nabla, and there's a gradient at Del missing from there.",
                    "label": 0
                },
                {
                    "sent": "So everybody doesn't update if everything is deterministic, everybody is using the same cost function.",
                    "label": 0
                },
                {
                    "sent": "Everybody does the same update, so there's nothing to be reconciled here.",
                    "label": 0
                },
                {
                    "sent": "So that would be an uninteresting situation.",
                    "label": 0
                },
                {
                    "sent": "But if you have updates that involve noise.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is then it does make sense to proceed, this follows.",
                    "label": 0
                },
                {
                    "sent": "Everybody is interested in that vector in that vector processor.",
                    "label": 0
                },
                {
                    "sent": "I has a vector XI, gets a measurement and carries out an update, and then you reconcile the updates of everyone by taking the average.",
                    "label": 0
                },
                {
                    "sent": "What the such an average does is?",
                    "label": 0
                },
                {
                    "sent": "It smooths out the effects of the noise is it reduces the noise variance.",
                    "label": 0
                },
                {
                    "sent": "So this could actually be useful and.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The the that's my favorite picture from my PhD thesis from last century, where the idea was that you have some process here that generates noisy data and you're trying to identify the parameters of the process and you have two processors and these processors they do updates of the usual type that you have in system identification, so one, but they exchange their estimates and they keep reconciling them.",
                    "label": 0
                },
                {
                    "sent": "So there's a legitimate story that comes for this case.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how would the analysis of such a method goal?",
                    "label": 0
                },
                {
                    "sent": "Well, let's think of running this method in a two phase version.",
                    "label": 0
                },
                {
                    "sent": "Everybody doesn't update of the ice component using gradient like step, plus some noise, and then everybody pauses and they run a consensus algorithm.",
                    "label": 0
                },
                {
                    "sent": "A consensus algorithm involves the iteration that I introduced some time before.",
                    "label": 0
                },
                {
                    "sent": "A is a stochastic matrix.",
                    "label": 0
                },
                {
                    "sent": "You keep forming convex combinations of everybody else.",
                    "label": 0
                },
                {
                    "sent": "What's going to happen in the limit we all converge to a common value.",
                    "label": 0
                },
                {
                    "sent": "And that common value is going to be a weighted combination of the values of the different processors.",
                    "label": 0
                },
                {
                    "sent": "OK, and so that's 11.",
                    "label": 0
                },
                {
                    "sent": "Basically round of the two phase method.",
                    "label": 0
                },
                {
                    "sent": "What happened at the end 12th?",
                    "label": 0
                },
                {
                    "sent": "We end up with the common value if we started with a common vector, we're going to end up with the.",
                    "label": 0
                },
                {
                    "sent": "OK, now if we start with different vectors X is we have the updates that everyone is doing.",
                    "label": 0
                },
                {
                    "sent": "But then because we reconcile the results and we form equated average, we end up with essentially having carried out an update which is a weighted average of the updates of the different processors.",
                    "label": 0
                },
                {
                    "sent": "I think there is something slightly wrong with the way I'm using exercise there.",
                    "label": 0
                },
                {
                    "sent": "Well, I think you get the idea.",
                    "label": 0
                },
                {
                    "sent": "We start with a common vector.",
                    "label": 0
                },
                {
                    "sent": "We do our respective updates that take us to slightly different places and then we run the consensus algorithm so we end up again with the common vector.",
                    "label": 0
                },
                {
                    "sent": "Net result is that we did an update that was that weighted average of the individual updates that each agent had done.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So is this algorithm sort of doing the right thing?",
                    "label": 0
                },
                {
                    "sent": "Yes, it is.",
                    "label": 0
                },
                {
                    "sent": "Why the important thing for convergence of gradient methods is that the update that we do is in a direction of dissent with respect to our cost function.",
                    "label": 0
                },
                {
                    "sent": "By adding lots of terms, each one of which is in a direction along which the cost function is going down, we still have a method with that property.",
                    "label": 0
                },
                {
                    "sent": "So in listing the expected sense, we're making updates that are in a decent direction, and so this thing will still will still converge.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But now let's look at an interesting version of this.",
                    "label": 0
                },
                {
                    "sent": "Instead of having two phases where we update, then run consensus, then update, then run consensus, let's do the two simultaneously.",
                    "label": 0
                },
                {
                    "sent": "So processor I has a component has a vector XI.",
                    "label": 0
                },
                {
                    "sent": "Actually, to make things easier to visualize and parse the slides, let's just think of X as being a scalar.",
                    "label": 0
                },
                {
                    "sent": "So we're optimizing a function F of a single variable.",
                    "label": 0
                },
                {
                    "sent": "Agents I has his own estimate of what that single variable should be gets messages from the other agents and forms a convex combination.",
                    "label": 0
                },
                {
                    "sent": "This is towards the purpose of eventually agreeing on a common value, but also gets his own measurement and makes an update in.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The direction of improvement.",
                    "label": 0
                },
                {
                    "sent": "So the two things are now interleaved.",
                    "label": 0
                },
                {
                    "sent": "How do we analyze this?",
                    "label": 0
                },
                {
                    "sent": "We can analyze this by keeping track of a summary of the values of the different agents, and as a summary I'm going to take the convex combination of the values of the different agents, where the way it's Pi.",
                    "label": 0
                },
                {
                    "sent": "I are going to be those pie eyes that show up in the consensus algorithm, so the consensus algorithm associated with the AI JS.",
                    "label": 0
                },
                {
                    "sent": "Ends up producing a weighted combination of the XYZ and those weights are the pie eyes.",
                    "label": 0
                },
                {
                    "sent": "So why is the vector on which the agents would agree if they stopped updating and just run the consensus algorithm for computing the gradient at a different point?",
                    "label": 0
                },
                {
                    "sent": "That point we're updating from?",
                    "label": 0
                },
                {
                    "sent": "That's the work.",
                    "label": 0
                },
                {
                    "sent": "Computing well agent.",
                    "label": 0
                },
                {
                    "sent": "I has a value XI so he can compute the gradient at the point that he knows.",
                    "label": 0
                },
                {
                    "sent": "And it makes an update.",
                    "label": 0
                },
                {
                    "sent": "The intricacy is that different agents have different XYZ, so they're computing gradients at different places.",
                    "label": 0
                },
                {
                    "sent": "Which is sort of incorrect.",
                    "label": 0
                },
                {
                    "sent": "And then we want to argue that although it's incorrect, the incorrectness is kind of small and doesn't matter.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "No, no one has access to PII, but defining now this quantities and mathematical tool for the purpose of analyzing it, so to keep track of what's happening in this algorithm, it's convenient to look at this quantity Y, which is sort of a summary of what everybody is doing and work with this.",
                    "label": 0
                },
                {
                    "sent": "Now the.",
                    "label": 0
                },
                {
                    "sent": "Because the Pi eyes are steady state probabilities for the Markov chain associated with the iij's simple algebra tells you that weighted average of this of these terms is the weighted average of the initial values, so.",
                    "label": 0
                },
                {
                    "sent": "So do you.",
                    "label": 0
                },
                {
                    "sent": "So becausw of when you carry out just the consensus iteration, WHI is not going to change?",
                    "label": 0
                },
                {
                    "sent": "And why is only going to change because of that + up?",
                    "label": 0
                },
                {
                    "sent": "There should be a minus so.",
                    "label": 0
                },
                {
                    "sent": "Huawei does change only because of the updates of the gradient type terms introduced by the different agents, so this is what we would agree on.",
                    "label": 0
                },
                {
                    "sent": "If the consensus algorithm was running infinitely fast.",
                    "label": 0
                },
                {
                    "sent": "If we don't do any updates, then what we will agree on doesn't change, but if we do updates, then what we will end up agreeing on will be something a little different.",
                    "label": 0
                },
                {
                    "sent": "So what happens?",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How do we analyze this?",
                    "label": 0
                },
                {
                    "sent": "Well again, let's keep track of how far is the value of a typical agent from the summary value.",
                    "label": 0
                },
                {
                    "sent": "OK, well the consensus algorithm has a sort of natural timescale on how quickly it converges.",
                    "label": 0
                },
                {
                    "sent": "So basically my being wrong has to do is affected by what happened since.",
                    "label": 0
                },
                {
                    "sent": "Let's say I think maybe in terms of sort of phases where we had consensus at some point, But then we kind of lost it and 40 times steps things have been happening and they have not already taken them into account.",
                    "label": 0
                },
                {
                    "sent": "So during the time scale of the consensus algorithm, everybody else is updating.",
                    "label": 0
                },
                {
                    "sent": "They do so many updates with this step size, and this is roughly the size of their update.",
                    "label": 0
                },
                {
                    "sent": "So this is how much everybody else has drifted from me before.",
                    "label": 0
                },
                {
                    "sent": "The consensus algorithm had a chance to take effect.",
                    "label": 0
                },
                {
                    "sent": "So throw it in here to do the error analysis.",
                    "label": 0
                },
                {
                    "sent": "Be 'cause if I put in here the gradient at Y instead of the gradient X, then I'm introducing an error of this order of magnitude where there's an extractor gamma term because my step size is of the order of gamma, and I guess that's the wrong + has made its way his way here.",
                    "label": 0
                },
                {
                    "sent": "This should have been a - So basically what I'm trying to argue here is that the.",
                    "label": 0
                },
                {
                    "sent": "This message distributed algorithm behaves approximately like a centralized algorithm when you keep track of the vector Y, except for some error terms that have to do with the amount of disagreement and those error terms will have in them the time that it takes for consensus to happen on the.",
                    "label": 0
                },
                {
                    "sent": "According to our consensus algorithm, because again, we have second order terms in the step size, it means that if we have to have.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "All step sizes.",
                    "label": 0
                },
                {
                    "sent": "This method as well, does converge to the place where you would like it to converge under sort of standard assumptions.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now, let's complicate things just a little bit more.",
                    "label": 0
                },
                {
                    "sent": "Suppose now that the cost function is additive.",
                    "label": 0
                },
                {
                    "sent": "It consists of several terms.",
                    "label": 0
                },
                {
                    "sent": "In which case the optimality conditions would be that the sum of the gradients is equal to 0.",
                    "label": 0
                },
                {
                    "sent": "What would you do in this case?",
                    "label": 0
                },
                {
                    "sent": "Well, let's start thinking again from the simple version.",
                    "label": 0
                },
                {
                    "sent": "If you were to run the algorithm in phases, what you would do?",
                    "label": 0
                },
                {
                    "sent": "Now think of the case worth agent.",
                    "label": 0
                },
                {
                    "sent": "I has access to the function FI so think of FI is corresponding to the large block of data.",
                    "label": 0
                },
                {
                    "sent": "So agents I calculates a gradient based only on its local cost function.",
                    "label": 0
                },
                {
                    "sent": "That agent knows.",
                    "label": 0
                },
                {
                    "sent": "So this means that even if we all started with the same vector, we would be moving in different directions.",
                    "label": 0
                },
                {
                    "sent": "But we want a common vector X, so after that we reconcile our axis by running a consensus algorithm, which convergence once more too.",
                    "label": 0
                },
                {
                    "sent": "To some value which is a weighted average of the values of the different agents altogether.",
                    "label": 0
                },
                {
                    "sent": "Taken altogether, what would these methods do?",
                    "label": 0
                },
                {
                    "sent": "It would do an update in the direction where the gradients or the updates terms of each agent are weighted by \u03c0. I is this the right thing to do?",
                    "label": 0
                },
                {
                    "sent": "Well.",
                    "label": 0
                },
                {
                    "sent": "If this method converges, what does it converge to?",
                    "label": 0
                },
                {
                    "sent": "It will converge to a place where this sum of the gradients is equal to 0.",
                    "label": 0
                },
                {
                    "sent": "But this is the wrong optimality condition, so the algorithm is doing the wrong thing.",
                    "label": 0
                },
                {
                    "sent": "In this case, what would we need in order to make it do the right thing?",
                    "label": 0
                },
                {
                    "sent": "What we need to do?",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is to have the pie eyes to be all equal, which means that in this particular case we need to run an averaging algorithm.",
                    "label": 0
                },
                {
                    "sent": "The metrics a should have a special property of being doubly stochastic, so in the previous version of optimization of distributed optimization, just any stochastic matrix would do to get consensus.",
                    "label": 0
                },
                {
                    "sent": "Here we need to make sure that the consensus algorithm we're using is.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is an averaging algorithm.",
                    "label": 0
                },
                {
                    "sent": "So this was the two phased version, now repeating the steps as I was discussing before.",
                    "label": 0
                },
                {
                    "sent": "Let us think of an interleaved version where we do both things simultaneously.",
                    "label": 0
                },
                {
                    "sent": "That is, we both run an averaging algorithm or that + is still there.",
                    "label": 0
                },
                {
                    "sent": "OK, so that of course has to be a - up there, so we run the consensus algorithm and at the same time and then the parenthesis missing gamma also multiplies the step size and we are making updates in the direction of negative.",
                    "label": 0
                },
                {
                    "sent": "Of direction of dissent.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's see thing.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK. Alright, how are we going to analyze this one?",
                    "label": 0
                },
                {
                    "sent": "How could one analyze this algorithm?",
                    "label": 0
                },
                {
                    "sent": "Well, again, you want to keep track of summary of the state of the algorithm, which in this case, since we're running an averaging algorithm, it should be the average of the values of the different agents.",
                    "label": 0
                },
                {
                    "sent": "And that's what we would agree if we were to stop updating.",
                    "label": 0
                },
                {
                    "sent": "But if you do, if we do an update.",
                    "label": 0
                },
                {
                    "sent": "If we do an update, we would do an update in that direction and after running the averaging algorithm, those updates would get an equal weight.",
                    "label": 0
                },
                {
                    "sent": "So this is sort of an approximate description of what the algorithm does.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And how do the axes differ from the wise, so the value possessed by a particular agent is going to differ from the summary of the state of the algorithm it's going to differ by factor that has to do with how much have the others done.",
                    "label": 0
                },
                {
                    "sent": "Before the consensus algorithm managed to take effect and deliver to similar argument is the one I went through before, but now it has termed that here.",
                    "label": 0
                },
                {
                    "sent": "That would involve the sum of the absolute of the magnitudes of the different gradients.",
                    "label": 0
                },
                {
                    "sent": "Because these terms have to do with how much everybody else is moving.",
                    "label": 0
                },
                {
                    "sent": "And now even if we were to converge to an optimum so that the gradient of the overall function goes to 0.",
                    "label": 0
                },
                {
                    "sent": "This term would not go to 0.",
                    "label": 0
                },
                {
                    "sent": "And so we this thing would fail to converge to 0 even if the algorithm converges.",
                    "label": 0
                },
                {
                    "sent": "And that's clear, it's clear what's happened.",
                    "label": 0
                },
                {
                    "sent": "Suppose we are at an optimum, even if we're at the optimum, the gradients of the different FI terms would be non zero.",
                    "label": 0
                },
                {
                    "sent": "The gradients adapt to zero at an optimum, but each one of the gradients of the FIS is non 0.",
                    "label": 0
                },
                {
                    "sent": "So even if we're at the optimum, everybody would take a step away and then the consensus algorithm might kind of bring them back.",
                    "label": 0
                },
                {
                    "sent": "But because they're stepping taking steps away, that means they do not converge.",
                    "label": 0
                },
                {
                    "sent": "So for this reason, this in this setting where we're dealing with the sum of the FIS, all the existing literature basically looks at cases where you have an excuse for taking the step size to 0 so that this term actually will will vanish.",
                    "label": 0
                },
                {
                    "sent": "And when do we take the step size to zero?",
                    "label": 0
                },
                {
                    "sent": "The typical cases are either when we have non smooth cost functions, in which case won't use the subgradient methods which does require a step sizes to go to zero.",
                    "label": 0
                },
                {
                    "sent": "Or the case where you have noise which is the stochastic approximation case.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK. Alright, so once you put throwing the all the right assumptions and so on is this work and Addison's dog Lauren then?",
                    "label": 0
                },
                {
                    "sent": "John Ducey and coauthors.",
                    "label": 0
                },
                {
                    "sent": "They have results for a variation of this method is slightly more sophisticated version of subgradient methods that shows that these methods will indeed converge and do the right thing.",
                    "label": 0
                },
                {
                    "sent": "Now let's look at the big picture.",
                    "label": 1
                },
                {
                    "sent": "If you were to start thinking about convergence times, how long doesn't any of the algorithms of the type that we discuss?",
                    "label": 0
                },
                {
                    "sent": "How long does it take to deliver a solution that's kind of epsilon close to the optimum?",
                    "label": 0
                },
                {
                    "sent": "Well, there's basically two things that are at play here.",
                    "label": 0
                },
                {
                    "sent": "You're running a convergent consensus algorithm.",
                    "label": 0
                },
                {
                    "sent": "That, and if you think about how much consensus algorithm takes in order to converge to consensus within some accuracy epsilon, this is going to be a function of your epsilon of the number of nodes and the topology of your network.",
                    "label": 1
                },
                {
                    "sent": "The dependence on epsilon is kind of trivial.",
                    "label": 0
                },
                {
                    "sent": "Becausw consensus algorithms are basically linear systems, so they converge at the rate of a geometric progression.",
                    "label": 0
                },
                {
                    "sent": "That means you're going to get the term.",
                    "label": 0
                },
                {
                    "sent": "That's basically like log, log, epsilon.",
                    "label": 0
                },
                {
                    "sent": "I guess I need an absolute value of in my log.",
                    "label": 0
                },
                {
                    "sent": "Or rather it's log one over epsilon, yeah?",
                    "label": 0
                },
                {
                    "sent": "OK, so basically that dependence on epsilon is kind of generic, so we're interested in how does the consensus time depends on the number of nodes.",
                    "label": 0
                },
                {
                    "sent": "And then there is the optimization side.",
                    "label": 0
                },
                {
                    "sent": "If you were to look at the gradient or subgradient algorithm just by itself in a centralized, centralized version of that algorithm, how long does it take to converge?",
                    "label": 1
                },
                {
                    "sent": "And in general that has some dependence on the number of nodes and the accuracy that you want.",
                    "label": 0
                },
                {
                    "sent": "Now typically these estimates for convergence times of an optimization algorithm have a lot more hidden in there.",
                    "label": 0
                },
                {
                    "sent": "You need to make specific assumptions about the structure of your functions put bounds on 1st and 2nd derivatives and all that, and this would somehow show up now.",
                    "label": 0
                },
                {
                    "sent": "But nevertheless one way or another people in mathematical programming do their homework and they come up with the rate of convergence of specific optimization algorithms.",
                    "label": 0
                },
                {
                    "sent": "If you were to run the two phase version.",
                    "label": 0
                },
                {
                    "sent": "Of any of the algorithms I described before, what's two phase?",
                    "label": 0
                },
                {
                    "sent": "Do a gradient update, then run a consensus algorithm?",
                    "label": 0
                },
                {
                    "sent": "Attila converges?",
                    "label": 0
                },
                {
                    "sent": "Do a gradient update, run consensus algorithm until updates?",
                    "label": 0
                },
                {
                    "sent": "Then basically we have the gradient algorithm, but each phase of the gradient algorithm needs to take so much time for the consensus algorithm to converge, so this would be the generic convergence time estimate.",
                    "label": 1
                },
                {
                    "sent": "The funny thing is that even when we look at Internet.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Live versions of this algorithm when we're trying to do both simultaneously.",
                    "label": 0
                },
                {
                    "sent": "That is, while you're updating, also run your consensus algorithm.",
                    "label": 0
                },
                {
                    "sent": "The whole the convergence time estimates that I can see in the literature basically have this kind of dependence.",
                    "label": 0
                },
                {
                    "sent": "OK, given that we can do that now, the following outsource this to people in mathematical programming and focus on that.",
                    "label": 0
                },
                {
                    "sent": "Basically I'm trying to say that there's sort of two separate challenges here.",
                    "label": 0
                },
                {
                    "sent": "One is to improve the optimization algorithm.",
                    "label": 0
                },
                {
                    "sent": "The other is to improve the convergence times of consensus algorithms and any results that you can get to improve the convergence time of a consensus algorithm automatically will translate to a converge to a faster convergence result.",
                    "label": 0
                },
                {
                    "sent": "For a distributed optimization.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this takes me to the second half of the talk, which will be of course less than 1/2.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And start moving a little faster.",
                    "label": 0
                },
                {
                    "sent": "So recall what consensus algorithm does.",
                    "label": 0
                },
                {
                    "sent": "But we're taking convex combinations of the values of different agents.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How long do these take to converge?",
                    "label": 0
                },
                {
                    "sent": "While you can come up, it's easiest here to think in terms of Markov chains.",
                    "label": 0
                },
                {
                    "sent": "You can easily come up with Markov chains whose time until they reach steady state, grows exponentially with the number of nodes.",
                    "label": 0
                },
                {
                    "sent": "Think of consensus algorithms.",
                    "label": 0
                },
                {
                    "sent": "The most interesting case perhaps is 1, where you give equal weight to all your neighbors.",
                    "label": 0
                },
                {
                    "sent": "That is, you get messages from 5 people and you take their values, take my values well, divide by 6 in terms of Markov chains.",
                    "label": 0
                },
                {
                    "sent": "That basically corresponds to doing a random walk on, do a random walk on a graph.",
                    "label": 0
                },
                {
                    "sent": "So depending on the graph, convergence times will change.",
                    "label": 0
                },
                {
                    "sent": "So for general random walks on directed graphs.",
                    "label": 0
                },
                {
                    "sent": "It takes an exponential amount for random walks to converge.",
                    "label": 0
                },
                {
                    "sent": "That's bad news for directed graphs, things that cannot be 2 buds in the worst cases, order of and tube, and the worst graph happens to be a so called dumbbell graph.",
                    "label": 0
                },
                {
                    "sent": "Of course, if you have special cases of graphs, things become better and better on a line consensus or a random walk takes order of N squared to converge, and if you look at even more special case of graph then the convergence time can be even smaller and smaller.",
                    "label": 0
                },
                {
                    "sent": "Even going down to Logan in some key.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is OK. No, already did that.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, now.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It happens to the for in the case of averaging algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For the case of.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Averaging algorithms on BI directional.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Graphs and if you take it, turns out that the convergence time is generically kind of good order of N squared divided by Alpha, where Alpha is a constant.",
                    "label": 0
                },
                {
                    "sent": "It's a lower bound on the non negative on the positive entries of the emetrics so positive that Alpha means the following.",
                    "label": 0
                },
                {
                    "sent": "Whenever I get a message from somebody else and I take that message into account in my updating, I'm going to give a weight of at least.",
                    "label": 0
                },
                {
                    "sent": "For to that neighbor.",
                    "label": 0
                },
                {
                    "sent": "Now what should Alpha be?",
                    "label": 0
                },
                {
                    "sent": "Well, in case I have neighbors and I'm giving a weight of Alpha to each one of them, my Alpha has to be one over North or smaller.",
                    "label": 0
                },
                {
                    "sent": "So in the worst case for graphs that have high degree, my Alpha would be 1 / N and this would give you convergence time of order of Ncube.",
                    "label": 0
                },
                {
                    "sent": "The interesting thing is that this is valid for any kind of graph.",
                    "label": 0
                },
                {
                    "sent": "We didn't need to make any any assumptions.",
                    "label": 0
                },
                {
                    "sent": "Averaging algorithms always take Ncube time to converge, assuming of course that you have connectivity in your graph.",
                    "label": 0
                },
                {
                    "sent": "If you have these two disconnected sets of agents, you wouldn't get.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, so that might sort of close the chapter, but here's why.",
                    "label": 0
                },
                {
                    "sent": "Don't quite exactly if this framework is not that fully satisfying.",
                    "label": 0
                },
                {
                    "sent": "If your deal, if you're running consensus algorithm of this form, X gets updated to aex.",
                    "label": 0
                },
                {
                    "sent": "So the coefficients AIJR constant.",
                    "label": 0
                },
                {
                    "sent": "We're basically assuming that we have a fixed graph in our network.",
                    "label": 1
                },
                {
                    "sent": "Now if you have a fixed graph, why in the world would you run a consensus algorithm by iterating any?",
                    "label": 1
                },
                {
                    "sent": "Let you do is take one of the nodes quality leader uniform spanning tree send messages to accumulate values, send them to that leader and then the leader tells the results.",
                    "label": 0
                },
                {
                    "sent": "There's absolutely no reason who I I iterate and use a messy and slow method.",
                    "label": 0
                },
                {
                    "sent": "If you have fixed graphs.",
                    "label": 0
                },
                {
                    "sent": "So this takes us to.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But I believe is a context where things could be interesting.",
                    "label": 0
                },
                {
                    "sent": "Or one could make an argument in favor of running a consensus algorithm, and that would be a chaotic or time varying environment in which the consensus algorithm has coefficients that change with time.",
                    "label": 0
                },
                {
                    "sent": "Who I do, they change with time.",
                    "label": 0
                },
                {
                    "sent": "Suppose that our interconnection graph keeps changing, so links are up and down.",
                    "label": 0
                },
                {
                    "sent": "I have a connection, but then the connection is off for some time.",
                    "label": 0
                },
                {
                    "sent": "What does that mean?",
                    "label": 0
                },
                {
                    "sent": "When the connection is off, AIJ has to be 0, but when the connection is on and I get a message and you take it to that into account, aij of tea is non 0, so the AIJ naturally will have to change with time.",
                    "label": 0
                },
                {
                    "sent": "If we have time varying topology.",
                    "label": 0
                },
                {
                    "sent": "So this takes us to an iteration of this kind.",
                    "label": 0
                },
                {
                    "sent": "So a of Tia metrics now starts depending on time, and we're now dealing with inhomogeneous Markov chains.",
                    "label": 0
                },
                {
                    "sent": "If you want to visualize this thing probabilistically.",
                    "label": 0
                },
                {
                    "sent": "So now that once we allow variations in the graph, there's basically two ways that you can go.",
                    "label": 0
                },
                {
                    "sent": "One is to assume to say yes, we have variations, but these variations are generated according to a very regular.",
                    "label": 0
                },
                {
                    "sent": "And time invariant mechanism.",
                    "label": 0
                },
                {
                    "sent": "So for example graphs are generated in in dependently identically distributed manner, every time.",
                    "label": 0
                },
                {
                    "sent": "So every time step you get a random graph.",
                    "label": 0
                },
                {
                    "sent": "Next time you get a random graph, the graphs are changing, but the statistics of the graphs are constant.",
                    "label": 0
                },
                {
                    "sent": "So in some sense in terms of expected values, this is not very different from the case of a fixed graph.",
                    "label": 0
                },
                {
                    "sent": "Think of a random graph as being a fixed graph plus noise in some sense.",
                    "label": 0
                },
                {
                    "sent": "So the expected value.",
                    "label": 0
                },
                {
                    "sent": "The a metrics is the expected a metrics plus an error term.",
                    "label": 0
                },
                {
                    "sent": "So things go through pretty nicely here and the same traditional analysis by looking at mixing times of Markov chains does work here as well.",
                    "label": 0
                },
                {
                    "sent": "No completely regular mechanism for generating those communication graphs would be a bit implausible in settings where you think of.",
                    "label": 0
                },
                {
                    "sent": "Some quite disconnected processors who do their own thing and decide to communicate once in awhile, so I'll take the different route and basically let the a matrices.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Changed arbitrarily with time, so I want my algorithm to work for any sequence of topologies.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "Any sequence of topologies, but with some restrictions once in there should be enough ways of everybody to influence everybody else, and we capture this in an assumption that says that every B time steps were B is some constant.",
                    "label": 0
                },
                {
                    "sent": "The communications that have happened over those big time steps give you strongly connected graph.",
                    "label": 1
                },
                {
                    "sent": "I guess in plain English that basically says that over B time steps there are there's a sequence of arcs that could have been used during these steps that would let Agent I influence Agent J Overby time steps.",
                    "label": 0
                },
                {
                    "sent": "There is a path of indirect influences that everybody can influence everybody else.",
                    "label": 0
                },
                {
                    "sent": "Now these influences do not need to happen at the same time.",
                    "label": 0
                },
                {
                    "sent": "So it's sometimes these are comes in, so this one can influence that one next time another arc comes in and this guy can influence that guy and so on.",
                    "label": 0
                },
                {
                    "sent": "OK, so under this assumption, the algorithm, the consensus algorithm still converges and we get consensus.",
                    "label": 0
                },
                {
                    "sent": "In the limit.",
                    "label": 0
                },
                {
                    "sent": "The news in general tend to be bad.",
                    "label": 0
                },
                {
                    "sent": "31 can make an example where the convergence time of this is going to be exponential even if we have a symmetric graph at each time.",
                    "label": 1
                },
                {
                    "sent": "Remember in the case of without time variations, I said before that when you have bidirectional or symmetric graphs, the result by Lando Delisco tells us that.",
                    "label": 0
                },
                {
                    "sent": "Order of N Cube is the worst case convergence time, but if you allow the time variations then things become much worse and can take exponential time to converge.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On the other hand, the good news is that if you restrict to the case of averaging so the a matrix is a stochastic matrix at.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Each point in time, then magically the convergence rate becomes the same one as the estimate that we had for the time invariant case.",
                    "label": 0
                },
                {
                    "sent": "So even though we allow time variations for doubly stochastic matrices, convergence times do not get worse.",
                    "label": 0
                },
                {
                    "sent": "It's again one order N squared over Alpha and Alpha.",
                    "label": 0
                },
                {
                    "sent": "Again, remember is that number is the minimal weight that you give to anybody that you do take into account.",
                    "label": 0
                },
                {
                    "sent": "As I said before, Alpha might have to be 1 / N. In case you have neighbors.",
                    "label": 1
                },
                {
                    "sent": "So if you want to improve this estimate and get rid of that Alpha, what would you do?",
                    "label": 0
                },
                {
                    "sent": "Kind of artificially forced the degree of your graph to be small by talking only to two neighbors at the time, and there is a trick of how to do this locally and this gives us a convergence time of order of North Square.",
                    "label": 1
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And Yep.",
                    "label": 0
                },
                {
                    "sent": "OB, of course, comes in yes.",
                    "label": 0
                },
                {
                    "sent": "And it comes in linearly, so it's B N ^2.",
                    "label": 0
                },
                {
                    "sent": "So amazingly, the case of time variations and arbitrary time variations is not much is no worse than what we can achieve on.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Fixed graphs.",
                    "label": 0
                },
                {
                    "sent": "Now, once you have this result, you can just take it and capitalize it in various forms.",
                    "label": 0
                },
                {
                    "sent": "What I'm refering to here is that Jillian edits and as well as the glare had done some work showing the convergence of the subgradient algorithm.",
                    "label": 0
                },
                {
                    "sent": "Distributed version of it using all estimates for convergence times.",
                    "label": 0
                },
                {
                    "sent": "And they gave convergence time that was exponentially North as soon as we got that result about the speed of convergence algorithm, then you just take the result in their paper.",
                    "label": 0
                },
                {
                    "sent": "And basically scale down the constants, Yep.",
                    "label": 0
                },
                {
                    "sent": "Sure, that doesn't.",
                    "label": 0
                },
                {
                    "sent": "Again stick when you're constrained by this small.",
                    "label": 0
                },
                {
                    "sent": "OK, so theoretically.",
                    "label": 0
                },
                {
                    "sent": "OK, are you refering to how do I make sure that it is double stochastic in general or in the trick?",
                    "label": 0
                },
                {
                    "sent": "The side that I kind of skipped?",
                    "label": 0
                },
                {
                    "sent": "So to make it doubly stochastic you can you have that property whenever you have pairwise exchanges that is somehow two nodes.",
                    "label": 0
                },
                {
                    "sent": "Decide and agree.",
                    "label": 0
                },
                {
                    "sent": "We're going to exchange values and we look.",
                    "label": 0
                },
                {
                    "sent": "You have eight.",
                    "label": 0
                },
                {
                    "sent": "I have 6 where 2 apart and now the two of us moved to 7 seven.",
                    "label": 0
                },
                {
                    "sent": "So the little trick that comes in here is basically a small protocol for four nodes to choose pairs of interactions and you have to do that in a local way.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so the.",
                    "label": 0
                },
                {
                    "sent": "After doing all this work and playing with all those convergence times and so on, the I think the intellectual question that shows up and perhaps practical as well, is whether this order of N squared that keeps showing up all the time is something that we can beat.",
                    "label": 0
                },
                {
                    "sent": "Can we get convergence or consensus algorithms to be faster?",
                    "label": 1
                },
                {
                    "sent": "OK and 1st let's try to understand that question for the case of static graphs, can we get the convergence time for consensus?",
                    "label": 1
                },
                {
                    "sent": "That's faster?",
                    "label": 0
                },
                {
                    "sent": "Of course yes.",
                    "label": 0
                },
                {
                    "sent": "If we have special static graphs.",
                    "label": 1
                },
                {
                    "sent": "If you have a geometric random graph or if you have a small world graph, consensus times are smaller.",
                    "label": 0
                },
                {
                    "sent": "But here opposing the question in the in the worst case overall graphs.",
                    "label": 0
                },
                {
                    "sent": "Well if you try to run nonlinear updates, may perhaps linearity was what was slowing down the algorithm.",
                    "label": 1
                },
                {
                    "sent": "Senior updates do not help if you look at update rules of this kind.",
                    "label": 0
                },
                {
                    "sent": "As long as F is smooth, non linearity does not help becausw locali near the point of convergence.",
                    "label": 1
                },
                {
                    "sent": "Whatever F you use will look as approximately linear.",
                    "label": 0
                },
                {
                    "sent": "Think of the random.",
                    "label": 1
                },
                {
                    "sent": "Let's take a random walk on the line which takes N squared to converge, but start playing with the probabilities that you use in that random walk and make them a little different.",
                    "label": 0
                },
                {
                    "sent": "Cannot help.",
                    "label": 0
                },
                {
                    "sent": "It turns out that this cannot help.",
                    "label": 0
                },
                {
                    "sent": "So on the line your any kind of random walk will have an square and you will get stuck.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of course we can beat N squared if we do the trivial solution.",
                    "label": 0
                },
                {
                    "sent": "Set up a spanning tree, add the values, and you're done.",
                    "label": 0
                },
                {
                    "sent": "That's takes time order of the day of the diameter of the network, so if we can beat it.",
                    "label": 0
                },
                {
                    "sent": "So in this simple way who I care about, everything else well, to get a meaningful discussion going, we need to put down a model of computation that does not allow spanning trees.",
                    "label": 0
                },
                {
                    "sent": "What would be this case?",
                    "label": 0
                },
                {
                    "sent": "This case would be a case of unstructured.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Problems.",
                    "label": 0
                },
                {
                    "sent": "We are unstructured.",
                    "label": 0
                },
                {
                    "sent": "Unstructured networks where do you do not?",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Have a clear way of setting up a leader and so on.",
                    "label": 0
                },
                {
                    "sent": "So think of sensor networks or sensor network with anonymous nodes for example, so we have come up with a model that we believe is reasonable and basically rules out spanning tree solutions and the model is the following.",
                    "label": 0
                },
                {
                    "sent": "First, we don't want to have IDs at the nodes because then you can elect a leader and get the spanning tree to avoid having ideas, we basically need to have nodes be anonymous, everybody doing the same thing.",
                    "label": 0
                },
                {
                    "sent": "And we prohibit randomization because if you use randomization you can generate ID's.",
                    "label": 0
                },
                {
                    "sent": "And within that model, the model is quite restrictive in what it can do.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But we have managed to show after quite a bit of struggle that we can solve some types of consensus problems in order of North Squared time.",
                    "label": 0
                },
                {
                    "sent": "So the model is restrictive but not too restrictive.",
                    "label": 0
                },
                {
                    "sent": "And skipping details, but.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In the end, the sort of conclusion concluding point is that is N ^2, a fundamental lower bound, and I may be hard, but perhaps there is a hope of showing such a lower bound under this particular model that we have here, which would be kind of bad news.",
                    "label": 1
                },
                {
                    "sent": "This is for bidirectional graphs or symmetric graphs.",
                    "label": 0
                },
                {
                    "sent": "Then there's questions for the directed case, and then what exactly happens when the time varying case under such restrictive models of computation?",
                    "label": 0
                },
                {
                    "sent": "Is not so clear.",
                    "label": 0
                },
                {
                    "sent": "So basically the point I want to make here is that they eventually were interested in finding what are the fundamental limitations of such consensus algorithms and but in order to address questions of this time one needs to be clear about what kind of model computation one is using.",
                    "label": 0
                },
                {
                    "sent": "And here one starts interacting with what happens in the distributed algorithms area in theoretical computer science sort of divisions, and one needs to adopt a little bit of that way of thinking.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Conclude, thank you very much.",
                    "label": 0
                },
                {
                    "sent": "OK, so now is the coffee break, but if there's maybe a couple of questions for you that so you have a pretty convincing story about what happens with edge deletion.",
                    "label": 0
                },
                {
                    "sent": "But if you run kind of a big enough complication on enough machines for enough time, some of those machines are going to die.",
                    "label": 0
                },
                {
                    "sent": "If you say anything about robustness to actually agents dropping out of the computation.",
                    "label": 0
                },
                {
                    "sent": "OK, so if you think of the case of F eyes that are the block of data, so I guess I dies and the date of I dive together right?",
                    "label": 0
                },
                {
                    "sent": "So this is the OK.",
                    "label": 0
                },
                {
                    "sent": "So this is more of a statistical issue I guess, so you're optimal.",
                    "label": 0
                },
                {
                    "sent": "Your optimal estimator based on fewer data.",
                    "label": 0
                },
                {
                    "sent": "How does it perform compared to the optimal based on all data?",
                    "label": 0
                },
                {
                    "sent": "I think it's interesting practical questions, probably tangential to what we've talked about.",
                    "label": 0
                },
                {
                    "sent": "You totally out of the storage complexity, so it seems like you're still having to store some of that statement for the excited just died on other machines.",
                    "label": 0
                },
                {
                    "sent": "This is, I get very large problems, my problems bigger because it's poorly machine model.",
                    "label": 0
                },
                {
                    "sent": "OK, so the XI might not be so hard to store, so the data are massive.",
                    "label": 0
                },
                {
                    "sent": "That means that my functions FI might be hard to compute, but the excise are sort of my parameter estimates that I'm trying to learn and so this might be much more manageable.",
                    "label": 0
                },
                {
                    "sent": "As you pointed out, for even these algorithms that run sort of interleaved consensus plus optimization, there's this disappointing aspect that the convergence rate is pretty much the the product of the two which the algorithm already gives.",
                    "label": 0
                },
                {
                    "sent": "You have an intuition about whether that's a fundamental restriction, or that's just a limitation of the analysis.",
                    "label": 0
                },
                {
                    "sent": "Have a sense that it's you cannot improve it, but I think this is a really good question to actually resolve.",
                    "label": 0
                },
                {
                    "sent": "If one could somehow could prove a negative result of this type, it would be interesting.",
                    "label": 0
                },
                {
                    "sent": "But to prove negative results, the trouble is that you need to become very specific about your models of computations and classes of algorithms that are allowed.",
                    "label": 0
                },
                {
                    "sent": "You must not distribute it.",
                    "label": 0
                },
                {
                    "sent": "Distributed way.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "What's the progress for them?",
                    "label": 0
                },
                {
                    "sent": "What's the progress?",
                    "label": 0
                },
                {
                    "sent": "Well, to the extent that it overlaps with what I mentioned here.",
                    "label": 0
                },
                {
                    "sent": "Basically, distributed reinforcement learning is at least some of the algorithms have the flavor of distributed gradient like algorithms.",
                    "label": 0
                },
                {
                    "sent": "An so if you have a distributor reinforcement learning algorithm that would fall in this type of setting, then you could kind of transfer some of the results.",
                    "label": 0
                },
                {
                    "sent": "On the other hand.",
                    "label": 0
                },
                {
                    "sent": "So that having followed very much the latest what's happening in that field.",
                    "label": 0
                },
                {
                    "sent": "My sense is that there are people really want to get things to work, and so there may be some ad hoc features in and out that are useful, but are less easy to analyze theoretically.",
                    "label": 0
                },
                {
                    "sent": "Close.",
                    "label": 0
                },
                {
                    "sent": "I think we'll take the coffee break now, so if you have more questions I'm sure.",
                    "label": 0
                },
                {
                    "sent": "Let's thank John.",
                    "label": 0
                }
            ]
        }
    }
}