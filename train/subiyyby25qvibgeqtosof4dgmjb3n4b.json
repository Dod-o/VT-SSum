{
    "id": "subiyyby25qvibgeqtosof4dgmjb3n4b",
    "title": "An Object Co-occurrence Assisted Hierarchical Model for Scene Understanding",
    "info": {
        "author": [
            "Xin Li, Temple University"
        ],
        "published": "Oct. 9, 2012",
        "recorded": "September 2012",
        "category": [
            "Top->Computer Science->Computer Vision"
        ]
    },
    "url": "http://videolectures.net/bmvc2012_li_scene_understanding/",
    "segmentation": [
        [
            "Hi, my name is Shelly and I'm from Temple University Philadelphia and our paper is.",
            "The title of our paper is the object occurrence assisted hierarchical model forcing understanding."
        ],
        [
            "First, what is this thing literally?",
            "It's a view of a real world environment.",
            "I list three thing categories here, and if you look carefully, the images from the same category has a similar object layout, so we can also interpret the thing as a configuration of objects.",
            "So it's a semantic description of the space."
        ],
        [
            "And the problem we're trying to solve is called.",
            "Scene recognition is to assign a set of semantic model labels to an image, and there is a similar task in computer vision called object recognition.",
            "And let's say this example.",
            "If we take this image as an input, the ideal output of object recognition should be car, House, Rd and Sky.",
            "Because this image contains this for objects but forcing recognition, the only output is street.",
            "So we can also say the street scene contains this for object."
        ],
        [
            "And there is a historic.",
            "Historically, there is a controversy of cognition.",
            "One argument is that the low level features capture the gist of a scene which is already good enough.",
            "But some other guys argues that intermediate semantic representation is still necessary because of the gap between the low level representation and the high level recognition goals.",
            "So what are they arguing about the.",
            "The people agree with.",
            "The first argument will stop there after they get the low level representation and they will perform classification based on this representation.",
            "But the supporters of the second argument would like to keep going."
        ],
        [
            "Following this two arguments, the existing work has two directions, 1 is low level modeling and the methods of this category use low level features to represent an image, and most of them using the linear classifier as VM and the other direction is semantic modeling.",
            "These methods are trying to deal with the gap between the low level representation and the recognition goes some of them using SVM and some of them using probabilistic graphical model."
        ],
        [
            "So our proposed solution is a hierarchical probabilistic graphical model.",
            "We require segmentation as a preprocessing step, and our model contains both low level representation and high level representation."
        ],
        [
            "So here is our model.",
            "It seems complicated, but."
        ],
        [
            "Don't worry, I think everyone can follow.",
            "First, it has three levels.",
            "The top level is the same level.",
            "There is a.",
            "There is a chain consisted by."
        ],
        [
            "Predefined the number of oh nodes.",
            "Each owner is a object category."
        ],
        [
            "It's a binary node.",
            "1 means the present presence, and 0 means the absence."
        ],
        [
            "This this chain category and this chain structure captures the relationship between different object categories and then the mid level is."
        ],
        [
            "The the object level where the object recognition is accomplished in place."
        ],
        [
            "And it's also the bridge between the low level representation and high level recognition."
        ],
        [
            "And the bottom level is super pixel level, where the low level representation TR nodes and the TX nodes are regions and patches respectively and."
        ],
        [
            "Since we have both regions and patches, so our features contains two types as well, the region based region based feature we use shape and location proposed in CVPR 2008 and texture, which is the average responses of filter banks in each region and the color is computed from the histogram for Patch based features we we use SIFT."
        ],
        [
            "OK, so for graphical model we always want to compute the joint probability and.",
            "For the, for the top level I mean the same level we perform supervised learning, which means we give the image itself and we also give this thing labels.",
            "And the four the.",
            "Answer For the object level.",
            "I mean the mid level we perform the unsupervised learning so we only input the segmentation result and without any labels at all."
        ],
        [
            "So the segmentation algorithm we use in our method is proposed by fails as well being my JCV 2004 and why we want to do this.",
            "The sync content contains multiple objects and each object occupies multiple regions.",
            "So the basic idea behind this is if we could obtain this image and this these regions then we could note the object layout in this in this image.",
            "And then we can do the same prediction based on this object layout."
        ],
        [
            "So for training we use the collapsed Gibbs sampling algorithm and which is.",
            "When you when you try to learn latent variable, you will assume all other variables are being given.",
            "So the objective function of low level modeling is the product of these two probability.",
            "Its meaning is if we know the object category, what's the low level representation looks like and the objective function of high level modeling.",
            "Is this product is this probability and its meaning is if we know this thing category and other objects in this image?",
            "Will this will this object appear?",
            "OK, so.",
            "For the inference."
        ],
        [
            "Step and the testing data.",
            "We only have low level representation.",
            "So we want to compute this probability and since based on our model structure and the local Markov property, we could.",
            "Factorize this probability into several factors and all these factors has been learned in our model.",
            "So we just what are we going to do is just integrate them out and finally we will output the same label with the highest probability."
        ],
        [
            "Since the Gibbs sampling cannot guarantee a global Optima, so.",
            "I mean, if you take different start, different value of para meters, you will end up with different models."
        ],
        [
            "So in order to deal with this issue, we our solution is we Train 5 models with different random starts and outputs.",
            "The prediction voted by most models.",
            "It cannot solve perfectly, but it can avoid some local optimum.",
            "This is our ansamble precede."
        ],
        [
            "OK, our our experiment.",
            "Performed on label made data set and specifically we take 10 scene categories including both indoor and outdoor thing, and then we define the number of object category to be 30.",
            "And then we also compare our method with with three other baselines.",
            "The our method without ansamble procedure.",
            "When we talked the last slides.",
            "And the model without the chain structure, the top level.",
            "Oh notes, chain structure and the also compare with the state of the art method object, the bank and SVN.",
            "Here is our result.",
            "The first column is a region."
        ],
        [
            "Image and the second column is the segmentation result and the third column is the object recognition result.",
            "Finally the same prediction.",
            "So since our object recognition we learned our mid level unsupervised.",
            "In less unsupervised way, so this annotation is being achieved automatically.",
            "It's really helpful since we all know that the annotation manual manual annotation is quite.",
            "However.",
            "And the course object recognition improve the prediction performance in a row.",
            "There are computers, speakers, window and the table in this image, but only computer being detected successfully.",
            "However, we can still tell this is an office because in the training set and each office thing has at least one computer, so computer is quite important for office thing and.",
            "And then missing critical objects may also lead to the wrong thing classification.",
            "Let's see the first row and the ground truth says it's a coast thing.",
            "But our algorithm output it St because there is a C hidden here, so it's even hard for human so.",
            "We also have some more empirical."
        ],
        [
            "Experimental result and.",
            "First I want to say object the bank is training on.",
            "Multiple objects are multiple datasets including label Me so they can.",
            "They can benefit from the large amount of training set and since our training set and testing set is partitioned randomly, so maybe our training training data in our testing data is being used as training data.",
            "When they train their detectors, but even though our average performance is still as good as the state of the art method.",
            "And the compare was the first column compared the first column with the third column we could see.",
            "That the chain structure does improve the accuracy.",
            "And also the ansamble procedure.",
            "Increase the robustness of the model.",
            "So we present."
        ],
        [
            "A hierarchical probabilistic graphical model which can achieve automatic and implicit object annotation and object recognition is helpful for the task of sting recognition and the context role information encoded by that probabilistic chain structure improves the performance of classifier and the issue of local optimum can be dressed effectively by simply using the ensamble strategy."
        ],
        [
            "OK, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi, my name is Shelly and I'm from Temple University Philadelphia and our paper is.",
                    "label": 0
                },
                {
                    "sent": "The title of our paper is the object occurrence assisted hierarchical model forcing understanding.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "First, what is this thing literally?",
                    "label": 1
                },
                {
                    "sent": "It's a view of a real world environment.",
                    "label": 1
                },
                {
                    "sent": "I list three thing categories here, and if you look carefully, the images from the same category has a similar object layout, so we can also interpret the thing as a configuration of objects.",
                    "label": 1
                },
                {
                    "sent": "So it's a semantic description of the space.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the problem we're trying to solve is called.",
                    "label": 0
                },
                {
                    "sent": "Scene recognition is to assign a set of semantic model labels to an image, and there is a similar task in computer vision called object recognition.",
                    "label": 1
                },
                {
                    "sent": "And let's say this example.",
                    "label": 0
                },
                {
                    "sent": "If we take this image as an input, the ideal output of object recognition should be car, House, Rd and Sky.",
                    "label": 0
                },
                {
                    "sent": "Because this image contains this for objects but forcing recognition, the only output is street.",
                    "label": 0
                },
                {
                    "sent": "So we can also say the street scene contains this for object.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And there is a historic.",
                    "label": 0
                },
                {
                    "sent": "Historically, there is a controversy of cognition.",
                    "label": 1
                },
                {
                    "sent": "One argument is that the low level features capture the gist of a scene which is already good enough.",
                    "label": 1
                },
                {
                    "sent": "But some other guys argues that intermediate semantic representation is still necessary because of the gap between the low level representation and the high level recognition goals.",
                    "label": 1
                },
                {
                    "sent": "So what are they arguing about the.",
                    "label": 0
                },
                {
                    "sent": "The people agree with.",
                    "label": 0
                },
                {
                    "sent": "The first argument will stop there after they get the low level representation and they will perform classification based on this representation.",
                    "label": 0
                },
                {
                    "sent": "But the supporters of the second argument would like to keep going.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Following this two arguments, the existing work has two directions, 1 is low level modeling and the methods of this category use low level features to represent an image, and most of them using the linear classifier as VM and the other direction is semantic modeling.",
                    "label": 0
                },
                {
                    "sent": "These methods are trying to deal with the gap between the low level representation and the recognition goes some of them using SVM and some of them using probabilistic graphical model.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So our proposed solution is a hierarchical probabilistic graphical model.",
                    "label": 0
                },
                {
                    "sent": "We require segmentation as a preprocessing step, and our model contains both low level representation and high level representation.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here is our model.",
                    "label": 0
                },
                {
                    "sent": "It seems complicated, but.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Don't worry, I think everyone can follow.",
                    "label": 0
                },
                {
                    "sent": "First, it has three levels.",
                    "label": 0
                },
                {
                    "sent": "The top level is the same level.",
                    "label": 0
                },
                {
                    "sent": "There is a.",
                    "label": 0
                },
                {
                    "sent": "There is a chain consisted by.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Predefined the number of oh nodes.",
                    "label": 0
                },
                {
                    "sent": "Each owner is a object category.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's a binary node.",
                    "label": 0
                },
                {
                    "sent": "1 means the present presence, and 0 means the absence.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This this chain category and this chain structure captures the relationship between different object categories and then the mid level is.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The the object level where the object recognition is accomplished in place.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And it's also the bridge between the low level representation and high level recognition.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the bottom level is super pixel level, where the low level representation TR nodes and the TX nodes are regions and patches respectively and.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Since we have both regions and patches, so our features contains two types as well, the region based region based feature we use shape and location proposed in CVPR 2008 and texture, which is the average responses of filter banks in each region and the color is computed from the histogram for Patch based features we we use SIFT.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so for graphical model we always want to compute the joint probability and.",
                    "label": 1
                },
                {
                    "sent": "For the, for the top level I mean the same level we perform supervised learning, which means we give the image itself and we also give this thing labels.",
                    "label": 0
                },
                {
                    "sent": "And the four the.",
                    "label": 1
                },
                {
                    "sent": "Answer For the object level.",
                    "label": 1
                },
                {
                    "sent": "I mean the mid level we perform the unsupervised learning so we only input the segmentation result and without any labels at all.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the segmentation algorithm we use in our method is proposed by fails as well being my JCV 2004 and why we want to do this.",
                    "label": 0
                },
                {
                    "sent": "The sync content contains multiple objects and each object occupies multiple regions.",
                    "label": 1
                },
                {
                    "sent": "So the basic idea behind this is if we could obtain this image and this these regions then we could note the object layout in this in this image.",
                    "label": 0
                },
                {
                    "sent": "And then we can do the same prediction based on this object layout.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for training we use the collapsed Gibbs sampling algorithm and which is.",
                    "label": 1
                },
                {
                    "sent": "When you when you try to learn latent variable, you will assume all other variables are being given.",
                    "label": 0
                },
                {
                    "sent": "So the objective function of low level modeling is the product of these two probability.",
                    "label": 0
                },
                {
                    "sent": "Its meaning is if we know the object category, what's the low level representation looks like and the objective function of high level modeling.",
                    "label": 0
                },
                {
                    "sent": "Is this product is this probability and its meaning is if we know this thing category and other objects in this image?",
                    "label": 0
                },
                {
                    "sent": "Will this will this object appear?",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "For the inference.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Step and the testing data.",
                    "label": 1
                },
                {
                    "sent": "We only have low level representation.",
                    "label": 0
                },
                {
                    "sent": "So we want to compute this probability and since based on our model structure and the local Markov property, we could.",
                    "label": 0
                },
                {
                    "sent": "Factorize this probability into several factors and all these factors has been learned in our model.",
                    "label": 0
                },
                {
                    "sent": "So we just what are we going to do is just integrate them out and finally we will output the same label with the highest probability.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Since the Gibbs sampling cannot guarantee a global Optima, so.",
                    "label": 0
                },
                {
                    "sent": "I mean, if you take different start, different value of para meters, you will end up with different models.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in order to deal with this issue, we our solution is we Train 5 models with different random starts and outputs.",
                    "label": 1
                },
                {
                    "sent": "The prediction voted by most models.",
                    "label": 0
                },
                {
                    "sent": "It cannot solve perfectly, but it can avoid some local optimum.",
                    "label": 0
                },
                {
                    "sent": "This is our ansamble precede.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, our our experiment.",
                    "label": 0
                },
                {
                    "sent": "Performed on label made data set and specifically we take 10 scene categories including both indoor and outdoor thing, and then we define the number of object category to be 30.",
                    "label": 1
                },
                {
                    "sent": "And then we also compare our method with with three other baselines.",
                    "label": 0
                },
                {
                    "sent": "The our method without ansamble procedure.",
                    "label": 0
                },
                {
                    "sent": "When we talked the last slides.",
                    "label": 0
                },
                {
                    "sent": "And the model without the chain structure, the top level.",
                    "label": 1
                },
                {
                    "sent": "Oh notes, chain structure and the also compare with the state of the art method object, the bank and SVN.",
                    "label": 0
                },
                {
                    "sent": "Here is our result.",
                    "label": 0
                },
                {
                    "sent": "The first column is a region.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Image and the second column is the segmentation result and the third column is the object recognition result.",
                    "label": 0
                },
                {
                    "sent": "Finally the same prediction.",
                    "label": 0
                },
                {
                    "sent": "So since our object recognition we learned our mid level unsupervised.",
                    "label": 0
                },
                {
                    "sent": "In less unsupervised way, so this annotation is being achieved automatically.",
                    "label": 0
                },
                {
                    "sent": "It's really helpful since we all know that the annotation manual manual annotation is quite.",
                    "label": 0
                },
                {
                    "sent": "However.",
                    "label": 0
                },
                {
                    "sent": "And the course object recognition improve the prediction performance in a row.",
                    "label": 1
                },
                {
                    "sent": "There are computers, speakers, window and the table in this image, but only computer being detected successfully.",
                    "label": 0
                },
                {
                    "sent": "However, we can still tell this is an office because in the training set and each office thing has at least one computer, so computer is quite important for office thing and.",
                    "label": 1
                },
                {
                    "sent": "And then missing critical objects may also lead to the wrong thing classification.",
                    "label": 0
                },
                {
                    "sent": "Let's see the first row and the ground truth says it's a coast thing.",
                    "label": 0
                },
                {
                    "sent": "But our algorithm output it St because there is a C hidden here, so it's even hard for human so.",
                    "label": 0
                },
                {
                    "sent": "We also have some more empirical.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Experimental result and.",
                    "label": 0
                },
                {
                    "sent": "First I want to say object the bank is training on.",
                    "label": 0
                },
                {
                    "sent": "Multiple objects are multiple datasets including label Me so they can.",
                    "label": 0
                },
                {
                    "sent": "They can benefit from the large amount of training set and since our training set and testing set is partitioned randomly, so maybe our training training data in our testing data is being used as training data.",
                    "label": 0
                },
                {
                    "sent": "When they train their detectors, but even though our average performance is still as good as the state of the art method.",
                    "label": 1
                },
                {
                    "sent": "And the compare was the first column compared the first column with the third column we could see.",
                    "label": 1
                },
                {
                    "sent": "That the chain structure does improve the accuracy.",
                    "label": 0
                },
                {
                    "sent": "And also the ansamble procedure.",
                    "label": 1
                },
                {
                    "sent": "Increase the robustness of the model.",
                    "label": 0
                },
                {
                    "sent": "So we present.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A hierarchical probabilistic graphical model which can achieve automatic and implicit object annotation and object recognition is helpful for the task of sting recognition and the context role information encoded by that probabilistic chain structure improves the performance of classifier and the issue of local optimum can be dressed effectively by simply using the ensamble strategy.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, thank you.",
                    "label": 0
                }
            ]
        }
    }
}