{
    "id": "oky2awb5sqoobd3kgilrg2cekrivgpoj",
    "title": "Tag Suggestr: Automatic Photo Tag Expansion using Visual Information for Photo Sharing Websites",
    "info": {
        "author": [
            "Sare G\u00fcl Sevil, Bilkent University"
        ],
        "published": "Dec. 18, 2008",
        "recorded": "December 2008",
        "category": [
            "Top->Computer Science->Computer Vision->Image & Video Retrieval",
            "Top->Computer Science->Web Mining",
            "Top->Computer Science->Image Analysis"
        ]
    },
    "url": "http://videolectures.net/samt08_sevil_apte/",
    "segmentation": [
        [
            "Hello, I'm here on behalf of my project group I will be presenting tax suggest Sir to you as you all know with the growth in number of various web applications on the new trend of sharing publishing digital media on the web, we have millions of photos available on the Internet.",
            "Unfortunately, due to the flexibility of the environment, it's hard to organize and retrieve these."
        ],
        [
            "It is.",
            "To solve this problem, photo sharing websites have been established.",
            "They provide."
        ],
        [
            "Functionality is including tagging, browsing.",
            "Here is a list subset of a list presented in Wikipedia.",
            "These are some of the most widely used photo sharing websites throughout the world, and although I do not know the details of their internal source structure, they organize their photos with respect to the users to upload them, and they are browsing and searching.",
            "Algorithms are text based.",
            "Why are they using text based approaches?",
            "Because it's easier to implement and.",
            "Claim to be more efficient as opposed to content based image retrieval methods, but despite their wide usage it would not be truthful to say that these photo sharing websites solves the organizational problems we have because text based approaches are not sufficient, we have chosen to implement our tax adjuster on Flickr.",
            "There was no specific reason Tech Flickr is a famous popular website and it has a nice API so but.",
            "The method we're proposing is applicable to any other photo sharing website, including tagging functionality.",
            "Here you see a picture that is available on Flickr and it's crisp."
        ],
        [
            "Turning tides listed on the right.",
            "As you can see, these types are not specifically describing the content of the picture.",
            "It includes tags that are describing the camera curse characteristics and.",
            "Which is not really relevant to the content of the image itself.",
            "They also have irrelevant tags like forest for example.",
            "OK, we do see trees in this picture, but this is not really a picture of forest and we have tag son.",
            "We don't see the sun itself, we see sunlight, so that's not very relevant, so it doesn't have any tags explaining the garden or the house.",
            "So what we see here is that tags are noisy Ann.",
            "They are not complete, so if we're searching for this image, the question is, are these tags really helping us?"
        ],
        [
            "So what we propose is a tax adjuster system that suggests tags at upload time.",
            "The purpose is to assist users in order to ease the process of tagging.",
            "Since users are willing to tag, but they're not necessarily there.",
            "Really lazy in doing this, and another purpose is to reduce noise and tags and provide more descriptive and meaningful tags.",
            "Our approach has four main steps, as you can see in the figure.",
            "First, one user is uploading.",
            "The image we require them to end."
        ],
        [
            "For some initial tags we use these tags to retrieve photos that we might we think that might be relevant to our target photo.",
            "We also retrieve their corresponding set of Tizen for unique set of tags from which we will choose our suggested tags.",
            "Then we compute weights for these tags using visual similarities and sort the tags according to their weights and suggests high strength once to the user.",
            "Now I will explain the steps in further detail."
        ],
        [
            "So requiring initial set of tags when the user is uploading an image.",
            "We ask for initial set of tasks, usually two or three words, which generally describe the image.",
            "We don't want to specific initial tags because.",
            "Since we use them for retrieving relevant photos, we have to have a lot of relevant photos and.",
            "That's in the next step.",
            "We use these initial tags to retrieve relevant photos."
        ],
        [
            "From Flickr we define a relevant photo as a photo that contains all of the initial tags obtained from the user.",
            "We also again retrieve their corresponding tags and use them to form the unique set of tags which become the candidate.",
            "Tags.",
            "Um?",
            "Now we have to assign weights to the."
        ],
        [
            "Tags we use both visual and textual information.",
            "In this process, we, as the frequency of usage of each tag, represents the textual information available, but we don't base our weight computation only on this because A tag might be used often, but that doesn't necessarily mean it would be relevant to our image.",
            "So we also look at the visual similarity."
        ],
        [
            "Um?",
            "To compute the visual similarity between a given relevant image I and our target image, we use the following Formula One over the distance of visual features of the target image and the visual features of the considered relevant image.",
            "We have evaluated two different visual features here.",
            "Color histograms and interest points for color histograms.",
            "We consider two alternatives, RGB and HSV.",
            "In our experiments, we saw that HSV.",
            "Performed slightly better, so we decided to use HSV for interest points.",
            "We used Lowe's sift descriptors.",
            "And since we have two different visual features, we have two different dysfunctions for color.",
            "Histograms were using a comedian distance and for interest points we're using the matching algorithm of low and the distance is represented by the total number of matching points between the images.",
            "So after computing the visual similarity, we."
        ],
        [
            "Have to compute weight for each tag in order to do this, we formed this binary matrix on the left, where each row represents the relevant image, and each column represents A tag and for example, if tattoos present in the list of image two, we put a one there.",
            "If it's not present in the list of image one, we put a 0.",
            "So that's how we fill the binary matrix, and then we multiply each row with the visual similarity we computed.",
            "As I said in the last slide and we sum all of the.",
            "All of these values column wise, so in the end we get a capital W vector which contains weights for each of our unique tags and in our last step we sort these."
        ],
        [
            "Weights and so just tags with higher weights.",
            "A careful observer might notice some problems with the tags we have suggested.",
            "There I will address the issues in the following slides.",
            "All in."
        ],
        [
            "Implementation we implemented tax adjuster in Java using the Flickr J, July Apio Flickr.",
            "We selected 100 photos from Flickr as target for our target set, but we had to eliminate some of them because they did not have.",
            "They had two descriptive tags or not enough number of tags with them.",
            "So in the end we had 66 target photos taken for from Flickr.",
            "We also had a restriction.",
            "For the relevant photos, we retrieve for each target image, we restricted the number to 100 for practical reasons.",
            "In the end we have process approximately 7000 images.",
            "Um?",
            "So since we're using them to retrieve our relevant images, the."
        ],
        [
            "Initial tags are really important for our system.",
            "The we need initial tags which are not too specific so that we don't have.",
            "Less number of relevant photos, so less number of tags to choose from and we don't want two general initial tags so that we don't have huge.",
            "We don't have a huge set to work on.",
            "There are two properties that affect the quality of initial tax.",
            "The first one is of course the tags themselves.",
            "On the second one is the number of initial tags were using.",
            "So since we cannot, we cannot restrict the user from choosing whatever tags that they want.",
            "We decided to.",
            "Look for the optimal number of initial ties we should be using for our experiments and we from our analysis we found that two and three tags are optimal for us.",
            "Here you see a table which has the average number of relevant photos retrieved per given initial number of tags.",
            "As you can see, for four and five we have only 14 and four images retrieved wild for only one initial tag.",
            "We get more than 500,000 images.",
            "So the two 3 range is good for us, but these are average values so they change per each for each image.",
            "Another important question is how do we decide if a suggested tag is valid?",
            "Well, since this is a very subjective question, finding an automatic evaluation was not easy.",
            "We decided to use already existing photos and their corresponding tags from Flickr.",
            "So what we did was we took a photo from Flickr and."
        ],
        [
            "Its corresponding tags as the target photo and we manually picked initial tags from its tag list and we checked to see how many of our suggested tags were actually appearing in the original tag list of a photo.",
            "For statistical value."
        ],
        [
            "And we computed precision recall values and accuracy.",
            "We defined accuracy of the.",
            "Accuracy for given target image I I as total number of tags.",
            "That appeared both in our suggested lists and the original list divided by the total number of suggested tax we had, and we also computed and overall accuracy by taking the average of all of the accuracies.",
            "We have evaluated three approaches.",
            "These were attack frequency, color similarity and so similarity by tag frequency I mean.",
            "The tax frequency represented the only texts.",
            "Based approach for suggesting tax.",
            "So that was our baseline.",
            "We performed two experiments to analyze our results.",
            "These were suggests all tags and suggests top five in suggests all tags.",
            "We suggested as many tags as were present in our.",
            "Originalists here you see a precision."
        ],
        [
            "Versus recall."
        ],
        [
            "Apps for the given images using suggests."
        ],
        [
            "All tax experiment for all of these three images we see that color.",
            "As you can see, Gray represents color histograms, black represent sift and dashed represents the frequency based method for all of these three images, color fi similarity shows a higher performance.",
            "Because the colors are very discriminative in these."
        ],
        [
            "Pictures for these three images.",
            "For the first one again, we have color similarity having a higher performance for the other two.",
            "Sift descriptors seem to be slightly better than the other two."
        ],
        [
            "Kids.",
            "And in in these last two experiment images.",
            "All approaches sort of show similar low performance.",
            "We would actually expect to have sift with a higher performance in Sift.",
            "Descriptors are good for recognizing objects, but these images are cluttered with objects so that that is why the performance is not too high."
        ],
        [
            "I.",
            "For these images I will show you the accuracy."
        ],
        [
            "Charts, so here are the darkest color represent stackers frequency while the light is a similarity in the middle one is color similarity in most of the images we see that tag frequency and color frequency are approximately at the same level only on if F&G we see that tag frequency is slightly better but for the remaining images we have.",
            "Improved our performance using visual features."
        ],
        [
            "For such a stop five, we suggested only the top five.",
            "Tags from our tag lists and disappear."
        ],
        [
            "And our performance again, we have the same list of.",
            "Um?"
        ],
        [
            "Images and.",
            "We have we have higher results here, but again color and tag frequency performances are us.",
            "Close to each other, but we have significantly higher sift.",
            "Results in CEGJ&O&G.",
            "None of the tags.",
            "Suggested by the tag frequency and the color similarity method were actually in the original list, so that's why it's a zero there and."
        ],
        [
            "Here we have.",
            "We also computed the overall accuracies for all of the.",
            "Approaches, as you can see, color similarity is slightly better than attack frequency, which shows that visual similarity information improves.",
            "The results and similarity is considerably lower because our data set will small, but I will talk about that in a few slides and since it is a specific descriptor for specific feature for some specific photos we did not have, I believe that we did not have any enough examples for them."
        ],
        [
            "So to discuss.",
            "Our results were.",
            "Not.",
            "Our performance was not too high for several reasons.",
            "First of all, selecting a ground truth for such a system is not easy here.",
            "We accepted user given tags as ground truth, but we know that these tags are noisy and usually incomplete.",
            "We have seen numerous examples where our system suggested tags that were actually relevant to the image, but since they were not present in the original tag, lists are statistical performance seemed to be low.",
            "Um?",
            "Also, our experiments were highly data dependent and we did not have a test set that was sufficiently large.",
            "Reason for this was because we had to collect our data, set ourselves and our objective list have randomly selected images that had sufficient number of tags and relevant tags and this was not easy considering the fact that more than 50% of flickers photos contain 23 tags only.",
            "And this selection had to be done manually, which slowed our process."
        ],
        [
            "So as a future work, we plan on collecting a larger data set to reduce data dependencies and also we have used basic visual features.",
            "At this stage.",
            "We plan on improving them by trying different visual features or using combinations of visual features.",
            "We also think that user studies are really important for the evaluation process.",
            "We actually made a small user study for the current version, but because of the smallest of our data set are the results were not to meaningful.",
            "But we believe that if we have a larger data set and we do an extensive user study, the results of user study would be can be used as ground truth and would be more reliable.",
            "Am I going early?",
            "I think I went really fast."
        ],
        [
            "I will show a demonstration."
        ],
        [
            "This is how our system looks like so.",
            "We upload."
        ],
        [
            "The image from here then we see the image showing and then we add the initial tags and as I said we restricted the number of relevant photos.",
            "We retrieved 200 and I selected HSV color.",
            "So grams for this.",
            "So to retrieve annotations we click on this button and then."
        ],
        [
            "Below we see some of the retrieved relevant photos plus the photo we are actually working on.",
            "We put."
        ],
        [
            "This here so that we can see the original tag lists.",
            "And here is the suggest tag lists with all of the weights shown there sorted.",
            "They do include.",
            "Irrelevant tags, but that's because users are seriously using a lot of irrelevant tags while they're tagging their photos so.",
            "But in any case, we let the user choose from these tags, they're not automatically assigned to the image, so when we choose the relevant ones, you see that we have food, light home, green wine, yellow and cooking, and some of which are not actually present in the.",
            "Original tag lists of the photo, so this is sort of helping the user and improving results."
        ],
        [
            "To conclude.",
            "This was only.",
            "We used naive approach and to prove the concept that visual similarity helps tag expansion.",
            "That's why our results are not very significant, but we plan on improving them as our future work.",
            "Thank you for listening.",
            "If you have any questions.",
            "Yes."
        ],
        [
            "Noise.",
            "Using.",
            "Are you going to realistically?",
            "I don't have any examples with me right now, but we can actually see some of them.",
            "Here maybe on this exam."
        ],
        [
            "People.",
            "For example, for our image, the original tags include HDR, which is, I think something related to.",
            "The picture is a picture of kitchen.",
            "There are some colorful cups and a glass bottle of wine, so that's what the images and it has tags like big Phase I don't know what that means.",
            "A big phase, which is another irrelevant one.",
            "EMMEDIBI 33, which I don't know what that is either, so we have.",
            "But for this example, let me let me show you this example."
        ],
        [
            "It's not relevant to the content when you're since."
        ],
        [
            "So what was our objective when we're doing search?",
            "We use text.",
            "The websites use text based approaches, so they rely on the tags while they're browsing and searching through the images.",
            "So if you have if you don't have tags that are describing the content of the image, this operation will be bad.",
            "So our objective is to suggest tags that are relevant to the contents of the image.",
            "Of course I mean it will be.",
            "Having tags that describe the camera Krstic characteristics might be relevant for some users, but it's not relevant for the search operation.",
            "It seems to me that you assume this tag is relevant only if it's refers to something which is visually appealing.",
            "Indeed, not, not necessarily, but our objective is to.",
            "So just tags that are.",
            "Referring to the content, but we don't have that assumption.",
            "For example.",
            "At the time we tend to use is, for example the name of events where the picture is being taken and that is not something visually.",
            "But you can observe Vision Image, but there's something useful way because it allows him to remember why you're taking this picture, but the location, if it's pictures that are taking the same location, will look similar.",
            "So we will.",
            "We will also suggest that tag to the user since they are visually similar, so we're including your example to our approach if I can.",
            "So this question.",
            "Delicious banging the children think they claim that if you pick from the authors past tags, you always be better than picking whatever suggested.",
            "Bristles now in Flickr.",
            "Everybody takes their own image, yes.",
            "I guess you didn't.",
            "No.",
            "That might be that might work actually, because users tend to.",
            "For example, if a person is traveling a lot, they have similar pictures, so you can actually group among them.",
            "So suggesting tags that they have used before might be relevant, but Flickr doesn't.",
            "Has a blind tagging process so they don't use a person.",
            "Cannot see tags of other images while they're tagging, so that's why we not focus on that aspect.",
            "Yeah they can always, but but it's it's not part of the tagging process.",
            "I mean, it's not meant they're not meant to see tags of other images.",
            "They can always browse and check.",
            "But when they're tagging, they don't necessarily.",
            "Really fast.",
            "Any other questions before?",
            "That's something that I forgot.",
            "I think you are penalizing yourself a lot by assuming.",
            "But taking only the types of over the bear on the image is ground truth, yes.",
            "Obviously because a lot of things that I can think of would apply to this image, but they're not necessarily yes.",
            "The.",
            "The other way to say if anything is even marginally relevant to the photo is accepted in my group as well.",
            "It's also problematic do you think, by the ways I missed some part of your question?",
            "Actually go and say look at all that I suggested we side after this addition whether or not they are relevant image, but that's also tricky because this rapid settlement of events that we could be something around it and they don't really need to understand.",
            "We are actually sort of.",
            "I went really fast, so I probably did not explain it very well.",
            "We plan on using the user studies and the results of user studies as ground truth, so we plan on giving the.",
            "We actually did this, but as I said, results were not meaningful.",
            "We plan on giving the list of candidate at all of all of the list of all tags within the Candidate Tag list to the user to a user so that he or she can decide which one would relate to the image.",
            "So we will take that as ground truth, which will be well, it will still be limited if there are not words there.",
            "If there are missing words in the candidate tag list, but at least we will be able to see.",
            "Our performance in a better way.",
            "Settings or in a real in the experimental settings know this.",
            "This is actually for checking our performance, so for statistical measurements, but I mean we had examples I did not put them here, but there was this picture taken and taken in London and none of its original tags contained.",
            "Night Lights or night Sky.",
            "But because of the visual similarity we picked up that tag, so we are seeing these.",
            "Results, but we cannot statistically say that, OK, we're better because.",
            "What we're comparing to is, not.",
            "Necessarily relevant to the image.",
            "Content.",
            "Convention.",
            "What what do I mean by incomplete swell?",
            "Since our focus is to."
        ],
        [
            "Have tags that are well.",
            "It's impossible to describe an image with limited set of words, so the tags will always be incomplete in the sense that they are not describing the image properly.",
            "So wrong.",
            "Don't have that address or long wanted suggested.",
            "You can find it in taxes, gold or anything.",
            "Schedule.",
            "Alright, thank you, sorry."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hello, I'm here on behalf of my project group I will be presenting tax suggest Sir to you as you all know with the growth in number of various web applications on the new trend of sharing publishing digital media on the web, we have millions of photos available on the Internet.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately, due to the flexibility of the environment, it's hard to organize and retrieve these.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It is.",
                    "label": 0
                },
                {
                    "sent": "To solve this problem, photo sharing websites have been established.",
                    "label": 0
                },
                {
                    "sent": "They provide.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Functionality is including tagging, browsing.",
                    "label": 0
                },
                {
                    "sent": "Here is a list subset of a list presented in Wikipedia.",
                    "label": 0
                },
                {
                    "sent": "These are some of the most widely used photo sharing websites throughout the world, and although I do not know the details of their internal source structure, they organize their photos with respect to the users to upload them, and they are browsing and searching.",
                    "label": 0
                },
                {
                    "sent": "Algorithms are text based.",
                    "label": 0
                },
                {
                    "sent": "Why are they using text based approaches?",
                    "label": 0
                },
                {
                    "sent": "Because it's easier to implement and.",
                    "label": 0
                },
                {
                    "sent": "Claim to be more efficient as opposed to content based image retrieval methods, but despite their wide usage it would not be truthful to say that these photo sharing websites solves the organizational problems we have because text based approaches are not sufficient, we have chosen to implement our tax adjuster on Flickr.",
                    "label": 0
                },
                {
                    "sent": "There was no specific reason Tech Flickr is a famous popular website and it has a nice API so but.",
                    "label": 0
                },
                {
                    "sent": "The method we're proposing is applicable to any other photo sharing website, including tagging functionality.",
                    "label": 0
                },
                {
                    "sent": "Here you see a picture that is available on Flickr and it's crisp.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Turning tides listed on the right.",
                    "label": 0
                },
                {
                    "sent": "As you can see, these types are not specifically describing the content of the picture.",
                    "label": 0
                },
                {
                    "sent": "It includes tags that are describing the camera curse characteristics and.",
                    "label": 0
                },
                {
                    "sent": "Which is not really relevant to the content of the image itself.",
                    "label": 0
                },
                {
                    "sent": "They also have irrelevant tags like forest for example.",
                    "label": 0
                },
                {
                    "sent": "OK, we do see trees in this picture, but this is not really a picture of forest and we have tag son.",
                    "label": 0
                },
                {
                    "sent": "We don't see the sun itself, we see sunlight, so that's not very relevant, so it doesn't have any tags explaining the garden or the house.",
                    "label": 0
                },
                {
                    "sent": "So what we see here is that tags are noisy Ann.",
                    "label": 0
                },
                {
                    "sent": "They are not complete, so if we're searching for this image, the question is, are these tags really helping us?",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what we propose is a tax adjuster system that suggests tags at upload time.",
                    "label": 1
                },
                {
                    "sent": "The purpose is to assist users in order to ease the process of tagging.",
                    "label": 1
                },
                {
                    "sent": "Since users are willing to tag, but they're not necessarily there.",
                    "label": 0
                },
                {
                    "sent": "Really lazy in doing this, and another purpose is to reduce noise and tags and provide more descriptive and meaningful tags.",
                    "label": 0
                },
                {
                    "sent": "Our approach has four main steps, as you can see in the figure.",
                    "label": 0
                },
                {
                    "sent": "First, one user is uploading.",
                    "label": 0
                },
                {
                    "sent": "The image we require them to end.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For some initial tags we use these tags to retrieve photos that we might we think that might be relevant to our target photo.",
                    "label": 0
                },
                {
                    "sent": "We also retrieve their corresponding set of Tizen for unique set of tags from which we will choose our suggested tags.",
                    "label": 0
                },
                {
                    "sent": "Then we compute weights for these tags using visual similarities and sort the tags according to their weights and suggests high strength once to the user.",
                    "label": 1
                },
                {
                    "sent": "Now I will explain the steps in further detail.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So requiring initial set of tags when the user is uploading an image.",
                    "label": 1
                },
                {
                    "sent": "We ask for initial set of tasks, usually two or three words, which generally describe the image.",
                    "label": 1
                },
                {
                    "sent": "We don't want to specific initial tags because.",
                    "label": 0
                },
                {
                    "sent": "Since we use them for retrieving relevant photos, we have to have a lot of relevant photos and.",
                    "label": 0
                },
                {
                    "sent": "That's in the next step.",
                    "label": 0
                },
                {
                    "sent": "We use these initial tags to retrieve relevant photos.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "From Flickr we define a relevant photo as a photo that contains all of the initial tags obtained from the user.",
                    "label": 0
                },
                {
                    "sent": "We also again retrieve their corresponding tags and use them to form the unique set of tags which become the candidate.",
                    "label": 1
                },
                {
                    "sent": "Tags.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Now we have to assign weights to the.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Tags we use both visual and textual information.",
                    "label": 0
                },
                {
                    "sent": "In this process, we, as the frequency of usage of each tag, represents the textual information available, but we don't base our weight computation only on this because A tag might be used often, but that doesn't necessarily mean it would be relevant to our image.",
                    "label": 0
                },
                {
                    "sent": "So we also look at the visual similarity.",
                    "label": 1
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "To compute the visual similarity between a given relevant image I and our target image, we use the following Formula One over the distance of visual features of the target image and the visual features of the considered relevant image.",
                    "label": 0
                },
                {
                    "sent": "We have evaluated two different visual features here.",
                    "label": 1
                },
                {
                    "sent": "Color histograms and interest points for color histograms.",
                    "label": 1
                },
                {
                    "sent": "We consider two alternatives, RGB and HSV.",
                    "label": 0
                },
                {
                    "sent": "In our experiments, we saw that HSV.",
                    "label": 0
                },
                {
                    "sent": "Performed slightly better, so we decided to use HSV for interest points.",
                    "label": 0
                },
                {
                    "sent": "We used Lowe's sift descriptors.",
                    "label": 0
                },
                {
                    "sent": "And since we have two different visual features, we have two different dysfunctions for color.",
                    "label": 0
                },
                {
                    "sent": "Histograms were using a comedian distance and for interest points we're using the matching algorithm of low and the distance is represented by the total number of matching points between the images.",
                    "label": 1
                },
                {
                    "sent": "So after computing the visual similarity, we.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Have to compute weight for each tag in order to do this, we formed this binary matrix on the left, where each row represents the relevant image, and each column represents A tag and for example, if tattoos present in the list of image two, we put a one there.",
                    "label": 0
                },
                {
                    "sent": "If it's not present in the list of image one, we put a 0.",
                    "label": 0
                },
                {
                    "sent": "So that's how we fill the binary matrix, and then we multiply each row with the visual similarity we computed.",
                    "label": 0
                },
                {
                    "sent": "As I said in the last slide and we sum all of the.",
                    "label": 0
                },
                {
                    "sent": "All of these values column wise, so in the end we get a capital W vector which contains weights for each of our unique tags and in our last step we sort these.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Weights and so just tags with higher weights.",
                    "label": 1
                },
                {
                    "sent": "A careful observer might notice some problems with the tags we have suggested.",
                    "label": 0
                },
                {
                    "sent": "There I will address the issues in the following slides.",
                    "label": 0
                },
                {
                    "sent": "All in.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Implementation we implemented tax adjuster in Java using the Flickr J, July Apio Flickr.",
                    "label": 0
                },
                {
                    "sent": "We selected 100 photos from Flickr as target for our target set, but we had to eliminate some of them because they did not have.",
                    "label": 0
                },
                {
                    "sent": "They had two descriptive tags or not enough number of tags with them.",
                    "label": 0
                },
                {
                    "sent": "So in the end we had 66 target photos taken for from Flickr.",
                    "label": 1
                },
                {
                    "sent": "We also had a restriction.",
                    "label": 1
                },
                {
                    "sent": "For the relevant photos, we retrieve for each target image, we restricted the number to 100 for practical reasons.",
                    "label": 1
                },
                {
                    "sent": "In the end we have process approximately 7000 images.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So since we're using them to retrieve our relevant images, the.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Initial tags are really important for our system.",
                    "label": 0
                },
                {
                    "sent": "The we need initial tags which are not too specific so that we don't have.",
                    "label": 0
                },
                {
                    "sent": "Less number of relevant photos, so less number of tags to choose from and we don't want two general initial tags so that we don't have huge.",
                    "label": 0
                },
                {
                    "sent": "We don't have a huge set to work on.",
                    "label": 0
                },
                {
                    "sent": "There are two properties that affect the quality of initial tax.",
                    "label": 0
                },
                {
                    "sent": "The first one is of course the tags themselves.",
                    "label": 0
                },
                {
                    "sent": "On the second one is the number of initial tags were using.",
                    "label": 1
                },
                {
                    "sent": "So since we cannot, we cannot restrict the user from choosing whatever tags that they want.",
                    "label": 0
                },
                {
                    "sent": "We decided to.",
                    "label": 0
                },
                {
                    "sent": "Look for the optimal number of initial ties we should be using for our experiments and we from our analysis we found that two and three tags are optimal for us.",
                    "label": 0
                },
                {
                    "sent": "Here you see a table which has the average number of relevant photos retrieved per given initial number of tags.",
                    "label": 0
                },
                {
                    "sent": "As you can see, for four and five we have only 14 and four images retrieved wild for only one initial tag.",
                    "label": 0
                },
                {
                    "sent": "We get more than 500,000 images.",
                    "label": 0
                },
                {
                    "sent": "So the two 3 range is good for us, but these are average values so they change per each for each image.",
                    "label": 0
                },
                {
                    "sent": "Another important question is how do we decide if a suggested tag is valid?",
                    "label": 0
                },
                {
                    "sent": "Well, since this is a very subjective question, finding an automatic evaluation was not easy.",
                    "label": 0
                },
                {
                    "sent": "We decided to use already existing photos and their corresponding tags from Flickr.",
                    "label": 0
                },
                {
                    "sent": "So what we did was we took a photo from Flickr and.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Its corresponding tags as the target photo and we manually picked initial tags from its tag list and we checked to see how many of our suggested tags were actually appearing in the original tag list of a photo.",
                    "label": 0
                },
                {
                    "sent": "For statistical value.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we computed precision recall values and accuracy.",
                    "label": 1
                },
                {
                    "sent": "We defined accuracy of the.",
                    "label": 0
                },
                {
                    "sent": "Accuracy for given target image I I as total number of tags.",
                    "label": 0
                },
                {
                    "sent": "That appeared both in our suggested lists and the original list divided by the total number of suggested tax we had, and we also computed and overall accuracy by taking the average of all of the accuracies.",
                    "label": 0
                },
                {
                    "sent": "We have evaluated three approaches.",
                    "label": 1
                },
                {
                    "sent": "These were attack frequency, color similarity and so similarity by tag frequency I mean.",
                    "label": 0
                },
                {
                    "sent": "The tax frequency represented the only texts.",
                    "label": 0
                },
                {
                    "sent": "Based approach for suggesting tax.",
                    "label": 0
                },
                {
                    "sent": "So that was our baseline.",
                    "label": 0
                },
                {
                    "sent": "We performed two experiments to analyze our results.",
                    "label": 0
                },
                {
                    "sent": "These were suggests all tags and suggests top five in suggests all tags.",
                    "label": 0
                },
                {
                    "sent": "We suggested as many tags as were present in our.",
                    "label": 0
                },
                {
                    "sent": "Originalists here you see a precision.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Versus recall.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Apps for the given images using suggests.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "All tax experiment for all of these three images we see that color.",
                    "label": 0
                },
                {
                    "sent": "As you can see, Gray represents color histograms, black represent sift and dashed represents the frequency based method for all of these three images, color fi similarity shows a higher performance.",
                    "label": 0
                },
                {
                    "sent": "Because the colors are very discriminative in these.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Pictures for these three images.",
                    "label": 0
                },
                {
                    "sent": "For the first one again, we have color similarity having a higher performance for the other two.",
                    "label": 0
                },
                {
                    "sent": "Sift descriptors seem to be slightly better than the other two.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Kids.",
                    "label": 0
                },
                {
                    "sent": "And in in these last two experiment images.",
                    "label": 0
                },
                {
                    "sent": "All approaches sort of show similar low performance.",
                    "label": 0
                },
                {
                    "sent": "We would actually expect to have sift with a higher performance in Sift.",
                    "label": 0
                },
                {
                    "sent": "Descriptors are good for recognizing objects, but these images are cluttered with objects so that that is why the performance is not too high.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I.",
                    "label": 0
                },
                {
                    "sent": "For these images I will show you the accuracy.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Charts, so here are the darkest color represent stackers frequency while the light is a similarity in the middle one is color similarity in most of the images we see that tag frequency and color frequency are approximately at the same level only on if F&G we see that tag frequency is slightly better but for the remaining images we have.",
                    "label": 0
                },
                {
                    "sent": "Improved our performance using visual features.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For such a stop five, we suggested only the top five.",
                    "label": 0
                },
                {
                    "sent": "Tags from our tag lists and disappear.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And our performance again, we have the same list of.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Images and.",
                    "label": 0
                },
                {
                    "sent": "We have we have higher results here, but again color and tag frequency performances are us.",
                    "label": 0
                },
                {
                    "sent": "Close to each other, but we have significantly higher sift.",
                    "label": 0
                },
                {
                    "sent": "Results in CEGJ&O&G.",
                    "label": 0
                },
                {
                    "sent": "None of the tags.",
                    "label": 0
                },
                {
                    "sent": "Suggested by the tag frequency and the color similarity method were actually in the original list, so that's why it's a zero there and.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here we have.",
                    "label": 0
                },
                {
                    "sent": "We also computed the overall accuracies for all of the.",
                    "label": 0
                },
                {
                    "sent": "Approaches, as you can see, color similarity is slightly better than attack frequency, which shows that visual similarity information improves.",
                    "label": 0
                },
                {
                    "sent": "The results and similarity is considerably lower because our data set will small, but I will talk about that in a few slides and since it is a specific descriptor for specific feature for some specific photos we did not have, I believe that we did not have any enough examples for them.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to discuss.",
                    "label": 0
                },
                {
                    "sent": "Our results were.",
                    "label": 0
                },
                {
                    "sent": "Not.",
                    "label": 0
                },
                {
                    "sent": "Our performance was not too high for several reasons.",
                    "label": 0
                },
                {
                    "sent": "First of all, selecting a ground truth for such a system is not easy here.",
                    "label": 1
                },
                {
                    "sent": "We accepted user given tags as ground truth, but we know that these tags are noisy and usually incomplete.",
                    "label": 0
                },
                {
                    "sent": "We have seen numerous examples where our system suggested tags that were actually relevant to the image, but since they were not present in the original tag, lists are statistical performance seemed to be low.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Also, our experiments were highly data dependent and we did not have a test set that was sufficiently large.",
                    "label": 0
                },
                {
                    "sent": "Reason for this was because we had to collect our data, set ourselves and our objective list have randomly selected images that had sufficient number of tags and relevant tags and this was not easy considering the fact that more than 50% of flickers photos contain 23 tags only.",
                    "label": 0
                },
                {
                    "sent": "And this selection had to be done manually, which slowed our process.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So as a future work, we plan on collecting a larger data set to reduce data dependencies and also we have used basic visual features.",
                    "label": 0
                },
                {
                    "sent": "At this stage.",
                    "label": 0
                },
                {
                    "sent": "We plan on improving them by trying different visual features or using combinations of visual features.",
                    "label": 1
                },
                {
                    "sent": "We also think that user studies are really important for the evaluation process.",
                    "label": 0
                },
                {
                    "sent": "We actually made a small user study for the current version, but because of the smallest of our data set are the results were not to meaningful.",
                    "label": 0
                },
                {
                    "sent": "But we believe that if we have a larger data set and we do an extensive user study, the results of user study would be can be used as ground truth and would be more reliable.",
                    "label": 0
                },
                {
                    "sent": "Am I going early?",
                    "label": 0
                },
                {
                    "sent": "I think I went really fast.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I will show a demonstration.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is how our system looks like so.",
                    "label": 0
                },
                {
                    "sent": "We upload.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The image from here then we see the image showing and then we add the initial tags and as I said we restricted the number of relevant photos.",
                    "label": 0
                },
                {
                    "sent": "We retrieved 200 and I selected HSV color.",
                    "label": 0
                },
                {
                    "sent": "So grams for this.",
                    "label": 0
                },
                {
                    "sent": "So to retrieve annotations we click on this button and then.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Below we see some of the retrieved relevant photos plus the photo we are actually working on.",
                    "label": 0
                },
                {
                    "sent": "We put.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This here so that we can see the original tag lists.",
                    "label": 0
                },
                {
                    "sent": "And here is the suggest tag lists with all of the weights shown there sorted.",
                    "label": 0
                },
                {
                    "sent": "They do include.",
                    "label": 0
                },
                {
                    "sent": "Irrelevant tags, but that's because users are seriously using a lot of irrelevant tags while they're tagging their photos so.",
                    "label": 0
                },
                {
                    "sent": "But in any case, we let the user choose from these tags, they're not automatically assigned to the image, so when we choose the relevant ones, you see that we have food, light home, green wine, yellow and cooking, and some of which are not actually present in the.",
                    "label": 0
                },
                {
                    "sent": "Original tag lists of the photo, so this is sort of helping the user and improving results.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To conclude.",
                    "label": 0
                },
                {
                    "sent": "This was only.",
                    "label": 0
                },
                {
                    "sent": "We used naive approach and to prove the concept that visual similarity helps tag expansion.",
                    "label": 0
                },
                {
                    "sent": "That's why our results are not very significant, but we plan on improving them as our future work.",
                    "label": 0
                },
                {
                    "sent": "Thank you for listening.",
                    "label": 0
                },
                {
                    "sent": "If you have any questions.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Noise.",
                    "label": 0
                },
                {
                    "sent": "Using.",
                    "label": 0
                },
                {
                    "sent": "Are you going to realistically?",
                    "label": 0
                },
                {
                    "sent": "I don't have any examples with me right now, but we can actually see some of them.",
                    "label": 0
                },
                {
                    "sent": "Here maybe on this exam.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "People.",
                    "label": 0
                },
                {
                    "sent": "For example, for our image, the original tags include HDR, which is, I think something related to.",
                    "label": 0
                },
                {
                    "sent": "The picture is a picture of kitchen.",
                    "label": 0
                },
                {
                    "sent": "There are some colorful cups and a glass bottle of wine, so that's what the images and it has tags like big Phase I don't know what that means.",
                    "label": 0
                },
                {
                    "sent": "A big phase, which is another irrelevant one.",
                    "label": 0
                },
                {
                    "sent": "EMMEDIBI 33, which I don't know what that is either, so we have.",
                    "label": 0
                },
                {
                    "sent": "But for this example, let me let me show you this example.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's not relevant to the content when you're since.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what was our objective when we're doing search?",
                    "label": 0
                },
                {
                    "sent": "We use text.",
                    "label": 0
                },
                {
                    "sent": "The websites use text based approaches, so they rely on the tags while they're browsing and searching through the images.",
                    "label": 0
                },
                {
                    "sent": "So if you have if you don't have tags that are describing the content of the image, this operation will be bad.",
                    "label": 0
                },
                {
                    "sent": "So our objective is to suggest tags that are relevant to the contents of the image.",
                    "label": 0
                },
                {
                    "sent": "Of course I mean it will be.",
                    "label": 0
                },
                {
                    "sent": "Having tags that describe the camera Krstic characteristics might be relevant for some users, but it's not relevant for the search operation.",
                    "label": 0
                },
                {
                    "sent": "It seems to me that you assume this tag is relevant only if it's refers to something which is visually appealing.",
                    "label": 0
                },
                {
                    "sent": "Indeed, not, not necessarily, but our objective is to.",
                    "label": 0
                },
                {
                    "sent": "So just tags that are.",
                    "label": 0
                },
                {
                    "sent": "Referring to the content, but we don't have that assumption.",
                    "label": 0
                },
                {
                    "sent": "For example.",
                    "label": 0
                },
                {
                    "sent": "At the time we tend to use is, for example the name of events where the picture is being taken and that is not something visually.",
                    "label": 0
                },
                {
                    "sent": "But you can observe Vision Image, but there's something useful way because it allows him to remember why you're taking this picture, but the location, if it's pictures that are taking the same location, will look similar.",
                    "label": 0
                },
                {
                    "sent": "So we will.",
                    "label": 0
                },
                {
                    "sent": "We will also suggest that tag to the user since they are visually similar, so we're including your example to our approach if I can.",
                    "label": 0
                },
                {
                    "sent": "So this question.",
                    "label": 0
                },
                {
                    "sent": "Delicious banging the children think they claim that if you pick from the authors past tags, you always be better than picking whatever suggested.",
                    "label": 0
                },
                {
                    "sent": "Bristles now in Flickr.",
                    "label": 0
                },
                {
                    "sent": "Everybody takes their own image, yes.",
                    "label": 0
                },
                {
                    "sent": "I guess you didn't.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "That might be that might work actually, because users tend to.",
                    "label": 0
                },
                {
                    "sent": "For example, if a person is traveling a lot, they have similar pictures, so you can actually group among them.",
                    "label": 0
                },
                {
                    "sent": "So suggesting tags that they have used before might be relevant, but Flickr doesn't.",
                    "label": 0
                },
                {
                    "sent": "Has a blind tagging process so they don't use a person.",
                    "label": 0
                },
                {
                    "sent": "Cannot see tags of other images while they're tagging, so that's why we not focus on that aspect.",
                    "label": 0
                },
                {
                    "sent": "Yeah they can always, but but it's it's not part of the tagging process.",
                    "label": 0
                },
                {
                    "sent": "I mean, it's not meant they're not meant to see tags of other images.",
                    "label": 0
                },
                {
                    "sent": "They can always browse and check.",
                    "label": 0
                },
                {
                    "sent": "But when they're tagging, they don't necessarily.",
                    "label": 0
                },
                {
                    "sent": "Really fast.",
                    "label": 0
                },
                {
                    "sent": "Any other questions before?",
                    "label": 0
                },
                {
                    "sent": "That's something that I forgot.",
                    "label": 0
                },
                {
                    "sent": "I think you are penalizing yourself a lot by assuming.",
                    "label": 0
                },
                {
                    "sent": "But taking only the types of over the bear on the image is ground truth, yes.",
                    "label": 0
                },
                {
                    "sent": "Obviously because a lot of things that I can think of would apply to this image, but they're not necessarily yes.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "The other way to say if anything is even marginally relevant to the photo is accepted in my group as well.",
                    "label": 0
                },
                {
                    "sent": "It's also problematic do you think, by the ways I missed some part of your question?",
                    "label": 0
                },
                {
                    "sent": "Actually go and say look at all that I suggested we side after this addition whether or not they are relevant image, but that's also tricky because this rapid settlement of events that we could be something around it and they don't really need to understand.",
                    "label": 0
                },
                {
                    "sent": "We are actually sort of.",
                    "label": 0
                },
                {
                    "sent": "I went really fast, so I probably did not explain it very well.",
                    "label": 0
                },
                {
                    "sent": "We plan on using the user studies and the results of user studies as ground truth, so we plan on giving the.",
                    "label": 0
                },
                {
                    "sent": "We actually did this, but as I said, results were not meaningful.",
                    "label": 0
                },
                {
                    "sent": "We plan on giving the list of candidate at all of all of the list of all tags within the Candidate Tag list to the user to a user so that he or she can decide which one would relate to the image.",
                    "label": 0
                },
                {
                    "sent": "So we will take that as ground truth, which will be well, it will still be limited if there are not words there.",
                    "label": 0
                },
                {
                    "sent": "If there are missing words in the candidate tag list, but at least we will be able to see.",
                    "label": 0
                },
                {
                    "sent": "Our performance in a better way.",
                    "label": 0
                },
                {
                    "sent": "Settings or in a real in the experimental settings know this.",
                    "label": 0
                },
                {
                    "sent": "This is actually for checking our performance, so for statistical measurements, but I mean we had examples I did not put them here, but there was this picture taken and taken in London and none of its original tags contained.",
                    "label": 0
                },
                {
                    "sent": "Night Lights or night Sky.",
                    "label": 0
                },
                {
                    "sent": "But because of the visual similarity we picked up that tag, so we are seeing these.",
                    "label": 0
                },
                {
                    "sent": "Results, but we cannot statistically say that, OK, we're better because.",
                    "label": 0
                },
                {
                    "sent": "What we're comparing to is, not.",
                    "label": 0
                },
                {
                    "sent": "Necessarily relevant to the image.",
                    "label": 0
                },
                {
                    "sent": "Content.",
                    "label": 0
                },
                {
                    "sent": "Convention.",
                    "label": 0
                },
                {
                    "sent": "What what do I mean by incomplete swell?",
                    "label": 0
                },
                {
                    "sent": "Since our focus is to.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Have tags that are well.",
                    "label": 0
                },
                {
                    "sent": "It's impossible to describe an image with limited set of words, so the tags will always be incomplete in the sense that they are not describing the image properly.",
                    "label": 0
                },
                {
                    "sent": "So wrong.",
                    "label": 0
                },
                {
                    "sent": "Don't have that address or long wanted suggested.",
                    "label": 0
                },
                {
                    "sent": "You can find it in taxes, gold or anything.",
                    "label": 0
                },
                {
                    "sent": "Schedule.",
                    "label": 0
                },
                {
                    "sent": "Alright, thank you, sorry.",
                    "label": 0
                }
            ]
        }
    }
}