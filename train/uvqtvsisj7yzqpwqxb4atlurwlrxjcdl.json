{
    "id": "uvqtvsisj7yzqpwqxb4atlurwlrxjcdl",
    "title": "Multilingual and Cross-lingual Ontology matching and its Application to Financial Accounting Standards",
    "info": {
        "author": [
            "Laura Hollink, Centrum Wiskunde & Informatica (CWI)"
        ],
        "published": "Nov. 25, 2011",
        "recorded": "October 2011",
        "category": [
            "Top->Computer Science->Semantic Web->OWL - Web Ontology Language",
            "Top->Computer Science->Semantic Web->Ontologies"
        ]
    },
    "url": "http://videolectures.net/iswc2011_hollink_standards/",
    "segmentation": [
        [
            "Great to see you're all still here and awake on this one of the last talks of this conference.",
            "Representing work done by Danish 4 from University of Bielefeld.",
            "Actually, he's the one who deserves more.",
            "Most of the credits.",
            "Philippe Cimiano, also also from University of Bielefeld and myself from Delft University of Technology.",
            "A special case of ontology matching, namely multilingual or cross lingual ontology matching.",
            "So this is the case where you have you're trying to match to ontologies that have either labels in multiple languages or labels in different languages."
        ],
        [
            "So I'll go through our motivation background on the only ontologies that we've used and that we've tested it on on our approach.",
            "Then evaluation and findings and a conclusion."
        ],
        [
            "Our work is motivated by a number of open issues that we've encountered in ontology matching and then specifically in multi lingual ontology matching.",
            "The first is the impact of machine translation, so if you have if you're trying to match to ontologies that have no overlapping languages, you'll have to translate now.",
            "How does this influence the matching process?",
            "So literature simply says?",
            "High-quality machine translation is a prerequisite for good matching.",
            "Well, sure, you can't argue with that, but we want to go a little bit more specific and ask OK, but how important is it?",
            "Are the tools that we have now, so the standard machine translation tools and websites that are available?",
            "Are they good enough?",
            "And also, what is the influence of having multiple languages or translating to multiple languages?",
            "Second, open issue that we saw is the impact of structural information.",
            "So this is something that a lot of people have already noted that structural information is potentially very important for ontology matching, but so we want to see well how does this work in multi lingual matching.",
            "Um?",
            "The third thing that we noticed is that there seems to be a lot of confusion on what multilingual and crossing orthology matching is.",
            "For example, are these two things different or not?",
            "So we want to contribute to sort of a consensus of what these terms mean by giving precise definitions.",
            "And finally we want to study the the the problem of real multi lingual ontology matching in the sense that you have to aggregate similarity between labels in different languages."
        ],
        [
            "OK, now something about the specific ontologies that we have."
        ],
        [
            "Mean.",
            "Working with their their sort of a specific kind, namely financial accounting standards.",
            "Which are ontologies used by?",
            "Well, each country, at least in Europe that prescribe how companies should report their finances.",
            "The problem is that different jurisdictions or different countries have different standards, so there is an interoperability problem there.",
            "A lot of these standards are in several languages, so you can think of countries that have more than one official language, then these standards will exist in several languages and obviously standards, each standard in each language is, well, it can be in a different language, so the Dutch standard is in touch.",
            "the German standard is in German.",
            "Another thing an important for us and you, at least for our test, is that some manual mappings between all these different financial standards exist.",
            "All in all, this is a very good use case for us to study multi lingual ontology alignment."
        ],
        [
            "Now there is a working group called the XBRL Europe Business Registers Working Group that aims at interoperability of these financial standards and they are now in the process of creating a taxonomy sort of a Europe, European wide taxonomy of core financial concepts and they are manually mapping each local or each national financial standard to this core taxonomy.",
            "So these manual mappings that they made will be the input to our machine learning approach.",
            "I should say a few things about that.",
            "The concepts in these taxonomies are very complex so they can be.",
            "Financial statements that are defined as a calculation over over other financial concepts so there could be a concept asset which is the sum of the current assets in a non current assets.",
            "These kinds of definitions.",
            "And the matching function that they made from the different standards to Discord taxonomy is in terms of schools exact match and also scores close match because there is not always a one to one mapping from these different tests."
        ],
        [
            "OK, so as I said we wanted to make clear definitions of create clear definitions of what monolingual, multilingual, and cross lingual ontology matching is.",
            "So here they are.",
            "Monolingual matching is simply matching two ontologies together based on one single language, so they're both in English.",
            "For example, this is the standard case.",
            "Multi lingual Ontology matching is the process of matching to ontologies.",
            "We call them source and target ontologies based on 2 languages that they share.",
            "So both of them have labels in, for example English and in Dutch.",
            "Then finally cross lingual matching is the situation where you want to match to ontologies that do not share any languages.",
            "So you have to translate.",
            "Um?",
            "Now you can do several things.",
            "Of course you can translate the labels of the source Ontology to the language of the target Ontology, which is situation a.",
            "Here you can do the other way round situation B.",
            "Or you could translate the labels in both languages to a third language.",
            "Well, to make things even more complicated, when we're translating, we do not, of course, need to limit ourselves to translate to one language.",
            "So if we have one ontology in English and the other one in French, we could translate them both to German.",
            "But we can also translate them both to Dutch and Italian and.",
            "Any number of languages.",
            "Now if we do that, we end up with a lot of overlapping languages, so we end up in a multi lingual scenario.",
            "So when we're talking about cross lingual matching, we can actually mean cross lingual modeling or cross lingual multilingual matching."
        ],
        [
            "Now, if you think of a multi lingual matching process, that means that each concept in each ontology has different labels as various labels in various languages.",
            "How do you compare these labels to each other, right?",
            "It could be that the two concepts in two different ontologies have two labels that are very similar, but their other labels are very dissimilar.",
            "How do we aggregate these label similarities?",
            "Well, we created definitions for this as well.",
            "First, intralingual aggregation is the strategy that you use to aggregate similarity of labels in one language.",
            "An interlingual aggregation is the similarity strategy that you use to aggregate labels in different languages, and later we will see how we have operationalized or implemented these strategies."
        ],
        [
            "OK, so that's for the background and definitions.",
            "Let me see how.",
            "Now do you approach itself?"
        ],
        [
            "Our approach is based on a ranking support vector machine which is technique that was originally developed to improve search engine quality by looking at logs of user clicks.",
            "And the difference with usual machine learning approaches is that the input is not classes but pairwise preferences.",
            "Now I'll show you in the next slide why this fits really well with the type of input that we have.",
            "But first an example of how this would work or how how this works for search engines.",
            "Assume you have a user that has inputed a query and that gets a ranked list of 10 results from the logs from the click logs we can see where the user clicked.",
            "In this case on result 1, three and five.",
            "Now if we want to learn a ranking function from this for this search engine, the input would be 3 pairwise preferences, namely that result 3 is better than result 2 because the user skipped result 2 in the list.",
            "Result 5 is better than result 4.",
            "Big.",
            "Again, because the user skip result for an result, 5 is better than result 2."
        ],
        [
            "Now if we translate this to ontology matching, it means that what we want to learn a ranking function that ranks matching concepts higher than non matching concepts and also that matches exact matches hired in close matches.",
            "Now This is why if it's this technique fits really well with the type of input that we have, because in these financial accounting standards the training set that we have with the manual mappings that are there are in terms of exact matches in close matches and there is not always an exact match."
        ],
        [
            "So we need it features.",
            "We define 42 features, twenty of which are syntactic, so string based.",
            "We used five of the.",
            "I would say standard string based similarity measures.",
            "So for example variations on Livingstones, edit, Edit distance or.",
            "A bag of words, cosine measure and we combine those with four different interlingual and intralingual aggregation strategies.",
            "I'll show you on the next slide.",
            "On top of that, we had 22 structure based features.",
            "An and these were, if you think about these financial concepts that are complex concepts consisting of well defined as.",
            "Equations or calculations.",
            "Then we looked at things like.",
            "In what place of the calculation does a certain concept appear, or how many elements does a certain concept having it's in its calculation?",
            "You can imagine that if one concept is defined as the sum of two items and another is defined as the sum of five items, it's probably not the same concept.",
            "So this kind of structural similarity measures were used.",
            "We also looked at.",
            "The distance between the labels of the items in the calculations.",
            "So in that sense it was.",
            "I could say some of them were hybrid syntactic Ann structural measures.",
            "In any case, these two led to a vector of similarity measures 42 similarity measures for each pair of concepts in the two ontologies.",
            "The source in the target anthologies."
        ],
        [
            "Yeah, OK, so as promised a quick word on how we operationalized the aggregation functions.",
            "This looks complicated, but it's extremely simple.",
            "We simply said that for intralingual aggregation we take the average of the similarity over all the pairs of labels.",
            "As shown here, or we take the best of the similarity values of all these pairs of labels.",
            "Then for intralingual aggregation we take the average of all the.",
            "Interlingual similarities as shown here or we take the best which is not shown, but it's a similar function."
        ],
        [
            "So to sum, sum it up.",
            "Our approach is we calculate similarity function functions for all combinations of source and target concepts.",
            "We use exact enclosed matches from the XBR to determine a rank of these of these vectors, and then we use this as a training set."
        ],
        [
            "OK."
        ],
        [
            "A word on our training set.",
            "So as I said, we use the manual mappings by the XCB are from this core this core European wide vocabulary to the the local vocabularies.",
            "Because they made a mapping from the core manually made a mapping from the core vocabulary to each local vocabulary we have also derived from that links between the different local vocabularies and use that as a training set as well.",
            "Now we have three, so we have three vocabularies here.",
            "The one is called XBR, so maybe confusing is the same name as the working group, but that's the core vocabulary.",
            "One is called AGB and the other one is ITC.",
            "X ers in English.",
            "AGB in English and German ITC in English, French, German and Italian."
        ],
        [
            "And we tried all kinds of different scenarios, so monolingual matching based only on the English labels.",
            "Multilingual matching on English and German labels, so two overlapping languages, their cross lingual matching, where we.",
            "But we matched English labels to Italian labels, English labels to German labels in Italian labels to English labels, and here we tried both scenarios, so we tried both.",
            "But we need in any cross lingual scenario you need to translate, so we translate it to one common language.",
            "But we also try to translate to several common languages to see if this improves the quality of the matches.",
            "Finally, to test the robustness of the approach, we.",
            "Learn to ranking function on two pairs of.",
            "Vocabularies and then applied it to the third pair to see if it still works.",
            "What we tried this with and without the structural features.",
            "And as an evaluation measure, we used a precision.",
            "So how often is the correct rank, rank, rank, rank?",
            "How often is the correct match ranked at number one?",
            "Or how often is the correct match in the top five or top 10?"
        ],
        [
            "Well, so you can imagine with all these conditions in all these scenarios, we have a lot of results.",
            "This is only a subset of it that I think is most useful now for this presentation.",
            "If you want to look at all the other scenarios.",
            "Please have a look at the paper I'll talk you through it.",
            "So.",
            "If you look at the first column, you see the different scenarios monolingual multilingual cross lingual will translate into one language or to several languages, and then cross lingual, but transfer transferring, so learning on one vocabulary using it for the other.",
            "The second column is the setting, structural or non structural or without, with or without structural features.",
            "And then I show 2 pairs of vocabularies, the third is not shown because it doesn't add any new conclusions to the ones that we can see here.",
            "As you see, there are a few empty cells.",
            "For the multilingual scenario, which is because these two vocabularies do not share more than one language, so there is no multilingual matching there.",
            "There are a few things to note.",
            "One is that.",
            "In all cases, structural matching while using the structural features works better than using no structural features.",
            "The second key second thing to note is that if you look here, I TCC 2 HGB so the final three columns you see that multilingual matching is better than monolingual matching, so it really helps to use all the labels that you have in different languages.",
            "Now if you look at the column before that the XYBRITCC column, we see that for the two cross lingual scenarios.",
            "US translate into multiple languages is better than translating to one language.",
            "So again, even in a cross lingual scenario, multilingual matching is better, works better than monolingual matching.",
            "Let me see yes and a final thing to note is that the cross link the transfer scenario works quite well actually.",
            "So apparently this possible to train on one set and use it for another set."
        ],
        [
            "So our findings summarized with structure outperforms without structure.",
            "Multilingual outperforms monolingual, and this also holds in a scenario where you have to translate.",
            "Transfer learning does work.",
            "Oh, that was it.",
            "Well then."
        ],
        [
            "We go to the conclusions so these are the four open issues that we started with that we wanted to shed some light on the impact of machine translation well.",
            "It does actually work using machine translation, even with one of the current standards tools that you can just use on the web.",
            "And also if you translate use this machine translations to translate to multiple languages, you sort of mitigate this dependence on high quality machine translation.",
            "Second conclusion, well, again, more evidence that also in this type of scenario structural information helps.",
            "Um?",
            "We have contributed to the an agreement on what multilingual and cross lingual ontology matching is, and also giving precise definitions of how you can aggregate similarities between in multilingual or monolingual situations."
        ],
        [
            "Thank you.",
            "So firstly user back because I think that one of the good novel Tees is that matching was also viewed as ranking.",
            "So this is one of the novel Tees.",
            "While the question is have you have you talked to the users actually that we are mapping different taxonomies to the standard?",
            "Have you shown this results to them and if So what were their, let's say appreciation or conclusions or how they found your work useful or what would be the next step?",
            "Yeah, yeah, this is a very good question.",
            "Actually I must say I know that Dennis has has talked to the user user actually has shown them the results and talk to them.",
            "I was not involved in that because it happens in Bielefeld.",
            "So I'll transfer your question to him from what he told me they were enthusiastic and he was happy with the results, but I can't give you an exact really.",
            "What kind of feedback they they gave him, so I'll have to leave this question pending.",
            "I'm very I ask one last question then, while we're changing over the machines, you seem to do a kind of a cross product comparison, comparing all terms to all terms and just thinking about the first talk we had, which was.",
            "Talking about efficiency, when you are trying to do matching across large ontologies is that you didn't say anything about how long it all takes.",
            "Is that an issue for you?",
            "Is it computationally expensive?",
            "I must say again, I'll have to talk to Dennis to see what the exact runtimes were and if this was a problem.",
            "It's, I think since the.",
            "OK, no, it wasn't the problem in this specific scenario, but I agree that it would certainly really harm the scalability if we had larger vocabulary for something here.",
            "OK, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Great to see you're all still here and awake on this one of the last talks of this conference.",
                    "label": 0
                },
                {
                    "sent": "Representing work done by Danish 4 from University of Bielefeld.",
                    "label": 0
                },
                {
                    "sent": "Actually, he's the one who deserves more.",
                    "label": 0
                },
                {
                    "sent": "Most of the credits.",
                    "label": 0
                },
                {
                    "sent": "Philippe Cimiano, also also from University of Bielefeld and myself from Delft University of Technology.",
                    "label": 1
                },
                {
                    "sent": "A special case of ontology matching, namely multilingual or cross lingual ontology matching.",
                    "label": 0
                },
                {
                    "sent": "So this is the case where you have you're trying to match to ontologies that have either labels in multiple languages or labels in different languages.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I'll go through our motivation background on the only ontologies that we've used and that we've tested it on on our approach.",
                    "label": 0
                },
                {
                    "sent": "Then evaluation and findings and a conclusion.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our work is motivated by a number of open issues that we've encountered in ontology matching and then specifically in multi lingual ontology matching.",
                    "label": 1
                },
                {
                    "sent": "The first is the impact of machine translation, so if you have if you're trying to match to ontologies that have no overlapping languages, you'll have to translate now.",
                    "label": 0
                },
                {
                    "sent": "How does this influence the matching process?",
                    "label": 0
                },
                {
                    "sent": "So literature simply says?",
                    "label": 0
                },
                {
                    "sent": "High-quality machine translation is a prerequisite for good matching.",
                    "label": 1
                },
                {
                    "sent": "Well, sure, you can't argue with that, but we want to go a little bit more specific and ask OK, but how important is it?",
                    "label": 0
                },
                {
                    "sent": "Are the tools that we have now, so the standard machine translation tools and websites that are available?",
                    "label": 0
                },
                {
                    "sent": "Are they good enough?",
                    "label": 0
                },
                {
                    "sent": "And also, what is the influence of having multiple languages or translating to multiple languages?",
                    "label": 1
                },
                {
                    "sent": "Second, open issue that we saw is the impact of structural information.",
                    "label": 0
                },
                {
                    "sent": "So this is something that a lot of people have already noted that structural information is potentially very important for ontology matching, but so we want to see well how does this work in multi lingual matching.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "The third thing that we noticed is that there seems to be a lot of confusion on what multilingual and crossing orthology matching is.",
                    "label": 0
                },
                {
                    "sent": "For example, are these two things different or not?",
                    "label": 0
                },
                {
                    "sent": "So we want to contribute to sort of a consensus of what these terms mean by giving precise definitions.",
                    "label": 0
                },
                {
                    "sent": "And finally we want to study the the the problem of real multi lingual ontology matching in the sense that you have to aggregate similarity between labels in different languages.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, now something about the specific ontologies that we have.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Mean.",
                    "label": 0
                },
                {
                    "sent": "Working with their their sort of a specific kind, namely financial accounting standards.",
                    "label": 1
                },
                {
                    "sent": "Which are ontologies used by?",
                    "label": 0
                },
                {
                    "sent": "Well, each country, at least in Europe that prescribe how companies should report their finances.",
                    "label": 1
                },
                {
                    "sent": "The problem is that different jurisdictions or different countries have different standards, so there is an interoperability problem there.",
                    "label": 0
                },
                {
                    "sent": "A lot of these standards are in several languages, so you can think of countries that have more than one official language, then these standards will exist in several languages and obviously standards, each standard in each language is, well, it can be in a different language, so the Dutch standard is in touch.",
                    "label": 1
                },
                {
                    "sent": "the German standard is in German.",
                    "label": 1
                },
                {
                    "sent": "Another thing an important for us and you, at least for our test, is that some manual mappings between all these different financial standards exist.",
                    "label": 0
                },
                {
                    "sent": "All in all, this is a very good use case for us to study multi lingual ontology alignment.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now there is a working group called the XBRL Europe Business Registers Working Group that aims at interoperability of these financial standards and they are now in the process of creating a taxonomy sort of a Europe, European wide taxonomy of core financial concepts and they are manually mapping each local or each national financial standard to this core taxonomy.",
                    "label": 1
                },
                {
                    "sent": "So these manual mappings that they made will be the input to our machine learning approach.",
                    "label": 0
                },
                {
                    "sent": "I should say a few things about that.",
                    "label": 0
                },
                {
                    "sent": "The concepts in these taxonomies are very complex so they can be.",
                    "label": 0
                },
                {
                    "sent": "Financial statements that are defined as a calculation over over other financial concepts so there could be a concept asset which is the sum of the current assets in a non current assets.",
                    "label": 0
                },
                {
                    "sent": "These kinds of definitions.",
                    "label": 0
                },
                {
                    "sent": "And the matching function that they made from the different standards to Discord taxonomy is in terms of schools exact match and also scores close match because there is not always a one to one mapping from these different tests.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so as I said we wanted to make clear definitions of create clear definitions of what monolingual, multilingual, and cross lingual ontology matching is.",
                    "label": 0
                },
                {
                    "sent": "So here they are.",
                    "label": 0
                },
                {
                    "sent": "Monolingual matching is simply matching two ontologies together based on one single language, so they're both in English.",
                    "label": 1
                },
                {
                    "sent": "For example, this is the standard case.",
                    "label": 1
                },
                {
                    "sent": "Multi lingual Ontology matching is the process of matching to ontologies.",
                    "label": 1
                },
                {
                    "sent": "We call them source and target ontologies based on 2 languages that they share.",
                    "label": 1
                },
                {
                    "sent": "So both of them have labels in, for example English and in Dutch.",
                    "label": 0
                },
                {
                    "sent": "Then finally cross lingual matching is the situation where you want to match to ontologies that do not share any languages.",
                    "label": 0
                },
                {
                    "sent": "So you have to translate.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Now you can do several things.",
                    "label": 0
                },
                {
                    "sent": "Of course you can translate the labels of the source Ontology to the language of the target Ontology, which is situation a.",
                    "label": 1
                },
                {
                    "sent": "Here you can do the other way round situation B.",
                    "label": 0
                },
                {
                    "sent": "Or you could translate the labels in both languages to a third language.",
                    "label": 0
                },
                {
                    "sent": "Well, to make things even more complicated, when we're translating, we do not, of course, need to limit ourselves to translate to one language.",
                    "label": 0
                },
                {
                    "sent": "So if we have one ontology in English and the other one in French, we could translate them both to German.",
                    "label": 0
                },
                {
                    "sent": "But we can also translate them both to Dutch and Italian and.",
                    "label": 0
                },
                {
                    "sent": "Any number of languages.",
                    "label": 0
                },
                {
                    "sent": "Now if we do that, we end up with a lot of overlapping languages, so we end up in a multi lingual scenario.",
                    "label": 0
                },
                {
                    "sent": "So when we're talking about cross lingual matching, we can actually mean cross lingual modeling or cross lingual multilingual matching.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now, if you think of a multi lingual matching process, that means that each concept in each ontology has different labels as various labels in various languages.",
                    "label": 0
                },
                {
                    "sent": "How do you compare these labels to each other, right?",
                    "label": 0
                },
                {
                    "sent": "It could be that the two concepts in two different ontologies have two labels that are very similar, but their other labels are very dissimilar.",
                    "label": 0
                },
                {
                    "sent": "How do we aggregate these label similarities?",
                    "label": 0
                },
                {
                    "sent": "Well, we created definitions for this as well.",
                    "label": 0
                },
                {
                    "sent": "First, intralingual aggregation is the strategy that you use to aggregate similarity of labels in one language.",
                    "label": 0
                },
                {
                    "sent": "An interlingual aggregation is the similarity strategy that you use to aggregate labels in different languages, and later we will see how we have operationalized or implemented these strategies.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so that's for the background and definitions.",
                    "label": 1
                },
                {
                    "sent": "Let me see how.",
                    "label": 0
                },
                {
                    "sent": "Now do you approach itself?",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Our approach is based on a ranking support vector machine which is technique that was originally developed to improve search engine quality by looking at logs of user clicks.",
                    "label": 1
                },
                {
                    "sent": "And the difference with usual machine learning approaches is that the input is not classes but pairwise preferences.",
                    "label": 0
                },
                {
                    "sent": "Now I'll show you in the next slide why this fits really well with the type of input that we have.",
                    "label": 0
                },
                {
                    "sent": "But first an example of how this would work or how how this works for search engines.",
                    "label": 0
                },
                {
                    "sent": "Assume you have a user that has inputed a query and that gets a ranked list of 10 results from the logs from the click logs we can see where the user clicked.",
                    "label": 0
                },
                {
                    "sent": "In this case on result 1, three and five.",
                    "label": 0
                },
                {
                    "sent": "Now if we want to learn a ranking function from this for this search engine, the input would be 3 pairwise preferences, namely that result 3 is better than result 2 because the user skipped result 2 in the list.",
                    "label": 0
                },
                {
                    "sent": "Result 5 is better than result 4.",
                    "label": 0
                },
                {
                    "sent": "Big.",
                    "label": 0
                },
                {
                    "sent": "Again, because the user skip result for an result, 5 is better than result 2.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now if we translate this to ontology matching, it means that what we want to learn a ranking function that ranks matching concepts higher than non matching concepts and also that matches exact matches hired in close matches.",
                    "label": 0
                },
                {
                    "sent": "Now This is why if it's this technique fits really well with the type of input that we have, because in these financial accounting standards the training set that we have with the manual mappings that are there are in terms of exact matches in close matches and there is not always an exact match.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we need it features.",
                    "label": 0
                },
                {
                    "sent": "We define 42 features, twenty of which are syntactic, so string based.",
                    "label": 0
                },
                {
                    "sent": "We used five of the.",
                    "label": 0
                },
                {
                    "sent": "I would say standard string based similarity measures.",
                    "label": 0
                },
                {
                    "sent": "So for example variations on Livingstones, edit, Edit distance or.",
                    "label": 0
                },
                {
                    "sent": "A bag of words, cosine measure and we combine those with four different interlingual and intralingual aggregation strategies.",
                    "label": 1
                },
                {
                    "sent": "I'll show you on the next slide.",
                    "label": 1
                },
                {
                    "sent": "On top of that, we had 22 structure based features.",
                    "label": 0
                },
                {
                    "sent": "An and these were, if you think about these financial concepts that are complex concepts consisting of well defined as.",
                    "label": 0
                },
                {
                    "sent": "Equations or calculations.",
                    "label": 0
                },
                {
                    "sent": "Then we looked at things like.",
                    "label": 0
                },
                {
                    "sent": "In what place of the calculation does a certain concept appear, or how many elements does a certain concept having it's in its calculation?",
                    "label": 0
                },
                {
                    "sent": "You can imagine that if one concept is defined as the sum of two items and another is defined as the sum of five items, it's probably not the same concept.",
                    "label": 0
                },
                {
                    "sent": "So this kind of structural similarity measures were used.",
                    "label": 0
                },
                {
                    "sent": "We also looked at.",
                    "label": 0
                },
                {
                    "sent": "The distance between the labels of the items in the calculations.",
                    "label": 0
                },
                {
                    "sent": "So in that sense it was.",
                    "label": 0
                },
                {
                    "sent": "I could say some of them were hybrid syntactic Ann structural measures.",
                    "label": 0
                },
                {
                    "sent": "In any case, these two led to a vector of similarity measures 42 similarity measures for each pair of concepts in the two ontologies.",
                    "label": 1
                },
                {
                    "sent": "The source in the target anthologies.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, OK, so as promised a quick word on how we operationalized the aggregation functions.",
                    "label": 0
                },
                {
                    "sent": "This looks complicated, but it's extremely simple.",
                    "label": 0
                },
                {
                    "sent": "We simply said that for intralingual aggregation we take the average of the similarity over all the pairs of labels.",
                    "label": 0
                },
                {
                    "sent": "As shown here, or we take the best of the similarity values of all these pairs of labels.",
                    "label": 0
                },
                {
                    "sent": "Then for intralingual aggregation we take the average of all the.",
                    "label": 0
                },
                {
                    "sent": "Interlingual similarities as shown here or we take the best which is not shown, but it's a similar function.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to sum, sum it up.",
                    "label": 0
                },
                {
                    "sent": "Our approach is we calculate similarity function functions for all combinations of source and target concepts.",
                    "label": 1
                },
                {
                    "sent": "We use exact enclosed matches from the XBR to determine a rank of these of these vectors, and then we use this as a training set.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A word on our training set.",
                    "label": 0
                },
                {
                    "sent": "So as I said, we use the manual mappings by the XCB are from this core this core European wide vocabulary to the the local vocabularies.",
                    "label": 0
                },
                {
                    "sent": "Because they made a mapping from the core manually made a mapping from the core vocabulary to each local vocabulary we have also derived from that links between the different local vocabularies and use that as a training set as well.",
                    "label": 0
                },
                {
                    "sent": "Now we have three, so we have three vocabularies here.",
                    "label": 0
                },
                {
                    "sent": "The one is called XBR, so maybe confusing is the same name as the working group, but that's the core vocabulary.",
                    "label": 0
                },
                {
                    "sent": "One is called AGB and the other one is ITC.",
                    "label": 0
                },
                {
                    "sent": "X ers in English.",
                    "label": 0
                },
                {
                    "sent": "AGB in English and German ITC in English, French, German and Italian.",
                    "label": 1
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we tried all kinds of different scenarios, so monolingual matching based only on the English labels.",
                    "label": 1
                },
                {
                    "sent": "Multilingual matching on English and German labels, so two overlapping languages, their cross lingual matching, where we.",
                    "label": 0
                },
                {
                    "sent": "But we matched English labels to Italian labels, English labels to German labels in Italian labels to English labels, and here we tried both scenarios, so we tried both.",
                    "label": 0
                },
                {
                    "sent": "But we need in any cross lingual scenario you need to translate, so we translate it to one common language.",
                    "label": 1
                },
                {
                    "sent": "But we also try to translate to several common languages to see if this improves the quality of the matches.",
                    "label": 0
                },
                {
                    "sent": "Finally, to test the robustness of the approach, we.",
                    "label": 1
                },
                {
                    "sent": "Learn to ranking function on two pairs of.",
                    "label": 0
                },
                {
                    "sent": "Vocabularies and then applied it to the third pair to see if it still works.",
                    "label": 0
                },
                {
                    "sent": "What we tried this with and without the structural features.",
                    "label": 1
                },
                {
                    "sent": "And as an evaluation measure, we used a precision.",
                    "label": 1
                },
                {
                    "sent": "So how often is the correct rank, rank, rank, rank?",
                    "label": 0
                },
                {
                    "sent": "How often is the correct match ranked at number one?",
                    "label": 0
                },
                {
                    "sent": "Or how often is the correct match in the top five or top 10?",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, so you can imagine with all these conditions in all these scenarios, we have a lot of results.",
                    "label": 0
                },
                {
                    "sent": "This is only a subset of it that I think is most useful now for this presentation.",
                    "label": 0
                },
                {
                    "sent": "If you want to look at all the other scenarios.",
                    "label": 0
                },
                {
                    "sent": "Please have a look at the paper I'll talk you through it.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "If you look at the first column, you see the different scenarios monolingual multilingual cross lingual will translate into one language or to several languages, and then cross lingual, but transfer transferring, so learning on one vocabulary using it for the other.",
                    "label": 0
                },
                {
                    "sent": "The second column is the setting, structural or non structural or without, with or without structural features.",
                    "label": 0
                },
                {
                    "sent": "And then I show 2 pairs of vocabularies, the third is not shown because it doesn't add any new conclusions to the ones that we can see here.",
                    "label": 0
                },
                {
                    "sent": "As you see, there are a few empty cells.",
                    "label": 0
                },
                {
                    "sent": "For the multilingual scenario, which is because these two vocabularies do not share more than one language, so there is no multilingual matching there.",
                    "label": 0
                },
                {
                    "sent": "There are a few things to note.",
                    "label": 0
                },
                {
                    "sent": "One is that.",
                    "label": 0
                },
                {
                    "sent": "In all cases, structural matching while using the structural features works better than using no structural features.",
                    "label": 0
                },
                {
                    "sent": "The second key second thing to note is that if you look here, I TCC 2 HGB so the final three columns you see that multilingual matching is better than monolingual matching, so it really helps to use all the labels that you have in different languages.",
                    "label": 0
                },
                {
                    "sent": "Now if you look at the column before that the XYBRITCC column, we see that for the two cross lingual scenarios.",
                    "label": 0
                },
                {
                    "sent": "US translate into multiple languages is better than translating to one language.",
                    "label": 0
                },
                {
                    "sent": "So again, even in a cross lingual scenario, multilingual matching is better, works better than monolingual matching.",
                    "label": 0
                },
                {
                    "sent": "Let me see yes and a final thing to note is that the cross link the transfer scenario works quite well actually.",
                    "label": 0
                },
                {
                    "sent": "So apparently this possible to train on one set and use it for another set.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So our findings summarized with structure outperforms without structure.",
                    "label": 1
                },
                {
                    "sent": "Multilingual outperforms monolingual, and this also holds in a scenario where you have to translate.",
                    "label": 0
                },
                {
                    "sent": "Transfer learning does work.",
                    "label": 0
                },
                {
                    "sent": "Oh, that was it.",
                    "label": 0
                },
                {
                    "sent": "Well then.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We go to the conclusions so these are the four open issues that we started with that we wanted to shed some light on the impact of machine translation well.",
                    "label": 1
                },
                {
                    "sent": "It does actually work using machine translation, even with one of the current standards tools that you can just use on the web.",
                    "label": 0
                },
                {
                    "sent": "And also if you translate use this machine translations to translate to multiple languages, you sort of mitigate this dependence on high quality machine translation.",
                    "label": 0
                },
                {
                    "sent": "Second conclusion, well, again, more evidence that also in this type of scenario structural information helps.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 1
                },
                {
                    "sent": "We have contributed to the an agreement on what multilingual and cross lingual ontology matching is, and also giving precise definitions of how you can aggregate similarities between in multilingual or monolingual situations.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "So firstly user back because I think that one of the good novel Tees is that matching was also viewed as ranking.",
                    "label": 0
                },
                {
                    "sent": "So this is one of the novel Tees.",
                    "label": 0
                },
                {
                    "sent": "While the question is have you have you talked to the users actually that we are mapping different taxonomies to the standard?",
                    "label": 0
                },
                {
                    "sent": "Have you shown this results to them and if So what were their, let's say appreciation or conclusions or how they found your work useful or what would be the next step?",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah, this is a very good question.",
                    "label": 0
                },
                {
                    "sent": "Actually I must say I know that Dennis has has talked to the user user actually has shown them the results and talk to them.",
                    "label": 0
                },
                {
                    "sent": "I was not involved in that because it happens in Bielefeld.",
                    "label": 0
                },
                {
                    "sent": "So I'll transfer your question to him from what he told me they were enthusiastic and he was happy with the results, but I can't give you an exact really.",
                    "label": 0
                },
                {
                    "sent": "What kind of feedback they they gave him, so I'll have to leave this question pending.",
                    "label": 0
                },
                {
                    "sent": "I'm very I ask one last question then, while we're changing over the machines, you seem to do a kind of a cross product comparison, comparing all terms to all terms and just thinking about the first talk we had, which was.",
                    "label": 0
                },
                {
                    "sent": "Talking about efficiency, when you are trying to do matching across large ontologies is that you didn't say anything about how long it all takes.",
                    "label": 0
                },
                {
                    "sent": "Is that an issue for you?",
                    "label": 0
                },
                {
                    "sent": "Is it computationally expensive?",
                    "label": 0
                },
                {
                    "sent": "I must say again, I'll have to talk to Dennis to see what the exact runtimes were and if this was a problem.",
                    "label": 0
                },
                {
                    "sent": "It's, I think since the.",
                    "label": 0
                },
                {
                    "sent": "OK, no, it wasn't the problem in this specific scenario, but I agree that it would certainly really harm the scalability if we had larger vocabulary for something here.",
                    "label": 0
                },
                {
                    "sent": "OK, thank you.",
                    "label": 0
                }
            ]
        }
    }
}