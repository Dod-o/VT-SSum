{
    "id": "uqzwsnxte5icdbao74u7s6rtelvvjfkv",
    "title": "Where's What? - Towards Semantic Mapping of Urban Environments",
    "info": {
        "author": [
            "Ingmar Posner, University of Oxford"
        ],
        "published": "Jan. 19, 2010",
        "recorded": "December 2009",
        "category": [
            "Top->Computer Science->Semantic Web",
            "Top->Computer Science->Computer Vision"
        ]
    },
    "url": "http://videolectures.net/nipsworkshops09_posner_wwts/",
    "segmentation": [
        [
            "So good morning everybody.",
            "It's a pleasure for me to start this workshop on learning for multiple sources with application to robotics.",
            "I am Francesco Bona from India presearch Institute.",
            "The topic that will.",
            "Of this workshop will be learning from multiple sources.",
            "In his general view.",
            "Learning from multiple sources denoted the problem or joint learning from a set of partially related learning problem, and in this view it it is.",
            "Basically, the most common, the most general idea that underlies problems has data Fusion, transfer learning, multitask learning, multi view learning and learning under covariate shift.",
            "We will we will.",
            "We will talk about theory and methods in this workshop, and in particular we will talk about robotics and natural application, another application, domain for learning from multiple sources.",
            "We tried to divide the session more or less in two parts, so in the session in the morning will be the session for the robotic application or the application in general and we will start with the Invited tool core equal partner.",
            "And then we will have the usual break and we will start again in the afternoon with the theory session.",
            "The workshop will end with a discarded discussion in future direction meeting.",
            "I think we can start now and where we can.",
            "The first talk will be by the invited Speaker.",
            "Equal Posner is a research assistant at the Oxford University.",
            "And it will talk us about.",
            "The use of multiple sources to create semantic Maps.",
            "Alright welcome hello.",
            "First of all, let me stop.",
            "I am thanking the organizers very much for being invited.",
            "I think this is a great topic for a workshop.",
            "Also, it's obviously brilliant setting, and there's a longstanding longstanding well established conference, so it doesn't happen often that you go through security at the airport and people just wave you through going.",
            "Oh yeah, you go into this artificial learning thing, OK, just keep on going, so that's that's nice.",
            "It doesn't happen often robotics.",
            "And putting together these slides, we really, really thought about the kind of communities that we that we tried to straddle in the audience here.",
            "And we do see a couple of you know, friendly, familiar faces from the robotics community, but also some of the things that we use.",
            "Obviously I'm very much inspired by machine vision, very much inspired by machine learning, and it's a privilege very much to to go first today, because I think I can possibly add or help set the scene of it simply by bridging the gap between between these communities to a certain extent.",
            "And so some of the things that you will see depending on what community or from will be somewhat familiar to you will be probably thinking that we do this.",
            "And whatever you know, our community is quite regularly quite a lot.",
            "I have been trying to pull it out.",
            "They'll draw it out in such a way that there's never coincide.",
            "So when you see something that's familiar opening for the find, a lot of the other parts are quite interesting to you.",
            "Now the the main title and the main topic of the talk, the bulk of the talk, really is what was mentioned in the introduction just now.",
            "The semantic mapping.",
            "Of urban environments, because we very much are interested in in mapping and an outdoor kind of urban environments in the group that I'm from and before I start actually talking about this subject, I thought I kind of talk about the things that we commonly see in terms of sensor integration in robotics, so there's going to be a bit of a pre lude sort of speak about the kind of things that we do, and kind of the kind of things that we that we commonly see.",
            "So for those of you who aren't in robotics, this is the kind of things that we do.",
            "We are."
        ],
        [
            "Very much about outdoors them very much about Samson.",
            "Herbs.",
            "Actually in the field we have several different sensor platforms, so we have a Segway here and an 80 LB junior here.",
            "And these things carry a whole lot of a whole bunch of sensors, so at the top here we've got the Omni directional current camera.",
            "It's a lady bug, we have a stereo rig right there forward looking.",
            "We have two laser scanners to besides the kind of scan like this and we troll them through the environment like so.",
            "To get essentially range and intensity out, and of course there's various on board computers etc etc.",
            "We also have a similar kind of setup on this slightly older older robot.",
            "Here we actually get 3D laser data from an inherently 2D scanner that rocks up and down, so it takes somewhat longer to acquire an entire 3D scene.",
            "Build.",
            "The advantage here is of course it's forward looking for it, so it's quite useful.",
            "Also ever have a camera on board here?",
            "That kind of takes takes pictures every couple of meters and these things kind of generally.",
            "Gently go round, go round Oxford really.",
            "And before anybody asks, they actually remote control so they're not autonomous.",
            "You know we don't need them out of our sight or out of easy reach of the emergency.",
            "Shut up.",
            "I mentioned some of the sensors, there's other sensors and other platforms that we get.",
            "I mean, I'm used.",
            "GPS is typically get wheel encoders that codes odometry movements trying to estimate where you are in the world though their noisy so we can use other other sensors to actually measure the same thing and infuse these measurements together.",
            "It's actually very very big topic in reported."
        ],
        [
            "Alright, this is the kind of data that we get out.",
            "So what we see up here is the stereo feed.",
            "The two frames there.",
            "We kind of matched individual features and get out essentially visual odometry for all intensive purposes for this talk and there's a system that was developed by game.",
            "Simply increase may in our group and was published at one of these conferences this year and it's really, really quite accurate over quite a quite a long way.",
            "What you see down here is essentially the trajectory of the robot as it goes around.",
            "In this case, one of those colleges, new college.",
            "So this is the kind of this kind of thing that we that we get from the from the stereo down.",
            "Here is the typical rendering of the 3D data that we get as we kind of go through the environment and what you see is again range and intensity and this is rendered relative to where we think or where the robot thinks it currently is based on information from the wheel encoders based on information from the visual dormitory etc.",
            "And the detail that we get from this kind of information is really quite quite astonishing.",
            "This again is just rendered from from local.",
            "Local traverse just just based on the dormitory and you can see that can even like reflective parts.",
            "Obviously shine very brightly in this sort of modality and even read number plates etc etc.",
            "So that's that's that was quite nicely with that that data first.",
            "This down here is just an example of the of the pictures that we get from the directional camera.",
            "There are five or six different cameras in their actual device kind of space at regular intervals.",
            "And here in this particular case, the cameras mounted on top of a car.",
            "So one of our guys Mark Mark Cummings going to car around Oxfordshire and around Britain in general in the end.",
            "Collected this sort of data as well as stereo data.",
            "He was going around.",
            "So.",
            "That's an impression of the kind of thing that you that you get.",
            "Now.",
            "Slide three or four and we're already at one of the main points that I think are important.",
            "It is nothing new, but I think it's important to kind of, you know, put in words and then put put on this slide, which is really the realization that is roboticists were quite privileged."
        ],
        [
            "The correct privilege in the sense that we have.",
            "A system, a platform that carries for us many centers, many different modalities through the same contiguous workspace, and that sets us apart from a lot of other other domains, such As for example, machine vision.",
            "Where yes, you can get video etc etc.",
            "But we have these other modalities sometimes.",
            "Often when you kind of work with random image collections these.",
            "Workspaces aren't contiguous, etc etc, and there's a.",
            "There's a lot of things that we can actually do, and that we can benefit from that.",
            "Other domains have have a harder time to access.",
            "And of course, very pertinent to this workshop is that this really provides ample scope for combining information from different sensors.",
            "One thing that's been done for a long, long time is booked under data Fusion, particularly in the context of of mapping and navigation.",
            "In this problem of simultaneous localization and mapping, there's going to be a slide on that in a minute, so I briefly explain what that actually means, but the idea really is to create a representation of an environment as well as a representation of where you are in that environment.",
            "And.",
            "Once you have that, there are other things we can we can build on top of that.",
            "For example, appearance based methods have become very prominent in robotics.",
            "You can use those from from based on videos on cameras, on images, you can use those to constrain things in your mapping process.",
            "In your metric mapping process.",
            "One problem that was prominent in robotics for a long time is the loop closure detection problem.",
            "I will talk again in a single slide about how we can help in terms of in terms of appearance based methods, but once again this is a is an example of how we fuse different modalities or fuse information.",
            "But different melodies, you can turn the whole thing around.",
            "You can say we've got a a metric kind of mapping task and we use.",
            "Sorry, we've got a topological type of mapping task and we swap it around that.",
            "We introduced geometric constraints into that topological mapping task, again fusing different sources of information.",
            "There's a more sensor based or a more directly sensor.",
            "Based.",
            "Version of the same kind of idea, where essentially we talk about sensor augmentation, which is a very straightforward kind of thing.",
            "Again, there's gonna be light on it, and then of course there is.",
            "There's Q integration, which is where a lot of work is done and has been done and is yet to be done about how we actually properly integrate information from these different modalities.",
            "Ultimately, in about 5 six slides from now we work that I'm talking about in terms of the semantic mapping.",
            "Very much sits in the centre or mentation bit, and to some extent in a very basic way in the.",
            "Q Integration part of this, but we'll get there in a minute, but let's talk about the kind of things that we currently that we commonly see in robotics in terms of sensor integration, so."
        ],
        [
            "This is this is directed at the slam idea, the simultaneous localization and mapping idea, and really the goal is to come up with a faithful representation of an environment as well as your trajectory through it.",
            "So what you see here is an almost plan view of the 3D laser Maps of the kind of thing that we saw in the second slide.",
            "Where you are, the robot went around the outside of the engineering triangle in Oxford, which is about half a kilometers worth of track.",
            "And here you see blowup of that, so you can very nicely see there's a bunch of steps here which is the entrance door to our building.",
            "There's kind of a ramp that goes up here, and this is the kind of data quality needs to get in this particular thing.",
            "Map was taken with Marge.",
            "All our robots are called out of The Simpsons for reasons that sometimes elude me, but so much the ATV junior with a kind of rocking laser, which is where you kind of see this.",
            "These stripes at the bottom because at some point when you invert the emotion you kind of get denser sampling at those points.",
            "So this is a typical kind of example of a slam map.",
            "Of course.",
            "I should probably say so.",
            "The way that we come up with these is essentially based on variance of Bayes filters, so common filters extended common filter's party for this, etc.",
            "And we use different sources of odometry, so you can get take the wheel looking encoders and you can do things like scan matching from the laser scanners and all these things will give you ideas of how you've moved, refuse all them together in a box understanding Fusion way and this is what people in robotics have done for 1520 years, so.",
            "Of course.",
            "There's a bit of a hitch because before that map looked like this, mostly triangular.",
            "We're just kind of that.",
            "The real shape of the environment kind of look more like this.",
            "And the problem is that this is the same environment is actually the same map with a with a plan."
        ],
        [
            "And if you."
        ],
        [
            "At any individual bit of the map, you will see that this is actually it's reasonably accurate.",
            "And these points were rendered simply from things like Wheeler Domitory.",
            "And it turns out that one of the big problems that roboticists had is essentially that noise integrates.",
            "So what that means is over short distances, we can get a Dominator measurements that are reasonably accurate, but as we go along, way, tiny errors in these odometry estimates accumulate to enormous errors, such that as we go around a big loop, we end up with an enormous bust where we really know this should be the same point in the map, and this is really the essence of the root cause of the problem, and it's kind of folks, people in the community for a long time.",
            "Until fairly recently, people have come up with the idea that maybe we could use a different modality again to recognize whether we come to the same place and this is really the idea behind the system called fab map that came out of out of our group Mccommons implement developed this in various versions and it's really been very successful and recognizing whether you come back to the same place.",
            "That allows you to do it allows you to put a constraint between this point at this point here.",
            "Merge these together and spread the air around the rest of the map so you come up with a representation that we've just seen.",
            "OK. Of course the cute the key thing here is that we have a sensor do to fix this problem."
        ],
        [
            "OK, so given that we have these these constraints that we can derive from abilities, these are the kind of reconstructions that we that we can come up with.",
            "So this is a publicly available data set.",
            "The new college data set from from Oxford.",
            "This is the yellow.",
            "Here you see the real the ground truth track of the of the robot.",
            "Down here you see a metric reconstruction of that of the data set over about two 2.2 kilometres, and for all intents and purposes this is a really really.",
            "Good representation of that of that environment in terms of in terms of accuracy.",
            "So combining these different abilities allows us now to build fairly large scale metric Maps, but also over several kilometers.",
            "But even larger scale topological Maps.",
            "Where some of this method has been used to essentially build topological Maps Coast to coast in Britain.",
            "So we're talking thousands of kilometres and for lack of a better metric to use, we've got the record of mega meter just because it's kind of consistent with the whole system.",
            "But these are the kind of things that we get.",
            "In terms of the reconstruction, so once we put all these things together we can go through the map that we've built the 3D map that we've built and pick out some very nice details like.",
            "These trees are kind of foliage, and as you go around the kind of different building at the people and different kind of signs on the wall, I'm going to play more video later, so so that might be more interesting in a bit.",
            "The other thing that we can do is."
        ],
        [
            "This idea of sensor augmentation, where essentially is something very very straightforward, where essentially we take the cross calibration that we have from different sensors from the camera and from the lasers, and we associate every laser point, every range measurement that we get with the color simply by projecting the color part of the laser points into the into the camera image, and that gives you representations like this, which kind of look very nice, and they make very good videos when it comes to talk to sponsors, but there's inherent problem with this, which is which is very much addressed by the work I'm going to talk about in a bit.",
            "The whole idea of assigning some higher order meaning to these things well, how does this fit in terms of in terms of the path in terms of the planning scenario in terms of the action selection scenario, which is really where where we want to get with."
        ],
        [
            "You can take this and you can turn it around again and say, OK, well in the previous slide we've seen this augmentation.",
            "We take any every range point, then we associated with every range point a color.",
            "But what if we actually want to go the other way?",
            "What we want to go from an image and some coarsely sampled range data, which is what you get, so you usually get one laser .1 range measurement for every kind of 1516 pixels.",
            "What if we want to go from that to a fully dense range map, so with every pixel in the image we now want to associate a range measurement.",
            "And of course you can do that sort of thing.",
            "This is a synthetic.",
            "A synthetic problem where essentially you've got some form of scenario with the intensity image associated with it and then kind of the square kind of ashtray type of type of shaped object here and the red dots are those sparse range measurements and you can say OK, well, we could obviously do is we could just take those measurements and we can interpolate.",
            "So we come up with a with a normal kind of bilinear interpolation interpolation and we see that many of the important shapes aren't really preserved.",
            "So for example the thing that."
        ],
        [
            "This thing used to be square and now the whole thing spreads, spreads around in space.",
            "And we got a whole lot of artifacts like that that we would rather want to avoid.",
            "And once again we can use a different modality that the whole kind of imaging idea, and we can use this intuition that discontinuity's in things like intensity or color.",
            "Not necessarily indicate, but allow for discontinuities in depth.",
            "So we can come up with a more intelligent."
        ],
        [
            "Interpolation method, which essentially preserves alot of the important shapes.",
            "I mean it's far from perfect for some of the stuff is still there still kind of bend and curve curve but we get a lot better representation than just from just from straightforward interpretation of this data.",
            "OK, so these kind of things are things that we do in our group.",
            "There are things that people in robotics have been doing for quite a long time and this is the kind of thing that we usually that we often see.",
            "In this sort of context.",
            "OK, of course the whole thing.",
            "So what we've seen so far is synthetic data.",
            "This is kind of real real bit of data from outside, but there's a lot of planes here simply because it does for a good illustration we can see that it's a decent response."
        ],
        [
            "It's not perfect, but again, we kind of get the overall idea."
        ],
        [
            "OK. Alright, so this is the kind of thing that we that we commonly see, and now I'm going to talk about how we can take that further and why we want to talk about higher order semantic mapping and why we get into the classification of these data into things that we can possibly under."
        ],
        [
            "And as as human beings and one of the reasons for that is really that these point cloud representations here, they're nice, and they make for the videos.",
            "But in terms of of common things that we really want to do with robots, action selection and navigation planning human machine interaction, they're not really terribly useful, because really, all they are big and by three matrix.",
            "So really, what we want is things like like seen labels.",
            "We want to know about things in the world.",
            "You know, grass, tarmac, pavement, or what kind of services we are kind of objects we have when we're crossing a Rd.",
            "Want to see?",
            "Can we see a car etc etc?",
            "How safe is it?",
            "These kind of things.",
            "These are kind of questions that we're that we're moving towards and This is why.",
            "Why this becomes a very natural problem to work on now."
        ],
        [
            "When we think about this, we.",
            "We come to appreciate that there are certain things in robotics that we that we want from these methods.",
            "One very big thing is that we we want uncertainty measures that are associated with our classifications.",
            "So in this case we really we really after we like probabilistic methods simply because we get these kind of measures out.",
            "Then we can employ the entire probabilistic machinery in combining information.",
            "So this is something that we're very fond of.",
            "Ideally things that we would like is certain degree of introspection.",
            "We'd like to be able to handle.",
            "Context in some in some respect, and of course we benefit a lot here from statistics and the vision community.",
            "We've done heaps of work on that.",
            "Also, a very important aspect for us is at least a handle on how.",
            "On how good our measurements are, how much do you trust the sensor?",
            "If you drive at night, would you rather put your trust in the vision sensor, or would you rather put your trust in laser?",
            "It's up to you to certain extent, but it's nice.",
            "Essentially have a have a handle on being able to to make a decision based on that of course.",
            "Very important would also be that we can adapt our class models online, so if you see something you'd like to be able to handle it somehow rather than go home and spend the next three weeks training a new classifier.",
            "So that was also something that that is on our list of desirable.",
            "And of course we would like to do this whole thing in real time.",
            "Answer That it's fast.",
            "And this is also something that's not necessarily given if you if you take any any standard machine learning technique, you kind of have to have to be very careful with what kind of things you you select here, and the work that we're about to talk about now is very much a snapshot from this kind of from this kind of list where we decided, OK, this is the kind of things that we wanted to see.",
            "How far how far we get through this.",
            "So briefly, I'm going to talk about the the kind of processing the data that we get, and what we do with it and the beef."
        ],
        [
            "It really is is here we talk about the different classification frameworks at the different different scales that we look at.",
            "And of course I want to talk about some results and some of the conclusion."
        ],
        [
            "So we that we've drawn from it.",
            "OK, so in terms of the processing pipeline is very similar to the kind of data that we've just seen.",
            "We have a 3D laser Flowers with our robot command center here, and we take images of the same scene.",
            "So that's the image that."
        ],
        [
            "Correspond to that scene and back then, so this work is about a year and a half old.",
            "Back then, one of the things that we did was argue that, of course, in man made environments there are some very predominant geometry, so that it will be for this.",
            "So planes or some of them and we can use them for very crude.",
            "Feature extractions in terms of quantifying the 3D geometry oversee so the first thing we do here is a is a plane extraction plane segmentation."
        ],
        [
            "And because we have the cross calibration, we actually know the viewing frustum of the camera."
        ],
        [
            "And we can take that."
        ],
        [
            "And essentially project those camera points into the image and just just for completeness, let me say that so that the different colors here of the points indicate plane memberships, nothing to do with classes yet OK?",
            "Again, this is a very kind of standard trick.",
            "To be done.",
            "OK, now once we're in this position, once we actually have these points in the image, we can apply any machine vision technique that we like that is based on interest points and kind of local local patches to move forward from that.",
            "So we just treat these laser pointers points of interest."
        ],
        [
            "But Interestingly, we can.",
            "Actually we can feed information from the image back into this plane segmentation.",
            "So if you consider that we have a C and we do everything that we just that we just said which essentially is project these points into into that scene where there."
        ],
        [
            "You in the red essentially extend outside the the viewing frustum of the camera.",
            "We can then look at this and think, OK, well, what kind of classes might we be interested in?",
            "And we can say OK, well, dirt tracks kind of interesting 'cause something to travel on grass is also kind of interesting because something not to travel on.",
            "And if we then look at this segmentation we see that, well, these planes really straddle both of those classes, so it's not really clear how we how we how we separate them.",
            "We can't just classify a plane and be done with it."
        ],
        [
            "So what we can do is again use a standard machine vision technique.",
            "We can.",
            "We can use the intuition that things that look the same are likely to be of the same class, so we can use a any off the shelf image segmentation algorithm and over segment the image, which is fairly easy to do, so we're not after an exact segmentation.",
            "We often over segmentation and we can say OK well."
        ],
        [
            "We can project the same laser points into this segmented image.",
            "And we can then repartition these laser points.",
            "These kind of planes into their membership of different segments in the segmented image and what you end up with is this sort of this sort of."
        ],
        [
            "So this green playing here has now been split up into points that apply in this segment, and points that lie in this segment appointments this segment.",
            "And if we take that in the projective back into the original image, we find that we've now actually come up with a representation that very closely follows this paradigm where we have one set of of points 11 entity to work with with respect to a single a single class.",
            "So what we end up working with is these patches or super pixels with.",
            "Of course their appearance information associated with it.",
            "But also some 3D geometry information associated with it."
        ],
        [
            "OK, so once we once we have that what we do is we encoded in a standard bag of words representation, which is probably very familiar to a lot of people here."
        ],
        [
            "But to just briefly summarize this so we we take the scene we now operate on these."
        ],
        [
            "Pixels.",
            "Every point we treat as a point of interest, so we try to extract local regions around it.",
            "We then."
        ],
        [
            "Go on an encode these local regions according to some descriptor and essentially can be descriptive.",
            "Your choice.",
            "I'm going to talk about what we used in the second.",
            "Some very, very simple features simply because we wanted to compare it with some prior work and we wanted to be reasonably fast.",
            "You compute these descriptors.",
            "You then."
        ],
        [
            "Quantize these descriptors according to some what we call a vocabulary.",
            "Essentially clusters in this feature space, which we learned offline, so you quantize them every single, every single descriptor to one of those clusters.",
            "These clusters are called words."
        ],
        [
            "Whole thing is called the dictionary and what you end up with is for every one of these patches, essentially binary vector indicating zeros and ones for every single one of those clusters.",
            "So a particular here cluster, one word one we've seen in this Patch where two we've seen were three, we haven't etc etc etc.",
            "And the length of that vector.",
            "The dimensionality of the vector essentially off of the size of the vocabulary of the number of clusters that you have in that in that space.",
            "The nice thing about that is of course that you end up with a with a very uniform representation of your of your world of your segments, irrespective of the segment size and the number of points."
        ],
        [
            "OK, in terms of features again, these are very very basic.",
            "In terms of the 3D geometry, So what you see here, I should probably say is extraction of the feature matrix.",
            "We see kind of the feature number here and the type of the type of class that we might be interested in in terms of 3D geometry.",
            "The obvious thing to users, for example the surface normal, which is the first column here and you can see that the surface normal very nicely separates things like ground from things like non ground, say in terms of 2D geometry we use things like normalized X&Y position in the image color histograms, Hue and saturation.",
            "And a very, very crude indicator, not even measured like an indicator of texture, simply encoded as part of the part of the histogram is already, so that's the kind of thing that we use."
        ],
        [
            "Alright.",
            "Those are the features that we use.",
            "That's the kind of data processing that we do.",
            "Let's talk about the classification part.",
            "And really, what we do is we kind of look at this as a two stage problem.",
            "First of all, we're interested in extracting these these segments and coming up with classifications for these segments.",
            "But then there's actually another level on top of that that encodes the whole intuition that you see objects in the world in context.",
            "So, for example, you would expect to see a car on road, and if you see something that kind of looks car like on something that really is very likely to be grass, you would think well.",
            "If it looks a bit like on a good like tree is probably more likely to be true.",
            "'cause you see a lot of tree on grants and it is this kind of information that we try to capture in this in the second stage and the the obvious way to do that is with a graphical model which we construct from the images and also through time, but we'll get to that in a couple of slides.",
            "So well.",
            "First of all, talk about how we actually classify these individual these individual patches, and at this stage of of this work.",
            "I mean you can.",
            "You can use pretty much any ranking classifier for this that you want at this stage of the work we essentially decided to.",
            "To play with probabilistic bag of words classifier but is very closely related to what's known as a tree augmented Naive Bayes classifier.",
            "I don't know whether you were familiar with that, but you'll get the hang of it in a couple of slides I think.",
            "Um?",
            "OK, so we start up with."
        ],
        [
            "Our class model, in this case, our classes, are represented by exemplars, so concretely, what that means is every class has a bunch of instance."
        ],
        [
            "Creations that come from labor from labeled data."
        ],
        [
            "Every class is NK.",
            "Every class K as a NK of those, and it can be different number over the different number of classes.",
            "So that's not a problem.",
            "And really, in terms of notation, the way we represent that is by a class.",
            "Is this math Cal Super K is represented by a whole bunch of examples.",
            "That's what these guys are.",
            "So want to NK.",
            "Alright.",
            "Once we have that."
        ],
        [
            "The question is, how do we actually represent these individual exemplars?",
            "And I apologize here because I rotation is slightly abusive, but it's really meant to to make clear what's going on here.",
            "Every exemplar is literally represented by a set of probabilities, and these probabilities are probabilities over a hidden layer of variables E, where intuitively stands for existence.",
            "And really, the idea is that Ian codes generator for a particular word at a particular at a particular example are so for example, in this particular case, here you've got.",
            "Generator for word one.",
            "Given this example are this example here and what that means is that if you had a perfect sensor.",
            "If you had a perfect sensor that picks up this this feature every time that it exists.",
            "Then you then then this E will indicate that actually you get.",
            "You get detection for this.",
            "So it means that there is actually something that gives rise to this particular feature.",
            "Weather sensor picks it up or not.",
            "And the nice thing about this is actually twofold.",
            "The immediate result of that is that we can come up with detector model where essentially we can say we do not assume a perfect sensor, but we say well given given that a generator for that particular word exists, there is still a chance we might miss it.",
            "And that's nice because relating back to that list that we just talked about.",
            "Earlier this kind of list of desirables it gives us exactly this handle on knowing how good or how much we trust our individual sensor.",
            "So you can imagine you've got one of these for every modality you can imagine you've got one of these for every individual word you can imagine that with different environmental conditions like lightness, darkness, etc.",
            "This kind of trust changes, so that's a that's a nice feature to have.",
            "Couple of in a couple of minutes we'll see that.",
            "The other thing that this E allows us to do is really take a very simple model of Patch appearance of kind of super pixel appearance and blended with a more elaborate with a more elaborate model of Global words Co occurrence.",
            "But we will get there.",
            "We'll get there in second.",
            "OK, so I think one of one of the best ways of actually illustrating."
        ],
        [
            "What we're doing here is going through through the process, so we start out by saying, well, we've got our class model and we've got got all that trained up.",
            "We get in a new observation and we encoded as we've talked."
        ],
        [
            "Well, we end up with this kind of indication vector with the observations at this.",
            "Just this binary vector and the obvious question then, is what class is it?"
        ],
        [
            "And you can answer that simply by.",
            "Well, we can start answering that simply by writing down."
        ],
        [
            "Jewel, where you have a."
        ],
        [
            "Posterior over class."
        ],
        [
            "Given the new observation and of course that."
        ],
        [
            "Proportional to the product of the the class prior, which is very easily obtained simply by looking at at label training data and counting."
        ],
        [
            "And a class likelihood term, and the tricky bit really is obtaining this class like or calculating computing.",
            "This class likely return, so the next couple of slides will take that initially Peter apart like like an onion and talk about how we how we get there."
        ],
        [
            "Oh OK, so."
        ],
        [
            "We are now concentrating."
        ],
        [
            "We are now concentrating on this term right here, so we kind of."
        ],
        [
            "That in mind, so."
        ],
        [
            "Next"
        ],
        [
            "Next slide here is exactly exactly the term, and it turns out of course we can.",
            "We can expand that out since there's an integration over Exemplar, so we start out with the condition on the class.",
            "We now have it in terms of the exam class, and we make two assumptions.",
            "One is that none of the training data on these labels, which is a fairly common assumption to make.",
            "Which essentially means that we kind of lose this term here and the second assumption is that all examples within a class are equally likely, and what that means is that essentially end up with this with this average essentially here, but we lose this.",
            "This class term from this first expression, which means we end up with this term here, which is nice, because now we have we moved away from this dependency on the actual class and were directly looking at the dependency on the actual examples on the actual data, that's good.",
            "OK, so now we can straighten this term here.",
            "What do we do about this?",
            "Well, in order to evaluate this, we need to know something about the actual distribution of observations.",
            "The joint distributions of all Zeds, and that's kind of tricky because there's a lot of them.",
            "So vocabulary sizes you know anything between two 200,000 words, pretty big distributions, and we essentially can live at one of two extremes or anywhere in between.",
            "For that matter.",
            "One extreme would be to say, well, we could do a naive Bayes approximation, which essentially says, well, all of these words are independent.",
            "The other approximation says OK. Actually the other thing is not an approximation at all, it's it's the exact factorization of that enormous joint distribution, including all the higher order terms.",
            "And of course, now you phase means we assume that the absolute independent and there's no structure in it.",
            "Coming up with a full joint would be awesome, but of course is intractable.",
            "So the question is, can we live somewhere in between?",
            "And of course, intuitively, we know that these kind of words could occur, so this is a representation.",
            "Here we have word 28 and 119 and word 741."
        ],
        [
            "We know that different bits of the environment give rise to a combination of words."
        ],
        [
            "So we know intuitively that these words don't occur in dependently.",
            "So can we come up with a better with a better representation than the naive base of the?"
        ],
        [
            "And the answer is yes, we can, with again a fairly standard trick from from statistics, which is known as the child new algorithm, and essentially that the concept is really quite quite simple, so that Charlie algorithm has a couple of nice properties.",
            "But what it does is it gives you a tree, a tree structured representation of the full joint.",
            "And because it's a tree you only end up with first order conditions, which is nice.",
            "The way construct this tree is, you essentially calculate the pairwise mutual information graph between all the observations.",
            "And calculated maximum spanning tree.",
            "That's that's literally what the what this child you tree is, and it's got a couple of very nice theoretical properties, such As for example.",
            "That is the best.",
            "Approximation in this class.",
            "So the best tree you could possibly construct that cloud most closely approximates the real joint distribution in terms of KL divergences, so this is the best approximation that we can possibly come up with in terms of those first order terms.",
            "And it's also very efficiently computed from unlabeled data, so it's very nice in that so we don't have to go around label heaps of data for this now.",
            "So what we what we end up with then is this kind of full joint, which is a term of the individual words, and we approximate it as the product of you know, the probability of the route with a whole bunch of other terms which are essentially 1st order conditions, where Q is a particular observation.",
            "So 611 and PQ denotes the parents of that one.",
            "So in this case it will be 28.",
            "And if we take that, we condition it on the exemplar, we kind of end up with this expression where this is exactly the kind of thing that we wanted to compute.",
            "OK, given that we're almost there, we can now look at this bit here and figure out and wonder.",
            "OK, So what do we do with this?",
            "And this is where we go back to these either."
        ],
        [
            "Both these existence variables, because now we can expand this out in terms of the variables which we then integrate out, and we can do.",
            "We can make two more fairly simple assumptions, one that detector errors are actually independent of class, which is which is fairly reasonable."
        ],
        [
            "And what that means is that we kind of lose the class from from this thing here, and we end up with something that we that we've seen over something close to term that we've we've seen earlier, and the other.",
            "The other assumption is that the probability of the generator variable for a particular word is actually independent of any of the observations of all the other words.",
            "And what that means is that."
        ],
        [
            "We lose this parent term from this thing here, and what that boils down to again, is simply our example and model, and this is how the existence of these E variables.",
            "This hidden layer allows us to blend these different things together.",
            "There are a couple of rearrangements, a little bit of of math that you have to do in order to to rearrange those terms and figure out how that relates to actual label."
        ],
        [
            "Data, but the bottom line is we can actually relate this to.",
            "We can learn this from a reasonable amount of training data.",
            "And we can go all the way back up and kind of reconstruct this onion and put all the big players.",
            "They gon put a big step in and say we can compute this in a reasonable amount of time, so that's good.",
            "So given that we compute this, we can go all the way back to the original formulation.",
            "We just roll base theorem and we can essentially assign a Class 2.",
            "To that to that new data?",
            "Alright, so, given that we that we are fairly happy with how to do that question is how do we actually learn these class models in the 1st place?",
            "And if we go back and remember that these are represented by individual exemplars, examples are represented by sets of probabilities like this one here for a particular word Q.",
            "And really in order to in order to learn this from data from labeled data, really what we write down again is is a Bayes update where we have a word existence prior that again we can get reasonably straightforward.",
            "Free from labor data."
        ],
        [
            "And what we have here is nothing."
        ],
        [
            "But the likelihood term that we've just seen with a given word existence, so we set the existence of this guy to one and then go through exactly the same calculation that we've just been through."
        ],
        [
            "And down here again, we've got the same likely terms, so we know how to compute all these guys.",
            "And the nice thing about this is that this calculation is very, very fast.",
            "So what that means is then you can get a new observation in.",
            "You can perform this update if you so wish.",
            "You can perform this update and you can literally take this new observation and bolted onto the end of your class model.",
            "That could mean that you either extend an existing class model or that you essentially open up a new class model.",
            "So if your system comes back and says, well, I'm not really quite sure operator help.",
            "What is this?",
            "You could come up with a label and you could say OK, well this is a new class and then you could literally just incorporate that on the fly, which is also a really nice property that we look for in robotics."
        ],
        [
            "OK."
        ],
        [
            "Alright, so that's the first stage.",
            "Now we essentially come up with a distribution or classification for every single one of these patches.",
            "So now how do we set these things into context?"
        ],
        [
            "In statistics.",
            "In machine learning there has been around for a while.",
            "I'm there now, everywhere graphical models, so I doubt there's anybody in this room hasn't heard of them or done anything with him.",
            "In this case, we're actually going for a basic, very basic variant of it Markov random field, where you have a bunch of nodes and abundant edges, and in a minute we'll see that every one of these nodes corresponds to one of these super pixels, where these patches and every edge corresponds to some relationship between them, and in this particular case it will be some very straightforward spatial relationships between those patches.",
            "And what you end up with them is in MRF, which OK as we know, is family of undirected graphical models, which models the joint between the observations and the available data and the question then is how do we perform inference in what kind of thing do we want to ask this model?",
            "And really the thing that we're after is a configuration X.",
            "So imagine that X is essentially vector.",
            "If you consider this graph here you go onto future.",
            "We got 66 nodes, so X will be a vector of length 6.",
            "And every single element of that can be one of NC classes.",
            "So it's a.",
            "It's a discrete, it's a discrete vector and there can be many of them.",
            "Many different configurations of that particular graph, and we essentially want to want to know which one is the most likely one given the data that we've seen.",
            "And that is a very.",
            "It's a book standard map inference problem will just be, you know, explored and applied many, many times, where essentially you know that you can solve it via an optimization of an energy function.",
            "In this case, minimization of an energy function.",
            "Where the whole thing.",
            "So you have an energy for a particular configuration X given the parameters for this model, and there's really only two types of parameters that we deal with here."
        ],
        [
            "These are kind of these.",
            "These guys here theater S which are the unary parameters.",
            "There's kind of a data cost which essentially encodes the cost of giving a particular particular node particular segment.",
            "Any given label given the data that's associated with it.",
            "And then we've got this pairwise term here, which are essentially both potentials, which includes the cost of giving two adjacent modes, different labels or the same ones so.",
            "That's essentially where that comes from and the this inference can be done in many, many different ways.",
            "They're kind of graph, had variance Max product loopy BP, and we actually chose something called Sequential Tree rated message passing TWS."
        ],
        [
            "Simply be cause it gives you some convergence guarantees to kind of local Maps.",
            "Maxima in the way that loopy doesn't.",
            "Having said that, of course many people know that loopy as being applied to many things quite successfully.",
            "We just.",
            "I mean, it was a design choice, so we just chose that.",
            "It doesn't make much of a difference.",
            "OK, so the question is how do we actually determine?"
        ],
        [
            "The structure of that model given given that the data that we have, and again we can look at it as seen and we can perform an image segment."
        ],
        [
            "And it's very straightforward.",
            "Once you've got the segmentation to come up with the neighborhood relationships between the individual segments.",
            "So you just look at it along the boundary and see."
        ],
        [
            "Which ones are border on which and you can then take everyone of the segments that you have laser data for.",
            "So you've got the 3D geometry data associated with it and come up with kind of this structure right here.",
            "And it's nice because it kind of provides a very intuitive and fast way of constructing these graphs from the data that we actually have.",
            "And of course, yeah, those graph."
        ],
        [
            "So fairly sparse, so we're kind of abstracted away from operating on the actual on the many hundreds of thousands of laser points to, you know, 10s of nodes."
        ],
        [
            "So that's a very nice property.",
            "OK, so this is the kind of guy we've just seen.",
            "We want to minimize it.",
            "The question is, where did these terms come from?",
            "The first term comes directly out of the first stage."
        ],
        [
            "So essentially this is just the posterior that we just calculated with our with our classifier.",
            "We use the compliment here, 1 minus because it's a minimization, so we want for something that's very likely what the cost to be cost to below one assumption that we make here is that our class is fully partitioned.",
            "The world, which is a slightly naive assumption to make, but it's something that we ran with here just for the sake of moving ahead.",
            "Of course, in practice you could have background class that that will kind of is a lot of the issues that you get from that."
        ],
        [
            "The binary potentials these guys here.",
            "Sorry these guys here are very much so.",
            "In this case we actually get them simply from counting, so our learning of those parameters is really looking at a training data and counting how often we see cars on roads, cars on on trees, cars on grass, cars and everything else, and essentially what you do is you simply construct a matrix like this which you do offline and that matrix never changes.",
            "Which is exactly is of course what makes this MRF and.",
            "You come up with the structure, which of course has a lot of self similarity.",
            "When you over segment you get a lot of self similarity in terms of the kind of neighborhood smoothing, but you also in code that that intuitive feeling that ensure feeling that of course you've got to cars.",
            "You know these objects are somehow related to each other, so that's good constitutes environmental prior that you just get very easily, so there's not much fancy learning involved in this particular stage, but."
        ],
        [
            "It does the trick.",
            "Now, what does that actually biases the question right?",
            "So we start out with a scene and we extract this graphical model from it, and so before the MRF, this is just the first stage output.",
            "Let me just briefly mention the color coding here means kind of purple is kind of tarmac pavement.",
            "We've got the kind of yellow here.",
            "That's it's dirt track type of environment.",
            "Red is textured walls, blue is kind of smooth wall window type of arrangements and we can see this great thing.",
            "Here is car and we can see that the first stage to kind of get some things correct.",
            "But it gets if it makes a few blatant errors right?",
            "For example, the there's some wall in the car and you know the the path kind of extends quite a way up the wall etc etc.",
            "And what this this MRF smoothing buys us within this scene is literally looking at, for example, the neighborhood, these patches and flipping those mistakes to something more sensible given the immediate neighbors.",
            "So that's a fairly nice result.",
            "That's exactly the kind of thing that we that we tried to."
        ],
        [
            "Of course, once you've got one of these graphs in a particular scene, you can extend this whole thing through time, which is another benefit of having this continuous workspace, and you can introduce essentially these red links across you know, frame to frame or from.",
            "Kind of skipping A-frame and you come up with this kind of filtering type of type of thing or this proper propagating sliding window type approach where you say OK things that are things that are the same in two different frames you know that they think they're the same thing.",
            "They should have the same label, right?",
            "I mean the label doesn't change so you can encode that simply by coming up with another matrix and encoding that very naturally into the framework that we've already got.",
            "Right?"
        ],
        [
            "OK, so in terms of results, what we've done is trained this up using.",
            "I don't know about, so this is assisted.",
            "The Jericho datasets from from Oxford, about 30 kilometres of track heaps of points, so heaps of images, many, many more heaps of points.",
            "So that's where we start training.",
            "We used a non overlapping set for."
        ],
        [
            "Sting and this is the."
        ],
        [
            "I think the system typically produces so on here we've got the original scene.",
            "Over here we get the.",
            "We get to the actual classification down.",
            "Here is the legend.",
            "What the what the.",
            "What the colors mean and those labels are then generated automatically simply by by performing clustering in the in the kind of in the pixel space.",
            "But we see we kind of get some fairly consistent classifications, agenda vehicles pick up a textured walls over there.",
            "We were fairly fairly good with the tarmac bits over here.",
            "We pick up the grass left and right here to some extent.",
            "Yeah, and even kind of bushes in the side here.",
            "But then that flips back so we get some, get some decent results out of it."
        ],
        [
            "In terms of confusion matrices, what does it look like?",
            "So appear you've got ground truth and down here you've got the actual classifications and you've got two different confusion matrices here, because you have one for precision, essentially along the diagonal and one for recall.",
            "And we can see that that pre MRF serves the output of the first stage.",
            "We're doing OK on some of the larger classes.",
            "I should say that the data here is totally unbalanced, so this is as it comes in.",
            "We see a lot more things like, in a city.",
            "Then for example grass and this is reflected in those results, so we're doing reasonably well on on tarmac and kind of textured walls and things like that in terms of precision.",
            "There's a lot of confusion between the walls.",
            "There's a lot of confusion between Bush, foliage vehicle and things like that.",
            "In terms of precision and also in terms of recall, now a home run results would of course be a completely diagonal matrix."
        ],
        [
            "Or two completed diagram matrices and this is what happens.",
            "It doesn't compute diagonal, but this is what happens after the after the MRF smoothing.",
            "So this is before and this is up there.",
            "We can see there's a market.",
            "Movement of the mass towards the diagonal, which is which is a nice result."
        ],
        [
            "So what we can see is here, we kind of we get, we get away from a lot of the confusion regarding regarding the cars and we get a lot away from a lot of confusion.",
            "Kind of from tarmac and dirt path here.",
            "So that kind of shift from towards."
        ],
        [
            "Side note here, particularly it's quite nice in terms of the recall, the benefits are."
        ],
        [
            "Less pronounced because you actually what you do is you over smooth small classes.",
            "That's part of the problem that you have with this.",
            "So what you find is."
        ],
        [
            "That, for example, you don't see much grass.",
            "You will find that the MRF will actually misclassify a couple of things as notgrass and then over smooth."
        ],
        [
            "Them as being correct so we actually misclassify alot of things they were grass as things like thomachan pay which is a side effect of the."
        ],
        [
            "Ticular population of this."
        ],
        [
            "In terms of numbers pre MRF so precision and recall.",
            "These are kind of the F5 numbers.",
            "We see that simply using spatial contexts only within a scene.",
            "We get some fairly significant gains, sometimes up to double double digit percentages.",
            "The thing that I said about over smoothing is also reflected here in terms of the grass.",
            "For example, where we see that the F measure actually goes down, we're just not not desirable, but that only happens for that.",
            "I will see that we actually gained even more from the from kind of folding into the spatial context, which is sort of the temporal context over here, which again is not really surprising, but it's nice to see it, actually."
        ],
        [
            "In terms of the time that it takes back then about a year and a half ago, we used to have real time constraints imposed by how long the robot takes to actually get the acquire the 3D point cloud, which was about 3 seconds which we needed classification.",
            "Then we see that in this particular case, on average the classification itself wasn't actually the constraint anymore, which was also nice thing.",
            "But again, 3 seconds nowadays is also having this old constraint."
        ],
        [
            "Alright, so given what we've seen, we've come up with something that's kind of, you know, it's principle is probabilistic, and it does, you know, have nice things in terms of context."
        ],
        [
            "And we have a."
        ],
        [
            "Detective model."
        ],
        [
            "We can actually learn."
        ],
        [
            "Things online fact every time we run this up, we learn the model of fresh in a matter of, you know, fractions of seconds, which is which is interesting.",
            "And two with respect to this old condition old restriction, we can actually do this in real time.",
            "OK, so.",
            "Back to back to the system and how it relates to to this to this workshop because really, I've told you all the things that are great about it, that all things that work about it but."
        ],
        [
            "This thing that haven't been talked about and this is one of the one of the single worst results that we got."
        ],
        [
            "The system and looking at it, it's terrible.",
            "It's terrible because you see that things that are classified or that could be distinguished quite easily by a single feature in our feature space simply by looking at the surface normal completely fall apart.",
            "In this particular case, and we looked at this and that kind of gave us a lot of hassle and we kind of ponder this quite a bit and we thought we use different features so we can rewrite the whole thing with a very elaborate feature set and it didn't make it go away and what what it turns out is.",
            "That one thing that we're not learning properly in this model is the waiting between these individual individual feature dimensions, the individual modalities.",
            "So if we if the system had properly acquired those those weightings, what you would figure out is that the in this case the surface normal would actually override the fact that this thing is really, really yellow.",
            "Farm.",
            "And that kind of thing we haven't actually managed to to make go away.",
            "And of course, in a very direct sense, this is this person and for what we're going to talk about here today, how are we going to integrate that information?",
            "I don't actually have a have a good answer for it.",
            "I'm looking forward to talking about it.",
            "And yeah, so there's a whole bunch of bunch of issues with it that are directly applied."
        ],
        [
            "Click over here.",
            "In fact, we've done some prior work on both VM's which use exactly the same data, exactly the same features and we can see that simply with devoted SVM classifier we seriously outperform this probabilistic classifier and our first stage classifier that we that we talked about.",
            "Of course, once we pull in the MRF smoothing, we kind of get back to similar ballpark, but of course is kind of unfair comparison because devoted SPM doesn't have this Emirates moving on the flip side of that is of course that you could use the voted SVM directly as a first step.",
            "First stage classifier or any ranking classifier for that matter, so the whole system kind of still holds, which is which is nice.",
            "So that that that particular sensation of the probabilistic classifier something we"
        ],
        [
            "We just experimented with alright, so in terms of the conclusions with respect to this workshop, I think one of the important things that I want to stress again is the fact that we have.",
            "We have this this benefit that we have this continuous workspace.",
            "Many sensors pointing at everything that we can and should really use.",
            "In fact, clean out the window and say some of the robotics applications that we look for really dim and sensor integration.",
            "Something that people often ask me about, strangely enough, is kind of driving a day and at night and again, you know, sometimes laser scanners are simply.",
            "A more direct way of measuring things than for example cameras, but another obvious in my mind at least.",
            "An example for that is kind of close range and long range reconstruction.",
            "Stereo is very good at close range, but if you want to look at, you know 10s tens, 50 meters or so.",
            "You will need to use a liter of some shape, but how to combine them?",
            "How to switch between them?",
            "Can you?",
            "Can you combine them in some sensible way so a lot of things like that we face in robotics?",
            "Of course we can use a lot of machinery developed in machine learning and statistics, and it's awesome.",
            "We have seen you know many probabilistic methods graphical models we all use kind of discriminative and generative classification models.",
            "We use regression models etc etc, but I think it's really important to realize that we do have different constraints then a lot of the machine learning and machine vision people out there.",
            "One of them, the most obvious one is we often retire require real time operation, and that's not really something that that is a priority in machine learning.",
            "When they develop algorithms, the thing that's really close to my heart is action selection and very closely coupled with that is, you know the meaning of uncertainties that we get out of these systems if you ask yourself the question.",
            "If you design A robot that kind of traverses, traverses, Rd.",
            "How much do you?",
            "How much would you trust your car detector?",
            "Would you actually switch on the press the autonomy button and let it go across the road on its own?",
            "And if you ask me, the answer is hell no.",
            "But if you have if your answer is yes, please come and see me because I would really be interested in how you do it.",
            "Yeah, so the bottom line is that we have a lot of scope.",
            "There's been a lot of work done, but there's a lot more to be done in terms of integration of of information in terms of Q integration, what level do we work at?",
            "Terms of transfer learning.",
            "Some works being being done there now in robotics as well, and of course domain adaptation, but it's wide open, so let's let's do that.",
            "Alright."
        ],
        [
            "And that's it.",
            "Thank you.",
            "See you tomorrow.",
            "Some sort of link?",
            "Yeah so.",
            "OK, I was going to show this video but OK. Well if you go back, if you if you think back to the to the scene when you come up with the segmentation is actually very simple.",
            "So what you do is you literally look at what segments border on each other and if there is a direct connection you just put a link in.",
            "If there isn't, you don't.",
            "That's that's how simple it is in terms of the temporal aspect.",
            "It's a.",
            "It's a different set of links in that in that respect, but really So what we have is we have the laser data and we can project the same laser data into different consecutive images.",
            "Because you know that the laser data is the same, you know that the points at the flick reflections come from the same point in space, so you know that these classifications need to be consistent.",
            "And once you know that, you can enforce that in the in the in the model.",
            "It's about words.",
            "Do the words that Christian shortly.",
            "Since you have the old imagine I see reduction steps before.",
            "It's a good question so.",
            "In this particular case, we decided to cluster on the original feature space simply because we had a very good like very tight control over what the feature space was.",
            "In terms of, I mean, there weren't many of them was about 35 of them.",
            "Would I would I do dimensionality reduction of this?",
            "I don't know.",
            "I'm not sure in this particular context what it would buy me, but it may well be that that is beneficial, like I don't know whether that would make a difference in this particular context.",
            "Does that does that answer your question?",
            "I mean it's good, I don't know, but I mean well.",
            "I mean, what's your impression you think would make a difference?",
            "Sensation.",
            "Sensor data after the session.",
            "Pizza pizza recipe.",
            "OK and then only becoming manipulative.",
            "So I was wondering whether we could pass on this very global and compressing as first stage performance testing works.",
            "Something stinks.",
            "Yeah, so that's so.",
            "The whole bag of words idea comes from a from a very different domain, right?",
            "And essentially they started off with in text text processing and that's where the word word comes from.",
            "So yeah, do not.",
            "Do not confuse this term word with semantic meaning of words, so we don't expect any of these patches to have intrinsic semantic meaning.",
            "Of the of the word patches.",
            "So there's nothing like that.",
            "I mean, in terms of dimensionality reduction, I would do it if I fear that my learning algorithm would overfit in enormous feature space.",
            "I don't think I'm in particular we first did this.",
            "We did it with with SVM, so we didn't use clustering at all.",
            "We just classify directly on the feature space and 35 dimensions is really not not much given.",
            "I mean, we had also quite a lot of data for it, but 35 dimensions didn't.",
            "Didn't worries, but it may well be beneficial.",
            "I mean, yeah, I certainly think about it, but if you have anymore questions that would be interesting.",
            "OK, let's take this bigger game."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So good morning everybody.",
                    "label": 0
                },
                {
                    "sent": "It's a pleasure for me to start this workshop on learning for multiple sources with application to robotics.",
                    "label": 0
                },
                {
                    "sent": "I am Francesco Bona from India presearch Institute.",
                    "label": 0
                },
                {
                    "sent": "The topic that will.",
                    "label": 0
                },
                {
                    "sent": "Of this workshop will be learning from multiple sources.",
                    "label": 0
                },
                {
                    "sent": "In his general view.",
                    "label": 0
                },
                {
                    "sent": "Learning from multiple sources denoted the problem or joint learning from a set of partially related learning problem, and in this view it it is.",
                    "label": 0
                },
                {
                    "sent": "Basically, the most common, the most general idea that underlies problems has data Fusion, transfer learning, multitask learning, multi view learning and learning under covariate shift.",
                    "label": 0
                },
                {
                    "sent": "We will we will.",
                    "label": 0
                },
                {
                    "sent": "We will talk about theory and methods in this workshop, and in particular we will talk about robotics and natural application, another application, domain for learning from multiple sources.",
                    "label": 0
                },
                {
                    "sent": "We tried to divide the session more or less in two parts, so in the session in the morning will be the session for the robotic application or the application in general and we will start with the Invited tool core equal partner.",
                    "label": 0
                },
                {
                    "sent": "And then we will have the usual break and we will start again in the afternoon with the theory session.",
                    "label": 0
                },
                {
                    "sent": "The workshop will end with a discarded discussion in future direction meeting.",
                    "label": 0
                },
                {
                    "sent": "I think we can start now and where we can.",
                    "label": 0
                },
                {
                    "sent": "The first talk will be by the invited Speaker.",
                    "label": 0
                },
                {
                    "sent": "Equal Posner is a research assistant at the Oxford University.",
                    "label": 0
                },
                {
                    "sent": "And it will talk us about.",
                    "label": 0
                },
                {
                    "sent": "The use of multiple sources to create semantic Maps.",
                    "label": 0
                },
                {
                    "sent": "Alright welcome hello.",
                    "label": 0
                },
                {
                    "sent": "First of all, let me stop.",
                    "label": 0
                },
                {
                    "sent": "I am thanking the organizers very much for being invited.",
                    "label": 0
                },
                {
                    "sent": "I think this is a great topic for a workshop.",
                    "label": 0
                },
                {
                    "sent": "Also, it's obviously brilliant setting, and there's a longstanding longstanding well established conference, so it doesn't happen often that you go through security at the airport and people just wave you through going.",
                    "label": 0
                },
                {
                    "sent": "Oh yeah, you go into this artificial learning thing, OK, just keep on going, so that's that's nice.",
                    "label": 0
                },
                {
                    "sent": "It doesn't happen often robotics.",
                    "label": 0
                },
                {
                    "sent": "And putting together these slides, we really, really thought about the kind of communities that we that we tried to straddle in the audience here.",
                    "label": 0
                },
                {
                    "sent": "And we do see a couple of you know, friendly, familiar faces from the robotics community, but also some of the things that we use.",
                    "label": 0
                },
                {
                    "sent": "Obviously I'm very much inspired by machine vision, very much inspired by machine learning, and it's a privilege very much to to go first today, because I think I can possibly add or help set the scene of it simply by bridging the gap between between these communities to a certain extent.",
                    "label": 0
                },
                {
                    "sent": "And so some of the things that you will see depending on what community or from will be somewhat familiar to you will be probably thinking that we do this.",
                    "label": 0
                },
                {
                    "sent": "And whatever you know, our community is quite regularly quite a lot.",
                    "label": 0
                },
                {
                    "sent": "I have been trying to pull it out.",
                    "label": 0
                },
                {
                    "sent": "They'll draw it out in such a way that there's never coincide.",
                    "label": 0
                },
                {
                    "sent": "So when you see something that's familiar opening for the find, a lot of the other parts are quite interesting to you.",
                    "label": 0
                },
                {
                    "sent": "Now the the main title and the main topic of the talk, the bulk of the talk, really is what was mentioned in the introduction just now.",
                    "label": 0
                },
                {
                    "sent": "The semantic mapping.",
                    "label": 0
                },
                {
                    "sent": "Of urban environments, because we very much are interested in in mapping and an outdoor kind of urban environments in the group that I'm from and before I start actually talking about this subject, I thought I kind of talk about the things that we commonly see in terms of sensor integration in robotics, so there's going to be a bit of a pre lude sort of speak about the kind of things that we do, and kind of the kind of things that we that we commonly see.",
                    "label": 0
                },
                {
                    "sent": "So for those of you who aren't in robotics, this is the kind of things that we do.",
                    "label": 0
                },
                {
                    "sent": "We are.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Very much about outdoors them very much about Samson.",
                    "label": 0
                },
                {
                    "sent": "Herbs.",
                    "label": 0
                },
                {
                    "sent": "Actually in the field we have several different sensor platforms, so we have a Segway here and an 80 LB junior here.",
                    "label": 0
                },
                {
                    "sent": "And these things carry a whole lot of a whole bunch of sensors, so at the top here we've got the Omni directional current camera.",
                    "label": 0
                },
                {
                    "sent": "It's a lady bug, we have a stereo rig right there forward looking.",
                    "label": 0
                },
                {
                    "sent": "We have two laser scanners to besides the kind of scan like this and we troll them through the environment like so.",
                    "label": 0
                },
                {
                    "sent": "To get essentially range and intensity out, and of course there's various on board computers etc etc.",
                    "label": 0
                },
                {
                    "sent": "We also have a similar kind of setup on this slightly older older robot.",
                    "label": 0
                },
                {
                    "sent": "Here we actually get 3D laser data from an inherently 2D scanner that rocks up and down, so it takes somewhat longer to acquire an entire 3D scene.",
                    "label": 0
                },
                {
                    "sent": "Build.",
                    "label": 0
                },
                {
                    "sent": "The advantage here is of course it's forward looking for it, so it's quite useful.",
                    "label": 0
                },
                {
                    "sent": "Also ever have a camera on board here?",
                    "label": 0
                },
                {
                    "sent": "That kind of takes takes pictures every couple of meters and these things kind of generally.",
                    "label": 0
                },
                {
                    "sent": "Gently go round, go round Oxford really.",
                    "label": 0
                },
                {
                    "sent": "And before anybody asks, they actually remote control so they're not autonomous.",
                    "label": 0
                },
                {
                    "sent": "You know we don't need them out of our sight or out of easy reach of the emergency.",
                    "label": 0
                },
                {
                    "sent": "Shut up.",
                    "label": 0
                },
                {
                    "sent": "I mentioned some of the sensors, there's other sensors and other platforms that we get.",
                    "label": 0
                },
                {
                    "sent": "I mean, I'm used.",
                    "label": 0
                },
                {
                    "sent": "GPS is typically get wheel encoders that codes odometry movements trying to estimate where you are in the world though their noisy so we can use other other sensors to actually measure the same thing and infuse these measurements together.",
                    "label": 0
                },
                {
                    "sent": "It's actually very very big topic in reported.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, this is the kind of data that we get out.",
                    "label": 0
                },
                {
                    "sent": "So what we see up here is the stereo feed.",
                    "label": 0
                },
                {
                    "sent": "The two frames there.",
                    "label": 0
                },
                {
                    "sent": "We kind of matched individual features and get out essentially visual odometry for all intensive purposes for this talk and there's a system that was developed by game.",
                    "label": 1
                },
                {
                    "sent": "Simply increase may in our group and was published at one of these conferences this year and it's really, really quite accurate over quite a quite a long way.",
                    "label": 0
                },
                {
                    "sent": "What you see down here is essentially the trajectory of the robot as it goes around.",
                    "label": 0
                },
                {
                    "sent": "In this case, one of those colleges, new college.",
                    "label": 0
                },
                {
                    "sent": "So this is the kind of this kind of thing that we that we get from the from the stereo down.",
                    "label": 0
                },
                {
                    "sent": "Here is the typical rendering of the 3D data that we get as we kind of go through the environment and what you see is again range and intensity and this is rendered relative to where we think or where the robot thinks it currently is based on information from the wheel encoders based on information from the visual dormitory etc.",
                    "label": 0
                },
                {
                    "sent": "And the detail that we get from this kind of information is really quite quite astonishing.",
                    "label": 0
                },
                {
                    "sent": "This again is just rendered from from local.",
                    "label": 0
                },
                {
                    "sent": "Local traverse just just based on the dormitory and you can see that can even like reflective parts.",
                    "label": 0
                },
                {
                    "sent": "Obviously shine very brightly in this sort of modality and even read number plates etc etc.",
                    "label": 0
                },
                {
                    "sent": "So that's that's that was quite nicely with that that data first.",
                    "label": 0
                },
                {
                    "sent": "This down here is just an example of the of the pictures that we get from the directional camera.",
                    "label": 1
                },
                {
                    "sent": "There are five or six different cameras in their actual device kind of space at regular intervals.",
                    "label": 0
                },
                {
                    "sent": "And here in this particular case, the cameras mounted on top of a car.",
                    "label": 1
                },
                {
                    "sent": "So one of our guys Mark Mark Cummings going to car around Oxfordshire and around Britain in general in the end.",
                    "label": 0
                },
                {
                    "sent": "Collected this sort of data as well as stereo data.",
                    "label": 0
                },
                {
                    "sent": "He was going around.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "That's an impression of the kind of thing that you that you get.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "Slide three or four and we're already at one of the main points that I think are important.",
                    "label": 0
                },
                {
                    "sent": "It is nothing new, but I think it's important to kind of, you know, put in words and then put put on this slide, which is really the realization that is roboticists were quite privileged.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The correct privilege in the sense that we have.",
                    "label": 0
                },
                {
                    "sent": "A system, a platform that carries for us many centers, many different modalities through the same contiguous workspace, and that sets us apart from a lot of other other domains, such As for example, machine vision.",
                    "label": 0
                },
                {
                    "sent": "Where yes, you can get video etc etc.",
                    "label": 0
                },
                {
                    "sent": "But we have these other modalities sometimes.",
                    "label": 0
                },
                {
                    "sent": "Often when you kind of work with random image collections these.",
                    "label": 0
                },
                {
                    "sent": "Workspaces aren't contiguous, etc etc, and there's a.",
                    "label": 0
                },
                {
                    "sent": "There's a lot of things that we can actually do, and that we can benefit from that.",
                    "label": 0
                },
                {
                    "sent": "Other domains have have a harder time to access.",
                    "label": 0
                },
                {
                    "sent": "And of course, very pertinent to this workshop is that this really provides ample scope for combining information from different sensors.",
                    "label": 1
                },
                {
                    "sent": "One thing that's been done for a long, long time is booked under data Fusion, particularly in the context of of mapping and navigation.",
                    "label": 0
                },
                {
                    "sent": "In this problem of simultaneous localization and mapping, there's going to be a slide on that in a minute, so I briefly explain what that actually means, but the idea really is to create a representation of an environment as well as a representation of where you are in that environment.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Once you have that, there are other things we can we can build on top of that.",
                    "label": 0
                },
                {
                    "sent": "For example, appearance based methods have become very prominent in robotics.",
                    "label": 0
                },
                {
                    "sent": "You can use those from from based on videos on cameras, on images, you can use those to constrain things in your mapping process.",
                    "label": 0
                },
                {
                    "sent": "In your metric mapping process.",
                    "label": 1
                },
                {
                    "sent": "One problem that was prominent in robotics for a long time is the loop closure detection problem.",
                    "label": 0
                },
                {
                    "sent": "I will talk again in a single slide about how we can help in terms of in terms of appearance based methods, but once again this is a is an example of how we fuse different modalities or fuse information.",
                    "label": 0
                },
                {
                    "sent": "But different melodies, you can turn the whole thing around.",
                    "label": 0
                },
                {
                    "sent": "You can say we've got a a metric kind of mapping task and we use.",
                    "label": 0
                },
                {
                    "sent": "Sorry, we've got a topological type of mapping task and we swap it around that.",
                    "label": 1
                },
                {
                    "sent": "We introduced geometric constraints into that topological mapping task, again fusing different sources of information.",
                    "label": 1
                },
                {
                    "sent": "There's a more sensor based or a more directly sensor.",
                    "label": 0
                },
                {
                    "sent": "Based.",
                    "label": 0
                },
                {
                    "sent": "Version of the same kind of idea, where essentially we talk about sensor augmentation, which is a very straightforward kind of thing.",
                    "label": 0
                },
                {
                    "sent": "Again, there's gonna be light on it, and then of course there is.",
                    "label": 0
                },
                {
                    "sent": "There's Q integration, which is where a lot of work is done and has been done and is yet to be done about how we actually properly integrate information from these different modalities.",
                    "label": 0
                },
                {
                    "sent": "Ultimately, in about 5 six slides from now we work that I'm talking about in terms of the semantic mapping.",
                    "label": 0
                },
                {
                    "sent": "Very much sits in the centre or mentation bit, and to some extent in a very basic way in the.",
                    "label": 0
                },
                {
                    "sent": "Q Integration part of this, but we'll get there in a minute, but let's talk about the kind of things that we currently that we commonly see in robotics in terms of sensor integration, so.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is this is directed at the slam idea, the simultaneous localization and mapping idea, and really the goal is to come up with a faithful representation of an environment as well as your trajectory through it.",
                    "label": 1
                },
                {
                    "sent": "So what you see here is an almost plan view of the 3D laser Maps of the kind of thing that we saw in the second slide.",
                    "label": 0
                },
                {
                    "sent": "Where you are, the robot went around the outside of the engineering triangle in Oxford, which is about half a kilometers worth of track.",
                    "label": 0
                },
                {
                    "sent": "And here you see blowup of that, so you can very nicely see there's a bunch of steps here which is the entrance door to our building.",
                    "label": 0
                },
                {
                    "sent": "There's kind of a ramp that goes up here, and this is the kind of data quality needs to get in this particular thing.",
                    "label": 0
                },
                {
                    "sent": "Map was taken with Marge.",
                    "label": 0
                },
                {
                    "sent": "All our robots are called out of The Simpsons for reasons that sometimes elude me, but so much the ATV junior with a kind of rocking laser, which is where you kind of see this.",
                    "label": 0
                },
                {
                    "sent": "These stripes at the bottom because at some point when you invert the emotion you kind of get denser sampling at those points.",
                    "label": 0
                },
                {
                    "sent": "So this is a typical kind of example of a slam map.",
                    "label": 0
                },
                {
                    "sent": "Of course.",
                    "label": 0
                },
                {
                    "sent": "I should probably say so.",
                    "label": 0
                },
                {
                    "sent": "The way that we come up with these is essentially based on variance of Bayes filters, so common filters extended common filter's party for this, etc.",
                    "label": 0
                },
                {
                    "sent": "And we use different sources of odometry, so you can get take the wheel looking encoders and you can do things like scan matching from the laser scanners and all these things will give you ideas of how you've moved, refuse all them together in a box understanding Fusion way and this is what people in robotics have done for 1520 years, so.",
                    "label": 0
                },
                {
                    "sent": "Of course.",
                    "label": 0
                },
                {
                    "sent": "There's a bit of a hitch because before that map looked like this, mostly triangular.",
                    "label": 0
                },
                {
                    "sent": "We're just kind of that.",
                    "label": 1
                },
                {
                    "sent": "The real shape of the environment kind of look more like this.",
                    "label": 0
                },
                {
                    "sent": "And the problem is that this is the same environment is actually the same map with a with a plan.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And if you.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "At any individual bit of the map, you will see that this is actually it's reasonably accurate.",
                    "label": 0
                },
                {
                    "sent": "And these points were rendered simply from things like Wheeler Domitory.",
                    "label": 0
                },
                {
                    "sent": "And it turns out that one of the big problems that roboticists had is essentially that noise integrates.",
                    "label": 0
                },
                {
                    "sent": "So what that means is over short distances, we can get a Dominator measurements that are reasonably accurate, but as we go along, way, tiny errors in these odometry estimates accumulate to enormous errors, such that as we go around a big loop, we end up with an enormous bust where we really know this should be the same point in the map, and this is really the essence of the root cause of the problem, and it's kind of folks, people in the community for a long time.",
                    "label": 0
                },
                {
                    "sent": "Until fairly recently, people have come up with the idea that maybe we could use a different modality again to recognize whether we come to the same place and this is really the idea behind the system called fab map that came out of out of our group Mccommons implement developed this in various versions and it's really been very successful and recognizing whether you come back to the same place.",
                    "label": 0
                },
                {
                    "sent": "That allows you to do it allows you to put a constraint between this point at this point here.",
                    "label": 0
                },
                {
                    "sent": "Merge these together and spread the air around the rest of the map so you come up with a representation that we've just seen.",
                    "label": 0
                },
                {
                    "sent": "OK. Of course the cute the key thing here is that we have a sensor do to fix this problem.",
                    "label": 1
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so given that we have these these constraints that we can derive from abilities, these are the kind of reconstructions that we that we can come up with.",
                    "label": 0
                },
                {
                    "sent": "So this is a publicly available data set.",
                    "label": 0
                },
                {
                    "sent": "The new college data set from from Oxford.",
                    "label": 1
                },
                {
                    "sent": "This is the yellow.",
                    "label": 0
                },
                {
                    "sent": "Here you see the real the ground truth track of the of the robot.",
                    "label": 0
                },
                {
                    "sent": "Down here you see a metric reconstruction of that of the data set over about two 2.2 kilometres, and for all intents and purposes this is a really really.",
                    "label": 0
                },
                {
                    "sent": "Good representation of that of that environment in terms of in terms of accuracy.",
                    "label": 0
                },
                {
                    "sent": "So combining these different abilities allows us now to build fairly large scale metric Maps, but also over several kilometers.",
                    "label": 1
                },
                {
                    "sent": "But even larger scale topological Maps.",
                    "label": 1
                },
                {
                    "sent": "Where some of this method has been used to essentially build topological Maps Coast to coast in Britain.",
                    "label": 0
                },
                {
                    "sent": "So we're talking thousands of kilometres and for lack of a better metric to use, we've got the record of mega meter just because it's kind of consistent with the whole system.",
                    "label": 0
                },
                {
                    "sent": "But these are the kind of things that we get.",
                    "label": 0
                },
                {
                    "sent": "In terms of the reconstruction, so once we put all these things together we can go through the map that we've built the 3D map that we've built and pick out some very nice details like.",
                    "label": 0
                },
                {
                    "sent": "These trees are kind of foliage, and as you go around the kind of different building at the people and different kind of signs on the wall, I'm going to play more video later, so so that might be more interesting in a bit.",
                    "label": 0
                },
                {
                    "sent": "The other thing that we can do is.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This idea of sensor augmentation, where essentially is something very very straightforward, where essentially we take the cross calibration that we have from different sensors from the camera and from the lasers, and we associate every laser point, every range measurement that we get with the color simply by projecting the color part of the laser points into the into the camera image, and that gives you representations like this, which kind of look very nice, and they make very good videos when it comes to talk to sponsors, but there's inherent problem with this, which is which is very much addressed by the work I'm going to talk about in a bit.",
                    "label": 0
                },
                {
                    "sent": "The whole idea of assigning some higher order meaning to these things well, how does this fit in terms of in terms of the path in terms of the planning scenario in terms of the action selection scenario, which is really where where we want to get with.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You can take this and you can turn it around again and say, OK, well in the previous slide we've seen this augmentation.",
                    "label": 0
                },
                {
                    "sent": "We take any every range point, then we associated with every range point a color.",
                    "label": 0
                },
                {
                    "sent": "But what if we actually want to go the other way?",
                    "label": 0
                },
                {
                    "sent": "What we want to go from an image and some coarsely sampled range data, which is what you get, so you usually get one laser .1 range measurement for every kind of 1516 pixels.",
                    "label": 1
                },
                {
                    "sent": "What if we want to go from that to a fully dense range map, so with every pixel in the image we now want to associate a range measurement.",
                    "label": 0
                },
                {
                    "sent": "And of course you can do that sort of thing.",
                    "label": 1
                },
                {
                    "sent": "This is a synthetic.",
                    "label": 0
                },
                {
                    "sent": "A synthetic problem where essentially you've got some form of scenario with the intensity image associated with it and then kind of the square kind of ashtray type of type of shaped object here and the red dots are those sparse range measurements and you can say OK, well, we could obviously do is we could just take those measurements and we can interpolate.",
                    "label": 1
                },
                {
                    "sent": "So we come up with a with a normal kind of bilinear interpolation interpolation and we see that many of the important shapes aren't really preserved.",
                    "label": 0
                },
                {
                    "sent": "So for example the thing that.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This thing used to be square and now the whole thing spreads, spreads around in space.",
                    "label": 0
                },
                {
                    "sent": "And we got a whole lot of artifacts like that that we would rather want to avoid.",
                    "label": 0
                },
                {
                    "sent": "And once again we can use a different modality that the whole kind of imaging idea, and we can use this intuition that discontinuity's in things like intensity or color.",
                    "label": 0
                },
                {
                    "sent": "Not necessarily indicate, but allow for discontinuities in depth.",
                    "label": 0
                },
                {
                    "sent": "So we can come up with a more intelligent.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Interpolation method, which essentially preserves alot of the important shapes.",
                    "label": 0
                },
                {
                    "sent": "I mean it's far from perfect for some of the stuff is still there still kind of bend and curve curve but we get a lot better representation than just from just from straightforward interpretation of this data.",
                    "label": 0
                },
                {
                    "sent": "OK, so these kind of things are things that we do in our group.",
                    "label": 0
                },
                {
                    "sent": "There are things that people in robotics have been doing for quite a long time and this is the kind of thing that we usually that we often see.",
                    "label": 0
                },
                {
                    "sent": "In this sort of context.",
                    "label": 0
                },
                {
                    "sent": "OK, of course the whole thing.",
                    "label": 0
                },
                {
                    "sent": "So what we've seen so far is synthetic data.",
                    "label": 0
                },
                {
                    "sent": "This is kind of real real bit of data from outside, but there's a lot of planes here simply because it does for a good illustration we can see that it's a decent response.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's not perfect, but again, we kind of get the overall idea.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK. Alright, so this is the kind of thing that we that we commonly see, and now I'm going to talk about how we can take that further and why we want to talk about higher order semantic mapping and why we get into the classification of these data into things that we can possibly under.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And as as human beings and one of the reasons for that is really that these point cloud representations here, they're nice, and they make for the videos.",
                    "label": 0
                },
                {
                    "sent": "But in terms of of common things that we really want to do with robots, action selection and navigation planning human machine interaction, they're not really terribly useful, because really, all they are big and by three matrix.",
                    "label": 0
                },
                {
                    "sent": "So really, what we want is things like like seen labels.",
                    "label": 0
                },
                {
                    "sent": "We want to know about things in the world.",
                    "label": 0
                },
                {
                    "sent": "You know, grass, tarmac, pavement, or what kind of services we are kind of objects we have when we're crossing a Rd.",
                    "label": 0
                },
                {
                    "sent": "Want to see?",
                    "label": 0
                },
                {
                    "sent": "Can we see a car etc etc?",
                    "label": 0
                },
                {
                    "sent": "How safe is it?",
                    "label": 0
                },
                {
                    "sent": "These kind of things.",
                    "label": 0
                },
                {
                    "sent": "These are kind of questions that we're that we're moving towards and This is why.",
                    "label": 0
                },
                {
                    "sent": "Why this becomes a very natural problem to work on now.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "When we think about this, we.",
                    "label": 0
                },
                {
                    "sent": "We come to appreciate that there are certain things in robotics that we that we want from these methods.",
                    "label": 0
                },
                {
                    "sent": "One very big thing is that we we want uncertainty measures that are associated with our classifications.",
                    "label": 0
                },
                {
                    "sent": "So in this case we really we really after we like probabilistic methods simply because we get these kind of measures out.",
                    "label": 0
                },
                {
                    "sent": "Then we can employ the entire probabilistic machinery in combining information.",
                    "label": 0
                },
                {
                    "sent": "So this is something that we're very fond of.",
                    "label": 0
                },
                {
                    "sent": "Ideally things that we would like is certain degree of introspection.",
                    "label": 0
                },
                {
                    "sent": "We'd like to be able to handle.",
                    "label": 0
                },
                {
                    "sent": "Context in some in some respect, and of course we benefit a lot here from statistics and the vision community.",
                    "label": 0
                },
                {
                    "sent": "We've done heaps of work on that.",
                    "label": 0
                },
                {
                    "sent": "Also, a very important aspect for us is at least a handle on how.",
                    "label": 0
                },
                {
                    "sent": "On how good our measurements are, how much do you trust the sensor?",
                    "label": 0
                },
                {
                    "sent": "If you drive at night, would you rather put your trust in the vision sensor, or would you rather put your trust in laser?",
                    "label": 0
                },
                {
                    "sent": "It's up to you to certain extent, but it's nice.",
                    "label": 0
                },
                {
                    "sent": "Essentially have a have a handle on being able to to make a decision based on that of course.",
                    "label": 0
                },
                {
                    "sent": "Very important would also be that we can adapt our class models online, so if you see something you'd like to be able to handle it somehow rather than go home and spend the next three weeks training a new classifier.",
                    "label": 1
                },
                {
                    "sent": "So that was also something that that is on our list of desirable.",
                    "label": 0
                },
                {
                    "sent": "And of course we would like to do this whole thing in real time.",
                    "label": 0
                },
                {
                    "sent": "Answer That it's fast.",
                    "label": 0
                },
                {
                    "sent": "And this is also something that's not necessarily given if you if you take any any standard machine learning technique, you kind of have to have to be very careful with what kind of things you you select here, and the work that we're about to talk about now is very much a snapshot from this kind of from this kind of list where we decided, OK, this is the kind of things that we wanted to see.",
                    "label": 0
                },
                {
                    "sent": "How far how far we get through this.",
                    "label": 0
                },
                {
                    "sent": "So briefly, I'm going to talk about the the kind of processing the data that we get, and what we do with it and the beef.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It really is is here we talk about the different classification frameworks at the different different scales that we look at.",
                    "label": 0
                },
                {
                    "sent": "And of course I want to talk about some results and some of the conclusion.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we that we've drawn from it.",
                    "label": 0
                },
                {
                    "sent": "OK, so in terms of the processing pipeline is very similar to the kind of data that we've just seen.",
                    "label": 0
                },
                {
                    "sent": "We have a 3D laser Flowers with our robot command center here, and we take images of the same scene.",
                    "label": 0
                },
                {
                    "sent": "So that's the image that.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Correspond to that scene and back then, so this work is about a year and a half old.",
                    "label": 0
                },
                {
                    "sent": "Back then, one of the things that we did was argue that, of course, in man made environments there are some very predominant geometry, so that it will be for this.",
                    "label": 0
                },
                {
                    "sent": "So planes or some of them and we can use them for very crude.",
                    "label": 0
                },
                {
                    "sent": "Feature extractions in terms of quantifying the 3D geometry oversee so the first thing we do here is a is a plane extraction plane segmentation.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And because we have the cross calibration, we actually know the viewing frustum of the camera.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we can take that.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And essentially project those camera points into the image and just just for completeness, let me say that so that the different colors here of the points indicate plane memberships, nothing to do with classes yet OK?",
                    "label": 0
                },
                {
                    "sent": "Again, this is a very kind of standard trick.",
                    "label": 0
                },
                {
                    "sent": "To be done.",
                    "label": 0
                },
                {
                    "sent": "OK, now once we're in this position, once we actually have these points in the image, we can apply any machine vision technique that we like that is based on interest points and kind of local local patches to move forward from that.",
                    "label": 0
                },
                {
                    "sent": "So we just treat these laser pointers points of interest.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But Interestingly, we can.",
                    "label": 0
                },
                {
                    "sent": "Actually we can feed information from the image back into this plane segmentation.",
                    "label": 0
                },
                {
                    "sent": "So if you consider that we have a C and we do everything that we just that we just said which essentially is project these points into into that scene where there.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You in the red essentially extend outside the the viewing frustum of the camera.",
                    "label": 0
                },
                {
                    "sent": "We can then look at this and think, OK, well, what kind of classes might we be interested in?",
                    "label": 0
                },
                {
                    "sent": "And we can say OK, well, dirt tracks kind of interesting 'cause something to travel on grass is also kind of interesting because something not to travel on.",
                    "label": 0
                },
                {
                    "sent": "And if we then look at this segmentation we see that, well, these planes really straddle both of those classes, so it's not really clear how we how we how we separate them.",
                    "label": 0
                },
                {
                    "sent": "We can't just classify a plane and be done with it.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what we can do is again use a standard machine vision technique.",
                    "label": 0
                },
                {
                    "sent": "We can.",
                    "label": 0
                },
                {
                    "sent": "We can use the intuition that things that look the same are likely to be of the same class, so we can use a any off the shelf image segmentation algorithm and over segment the image, which is fairly easy to do, so we're not after an exact segmentation.",
                    "label": 0
                },
                {
                    "sent": "We often over segmentation and we can say OK well.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We can project the same laser points into this segmented image.",
                    "label": 0
                },
                {
                    "sent": "And we can then repartition these laser points.",
                    "label": 0
                },
                {
                    "sent": "These kind of planes into their membership of different segments in the segmented image and what you end up with is this sort of this sort of.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this green playing here has now been split up into points that apply in this segment, and points that lie in this segment appointments this segment.",
                    "label": 0
                },
                {
                    "sent": "And if we take that in the projective back into the original image, we find that we've now actually come up with a representation that very closely follows this paradigm where we have one set of of points 11 entity to work with with respect to a single a single class.",
                    "label": 0
                },
                {
                    "sent": "So what we end up working with is these patches or super pixels with.",
                    "label": 0
                },
                {
                    "sent": "Of course their appearance information associated with it.",
                    "label": 0
                },
                {
                    "sent": "But also some 3D geometry information associated with it.",
                    "label": 1
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so once we once we have that what we do is we encoded in a standard bag of words representation, which is probably very familiar to a lot of people here.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But to just briefly summarize this so we we take the scene we now operate on these.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Pixels.",
                    "label": 0
                },
                {
                    "sent": "Every point we treat as a point of interest, so we try to extract local regions around it.",
                    "label": 0
                },
                {
                    "sent": "We then.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Go on an encode these local regions according to some descriptor and essentially can be descriptive.",
                    "label": 0
                },
                {
                    "sent": "Your choice.",
                    "label": 0
                },
                {
                    "sent": "I'm going to talk about what we used in the second.",
                    "label": 0
                },
                {
                    "sent": "Some very, very simple features simply because we wanted to compare it with some prior work and we wanted to be reasonably fast.",
                    "label": 0
                },
                {
                    "sent": "You compute these descriptors.",
                    "label": 0
                },
                {
                    "sent": "You then.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Quantize these descriptors according to some what we call a vocabulary.",
                    "label": 0
                },
                {
                    "sent": "Essentially clusters in this feature space, which we learned offline, so you quantize them every single, every single descriptor to one of those clusters.",
                    "label": 0
                },
                {
                    "sent": "These clusters are called words.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Whole thing is called the dictionary and what you end up with is for every one of these patches, essentially binary vector indicating zeros and ones for every single one of those clusters.",
                    "label": 0
                },
                {
                    "sent": "So a particular here cluster, one word one we've seen in this Patch where two we've seen were three, we haven't etc etc etc.",
                    "label": 0
                },
                {
                    "sent": "And the length of that vector.",
                    "label": 0
                },
                {
                    "sent": "The dimensionality of the vector essentially off of the size of the vocabulary of the number of clusters that you have in that in that space.",
                    "label": 0
                },
                {
                    "sent": "The nice thing about that is of course that you end up with a with a very uniform representation of your of your world of your segments, irrespective of the segment size and the number of points.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, in terms of features again, these are very very basic.",
                    "label": 0
                },
                {
                    "sent": "In terms of the 3D geometry, So what you see here, I should probably say is extraction of the feature matrix.",
                    "label": 0
                },
                {
                    "sent": "We see kind of the feature number here and the type of the type of class that we might be interested in in terms of 3D geometry.",
                    "label": 0
                },
                {
                    "sent": "The obvious thing to users, for example the surface normal, which is the first column here and you can see that the surface normal very nicely separates things like ground from things like non ground, say in terms of 2D geometry we use things like normalized X&Y position in the image color histograms, Hue and saturation.",
                    "label": 1
                },
                {
                    "sent": "And a very, very crude indicator, not even measured like an indicator of texture, simply encoded as part of the part of the histogram is already, so that's the kind of thing that we use.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright.",
                    "label": 0
                },
                {
                    "sent": "Those are the features that we use.",
                    "label": 0
                },
                {
                    "sent": "That's the kind of data processing that we do.",
                    "label": 0
                },
                {
                    "sent": "Let's talk about the classification part.",
                    "label": 0
                },
                {
                    "sent": "And really, what we do is we kind of look at this as a two stage problem.",
                    "label": 0
                },
                {
                    "sent": "First of all, we're interested in extracting these these segments and coming up with classifications for these segments.",
                    "label": 0
                },
                {
                    "sent": "But then there's actually another level on top of that that encodes the whole intuition that you see objects in the world in context.",
                    "label": 0
                },
                {
                    "sent": "So, for example, you would expect to see a car on road, and if you see something that kind of looks car like on something that really is very likely to be grass, you would think well.",
                    "label": 0
                },
                {
                    "sent": "If it looks a bit like on a good like tree is probably more likely to be true.",
                    "label": 0
                },
                {
                    "sent": "'cause you see a lot of tree on grants and it is this kind of information that we try to capture in this in the second stage and the the obvious way to do that is with a graphical model which we construct from the images and also through time, but we'll get to that in a couple of slides.",
                    "label": 0
                },
                {
                    "sent": "So well.",
                    "label": 0
                },
                {
                    "sent": "First of all, talk about how we actually classify these individual these individual patches, and at this stage of of this work.",
                    "label": 0
                },
                {
                    "sent": "I mean you can.",
                    "label": 0
                },
                {
                    "sent": "You can use pretty much any ranking classifier for this that you want at this stage of the work we essentially decided to.",
                    "label": 0
                },
                {
                    "sent": "To play with probabilistic bag of words classifier but is very closely related to what's known as a tree augmented Naive Bayes classifier.",
                    "label": 0
                },
                {
                    "sent": "I don't know whether you were familiar with that, but you'll get the hang of it in a couple of slides I think.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "OK, so we start up with.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Our class model, in this case, our classes, are represented by exemplars, so concretely, what that means is every class has a bunch of instance.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Creations that come from labor from labeled data.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Every class is NK.",
                    "label": 0
                },
                {
                    "sent": "Every class K as a NK of those, and it can be different number over the different number of classes.",
                    "label": 0
                },
                {
                    "sent": "So that's not a problem.",
                    "label": 0
                },
                {
                    "sent": "And really, in terms of notation, the way we represent that is by a class.",
                    "label": 0
                },
                {
                    "sent": "Is this math Cal Super K is represented by a whole bunch of examples.",
                    "label": 0
                },
                {
                    "sent": "That's what these guys are.",
                    "label": 0
                },
                {
                    "sent": "So want to NK.",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                },
                {
                    "sent": "Once we have that.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The question is, how do we actually represent these individual exemplars?",
                    "label": 0
                },
                {
                    "sent": "And I apologize here because I rotation is slightly abusive, but it's really meant to to make clear what's going on here.",
                    "label": 0
                },
                {
                    "sent": "Every exemplar is literally represented by a set of probabilities, and these probabilities are probabilities over a hidden layer of variables E, where intuitively stands for existence.",
                    "label": 0
                },
                {
                    "sent": "And really, the idea is that Ian codes generator for a particular word at a particular at a particular example are so for example, in this particular case, here you've got.",
                    "label": 0
                },
                {
                    "sent": "Generator for word one.",
                    "label": 0
                },
                {
                    "sent": "Given this example are this example here and what that means is that if you had a perfect sensor.",
                    "label": 0
                },
                {
                    "sent": "If you had a perfect sensor that picks up this this feature every time that it exists.",
                    "label": 0
                },
                {
                    "sent": "Then you then then this E will indicate that actually you get.",
                    "label": 0
                },
                {
                    "sent": "You get detection for this.",
                    "label": 0
                },
                {
                    "sent": "So it means that there is actually something that gives rise to this particular feature.",
                    "label": 0
                },
                {
                    "sent": "Weather sensor picks it up or not.",
                    "label": 0
                },
                {
                    "sent": "And the nice thing about this is actually twofold.",
                    "label": 0
                },
                {
                    "sent": "The immediate result of that is that we can come up with detector model where essentially we can say we do not assume a perfect sensor, but we say well given given that a generator for that particular word exists, there is still a chance we might miss it.",
                    "label": 1
                },
                {
                    "sent": "And that's nice because relating back to that list that we just talked about.",
                    "label": 0
                },
                {
                    "sent": "Earlier this kind of list of desirables it gives us exactly this handle on knowing how good or how much we trust our individual sensor.",
                    "label": 0
                },
                {
                    "sent": "So you can imagine you've got one of these for every modality you can imagine you've got one of these for every individual word you can imagine that with different environmental conditions like lightness, darkness, etc.",
                    "label": 0
                },
                {
                    "sent": "This kind of trust changes, so that's a that's a nice feature to have.",
                    "label": 0
                },
                {
                    "sent": "Couple of in a couple of minutes we'll see that.",
                    "label": 0
                },
                {
                    "sent": "The other thing that this E allows us to do is really take a very simple model of Patch appearance of kind of super pixel appearance and blended with a more elaborate with a more elaborate model of Global words Co occurrence.",
                    "label": 0
                },
                {
                    "sent": "But we will get there.",
                    "label": 0
                },
                {
                    "sent": "We'll get there in second.",
                    "label": 0
                },
                {
                    "sent": "OK, so I think one of one of the best ways of actually illustrating.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What we're doing here is going through through the process, so we start out by saying, well, we've got our class model and we've got got all that trained up.",
                    "label": 0
                },
                {
                    "sent": "We get in a new observation and we encoded as we've talked.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, we end up with this kind of indication vector with the observations at this.",
                    "label": 0
                },
                {
                    "sent": "Just this binary vector and the obvious question then, is what class is it?",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And you can answer that simply by.",
                    "label": 0
                },
                {
                    "sent": "Well, we can start answering that simply by writing down.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Jewel, where you have a.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Posterior over class.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Given the new observation and of course that.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Proportional to the product of the the class prior, which is very easily obtained simply by looking at at label training data and counting.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And a class likelihood term, and the tricky bit really is obtaining this class like or calculating computing.",
                    "label": 0
                },
                {
                    "sent": "This class likely return, so the next couple of slides will take that initially Peter apart like like an onion and talk about how we how we get there.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Oh OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We are now concentrating.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We are now concentrating on this term right here, so we kind of.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That in mind, so.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Next",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Next slide here is exactly exactly the term, and it turns out of course we can.",
                    "label": 0
                },
                {
                    "sent": "We can expand that out since there's an integration over Exemplar, so we start out with the condition on the class.",
                    "label": 0
                },
                {
                    "sent": "We now have it in terms of the exam class, and we make two assumptions.",
                    "label": 0
                },
                {
                    "sent": "One is that none of the training data on these labels, which is a fairly common assumption to make.",
                    "label": 0
                },
                {
                    "sent": "Which essentially means that we kind of lose this term here and the second assumption is that all examples within a class are equally likely, and what that means is that essentially end up with this with this average essentially here, but we lose this.",
                    "label": 0
                },
                {
                    "sent": "This class term from this first expression, which means we end up with this term here, which is nice, because now we have we moved away from this dependency on the actual class and were directly looking at the dependency on the actual examples on the actual data, that's good.",
                    "label": 0
                },
                {
                    "sent": "OK, so now we can straighten this term here.",
                    "label": 0
                },
                {
                    "sent": "What do we do about this?",
                    "label": 0
                },
                {
                    "sent": "Well, in order to evaluate this, we need to know something about the actual distribution of observations.",
                    "label": 0
                },
                {
                    "sent": "The joint distributions of all Zeds, and that's kind of tricky because there's a lot of them.",
                    "label": 0
                },
                {
                    "sent": "So vocabulary sizes you know anything between two 200,000 words, pretty big distributions, and we essentially can live at one of two extremes or anywhere in between.",
                    "label": 0
                },
                {
                    "sent": "For that matter.",
                    "label": 0
                },
                {
                    "sent": "One extreme would be to say, well, we could do a naive Bayes approximation, which essentially says, well, all of these words are independent.",
                    "label": 0
                },
                {
                    "sent": "The other approximation says OK. Actually the other thing is not an approximation at all, it's it's the exact factorization of that enormous joint distribution, including all the higher order terms.",
                    "label": 0
                },
                {
                    "sent": "And of course, now you phase means we assume that the absolute independent and there's no structure in it.",
                    "label": 0
                },
                {
                    "sent": "Coming up with a full joint would be awesome, but of course is intractable.",
                    "label": 0
                },
                {
                    "sent": "So the question is, can we live somewhere in between?",
                    "label": 0
                },
                {
                    "sent": "And of course, intuitively, we know that these kind of words could occur, so this is a representation.",
                    "label": 0
                },
                {
                    "sent": "Here we have word 28 and 119 and word 741.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We know that different bits of the environment give rise to a combination of words.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we know intuitively that these words don't occur in dependently.",
                    "label": 0
                },
                {
                    "sent": "So can we come up with a better with a better representation than the naive base of the?",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the answer is yes, we can, with again a fairly standard trick from from statistics, which is known as the child new algorithm, and essentially that the concept is really quite quite simple, so that Charlie algorithm has a couple of nice properties.",
                    "label": 0
                },
                {
                    "sent": "But what it does is it gives you a tree, a tree structured representation of the full joint.",
                    "label": 0
                },
                {
                    "sent": "And because it's a tree you only end up with first order conditions, which is nice.",
                    "label": 0
                },
                {
                    "sent": "The way construct this tree is, you essentially calculate the pairwise mutual information graph between all the observations.",
                    "label": 0
                },
                {
                    "sent": "And calculated maximum spanning tree.",
                    "label": 0
                },
                {
                    "sent": "That's that's literally what the what this child you tree is, and it's got a couple of very nice theoretical properties, such As for example.",
                    "label": 0
                },
                {
                    "sent": "That is the best.",
                    "label": 0
                },
                {
                    "sent": "Approximation in this class.",
                    "label": 0
                },
                {
                    "sent": "So the best tree you could possibly construct that cloud most closely approximates the real joint distribution in terms of KL divergences, so this is the best approximation that we can possibly come up with in terms of those first order terms.",
                    "label": 0
                },
                {
                    "sent": "And it's also very efficiently computed from unlabeled data, so it's very nice in that so we don't have to go around label heaps of data for this now.",
                    "label": 0
                },
                {
                    "sent": "So what we what we end up with then is this kind of full joint, which is a term of the individual words, and we approximate it as the product of you know, the probability of the route with a whole bunch of other terms which are essentially 1st order conditions, where Q is a particular observation.",
                    "label": 0
                },
                {
                    "sent": "So 611 and PQ denotes the parents of that one.",
                    "label": 0
                },
                {
                    "sent": "So in this case it will be 28.",
                    "label": 0
                },
                {
                    "sent": "And if we take that, we condition it on the exemplar, we kind of end up with this expression where this is exactly the kind of thing that we wanted to compute.",
                    "label": 0
                },
                {
                    "sent": "OK, given that we're almost there, we can now look at this bit here and figure out and wonder.",
                    "label": 0
                },
                {
                    "sent": "OK, So what do we do with this?",
                    "label": 0
                },
                {
                    "sent": "And this is where we go back to these either.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Both these existence variables, because now we can expand this out in terms of the variables which we then integrate out, and we can do.",
                    "label": 0
                },
                {
                    "sent": "We can make two more fairly simple assumptions, one that detector errors are actually independent of class, which is which is fairly reasonable.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And what that means is that we kind of lose the class from from this thing here, and we end up with something that we that we've seen over something close to term that we've we've seen earlier, and the other.",
                    "label": 0
                },
                {
                    "sent": "The other assumption is that the probability of the generator variable for a particular word is actually independent of any of the observations of all the other words.",
                    "label": 1
                },
                {
                    "sent": "And what that means is that.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We lose this parent term from this thing here, and what that boils down to again, is simply our example and model, and this is how the existence of these E variables.",
                    "label": 0
                },
                {
                    "sent": "This hidden layer allows us to blend these different things together.",
                    "label": 0
                },
                {
                    "sent": "There are a couple of rearrangements, a little bit of of math that you have to do in order to to rearrange those terms and figure out how that relates to actual label.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Data, but the bottom line is we can actually relate this to.",
                    "label": 0
                },
                {
                    "sent": "We can learn this from a reasonable amount of training data.",
                    "label": 0
                },
                {
                    "sent": "And we can go all the way back up and kind of reconstruct this onion and put all the big players.",
                    "label": 0
                },
                {
                    "sent": "They gon put a big step in and say we can compute this in a reasonable amount of time, so that's good.",
                    "label": 0
                },
                {
                    "sent": "So given that we compute this, we can go all the way back to the original formulation.",
                    "label": 0
                },
                {
                    "sent": "We just roll base theorem and we can essentially assign a Class 2.",
                    "label": 0
                },
                {
                    "sent": "To that to that new data?",
                    "label": 0
                },
                {
                    "sent": "Alright, so, given that we that we are fairly happy with how to do that question is how do we actually learn these class models in the 1st place?",
                    "label": 0
                },
                {
                    "sent": "And if we go back and remember that these are represented by individual exemplars, examples are represented by sets of probabilities like this one here for a particular word Q.",
                    "label": 0
                },
                {
                    "sent": "And really in order to in order to learn this from data from labeled data, really what we write down again is is a Bayes update where we have a word existence prior that again we can get reasonably straightforward.",
                    "label": 0
                },
                {
                    "sent": "Free from labor data.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And what we have here is nothing.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But the likelihood term that we've just seen with a given word existence, so we set the existence of this guy to one and then go through exactly the same calculation that we've just been through.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And down here again, we've got the same likely terms, so we know how to compute all these guys.",
                    "label": 0
                },
                {
                    "sent": "And the nice thing about this is that this calculation is very, very fast.",
                    "label": 0
                },
                {
                    "sent": "So what that means is then you can get a new observation in.",
                    "label": 0
                },
                {
                    "sent": "You can perform this update if you so wish.",
                    "label": 0
                },
                {
                    "sent": "You can perform this update and you can literally take this new observation and bolted onto the end of your class model.",
                    "label": 0
                },
                {
                    "sent": "That could mean that you either extend an existing class model or that you essentially open up a new class model.",
                    "label": 1
                },
                {
                    "sent": "So if your system comes back and says, well, I'm not really quite sure operator help.",
                    "label": 0
                },
                {
                    "sent": "What is this?",
                    "label": 0
                },
                {
                    "sent": "You could come up with a label and you could say OK, well this is a new class and then you could literally just incorporate that on the fly, which is also a really nice property that we look for in robotics.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so that's the first stage.",
                    "label": 0
                },
                {
                    "sent": "Now we essentially come up with a distribution or classification for every single one of these patches.",
                    "label": 0
                },
                {
                    "sent": "So now how do we set these things into context?",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In statistics.",
                    "label": 0
                },
                {
                    "sent": "In machine learning there has been around for a while.",
                    "label": 0
                },
                {
                    "sent": "I'm there now, everywhere graphical models, so I doubt there's anybody in this room hasn't heard of them or done anything with him.",
                    "label": 0
                },
                {
                    "sent": "In this case, we're actually going for a basic, very basic variant of it Markov random field, where you have a bunch of nodes and abundant edges, and in a minute we'll see that every one of these nodes corresponds to one of these super pixels, where these patches and every edge corresponds to some relationship between them, and in this particular case it will be some very straightforward spatial relationships between those patches.",
                    "label": 0
                },
                {
                    "sent": "And what you end up with them is in MRF, which OK as we know, is family of undirected graphical models, which models the joint between the observations and the available data and the question then is how do we perform inference in what kind of thing do we want to ask this model?",
                    "label": 0
                },
                {
                    "sent": "And really the thing that we're after is a configuration X.",
                    "label": 0
                },
                {
                    "sent": "So imagine that X is essentially vector.",
                    "label": 0
                },
                {
                    "sent": "If you consider this graph here you go onto future.",
                    "label": 0
                },
                {
                    "sent": "We got 66 nodes, so X will be a vector of length 6.",
                    "label": 0
                },
                {
                    "sent": "And every single element of that can be one of NC classes.",
                    "label": 0
                },
                {
                    "sent": "So it's a.",
                    "label": 0
                },
                {
                    "sent": "It's a discrete, it's a discrete vector and there can be many of them.",
                    "label": 0
                },
                {
                    "sent": "Many different configurations of that particular graph, and we essentially want to want to know which one is the most likely one given the data that we've seen.",
                    "label": 0
                },
                {
                    "sent": "And that is a very.",
                    "label": 0
                },
                {
                    "sent": "It's a book standard map inference problem will just be, you know, explored and applied many, many times, where essentially you know that you can solve it via an optimization of an energy function.",
                    "label": 0
                },
                {
                    "sent": "In this case, minimization of an energy function.",
                    "label": 0
                },
                {
                    "sent": "Where the whole thing.",
                    "label": 0
                },
                {
                    "sent": "So you have an energy for a particular configuration X given the parameters for this model, and there's really only two types of parameters that we deal with here.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "These are kind of these.",
                    "label": 0
                },
                {
                    "sent": "These guys here theater S which are the unary parameters.",
                    "label": 0
                },
                {
                    "sent": "There's kind of a data cost which essentially encodes the cost of giving a particular particular node particular segment.",
                    "label": 0
                },
                {
                    "sent": "Any given label given the data that's associated with it.",
                    "label": 0
                },
                {
                    "sent": "And then we've got this pairwise term here, which are essentially both potentials, which includes the cost of giving two adjacent modes, different labels or the same ones so.",
                    "label": 0
                },
                {
                    "sent": "That's essentially where that comes from and the this inference can be done in many, many different ways.",
                    "label": 1
                },
                {
                    "sent": "They're kind of graph, had variance Max product loopy BP, and we actually chose something called Sequential Tree rated message passing TWS.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Simply be cause it gives you some convergence guarantees to kind of local Maps.",
                    "label": 0
                },
                {
                    "sent": "Maxima in the way that loopy doesn't.",
                    "label": 0
                },
                {
                    "sent": "Having said that, of course many people know that loopy as being applied to many things quite successfully.",
                    "label": 0
                },
                {
                    "sent": "We just.",
                    "label": 0
                },
                {
                    "sent": "I mean, it was a design choice, so we just chose that.",
                    "label": 0
                },
                {
                    "sent": "It doesn't make much of a difference.",
                    "label": 0
                },
                {
                    "sent": "OK, so the question is how do we actually determine?",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The structure of that model given given that the data that we have, and again we can look at it as seen and we can perform an image segment.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And it's very straightforward.",
                    "label": 0
                },
                {
                    "sent": "Once you've got the segmentation to come up with the neighborhood relationships between the individual segments.",
                    "label": 0
                },
                {
                    "sent": "So you just look at it along the boundary and see.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which ones are border on which and you can then take everyone of the segments that you have laser data for.",
                    "label": 0
                },
                {
                    "sent": "So you've got the 3D geometry data associated with it and come up with kind of this structure right here.",
                    "label": 0
                },
                {
                    "sent": "And it's nice because it kind of provides a very intuitive and fast way of constructing these graphs from the data that we actually have.",
                    "label": 0
                },
                {
                    "sent": "And of course, yeah, those graph.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So fairly sparse, so we're kind of abstracted away from operating on the actual on the many hundreds of thousands of laser points to, you know, 10s of nodes.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that's a very nice property.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is the kind of guy we've just seen.",
                    "label": 0
                },
                {
                    "sent": "We want to minimize it.",
                    "label": 0
                },
                {
                    "sent": "The question is, where did these terms come from?",
                    "label": 0
                },
                {
                    "sent": "The first term comes directly out of the first stage.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So essentially this is just the posterior that we just calculated with our with our classifier.",
                    "label": 0
                },
                {
                    "sent": "We use the compliment here, 1 minus because it's a minimization, so we want for something that's very likely what the cost to be cost to below one assumption that we make here is that our class is fully partitioned.",
                    "label": 0
                },
                {
                    "sent": "The world, which is a slightly naive assumption to make, but it's something that we ran with here just for the sake of moving ahead.",
                    "label": 1
                },
                {
                    "sent": "Of course, in practice you could have background class that that will kind of is a lot of the issues that you get from that.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The binary potentials these guys here.",
                    "label": 0
                },
                {
                    "sent": "Sorry these guys here are very much so.",
                    "label": 0
                },
                {
                    "sent": "In this case we actually get them simply from counting, so our learning of those parameters is really looking at a training data and counting how often we see cars on roads, cars on on trees, cars on grass, cars and everything else, and essentially what you do is you simply construct a matrix like this which you do offline and that matrix never changes.",
                    "label": 0
                },
                {
                    "sent": "Which is exactly is of course what makes this MRF and.",
                    "label": 0
                },
                {
                    "sent": "You come up with the structure, which of course has a lot of self similarity.",
                    "label": 0
                },
                {
                    "sent": "When you over segment you get a lot of self similarity in terms of the kind of neighborhood smoothing, but you also in code that that intuitive feeling that ensure feeling that of course you've got to cars.",
                    "label": 0
                },
                {
                    "sent": "You know these objects are somehow related to each other, so that's good constitutes environmental prior that you just get very easily, so there's not much fancy learning involved in this particular stage, but.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It does the trick.",
                    "label": 0
                },
                {
                    "sent": "Now, what does that actually biases the question right?",
                    "label": 0
                },
                {
                    "sent": "So we start out with a scene and we extract this graphical model from it, and so before the MRF, this is just the first stage output.",
                    "label": 0
                },
                {
                    "sent": "Let me just briefly mention the color coding here means kind of purple is kind of tarmac pavement.",
                    "label": 0
                },
                {
                    "sent": "We've got the kind of yellow here.",
                    "label": 0
                },
                {
                    "sent": "That's it's dirt track type of environment.",
                    "label": 0
                },
                {
                    "sent": "Red is textured walls, blue is kind of smooth wall window type of arrangements and we can see this great thing.",
                    "label": 0
                },
                {
                    "sent": "Here is car and we can see that the first stage to kind of get some things correct.",
                    "label": 0
                },
                {
                    "sent": "But it gets if it makes a few blatant errors right?",
                    "label": 0
                },
                {
                    "sent": "For example, the there's some wall in the car and you know the the path kind of extends quite a way up the wall etc etc.",
                    "label": 0
                },
                {
                    "sent": "And what this this MRF smoothing buys us within this scene is literally looking at, for example, the neighborhood, these patches and flipping those mistakes to something more sensible given the immediate neighbors.",
                    "label": 0
                },
                {
                    "sent": "So that's a fairly nice result.",
                    "label": 0
                },
                {
                    "sent": "That's exactly the kind of thing that we that we tried to.",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of course, once you've got one of these graphs in a particular scene, you can extend this whole thing through time, which is another benefit of having this continuous workspace, and you can introduce essentially these red links across you know, frame to frame or from.",
                    "label": 0
                },
                {
                    "sent": "Kind of skipping A-frame and you come up with this kind of filtering type of type of thing or this proper propagating sliding window type approach where you say OK things that are things that are the same in two different frames you know that they think they're the same thing.",
                    "label": 0
                },
                {
                    "sent": "They should have the same label, right?",
                    "label": 0
                },
                {
                    "sent": "I mean the label doesn't change so you can encode that simply by coming up with another matrix and encoding that very naturally into the framework that we've already got.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so in terms of results, what we've done is trained this up using.",
                    "label": 0
                },
                {
                    "sent": "I don't know about, so this is assisted.",
                    "label": 0
                },
                {
                    "sent": "The Jericho datasets from from Oxford, about 30 kilometres of track heaps of points, so heaps of images, many, many more heaps of points.",
                    "label": 0
                },
                {
                    "sent": "So that's where we start training.",
                    "label": 0
                },
                {
                    "sent": "We used a non overlapping set for.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sting and this is the.",
                    "label": 0
                }
            ]
        },
        "clip_80": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I think the system typically produces so on here we've got the original scene.",
                    "label": 0
                },
                {
                    "sent": "Over here we get the.",
                    "label": 0
                },
                {
                    "sent": "We get to the actual classification down.",
                    "label": 0
                },
                {
                    "sent": "Here is the legend.",
                    "label": 0
                },
                {
                    "sent": "What the what the.",
                    "label": 0
                },
                {
                    "sent": "What the colors mean and those labels are then generated automatically simply by by performing clustering in the in the kind of in the pixel space.",
                    "label": 0
                },
                {
                    "sent": "But we see we kind of get some fairly consistent classifications, agenda vehicles pick up a textured walls over there.",
                    "label": 0
                },
                {
                    "sent": "We were fairly fairly good with the tarmac bits over here.",
                    "label": 0
                },
                {
                    "sent": "We pick up the grass left and right here to some extent.",
                    "label": 0
                },
                {
                    "sent": "Yeah, and even kind of bushes in the side here.",
                    "label": 0
                },
                {
                    "sent": "But then that flips back so we get some, get some decent results out of it.",
                    "label": 0
                }
            ]
        },
        "clip_81": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In terms of confusion matrices, what does it look like?",
                    "label": 0
                },
                {
                    "sent": "So appear you've got ground truth and down here you've got the actual classifications and you've got two different confusion matrices here, because you have one for precision, essentially along the diagonal and one for recall.",
                    "label": 0
                },
                {
                    "sent": "And we can see that that pre MRF serves the output of the first stage.",
                    "label": 0
                },
                {
                    "sent": "We're doing OK on some of the larger classes.",
                    "label": 0
                },
                {
                    "sent": "I should say that the data here is totally unbalanced, so this is as it comes in.",
                    "label": 0
                },
                {
                    "sent": "We see a lot more things like, in a city.",
                    "label": 0
                },
                {
                    "sent": "Then for example grass and this is reflected in those results, so we're doing reasonably well on on tarmac and kind of textured walls and things like that in terms of precision.",
                    "label": 0
                },
                {
                    "sent": "There's a lot of confusion between the walls.",
                    "label": 0
                },
                {
                    "sent": "There's a lot of confusion between Bush, foliage vehicle and things like that.",
                    "label": 0
                },
                {
                    "sent": "In terms of precision and also in terms of recall, now a home run results would of course be a completely diagonal matrix.",
                    "label": 0
                }
            ]
        },
        "clip_82": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or two completed diagram matrices and this is what happens.",
                    "label": 0
                },
                {
                    "sent": "It doesn't compute diagonal, but this is what happens after the after the MRF smoothing.",
                    "label": 0
                },
                {
                    "sent": "So this is before and this is up there.",
                    "label": 0
                },
                {
                    "sent": "We can see there's a market.",
                    "label": 0
                },
                {
                    "sent": "Movement of the mass towards the diagonal, which is which is a nice result.",
                    "label": 0
                }
            ]
        },
        "clip_83": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_84": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what we can see is here, we kind of we get, we get away from a lot of the confusion regarding regarding the cars and we get a lot away from a lot of confusion.",
                    "label": 0
                },
                {
                    "sent": "Kind of from tarmac and dirt path here.",
                    "label": 0
                },
                {
                    "sent": "So that kind of shift from towards.",
                    "label": 0
                }
            ]
        },
        "clip_85": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Side note here, particularly it's quite nice in terms of the recall, the benefits are.",
                    "label": 0
                }
            ]
        },
        "clip_86": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Less pronounced because you actually what you do is you over smooth small classes.",
                    "label": 0
                },
                {
                    "sent": "That's part of the problem that you have with this.",
                    "label": 0
                },
                {
                    "sent": "So what you find is.",
                    "label": 0
                }
            ]
        },
        "clip_87": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That, for example, you don't see much grass.",
                    "label": 0
                },
                {
                    "sent": "You will find that the MRF will actually misclassify a couple of things as notgrass and then over smooth.",
                    "label": 0
                }
            ]
        },
        "clip_88": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Them as being correct so we actually misclassify alot of things they were grass as things like thomachan pay which is a side effect of the.",
                    "label": 0
                }
            ]
        },
        "clip_89": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Ticular population of this.",
                    "label": 0
                }
            ]
        },
        "clip_90": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In terms of numbers pre MRF so precision and recall.",
                    "label": 0
                },
                {
                    "sent": "These are kind of the F5 numbers.",
                    "label": 0
                },
                {
                    "sent": "We see that simply using spatial contexts only within a scene.",
                    "label": 0
                },
                {
                    "sent": "We get some fairly significant gains, sometimes up to double double digit percentages.",
                    "label": 0
                },
                {
                    "sent": "The thing that I said about over smoothing is also reflected here in terms of the grass.",
                    "label": 0
                },
                {
                    "sent": "For example, where we see that the F measure actually goes down, we're just not not desirable, but that only happens for that.",
                    "label": 0
                },
                {
                    "sent": "I will see that we actually gained even more from the from kind of folding into the spatial context, which is sort of the temporal context over here, which again is not really surprising, but it's nice to see it, actually.",
                    "label": 0
                }
            ]
        },
        "clip_91": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_92": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In terms of the time that it takes back then about a year and a half ago, we used to have real time constraints imposed by how long the robot takes to actually get the acquire the 3D point cloud, which was about 3 seconds which we needed classification.",
                    "label": 0
                },
                {
                    "sent": "Then we see that in this particular case, on average the classification itself wasn't actually the constraint anymore, which was also nice thing.",
                    "label": 0
                },
                {
                    "sent": "But again, 3 seconds nowadays is also having this old constraint.",
                    "label": 0
                }
            ]
        },
        "clip_93": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alright, so given what we've seen, we've come up with something that's kind of, you know, it's principle is probabilistic, and it does, you know, have nice things in terms of context.",
                    "label": 0
                }
            ]
        },
        "clip_94": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we have a.",
                    "label": 0
                }
            ]
        },
        "clip_95": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Detective model.",
                    "label": 0
                }
            ]
        },
        "clip_96": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We can actually learn.",
                    "label": 0
                }
            ]
        },
        "clip_97": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Things online fact every time we run this up, we learn the model of fresh in a matter of, you know, fractions of seconds, which is which is interesting.",
                    "label": 0
                },
                {
                    "sent": "And two with respect to this old condition old restriction, we can actually do this in real time.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Back to back to the system and how it relates to to this to this workshop because really, I've told you all the things that are great about it, that all things that work about it but.",
                    "label": 0
                }
            ]
        },
        "clip_98": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This thing that haven't been talked about and this is one of the one of the single worst results that we got.",
                    "label": 0
                }
            ]
        },
        "clip_99": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The system and looking at it, it's terrible.",
                    "label": 0
                },
                {
                    "sent": "It's terrible because you see that things that are classified or that could be distinguished quite easily by a single feature in our feature space simply by looking at the surface normal completely fall apart.",
                    "label": 0
                },
                {
                    "sent": "In this particular case, and we looked at this and that kind of gave us a lot of hassle and we kind of ponder this quite a bit and we thought we use different features so we can rewrite the whole thing with a very elaborate feature set and it didn't make it go away and what what it turns out is.",
                    "label": 0
                },
                {
                    "sent": "That one thing that we're not learning properly in this model is the waiting between these individual individual feature dimensions, the individual modalities.",
                    "label": 0
                },
                {
                    "sent": "So if we if the system had properly acquired those those weightings, what you would figure out is that the in this case the surface normal would actually override the fact that this thing is really, really yellow.",
                    "label": 0
                },
                {
                    "sent": "Farm.",
                    "label": 0
                },
                {
                    "sent": "And that kind of thing we haven't actually managed to to make go away.",
                    "label": 0
                },
                {
                    "sent": "And of course, in a very direct sense, this is this person and for what we're going to talk about here today, how are we going to integrate that information?",
                    "label": 0
                },
                {
                    "sent": "I don't actually have a have a good answer for it.",
                    "label": 0
                },
                {
                    "sent": "I'm looking forward to talking about it.",
                    "label": 0
                },
                {
                    "sent": "And yeah, so there's a whole bunch of bunch of issues with it that are directly applied.",
                    "label": 0
                }
            ]
        },
        "clip_100": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Click over here.",
                    "label": 0
                },
                {
                    "sent": "In fact, we've done some prior work on both VM's which use exactly the same data, exactly the same features and we can see that simply with devoted SVM classifier we seriously outperform this probabilistic classifier and our first stage classifier that we that we talked about.",
                    "label": 0
                },
                {
                    "sent": "Of course, once we pull in the MRF smoothing, we kind of get back to similar ballpark, but of course is kind of unfair comparison because devoted SPM doesn't have this Emirates moving on the flip side of that is of course that you could use the voted SVM directly as a first step.",
                    "label": 0
                },
                {
                    "sent": "First stage classifier or any ranking classifier for that matter, so the whole system kind of still holds, which is which is nice.",
                    "label": 0
                },
                {
                    "sent": "So that that that particular sensation of the probabilistic classifier something we",
                    "label": 0
                }
            ]
        },
        "clip_101": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We just experimented with alright, so in terms of the conclusions with respect to this workshop, I think one of the important things that I want to stress again is the fact that we have.",
                    "label": 0
                },
                {
                    "sent": "We have this this benefit that we have this continuous workspace.",
                    "label": 0
                },
                {
                    "sent": "Many sensors pointing at everything that we can and should really use.",
                    "label": 0
                },
                {
                    "sent": "In fact, clean out the window and say some of the robotics applications that we look for really dim and sensor integration.",
                    "label": 0
                },
                {
                    "sent": "Something that people often ask me about, strangely enough, is kind of driving a day and at night and again, you know, sometimes laser scanners are simply.",
                    "label": 0
                },
                {
                    "sent": "A more direct way of measuring things than for example cameras, but another obvious in my mind at least.",
                    "label": 0
                },
                {
                    "sent": "An example for that is kind of close range and long range reconstruction.",
                    "label": 0
                },
                {
                    "sent": "Stereo is very good at close range, but if you want to look at, you know 10s tens, 50 meters or so.",
                    "label": 0
                },
                {
                    "sent": "You will need to use a liter of some shape, but how to combine them?",
                    "label": 0
                },
                {
                    "sent": "How to switch between them?",
                    "label": 0
                },
                {
                    "sent": "Can you?",
                    "label": 0
                },
                {
                    "sent": "Can you combine them in some sensible way so a lot of things like that we face in robotics?",
                    "label": 0
                },
                {
                    "sent": "Of course we can use a lot of machinery developed in machine learning and statistics, and it's awesome.",
                    "label": 0
                },
                {
                    "sent": "We have seen you know many probabilistic methods graphical models we all use kind of discriminative and generative classification models.",
                    "label": 0
                },
                {
                    "sent": "We use regression models etc etc, but I think it's really important to realize that we do have different constraints then a lot of the machine learning and machine vision people out there.",
                    "label": 0
                },
                {
                    "sent": "One of them, the most obvious one is we often retire require real time operation, and that's not really something that that is a priority in machine learning.",
                    "label": 0
                },
                {
                    "sent": "When they develop algorithms, the thing that's really close to my heart is action selection and very closely coupled with that is, you know the meaning of uncertainties that we get out of these systems if you ask yourself the question.",
                    "label": 0
                },
                {
                    "sent": "If you design A robot that kind of traverses, traverses, Rd.",
                    "label": 0
                },
                {
                    "sent": "How much do you?",
                    "label": 0
                },
                {
                    "sent": "How much would you trust your car detector?",
                    "label": 0
                },
                {
                    "sent": "Would you actually switch on the press the autonomy button and let it go across the road on its own?",
                    "label": 0
                },
                {
                    "sent": "And if you ask me, the answer is hell no.",
                    "label": 0
                },
                {
                    "sent": "But if you have if your answer is yes, please come and see me because I would really be interested in how you do it.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so the bottom line is that we have a lot of scope.",
                    "label": 0
                },
                {
                    "sent": "There's been a lot of work done, but there's a lot more to be done in terms of integration of of information in terms of Q integration, what level do we work at?",
                    "label": 0
                },
                {
                    "sent": "Terms of transfer learning.",
                    "label": 0
                },
                {
                    "sent": "Some works being being done there now in robotics as well, and of course domain adaptation, but it's wide open, so let's let's do that.",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                }
            ]
        },
        "clip_102": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And that's it.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "See you tomorrow.",
                    "label": 0
                },
                {
                    "sent": "Some sort of link?",
                    "label": 0
                },
                {
                    "sent": "Yeah so.",
                    "label": 0
                },
                {
                    "sent": "OK, I was going to show this video but OK. Well if you go back, if you if you think back to the to the scene when you come up with the segmentation is actually very simple.",
                    "label": 0
                },
                {
                    "sent": "So what you do is you literally look at what segments border on each other and if there is a direct connection you just put a link in.",
                    "label": 1
                },
                {
                    "sent": "If there isn't, you don't.",
                    "label": 0
                },
                {
                    "sent": "That's that's how simple it is in terms of the temporal aspect.",
                    "label": 0
                },
                {
                    "sent": "It's a.",
                    "label": 0
                },
                {
                    "sent": "It's a different set of links in that in that respect, but really So what we have is we have the laser data and we can project the same laser data into different consecutive images.",
                    "label": 0
                },
                {
                    "sent": "Because you know that the laser data is the same, you know that the points at the flick reflections come from the same point in space, so you know that these classifications need to be consistent.",
                    "label": 0
                },
                {
                    "sent": "And once you know that, you can enforce that in the in the in the model.",
                    "label": 0
                },
                {
                    "sent": "It's about words.",
                    "label": 0
                },
                {
                    "sent": "Do the words that Christian shortly.",
                    "label": 0
                },
                {
                    "sent": "Since you have the old imagine I see reduction steps before.",
                    "label": 0
                },
                {
                    "sent": "It's a good question so.",
                    "label": 0
                },
                {
                    "sent": "In this particular case, we decided to cluster on the original feature space simply because we had a very good like very tight control over what the feature space was.",
                    "label": 0
                },
                {
                    "sent": "In terms of, I mean, there weren't many of them was about 35 of them.",
                    "label": 0
                },
                {
                    "sent": "Would I would I do dimensionality reduction of this?",
                    "label": 0
                },
                {
                    "sent": "I don't know.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure in this particular context what it would buy me, but it may well be that that is beneficial, like I don't know whether that would make a difference in this particular context.",
                    "label": 0
                },
                {
                    "sent": "Does that does that answer your question?",
                    "label": 0
                },
                {
                    "sent": "I mean it's good, I don't know, but I mean well.",
                    "label": 0
                },
                {
                    "sent": "I mean, what's your impression you think would make a difference?",
                    "label": 0
                },
                {
                    "sent": "Sensation.",
                    "label": 0
                },
                {
                    "sent": "Sensor data after the session.",
                    "label": 0
                },
                {
                    "sent": "Pizza pizza recipe.",
                    "label": 0
                },
                {
                    "sent": "OK and then only becoming manipulative.",
                    "label": 0
                },
                {
                    "sent": "So I was wondering whether we could pass on this very global and compressing as first stage performance testing works.",
                    "label": 0
                },
                {
                    "sent": "Something stinks.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so that's so.",
                    "label": 0
                },
                {
                    "sent": "The whole bag of words idea comes from a from a very different domain, right?",
                    "label": 0
                },
                {
                    "sent": "And essentially they started off with in text text processing and that's where the word word comes from.",
                    "label": 0
                },
                {
                    "sent": "So yeah, do not.",
                    "label": 1
                },
                {
                    "sent": "Do not confuse this term word with semantic meaning of words, so we don't expect any of these patches to have intrinsic semantic meaning.",
                    "label": 1
                },
                {
                    "sent": "Of the of the word patches.",
                    "label": 0
                },
                {
                    "sent": "So there's nothing like that.",
                    "label": 0
                },
                {
                    "sent": "I mean, in terms of dimensionality reduction, I would do it if I fear that my learning algorithm would overfit in enormous feature space.",
                    "label": 0
                },
                {
                    "sent": "I don't think I'm in particular we first did this.",
                    "label": 0
                },
                {
                    "sent": "We did it with with SVM, so we didn't use clustering at all.",
                    "label": 0
                },
                {
                    "sent": "We just classify directly on the feature space and 35 dimensions is really not not much given.",
                    "label": 0
                },
                {
                    "sent": "I mean, we had also quite a lot of data for it, but 35 dimensions didn't.",
                    "label": 1
                },
                {
                    "sent": "Didn't worries, but it may well be beneficial.",
                    "label": 0
                },
                {
                    "sent": "I mean, yeah, I certainly think about it, but if you have anymore questions that would be interesting.",
                    "label": 0
                },
                {
                    "sent": "OK, let's take this bigger game.",
                    "label": 0
                }
            ]
        }
    }
}