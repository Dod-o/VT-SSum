{
    "id": "4jphs2d3jaf2odszcymammii5gl5ryea",
    "title": "Dirichlet Processes and Nonparametric Bayesian Modelling",
    "info": {
        "author": [
            "Volker Tresp, Siemens AG"
        ],
        "published": "Feb. 25, 2007",
        "recorded": "February 2006",
        "category": [
            "Top->Computer Science->Machine Learning->Bayesian Learning",
            "Top->Computer Science->Machine Learning->Bayesian Learning->Dirichlet Processes"
        ]
    },
    "url": "http://videolectures.net/mlss06au_tresp_dpnbm/",
    "segmentation": [
        [
            "Yeah, so I'm with carpet research or corporate technology of humans and Munich and I'm part of the Department of maybe 35 people.",
            "Working on learning systems and related issues and I'm heading a group of approximately 10 people focusing on machine learning techniques and trying to apply them problems in the company.",
            "So my talk today is about dishley processes and nonparametric Bayesian modeling.",
            "And I encourage you to ask questions."
        ],
        [
            "It always loosens up everything a little bit.",
            "So the motivation is that infinite dimensional models have gained a lot of attention.",
            "Invasion machine learning recently the most prominent ones are Gaussian processes and Additionally processes.",
            "And today the focus is on digitally processes.",
            "I just briefly want to mention Gaussian processes, and the advantage is that they offer great flexibility and in many applications allow for more truthful representation.",
            "Of the problem you're trying to solve."
        ],
        [
            "So Gaussian processes are sort of simpler and maybe some of you have heard of them already and have looked at them a little bit.",
            "Gaussian process essentially defines a prior distribution over functions.",
            "And which means that a sample of a Gaussian process is a function.",
            "So like function from X to Y or something from inputs based doctor space and you can write it like this Gaussian process, you have a mean function and you have some covariance kernel function which specifies the Gaussian process.",
            "And Gaussian processes are infinite.",
            "Dimensional generalizations are finite dimensional Gaussian distributions.",
            "So you simply let the number of dimensions going to incident and you obtain it out in process.",
            "In a typical problem, we might have samples of the underlying two function.",
            "And we want to calculate the posterior distribution of the functions or may make predictions at the new input.",
            "So if you have exact measurements of the function, you might consider this.",
            "We thousand process moving in most applications you have only noisy measurements of the function and then you'll have to deal with Gaussian process regression.",
            "So this is all I want to say about Gaussian process."
        ],
        [
            "This is so today it's about directly processes and a lot of ways they are similar in a lot of other ways.",
            "Have a different but initially process defines the prior over probability distributions over measures.",
            "And these are these things which are not negative and have to integrate 2 to one in some sense.",
            "And before we had a sample of a Gaussian process was a function.",
            "Now we have a sample of the richly process is a distribution, and the notation is typically the United with this Big G letter, and there are two things here.",
            "One is the base distribution.",
            "Do not, and the concentration parameter F or not and we will learn about all of this later on.",
            "So in the same sense as in Gaussian processes, infinite dimensional digitally processes are simple generalizations of the finite usually distribution to infinite dimensions and hear their typical example.",
            "We might have samples of the underlying true distribution, and we want to calculate the posterior distribution or calculated predicted distribution for a new sample.",
            "So the big difference here is now we don't have samples of the function, but we have samples of the distribution.",
            "Of the two underlying distribution.",
            "And again, we can also consider the case that we don't obtain samples from this distribution, but something like noisy samples from this distribution and this will be the most important case.",
            "Most important application of the process is in terms of this during the process mixture model.",
            "So this is a very short introduction and we now we go into the details of all of this."
        ],
        [
            "Alyssa questions, so I will start with a brief introduction into evasion modeling.",
            "I'm not sure if how many lectures in the summer school have taken occasion view on things, so get everybody sort of warmed up on this.",
            "Then I will talk about multinomial sampling was Additionally prior.",
            "So this finite dimensional case.",
            "And it's very important because it sets up the whole situation for the infinite case.",
            "So if you understand this very deeply, then the judicial process is quite simple.",
            "Otherwise, it seems always like all these definitions, like Chinese restaurant processes and stick breaking processes come out of nowhere.",
            "But if you sort of see the finite dimensional case, the infinite infinite dimensional case comes to no surprise.",
            "Then why should we care about this at all?",
            "The motive main motivation is the application to hierarchical Bayesian modeling, which is.",
            "Not quite the standard way of doing Bayesian modeling.",
            "It's allows you to model situations where you have related but not identical models for different situations.",
            "For example, if you model outcome prediction different hospitals, these models might be slightly different, but also have a lot in common.",
            "This situation, where you can imply her occupation modeling.",
            "And then this is sort of the core of the whole election.",
            "That usually process is and then I will end this applications and a couple more comments on nonparametric Bayesian modeling."
        ],
        [
            "OK."
        ],
        [
            "Comes first.",
            "So this is sort of to get people warmed up on that to think about abbasian approaches to machine learning.",
            "So probability theory is considered a branch of mathematics.",
            "So you start with axioms and theorems and your theorems to prove things to be true or not, and where statistics and statistical machine learning are sort of attempts to applying probability theory to solving problems in the real world.",
            "Examples I effectiveness of the medication, so this is a typical problem.",
            "Statisticians want to address is a significant improvement if you apply a medication or not in machine learning, you might do text classification or you want to design a medical expert system where you want to incorporate the experts medical experts knowledge into the system and then you want to do inference in the system about diseases, symptoms and so on.",
            "There are different approaches to applying probability theory to problems in the real world in a useful way.",
            "The classical Way is the frequentist where frequented statistics.",
            "Then there's the Bayesian statistics and their statistical learning theory.",
            "And there a couple more.",
            "So all of them seem to be doing something useful in their own right, and it's probably not very good idea to.",
            "Try to start a discussion about which one is the right one and which one is the wrong one.",
            "There are interesting situations where each of them can be very useful, and but today we will take a basin.",
            "POV On all of this."
        ],
        [
            "OK."
        ],
        [
            "As I said, I will really start very far back to warm you up a little bit.",
            "So just because if you haven't done Bayesian statistics in awhile, you might not remember all these simple.",
            "Rules anymore, so I will review the review them briefly so a giant distribution X&Y is simply means the probability that you observe that random variable access instead, X&Y is in state Y."
        ],
        [
            "Then there is the definition of a conditional distribution.",
            "P of Y given X is defined as a joint of X and Y / P of X.",
            "So this just you have extras normalizes this expression such it is a proper probability density in terms of Y.",
            "Very simple rules."
        ],
        [
            "Then there's a product decomposition.",
            "If you have a distribution of two random variables, you can always decompose them in the probability distribution of one of them and then times probability distribution of the second one given the first one.",
            "And of course you can also change the order and get a.",
            "Another decomposition.",
            "And this can be extended if you repeatedly apply this rule, you obtain the chain rule of probability.",
            "So any high dimensional probability distribution X one to XM can be decomposed in any order by starting for example with X one.",
            "Then you multiply it by probability of X2 given X one X3.",
            "Given all the previous variables appear in the formula and the last term is XM given all the previous predecessors.",
            "And this is so these are now one dimensional probability densities.",
            "And this is very general.",
            "And of course one hopes then that one can use exploit some in dependencies in the domain, for example that X3 is independent of X1 given X2, something of that sort.",
            "And this is also the basis for Bayesian networks, which are essentially implementation of this decomposition in in terms of a graphical representation."
        ],
        [
            "What else we have obeys who is also very simple PX given Y, this is just the definition of the conditional probability distribution and then you do the product decomposition up here and you get based rule P of X given YSP of Y given X * 2 X divided by P of Y.",
            "So all of this is simple."
        ],
        [
            "Basic but invasion modeling.",
            "You use these formulas all the time, and I think the last one which is relevant is the modernization.",
            "So if you.",
            "Know the giant probability distribution and you want to.",
            "Let the marginal of one of the variables involved you have to integrate this distribution over all the other random variables in the distribution.",
            "This model distribution I mean this calculation, gives you all the headaches if you apply."
        ],
        [
            "To have given problem so."
        ],
        [
            "The basic rules which will use all the time invariant cetis ticks and.",
            "We simply apply these rules in in a statistical sense.",
            "So in the simple case, we might have a hypothesis of probability of hypothesis being true.",
            "Before that we see any data.",
            "So this is the prior probability and 1 minus probability.",
            "Of course, is the probability that the hypothesis might be true.",
            "Then we observe some data.",
            "And we assume some.",
            "Distribution data given hypothesis being true or the data given hypothesis is not true and these terms are called likelihood terms, engagement, reasoning and then we are interested in updating our hypothesis about age being true given the data.",
            "And this is done by simply applying Bayes rule and we can plug terms into this equation which we can which you have specified previously.",
            "So here's the prior probability that ages 2.",
            "Times probability of the data given access to divided by probability of the data.",
            "So this is a very simple procedure for updating.",
            "You believe in an hypothesis.",
            "If you have observed some data."
        ],
        [
            "So here's a very simple example.",
            "So a friend has bought a new car and but you don't know what kind of car it is.",
            "It might be sports car, it might be another car, so we assume that the probability that the cars sports cars 1/2, then you learn that the car somewhere churches that the car is 2 doors.",
            "And here's the life here.",
            "The likelihood terms the probability of two doors given that it's a sports car is 1.",
            "So let's assume that every sports car is exactly 2 doors, but they also other cars which have to doors and give them a probability of 1/2.",
            "And then you can apply a base hearing to update your belief that your friend is bought.",
            "The sports car, given you know that it has two doors.",
            "This is the prior probability of a sports car.",
            "This is the likelihood term.",
            "The two doors, given it's a sports car divide by the normalization term and you end up with probability .66 previously at .5, so you believe in the fact that it is a sports car has increased by Sir."
        ],
        [
            "An amount.",
            "Um?",
            "So what is the debate about Bayesian reasoning?",
            "I mean, there's no disagreement that one can define something like likelihood term.",
            "The probability of the observation given the hypothesis.",
            "Because I mean frequencies also have to do the same thing.",
            "But there's disagreement one should be allowed to define this prior probability about the truth value of the hypothesis before you observe any data, because here you seem to add a lot of personal opinion about truth or non truth, and this has been criticized by critics to Bayesian reasoning.",
            "But in some sense, it's also a chance.",
            "It's not just a problem with patient reasoning because particular machine learning you often want to include your prior knowledge in the modeling process, otherwise your problem cannot be solved.",
            "So in some sense, it's also a chance and not just the problem that you have the opportunity to enter your prior knowledge in a systematic way.",
            "And there are some examples like medical expert systems where without any expert knowledge you would not be able to do anything.",
            "And also basis would argue that to obtain a complete statistical model you really need this prior probability.",
            "And the frequentists are sort of trying to work around this problem by using all sorts of fancy methods.",
            "But one comment that we made is that I think the critical term is really this likelihood term, and this is also something somebody has to specify in an experiment.",
            "So and this in fact is much more critical than the prior distribution.",
            "So in some sense the.",
            "Discussion about prior or not prior is not quite to the point be cause this is the much more critical term."
        ],
        [
            "OK, then there was early on in AI and artificial intelligence.",
            "The debate if humans do reasoning according to probability or not, and the assumption was rather not.",
            "And so I people for long for many years, sort of ignored more or less the probabilistic approach.",
            "But there's always been an argument in favor of the probabilistic approach.",
            "The Classical one is my Cox, which essentially says if one is willing to assign numbers to believe, then under a few assumptions of consistency, and if one means that one is certain, that event is true or will occur.",
            "And if O means that one is certain that the event will not occur when these numbers exactly behaviors probabilities probabilities.",
            "The theme says any measure of belief is isomorphic to a probability measure.",
            "So this means that.",
            "Humans, probably, as long as they are reasonable people and the reasonable things, they're probably behaving more or less as if they're dealing with probabilities, and if their beliefs are probabilities, and this is not only the only person which came to this conclusion in this longer statement, Heckerman argues that a number of people have come to this to this identical conclusion with, which gives a lot of weight to the idea that also.",
            "Personal beliefs should be modeled in terms of probabilities."
        ],
        [
            "OK, so this is so far.",
            "Maybe quite simple and.",
            "And so why aren't more people using Bayesian statistics, although in machine learning from must say that it's probably 5050 in some sense of people who are doing patient stuff and people are doing web page and stuff, one problem other."
        ],
        [
            "Technologies involved in Bayesian statistics.",
            "So first of all, any quantity of interest in a basin approach is treated as a random variable.",
            "If there's some uncertainty involved in this in this quantity.",
            "So we make the distinction between parameters and other random variables.",
            "Parameters are typically random variables, which would assume the same value in all of the experiments we are doing.",
            "So so these are there.",
            "Some underlying two parameters.",
            "We don't know them, so we choose them as random variables, but they don't change from measurement and measurement with other random variables typically assume different values in each data point.",
            "So in a typical setting we might have have observed data we might have unknown parameters and we might predict a quantity X.",
            "Furthermore, to make it a bit more interesting, we might have something like latent variables in the training data D. Just more into this HD and we also have a latent variable in the in the new data point we want to predict.",
            "So this might be might be a discrete variable indicating to which cluster a datapoint belongs, and it's not known in the training data in the test data, but we don't want to be very specific right now about this.",
            "So the first thing in beige modeling is to think about the joint probability distribution of all these quantities involved, and you decompose it into a smart way.",
            "Typically, you start with your parameters.",
            "You assume this is just the application of this product decomposition to this problem.",
            "So you start a probability distribution of your parameters.",
            "Then you say OK, the next one piece of data and the hidden variables in the data given the parameters.",
            "So this is still completely general.",
            "And then you say, OK, I want to pull the of X&H given and then I should in theory have the whole.",
            "Bunch over here.",
            "Set a data HD, but typical assumption is that the observed data independent from one another given the parameters are known.",
            "So that's why we can drop all these terms out of this expression and end up with this more compact representation.",
            "So pure feta is the sort of prior distribution of parameters P of D and HD given Theta is complete data likelihood.",
            "But of course HD is not known, so we have to.",
            "Integrate that out in the next step, the complete data likelihood means assuming we could have measured everything.",
            "What is the likelihood that likely is always the probability of observing reservations given the parameters?",
            "So typically we might be interested in predicting X given the data, so we're not really interested in all these other quantities here.",
            "We want to calculate this quantity.",
            "So the first thing is, as I said, we don't.",
            "We don't know HD, so the first thing is to marginalized it out to make this expression.",
            "Without the D, so this was one of the operations we have discussed before, so you have to integrate grayed out HD and get this module.",
            "Likelihood or the likelihood of the observed data.",
            "Integrating all the unobserved data.",
            "This is the first operation to do and."
        ],
        [
            "Next operation is.",
            "Then we can calculate the probability distribution of the parameters given the data by simply using Bayes formula.",
            "This was specified in the model.",
            "This is the term we have just calculated.",
            "This is the normalization here.",
            "The next thing is that we end up with a product of P of XH given CATA times P of Theta given D. But we are not interested in theater at all, so we have to integrate that out and obtain this simple expression P of X&H.",
            "Given the data, and finally we also not interested in H. But in P of X given D and so we also have to integrate out the hidden variable in the new data point.",
            "So these are as you go through this.",
            "Maybe when you review the lecture or something really not very difficult operations to derive from the basic principles, the technicalities involved.",
            "Are all these integrals and and and this sums over here.",
            "Everything else is sort of a simple.",
            "How does that?",
            "So this one, how does it interpret?",
            "It goes to probably the next comanage.",
            "OK, this is this is.",
            "Probability of etc.",
            "Given the data and then X of H given set in the data.",
            "But the data dropout because soon settle this is independent, so this is just a joint distribution of XH and better given the data.",
            "And then to remove.",
            "Better we have to integrate it out so much and less architecture.",
            "Alright.",
            "So these are very simple operations in principle, but crooks are these difficulties intervals.",
            "This is because that typically about high dimensional features etc.",
            "Might be whatever tender 100 dimensional, so they're not very simple to solve.",
            "And the trick is to find efficient ways to approximate calculate all these integrals.",
            "So one might say.",
            "Frequencies typically end up with optimization problems.",
            "For example, exactly with maximum likelihood approach and invasions typically end up with intervals to be solved."
        ],
        [
            "So this is a list of methods which can be used to solving these integrals.",
            "Also, approximating integrals in some cases some close form solutions exist.",
            "And this, of course the stuff people have done before computers were available.",
            "They could only do this these things where in some sense they could solve these integrals and they are very clever methods for doing that.",
            "But they are only applicable to certain situations.",
            "Then there's something like the Laplace approximations which.",
            "Since calculates the maximum.",
            "Probable parameter setting after you have seen the data which is then listen optimization problem to be solved.",
            "Then so this is very similar to a frequentist approximation.",
            "When you calculate the maximum likelihood parameter setting, just that you typically end up end up having another regularization term, then in the following we will extensively use this idea of Markov chain Monte Carlo sampling.",
            "And the example we are using this specific case of Gibbs sampling, which applies the idea of integrals solving integrals by doing Monte Carlo simulation and we will talk about this in more detail.",
            "Then, as the variational approximations for example, mean field approximations, this again is a method which leads to an optimization problem to be solved, which is also quite tricky and I don't want to really go into this and any detail and a new a new variant is expectation propagation, which can also be used in Beijing to South Asian integrals."
        ],
        [
            "OK, so the conclusion on this on this part is that vision modeling is a straightforward application of the laws of probability to problems in the real world.",
            "In essence, the Basin program is quite simple.",
            "You build a model incorporating or prior knowledge and your assumption about the data generating process.",
            "You measure the data and then you perform inference in this model.",
            "And inference means inference with Spectra that may be hidden variables or something like that, or unknown variables, but also with respect to the parameters involved.",
            "And finally a comment.",
            "I mean, one should never forget that the assumption going and more statistical models are quite rough.",
            "And probably not very truth.",
            "Very, very close to the truth of the situation.",
            "You do a lot of assumptions about in dependencies which might be not there if you look very, very detail.",
            "So you always have to live with some approximate systems and you shouldn't overdo.",
            "Your mathematics to find you in a model to the last extent where you really have to assume that the model itself is not quite correct."
        ],
        [
            "OK.",
            "So this was a little bit of an.",
            "Introduction into the basin.",
            "View on things, and.",
            "Now we get into the first part, which is more specific and more technical, and it's model using multinomial sampling with Additionally prior."
        ],
        [
            "OK.",
            "So essentially, if you generalize this model, then to infinite dimensions we will end up with the usual process is, but it's very important to 1st get a good understanding of the finite dimensional case.",
            "And learning and inference in the final case find the equivalent equivalence is also in the infinite dimensional case of usually process is.",
            "For this part of the presentation, I would highly recommend.",
            "By the way, this tutorial, which is a couple years old but essentially contains all the equations in this part of the lecture and also for other reasons is very highly recommended.",
            "For reading."
        ],
        [
            "OK, the example we are using here is the throwing of tossing overloaded dice, so the outcome is 1.",
            "One out of six phases which might show up, but we assume that this guys is not a fair dice and we don't know the probabilities of a certain phase showing up.",
            "So notation is that that's a random variable.",
            "Sekaran set assumes that OK, this means that the face.",
            "Of the dice shows that OK.",
            "So that OK might be 12345 or six in general, and now we do a lot of tosses, independent tosses of the dice and and of them.",
            "And in this end processes we observe a certain result that OK, NK times.",
            "So a reasonable estimate then for the probability that we will show we will see a certain result in tossing the dice is the number of observations divided by the total number of tosses.",
            "So this seems very reasonable, and if I observe certain phase they often then it correspondingly becomes very likely if I observe it very rarely, then this probability estimate where we will be quite small.",
            "So this is I think."
        ],
        [
            "OK, now we become a little bit more probabilistic.",
            "So in this model, typically we assume multinomial sampling.",
            "So we assume that this observed variables data might.",
            "How it might have are different states.",
            "But I want to set R so in the case of the dice are six or better one to six, and the likelihood function is given by.",
            "Probability of observing that dice showed factor K given the parameters in the model is equals to the case component of this parameter vector.",
            "So G is a vector of.",
            "Two are but the first.",
            "The first entry is simply 1 minus the other entries.",
            "So why one might debate with this has our degrees.",
            "I mean our minus 1 degrees of freedoms, but an hour minus one free parameters because the last one is given by the normalization constraint anyways.",
            "So we just have a vector of numbers here and which are exactly the physical probabilities of observing a certain result in tossing the dice.",
            "And and these are numbers between a positive numbers are greater non negative numbers and they should sum up to one.",
            "So it's exactly the probabilities.",
            "And these are of course the quantities we are interested in.",
            "If we want to characterize this loaded dice.",
            "Um?",
            "Yeah, then you observe data set before and these are realizations of these random variables that are one is better.",
            "One then equals set N and we simply calculate the sufficient statistics which in this case is the total number.",
            "We have observed a result.",
            "So one means the number of times you have observed that the dice showed one and R in this case, which result would be the number of times you have observed the six showing up.",
            "OK, so D and the following will stand in general."
        ],
        [
            "Cool surf data.",
            "Then we calculate the likelihood term based on this and these assumptions and.",
            "Since the probability of observing one of those results is just GK, so that would be the result of observing set OK. And if you observe that and K times then we just have to calculate G to the power of NK and we have to do that for all results of all thrown dices.",
            "So this is the likelihood function with this normalization term in front, which is not relevant for our discussion.",
            "But essentially we are just multiplying all the probabilities of observing the individual results and end up with this formula.",
            "In the in the maximum likelihood setting we would then estimate this unknown parameter by finding the parameter values which maximize this expression and we would end up exactly with our plausable result that.",
            "Parameters would correspond to the experimental counts.",
            "And this is a fine if N is very large and the number of states in particular is much much smaller than N. This is might be a very good estimate, but in cases where we don't have so much data to be observed, this estimate might be quite wrong and we might not have observed certain tosses at all, and this number would be 0, which might be unreasonable in many situations.",
            "So in this situation."
        ],
        [
            "If not having too many data of Asian treatment might be more appropriate.",
            "And as we said before, for basean treatment we need prior probability of the parameters under consideration, and in this case it is the probability probability of this vector G given some hyperparameters Alpha star and the conjugate distribution to a multinomial distribution is ideally distribution, and it's written like this.",
            "Dear ladies, solution, given the set of parameters specifying the directional distribution again, it's a normalization term.",
            "Types of product of G to the K to the power of Alpha K star minus one.",
            "So Interestingly, here, the likelihood function and the prior distribution with a very similar form.",
            "And we can think of this as being something like equivalent counts equivalent to our prior knowledge before we see any data.",
            "So this is now a function of Gina.",
            "We have to specify here probability for every combination of.",
            "Settings of realizations of GK and some of them will be more likely and some some of them will not be very likely and I will come to an intuitive.",
            "The explanation of this formula in the moment.",
            "First of all this is number which is non negative.",
            "But it doesn't have to integrate or sum to one.",
            "So it's not normalized, but sometimes it makes sense to normalize this quantity.",
            "So we calculate first the sum overall F star case and then divide the Alpha stock his.",
            "I mean, the Alpha stars came by this number I forgot and observe something which now comes to one.",
            "So if we do this, we can write this expression over here in this form where we now explicitly have the product of I forgot and I for K. And this makes sense for many reasons.",
            "One is that if we calculate the.",
            "Probability of observing a certain result in the tosses given the parameter vector lifestar we have to solve this integral and we obtain this normalized quantity Alpha K. So if we do this normalization by dividing by Alpha, not.",
            "We obtain the expected values of what we would observe before we have seen any data.",
            "You just have the Alpha star parameter given and we do it.",
            "We do a toss, then we would observe these quantities.",
            "In terms of the probabilities.",
            "So in some sense the Alpha K indicate the distribution we are expecting.",
            "A knife and not put some weight on this expectation.",
            "So if I'm not as very large, we're very strong about our belief that these are the correct probabilities.",
            "I for now it is very small, then we're not very certain about these probabilities and probabilities.",
            "We're certain about how this offer cases normalized normalized quantities."
        ],
        [
            "We can also calculate the posterior distribution by sort of.",
            "Applying Bayes formula to the product of likelihood and the prior distribution and the probability of the parameters given the data and our priority parameters of a star is again additional distribution, where here we now have to add the Alpha stars with the corresponding counts.",
            "So this is the property of this.",
            "The fact that we used the.",
            "Conjugate prior one of the properties of the in this situation is that the posterior takes on the same form as the prior, so it's no surprise that the posterior distribution is also directly.",
            "And all we can calculate the probability of a toss of the next toss given our prior assumption.",
            "Given the data.",
            "And again we can calculate this integral and the result is.",
            "Very interesting, very important.",
            "It's quality iPhone, not times Alpha K plus NK normalize.",
            "So what we see here is that if we have observed a certain result in a past, very often the probability of observing this resulted in the future will be very high.",
            "And here we see also that I forgot exactly has this meaning of specifying the belief in this in our prior assumption about the distribution.",
            "That I for case would be the right count.",
            "So this is also quite an client intuitive result.",
            "And of course, we also observe if we have N becomes very, very large.",
            "We can sort of ignore this term and again become obtained the result.",
            "The same result we would have obtained a maximum likelihood approach that the empirical counts are determining the probabilities for future events."
        ],
        [
            "Now we have to look.",
            "Take a look at a little closer.",
            "Look at this distribution, which is has some interesting features.",
            "So this is the definition again in this formula with Alpha stars and now we can plug in different numbers.",
            "This is the case of a 3 dimensional distribution, so we plotting here two of the dimensions of the third one is the one I thought of ordinal here, so it's sort of we should think signal.",
            "This is a plane sort of coming out here, and if we specify as I start parameters 111, then here's a 1 -- 1.",
            "So this is a. G to the zero and everything becomes very uniform, so any parameter value essentially has the same value in this case.",
            "Then we can increase this iPhone not factor, which just means melting.",
            "These.",
            "Multiplying these numbers with a large number for two to 210-1010.",
            "For example, we see that the probability mass gets more and more concentrated in the central region here, which should be situation .3 and .3.",
            "So we are implementing our belief that we are dealing with a fair dice.",
            "All the probabilities are the same and the weight on this belief.",
            "Also increases because the probability of this distribution .3 point 3.3 becomes larger and larger.",
            "We can also implement an unbalanced prior belief, so this would indicate that we believe the 2nd.",
            "Parameter with the 2nd result in the tossing the dice would be a very high probability.",
            "The first one is low and the third one would also be low.",
            "And this is an example where the third dimension is very high.",
            "But the two observed, I mean the two plotted here have a low values.",
            "So this is all quite reasonable and maybe.",
            "Quite expected, but this is an interesting plot over here, which is not so expected.",
            "Maybe so this is it usually distribution with numbers which are slightly smaller.",
            "Smaller than one, so we remember these various only have to be positively, but there can be smaller than one and we still sort of implement our prior belief that we are dealing with a fair dice because all the probabilities of these numbers here are sort of identical.",
            "But what now happens if?",
            "If these numbers become smaller smaller than one that the probabilities in the extreme values.",
            "Become very likely.",
            "So although we have sort of implementing an expected sense anyways that we're dealing with a fair dice, any sampled or any dice generated by this prior distribution becomes more and more loaded, and if we make these numbers even smaller, then we will almost exclusively observe these extreme points.",
            "And this is.",
            "A little bit surprising when observed this first, and it will also have a very important effect later.",
            "Individually, process is because this is sort of the explanation.",
            "Why do usually processes will lead to very clustered solutions where the prior sort of essentially says on average.",
            "I believe this is a fair dice, but every single dice I'm producing is extremely unfair.",
            "At least, this is sort of the bias implemented by by this dishley prior distribution.",
            "If these numbers become smaller and smaller."
        ],
        [
            "So this is the set of the of the model and to do inference in these models and later on in the display process is it's important to consider how to generate samples from these models."
        ],
        [
            "So let's OK, maybe first look at graphical representation of the situation.",
            "So what I mean by generating samples as we start off with some iPhone, not an Alpha parameters.",
            "We could also have put them together as I for star and based on these parameters describing the prior distribution we generate a sample of G. Using the dishley distribution and then given G we generate samples from different results of of the devices.",
            "So in this case we do any experiments.",
            "We throw the dice N times and observe and different values of the results of the dices.",
            "And there's a more compact representation of this, since this dependency is sort of repeated N * 1 simply draws square around this node over here, and indicates how often this process is repeated.",
            "This is called a plate representation.",
            "It's just a shorthand notation for this situation here on the left, so generating samples essentially means we have a factory of devices, and we produce unfair dices according to our.",
            "Prior assumption about.",
            "The probability of generating G. Then we take this unfair dices and throw the dice is and then observe these data belong to a given Dyas.",
            "Say something."
        ],
        [
            "OK, so this is.",
            "So the first approach is to do exactly what I have described.",
            "You first generate a sample of G of this of the parameters of the diocese, and then you generate these tosses.",
            "It's not.",
            "It's not straightforward to generate these samples for G, But there are different approaches and I don't want to get too much into detail how the system.",
            "But if you look at the literature, there are different ways of doing it.",
            "Here's describing that you sample from independent gamma distributions.",
            "Using certain shape parameters and normalizes samples, but I don't want to get into a lot of detail here in the later in the deep case, an additional process case.",
            "This is more interesting and will lead us to the stick breaking representation, but given that we have generated the sample from the dishley distribution, it's very simple.",
            "Of course to generate samples of the of the tosses because these genes are simply the probabilities of observing a certain result in throwing the dice."
        ],
        [
            "So this is the first approach.",
            "The second approach is also very interesting.",
            "We never generate a sample of G directly, but we directly generate samples of the results of the of the devices.",
            "And to do this we use the equation we have observed you have used before before we said, given past observations of results of.",
            "We want to predict the result of the next thoughts and we use we came up with this formula over here.",
            "But we can also use exactly the same formula too.",
            "Generate samples of and specific but unknown unloaded loaded dice.",
            "So in this sense we have generated some samples.",
            "We put them in D and condition on them and use exactly the same formula to estimate our probability probability of observing the next result of the next toss.",
            "And.",
            "The advantage here is that we never have to assemble from G. In particular, gym might become later on infinite dimensional and it's not very easy to assemble of G. This is a very nice equation because we never have to do that.",
            "We can directly sample from the results of the guys we're tossing.",
            "Because interpret this in this way with probability proportional to N, we will sample from a distribution with empirical accounts and with probability proportional to Alpha, not you generate the sample according to the distribution implied by the Eiffel case.",
            "This is also a very nice interpretation of this iPhone.",
            "Not again, it's very weak.",
            "We will right away sample from the empirical data from the empirical estimate of the probabilities.",
            "If I find out if a strong we will this term will.",
            "Dominate quite awhile and we will keep sampling from our prior model."
        ],
        [
            "OK, and this type of sampling later be associated with the pool, your own representation and the Chinese restaurant process.",
            "Just to"
        ],
        [
            "Later, you might look at this up, but there's a very strange thing about this.",
            "Equation is also related to this strange property of the richly prior.",
            "If you look at this formula and let for not go to zero, then what does this mean?",
            "It means if we observe one.",
            "Result of of that.",
            "I sort of dice and this result will immediately dominate all the probabilities, because this number is very small.",
            "So after the first toss we have here, especially one.",
            "Well, one for the observed toss and the zero for all the other choices for the other possible results.",
            "So this seems to be very strange now you might want to implement a fair die assumption about a fair dice, but all we are generating are very unfair loaded dices.",
            "And this can also be seen if you take the this distribution and let these iPhone not go to zero.",
            "Then this becomes essentially one over the parameters and this is maximized if most most parameters become zero and all the probability mass is sort of taking up by one of the parameters.",
            "So this is a little bit strange thing in the data sleeve distribution and generally processes that at least two very highly unbalanced solutions and the high tendency.",
            "To be produced sort of very clustered solutions and which can be tuned by varying this concentration parameter Alpha.",
            "Not so if you make it very small we will get a very small number of very concentrated parameters.",
            "Let me in parameters which were small number will have very high values, the other ones will have various almost equal to 0 and the other device or not is very large.",
            "Prior will dominate very long and we will get a very smooth.",
            "Is that?",
            "But this is the paradox is more when we let off and not go to 0.",
            "I'm.",
            "So the resources that we should think of Alpha without knowing the Alpha distribution is really important.",
            "Implementing our prior belief, but that this probability is very, very weak and can be easily overwritten by data which we observe for which we have generated.",
            "But this is something to be comes comes back again.",
            "The situation when we talk about directly processes, which we will show exactly the same result that.",
            "Probably probability mass tends to be clustered in."
        ],
        [
            "Small number of clusters.",
            "There's another illustration of the situation.",
            "The better distribution is essentially usually distribution, which was two dimensions, so it's a little bit easier to plot and what we have talked about is this situation over here.",
            "When I find better, the two parameters here 1/2, we get this effect that these extreme.",
            "Distributions with 1001 very high probability and in between the drops to very small values, whereas other distributions behave more normally if you have Alpha equals two better equals five, we get a nice model distribution over here."
        ],
        [
            "So this was now concerned with the experiment that somebody generates these.",
            "The loaded ISIS, like a loaded dice factory or so, and then we observe tosses of a loaded dice is now we make the model one step more complicated.",
            "And we assume we obtain noisy situations."
        ],
        [
            "Maybe let me go to the graphic representations right away so this is what we had before we had some prior distribution of producing loaded dices.",
            "Then of observing the tosses of the loaded dice, and now we assume that we cannot observe these results directly, but some derived quantities of the result of the loaded dice.",
            "So let's say these are unreliable friends which tell us about the outcome of the experiment, and we might even have more than one.",
            "So in this case we might have.",
            "I'm friends, which all gives us give us some sort of unreliable information about the outcome of the toss.",
            "And of course, this will be hopefully everybody will see that this is a very useful model later on.",
            "Right now it seems to be a little bit artificial.",
            "This is the situation now and now we.",
            "We didn't observe this set as we only observe the access, which are the results of the information given by some."
        ],
        [
            "Reliable friends, let's say.",
            "So what we now have to specify some probability of observing this results in the information of the.",
            "Unreliable friends, given the results of the tosses in this probability distribution, and we assign a certain set of data DI to the.",
            "To set a right to the result of the talks.",
            "And now again, we might be interested in updating our belief about this quality G. The parameters describing the loaded dice is or we might be interested in predicting and estimating the actual results of the tosses.",
            "Or we might want to predict the next result of a task based on the observed data.",
            "So this is now a problem with missing data.",
            "The fact are missing.",
            "We haven't observed them.",
            "And there are different ways of dealing with this problem.",
            "The one which is relevant in context with the richly process is is the approach based on Gibbs sampling, which I will discuss in a moment.",
            "Another possible approach, of course, is to use the popular EM algorithm, which gives us point estimates of the parameters G, But the Gibbs sampling is sort of the more.",
            "Appropriate from a basin POV because you're taking all the uncertainty more serious, whereas in the EM algorithm you end up with point estimates, which is has more flavor for frequentist approach.",
            "So this experiment?",
            "Hopefully clear."
        ],
        [
            "So yeah, this is a shot.",
            "Attempt to explain what Gibbs sampling is all about.",
            "So for example, if you are interested in probability of observing the next result of our our ties.",
            "We based on the data, we can decompose it first in the probability of observing the past of the past choices given the data times the probability of the next test given the past results of the tosses and we have to integrate about these unknown quantities because that I want to set and the results are really unknown and this is a very big sum because this might be these are in terms.",
            "Maybe having two to the N different configurations and depending on the number of states, but this sort of grows exponentially in the number of variables goes up the terms you have to sum about grows exponentially the number of terms.",
            "So the idea in Monte Carlo approximation is to approximate this term over here by this expression over here.",
            "So this should be pure Theta N + 1, not the popular.",
            "Given these quantities over here and these are samples of this distribution over here.",
            "So the idea is to sample of this distribution.",
            "And plug these samples into this expression and take the average over over this summer.",
            "So this is the basic idea and Monte Carlo approximation, and one can sort of proof convergence of this expression if X goes to Infinity.",
            "The problem here is now that we need these independent samples of these parameters of this posterior.",
            "Solution of the unknown parameters given the data and and.",
            "This is sort of the difficult part.",
            "I mean, this sum is really nice and simple and very intuitive, but obtaining independent samples quite quite difficult.",
            "And one typically have to rely on multiple Markov chain Monte Carlo methods, which does not produce independent samples of the distribution.",
            "I mean it produces samples of the correct distribution, but subsequent samples are quite dependent because the next sample depends on previous sample doesn't depend on other or the other symbol in the past, but it depends on the previous sample.",
            "And and the general approach is called Markov chain Monte Carlo sampling."
        ],
        [
            "And an example of this which will be used.",
            "In this lecture is called gift sampling, which is a specific form of Markov chain Monte Carlo sampling.",
            "So the idea and Gibbs sampling is that all the unknown variables initialized in some smart way.",
            "And then we repeatedly replace the values.",
            "Off one of the variables.",
            "Given by a new sample of the probability distribution of this variable given all the other variables and given the data.",
            "So essentially we update one variable at a time.",
            "And we updated by considering this conditional probability distribution.",
            "We want to find out what all the other data and all the other samples have to tell us about the variables we are interested in updating.",
            "We calculate this probability distribution and update this variable 1 by 1.",
            "And we have to do that for all variables in some reasonable order.",
            "It's not very important exactly how we do it, but of course every variable should be updated solution number of times.",
            "So one so one can show that after some burning phase this produces samples exactly of the right distribution.",
            "The problem is that they might be independent.",
            "So if you have a Gaussian distribution, let's say.",
            "Sort of time.",
            "Then you might start over here and you might sample along time in this region before you sort of come up to the other region of the Gaussian distribution, and you move back so the samples are dependent, which is called if they're very dependent, it means that the change doesn't mix very well.",
            "If they're sort of tend to be independent, then this is a desired property property, and it said that the chain mixes well.",
            "So.",
            "Yeah.",
            "OK, in the first approach is what happens happening down there?",
            "OK it's where we apply this idea of sampling from the setters without ever sampling from the G to generate samples for the other setters, and this is called collapsed Gibbs sampling 'cause we integrate out this quantity G which we never sample off.",
            "We've sort of 1st integrate authors quality so we only have to samples from the status."
        ],
        [
            "And So what we need is to update one specific quantity over here.",
            "So this is again the result of a dice.",
            "So what's the probability of cetacaine taking on the value Theta L given all the other samples?",
            "So I left all this South for convenience and given all the data.",
            "So first of all, we can say that given all the other samples of all the other tosses, we don't need all the data, we only need to condition on the data of this particular trust.",
            "We are interested in.",
            "So we remove or maybe replace D by DK, then in the next step we can apply based formula to turn around these probabilities.",
            "The normalization factor, where again here we have explored that.",
            "So we have explored independence.",
            "Forgot.",
            "OK, I don't see it right now, But anyway, this is the formula we end up with and this term we already know this.",
            "The probability of drawing a sample for the K store's given all the other choices, which is just this expression over here which we have seen before it cipher, not times I felt I'm plus the number of observations of this result and times the probability of observed of observing the data, given that this is the result of the toss.",
            "So this is very similar to what we have observed before.",
            "Before we had this before, we have seen any data.",
            "Now we simply multiply.",
            "Multiply this term by the likelihood of observing the data.",
            "Given that we make the assumption that we observe.",
            "So this will now give higher probability to results which agree with the data we have observed for this particular result of the test."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yeah, so I'm with carpet research or corporate technology of humans and Munich and I'm part of the Department of maybe 35 people.",
                    "label": 0
                },
                {
                    "sent": "Working on learning systems and related issues and I'm heading a group of approximately 10 people focusing on machine learning techniques and trying to apply them problems in the company.",
                    "label": 0
                },
                {
                    "sent": "So my talk today is about dishley processes and nonparametric Bayesian modeling.",
                    "label": 1
                },
                {
                    "sent": "And I encourage you to ask questions.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It always loosens up everything a little bit.",
                    "label": 0
                },
                {
                    "sent": "So the motivation is that infinite dimensional models have gained a lot of attention.",
                    "label": 1
                },
                {
                    "sent": "Invasion machine learning recently the most prominent ones are Gaussian processes and Additionally processes.",
                    "label": 0
                },
                {
                    "sent": "And today the focus is on digitally processes.",
                    "label": 0
                },
                {
                    "sent": "I just briefly want to mention Gaussian processes, and the advantage is that they offer great flexibility and in many applications allow for more truthful representation.",
                    "label": 1
                },
                {
                    "sent": "Of the problem you're trying to solve.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So Gaussian processes are sort of simpler and maybe some of you have heard of them already and have looked at them a little bit.",
                    "label": 0
                },
                {
                    "sent": "Gaussian process essentially defines a prior distribution over functions.",
                    "label": 1
                },
                {
                    "sent": "And which means that a sample of a Gaussian process is a function.",
                    "label": 1
                },
                {
                    "sent": "So like function from X to Y or something from inputs based doctor space and you can write it like this Gaussian process, you have a mean function and you have some covariance kernel function which specifies the Gaussian process.",
                    "label": 0
                },
                {
                    "sent": "And Gaussian processes are infinite.",
                    "label": 0
                },
                {
                    "sent": "Dimensional generalizations are finite dimensional Gaussian distributions.",
                    "label": 0
                },
                {
                    "sent": "So you simply let the number of dimensions going to incident and you obtain it out in process.",
                    "label": 1
                },
                {
                    "sent": "In a typical problem, we might have samples of the underlying two function.",
                    "label": 0
                },
                {
                    "sent": "And we want to calculate the posterior distribution of the functions or may make predictions at the new input.",
                    "label": 1
                },
                {
                    "sent": "So if you have exact measurements of the function, you might consider this.",
                    "label": 0
                },
                {
                    "sent": "We thousand process moving in most applications you have only noisy measurements of the function and then you'll have to deal with Gaussian process regression.",
                    "label": 0
                },
                {
                    "sent": "So this is all I want to say about Gaussian process.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is so today it's about directly processes and a lot of ways they are similar in a lot of other ways.",
                    "label": 0
                },
                {
                    "sent": "Have a different but initially process defines the prior over probability distributions over measures.",
                    "label": 1
                },
                {
                    "sent": "And these are these things which are not negative and have to integrate 2 to one in some sense.",
                    "label": 0
                },
                {
                    "sent": "And before we had a sample of a Gaussian process was a function.",
                    "label": 1
                },
                {
                    "sent": "Now we have a sample of the richly process is a distribution, and the notation is typically the United with this Big G letter, and there are two things here.",
                    "label": 1
                },
                {
                    "sent": "One is the base distribution.",
                    "label": 0
                },
                {
                    "sent": "Do not, and the concentration parameter F or not and we will learn about all of this later on.",
                    "label": 0
                },
                {
                    "sent": "So in the same sense as in Gaussian processes, infinite dimensional digitally processes are simple generalizations of the finite usually distribution to infinite dimensions and hear their typical example.",
                    "label": 0
                },
                {
                    "sent": "We might have samples of the underlying true distribution, and we want to calculate the posterior distribution or calculated predicted distribution for a new sample.",
                    "label": 1
                },
                {
                    "sent": "So the big difference here is now we don't have samples of the function, but we have samples of the distribution.",
                    "label": 1
                },
                {
                    "sent": "Of the two underlying distribution.",
                    "label": 0
                },
                {
                    "sent": "And again, we can also consider the case that we don't obtain samples from this distribution, but something like noisy samples from this distribution and this will be the most important case.",
                    "label": 0
                },
                {
                    "sent": "Most important application of the process is in terms of this during the process mixture model.",
                    "label": 0
                },
                {
                    "sent": "So this is a very short introduction and we now we go into the details of all of this.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alyssa questions, so I will start with a brief introduction into evasion modeling.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure if how many lectures in the summer school have taken occasion view on things, so get everybody sort of warmed up on this.",
                    "label": 0
                },
                {
                    "sent": "Then I will talk about multinomial sampling was Additionally prior.",
                    "label": 0
                },
                {
                    "sent": "So this finite dimensional case.",
                    "label": 0
                },
                {
                    "sent": "And it's very important because it sets up the whole situation for the infinite case.",
                    "label": 0
                },
                {
                    "sent": "So if you understand this very deeply, then the judicial process is quite simple.",
                    "label": 0
                },
                {
                    "sent": "Otherwise, it seems always like all these definitions, like Chinese restaurant processes and stick breaking processes come out of nowhere.",
                    "label": 0
                },
                {
                    "sent": "But if you sort of see the finite dimensional case, the infinite infinite dimensional case comes to no surprise.",
                    "label": 0
                },
                {
                    "sent": "Then why should we care about this at all?",
                    "label": 0
                },
                {
                    "sent": "The motive main motivation is the application to hierarchical Bayesian modeling, which is.",
                    "label": 0
                },
                {
                    "sent": "Not quite the standard way of doing Bayesian modeling.",
                    "label": 0
                },
                {
                    "sent": "It's allows you to model situations where you have related but not identical models for different situations.",
                    "label": 0
                },
                {
                    "sent": "For example, if you model outcome prediction different hospitals, these models might be slightly different, but also have a lot in common.",
                    "label": 0
                },
                {
                    "sent": "This situation, where you can imply her occupation modeling.",
                    "label": 0
                },
                {
                    "sent": "And then this is sort of the core of the whole election.",
                    "label": 0
                },
                {
                    "sent": "That usually process is and then I will end this applications and a couple more comments on nonparametric Bayesian modeling.",
                    "label": 1
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Comes first.",
                    "label": 0
                },
                {
                    "sent": "So this is sort of to get people warmed up on that to think about abbasian approaches to machine learning.",
                    "label": 0
                },
                {
                    "sent": "So probability theory is considered a branch of mathematics.",
                    "label": 1
                },
                {
                    "sent": "So you start with axioms and theorems and your theorems to prove things to be true or not, and where statistics and statistical machine learning are sort of attempts to applying probability theory to solving problems in the real world.",
                    "label": 1
                },
                {
                    "sent": "Examples I effectiveness of the medication, so this is a typical problem.",
                    "label": 0
                },
                {
                    "sent": "Statisticians want to address is a significant improvement if you apply a medication or not in machine learning, you might do text classification or you want to design a medical expert system where you want to incorporate the experts medical experts knowledge into the system and then you want to do inference in the system about diseases, symptoms and so on.",
                    "label": 1
                },
                {
                    "sent": "There are different approaches to applying probability theory to problems in the real world in a useful way.",
                    "label": 1
                },
                {
                    "sent": "The classical Way is the frequentist where frequented statistics.",
                    "label": 0
                },
                {
                    "sent": "Then there's the Bayesian statistics and their statistical learning theory.",
                    "label": 0
                },
                {
                    "sent": "And there a couple more.",
                    "label": 0
                },
                {
                    "sent": "So all of them seem to be doing something useful in their own right, and it's probably not very good idea to.",
                    "label": 0
                },
                {
                    "sent": "Try to start a discussion about which one is the right one and which one is the wrong one.",
                    "label": 0
                },
                {
                    "sent": "There are interesting situations where each of them can be very useful, and but today we will take a basin.",
                    "label": 0
                },
                {
                    "sent": "POV On all of this.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As I said, I will really start very far back to warm you up a little bit.",
                    "label": 0
                },
                {
                    "sent": "So just because if you haven't done Bayesian statistics in awhile, you might not remember all these simple.",
                    "label": 0
                },
                {
                    "sent": "Rules anymore, so I will review the review them briefly so a giant distribution X&Y is simply means the probability that you observe that random variable access instead, X&Y is in state Y.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then there is the definition of a conditional distribution.",
                    "label": 1
                },
                {
                    "sent": "P of Y given X is defined as a joint of X and Y / P of X.",
                    "label": 0
                },
                {
                    "sent": "So this just you have extras normalizes this expression such it is a proper probability density in terms of Y.",
                    "label": 0
                },
                {
                    "sent": "Very simple rules.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then there's a product decomposition.",
                    "label": 1
                },
                {
                    "sent": "If you have a distribution of two random variables, you can always decompose them in the probability distribution of one of them and then times probability distribution of the second one given the first one.",
                    "label": 0
                },
                {
                    "sent": "And of course you can also change the order and get a.",
                    "label": 0
                },
                {
                    "sent": "Another decomposition.",
                    "label": 0
                },
                {
                    "sent": "And this can be extended if you repeatedly apply this rule, you obtain the chain rule of probability.",
                    "label": 1
                },
                {
                    "sent": "So any high dimensional probability distribution X one to XM can be decomposed in any order by starting for example with X one.",
                    "label": 0
                },
                {
                    "sent": "Then you multiply it by probability of X2 given X one X3.",
                    "label": 0
                },
                {
                    "sent": "Given all the previous variables appear in the formula and the last term is XM given all the previous predecessors.",
                    "label": 1
                },
                {
                    "sent": "And this is so these are now one dimensional probability densities.",
                    "label": 0
                },
                {
                    "sent": "And this is very general.",
                    "label": 0
                },
                {
                    "sent": "And of course one hopes then that one can use exploit some in dependencies in the domain, for example that X3 is independent of X1 given X2, something of that sort.",
                    "label": 0
                },
                {
                    "sent": "And this is also the basis for Bayesian networks, which are essentially implementation of this decomposition in in terms of a graphical representation.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What else we have obeys who is also very simple PX given Y, this is just the definition of the conditional probability distribution and then you do the product decomposition up here and you get based rule P of X given YSP of Y given X * 2 X divided by P of Y.",
                    "label": 0
                },
                {
                    "sent": "So all of this is simple.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Basic but invasion modeling.",
                    "label": 0
                },
                {
                    "sent": "You use these formulas all the time, and I think the last one which is relevant is the modernization.",
                    "label": 0
                },
                {
                    "sent": "So if you.",
                    "label": 0
                },
                {
                    "sent": "Know the giant probability distribution and you want to.",
                    "label": 0
                },
                {
                    "sent": "Let the marginal of one of the variables involved you have to integrate this distribution over all the other random variables in the distribution.",
                    "label": 0
                },
                {
                    "sent": "This model distribution I mean this calculation, gives you all the headaches if you apply.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To have given problem so.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The basic rules which will use all the time invariant cetis ticks and.",
                    "label": 0
                },
                {
                    "sent": "We simply apply these rules in in a statistical sense.",
                    "label": 0
                },
                {
                    "sent": "So in the simple case, we might have a hypothesis of probability of hypothesis being true.",
                    "label": 1
                },
                {
                    "sent": "Before that we see any data.",
                    "label": 1
                },
                {
                    "sent": "So this is the prior probability and 1 minus probability.",
                    "label": 0
                },
                {
                    "sent": "Of course, is the probability that the hypothesis might be true.",
                    "label": 0
                },
                {
                    "sent": "Then we observe some data.",
                    "label": 0
                },
                {
                    "sent": "And we assume some.",
                    "label": 0
                },
                {
                    "sent": "Distribution data given hypothesis being true or the data given hypothesis is not true and these terms are called likelihood terms, engagement, reasoning and then we are interested in updating our hypothesis about age being true given the data.",
                    "label": 0
                },
                {
                    "sent": "And this is done by simply applying Bayes rule and we can plug terms into this equation which we can which you have specified previously.",
                    "label": 0
                },
                {
                    "sent": "So here's the prior probability that ages 2.",
                    "label": 0
                },
                {
                    "sent": "Times probability of the data given access to divided by probability of the data.",
                    "label": 1
                },
                {
                    "sent": "So this is a very simple procedure for updating.",
                    "label": 0
                },
                {
                    "sent": "You believe in an hypothesis.",
                    "label": 0
                },
                {
                    "sent": "If you have observed some data.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's a very simple example.",
                    "label": 0
                },
                {
                    "sent": "So a friend has bought a new car and but you don't know what kind of car it is.",
                    "label": 1
                },
                {
                    "sent": "It might be sports car, it might be another car, so we assume that the probability that the cars sports cars 1/2, then you learn that the car somewhere churches that the car is 2 doors.",
                    "label": 0
                },
                {
                    "sent": "And here's the life here.",
                    "label": 0
                },
                {
                    "sent": "The likelihood terms the probability of two doors given that it's a sports car is 1.",
                    "label": 0
                },
                {
                    "sent": "So let's assume that every sports car is exactly 2 doors, but they also other cars which have to doors and give them a probability of 1/2.",
                    "label": 1
                },
                {
                    "sent": "And then you can apply a base hearing to update your belief that your friend is bought.",
                    "label": 0
                },
                {
                    "sent": "The sports car, given you know that it has two doors.",
                    "label": 0
                },
                {
                    "sent": "This is the prior probability of a sports car.",
                    "label": 0
                },
                {
                    "sent": "This is the likelihood term.",
                    "label": 0
                },
                {
                    "sent": "The two doors, given it's a sports car divide by the normalization term and you end up with probability .66 previously at .5, so you believe in the fact that it is a sports car has increased by Sir.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "An amount.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So what is the debate about Bayesian reasoning?",
                    "label": 1
                },
                {
                    "sent": "I mean, there's no disagreement that one can define something like likelihood term.",
                    "label": 1
                },
                {
                    "sent": "The probability of the observation given the hypothesis.",
                    "label": 0
                },
                {
                    "sent": "Because I mean frequencies also have to do the same thing.",
                    "label": 0
                },
                {
                    "sent": "But there's disagreement one should be allowed to define this prior probability about the truth value of the hypothesis before you observe any data, because here you seem to add a lot of personal opinion about truth or non truth, and this has been criticized by critics to Bayesian reasoning.",
                    "label": 1
                },
                {
                    "sent": "But in some sense, it's also a chance.",
                    "label": 0
                },
                {
                    "sent": "It's not just a problem with patient reasoning because particular machine learning you often want to include your prior knowledge in the modeling process, otherwise your problem cannot be solved.",
                    "label": 0
                },
                {
                    "sent": "So in some sense, it's also a chance and not just the problem that you have the opportunity to enter your prior knowledge in a systematic way.",
                    "label": 1
                },
                {
                    "sent": "And there are some examples like medical expert systems where without any expert knowledge you would not be able to do anything.",
                    "label": 0
                },
                {
                    "sent": "And also basis would argue that to obtain a complete statistical model you really need this prior probability.",
                    "label": 0
                },
                {
                    "sent": "And the frequentists are sort of trying to work around this problem by using all sorts of fancy methods.",
                    "label": 1
                },
                {
                    "sent": "But one comment that we made is that I think the critical term is really this likelihood term, and this is also something somebody has to specify in an experiment.",
                    "label": 0
                },
                {
                    "sent": "So and this in fact is much more critical than the prior distribution.",
                    "label": 0
                },
                {
                    "sent": "So in some sense the.",
                    "label": 0
                },
                {
                    "sent": "Discussion about prior or not prior is not quite to the point be cause this is the much more critical term.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, then there was early on in AI and artificial intelligence.",
                    "label": 0
                },
                {
                    "sent": "The debate if humans do reasoning according to probability or not, and the assumption was rather not.",
                    "label": 0
                },
                {
                    "sent": "And so I people for long for many years, sort of ignored more or less the probabilistic approach.",
                    "label": 0
                },
                {
                    "sent": "But there's always been an argument in favor of the probabilistic approach.",
                    "label": 0
                },
                {
                    "sent": "The Classical one is my Cox, which essentially says if one is willing to assign numbers to believe, then under a few assumptions of consistency, and if one means that one is certain, that event is true or will occur.",
                    "label": 1
                },
                {
                    "sent": "And if O means that one is certain that the event will not occur when these numbers exactly behaviors probabilities probabilities.",
                    "label": 0
                },
                {
                    "sent": "The theme says any measure of belief is isomorphic to a probability measure.",
                    "label": 0
                },
                {
                    "sent": "So this means that.",
                    "label": 0
                },
                {
                    "sent": "Humans, probably, as long as they are reasonable people and the reasonable things, they're probably behaving more or less as if they're dealing with probabilities, and if their beliefs are probabilities, and this is not only the only person which came to this conclusion in this longer statement, Heckerman argues that a number of people have come to this to this identical conclusion with, which gives a lot of weight to the idea that also.",
                    "label": 0
                },
                {
                    "sent": "Personal beliefs should be modeled in terms of probabilities.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so this is so far.",
                    "label": 0
                },
                {
                    "sent": "Maybe quite simple and.",
                    "label": 0
                },
                {
                    "sent": "And so why aren't more people using Bayesian statistics, although in machine learning from must say that it's probably 5050 in some sense of people who are doing patient stuff and people are doing web page and stuff, one problem other.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Technologies involved in Bayesian statistics.",
                    "label": 0
                },
                {
                    "sent": "So first of all, any quantity of interest in a basin approach is treated as a random variable.",
                    "label": 1
                },
                {
                    "sent": "If there's some uncertainty involved in this in this quantity.",
                    "label": 0
                },
                {
                    "sent": "So we make the distinction between parameters and other random variables.",
                    "label": 0
                },
                {
                    "sent": "Parameters are typically random variables, which would assume the same value in all of the experiments we are doing.",
                    "label": 0
                },
                {
                    "sent": "So so these are there.",
                    "label": 0
                },
                {
                    "sent": "Some underlying two parameters.",
                    "label": 1
                },
                {
                    "sent": "We don't know them, so we choose them as random variables, but they don't change from measurement and measurement with other random variables typically assume different values in each data point.",
                    "label": 1
                },
                {
                    "sent": "So in a typical setting we might have have observed data we might have unknown parameters and we might predict a quantity X.",
                    "label": 1
                },
                {
                    "sent": "Furthermore, to make it a bit more interesting, we might have something like latent variables in the training data D. Just more into this HD and we also have a latent variable in the in the new data point we want to predict.",
                    "label": 0
                },
                {
                    "sent": "So this might be might be a discrete variable indicating to which cluster a datapoint belongs, and it's not known in the training data in the test data, but we don't want to be very specific right now about this.",
                    "label": 0
                },
                {
                    "sent": "So the first thing in beige modeling is to think about the joint probability distribution of all these quantities involved, and you decompose it into a smart way.",
                    "label": 0
                },
                {
                    "sent": "Typically, you start with your parameters.",
                    "label": 0
                },
                {
                    "sent": "You assume this is just the application of this product decomposition to this problem.",
                    "label": 0
                },
                {
                    "sent": "So you start a probability distribution of your parameters.",
                    "label": 0
                },
                {
                    "sent": "Then you say OK, the next one piece of data and the hidden variables in the data given the parameters.",
                    "label": 0
                },
                {
                    "sent": "So this is still completely general.",
                    "label": 0
                },
                {
                    "sent": "And then you say, OK, I want to pull the of X&H given and then I should in theory have the whole.",
                    "label": 0
                },
                {
                    "sent": "Bunch over here.",
                    "label": 1
                },
                {
                    "sent": "Set a data HD, but typical assumption is that the observed data independent from one another given the parameters are known.",
                    "label": 0
                },
                {
                    "sent": "So that's why we can drop all these terms out of this expression and end up with this more compact representation.",
                    "label": 0
                },
                {
                    "sent": "So pure feta is the sort of prior distribution of parameters P of D and HD given Theta is complete data likelihood.",
                    "label": 0
                },
                {
                    "sent": "But of course HD is not known, so we have to.",
                    "label": 0
                },
                {
                    "sent": "Integrate that out in the next step, the complete data likelihood means assuming we could have measured everything.",
                    "label": 0
                },
                {
                    "sent": "What is the likelihood that likely is always the probability of observing reservations given the parameters?",
                    "label": 0
                },
                {
                    "sent": "So typically we might be interested in predicting X given the data, so we're not really interested in all these other quantities here.",
                    "label": 0
                },
                {
                    "sent": "We want to calculate this quantity.",
                    "label": 0
                },
                {
                    "sent": "So the first thing is, as I said, we don't.",
                    "label": 1
                },
                {
                    "sent": "We don't know HD, so the first thing is to marginalized it out to make this expression.",
                    "label": 0
                },
                {
                    "sent": "Without the D, so this was one of the operations we have discussed before, so you have to integrate grayed out HD and get this module.",
                    "label": 0
                },
                {
                    "sent": "Likelihood or the likelihood of the observed data.",
                    "label": 0
                },
                {
                    "sent": "Integrating all the unobserved data.",
                    "label": 0
                },
                {
                    "sent": "This is the first operation to do and.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Next operation is.",
                    "label": 0
                },
                {
                    "sent": "Then we can calculate the probability distribution of the parameters given the data by simply using Bayes formula.",
                    "label": 1
                },
                {
                    "sent": "This was specified in the model.",
                    "label": 0
                },
                {
                    "sent": "This is the term we have just calculated.",
                    "label": 0
                },
                {
                    "sent": "This is the normalization here.",
                    "label": 0
                },
                {
                    "sent": "The next thing is that we end up with a product of P of XH given CATA times P of Theta given D. But we are not interested in theater at all, so we have to integrate that out and obtain this simple expression P of X&H.",
                    "label": 0
                },
                {
                    "sent": "Given the data, and finally we also not interested in H. But in P of X given D and so we also have to integrate out the hidden variable in the new data point.",
                    "label": 0
                },
                {
                    "sent": "So these are as you go through this.",
                    "label": 0
                },
                {
                    "sent": "Maybe when you review the lecture or something really not very difficult operations to derive from the basic principles, the technicalities involved.",
                    "label": 0
                },
                {
                    "sent": "Are all these integrals and and and this sums over here.",
                    "label": 0
                },
                {
                    "sent": "Everything else is sort of a simple.",
                    "label": 0
                },
                {
                    "sent": "How does that?",
                    "label": 0
                },
                {
                    "sent": "So this one, how does it interpret?",
                    "label": 0
                },
                {
                    "sent": "It goes to probably the next comanage.",
                    "label": 0
                },
                {
                    "sent": "OK, this is this is.",
                    "label": 0
                },
                {
                    "sent": "Probability of etc.",
                    "label": 0
                },
                {
                    "sent": "Given the data and then X of H given set in the data.",
                    "label": 0
                },
                {
                    "sent": "But the data dropout because soon settle this is independent, so this is just a joint distribution of XH and better given the data.",
                    "label": 0
                },
                {
                    "sent": "And then to remove.",
                    "label": 0
                },
                {
                    "sent": "Better we have to integrate it out so much and less architecture.",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                },
                {
                    "sent": "So these are very simple operations in principle, but crooks are these difficulties intervals.",
                    "label": 0
                },
                {
                    "sent": "This is because that typically about high dimensional features etc.",
                    "label": 0
                },
                {
                    "sent": "Might be whatever tender 100 dimensional, so they're not very simple to solve.",
                    "label": 0
                },
                {
                    "sent": "And the trick is to find efficient ways to approximate calculate all these integrals.",
                    "label": 0
                },
                {
                    "sent": "So one might say.",
                    "label": 0
                },
                {
                    "sent": "Frequencies typically end up with optimization problems.",
                    "label": 0
                },
                {
                    "sent": "For example, exactly with maximum likelihood approach and invasions typically end up with intervals to be solved.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is a list of methods which can be used to solving these integrals.",
                    "label": 0
                },
                {
                    "sent": "Also, approximating integrals in some cases some close form solutions exist.",
                    "label": 0
                },
                {
                    "sent": "And this, of course the stuff people have done before computers were available.",
                    "label": 0
                },
                {
                    "sent": "They could only do this these things where in some sense they could solve these integrals and they are very clever methods for doing that.",
                    "label": 0
                },
                {
                    "sent": "But they are only applicable to certain situations.",
                    "label": 0
                },
                {
                    "sent": "Then there's something like the Laplace approximations which.",
                    "label": 0
                },
                {
                    "sent": "Since calculates the maximum.",
                    "label": 0
                },
                {
                    "sent": "Probable parameter setting after you have seen the data which is then listen optimization problem to be solved.",
                    "label": 0
                },
                {
                    "sent": "Then so this is very similar to a frequentist approximation.",
                    "label": 0
                },
                {
                    "sent": "When you calculate the maximum likelihood parameter setting, just that you typically end up end up having another regularization term, then in the following we will extensively use this idea of Markov chain Monte Carlo sampling.",
                    "label": 1
                },
                {
                    "sent": "And the example we are using this specific case of Gibbs sampling, which applies the idea of integrals solving integrals by doing Monte Carlo simulation and we will talk about this in more detail.",
                    "label": 0
                },
                {
                    "sent": "Then, as the variational approximations for example, mean field approximations, this again is a method which leads to an optimization problem to be solved, which is also quite tricky and I don't want to really go into this and any detail and a new a new variant is expectation propagation, which can also be used in Beijing to South Asian integrals.",
                    "label": 1
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so the conclusion on this on this part is that vision modeling is a straightforward application of the laws of probability to problems in the real world.",
                    "label": 1
                },
                {
                    "sent": "In essence, the Basin program is quite simple.",
                    "label": 0
                },
                {
                    "sent": "You build a model incorporating or prior knowledge and your assumption about the data generating process.",
                    "label": 0
                },
                {
                    "sent": "You measure the data and then you perform inference in this model.",
                    "label": 0
                },
                {
                    "sent": "And inference means inference with Spectra that may be hidden variables or something like that, or unknown variables, but also with respect to the parameters involved.",
                    "label": 0
                },
                {
                    "sent": "And finally a comment.",
                    "label": 1
                },
                {
                    "sent": "I mean, one should never forget that the assumption going and more statistical models are quite rough.",
                    "label": 0
                },
                {
                    "sent": "And probably not very truth.",
                    "label": 0
                },
                {
                    "sent": "Very, very close to the truth of the situation.",
                    "label": 0
                },
                {
                    "sent": "You do a lot of assumptions about in dependencies which might be not there if you look very, very detail.",
                    "label": 0
                },
                {
                    "sent": "So you always have to live with some approximate systems and you shouldn't overdo.",
                    "label": 0
                },
                {
                    "sent": "Your mathematics to find you in a model to the last extent where you really have to assume that the model itself is not quite correct.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So this was a little bit of an.",
                    "label": 0
                },
                {
                    "sent": "Introduction into the basin.",
                    "label": 0
                },
                {
                    "sent": "View on things, and.",
                    "label": 0
                },
                {
                    "sent": "Now we get into the first part, which is more specific and more technical, and it's model using multinomial sampling with Additionally prior.",
                    "label": 1
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So essentially, if you generalize this model, then to infinite dimensions we will end up with the usual process is, but it's very important to 1st get a good understanding of the finite dimensional case.",
                    "label": 1
                },
                {
                    "sent": "And learning and inference in the final case find the equivalent equivalence is also in the infinite dimensional case of usually process is.",
                    "label": 1
                },
                {
                    "sent": "For this part of the presentation, I would highly recommend.",
                    "label": 0
                },
                {
                    "sent": "By the way, this tutorial, which is a couple years old but essentially contains all the equations in this part of the lecture and also for other reasons is very highly recommended.",
                    "label": 0
                },
                {
                    "sent": "For reading.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, the example we are using here is the throwing of tossing overloaded dice, so the outcome is 1.",
                    "label": 0
                },
                {
                    "sent": "One out of six phases which might show up, but we assume that this guys is not a fair dice and we don't know the probabilities of a certain phase showing up.",
                    "label": 0
                },
                {
                    "sent": "So notation is that that's a random variable.",
                    "label": 0
                },
                {
                    "sent": "Sekaran set assumes that OK, this means that the face.",
                    "label": 0
                },
                {
                    "sent": "Of the dice shows that OK.",
                    "label": 0
                },
                {
                    "sent": "So that OK might be 12345 or six in general, and now we do a lot of tosses, independent tosses of the dice and and of them.",
                    "label": 0
                },
                {
                    "sent": "And in this end processes we observe a certain result that OK, NK times.",
                    "label": 1
                },
                {
                    "sent": "So a reasonable estimate then for the probability that we will show we will see a certain result in tossing the dice is the number of observations divided by the total number of tosses.",
                    "label": 1
                },
                {
                    "sent": "So this seems very reasonable, and if I observe certain phase they often then it correspondingly becomes very likely if I observe it very rarely, then this probability estimate where we will be quite small.",
                    "label": 0
                },
                {
                    "sent": "So this is I think.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, now we become a little bit more probabilistic.",
                    "label": 0
                },
                {
                    "sent": "So in this model, typically we assume multinomial sampling.",
                    "label": 1
                },
                {
                    "sent": "So we assume that this observed variables data might.",
                    "label": 0
                },
                {
                    "sent": "How it might have are different states.",
                    "label": 1
                },
                {
                    "sent": "But I want to set R so in the case of the dice are six or better one to six, and the likelihood function is given by.",
                    "label": 1
                },
                {
                    "sent": "Probability of observing that dice showed factor K given the parameters in the model is equals to the case component of this parameter vector.",
                    "label": 0
                },
                {
                    "sent": "So G is a vector of.",
                    "label": 0
                },
                {
                    "sent": "Two are but the first.",
                    "label": 0
                },
                {
                    "sent": "The first entry is simply 1 minus the other entries.",
                    "label": 0
                },
                {
                    "sent": "So why one might debate with this has our degrees.",
                    "label": 0
                },
                {
                    "sent": "I mean our minus 1 degrees of freedoms, but an hour minus one free parameters because the last one is given by the normalization constraint anyways.",
                    "label": 0
                },
                {
                    "sent": "So we just have a vector of numbers here and which are exactly the physical probabilities of observing a certain result in tossing the dice.",
                    "label": 0
                },
                {
                    "sent": "And and these are numbers between a positive numbers are greater non negative numbers and they should sum up to one.",
                    "label": 0
                },
                {
                    "sent": "So it's exactly the probabilities.",
                    "label": 0
                },
                {
                    "sent": "And these are of course the quantities we are interested in.",
                    "label": 0
                },
                {
                    "sent": "If we want to characterize this loaded dice.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Yeah, then you observe data set before and these are realizations of these random variables that are one is better.",
                    "label": 1
                },
                {
                    "sent": "One then equals set N and we simply calculate the sufficient statistics which in this case is the total number.",
                    "label": 1
                },
                {
                    "sent": "We have observed a result.",
                    "label": 0
                },
                {
                    "sent": "So one means the number of times you have observed that the dice showed one and R in this case, which result would be the number of times you have observed the six showing up.",
                    "label": 0
                },
                {
                    "sent": "OK, so D and the following will stand in general.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Cool surf data.",
                    "label": 0
                },
                {
                    "sent": "Then we calculate the likelihood term based on this and these assumptions and.",
                    "label": 1
                },
                {
                    "sent": "Since the probability of observing one of those results is just GK, so that would be the result of observing set OK. And if you observe that and K times then we just have to calculate G to the power of NK and we have to do that for all results of all thrown dices.",
                    "label": 0
                },
                {
                    "sent": "So this is the likelihood function with this normalization term in front, which is not relevant for our discussion.",
                    "label": 0
                },
                {
                    "sent": "But essentially we are just multiplying all the probabilities of observing the individual results and end up with this formula.",
                    "label": 0
                },
                {
                    "sent": "In the in the maximum likelihood setting we would then estimate this unknown parameter by finding the parameter values which maximize this expression and we would end up exactly with our plausable result that.",
                    "label": 1
                },
                {
                    "sent": "Parameters would correspond to the experimental counts.",
                    "label": 0
                },
                {
                    "sent": "And this is a fine if N is very large and the number of states in particular is much much smaller than N. This is might be a very good estimate, but in cases where we don't have so much data to be observed, this estimate might be quite wrong and we might not have observed certain tosses at all, and this number would be 0, which might be unreasonable in many situations.",
                    "label": 0
                },
                {
                    "sent": "So in this situation.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If not having too many data of Asian treatment might be more appropriate.",
                    "label": 0
                },
                {
                    "sent": "And as we said before, for basean treatment we need prior probability of the parameters under consideration, and in this case it is the probability probability of this vector G given some hyperparameters Alpha star and the conjugate distribution to a multinomial distribution is ideally distribution, and it's written like this.",
                    "label": 0
                },
                {
                    "sent": "Dear ladies, solution, given the set of parameters specifying the directional distribution again, it's a normalization term.",
                    "label": 0
                },
                {
                    "sent": "Types of product of G to the K to the power of Alpha K star minus one.",
                    "label": 0
                },
                {
                    "sent": "So Interestingly, here, the likelihood function and the prior distribution with a very similar form.",
                    "label": 0
                },
                {
                    "sent": "And we can think of this as being something like equivalent counts equivalent to our prior knowledge before we see any data.",
                    "label": 0
                },
                {
                    "sent": "So this is now a function of Gina.",
                    "label": 0
                },
                {
                    "sent": "We have to specify here probability for every combination of.",
                    "label": 0
                },
                {
                    "sent": "Settings of realizations of GK and some of them will be more likely and some some of them will not be very likely and I will come to an intuitive.",
                    "label": 0
                },
                {
                    "sent": "The explanation of this formula in the moment.",
                    "label": 0
                },
                {
                    "sent": "First of all this is number which is non negative.",
                    "label": 0
                },
                {
                    "sent": "But it doesn't have to integrate or sum to one.",
                    "label": 0
                },
                {
                    "sent": "So it's not normalized, but sometimes it makes sense to normalize this quantity.",
                    "label": 0
                },
                {
                    "sent": "So we calculate first the sum overall F star case and then divide the Alpha stock his.",
                    "label": 0
                },
                {
                    "sent": "I mean, the Alpha stars came by this number I forgot and observe something which now comes to one.",
                    "label": 0
                },
                {
                    "sent": "So if we do this, we can write this expression over here in this form where we now explicitly have the product of I forgot and I for K. And this makes sense for many reasons.",
                    "label": 0
                },
                {
                    "sent": "One is that if we calculate the.",
                    "label": 0
                },
                {
                    "sent": "Probability of observing a certain result in the tosses given the parameter vector lifestar we have to solve this integral and we obtain this normalized quantity Alpha K. So if we do this normalization by dividing by Alpha, not.",
                    "label": 0
                },
                {
                    "sent": "We obtain the expected values of what we would observe before we have seen any data.",
                    "label": 0
                },
                {
                    "sent": "You just have the Alpha star parameter given and we do it.",
                    "label": 0
                },
                {
                    "sent": "We do a toss, then we would observe these quantities.",
                    "label": 0
                },
                {
                    "sent": "In terms of the probabilities.",
                    "label": 0
                },
                {
                    "sent": "So in some sense the Alpha K indicate the distribution we are expecting.",
                    "label": 0
                },
                {
                    "sent": "A knife and not put some weight on this expectation.",
                    "label": 0
                },
                {
                    "sent": "So if I'm not as very large, we're very strong about our belief that these are the correct probabilities.",
                    "label": 0
                },
                {
                    "sent": "I for now it is very small, then we're not very certain about these probabilities and probabilities.",
                    "label": 0
                },
                {
                    "sent": "We're certain about how this offer cases normalized normalized quantities.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We can also calculate the posterior distribution by sort of.",
                    "label": 1
                },
                {
                    "sent": "Applying Bayes formula to the product of likelihood and the prior distribution and the probability of the parameters given the data and our priority parameters of a star is again additional distribution, where here we now have to add the Alpha stars with the corresponding counts.",
                    "label": 1
                },
                {
                    "sent": "So this is the property of this.",
                    "label": 0
                },
                {
                    "sent": "The fact that we used the.",
                    "label": 0
                },
                {
                    "sent": "Conjugate prior one of the properties of the in this situation is that the posterior takes on the same form as the prior, so it's no surprise that the posterior distribution is also directly.",
                    "label": 1
                },
                {
                    "sent": "And all we can calculate the probability of a toss of the next toss given our prior assumption.",
                    "label": 0
                },
                {
                    "sent": "Given the data.",
                    "label": 0
                },
                {
                    "sent": "And again we can calculate this integral and the result is.",
                    "label": 0
                },
                {
                    "sent": "Very interesting, very important.",
                    "label": 0
                },
                {
                    "sent": "It's quality iPhone, not times Alpha K plus NK normalize.",
                    "label": 0
                },
                {
                    "sent": "So what we see here is that if we have observed a certain result in a past, very often the probability of observing this resulted in the future will be very high.",
                    "label": 0
                },
                {
                    "sent": "And here we see also that I forgot exactly has this meaning of specifying the belief in this in our prior assumption about the distribution.",
                    "label": 0
                },
                {
                    "sent": "That I for case would be the right count.",
                    "label": 0
                },
                {
                    "sent": "So this is also quite an client intuitive result.",
                    "label": 0
                },
                {
                    "sent": "And of course, we also observe if we have N becomes very, very large.",
                    "label": 1
                },
                {
                    "sent": "We can sort of ignore this term and again become obtained the result.",
                    "label": 0
                },
                {
                    "sent": "The same result we would have obtained a maximum likelihood approach that the empirical counts are determining the probabilities for future events.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now we have to look.",
                    "label": 0
                },
                {
                    "sent": "Take a look at a little closer.",
                    "label": 0
                },
                {
                    "sent": "Look at this distribution, which is has some interesting features.",
                    "label": 0
                },
                {
                    "sent": "So this is the definition again in this formula with Alpha stars and now we can plug in different numbers.",
                    "label": 0
                },
                {
                    "sent": "This is the case of a 3 dimensional distribution, so we plotting here two of the dimensions of the third one is the one I thought of ordinal here, so it's sort of we should think signal.",
                    "label": 0
                },
                {
                    "sent": "This is a plane sort of coming out here, and if we specify as I start parameters 111, then here's a 1 -- 1.",
                    "label": 0
                },
                {
                    "sent": "So this is a. G to the zero and everything becomes very uniform, so any parameter value essentially has the same value in this case.",
                    "label": 0
                },
                {
                    "sent": "Then we can increase this iPhone not factor, which just means melting.",
                    "label": 0
                },
                {
                    "sent": "These.",
                    "label": 0
                },
                {
                    "sent": "Multiplying these numbers with a large number for two to 210-1010.",
                    "label": 0
                },
                {
                    "sent": "For example, we see that the probability mass gets more and more concentrated in the central region here, which should be situation .3 and .3.",
                    "label": 0
                },
                {
                    "sent": "So we are implementing our belief that we are dealing with a fair dice.",
                    "label": 0
                },
                {
                    "sent": "All the probabilities are the same and the weight on this belief.",
                    "label": 0
                },
                {
                    "sent": "Also increases because the probability of this distribution .3 point 3.3 becomes larger and larger.",
                    "label": 0
                },
                {
                    "sent": "We can also implement an unbalanced prior belief, so this would indicate that we believe the 2nd.",
                    "label": 0
                },
                {
                    "sent": "Parameter with the 2nd result in the tossing the dice would be a very high probability.",
                    "label": 0
                },
                {
                    "sent": "The first one is low and the third one would also be low.",
                    "label": 0
                },
                {
                    "sent": "And this is an example where the third dimension is very high.",
                    "label": 0
                },
                {
                    "sent": "But the two observed, I mean the two plotted here have a low values.",
                    "label": 0
                },
                {
                    "sent": "So this is all quite reasonable and maybe.",
                    "label": 0
                },
                {
                    "sent": "Quite expected, but this is an interesting plot over here, which is not so expected.",
                    "label": 0
                },
                {
                    "sent": "Maybe so this is it usually distribution with numbers which are slightly smaller.",
                    "label": 0
                },
                {
                    "sent": "Smaller than one, so we remember these various only have to be positively, but there can be smaller than one and we still sort of implement our prior belief that we are dealing with a fair dice because all the probabilities of these numbers here are sort of identical.",
                    "label": 0
                },
                {
                    "sent": "But what now happens if?",
                    "label": 0
                },
                {
                    "sent": "If these numbers become smaller smaller than one that the probabilities in the extreme values.",
                    "label": 0
                },
                {
                    "sent": "Become very likely.",
                    "label": 0
                },
                {
                    "sent": "So although we have sort of implementing an expected sense anyways that we're dealing with a fair dice, any sampled or any dice generated by this prior distribution becomes more and more loaded, and if we make these numbers even smaller, then we will almost exclusively observe these extreme points.",
                    "label": 0
                },
                {
                    "sent": "And this is.",
                    "label": 0
                },
                {
                    "sent": "A little bit surprising when observed this first, and it will also have a very important effect later.",
                    "label": 0
                },
                {
                    "sent": "Individually, process is because this is sort of the explanation.",
                    "label": 0
                },
                {
                    "sent": "Why do usually processes will lead to very clustered solutions where the prior sort of essentially says on average.",
                    "label": 0
                },
                {
                    "sent": "I believe this is a fair dice, but every single dice I'm producing is extremely unfair.",
                    "label": 0
                },
                {
                    "sent": "At least, this is sort of the bias implemented by by this dishley prior distribution.",
                    "label": 0
                },
                {
                    "sent": "If these numbers become smaller and smaller.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is the set of the of the model and to do inference in these models and later on in the display process is it's important to consider how to generate samples from these models.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's OK, maybe first look at graphical representation of the situation.",
                    "label": 0
                },
                {
                    "sent": "So what I mean by generating samples as we start off with some iPhone, not an Alpha parameters.",
                    "label": 0
                },
                {
                    "sent": "We could also have put them together as I for star and based on these parameters describing the prior distribution we generate a sample of G. Using the dishley distribution and then given G we generate samples from different results of of the devices.",
                    "label": 0
                },
                {
                    "sent": "So in this case we do any experiments.",
                    "label": 0
                },
                {
                    "sent": "We throw the dice N times and observe and different values of the results of the dices.",
                    "label": 0
                },
                {
                    "sent": "And there's a more compact representation of this, since this dependency is sort of repeated N * 1 simply draws square around this node over here, and indicates how often this process is repeated.",
                    "label": 0
                },
                {
                    "sent": "This is called a plate representation.",
                    "label": 0
                },
                {
                    "sent": "It's just a shorthand notation for this situation here on the left, so generating samples essentially means we have a factory of devices, and we produce unfair dices according to our.",
                    "label": 0
                },
                {
                    "sent": "Prior assumption about.",
                    "label": 0
                },
                {
                    "sent": "The probability of generating G. Then we take this unfair dices and throw the dice is and then observe these data belong to a given Dyas.",
                    "label": 0
                },
                {
                    "sent": "Say something.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so this is.",
                    "label": 0
                },
                {
                    "sent": "So the first approach is to do exactly what I have described.",
                    "label": 1
                },
                {
                    "sent": "You first generate a sample of G of this of the parameters of the diocese, and then you generate these tosses.",
                    "label": 1
                },
                {
                    "sent": "It's not.",
                    "label": 1
                },
                {
                    "sent": "It's not straightforward to generate these samples for G, But there are different approaches and I don't want to get too much into detail how the system.",
                    "label": 0
                },
                {
                    "sent": "But if you look at the literature, there are different ways of doing it.",
                    "label": 1
                },
                {
                    "sent": "Here's describing that you sample from independent gamma distributions.",
                    "label": 1
                },
                {
                    "sent": "Using certain shape parameters and normalizes samples, but I don't want to get into a lot of detail here in the later in the deep case, an additional process case.",
                    "label": 0
                },
                {
                    "sent": "This is more interesting and will lead us to the stick breaking representation, but given that we have generated the sample from the dishley distribution, it's very simple.",
                    "label": 0
                },
                {
                    "sent": "Of course to generate samples of the of the tosses because these genes are simply the probabilities of observing a certain result in throwing the dice.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is the first approach.",
                    "label": 0
                },
                {
                    "sent": "The second approach is also very interesting.",
                    "label": 0
                },
                {
                    "sent": "We never generate a sample of G directly, but we directly generate samples of the results of the of the devices.",
                    "label": 0
                },
                {
                    "sent": "And to do this we use the equation we have observed you have used before before we said, given past observations of results of.",
                    "label": 0
                },
                {
                    "sent": "We want to predict the result of the next thoughts and we use we came up with this formula over here.",
                    "label": 0
                },
                {
                    "sent": "But we can also use exactly the same formula too.",
                    "label": 1
                },
                {
                    "sent": "Generate samples of and specific but unknown unloaded loaded dice.",
                    "label": 0
                },
                {
                    "sent": "So in this sense we have generated some samples.",
                    "label": 0
                },
                {
                    "sent": "We put them in D and condition on them and use exactly the same formula to estimate our probability probability of observing the next result of the next toss.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "The advantage here is that we never have to assemble from G. In particular, gym might become later on infinite dimensional and it's not very easy to assemble of G. This is a very nice equation because we never have to do that.",
                    "label": 0
                },
                {
                    "sent": "We can directly sample from the results of the guys we're tossing.",
                    "label": 0
                },
                {
                    "sent": "Because interpret this in this way with probability proportional to N, we will sample from a distribution with empirical accounts and with probability proportional to Alpha, not you generate the sample according to the distribution implied by the Eiffel case.",
                    "label": 1
                },
                {
                    "sent": "This is also a very nice interpretation of this iPhone.",
                    "label": 1
                },
                {
                    "sent": "Not again, it's very weak.",
                    "label": 0
                },
                {
                    "sent": "We will right away sample from the empirical data from the empirical estimate of the probabilities.",
                    "label": 0
                },
                {
                    "sent": "If I find out if a strong we will this term will.",
                    "label": 0
                },
                {
                    "sent": "Dominate quite awhile and we will keep sampling from our prior model.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and this type of sampling later be associated with the pool, your own representation and the Chinese restaurant process.",
                    "label": 0
                },
                {
                    "sent": "Just to",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Later, you might look at this up, but there's a very strange thing about this.",
                    "label": 0
                },
                {
                    "sent": "Equation is also related to this strange property of the richly prior.",
                    "label": 0
                },
                {
                    "sent": "If you look at this formula and let for not go to zero, then what does this mean?",
                    "label": 0
                },
                {
                    "sent": "It means if we observe one.",
                    "label": 1
                },
                {
                    "sent": "Result of of that.",
                    "label": 0
                },
                {
                    "sent": "I sort of dice and this result will immediately dominate all the probabilities, because this number is very small.",
                    "label": 1
                },
                {
                    "sent": "So after the first toss we have here, especially one.",
                    "label": 0
                },
                {
                    "sent": "Well, one for the observed toss and the zero for all the other choices for the other possible results.",
                    "label": 0
                },
                {
                    "sent": "So this seems to be very strange now you might want to implement a fair die assumption about a fair dice, but all we are generating are very unfair loaded dices.",
                    "label": 1
                },
                {
                    "sent": "And this can also be seen if you take the this distribution and let these iPhone not go to zero.",
                    "label": 0
                },
                {
                    "sent": "Then this becomes essentially one over the parameters and this is maximized if most most parameters become zero and all the probability mass is sort of taking up by one of the parameters.",
                    "label": 0
                },
                {
                    "sent": "So this is a little bit strange thing in the data sleeve distribution and generally processes that at least two very highly unbalanced solutions and the high tendency.",
                    "label": 0
                },
                {
                    "sent": "To be produced sort of very clustered solutions and which can be tuned by varying this concentration parameter Alpha.",
                    "label": 0
                },
                {
                    "sent": "Not so if you make it very small we will get a very small number of very concentrated parameters.",
                    "label": 0
                },
                {
                    "sent": "Let me in parameters which were small number will have very high values, the other ones will have various almost equal to 0 and the other device or not is very large.",
                    "label": 0
                },
                {
                    "sent": "Prior will dominate very long and we will get a very smooth.",
                    "label": 0
                },
                {
                    "sent": "Is that?",
                    "label": 1
                },
                {
                    "sent": "But this is the paradox is more when we let off and not go to 0.",
                    "label": 1
                },
                {
                    "sent": "I'm.",
                    "label": 0
                },
                {
                    "sent": "So the resources that we should think of Alpha without knowing the Alpha distribution is really important.",
                    "label": 0
                },
                {
                    "sent": "Implementing our prior belief, but that this probability is very, very weak and can be easily overwritten by data which we observe for which we have generated.",
                    "label": 1
                },
                {
                    "sent": "But this is something to be comes comes back again.",
                    "label": 0
                },
                {
                    "sent": "The situation when we talk about directly processes, which we will show exactly the same result that.",
                    "label": 0
                },
                {
                    "sent": "Probably probability mass tends to be clustered in.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Small number of clusters.",
                    "label": 0
                },
                {
                    "sent": "There's another illustration of the situation.",
                    "label": 0
                },
                {
                    "sent": "The better distribution is essentially usually distribution, which was two dimensions, so it's a little bit easier to plot and what we have talked about is this situation over here.",
                    "label": 0
                },
                {
                    "sent": "When I find better, the two parameters here 1/2, we get this effect that these extreme.",
                    "label": 1
                },
                {
                    "sent": "Distributions with 1001 very high probability and in between the drops to very small values, whereas other distributions behave more normally if you have Alpha equals two better equals five, we get a nice model distribution over here.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this was now concerned with the experiment that somebody generates these.",
                    "label": 0
                },
                {
                    "sent": "The loaded ISIS, like a loaded dice factory or so, and then we observe tosses of a loaded dice is now we make the model one step more complicated.",
                    "label": 0
                },
                {
                    "sent": "And we assume we obtain noisy situations.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Maybe let me go to the graphic representations right away so this is what we had before we had some prior distribution of producing loaded dices.",
                    "label": 0
                },
                {
                    "sent": "Then of observing the tosses of the loaded dice, and now we assume that we cannot observe these results directly, but some derived quantities of the result of the loaded dice.",
                    "label": 0
                },
                {
                    "sent": "So let's say these are unreliable friends which tell us about the outcome of the experiment, and we might even have more than one.",
                    "label": 0
                },
                {
                    "sent": "So in this case we might have.",
                    "label": 0
                },
                {
                    "sent": "I'm friends, which all gives us give us some sort of unreliable information about the outcome of the toss.",
                    "label": 0
                },
                {
                    "sent": "And of course, this will be hopefully everybody will see that this is a very useful model later on.",
                    "label": 0
                },
                {
                    "sent": "Right now it seems to be a little bit artificial.",
                    "label": 0
                },
                {
                    "sent": "This is the situation now and now we.",
                    "label": 0
                },
                {
                    "sent": "We didn't observe this set as we only observe the access, which are the results of the information given by some.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Reliable friends, let's say.",
                    "label": 0
                },
                {
                    "sent": "So what we now have to specify some probability of observing this results in the information of the.",
                    "label": 0
                },
                {
                    "sent": "Unreliable friends, given the results of the tosses in this probability distribution, and we assign a certain set of data DI to the.",
                    "label": 0
                },
                {
                    "sent": "To set a right to the result of the talks.",
                    "label": 0
                },
                {
                    "sent": "And now again, we might be interested in updating our belief about this quality G. The parameters describing the loaded dice is or we might be interested in predicting and estimating the actual results of the tosses.",
                    "label": 1
                },
                {
                    "sent": "Or we might want to predict the next result of a task based on the observed data.",
                    "label": 1
                },
                {
                    "sent": "So this is now a problem with missing data.",
                    "label": 0
                },
                {
                    "sent": "The fact are missing.",
                    "label": 0
                },
                {
                    "sent": "We haven't observed them.",
                    "label": 0
                },
                {
                    "sent": "And there are different ways of dealing with this problem.",
                    "label": 1
                },
                {
                    "sent": "The one which is relevant in context with the richly process is is the approach based on Gibbs sampling, which I will discuss in a moment.",
                    "label": 0
                },
                {
                    "sent": "Another possible approach, of course, is to use the popular EM algorithm, which gives us point estimates of the parameters G, But the Gibbs sampling is sort of the more.",
                    "label": 0
                },
                {
                    "sent": "Appropriate from a basin POV because you're taking all the uncertainty more serious, whereas in the EM algorithm you end up with point estimates, which is has more flavor for frequentist approach.",
                    "label": 0
                },
                {
                    "sent": "So this experiment?",
                    "label": 0
                },
                {
                    "sent": "Hopefully clear.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So yeah, this is a shot.",
                    "label": 0
                },
                {
                    "sent": "Attempt to explain what Gibbs sampling is all about.",
                    "label": 0
                },
                {
                    "sent": "So for example, if you are interested in probability of observing the next result of our our ties.",
                    "label": 0
                },
                {
                    "sent": "We based on the data, we can decompose it first in the probability of observing the past of the past choices given the data times the probability of the next test given the past results of the tosses and we have to integrate about these unknown quantities because that I want to set and the results are really unknown and this is a very big sum because this might be these are in terms.",
                    "label": 0
                },
                {
                    "sent": "Maybe having two to the N different configurations and depending on the number of states, but this sort of grows exponentially in the number of variables goes up the terms you have to sum about grows exponentially the number of terms.",
                    "label": 0
                },
                {
                    "sent": "So the idea in Monte Carlo approximation is to approximate this term over here by this expression over here.",
                    "label": 0
                },
                {
                    "sent": "So this should be pure Theta N + 1, not the popular.",
                    "label": 0
                },
                {
                    "sent": "Given these quantities over here and these are samples of this distribution over here.",
                    "label": 0
                },
                {
                    "sent": "So the idea is to sample of this distribution.",
                    "label": 0
                },
                {
                    "sent": "And plug these samples into this expression and take the average over over this summer.",
                    "label": 0
                },
                {
                    "sent": "So this is the basic idea and Monte Carlo approximation, and one can sort of proof convergence of this expression if X goes to Infinity.",
                    "label": 0
                },
                {
                    "sent": "The problem here is now that we need these independent samples of these parameters of this posterior.",
                    "label": 0
                },
                {
                    "sent": "Solution of the unknown parameters given the data and and.",
                    "label": 0
                },
                {
                    "sent": "This is sort of the difficult part.",
                    "label": 0
                },
                {
                    "sent": "I mean, this sum is really nice and simple and very intuitive, but obtaining independent samples quite quite difficult.",
                    "label": 0
                },
                {
                    "sent": "And one typically have to rely on multiple Markov chain Monte Carlo methods, which does not produce independent samples of the distribution.",
                    "label": 0
                },
                {
                    "sent": "I mean it produces samples of the correct distribution, but subsequent samples are quite dependent because the next sample depends on previous sample doesn't depend on other or the other symbol in the past, but it depends on the previous sample.",
                    "label": 0
                },
                {
                    "sent": "And and the general approach is called Markov chain Monte Carlo sampling.",
                    "label": 1
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And an example of this which will be used.",
                    "label": 0
                },
                {
                    "sent": "In this lecture is called gift sampling, which is a specific form of Markov chain Monte Carlo sampling.",
                    "label": 1
                },
                {
                    "sent": "So the idea and Gibbs sampling is that all the unknown variables initialized in some smart way.",
                    "label": 1
                },
                {
                    "sent": "And then we repeatedly replace the values.",
                    "label": 0
                },
                {
                    "sent": "Off one of the variables.",
                    "label": 0
                },
                {
                    "sent": "Given by a new sample of the probability distribution of this variable given all the other variables and given the data.",
                    "label": 1
                },
                {
                    "sent": "So essentially we update one variable at a time.",
                    "label": 0
                },
                {
                    "sent": "And we updated by considering this conditional probability distribution.",
                    "label": 0
                },
                {
                    "sent": "We want to find out what all the other data and all the other samples have to tell us about the variables we are interested in updating.",
                    "label": 1
                },
                {
                    "sent": "We calculate this probability distribution and update this variable 1 by 1.",
                    "label": 0
                },
                {
                    "sent": "And we have to do that for all variables in some reasonable order.",
                    "label": 1
                },
                {
                    "sent": "It's not very important exactly how we do it, but of course every variable should be updated solution number of times.",
                    "label": 0
                },
                {
                    "sent": "So one so one can show that after some burning phase this produces samples exactly of the right distribution.",
                    "label": 0
                },
                {
                    "sent": "The problem is that they might be independent.",
                    "label": 0
                },
                {
                    "sent": "So if you have a Gaussian distribution, let's say.",
                    "label": 0
                },
                {
                    "sent": "Sort of time.",
                    "label": 0
                },
                {
                    "sent": "Then you might start over here and you might sample along time in this region before you sort of come up to the other region of the Gaussian distribution, and you move back so the samples are dependent, which is called if they're very dependent, it means that the change doesn't mix very well.",
                    "label": 1
                },
                {
                    "sent": "If they're sort of tend to be independent, then this is a desired property property, and it said that the chain mixes well.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "OK, in the first approach is what happens happening down there?",
                    "label": 0
                },
                {
                    "sent": "OK it's where we apply this idea of sampling from the setters without ever sampling from the G to generate samples for the other setters, and this is called collapsed Gibbs sampling 'cause we integrate out this quantity G which we never sample off.",
                    "label": 1
                },
                {
                    "sent": "We've sort of 1st integrate authors quality so we only have to samples from the status.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And So what we need is to update one specific quantity over here.",
                    "label": 0
                },
                {
                    "sent": "So this is again the result of a dice.",
                    "label": 0
                },
                {
                    "sent": "So what's the probability of cetacaine taking on the value Theta L given all the other samples?",
                    "label": 0
                },
                {
                    "sent": "So I left all this South for convenience and given all the data.",
                    "label": 0
                },
                {
                    "sent": "So first of all, we can say that given all the other samples of all the other tosses, we don't need all the data, we only need to condition on the data of this particular trust.",
                    "label": 0
                },
                {
                    "sent": "We are interested in.",
                    "label": 0
                },
                {
                    "sent": "So we remove or maybe replace D by DK, then in the next step we can apply based formula to turn around these probabilities.",
                    "label": 0
                },
                {
                    "sent": "The normalization factor, where again here we have explored that.",
                    "label": 0
                },
                {
                    "sent": "So we have explored independence.",
                    "label": 0
                },
                {
                    "sent": "Forgot.",
                    "label": 0
                },
                {
                    "sent": "OK, I don't see it right now, But anyway, this is the formula we end up with and this term we already know this.",
                    "label": 0
                },
                {
                    "sent": "The probability of drawing a sample for the K store's given all the other choices, which is just this expression over here which we have seen before it cipher, not times I felt I'm plus the number of observations of this result and times the probability of observed of observing the data, given that this is the result of the toss.",
                    "label": 0
                },
                {
                    "sent": "So this is very similar to what we have observed before.",
                    "label": 0
                },
                {
                    "sent": "Before we had this before, we have seen any data.",
                    "label": 0
                },
                {
                    "sent": "Now we simply multiply.",
                    "label": 0
                },
                {
                    "sent": "Multiply this term by the likelihood of observing the data.",
                    "label": 0
                },
                {
                    "sent": "Given that we make the assumption that we observe.",
                    "label": 0
                },
                {
                    "sent": "So this will now give higher probability to results which agree with the data we have observed for this particular result of the test.",
                    "label": 0
                }
            ]
        }
    }
}