{
    "id": "fj7gszwuotvp7fqossigxspcew27b3ac",
    "title": "Discriminative and Generative Views of Binary Experiments",
    "info": {
        "author": [
            "Robert C. Williamson, Australian National University"
        ],
        "published": "March 26, 2010",
        "recorded": "December 2009",
        "category": [
            "Top->Computer Science->Machine Learning->Supervised Learning"
        ]
    },
    "url": "http://videolectures.net/nipsworkshops09_williamson_dgvbe/",
    "segmentation": [
        [
            "Those are nasty Chris Morris Williamson and he'll be talking college with generative intuitively.",
            "Winery experience.",
            "Thanks.",
            "So I'm interested in learning problems.",
            "My big research agenda at the moment is to try and take a much higher level view to see how all of the dots connect, and so I'm going to join two dots in this talk.",
            "So to start, look at the."
        ],
        [
            "First formula on the slide there this is a classical result.",
            "You find it in.",
            "The book by Gabor Lugosi and looked of Roy.",
            "Left hand side, you've got the Bayes risk for 01 loss for a particular binary problem.",
            "P&Q of the class conditional distributions.",
            "So that tells you the minimum risk that you can achieve with respect to 01 loss on the right hand side you've got half minus 1/4 of the variational divergences between those two distributions.",
            "The variational divergents is a classical distance measure between two distributions, right?",
            "So I've formally defined.",
            "These two quantities, the Bayes risk there, it's the minimum of the expected risk.",
            "So you take the minimum.",
            "Overall functions are from the input SpaceX to set 01, and here's the definition of the variational divergences.",
            "It's got two different forms.",
            "The first one shows why it's called variational to variational representation.",
            "But you can also write it in the second form where little P and little Q are just the densities.",
            "OK, so.",
            "That's kind of interesting.",
            "Two different views of the same thing.",
            "An exact equality and the theme of this talk is to.",
            "Really, a meditation on that.",
            "Generalize this and see where it leads us."
        ],
        [
            "So these.",
            "The two sides of that formula.",
            "Give two different views of a binary experiment which are illustrated in the picture here.",
            "So on the left hand side you've got what I call the generative view, and there's a bit of Humpty Dumpty ISM here.",
            "I'm using generative in my sense, and you know, maybe it's different to what you're using, but it seems the right would use.",
            "You have the two class conditional distributions and that's the way you're thinking of the problem, and you know if you want to predict.",
            "Obviously if these distributions don't overlap, that's easier than if they do.",
            "That's what the variational divergences measuring.",
            "On the right hand side you have what we call the discriminative view.",
            "So the key parameters there are M. That's the underlying distribution of the data.",
            "That's just the distribution on your input space.",
            "And Eater, which is the sorry the conditional probability of a positive label given the value of X. OK, so you know it should be intuitively clear that you can use either one of these and it's kind of trivial to translate from one to the other and back right there two sides of the same coin.",
            "So."
        ],
        [
            "I want to look at.",
            "A whole bunch of different loss functions, not just 01 loss, and I have to have a little bit of notation to talk about that.",
            "So rather than just being interested in giving a label more generally, you might want the probability of a label, and you don't want to just say this is a positive example.",
            "You want to say it's a positive example and give your certainty probability .8 or probability .6.",
            "So we use Eater to denote probability values and eat.",
            "A hat is the is the."
        ],
        [
            "Estimate you have a loss function which takes 2 arguments.",
            "First argument is the actual label that you get, and the second argument is the predictor that you have, right?",
            "So you can just given binary labels, but your prediction is in the interval zero to 1.",
            "Um?",
            "And then you have the conditional loss.",
            "So this is when you take expectations over the labels that you get.",
            "So normally in constructing the full expected loss you actually take in two different expectations.",
            "You're taking the expectations with respect to why the labels, and then the expectation over X.",
            "Now it turns out that if you split that expectation in two parts and work with this thing that we call the conditional expectation the conditional risk rather in ghost in white causes the inner risk.",
            "Then you can actually do a lot of work with this capital L, Theoretically, which is nice becausw why you often don't know the distribution on the X is so you can make a lot of progress with this so you can see what you've got here.",
            "You've got the elementary partial losses, right?",
            "This is the zero, is the label zero?",
            "You've got the probability of getting a zero label, which is just one minor Cedar here.",
            "We've got the loss when you've got a label one with your estimate Eater Hat and Eater.",
            "Is the true probability of getting a positive label, so I've just computed this expectation right?",
            "So little L is the pointwise loss capital, L is the conditional loss, the conditional risk?",
            "And then you can take the expectation of capital L with respect to the distribution of the X is, so that's what I'm doing here.",
            "On the right hand side and that gives me the full risk.",
            "OK, now this depends on Eater hat, which is now a function, right?",
            "So to translate from the conditional perspective where you have either hat is just a number to the full risk perspective you now think of either had as a function from X201.",
            "OK, so little else pointwise loss.",
            "Capital L is the conditional loss and the BF L is the full expected loss.",
            "So to define a problem that you want to solve, you can do this now in two ways and in my language discriminatively or generatively you can either have the easier M&L or you can have.",
            "\u03a0, which is the apriori probability of a positive label.",
            "You know, you might have a lot more positive examples of negative.",
            "The two class conditional distributions and L that is a complete spec of a of a problem, and the Bayes risk, to reiterate is the measure of difficulty of the learning problem.",
            "It's the best that you can do.",
            "It's the smallest value of the expected risk that you can get, and you can indeed write it as the expected value.",
            "Of the conditional Bayes risk.",
            "So this is, you know, illustration of whites.",
            "You can actually do a fair bit of work before you take the outer expectation."
        ],
        [
            "So instead of 01 loss you can have a much wider class of losses, and if you're interested in class probability estimation that is predicting the probability of a positive label, the natural class of losses to use our proper losses.",
            "So proper losses have the property that they are minimized when you get that probability estimate correct.",
            "It's kind of the natural thing to do, and that that that alone actually gives you a lot of structure, so there's a result due to Savage the 1970s, which I mean.",
            "I was ignorant of until last year.",
            "Actually, you don't see this in machine learning textbooks.",
            "Amazingly, and it is very simple and it says that the conditional loss.",
            "Went so for losses proper you can write the conditional loss in this form, right?",
            "So here we've got the Bayes.",
            "The Conditional Bayes risk.",
            "Here we've got the first derivative of the conditional Bayes risk and what's interesting is you see that the only way that either had an eater come in together is in that second term, right?",
            "So you don't have some arbitrary function of ITA Anita hat, right?",
            "You know you look at the left hand side you think are this is like this is a function of two variables, the only dependences through that either minus eat ahead as a.",
            "A lot of structure imposed by the assumption of properness.",
            "So there there that's the generalized."
        ],
        [
            "I want to use on the left hand side of my first equation.",
            "And on the right hand side, we want to generalize the variational divergences.",
            "But this is also been done for a long time in the 1960s.",
            "She's developed F divergences the same time Ally and Sylvie.",
            "Did it in the statistics community.",
            "It's the same thing, and here's the definition and I'm not going to go through this in detail, right?",
            "This is you can read about this in textbooks.",
            "Key thing I want you to realize is that it's a distance between two distributions, P&Q and there's an OB F right.",
            "F is the nob that you choose a different F you get a different distance?",
            "And what is F?",
            "It's a convex function and we normalize it such that F of 1 = 0, right?",
            "That's just a convenience, right?"
        ],
        [
            "If you.",
            "Right, so you just think F is a convex function, so we've got the set of proper losses and you've got a lot of freedom there, but not arbitrary functions of two variables.",
            "And you've got F divergences, and here's some examples of F divergences, right?",
            "Pretty well, not many.",
            "Many of the standard distances between distributions.",
            "You get yourself a different F. So the key result in the paper that's pointed to."
        ],
        [
            "From the workshop page relates these quantities together.",
            "So.",
            "There's a bunch of constructions you've got to do, and the key thing to take away from this is that you can do all of this very explicitly, right.",
            "The bottom line is the stuff here in red.",
            "So what we've got is the FD vergence.",
            "Is this thing?",
            "Now?",
            "There's a slight complication.",
            "This is not the risk.",
            "This is a thing called the statistical information, and it's related to a thing called the Bregman information.",
            "So this thing here, the triangle L bar is called the statistical information.",
            "It's the difference between the prior and posterior Bayes risk.",
            "The prior Bayes risk is what is the Bayes risk you would get if you didn't have any data points.",
            "If all you knew was the probability of a positive example, so it's a natural normalize."
        ],
        [
            "Way of doing it just makes it nicer, so you can have this equals.",
            "This equals this without any constants, right?",
            "So this is a generalization of the result I showed you on the first page.",
            "I'm not going to talk in detail about the Bregman Divergent's stuff, but if people are interested I can tell you later on now.",
            "Actually, from this perspective, you can do a lot more it."
        ],
        [
            "Is it that you can represent every loss as a weighted integral of primitive losses and they are cost sensitive misclassification losses?",
            "It turns out every F Divergents can be also written as a weighted integral combination of primitive F divergences, and they're like the variational divergents.",
            "So the result on the previous page actually allows you to take the weight function for the loss and transform it through an explicit formula and get the weight function for the F divergents.",
            "Now without justifying why I will just assert that these representations or parameterisations of losses and F divergences respectively are the right ones to you.",
            "Alright.",
            "If you get equality of the white functions, you get equality of."
        ],
        [
            "The two divergences.",
            "So there's an interesting development that arises from this perspective.",
            "If you slightly generalize the notion of variational divergents to allow an imbalance.",
            "So unequal class probabilities, that's the only thing that I've done here, and I also consider a loss function.",
            "The linear loss, which isn't a legitimate loss because it's not bounded from below, but I will deal with that.",
            "I'll show you an interesting connection."
        ],
        [
            "So first of all, pretty trivially, you get a generalization of the result on the 1st slide.",
            "That is the Bayes risk with respect to the linear loss.",
            "And now I've got a parameter Pi, which is the probability of a positive label and on the right hand side I've got a variational divergent.",
            "Here there's a factor of two that's gone missing, but we've kept kept careful track of that, so just trust me.",
            "Now if."
        ],
        [
            "You instead of just thinking of drawing your function from an arbitrary set, you actually work in a reproducing kernel Hilbert space like you do in kernel machines.",
            "So now my set R is a unit ball in a Hilbert space.",
            "That means I've got a kernel and I've got inner products.",
            "I can represent a kernel is dot product of feature vectors, then Karsten Borgwardt and others have shown that you can write this quantity.",
            "The square of this generalized variational divergences with respect to that function set the set of functions in a unit ball in a Hilbert space.",
            "You can write like this where now this thing is the norm in the Hilbert space.",
            "This is just standard kernel trickery.",
            "OK, there's nothing particularly fancy there, and it's just a few line proof.",
            "As a consequence of that, in the previous slide, you can write the Bayes risk with respect to this linear loss like that OK. Now this is the kind of the slightly odd."
        ],
        [
            "Thing that we've done, you say that's all for full distributions.",
            "What if you have an empirical sample so you know the normal way of going from a distribution to a sample is you're taking the empirical distribution.",
            "Now you can generalize that and have a weighted empirical distribution, and this is used in particle filtering.",
            "You put weights on these samples that aren't necessarily all equal, so if you go and do that in the alphas are going to be the weights, and then you can write, you know.",
            "Here's the empirical.",
            "This is the empirical expected value with respect to a sequence of points W weights Alpha of some function Phi.",
            "And again this just goes through.",
            "It's still an expectation, right?",
            "So the same formula works, it just looks uglier because I've got a lot of these indices around.",
            "Still expectations that the norms and everything still."
        ],
        [
            "So if you do this and we say that we want to keep a balance, so we have this parameter \u03c0.",
            "Which tells you the probability of a positive label if you've got EM samples right and \u03c0 = 3/4.",
            "That means you're going to have three M / 4 positive samples on average, and one M / 4 negative samples.",
            "So keeping track of that, and I know there's a number of indices that maybe you should just kind of glaze over, squint your eyes a bit, and get the feel for these formulas, because I don't know how to write it without so many indices."
        ],
        [
            "And you can then again, do you know the usual kernel manipulations, but this quantity of interest you express it in these inner products.",
            "Simple calculation.",
            "You get this formula down here, right?",
            "So this one is a crucial one to look at and this should start to look familiar for those people who do kernel methods right?",
            "So I've got this objective function J depends on Alpha and the sample X."
        ],
        [
            "If I put all of the Alpha is equal to 1, so that's just the normal empirical distribution and plug this in here then this thing is equal to what's called MMD maximum mean discrepancy.",
            "So that's shown up in NIPS in a number of papers in the last few years.",
            "So what you see here is that MMD is simply doing Kernel Fisher discriminant analysis.",
            "Assuming that class covariance matrices.",
            "The identity, right?",
            "So that's this dual view, right?",
            "You can either think of a distance between distributions, which is what MMD is about.",
            "Or I can interpret them as class conditional distributions for discrimination problem and then realize that's what I'm doing."
        ],
        [
            "If instead of having a uniform weighting, I say what's the worst thing that I could do so the worst thing that I could do is to maximize the Bayes risk, right?",
            "We want the Bayes risk to be as small as possible, so suppose I say what choice of alphas makes the Bayes risk worse, right?",
            "Because that's kind of the worst thing that I could do for myself, so I have this minimization problem.",
            "These are the constraints that I just had to propagate through to keep the problem consistent, and hey presto, I get the support vector machine.",
            "That just falls out of it and the support vector machine uses the sign of this function as its predictor."
        ],
        [
            "If I wanted to interpolate between the previous two cases, I could bound the magnitude of the weights.",
            "If I cap how big the alphas can be right, then I can go between doing the worst case or squish it down so that they're all uniform.",
            "Sonu is now a nob that does that, and if I do that, then Crispin Burgess showed that this is actually equivalent to what's called the new SVM.",
            "So what we've got?"
        ],
        [
            "And my last slide is two different views, so the traditional way of you know that Nixon, empirical risk minimization, inductive principle you have expected base risk.",
            "You do an empirical approximation.",
            "You then have to restrict the class to regularize it, and that's what you go and estimate.",
            "What I've done is I've started with this thing, which is not really a legitimate until I restrict the class.",
            "Then I do an empirical approximation, but I have the flexibility are doing it with a weighted empirical distribution.",
            "The same thing, so that's interesting so."
        ],
        [
            "I had two different views of the same thing.",
            "There, two sides of the same coin.",
            "I've omitted the details of the weight functions and interesting Lee, you can get SVM's in MMD from this perspective.",
            "Question.",
            "So what's next?",
            "So the thing we're working on at the moment is extending this to the multiclass case, and Interestingly, I can prove that there does exist an integral representation for the multiclass losses guarantee that one exists, but we haven't found it yet.",
            "So at least we know that the thing we're shooting for is nice.",
            "Is there and what end you know, the hope of having that is that you'll have some nice knobs for multiclass losses, because this seems a lot tougher.",
            "People come up with these multiclass losses.",
            "Some of them aren't even proper.",
            "We want to parameterise all legitimate proper multiclass losses, and it actually can suggest a whole bunch of things that you can do.",
            "You can get the surrogate regret bound, you can develop new learning algorithms.",
            "So I'm working on."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Those are nasty Chris Morris Williamson and he'll be talking college with generative intuitively.",
                    "label": 0
                },
                {
                    "sent": "Winery experience.",
                    "label": 0
                },
                {
                    "sent": "Thanks.",
                    "label": 0
                },
                {
                    "sent": "So I'm interested in learning problems.",
                    "label": 0
                },
                {
                    "sent": "My big research agenda at the moment is to try and take a much higher level view to see how all of the dots connect, and so I'm going to join two dots in this talk.",
                    "label": 0
                },
                {
                    "sent": "So to start, look at the.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "First formula on the slide there this is a classical result.",
                    "label": 0
                },
                {
                    "sent": "You find it in.",
                    "label": 0
                },
                {
                    "sent": "The book by Gabor Lugosi and looked of Roy.",
                    "label": 0
                },
                {
                    "sent": "Left hand side, you've got the Bayes risk for 01 loss for a particular binary problem.",
                    "label": 1
                },
                {
                    "sent": "P&Q of the class conditional distributions.",
                    "label": 0
                },
                {
                    "sent": "So that tells you the minimum risk that you can achieve with respect to 01 loss on the right hand side you've got half minus 1/4 of the variational divergences between those two distributions.",
                    "label": 1
                },
                {
                    "sent": "The variational divergents is a classical distance measure between two distributions, right?",
                    "label": 0
                },
                {
                    "sent": "So I've formally defined.",
                    "label": 0
                },
                {
                    "sent": "These two quantities, the Bayes risk there, it's the minimum of the expected risk.",
                    "label": 0
                },
                {
                    "sent": "So you take the minimum.",
                    "label": 0
                },
                {
                    "sent": "Overall functions are from the input SpaceX to set 01, and here's the definition of the variational divergences.",
                    "label": 0
                },
                {
                    "sent": "It's got two different forms.",
                    "label": 0
                },
                {
                    "sent": "The first one shows why it's called variational to variational representation.",
                    "label": 0
                },
                {
                    "sent": "But you can also write it in the second form where little P and little Q are just the densities.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "That's kind of interesting.",
                    "label": 1
                },
                {
                    "sent": "Two different views of the same thing.",
                    "label": 0
                },
                {
                    "sent": "An exact equality and the theme of this talk is to.",
                    "label": 0
                },
                {
                    "sent": "Really, a meditation on that.",
                    "label": 0
                },
                {
                    "sent": "Generalize this and see where it leads us.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So these.",
                    "label": 0
                },
                {
                    "sent": "The two sides of that formula.",
                    "label": 0
                },
                {
                    "sent": "Give two different views of a binary experiment which are illustrated in the picture here.",
                    "label": 0
                },
                {
                    "sent": "So on the left hand side you've got what I call the generative view, and there's a bit of Humpty Dumpty ISM here.",
                    "label": 0
                },
                {
                    "sent": "I'm using generative in my sense, and you know, maybe it's different to what you're using, but it seems the right would use.",
                    "label": 0
                },
                {
                    "sent": "You have the two class conditional distributions and that's the way you're thinking of the problem, and you know if you want to predict.",
                    "label": 0
                },
                {
                    "sent": "Obviously if these distributions don't overlap, that's easier than if they do.",
                    "label": 0
                },
                {
                    "sent": "That's what the variational divergences measuring.",
                    "label": 0
                },
                {
                    "sent": "On the right hand side you have what we call the discriminative view.",
                    "label": 0
                },
                {
                    "sent": "So the key parameters there are M. That's the underlying distribution of the data.",
                    "label": 0
                },
                {
                    "sent": "That's just the distribution on your input space.",
                    "label": 0
                },
                {
                    "sent": "And Eater, which is the sorry the conditional probability of a positive label given the value of X. OK, so you know it should be intuitively clear that you can use either one of these and it's kind of trivial to translate from one to the other and back right there two sides of the same coin.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I want to look at.",
                    "label": 0
                },
                {
                    "sent": "A whole bunch of different loss functions, not just 01 loss, and I have to have a little bit of notation to talk about that.",
                    "label": 1
                },
                {
                    "sent": "So rather than just being interested in giving a label more generally, you might want the probability of a label, and you don't want to just say this is a positive example.",
                    "label": 1
                },
                {
                    "sent": "You want to say it's a positive example and give your certainty probability .8 or probability .6.",
                    "label": 0
                },
                {
                    "sent": "So we use Eater to denote probability values and eat.",
                    "label": 1
                },
                {
                    "sent": "A hat is the is the.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Estimate you have a loss function which takes 2 arguments.",
                    "label": 0
                },
                {
                    "sent": "First argument is the actual label that you get, and the second argument is the predictor that you have, right?",
                    "label": 0
                },
                {
                    "sent": "So you can just given binary labels, but your prediction is in the interval zero to 1.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And then you have the conditional loss.",
                    "label": 0
                },
                {
                    "sent": "So this is when you take expectations over the labels that you get.",
                    "label": 0
                },
                {
                    "sent": "So normally in constructing the full expected loss you actually take in two different expectations.",
                    "label": 0
                },
                {
                    "sent": "You're taking the expectations with respect to why the labels, and then the expectation over X.",
                    "label": 0
                },
                {
                    "sent": "Now it turns out that if you split that expectation in two parts and work with this thing that we call the conditional expectation the conditional risk rather in ghost in white causes the inner risk.",
                    "label": 0
                },
                {
                    "sent": "Then you can actually do a lot of work with this capital L, Theoretically, which is nice becausw why you often don't know the distribution on the X is so you can make a lot of progress with this so you can see what you've got here.",
                    "label": 0
                },
                {
                    "sent": "You've got the elementary partial losses, right?",
                    "label": 0
                },
                {
                    "sent": "This is the zero, is the label zero?",
                    "label": 0
                },
                {
                    "sent": "You've got the probability of getting a zero label, which is just one minor Cedar here.",
                    "label": 0
                },
                {
                    "sent": "We've got the loss when you've got a label one with your estimate Eater Hat and Eater.",
                    "label": 0
                },
                {
                    "sent": "Is the true probability of getting a positive label, so I've just computed this expectation right?",
                    "label": 0
                },
                {
                    "sent": "So little L is the pointwise loss capital, L is the conditional loss, the conditional risk?",
                    "label": 0
                },
                {
                    "sent": "And then you can take the expectation of capital L with respect to the distribution of the X is, so that's what I'm doing here.",
                    "label": 0
                },
                {
                    "sent": "On the right hand side and that gives me the full risk.",
                    "label": 0
                },
                {
                    "sent": "OK, now this depends on Eater hat, which is now a function, right?",
                    "label": 0
                },
                {
                    "sent": "So to translate from the conditional perspective where you have either hat is just a number to the full risk perspective you now think of either had as a function from X201.",
                    "label": 0
                },
                {
                    "sent": "OK, so little else pointwise loss.",
                    "label": 0
                },
                {
                    "sent": "Capital L is the conditional loss and the BF L is the full expected loss.",
                    "label": 0
                },
                {
                    "sent": "So to define a problem that you want to solve, you can do this now in two ways and in my language discriminatively or generatively you can either have the easier M&L or you can have.",
                    "label": 0
                },
                {
                    "sent": "\u03a0, which is the apriori probability of a positive label.",
                    "label": 0
                },
                {
                    "sent": "You know, you might have a lot more positive examples of negative.",
                    "label": 0
                },
                {
                    "sent": "The two class conditional distributions and L that is a complete spec of a of a problem, and the Bayes risk, to reiterate is the measure of difficulty of the learning problem.",
                    "label": 1
                },
                {
                    "sent": "It's the best that you can do.",
                    "label": 0
                },
                {
                    "sent": "It's the smallest value of the expected risk that you can get, and you can indeed write it as the expected value.",
                    "label": 0
                },
                {
                    "sent": "Of the conditional Bayes risk.",
                    "label": 0
                },
                {
                    "sent": "So this is, you know, illustration of whites.",
                    "label": 0
                },
                {
                    "sent": "You can actually do a fair bit of work before you take the outer expectation.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So instead of 01 loss you can have a much wider class of losses, and if you're interested in class probability estimation that is predicting the probability of a positive label, the natural class of losses to use our proper losses.",
                    "label": 1
                },
                {
                    "sent": "So proper losses have the property that they are minimized when you get that probability estimate correct.",
                    "label": 0
                },
                {
                    "sent": "It's kind of the natural thing to do, and that that that alone actually gives you a lot of structure, so there's a result due to Savage the 1970s, which I mean.",
                    "label": 0
                },
                {
                    "sent": "I was ignorant of until last year.",
                    "label": 0
                },
                {
                    "sent": "Actually, you don't see this in machine learning textbooks.",
                    "label": 0
                },
                {
                    "sent": "Amazingly, and it is very simple and it says that the conditional loss.",
                    "label": 1
                },
                {
                    "sent": "Went so for losses proper you can write the conditional loss in this form, right?",
                    "label": 0
                },
                {
                    "sent": "So here we've got the Bayes.",
                    "label": 0
                },
                {
                    "sent": "The Conditional Bayes risk.",
                    "label": 0
                },
                {
                    "sent": "Here we've got the first derivative of the conditional Bayes risk and what's interesting is you see that the only way that either had an eater come in together is in that second term, right?",
                    "label": 0
                },
                {
                    "sent": "So you don't have some arbitrary function of ITA Anita hat, right?",
                    "label": 0
                },
                {
                    "sent": "You know you look at the left hand side you think are this is like this is a function of two variables, the only dependences through that either minus eat ahead as a.",
                    "label": 0
                },
                {
                    "sent": "A lot of structure imposed by the assumption of properness.",
                    "label": 0
                },
                {
                    "sent": "So there there that's the generalized.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I want to use on the left hand side of my first equation.",
                    "label": 0
                },
                {
                    "sent": "And on the right hand side, we want to generalize the variational divergences.",
                    "label": 0
                },
                {
                    "sent": "But this is also been done for a long time in the 1960s.",
                    "label": 0
                },
                {
                    "sent": "She's developed F divergences the same time Ally and Sylvie.",
                    "label": 0
                },
                {
                    "sent": "Did it in the statistics community.",
                    "label": 0
                },
                {
                    "sent": "It's the same thing, and here's the definition and I'm not going to go through this in detail, right?",
                    "label": 0
                },
                {
                    "sent": "This is you can read about this in textbooks.",
                    "label": 0
                },
                {
                    "sent": "Key thing I want you to realize is that it's a distance between two distributions, P&Q and there's an OB F right.",
                    "label": 0
                },
                {
                    "sent": "F is the nob that you choose a different F you get a different distance?",
                    "label": 0
                },
                {
                    "sent": "And what is F?",
                    "label": 0
                },
                {
                    "sent": "It's a convex function and we normalize it such that F of 1 = 0, right?",
                    "label": 0
                },
                {
                    "sent": "That's just a convenience, right?",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you.",
                    "label": 0
                },
                {
                    "sent": "Right, so you just think F is a convex function, so we've got the set of proper losses and you've got a lot of freedom there, but not arbitrary functions of two variables.",
                    "label": 0
                },
                {
                    "sent": "And you've got F divergences, and here's some examples of F divergences, right?",
                    "label": 0
                },
                {
                    "sent": "Pretty well, not many.",
                    "label": 0
                },
                {
                    "sent": "Many of the standard distances between distributions.",
                    "label": 0
                },
                {
                    "sent": "You get yourself a different F. So the key result in the paper that's pointed to.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "From the workshop page relates these quantities together.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "There's a bunch of constructions you've got to do, and the key thing to take away from this is that you can do all of this very explicitly, right.",
                    "label": 0
                },
                {
                    "sent": "The bottom line is the stuff here in red.",
                    "label": 0
                },
                {
                    "sent": "So what we've got is the FD vergence.",
                    "label": 0
                },
                {
                    "sent": "Is this thing?",
                    "label": 0
                },
                {
                    "sent": "Now?",
                    "label": 0
                },
                {
                    "sent": "There's a slight complication.",
                    "label": 0
                },
                {
                    "sent": "This is not the risk.",
                    "label": 0
                },
                {
                    "sent": "This is a thing called the statistical information, and it's related to a thing called the Bregman information.",
                    "label": 0
                },
                {
                    "sent": "So this thing here, the triangle L bar is called the statistical information.",
                    "label": 0
                },
                {
                    "sent": "It's the difference between the prior and posterior Bayes risk.",
                    "label": 0
                },
                {
                    "sent": "The prior Bayes risk is what is the Bayes risk you would get if you didn't have any data points.",
                    "label": 0
                },
                {
                    "sent": "If all you knew was the probability of a positive example, so it's a natural normalize.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Way of doing it just makes it nicer, so you can have this equals.",
                    "label": 0
                },
                {
                    "sent": "This equals this without any constants, right?",
                    "label": 0
                },
                {
                    "sent": "So this is a generalization of the result I showed you on the first page.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to talk in detail about the Bregman Divergent's stuff, but if people are interested I can tell you later on now.",
                    "label": 0
                },
                {
                    "sent": "Actually, from this perspective, you can do a lot more it.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is it that you can represent every loss as a weighted integral of primitive losses and they are cost sensitive misclassification losses?",
                    "label": 1
                },
                {
                    "sent": "It turns out every F Divergents can be also written as a weighted integral combination of primitive F divergences, and they're like the variational divergents.",
                    "label": 1
                },
                {
                    "sent": "So the result on the previous page actually allows you to take the weight function for the loss and transform it through an explicit formula and get the weight function for the F divergents.",
                    "label": 0
                },
                {
                    "sent": "Now without justifying why I will just assert that these representations or parameterisations of losses and F divergences respectively are the right ones to you.",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                },
                {
                    "sent": "If you get equality of the white functions, you get equality of.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The two divergences.",
                    "label": 0
                },
                {
                    "sent": "So there's an interesting development that arises from this perspective.",
                    "label": 0
                },
                {
                    "sent": "If you slightly generalize the notion of variational divergents to allow an imbalance.",
                    "label": 0
                },
                {
                    "sent": "So unequal class probabilities, that's the only thing that I've done here, and I also consider a loss function.",
                    "label": 0
                },
                {
                    "sent": "The linear loss, which isn't a legitimate loss because it's not bounded from below, but I will deal with that.",
                    "label": 1
                },
                {
                    "sent": "I'll show you an interesting connection.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So first of all, pretty trivially, you get a generalization of the result on the 1st slide.",
                    "label": 0
                },
                {
                    "sent": "That is the Bayes risk with respect to the linear loss.",
                    "label": 0
                },
                {
                    "sent": "And now I've got a parameter Pi, which is the probability of a positive label and on the right hand side I've got a variational divergent.",
                    "label": 0
                },
                {
                    "sent": "Here there's a factor of two that's gone missing, but we've kept kept careful track of that, so just trust me.",
                    "label": 0
                },
                {
                    "sent": "Now if.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You instead of just thinking of drawing your function from an arbitrary set, you actually work in a reproducing kernel Hilbert space like you do in kernel machines.",
                    "label": 1
                },
                {
                    "sent": "So now my set R is a unit ball in a Hilbert space.",
                    "label": 1
                },
                {
                    "sent": "That means I've got a kernel and I've got inner products.",
                    "label": 0
                },
                {
                    "sent": "I can represent a kernel is dot product of feature vectors, then Karsten Borgwardt and others have shown that you can write this quantity.",
                    "label": 0
                },
                {
                    "sent": "The square of this generalized variational divergences with respect to that function set the set of functions in a unit ball in a Hilbert space.",
                    "label": 0
                },
                {
                    "sent": "You can write like this where now this thing is the norm in the Hilbert space.",
                    "label": 0
                },
                {
                    "sent": "This is just standard kernel trickery.",
                    "label": 0
                },
                {
                    "sent": "OK, there's nothing particularly fancy there, and it's just a few line proof.",
                    "label": 0
                },
                {
                    "sent": "As a consequence of that, in the previous slide, you can write the Bayes risk with respect to this linear loss like that OK. Now this is the kind of the slightly odd.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Thing that we've done, you say that's all for full distributions.",
                    "label": 0
                },
                {
                    "sent": "What if you have an empirical sample so you know the normal way of going from a distribution to a sample is you're taking the empirical distribution.",
                    "label": 0
                },
                {
                    "sent": "Now you can generalize that and have a weighted empirical distribution, and this is used in particle filtering.",
                    "label": 1
                },
                {
                    "sent": "You put weights on these samples that aren't necessarily all equal, so if you go and do that in the alphas are going to be the weights, and then you can write, you know.",
                    "label": 0
                },
                {
                    "sent": "Here's the empirical.",
                    "label": 0
                },
                {
                    "sent": "This is the empirical expected value with respect to a sequence of points W weights Alpha of some function Phi.",
                    "label": 1
                },
                {
                    "sent": "And again this just goes through.",
                    "label": 0
                },
                {
                    "sent": "It's still an expectation, right?",
                    "label": 0
                },
                {
                    "sent": "So the same formula works, it just looks uglier because I've got a lot of these indices around.",
                    "label": 0
                },
                {
                    "sent": "Still expectations that the norms and everything still.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if you do this and we say that we want to keep a balance, so we have this parameter \u03c0.",
                    "label": 0
                },
                {
                    "sent": "Which tells you the probability of a positive label if you've got EM samples right and \u03c0 = 3/4.",
                    "label": 0
                },
                {
                    "sent": "That means you're going to have three M / 4 positive samples on average, and one M / 4 negative samples.",
                    "label": 0
                },
                {
                    "sent": "So keeping track of that, and I know there's a number of indices that maybe you should just kind of glaze over, squint your eyes a bit, and get the feel for these formulas, because I don't know how to write it without so many indices.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And you can then again, do you know the usual kernel manipulations, but this quantity of interest you express it in these inner products.",
                    "label": 0
                },
                {
                    "sent": "Simple calculation.",
                    "label": 0
                },
                {
                    "sent": "You get this formula down here, right?",
                    "label": 0
                },
                {
                    "sent": "So this one is a crucial one to look at and this should start to look familiar for those people who do kernel methods right?",
                    "label": 0
                },
                {
                    "sent": "So I've got this objective function J depends on Alpha and the sample X.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If I put all of the Alpha is equal to 1, so that's just the normal empirical distribution and plug this in here then this thing is equal to what's called MMD maximum mean discrepancy.",
                    "label": 1
                },
                {
                    "sent": "So that's shown up in NIPS in a number of papers in the last few years.",
                    "label": 0
                },
                {
                    "sent": "So what you see here is that MMD is simply doing Kernel Fisher discriminant analysis.",
                    "label": 1
                },
                {
                    "sent": "Assuming that class covariance matrices.",
                    "label": 0
                },
                {
                    "sent": "The identity, right?",
                    "label": 0
                },
                {
                    "sent": "So that's this dual view, right?",
                    "label": 0
                },
                {
                    "sent": "You can either think of a distance between distributions, which is what MMD is about.",
                    "label": 0
                },
                {
                    "sent": "Or I can interpret them as class conditional distributions for discrimination problem and then realize that's what I'm doing.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If instead of having a uniform weighting, I say what's the worst thing that I could do so the worst thing that I could do is to maximize the Bayes risk, right?",
                    "label": 0
                },
                {
                    "sent": "We want the Bayes risk to be as small as possible, so suppose I say what choice of alphas makes the Bayes risk worse, right?",
                    "label": 0
                },
                {
                    "sent": "Because that's kind of the worst thing that I could do for myself, so I have this minimization problem.",
                    "label": 0
                },
                {
                    "sent": "These are the constraints that I just had to propagate through to keep the problem consistent, and hey presto, I get the support vector machine.",
                    "label": 0
                },
                {
                    "sent": "That just falls out of it and the support vector machine uses the sign of this function as its predictor.",
                    "label": 1
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "If I wanted to interpolate between the previous two cases, I could bound the magnitude of the weights.",
                    "label": 1
                },
                {
                    "sent": "If I cap how big the alphas can be right, then I can go between doing the worst case or squish it down so that they're all uniform.",
                    "label": 0
                },
                {
                    "sent": "Sonu is now a nob that does that, and if I do that, then Crispin Burgess showed that this is actually equivalent to what's called the new SVM.",
                    "label": 0
                },
                {
                    "sent": "So what we've got?",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And my last slide is two different views, so the traditional way of you know that Nixon, empirical risk minimization, inductive principle you have expected base risk.",
                    "label": 1
                },
                {
                    "sent": "You do an empirical approximation.",
                    "label": 1
                },
                {
                    "sent": "You then have to restrict the class to regularize it, and that's what you go and estimate.",
                    "label": 0
                },
                {
                    "sent": "What I've done is I've started with this thing, which is not really a legitimate until I restrict the class.",
                    "label": 0
                },
                {
                    "sent": "Then I do an empirical approximation, but I have the flexibility are doing it with a weighted empirical distribution.",
                    "label": 0
                },
                {
                    "sent": "The same thing, so that's interesting so.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I had two different views of the same thing.",
                    "label": 1
                },
                {
                    "sent": "There, two sides of the same coin.",
                    "label": 0
                },
                {
                    "sent": "I've omitted the details of the weight functions and interesting Lee, you can get SVM's in MMD from this perspective.",
                    "label": 0
                },
                {
                    "sent": "Question.",
                    "label": 0
                },
                {
                    "sent": "So what's next?",
                    "label": 0
                },
                {
                    "sent": "So the thing we're working on at the moment is extending this to the multiclass case, and Interestingly, I can prove that there does exist an integral representation for the multiclass losses guarantee that one exists, but we haven't found it yet.",
                    "label": 0
                },
                {
                    "sent": "So at least we know that the thing we're shooting for is nice.",
                    "label": 0
                },
                {
                    "sent": "Is there and what end you know, the hope of having that is that you'll have some nice knobs for multiclass losses, because this seems a lot tougher.",
                    "label": 0
                },
                {
                    "sent": "People come up with these multiclass losses.",
                    "label": 0
                },
                {
                    "sent": "Some of them aren't even proper.",
                    "label": 0
                },
                {
                    "sent": "We want to parameterise all legitimate proper multiclass losses, and it actually can suggest a whole bunch of things that you can do.",
                    "label": 0
                },
                {
                    "sent": "You can get the surrogate regret bound, you can develop new learning algorithms.",
                    "label": 0
                },
                {
                    "sent": "So I'm working on.",
                    "label": 0
                }
            ]
        }
    }
}