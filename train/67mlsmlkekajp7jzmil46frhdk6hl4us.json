{
    "id": "67mlsmlkekajp7jzmil46frhdk6hl4us",
    "title": "Open-domain Quantity Queries on Web Tables: Annotation, Response, and Consensus Models",
    "info": {
        "author": [
            "Sunita Sarawagi, Indian Institute of Technology Madras"
        ],
        "published": "Oct. 7, 2014",
        "recorded": "August 2014",
        "category": [
            "Top->Computer Science->Data Mining",
            "Top->Computer Science->Knowledge Extraction"
        ]
    },
    "url": "http://videolectures.net/kdd2014_sarawagi_quantity_queries/",
    "segmentation": [
        [
            "Consider this query escape velocity."
        ],
        [
            "When you post this query to a typical search engine, you get back a set of links to documents and many of them contain the answer, but you actually have to do this step of following the links."
        ],
        [
            "Meanwhile, there are several hundreds of millions of tables on the web, and many of them contain answers to quantitative queries such as these.",
            "In fact, we analyzed and found that 40% of web table columns are quantitative, so you're very likely to find a good answer to quantitative queries on web tables this."
        ],
        [
            "Talk is about how we bridge the gap between the answers as present or scattered over several tables on the web to appoint answer which we can present to the user.",
            "So the first task that we have to solve is match is know how to match a set of query keywords to a structural entity like a table in an intelligent manner.",
            "For example the query keywords might be broken down into matches which happen across the row header.",
            "The column header or the title of the table.",
            "Or maybe text surrounding the table.",
            "2nd we have to grapple with the problem of dealing with the bewildering variety of variations in which numbers and units can be present in tables.",
            "Anyone who has been with this problem for long enough will just get Lee will get totally blown away by the amount of noise that you see in the way.",
            "Numbers and units are mentioned on the web.",
            "So like 59 copper, two could actually be 59.2.",
            "Yeah, depending on which countries table you're looking at, or whether you're looking at an electronic catalog or not, but typically it's 592 M could be meter or million.",
            "Katie could be kiloton or not, or carrot even a simple thing like a slash can be ambiguous when present in a table header when expressing units, slash could either be separating list of units or more typically it is a ratio.",
            "Between 2 units.",
            "So you know, so we grapple with this variety or with this noise, by by deferring the decision on a particular number or unit extraction until we have seen a lot of extractions.",
            "So we try to be robust by maintaining many possible extractions, and then we try to achieve consensus by by doing some kind of support building across many answers, but even consensus with continuous quantities it is tricky.",
            "So for if you are looking for entities or other discrete answers, you can achieve consensus by just counting support, but for numbers you would like to aggregate support from other numbers which are close enough and what is closed is difficult to characterize in a query independent way.",
            "So if you want to make it domain independent it becomes challenging.",
            "So in this talk I'm going to address each of these points step."
        ],
        [
            "Wasted, so first we'll consider the the task of matching query keyboard setup query keywords with a table.",
            "So consider again our example of escape velocity of Jupiter.",
            "So the first table matches quite nicely.",
            "You see part of the query matches the rule.",
            "Had the rule header Jupiter another part matches escape velocity, and so that gives us the corner table as the answer and because this match is very nice.",
            "We attach a relevance probability of 1 to this extraction, but the second table also matches very nicely, just that the rows and columns are interchanged with the third table.",
            "We have a problem, so the query part of the query would Jupiter matches the row header, but for the column we don't have any match.",
            "But then we look around and we find that this table has context snippet like list of Escape velocities which look relevant.",
            "So from this we know that this table might be.",
            "Providing the answer but we don't know which column has the answer, so we go ahead and mark all the quantitative columns as being potentially relevant.",
            "In this case there are two such columns and we assign a lower probability of .4 to each of these two extractions.",
            "Now to the second step of extracting numbers and units from each of the tables."
        ],
        [
            "So again, as I mentioned, for numbers and units, the ambiguity and noise is too much and also the same quantity can be expressed in different units in different tables.",
            "So we have to somehow in order to gain proper support and do proper consensus building we have to canonicalize all the units to a common form."
        ],
        [
            "So for that we follow a catalog of units.",
            "So we starting from Wikipedia, we created this XML kind of catalog where we have two levels at the top level we have different quantity types.",
            "There are 44 of this quantity types, which includes things like weight length, speed, multiplier units, currency and so on.",
            "And then for each quantity type we have different units and we have hundreds of 7050 of those in total for.",
            "Quantity type we have a Canonical unit and other units have conversion factors to this Canonical unit and with each unit we have it symbolon lemmas and all of those things which help us to."
        ],
        [
            "Asians, so now our task from here is to extract from each cell the number and the unit, which now is an annotation task, much like the way you do entity annotation.",
            "Now it becomes like an annotation task, so you need extraction is a unit annotation task and this is noisy so therefore we will extract multiple extractions, each with a score.",
            "So the first case is easy.",
            "We extract 59.1 as the number with a score of 1 kilometer per second is the annotation with a score of 1.",
            "The second case, depending on how well you are able to interpret the comma, you might choose to keep around two possible extractions, one which says that this is actually 216 point.",
            "This is decimal .720 with a score of .2 another, which takes the comma, is just a formatting through the unit.",
            "Here you know each can be an hour or Henry, which is a unit of measure of inductance.",
            "So actually when you just do plain symbolic annotation you might have.",
            "Two possibilities kilometer per hour and kilometer per Henry and later I will describe our unit annotation, which is smarter than this.",
            "So what it actually does is depends on the word velocity in the proximity of this unit and it's able to eliminate the second possibility and it keeps around just KPH.",
            "For the third table, we extract 59.6 after some struggle because there are those footmark numbers which we had to clean out and the unit does not appear in the cell in this case.",
            "So we extract the unit from the table header and the unit you know.",
            "If you're not very careful about again how you pass footnotes, you might end up with two possible units, one which says kilometer per second another, which might confuse the three with cube.",
            "And yeah, in this particular case you can clean up, but the number of these things that you have to clean up can quickly get out of hand, so you.",
            "Do end up with noises like this so we have another possibility kilometer per second.",
            "Cube with a smaller score."
        ],
        [
            "So now we have maintained from each site as a sort of a card which contains the relevance probability which we got by matching the keywords to the table and and from the unit and number extractor we have a set of possible unit and number pairs where the score is obtained by multiplying the number score with the unit score."
        ],
        [
            "So we have this in our example.",
            "We had this four possible answers these nuns answers.",
            "If you're trying to actually, if you're good, and if you're trying to match up the numbers with the previous sliced, I have not maintained that.",
            "So sorry about that.",
            "But just think of these as four new sets of cards that I've extracted and."
        ],
        [
            "Now.",
            "We will try to achieve consensus in the scores that we have assigned locally.",
            "So we tackled this through our collective inference module and in the collective inference step, the starting premise is that for every probability that you see there, there is actually an unknown true probability, and because it is unknown, we will model it as a hidden variable whose value we will try to estimate iteratively.",
            "So initially the hidden probabilities, the relevance probability and number unit scores.",
            "I just copied from the local scores.",
            "And we iteratively define them as follows.",
            "So we hide one extraction at a time and use the remaining extractions to learn a global distribution.",
            "Now the global distribution in this case will consist of two density functions over each of the two distinct quantity types.",
            "We have one quantity type of, which is a unit of speed which is kilometer per second.",
            "Another fake one which is kilometer per second cubed.",
            "But that's what we saw in the extraction.",
            "So we have these two functional distributions which will keep around.",
            "Each with score of point 9.3, so this gives us a full distribution.",
            "Now using this distribution is a mixture of two quantities.",
            "We re estimate the true probabilities of the first extraction and that you see the first value.",
            "59.6 gets a higher probability of .99 because of consensus from the other extractions.",
            "The wrong extraction has a suppressed problem."
        ],
        [
            "And we do this iteratively.",
            "Now to the next one.",
            "Again, you know, you see that when you when you hide the first, the third, the second extraction, then the kilometer per second cube is no longer a candidate, and that therefore the defined probabilities are one and zero for this case."
        ],
        [
            "And we do this iteratively.",
            "Notice that for this last extraction, that'll levels probability has been reduced to .01, because the number they are 2.56 does not find much support from its neighbors.",
            "So now we're done with this certified set of probabilities and we will use these probabilities to create a distribution which can then be presented to the user in any of several formats which we discussed in the."
        ],
        [
            "And now I will revisit the problem of how we do unit and annotation.",
            "This is the second part of my talk, so so we have this quantity tree and with respect to this quantity tree, we want to annotate the units which appeared in various various table headers.",
            "In this example I'm showing 4 table headers and these are the annotations we would like to produce the yellow boxes.",
            "So there are five different kinds of units that these examples illustrate.",
            "The first is an atomic unit, the 2nd is a unit with a multiplier.",
            "The 3rd is a list of units.",
            "Here we have a unit which is a ratio of two units.",
            "Another user issue, but with an you unit.",
            "We also do such annotation."
        ],
        [
            "So initially we thought that unit annotation was not a major problem when we could just handle it with a set of rules.",
            "So so you see that many table headers are of the form price in dollar length in kilometers and so OK, you look for matches after the word in and that should give you a unit.",
            "But there were surprising number of problems even with this simple rule.",
            "So you had table headers like scores in last match.",
            "I was blown away to find that last is actually also a unit name, so it ended up and annotating lost as a unique name.",
            "And so capacity in Katy.",
            "You don't know Katie whether it is carrot or kiloton or not, and you know other rules that we created had similar problems.",
            "So we decided there.",
            "Yes, we cannot just sort of.",
            "We cannot run away from this problem.",
            "We had to actually solve it properly, so we deployed more powerful models."
        ],
        [
            "We we chose a probabilistic context free grammar for two reasons.",
            "First, it was very easy for us to come up with a grammar which would capture a lot of special cases with a lot of resistance or either grammar which would capture the typical patterns in which units and multiplier appears in text, so that grammar is easy to write with some iterations, But the second part, which is the more interesting part, is that in general the grammar will allow multiple parse trees of a particular header.",
            "But we will use a set of features to score each of these powers tree such that the higher scoring pass tree is more likely to be correct and we dependent on a set of features, some of which capture lexical clues, others which capture semantic priors, some others which capture.",
            "We just kind of frequency statistics and I will illustrate."
        ],
        [
            "Then return example again.",
            "So here, let's say we have a table header like wind speed within brackets you have MPs slash kilometer per hour.",
            "And what I show here is the correct path tree that we obtained from our grammar and this parse tree was chosen over several other parse trees becausw of help that we obtained from a set of features.",
            "So this first feature which was helpful was the dictionary match of MPH to lemma of the unit Miller, MPH.",
            "A second feature was the presence of brackets.",
            "Delimiting sort of something which we are calling as at Unit 1/3 feature captured the fact that age is more frequently used as an hour in Word net, then as Henry, and then we had features which captured the Co occurrence of quantity types like speed with words like wind and speed and semantic priors like multiple units within a header tend to be of the same type."
        ],
        [
            "So using this now we had what I think is a good unit annotator and now I'll present some numbers in the next last one minute I."
        ],
        [
            "So what you see in this graph on the X axis you have different set of quantity queries like economic indicators for countries, companies and other random quantity queries on the Y axis you have F1.",
            "So higher is good and we compare the collective model with an independent model which does not do the collective extraction and something in which in between which does collective annotation the collective inference of probabilities but maintains only one possibility for each local extraction and you see the desired result as I had motivated.",
            "So far and."
        ],
        [
            "And 2nd we talk, we show that rule based extractions even when you look at into and query performance is not as good as the query performance we obtained with the CFG based extractor."
        ],
        [
            "So that's the end of my talk.",
            "I mean, like I motivated the role of tables in answering quantity queries.",
            "In this work I tried to push the role of two ideas, one using collective inference based, which does a good job in spite of errors of number and unit extraction, and I presented, I think the first ever unit extractor which uses be CFG and frequency to do a good job of the extraction."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Consider this query escape velocity.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "When you post this query to a typical search engine, you get back a set of links to documents and many of them contain the answer, but you actually have to do this step of following the links.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Meanwhile, there are several hundreds of millions of tables on the web, and many of them contain answers to quantitative queries such as these.",
                    "label": 0
                },
                {
                    "sent": "In fact, we analyzed and found that 40% of web table columns are quantitative, so you're very likely to find a good answer to quantitative queries on web tables this.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Talk is about how we bridge the gap between the answers as present or scattered over several tables on the web to appoint answer which we can present to the user.",
                    "label": 1
                },
                {
                    "sent": "So the first task that we have to solve is match is know how to match a set of query keywords to a structural entity like a table in an intelligent manner.",
                    "label": 0
                },
                {
                    "sent": "For example the query keywords might be broken down into matches which happen across the row header.",
                    "label": 0
                },
                {
                    "sent": "The column header or the title of the table.",
                    "label": 0
                },
                {
                    "sent": "Or maybe text surrounding the table.",
                    "label": 0
                },
                {
                    "sent": "2nd we have to grapple with the problem of dealing with the bewildering variety of variations in which numbers and units can be present in tables.",
                    "label": 0
                },
                {
                    "sent": "Anyone who has been with this problem for long enough will just get Lee will get totally blown away by the amount of noise that you see in the way.",
                    "label": 0
                },
                {
                    "sent": "Numbers and units are mentioned on the web.",
                    "label": 0
                },
                {
                    "sent": "So like 59 copper, two could actually be 59.2.",
                    "label": 0
                },
                {
                    "sent": "Yeah, depending on which countries table you're looking at, or whether you're looking at an electronic catalog or not, but typically it's 592 M could be meter or million.",
                    "label": 1
                },
                {
                    "sent": "Katie could be kiloton or not, or carrot even a simple thing like a slash can be ambiguous when present in a table header when expressing units, slash could either be separating list of units or more typically it is a ratio.",
                    "label": 0
                },
                {
                    "sent": "Between 2 units.",
                    "label": 0
                },
                {
                    "sent": "So you know, so we grapple with this variety or with this noise, by by deferring the decision on a particular number or unit extraction until we have seen a lot of extractions.",
                    "label": 0
                },
                {
                    "sent": "So we try to be robust by maintaining many possible extractions, and then we try to achieve consensus by by doing some kind of support building across many answers, but even consensus with continuous quantities it is tricky.",
                    "label": 1
                },
                {
                    "sent": "So for if you are looking for entities or other discrete answers, you can achieve consensus by just counting support, but for numbers you would like to aggregate support from other numbers which are close enough and what is closed is difficult to characterize in a query independent way.",
                    "label": 0
                },
                {
                    "sent": "So if you want to make it domain independent it becomes challenging.",
                    "label": 0
                },
                {
                    "sent": "So in this talk I'm going to address each of these points step.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Wasted, so first we'll consider the the task of matching query keyboard setup query keywords with a table.",
                    "label": 0
                },
                {
                    "sent": "So consider again our example of escape velocity of Jupiter.",
                    "label": 0
                },
                {
                    "sent": "So the first table matches quite nicely.",
                    "label": 0
                },
                {
                    "sent": "You see part of the query matches the rule.",
                    "label": 0
                },
                {
                    "sent": "Had the rule header Jupiter another part matches escape velocity, and so that gives us the corner table as the answer and because this match is very nice.",
                    "label": 0
                },
                {
                    "sent": "We attach a relevance probability of 1 to this extraction, but the second table also matches very nicely, just that the rows and columns are interchanged with the third table.",
                    "label": 0
                },
                {
                    "sent": "We have a problem, so the query part of the query would Jupiter matches the row header, but for the column we don't have any match.",
                    "label": 0
                },
                {
                    "sent": "But then we look around and we find that this table has context snippet like list of Escape velocities which look relevant.",
                    "label": 1
                },
                {
                    "sent": "So from this we know that this table might be.",
                    "label": 0
                },
                {
                    "sent": "Providing the answer but we don't know which column has the answer, so we go ahead and mark all the quantitative columns as being potentially relevant.",
                    "label": 0
                },
                {
                    "sent": "In this case there are two such columns and we assign a lower probability of .4 to each of these two extractions.",
                    "label": 0
                },
                {
                    "sent": "Now to the second step of extracting numbers and units from each of the tables.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So again, as I mentioned, for numbers and units, the ambiguity and noise is too much and also the same quantity can be expressed in different units in different tables.",
                    "label": 0
                },
                {
                    "sent": "So we have to somehow in order to gain proper support and do proper consensus building we have to canonicalize all the units to a common form.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for that we follow a catalog of units.",
                    "label": 0
                },
                {
                    "sent": "So we starting from Wikipedia, we created this XML kind of catalog where we have two levels at the top level we have different quantity types.",
                    "label": 1
                },
                {
                    "sent": "There are 44 of this quantity types, which includes things like weight length, speed, multiplier units, currency and so on.",
                    "label": 1
                },
                {
                    "sent": "And then for each quantity type we have different units and we have hundreds of 7050 of those in total for.",
                    "label": 0
                },
                {
                    "sent": "Quantity type we have a Canonical unit and other units have conversion factors to this Canonical unit and with each unit we have it symbolon lemmas and all of those things which help us to.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Asians, so now our task from here is to extract from each cell the number and the unit, which now is an annotation task, much like the way you do entity annotation.",
                    "label": 0
                },
                {
                    "sent": "Now it becomes like an annotation task, so you need extraction is a unit annotation task and this is noisy so therefore we will extract multiple extractions, each with a score.",
                    "label": 0
                },
                {
                    "sent": "So the first case is easy.",
                    "label": 0
                },
                {
                    "sent": "We extract 59.1 as the number with a score of 1 kilometer per second is the annotation with a score of 1.",
                    "label": 0
                },
                {
                    "sent": "The second case, depending on how well you are able to interpret the comma, you might choose to keep around two possible extractions, one which says that this is actually 216 point.",
                    "label": 0
                },
                {
                    "sent": "This is decimal .720 with a score of .2 another, which takes the comma, is just a formatting through the unit.",
                    "label": 0
                },
                {
                    "sent": "Here you know each can be an hour or Henry, which is a unit of measure of inductance.",
                    "label": 0
                },
                {
                    "sent": "So actually when you just do plain symbolic annotation you might have.",
                    "label": 0
                },
                {
                    "sent": "Two possibilities kilometer per hour and kilometer per Henry and later I will describe our unit annotation, which is smarter than this.",
                    "label": 0
                },
                {
                    "sent": "So what it actually does is depends on the word velocity in the proximity of this unit and it's able to eliminate the second possibility and it keeps around just KPH.",
                    "label": 0
                },
                {
                    "sent": "For the third table, we extract 59.6 after some struggle because there are those footmark numbers which we had to clean out and the unit does not appear in the cell in this case.",
                    "label": 0
                },
                {
                    "sent": "So we extract the unit from the table header and the unit you know.",
                    "label": 0
                },
                {
                    "sent": "If you're not very careful about again how you pass footnotes, you might end up with two possible units, one which says kilometer per second another, which might confuse the three with cube.",
                    "label": 0
                },
                {
                    "sent": "And yeah, in this particular case you can clean up, but the number of these things that you have to clean up can quickly get out of hand, so you.",
                    "label": 0
                },
                {
                    "sent": "Do end up with noises like this so we have another possibility kilometer per second.",
                    "label": 0
                },
                {
                    "sent": "Cube with a smaller score.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now we have maintained from each site as a sort of a card which contains the relevance probability which we got by matching the keywords to the table and and from the unit and number extractor we have a set of possible unit and number pairs where the score is obtained by multiplying the number score with the unit score.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we have this in our example.",
                    "label": 0
                },
                {
                    "sent": "We had this four possible answers these nuns answers.",
                    "label": 0
                },
                {
                    "sent": "If you're trying to actually, if you're good, and if you're trying to match up the numbers with the previous sliced, I have not maintained that.",
                    "label": 0
                },
                {
                    "sent": "So sorry about that.",
                    "label": 0
                },
                {
                    "sent": "But just think of these as four new sets of cards that I've extracted and.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "We will try to achieve consensus in the scores that we have assigned locally.",
                    "label": 0
                },
                {
                    "sent": "So we tackled this through our collective inference module and in the collective inference step, the starting premise is that for every probability that you see there, there is actually an unknown true probability, and because it is unknown, we will model it as a hidden variable whose value we will try to estimate iteratively.",
                    "label": 0
                },
                {
                    "sent": "So initially the hidden probabilities, the relevance probability and number unit scores.",
                    "label": 0
                },
                {
                    "sent": "I just copied from the local scores.",
                    "label": 0
                },
                {
                    "sent": "And we iteratively define them as follows.",
                    "label": 0
                },
                {
                    "sent": "So we hide one extraction at a time and use the remaining extractions to learn a global distribution.",
                    "label": 0
                },
                {
                    "sent": "Now the global distribution in this case will consist of two density functions over each of the two distinct quantity types.",
                    "label": 0
                },
                {
                    "sent": "We have one quantity type of, which is a unit of speed which is kilometer per second.",
                    "label": 0
                },
                {
                    "sent": "Another fake one which is kilometer per second cubed.",
                    "label": 0
                },
                {
                    "sent": "But that's what we saw in the extraction.",
                    "label": 0
                },
                {
                    "sent": "So we have these two functional distributions which will keep around.",
                    "label": 0
                },
                {
                    "sent": "Each with score of point 9.3, so this gives us a full distribution.",
                    "label": 0
                },
                {
                    "sent": "Now using this distribution is a mixture of two quantities.",
                    "label": 0
                },
                {
                    "sent": "We re estimate the true probabilities of the first extraction and that you see the first value.",
                    "label": 0
                },
                {
                    "sent": "59.6 gets a higher probability of .99 because of consensus from the other extractions.",
                    "label": 0
                },
                {
                    "sent": "The wrong extraction has a suppressed problem.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we do this iteratively.",
                    "label": 0
                },
                {
                    "sent": "Now to the next one.",
                    "label": 0
                },
                {
                    "sent": "Again, you know, you see that when you when you hide the first, the third, the second extraction, then the kilometer per second cube is no longer a candidate, and that therefore the defined probabilities are one and zero for this case.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we do this iteratively.",
                    "label": 0
                },
                {
                    "sent": "Notice that for this last extraction, that'll levels probability has been reduced to .01, because the number they are 2.56 does not find much support from its neighbors.",
                    "label": 0
                },
                {
                    "sent": "So now we're done with this certified set of probabilities and we will use these probabilities to create a distribution which can then be presented to the user in any of several formats which we discussed in the.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And now I will revisit the problem of how we do unit and annotation.",
                    "label": 0
                },
                {
                    "sent": "This is the second part of my talk, so so we have this quantity tree and with respect to this quantity tree, we want to annotate the units which appeared in various various table headers.",
                    "label": 0
                },
                {
                    "sent": "In this example I'm showing 4 table headers and these are the annotations we would like to produce the yellow boxes.",
                    "label": 0
                },
                {
                    "sent": "So there are five different kinds of units that these examples illustrate.",
                    "label": 0
                },
                {
                    "sent": "The first is an atomic unit, the 2nd is a unit with a multiplier.",
                    "label": 0
                },
                {
                    "sent": "The 3rd is a list of units.",
                    "label": 0
                },
                {
                    "sent": "Here we have a unit which is a ratio of two units.",
                    "label": 0
                },
                {
                    "sent": "Another user issue, but with an you unit.",
                    "label": 0
                },
                {
                    "sent": "We also do such annotation.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So initially we thought that unit annotation was not a major problem when we could just handle it with a set of rules.",
                    "label": 0
                },
                {
                    "sent": "So so you see that many table headers are of the form price in dollar length in kilometers and so OK, you look for matches after the word in and that should give you a unit.",
                    "label": 1
                },
                {
                    "sent": "But there were surprising number of problems even with this simple rule.",
                    "label": 1
                },
                {
                    "sent": "So you had table headers like scores in last match.",
                    "label": 1
                },
                {
                    "sent": "I was blown away to find that last is actually also a unit name, so it ended up and annotating lost as a unique name.",
                    "label": 1
                },
                {
                    "sent": "And so capacity in Katy.",
                    "label": 0
                },
                {
                    "sent": "You don't know Katie whether it is carrot or kiloton or not, and you know other rules that we created had similar problems.",
                    "label": 0
                },
                {
                    "sent": "So we decided there.",
                    "label": 0
                },
                {
                    "sent": "Yes, we cannot just sort of.",
                    "label": 0
                },
                {
                    "sent": "We cannot run away from this problem.",
                    "label": 0
                },
                {
                    "sent": "We had to actually solve it properly, so we deployed more powerful models.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We we chose a probabilistic context free grammar for two reasons.",
                    "label": 1
                },
                {
                    "sent": "First, it was very easy for us to come up with a grammar which would capture a lot of special cases with a lot of resistance or either grammar which would capture the typical patterns in which units and multiplier appears in text, so that grammar is easy to write with some iterations, But the second part, which is the more interesting part, is that in general the grammar will allow multiple parse trees of a particular header.",
                    "label": 0
                },
                {
                    "sent": "But we will use a set of features to score each of these powers tree such that the higher scoring pass tree is more likely to be correct and we dependent on a set of features, some of which capture lexical clues, others which capture semantic priors, some others which capture.",
                    "label": 0
                },
                {
                    "sent": "We just kind of frequency statistics and I will illustrate.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then return example again.",
                    "label": 0
                },
                {
                    "sent": "So here, let's say we have a table header like wind speed within brackets you have MPs slash kilometer per hour.",
                    "label": 0
                },
                {
                    "sent": "And what I show here is the correct path tree that we obtained from our grammar and this parse tree was chosen over several other parse trees becausw of help that we obtained from a set of features.",
                    "label": 0
                },
                {
                    "sent": "So this first feature which was helpful was the dictionary match of MPH to lemma of the unit Miller, MPH.",
                    "label": 0
                },
                {
                    "sent": "A second feature was the presence of brackets.",
                    "label": 0
                },
                {
                    "sent": "Delimiting sort of something which we are calling as at Unit 1/3 feature captured the fact that age is more frequently used as an hour in Word net, then as Henry, and then we had features which captured the Co occurrence of quantity types like speed with words like wind and speed and semantic priors like multiple units within a header tend to be of the same type.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So using this now we had what I think is a good unit annotator and now I'll present some numbers in the next last one minute I.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what you see in this graph on the X axis you have different set of quantity queries like economic indicators for countries, companies and other random quantity queries on the Y axis you have F1.",
                    "label": 0
                },
                {
                    "sent": "So higher is good and we compare the collective model with an independent model which does not do the collective extraction and something in which in between which does collective annotation the collective inference of probabilities but maintains only one possibility for each local extraction and you see the desired result as I had motivated.",
                    "label": 0
                },
                {
                    "sent": "So far and.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And 2nd we talk, we show that rule based extractions even when you look at into and query performance is not as good as the query performance we obtained with the CFG based extractor.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that's the end of my talk.",
                    "label": 0
                },
                {
                    "sent": "I mean, like I motivated the role of tables in answering quantity queries.",
                    "label": 0
                },
                {
                    "sent": "In this work I tried to push the role of two ideas, one using collective inference based, which does a good job in spite of errors of number and unit extraction, and I presented, I think the first ever unit extractor which uses be CFG and frequency to do a good job of the extraction.",
                    "label": 1
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": []
        }
    }
}