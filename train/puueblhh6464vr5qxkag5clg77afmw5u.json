{
    "id": "puueblhh6464vr5qxkag5clg77afmw5u",
    "title": "Online Learning and Bregman Divergences",
    "info": {
        "author": [
            "Manfred K. Warmuth, Department of Computer Science, University of California Santa Cruz"
        ],
        "published": "Feb. 25, 2007",
        "recorded": "July 2006",
        "category": [
            "Top->Computer Science->Machine Learning->Computational Learning Theory",
            "Top->Computer Science->Machine Learning->On-line Learning"
        ]
    },
    "url": "http://videolectures.net/mlss06tw_warmuth_olbd/",
    "segmentation": [
        [
            "Of the tutorial on online learning and Bregman divergences.",
            "There's going to be 2 lectures in a row.",
            "And break in the middle.",
            "And then there's going to be research talks on related topics this afternoon and tomorrow afternoon.",
            "OK, I'm Munford Vermote University of California, Santa Cruz and again credits to Ghana Ranch as well.",
            "We still working on his tutorial I guess.",
            "see I don't see him here.",
            "So I wanted to talk a little bit more about Bregman divergences.",
            "So have to screen through this, apologies for that.",
            "So here's the picture you should have in mind on Bregman divergences."
        ],
        [
            "Anne, it's.",
            "Convex function.",
            "Minus linear.",
            "Approximation.",
            "OK, this is the formula you should keep in mind.",
            "And I'm now going to motivate this.",
            "Bregman divergences using exponential exponential family distribution.",
            "Kind of very much similar to what Alex Maller did yesterday.",
            "So now I have to figure out where I stopped.",
            "OK, here we are on page."
        ],
        [
            "91 at so you should have the handout and a second part of the handout you're going to get at the break.",
            "OK, we do.",
            "As you know, I'm an online learner so everything is happening online.",
            "Even the even the slides are produced online, OK?",
            "So.",
            "So what is exponential family of distribution?",
            "You have a density defined by this exponential and why?",
            "Why this exponential?",
            "I always joke around in my class is well in machine learning we only do what we can do.",
            "We interested in log loss and we know how to do linear things so suddenly E to the linear becomes important.",
            "OK so Y to the linear, that's what this is.",
            "It's linear in X.",
            "Then OK, Alex yesterday had a fire in front of this.",
            "I simplified and just have an X here for simplicity.",
            "So no very simplest case of a sufficient statistic and this function.",
            "It's going to take care of the normalization.",
            "This is a reference density, so many of these distributions that we're looking at most natural distributions have this form.",
            "OK.",
            "The parameter is.",
            "You have a parameter vector and an instance vector.",
            "Sort of OK.",
            "This is called a cumulant function.",
            "It makes sure that this thing integrates to one.",
            "So I'm going to talk a lot about that Bregman divergences generalized.",
            "This big problem in this area is you have to make sure the cumulant function integrates to one when you do Bregman divergences.",
            "You don't need to assure that you sort of can work with arbitrary convex function, I'll get to that later.",
            "Turns out that very nicely G is a convex function on some convex set.",
            "D's number parameters and this cumulative function generalizes characterizes members of the family.",
            "The parameter when you write it this way.",
            "This parameter is called a natural parameter.",
            "OK, I will go through a number of examples in a moment.",
            "You must have heard this many Times Now, but."
        ],
        [
            "I emphasize slightly different things, so I'm going over again.",
            "There's a second parameter called expectation parameter, which is the expectation of.",
            "The instance vector with respective distribution.",
            "And then it turns out that this expectation and.",
            "Anne.",
            "Alex gave a proof yesterday.",
            "Is equal to the derivative of the human function.",
            "Right, so this new parameter is equal to little G of Theta, where G of ETA is the gradient of the cumulant function.",
            "Again, the cumulant function was this now."
        ],
        [
            "Analyzing thing.",
            "It made sure that the distribution was normalized."
        ],
        [
            "Then expect expected value of the instance is equal to.",
            "Little G of data, which is the derivative of the cumulative function.",
            "So now.",
            "Whenever you work with this kind of a thing.",
            "You always have a notion of duality, so there's a 6 second convex function called the convex convex conjugate function.",
            "You can write it with terms of a soup.",
            "Martin Wainwright did that, of course.",
            "Here I'm in the differential case, so I don't need the soup.",
            "I can write down explicit formula and the second function is F of mu, which is Theta times move, minus G of Theta.",
            "OK these are.",
            "Convex conjugates?",
            "And again, little F denotes the gradient of capital F, and then these two are inverses of each other in pictures in a more over."
        ],
        [
            "You type picture.",
            "You sort of have two parameters.",
            "Primal and dual parameters natural and expectation parameters right.",
            "Everything comes in pairs.",
            "That's always how these things work, and I'm going to go through examples in a moment.",
            "And this is also why it's confusing.",
            "But once you get a handle on it, it's actually quite elegant.",
            "OK, natural parameter is mapped via the little G function, which is the derivative of this function to the expectation parameter which is mapped via the little F function, which is the derivative of F back to the natural parameter.",
            "So their tool parameters and here the transformations.",
            "OK, so this is sort of the overview picture.",
            "Now.",
            "Examples."
        ],
        [
            "Simplest example is the Gaussian and now I I do the Gaussian even simpler than Alex I did yesterday.",
            "I do it for a fixed variance.",
            "So.",
            "The distribution is E to the minus.",
            "Quadratic.",
            "The quadratic you can rewrite it this way.",
            "This is a reference density.",
            "This is your G function.",
            "This is your linear part.",
            "So here's the Cuban function.",
            "OK. Now in this case, if you take the derivative of this function, you get the identity function and the inverse of that identity function is again the identity function.",
            "So this is sort of the simplest case.",
            "This is the case that corresponds to.",
            "Represent a theorem corresponds to kernel isable algorithm.",
            "Everything is sort of very simple.",
            "There's the link function is the identity function.",
            "And the dual convex function is.",
            "You plug in the formula.",
            "Now also the same function in terms of the other variable.",
            "OK, the log likelihood of this function is simply the square loss.",
            "So let me go back again."
        ],
        [
            "In generality, two parameters natural parameter expectation parameter mappings, little G Maps to hear little F Maps back.",
            "Those are the derivatives of the corresponding functions.",
            "These two functions are convex conjugates."
        ],
        [
            "First example.",
            "Gaussian.",
            "You rewrite it.",
            "Linear part cumulant function.",
            "You take the derivatives and you see everything is the identity function.",
            "The two convex conjugate functions are identical, this one, and this one.",
            "They are identical clear.",
            "OK. Now."
        ],
        [
            "Other very basic case.",
            "Is bernoulli.",
            "Density looks like this.",
            "The.",
            "Where mu is the probability.",
            "It's a coin, and it's the probability of the outcome of the coin being one.",
            "The natural parameter happens to be.",
            "This actually moves the expectation parameters you will see.",
            "And this is the natural parameter.",
            "Now I can write my density as.",
            "PF Theta X.",
            "Minus L and this is just straightforward algebra, which I didn't show, but it's not so hard.",
            "If you have some time, it's linear minus this function.",
            "This of course is a. Convex function.",
            "Here.",
            "And then you take the derivative of this, you get the softmax.",
            "As the little G and it's the little F you get this function.",
            "You can also plug in and compute the dual and you get this.",
            "And.",
            "The negative entropy.",
            "Right?",
            "And.",
            "If you.",
            "Take the log of this function and write it in the Theta domain.",
            "It looks like this if you write it using the new parameter.",
            "It looks like this so it looks sort of like a cross entropy.",
            "OK.",
            "So this all may seem like magic, but it follows a certain routine.",
            "Once you have the routine, it's OK. And people have done this for very long."
        ],
        [
            "I'm they wrote books and books of these exponential families and basically they were too hard to read for me, so I got rid of them and use pregnant emergencies which are easier.",
            "Um?",
            "Plus on another famous case.",
            "The instances are natural numbers.",
            "This is the distribution.",
            "I wrote it again in terms of the expectation parameter.",
            "The natural parameters log of mu.",
            "If you write it as a function of the natural parameter, it becomes easy to the linear minus Y to the Theta.",
            "This is your convex function.",
            "Obviously the exponential is convex.",
            "Taking the derivative of this function, you get either the theater back.",
            "And now inverse of each of the Theta you get log of me.",
            "So you take E to Theta equals mu solve from you and you get the other function here that that's not integral of that is the convex conjugate function.",
            "These two are conjugates.",
            "Loss.",
            "Is simply the log of this.",
            "An and this sort of looks like a normalized cross entropy.",
            "Will make all of this a little bit more precise in a moment, so this is possible, but newly prosar.",
            "Ha, let's do."
        ],
        [
            "A more general observation, how do these two relate?",
            "OK, so whenever you have a distribution, the only reasonable measure of divergent between two distributions, relative entropy is a coding theoretic interpretation.",
            "Right in terms of the additional code book length, if you take the wrong code blah blah blah little bit too much, it's this.",
            "It goes back to Shannon.",
            "You can read the first couple of chapters covis book.",
            "So this is the relative entropy and I measure the relative entropy between two distributions from the same family characterized by G1.",
            "Parameter Theta one parameter Theta twiddle, and what I'm going to get out of this.",
            "Is that this is a Bregman divergent?",
            "This is a familiar Bregman divergences.",
            "OK. How do we prove this well?",
            "Look, this had this E to the linear form right?",
            "And eat the linear matches with the log, because if you take logs, the linear pulls down and what do we know how to do linear?",
            "OK, good so.",
            "E to the linear log of each of the linear.",
            "That's this part.",
            "The reference density cancels out.",
            "Then minus log either the each of the same thing becomes this piece these two terms.",
            "And I have an integral over this.",
            "Everybody understand this step from the idea.",
            "OK, I just plugged in the E to the linear form and talk logs, so I'm here.",
            "Now I distribute over this whole thing because everything is constant except X, so I have.",
            "Here.",
            "I have here.",
            "The integral only is staying over the X, but this is an expectation.",
            "So that is our mood.",
            "And Wala and moves actually little G of Theta.",
            "So this here.",
            "Is our normal formula, which you should recognize now.",
            "For this relative entropy, it is convex function minus the linear approximation, where this is G of Theta.",
            "OK, now if you take this line here and plug in the definition of convex conjugate.",
            "For differentiable function, then via transformation you end up with a very similar looking formula where now.",
            "You use the convex conjugate function as the convex function.",
            "F 12 minus the linear approximation, and here this is a little F of.",
            "Mutual.",
            "So this.",
            "This.",
            "It's the same as this.",
            "Everything comes in pairs.",
            "It's related to in some sense convex problems.",
            "I've always the dual problem.",
            "The dual of the dual is the original and you see here.",
            "That as well, because if you take the convex conjugate contest operation applied twice, you would go back to here and then.",
            "This argument would switch once more and go to the other domain and you would end up here.",
            "So you can kind of see that if you apply twice you get back to the original.",
            "So this is equal to this.",
            "So what I have what have I done so far?",
            "And I'm going to go through examples again in a moment.",
            "Same kind of examples I see."
        ],
        [
            "Find exponential family distribution very, very simple form.",
            "This was the convex function that characterized the family.",
            "It makes sure that things integrate to one.",
            "I did."
        ],
        [
            "Find another parameter expectation parameter, which is supposedly the derivative of the cumulant function.",
            "Defined a second convex function convex conjugate differential case.",
            "You don't need the soup, you have an explicit formula.",
            "And then went through a bunch of examples and then."
        ],
        [
            "Establish this relationship.",
            "You never have a convex come a exponential family if you compute relative entropies, you get Bregman divergences, but it is not true that an arbitrary Bregman divergences corresponds to an exponential family, not at all.",
            "Intuitively, what you need to assure for it to be an exponential family is that that the some kind of probabilistic interpretation and something integrates to one for arbitrary Bregman divergences.",
            "You start start with a convex function.",
            "OK.",
            "So.",
            "This form questions.",
            "OK, this form of the Bregman divergent convex functions minus linear approximation was popularized by Bregman.",
            "And actually.",
            "Discovered or rediscovered this family in a different way as an integral."
        ],
        [
            "Anne, it turns out that.",
            "If you write down the sigmoid function and you compute these kind of integrals underneath the sigmoid, they become relative entropies and I was.",
            "That's how I rediscovered this in more general terms.",
            "If you have a little G function.",
            "And you integrate from Theta Twiddle.",
            "Two Theta should be Theta here.",
            "Then the integral underneath happens to be the Bregman divergent.",
            "Is this the kind of the matching loss type motivation that I talked about already?",
            "And before I knew about Bregman divergences and even convex conjugacy in all of these things.",
            "I there is a version, there is a very intuitive version of showing that they.",
            "This kind of relationship, why?",
            "Well there is.",
            "This is an increasing function.",
            "Of course.",
            "If you mirror this function on this line, you get the.",
            "Inverse of this increasing function.",
            "So now you can do the integral over in this domain, or you can flip your transparency, which I can't do anymore because we have these.",
            "Uh.",
            "We have now, you know, dislike projectors.",
            "You flip the transparency and you can do the integral on the other axis and what happens?"
        ],
        [
            "This this way?",
            "So you write your divergance the normal way you can write it as an integral over the G. This is the same as this.",
            "More general case, you need to have a path integral OK and now here integrate over the G function.",
            "But instead I could go to the other domain and integrate over the Moose which are the other domain you see.",
            "He left."
        ],
        [
            "Here in this axis, live the status in this axis.",
            "Stiff moves so."
        ],
        [
            "I can flip the transparency integrate over the other domain and I get this, so this is another way of seeing that there's always a duality.",
            "And why?",
            "Because I flipped the arguments flip and so forth, OK?",
            "So this is how I had discovered it.",
            "Before I even knew about convex conjugacy.",
            "Soleb"
        ],
        [
            "Let's go through these examples.",
            "That I had.",
            "Bernoulli convex function.",
            "Convex conjugate function.",
            "This is sort of the log partition function.",
            "Which always is associated with a minimum relative with a relative entropy.",
            "So here's the here's the.",
            "Actually the convex function is just the entropy.",
            "For negative the entropy.",
            "Here the corresponding link functions the softmax, and then this.",
            "I think this is the probe.",
            "It kind of thing.",
            "Now if you go ahead.",
            "And plug this function into."
        ],
        [
            "This first line."
        ],
        [
            "Then you get this piece.",
            "And this one maybe you don't recognize as clearly.",
            "But if you would plug this function into.",
            "I don't have that formula up to older versions into.",
            "OK. And."
        ],
        [
            "To this formula."
        ],
        [
            "Then you get the familiar looking relative entropy.",
            "For single coin, so there's two outcomes.",
            "One account with probability move, the other one 1 minus me.",
            "And so it's the binary relative entropy.",
            "And the sum of independent binary.",
            "Entropies finally, relative entropies was used to motivate one of those entropic algorithms.",
            "Binary exponentially gradient algorithm.",
            "OK so again.",
            "Whenever you write down these kind of relative entropies.",
            "You sort of end up with Bernoulli or.",
            "In a more general state case, multinomial.",
            "Modeling that's happening.",
            "So this was the binary relative entropy."
        ],
        [
            "If you want to do, here it is.",
            "The new lease for two outcomes you have N outcomes.",
            "You get the normalized the normal entropy out of here.",
            "OK, which motivated e.g exponentially creating algorithm.",
            "K Dual divergance 4 plus saw.",
            "This was the cumulant function.",
            "This was the convex conjugate function.",
            "Derivatives little G. They left ITA Theta log me.",
            "Plug into the two formulas.",
            "You get this relative entropy.",
            "You know these formula.",
            "These are always non negative right?",
            "And have all these fine fancy properties?",
            "They have Pythagorean theorem box equality.",
            "All of these things that I said they always hold in general.",
            "K bam, one.",
            "If you do the if you plug this into the formula, bam, you get that these two are equal.",
            "This is the a normalized relative entropy, so this motivates the unnormalized exponentially greater algorithm example window algorithm.",
            "This is Claire.",
            "So this is a normalized relative entropy.",
            "OK, let me do a."
        ],
        [
            "Case will be motivated the matching loss.",
            "It's essentially using again.",
            "The binary relative entropy so.",
            "Your age of Z could be this.",
            "Now.",
            "The tool I wrote this way.",
            "Link function.",
            "Inverse link function.",
            "These are convex conjugates of each other, and now you plug into the formula.",
            "So by duality.",
            "The logistic loss.",
            "Which.",
            "Is this one is the same as the entropic loss, which is this one?",
            "And we were using this as the matching loss for the logistic transfer function.",
            "Anne.",
            "Again, our model uses 2 divergences, one for the parameter domain and one for the last domain.",
            "When the two are the same.",
            "Then it's sort of the Canonical case.",
            "It corresponds to what conjugate prior case.",
            "But they don't have to be the same.",
            "OK, so this is what I wanted to say.",
            "About Bregman divergences?",
            "And how they relate to the exponential families.",
            "You can always go back to the exponential families.",
            "And sort of glean intuitions from statistics.",
            "Exponential families is to make mainstay of statistics and whatever these guys have done, you can kind of look at and see how it fits in your thing and learn from.",
            "The path that these guys have taken.",
            "So that's why I linked.",
            "I linked Bregman divergences back to.",
            "The exponential family.",
            "OK, but you can forget about all of this complicated stuff underlying probability distribution.",
            "Maybe you're not so good at doing integrals.",
            "So forget about that and just go back to the definition of Bregman divergent, which is convex function minus linear approximation.",
            "You can completely characterize which Bregman divergences correspond to the exponential family, and basically it's it's pregnant divergences with a convex function has these log of sum of exponential form.",
            "Not surprisingly, because that.",
            "Corresponds to.",
            "In some deep way to the to the what a cumulant is in general.",
            "OK, so."
        ],
        [
            "Oh, I always like to study.",
            "The simplest problems.",
            "So I talked about in this thing about the expert setting, which is rather simple setting.",
            "I talked about linear regression, which was a large simple setting for online learning.",
            "Now let's do the simplest density estimation.",
            "The simplest case of density estimation.",
            "Gaussian density estimation.",
            "Right, and I'm going to tell you what we found out.",
            "Using the methodology of divergencies.",
            "And then I'm going to tell you.",
            "A game theoretic and alternate game theoretic one which goes a little bit beyond this stuff.",
            "And it's kind of interesting in its own right.",
            "So what's Gaussian density estimation?",
            "You get about cloud of points and you supposed to predict the mean.",
            "Assume the variance is fixed simplest case.",
            "So all you do is you take the mean.",
            "You predict the average.",
            "OK, so that's a good thing to do, but it turns out that for online learning well, what's online?",
            "Learning?",
            "In this context, you get one point at a time, right?",
            "You get one point.",
            "You have to predict with the mean.",
            "You incur some losses by how far you were off.",
            "You get another point.",
            "You have to predict with the mean, maybe of the previous points that you have seen, etc etc.",
            "So you do this online and the question is, what's a reasonable model and so forth.",
            "So the loss in this context would be log of Gaussians.",
            "Densities, which is of course quadratic, very simple.",
            "Now, why are we interested in quadratic?",
            "Well, if we take, derivatives are linear and we're very good at linear.",
            "OK."
        ],
        [
            "Good so we want.",
            "To derive our updates and to actually what we want to bound is this kind of a thing.",
            "The total loss of the algorithm.",
            "Minus.",
            "The in hindsight best.",
            "Loss of the best parameter."
        ],
        [
            "OK, so.",
            "We get one point.",
            "We have a mean.",
            "We get a point where current loss.",
            "We get another point.",
            "We know we have a mean.",
            "We get a point.",
            "We incur loss, we make up another mean, get the second point incur a loss, make up another mean, get the Third Point, get a loss.",
            "We sum these losses."
        ],
        [
            "Overall trials.",
            "Right?",
            "That's what this is.",
            "This is a total loss of the algorithm we want to compare this against.",
            "The in hindsight, best loss.",
            "What's the in hindsight?",
            "Best loss well.",
            "You get all points.",
            "And you get the one that minimizes the total loss, and actually that is always as Alex did yesterday.",
            "The average point.",
            "The average of all the points, including the future ones.",
            "The online algorithm doesn't know the future points, so it doesn't know this, but I still can compare the total loss of the online algorithm against the best offline algorithm.",
            "So this is called the regret.",
            "And.",
            "This is what we want to bound.",
            "Again the offline algorithm.",
            "Anne.",
            "Has if you just want to minimize this, it puts you things at the average, but in a more fancy one.",
            "If you want to compute an offline algorithm Now, what you would want to do is.",
            "You would also maybe add some kind of a prior or some kind of initial divergance to some initial weight vector.",
            "And if you minimize this, this is not a break.",
            "Man divergences were G is is the cumulant function associated with the Gaussian which is quadratic the simplest case.",
            "Then you can define.",
            "Can minimize.",
            "This term and what you get.",
            "You see I didn't do it.",
            "I didn't do the form yet, OK?",
            "Duration of the updates.",
            "OK, so this is how you would motivate."
        ],
        [
            "The.",
            "The batch algorithm.",
            "The online algorithm you would motivate it by taking it to virgins too.",
            "Also the initial parameter, but only the loss.",
            "So far in curd so far.",
            "And these different.",
            "This weightings of the initial distribution, this one.",
            "Versus this one might be different.",
            "OK."
        ],
        [
            "An alternate version of motivation of the online algorithms you take the divergance to the last.",
            "And then just the loss the current loss occurred at the end.",
            "And where your parameter is set this way.",
            "And if you do this kind of updates and compute this minima, you get the following.",
            "The offline algorithm basically.",
            "Puts certain weight on the initial and then.",
            "Sums all the instances and divides by.",
            "Anne.",
            "This trade off parameter plus the number of trials and number of trials, number of examples the online algorithm has a very similar form, except these weights might be different.",
            "You can also.",
            "Derive this express this in terms of the previous, so this is the previous 1 -- 8 AT plus one times this where this is sort of the gradient of the loss and this has the 1 / T type of behavior.",
            "You can also see here.",
            "That this update here.",
            "Can be written in terms of a link function.",
            "Remember when we derive things with pregnant divergences always?",
            "You took a parameter.",
            "You went to another domain.",
            "This is not going to be the expiration expectation domain.",
            "You add in a gradient and you go back, so this update.",
            "You can write this way.",
            "And then it's it's similar to what we used before.",
            "OK.",
            "So."
        ],
        [
            "The online algorithm has the freedom to choose this initial.",
            "Trade off parameter which could be different from the initial trade off the trade off parameter of the batch algorithm.",
            "If the two are the same, then the online algorithm is kind of an incremental offline algorithm.",
            "But sometimes it's good to make the online parameter the online parameter a little bit bigger.",
            "K so this could."
        ],
        [
            "Response to."
        ],
        [
            "The following situation.",
            "If you plug in everything and you do it for Gaussians and so forth, these are the reasonable things.",
            "The.",
            "The plain offline algorithm would be you want to set this parameter to zero and you just sort of do maximum likelihood.",
            "You have T examples, you divide by T. The online algorithm at trial T has seen T -- 1 examples.",
            "But it turns out by setting the these eight parameters.",
            "A little bit differently.",
            "A better way to set it is to add here plus one.",
            "So number of examples plus one.",
            "It's a, it's like regularising it by adding an initial example at .0.",
            "We call this the forward algorithm because it estimates it doesn't just.",
            "Compute the maximum likelihood it estimates it by by putting another point at 0.",
            "Before it before it.",
            "Compute its current parameter.",
            "It guesses that the parameter is actually at 0, and that includes that into the estimate and that gets you a plus one.",
            "Imagine here plus zero, which doesn't show up.",
            "Anne.",
            "Can do the same thing.",
            "For bernoulli maximum likelihood, again is the average, but.",
            "Anne.",
            "A fancier online algorithm would be something like Kasimov.",
            "Trust him off.",
            "I don't know.",
            "It's to Russians.",
            "Which put a half count here.",
            "Put an additional example at a half and then divide by the number of examples plus one.",
            "And that's sort of a regularised version.",
            "Laplace estimators, another case where you have one here.",
            "I'm repeating this because.",
            "Using, but if you do this online algorithms very carefully, you see that these algorithms are not the best possible algorithms that much better ones.",
            "OK.",
            "So what's again happening?",
            "Maximum likelihood is just averaging.",
            "By setting some kind of initial counts differently, you get the forward algorithm which divides by one more number of examples plus one.",
            "And here this this dummy example is at 0 and here the W example is at half.",
            "OK."
        ],
        [
            "You can write very very general theorem for this kind of density estimation.",
            "General framework.",
            "Lots of the algorithm.",
            "This is the regret is at most as big as.",
            "This.",
            "Telescoping things that are going to telescope when you sum them up.",
            "Plus this additional term.",
            "And this is sort of the cost of the update."
        ],
        [
            "And then you can.",
            "You can sum up and telescope.",
            "This is the total regret and then here is the initial divergent to the initial diversions to the last one.",
            "This is not negative and can be dropped, and this is the cost of all of the updates.",
            "And then you can get bounced by bounding this additional term."
        ],
        [
            "What comes out of this?",
            "Is pounds of the following type.",
            "The regret for the Gaussian density estimation is at most as big as this.",
            "It's the upper bound on the norms of the instances times essentially log T. For Bernoulli it is total regret for arbitrary sequences of examples is at most log T plus log \u03c0 / 2.",
            "Anne.",
            "I talked a lot.",
            "About so I like to work on very simple problems like Gaussian density estimation, linear regression and try to get new algorithms.",
            "So I talked.",
            "About"
        ],
        [
            "This trick of shrinking.",
            "This is the maximum likelihood estimator.",
            "This is sort of the online maximum likelihood, except there's a little thing you shrink a little bit more.",
            "You add +10 here.",
            "You also added additional counts.",
            "The question I was obsessed with it.",
            "What is the right shrinkage?",
            "And why is this shrinkage there at all?",
            "Turns out it's there.",
            "In the worst case already, and it's quite an interesting story.",
            "Little bit much for early in the morning, but.",
            "OK, so."
        ],
        [
            "These forward albums are all the ones with half the additional shrinkage and the balance come out better that way.",
            "If you don't do the shrinkage to bounce another's good.",
            "So this is the balance I got 4.",
            "Gaussian density estimation.",
            "This is one for the.",
            "For the Bernoulli, when you added the additional half and divided by one more example, you can also do this kind of a thing for linear regression.",
            "Initially done by Valk, then by some other people.",
            "Anne.",
            "Normal linear regression has this inverse covariance matrix, but you take the inverse covariance matrix of the examples we have seen so far, so there would be a T -- 1.",
            "Here is some the outer product over all the examples we have seen already lost T -- 1.",
            "You regularize with this taken inverse and then you multiply by this and that's your current weight vector.",
            "Want to Bellagio figured out via some very roundabout way and then we did the proof using Bregman.",
            "Urgencies in a very sort of concise way in a collapsed way.",
            "It's a long story.",
            "Is you if you want to do linear regression good and you want to get good worst case loss pounds before you predict on an instance you should actually use the current instances you predict on and put it in the covariance matrix.",
            "So at trial T you're going to predict with www.xt.",
            "But the WT dot XT but UW T has in its government covariance matrix already the current instance.",
            "So this kind of a nifty algorithm that came out of these are some of the most subtle algorithms that came out of these worst case analysis.",
            "So this corresponds to adding plus one in Gaussian density estimation, we divided by the number of examples plus one.",
            "In regression we use all the examples you have seen already in the past plus the current example that corresponds to the plus one.",
            "In the motivation, it means that you add in your loss total loss, the loss on the past examples, plus the loss on the current example.",
            "But you assume that its label is 0.",
            "So this is very subtle shrinkage going on.",
            "If you want to get good worst case lost pounds and optimize them, you should include the current example into the covariance matrix.",
            "OK."
        ],
        [
            "So.",
            "We got pretty subtle algorithms out of this, so and.",
            "But let me summarize why Bregman divergences, so you know don't need to check whether the underlying exponential distribution.",
            "Is in the exponential family, but there's an underlying distribution at all.",
            "It's more general and exponential families.",
            "We always use two divergences.",
            "It's sort of fairly elegant because we have a parameter divergance analostan vergence.",
            "And we used the same one in the motivation of the analysis and.",
            "As a measure of progress in the analysis, so there's all these multiple users.",
            "That's why pick Bregman divergences.",
            "When a dog gets to Infinity, the updates morph into Bregman projections and then you have a general penalized for staggering theorem.",
            "So you sort of get boosting as a special case.",
            "K."
        ],
        [
            "So now let me take a step back.",
            "I talked about online learning, deriving updates.",
            "Using Bregman divergences now, I wanted to sort of a game theoretic point of view.",
            "The general setup is we had some information from the learner and the relative loss time qualifies the price for hiding that information.",
            "So far.",
            "The future examples were hidden and the offline algorithm knows all the examples.",
            "The online algorithm only knows the past examples."
        ],
        [
            "So this sort of leads you to game theoretic type of philosophy.",
            "So imagine for a moment when Gaussian density estimation right, you have to predict.",
            "I mean.",
            "I am the algorithm, so I want to be lost small so I have to predict the mean.",
            "Nature produces an instance.",
            "I have to predict the second Queen nature produces an instance, so I have these nested in Supes horizon many times.",
            "T is my horizon.",
            "What's the payoff?",
            "Total loss of my online algorithm minus total loss.",
            "Of the best offline algorithm I used moves here.",
            "For means in the case of Gaussians where they use Muszar, Theta is the same because the expectation and the natural parameter is the same.",
            "Head.",
            "So.",
            "This is the minimax optimum.",
            "The best you can do.",
            "Any soup and soup and soups.",
            "Total regret.",
            "Online loss minus best in hindsight loss.",
            "That's what we want to optimize.",
            "OK, that's what we try to optimize using this complicated divergent stuff.",
            "OK, to make sense of this you need to bound the instances.",
            "Otherwise you can make this gap infinitely big.",
            "And the minimax algorithms are usually intractable.",
            "But it turns out for Bernoulli you can do it.",
            "That's pretty much known, but we also figured out how to do that for Gaussian.",
            "And then we found out something that is completely.",
            "It's kind of wild because it gets it.",
            "There's a shrinkage.",
            "Factors are quite curious.",
            "OK, so let me."
        ],
        [
            "He go back to Gaussian, the fanciest one I got.",
            "Using divergences was average but plus one right?",
            "So it's T -- 1 and T -- 1 + 1.",
            "So this is the fanciest I got got with the Virgin season abound.",
            "Had this form.",
            "It turns out the minimax algorithm Gaussian density estimation when the horizon is T at trial T is supposed to predict with the roughly the past average instances.",
            "But there is an additional.",
            "A shrinkage factor.",
            "The shrinkage is 1 plus log T minus log log T. And it's actually recurrence for the shrinkage factors, so this suggests.",
            "And since it's the optimal algorithm.",
            "We know it's the right thing.",
            "So this suggests that the whole approach of this divergent stuff will never get these kind of shrinkage is right.",
            "So you need to.",
            "Really go to this minimax thing to get all the shrinkage is perfect.",
            "And it was quite curious to figure out data recursive formula for the shrinkage.",
            "And this is only an approximation, but it has this form.",
            "K and abound also improves much slightly.",
            "But this minimax algorithm needs to know T to get the shrinkage, right?",
            "Questions.",
            "OK."
        ],
        [
            "So.",
            "So this thing."
        ],
        [
            "It's a little bit too complicated, right?",
            "In soup and soup T many times.",
            "How do you analyze something like this?",
            "Can you don't worry, you know you.",
            "You write down complicated things, you know you take a nap and sometimes things simplify.",
            "Well, in this case, in general they didn't.",
            "As far as I know.",
            "I suppose I can do it, but what you can do is the following."
        ],
        [
            "Simple trick, you always assume that the current trial is the last trial we call this last step, minimax.",
            "So now the situation is.",
            "I assume the current trial is the last round, so I have only one inch soup left.",
            "And the current and the parameter vector I'm going to pick it.",
            "Is the Ark in soup?",
            "So what is this total loss so far minus in?",
            "And the previous ones don't matter, so it simplifies to this.",
            "So I'm left with this thing and there's a very simple formula for this in so it turns out this thing can be analyzed in many, many contexts.",
            "And this very simple motivation without divergences, blah blah blah already gets you some of the fanciest algorithms that I got using divergences.",
            "It got you to forward algorithms for Gaussian and linear regression.",
            "So after seeing this, I have high respect for this game theoretic stuff.",
            "OK, so it did the right thing for Gaussian and for linear regression."
        ],
        [
            "Let's talk about Bernoulli a little bit.",
            "Now these kind of problems have been studied for, you know 5060 years.",
            "Turns out if you look at them in the worst case and do this very simple thing.",
            "Here you get a better algorithm.",
            "So I just want to give you these kind of little examples that you might.",
            "Have seen before because.",
            "They show the subtlety of this analysis.",
            "Forward algorithm is kind of adjusting the counts and one of them is this throwing off algorithm OK to Russians.",
            "You put in the half count.",
            "Laplace would be the one adding the one count here as is the total number of this weekend Bernoulli case.",
            "So we have coin flips, so this is the total number of flips.",
            "Zeros is tails, one is heads, total number of ones and then you add a half and you divide by the number of flips plus one.",
            "This is sort of the best algorithm in this context, it turns out.",
            "That there is a better if you do the last step in Emacs, it has this form, which is seemingly completely unrelated.",
            "Or at least not easily related to anything of this type.",
            "It's certainly not related to maximum likelihood, kind of estimates in the exponential family.",
            "Not obviously, at least.",
            "The worst case regret bounds are also log T + 1 + C, But now the constant is slightly improved, so whenever you have an application.",
            "That uses these counts well, why don't you try this algorithm and see whether it's slightly better?",
            "So this was again.",
            "The fancy of this laughs that minimax, and in some cases."
        ],
        [
            "You can even analyze this.",
            "OK. Analyzing this showed that shrinkage is very important.",
            "Shrinkage was a big thing.",
            "In the statistics community, when they discovered Stein estimators.",
            "Stein estimators uses shrinkage for some kind of a problem.",
            "That is an expected loss type of problem.",
            "Here we show shrinkage is already necessary in the worst case, so it's kind of a curious thing.",
            "OK.",
            "So."
        ],
        [
            "Synopsis game theoretic.",
            "They have slightly better bounds, but they're harder to prove and harder to deal with divergences.",
            "Closer to base and standard convex optimization, you have differentiation.",
            "Usually because we look at differentiable case and.",
            "It's.",
            "More commonly used, more accessible for most people and gets you her istics very fast.",
            "But if you wanted to really do your homework, then you should do this game theoretic stuff.",
            "Now of course these are worst case bounds, and you could always be in a situation where this kind of worst."
        ],
        [
            "Case thing is too overly pessimistic and then the divergents based stuff might be better.",
            "OK, but if this is your goal then you should use game theory.",
            "OK, now.",
            "Where is my little open problem?",
            "Actually I have fun making up lots of open problems.",
            "It's one of my main hobbies so.",
            "I did this for.",
            "Gaussian density estimation.",
            "And.",
            "Ended up."
        ],
        [
            "With this funny shrinkage.",
            "Now for linear regression.",
            "The last step, mini Max, was his fancy algorithm.",
            "That added one more count in the Gaussian case and in the linear regression case it added the current instance into the covariance matrix.",
            "So imagine you're in the following situation where you have a bunch of labeled points and lots of unlabeled points.",
            "And now you want to.",
            "Set up one of those minimax problems.",
            "And compute the minimax for.",
            "Linear regression and that's the first problem.",
            "I don't know.",
            "It somehow would.",
            "Involves shrinkage.",
            "In terms of covariance matrices.",
            "I have guesses as to what the recurrence is, but I don't know how to analyze it yet.",
            "Basically I need a good student.",
            "You know that's how you do it.",
            "OK."
        ],
        [
            "Um?",
            "So this is this part of this.",
            "Tutorial.",
            "And what I'm going to do next is.",
            "Talk a little bit about.",
            "I talked a lot about online learning which is worst case loss bounds.",
            "Now I want to talk about the case.",
            "What happens if you have an online bound but you actually interested in the case when you are instances are examples of generated by distribution.",
            "Well.",
            "It turns out there's conversion algorithms.",
            "I will talk about convergence algorithm set a little bit and then I will talk about applications because.",
            "Kind of noticing there wasn't too many questions when you do thiery so.",
            "I reshuffle things and you're going to get new slides where I talk about lots of applications of this online learning.",
            "That should be fairly accessible.",
            "For people, well, you get a sense for how you actually use these online algorithms, OK?",
            "And I'm going to do that mainly in the second lecture today, but for the next 15 minutes I will start with conversions and.",
            "A little bit of applications and then lots more applications in the second lecture, so let me switch for a moment.",
            "Online to batch conversions.",
            "Some simple cases.",
            "Then I talk about caching, disk, spin, time and many other problems.",
            "OK."
        ],
        [
            "So, so we have an algorithm.",
            "You have a worst case loss bound.",
            "Now you want an expected loss bound, so you want to have something like that."
        ],
        [
            "This is small with high probability tail bound."
        ],
        [
            "So.",
            "You have some kind of a loss function.",
            "Right, I'm going to do only sketch this.",
            "Basically what you want is if you want to get good bounds my my.",
            "Personal opinion is first try to prove them in the worst case.",
            "Why?",
            "Because very often you get the boost, the good the best probabilistic bounds.",
            "That way it's kind of if you if you take that forward algorithm for linear regression and take one of those conversions and turn it into an expected bound expected regret bound or something like that.",
            "You beat any kind of probabilistic bandits around.",
            "Why this is the case, we don't know.",
            "It's kind of lucky, don't know.",
            "So you have a worst case lost found and now.",
            "Imagine that your sequence is generated by a fixed but unknown distribution.",
            "Right not what I said.",
            "Talk to set out in this tutorial at all.",
            "This toilet said well.",
            "Examples are produced by an adversary.",
            "Examples are produced by nature of no assumption probabilistic assumptions.",
            "But now let's go back to the Canonical case that everybody else is looking at.",
            "Where the instances are actually generated by a fixed distribution that they drawn independently at random IID.",
            "Well, how do you recover that old case?",
            "Well, you take your online algorithm, that is, that was proven for the worst case, and you do a general conversion.",
            "You do some general trick on top of it, and then you immediately have guarantees that hold in the expected case.",
            "And so I'm going to show you a little.",
            "Basically, you need to do some averaging.",
            "OK, the simplest.",
            "Assume you have the perceptron algorithm.",
            "You have the perceptron convergence theorem, which bounds the number of mistakes.",
            "Perception album Now you want to say, well, if the things are generated at random, what's the expected loss expected?",
            "Number of mistakes of the perceptron algorithm?",
            "Well, the simplest thing to do is you run the perceptron algorithm over all your data and you take the last hypothesis.",
            "Turns out that's not the right thing to do.",
            "You need to do a little bit more.",
            "Averaging are slightly sophisticated tricks, not too sophisticated.",
            "So what we want to get is now a bound of the type you get about a sample, and then at the end you want to produce a hypothesis.",
            "And it's supposed to have small expected loss.",
            "So now I need to.",
            "Define instantaneous loss of a hypothesis with respect to distribution.",
            "It's just the expected loss of this hypothesis on an example drawn according to the same distribution.",
            "Ceclor so this loss.",
            "This consists of an instance and a label.",
            "You predict the instance and then you measure the loss to the label.",
            "So this is sort of a little bit concise notation.",
            "But oh.",
            "Somebody."
        ],
        [
            "Go away.",
            "OK.",
            "So how do you get a conversion for the expected loss?",
            "So you look at the total loss of the algorithm.",
            "Right, expected to Lausanne, now you observe the following this one.",
            "Is expand this out is the sum of these losses.",
            "You take the algorithm on T -- 1 example you get the next, you incur loss and you sum over trials.",
            "Now the expectation goes inside.",
            "And this actually becomes the sum of the expectation expected instantaneous losses.",
            "So, so what's happening is the following when you do.",
            "When you have your stream of examples, you have T + 1 hypothesis one here, one here, one here, one here, one here, right until all the way to the end and what you want to do is you pick one at random.",
            "So you pick a hypothesis."
        ],
        [
            "Up the T Plus was about this at random and you predict on the new instance with this hypothesis and the instantaneous loss of this algorithm is the expected loss.",
            "Expect a total loss of the original algorithm over T + 1 trials.",
            "And.",
            "So whenever you have a lost bound that holds in the worst case it's, let's say M, then we're this conversion.",
            "Will you pick one of those?",
            "Hypothesis at random immediately you get expected loss of M / T. And.",
            "Again."
        ],
        [
            "Just going to the end and picking the last hypothesis is not good, because if you only have a guarantee on the total loss, you could have algorithms that go along and then curl off of loss at the end, which you don't know.",
            "You only have a bound on the total loss so but the averaging trick hedges against that.",
            "Now you could say does this occur for practical algorithm?",
            "And yes, it occurs for the perceptron algorithm if you.",
            "Want to convert the perceptron algorithm to A to a loss to an algorithm that that probably works well in the expected case?",
            "This is actually a good thing to do.",
            "Sometimes in the perception case, you take multiple.",
            "Sorry, you take multiple.",
            "Passes over your data an average.",
            "OK.",
            "So this is very close to averaging the hypothesis, of course.",
            "Case also tailback."
        ],
        [
            "So for instance, you have a loss which has this range.",
            "Again, you look at your T + 1 hypothesis you average.",
            "They hypothesis.",
            "And then you can show if the total worst case loss is M, then with probability at least one minus Delta.",
            "The error of the average hypothesis is.",
            "This big.",
            "So this was the expectation.",
            "Now you're going a little bit further out.",
            "And you get a tail bound.",
            "You get the error is small with high probability.",
            "So.",
            "Again, my philosophy is.",
            "Go ahead.",
            "And.",
            "Do your worst case loss Fund 1st and then convert it.",
            "OK."
        ],
        [
            "So.",
            "Um?",
            "What I'm going to talk about next is lots of applications.",
            "OK, and actually still have quite a few slides to go through.",
            "But there's not so many formulas this time.",
            "So whenever you pick up your telephone and you listen to your telephone very carefully.",
            "It goes like shit.",
            "So what happens is there's some kind of echo cancellation happening or.",
            "Adaptive channel equalization where?",
            "The.",
            "An online algorithm learns.",
            "The average signal.",
            "And then subtracts that average signal.",
            "From the current signal.",
            "And the average signal is supposed to be noise.",
            "Subtracting that off gets rid of the noise and it clears your channel.",
            "Very old thing.",
            "People usually do this using.",
            "The Witcher half algorithm.",
            "That's where it was invented.",
            "That's basically what it was invented for.",
            "I went to Bell Labs and talk to some of the original researchers.",
            "Anne.",
            "And the typical algorithm is this algorithm, Woodruff algorithm.",
            "And fans a slight fancy fications of it.",
            "In certain settings in certain settings, certain rooms the echoes actually are quite sparse.",
            "The weight vector has lots of zeros.",
            "Then it turns out you can use the unnormalized exponential equation algorithm and.",
            "This guy Mahoney I don't know and Williamson and some other people showed that in this case this other online album that we developed in the online learning community more recently.",
            "And this the proximation of it actually performs much better than this algorithm.",
            "The exponential gradient algorithm would be.",
            "Ice new weight is I sold wait times E to this gradient, but you can approximate this gradient.",
            "Each of the gradient using this factor.",
            "This is sometimes called the Chi squared update.",
            "Why?",
            "Because in practice very often you want to be very fast, so exponentials are too hard to compute already.",
            "Hey so.",
            "Then I will talk."
        ],
        [
            "Art cashin so, in caching occurs all over the place.",
            "It occurs whenever you have a small fast memory.",
            "And a much larger, slower secondary memory.",
            "So the idea is you keep.",
            "In the fast memory objects there likely to be.",
            "Need it soon you have a hit.",
            "If the next object resides in the cache in the miss otherwise.",
            "And.",
            "Basically, I'm going to learn a good caching strategy and adapt to the particular data looked at.",
            "Request sequence might change overtime, right?",
            "Certain people might favor certain things you might want to change.",
            "The user might change, and so forth, right?",
            "Or the time of the day, dependencies all kinds of dependencies.",
            "They are."
        ],
        [
            "Some fancy well known caching strategies.",
            "Forecasting policy's seven most common policies might be least recently used random, first, in first out, last, first, last in first out.",
            "These already fancy strategies.",
            "Oh, which I don't know the acronyms for and then these are composite strategies.",
            "So of course I'm not a caching special specialist, I'm just.",
            "Taking things.",
            "Throwing an online algorithm on top and I'm going to show you I'm going to do much better.",
            "I'm going to beat the hell out of any of these individual strategies because I'm going to adapt online, right?",
            "You got the game.",
            "All of these strategies use sort of recency, frequency of access, size of objects, Costa fetching from secondary member.",
            "The defector standard is least recently used."
        ],
        [
            "OK.",
            "Which policy do choose?",
            "Well, first of all situation dependency.",
            "Disk access, web web browser kind of thing, file server kind of applications, different time of the day.",
            "It's application as well as time dependent as well as user dependent.",
            "Choosing one is ridiculous.",
            "Of course all of these algorithms already at particular fancy one they claim to be attractive, so the term adaptive is everywhere.",
            "So our first most difficult task was.",
            "To come up with a good comparator.",
            "And I'm going to explain that to you in a moment.",
            "We had a lot of fun."
        ],
        [
            "So this is what it looks like.",
            "Here's a a stream of requests and we have some kind of we get data from some large simulators right operating system, but they're very good at writing simulators.",
            "And then I looked at a window of 300 and I looked at the miss rate.",
            "A window of 300 and I wrote down the miss rate and then followed how the mystery changes overtime.",
            "Least recently used, there's a different colors for the different strategies are 12 different strategies.",
            "You can see sort of that.",
            "It's data that kind of moves around a lot.",
            "The Miss rates move around a lot, and different strategies are on the top.",
            "And intuitively, we want to design an algorithm that's at least as good as the best one.",
            "As the minute as it is, the minimum miss rate of this right, the best of these.",
            "We want to hug this curve from below.",
            "Turns out that's fairly easy.",
            "We can do much better.",
            "K now if you have an online problem, there's a very simple way to test.",
            "How much online Ness you have?",
            "What you do is you take your data and permute it.",
            "Run the algorithm again and see whether or run your tests again and see whether something is worse.",
            "If you do this in this case.",
            "Look"
        ],
        [
            "Like this?",
            "So there's one guy that is always best.",
            "Which is some kind of some kind of a frequency based thing.",
            "But the miss rates in general shift up are actually the best one is down here 0.2.",
            "Which is sort of this kind of thing OK?",
            "Anne.",
            "At the overall miss rates.",
            "Bam, bam.",
            "Here work very close to 0."
        ],
        [
            "So.",
            "The minimum ones average maybe about 0.1 now.",
            "After permuting the data."
        ],
        [
            "I made my day to worse.",
            "I took the online Ness away.",
            "Right, and of course.",
            "Here I can't do anything with online.",
            "But because I made it IID data when I've IID data, there's a fixed one that is best.",
            "I cannot adapt.",
            "What I have seen before doesn't influence in any way what depends on the future where it's here, I still have the online Ness.",
            "OK, so I want to explore the difference between these two curves you see.",
            "With more online algorithms and it turns out.",
            "You can do that."
        ],
        [
            "And I will do that in the second lecture.",
            "OK. And give you other applications break time.",
            "Extra online learning loss tutorial lecture.",
            "And then there's going to be some research talks one this afternoon and PCA.",
            "Where I generalize the exponential gradient algorithm to a matrix exponential integration algorithm.",
            "Quite interesting, very recent research and then I. I have another talk tomorrow or generalized Bayes rule to a basal for positive density density to basically for density matrices.",
            "It's actually related to.",
            "Quantum physics anyway."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Of the tutorial on online learning and Bregman divergences.",
                    "label": 0
                },
                {
                    "sent": "There's going to be 2 lectures in a row.",
                    "label": 0
                },
                {
                    "sent": "And break in the middle.",
                    "label": 0
                },
                {
                    "sent": "And then there's going to be research talks on related topics this afternoon and tomorrow afternoon.",
                    "label": 0
                },
                {
                    "sent": "OK, I'm Munford Vermote University of California, Santa Cruz and again credits to Ghana Ranch as well.",
                    "label": 0
                },
                {
                    "sent": "We still working on his tutorial I guess.",
                    "label": 0
                },
                {
                    "sent": "see I don't see him here.",
                    "label": 0
                },
                {
                    "sent": "So I wanted to talk a little bit more about Bregman divergences.",
                    "label": 0
                },
                {
                    "sent": "So have to screen through this, apologies for that.",
                    "label": 0
                },
                {
                    "sent": "So here's the picture you should have in mind on Bregman divergences.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Anne, it's.",
                    "label": 0
                },
                {
                    "sent": "Convex function.",
                    "label": 0
                },
                {
                    "sent": "Minus linear.",
                    "label": 0
                },
                {
                    "sent": "Approximation.",
                    "label": 0
                },
                {
                    "sent": "OK, this is the formula you should keep in mind.",
                    "label": 0
                },
                {
                    "sent": "And I'm now going to motivate this.",
                    "label": 0
                },
                {
                    "sent": "Bregman divergences using exponential exponential family distribution.",
                    "label": 0
                },
                {
                    "sent": "Kind of very much similar to what Alex Maller did yesterday.",
                    "label": 0
                },
                {
                    "sent": "So now I have to figure out where I stopped.",
                    "label": 0
                },
                {
                    "sent": "OK, here we are on page.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "91 at so you should have the handout and a second part of the handout you're going to get at the break.",
                    "label": 0
                },
                {
                    "sent": "OK, we do.",
                    "label": 0
                },
                {
                    "sent": "As you know, I'm an online learner so everything is happening online.",
                    "label": 0
                },
                {
                    "sent": "Even the even the slides are produced online, OK?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So what is exponential family of distribution?",
                    "label": 0
                },
                {
                    "sent": "You have a density defined by this exponential and why?",
                    "label": 0
                },
                {
                    "sent": "Why this exponential?",
                    "label": 0
                },
                {
                    "sent": "I always joke around in my class is well in machine learning we only do what we can do.",
                    "label": 0
                },
                {
                    "sent": "We interested in log loss and we know how to do linear things so suddenly E to the linear becomes important.",
                    "label": 0
                },
                {
                    "sent": "OK so Y to the linear, that's what this is.",
                    "label": 0
                },
                {
                    "sent": "It's linear in X.",
                    "label": 0
                },
                {
                    "sent": "Then OK, Alex yesterday had a fire in front of this.",
                    "label": 0
                },
                {
                    "sent": "I simplified and just have an X here for simplicity.",
                    "label": 0
                },
                {
                    "sent": "So no very simplest case of a sufficient statistic and this function.",
                    "label": 0
                },
                {
                    "sent": "It's going to take care of the normalization.",
                    "label": 0
                },
                {
                    "sent": "This is a reference density, so many of these distributions that we're looking at most natural distributions have this form.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "The parameter is.",
                    "label": 0
                },
                {
                    "sent": "You have a parameter vector and an instance vector.",
                    "label": 0
                },
                {
                    "sent": "Sort of OK.",
                    "label": 0
                },
                {
                    "sent": "This is called a cumulant function.",
                    "label": 0
                },
                {
                    "sent": "It makes sure that this thing integrates to one.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to talk a lot about that Bregman divergences generalized.",
                    "label": 0
                },
                {
                    "sent": "This big problem in this area is you have to make sure the cumulant function integrates to one when you do Bregman divergences.",
                    "label": 0
                },
                {
                    "sent": "You don't need to assure that you sort of can work with arbitrary convex function, I'll get to that later.",
                    "label": 0
                },
                {
                    "sent": "Turns out that very nicely G is a convex function on some convex set.",
                    "label": 0
                },
                {
                    "sent": "D's number parameters and this cumulative function generalizes characterizes members of the family.",
                    "label": 0
                },
                {
                    "sent": "The parameter when you write it this way.",
                    "label": 0
                },
                {
                    "sent": "This parameter is called a natural parameter.",
                    "label": 0
                },
                {
                    "sent": "OK, I will go through a number of examples in a moment.",
                    "label": 0
                },
                {
                    "sent": "You must have heard this many Times Now, but.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I emphasize slightly different things, so I'm going over again.",
                    "label": 0
                },
                {
                    "sent": "There's a second parameter called expectation parameter, which is the expectation of.",
                    "label": 0
                },
                {
                    "sent": "The instance vector with respective distribution.",
                    "label": 0
                },
                {
                    "sent": "And then it turns out that this expectation and.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "Alex gave a proof yesterday.",
                    "label": 0
                },
                {
                    "sent": "Is equal to the derivative of the human function.",
                    "label": 0
                },
                {
                    "sent": "Right, so this new parameter is equal to little G of Theta, where G of ETA is the gradient of the cumulant function.",
                    "label": 0
                },
                {
                    "sent": "Again, the cumulant function was this now.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Analyzing thing.",
                    "label": 0
                },
                {
                    "sent": "It made sure that the distribution was normalized.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then expect expected value of the instance is equal to.",
                    "label": 0
                },
                {
                    "sent": "Little G of data, which is the derivative of the cumulative function.",
                    "label": 0
                },
                {
                    "sent": "So now.",
                    "label": 0
                },
                {
                    "sent": "Whenever you work with this kind of a thing.",
                    "label": 0
                },
                {
                    "sent": "You always have a notion of duality, so there's a 6 second convex function called the convex convex conjugate function.",
                    "label": 0
                },
                {
                    "sent": "You can write it with terms of a soup.",
                    "label": 0
                },
                {
                    "sent": "Martin Wainwright did that, of course.",
                    "label": 0
                },
                {
                    "sent": "Here I'm in the differential case, so I don't need the soup.",
                    "label": 0
                },
                {
                    "sent": "I can write down explicit formula and the second function is F of mu, which is Theta times move, minus G of Theta.",
                    "label": 0
                },
                {
                    "sent": "OK these are.",
                    "label": 0
                },
                {
                    "sent": "Convex conjugates?",
                    "label": 0
                },
                {
                    "sent": "And again, little F denotes the gradient of capital F, and then these two are inverses of each other in pictures in a more over.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You type picture.",
                    "label": 0
                },
                {
                    "sent": "You sort of have two parameters.",
                    "label": 0
                },
                {
                    "sent": "Primal and dual parameters natural and expectation parameters right.",
                    "label": 0
                },
                {
                    "sent": "Everything comes in pairs.",
                    "label": 0
                },
                {
                    "sent": "That's always how these things work, and I'm going to go through examples in a moment.",
                    "label": 0
                },
                {
                    "sent": "And this is also why it's confusing.",
                    "label": 0
                },
                {
                    "sent": "But once you get a handle on it, it's actually quite elegant.",
                    "label": 0
                },
                {
                    "sent": "OK, natural parameter is mapped via the little G function, which is the derivative of this function to the expectation parameter which is mapped via the little F function, which is the derivative of F back to the natural parameter.",
                    "label": 0
                },
                {
                    "sent": "So their tool parameters and here the transformations.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is sort of the overview picture.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "Examples.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Simplest example is the Gaussian and now I I do the Gaussian even simpler than Alex I did yesterday.",
                    "label": 0
                },
                {
                    "sent": "I do it for a fixed variance.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The distribution is E to the minus.",
                    "label": 0
                },
                {
                    "sent": "Quadratic.",
                    "label": 0
                },
                {
                    "sent": "The quadratic you can rewrite it this way.",
                    "label": 0
                },
                {
                    "sent": "This is a reference density.",
                    "label": 0
                },
                {
                    "sent": "This is your G function.",
                    "label": 0
                },
                {
                    "sent": "This is your linear part.",
                    "label": 0
                },
                {
                    "sent": "So here's the Cuban function.",
                    "label": 0
                },
                {
                    "sent": "OK. Now in this case, if you take the derivative of this function, you get the identity function and the inverse of that identity function is again the identity function.",
                    "label": 0
                },
                {
                    "sent": "So this is sort of the simplest case.",
                    "label": 0
                },
                {
                    "sent": "This is the case that corresponds to.",
                    "label": 0
                },
                {
                    "sent": "Represent a theorem corresponds to kernel isable algorithm.",
                    "label": 0
                },
                {
                    "sent": "Everything is sort of very simple.",
                    "label": 0
                },
                {
                    "sent": "There's the link function is the identity function.",
                    "label": 0
                },
                {
                    "sent": "And the dual convex function is.",
                    "label": 0
                },
                {
                    "sent": "You plug in the formula.",
                    "label": 0
                },
                {
                    "sent": "Now also the same function in terms of the other variable.",
                    "label": 0
                },
                {
                    "sent": "OK, the log likelihood of this function is simply the square loss.",
                    "label": 0
                },
                {
                    "sent": "So let me go back again.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In generality, two parameters natural parameter expectation parameter mappings, little G Maps to hear little F Maps back.",
                    "label": 0
                },
                {
                    "sent": "Those are the derivatives of the corresponding functions.",
                    "label": 0
                },
                {
                    "sent": "These two functions are convex conjugates.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "First example.",
                    "label": 0
                },
                {
                    "sent": "Gaussian.",
                    "label": 0
                },
                {
                    "sent": "You rewrite it.",
                    "label": 0
                },
                {
                    "sent": "Linear part cumulant function.",
                    "label": 0
                },
                {
                    "sent": "You take the derivatives and you see everything is the identity function.",
                    "label": 0
                },
                {
                    "sent": "The two convex conjugate functions are identical, this one, and this one.",
                    "label": 0
                },
                {
                    "sent": "They are identical clear.",
                    "label": 0
                },
                {
                    "sent": "OK. Now.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Other very basic case.",
                    "label": 0
                },
                {
                    "sent": "Is bernoulli.",
                    "label": 0
                },
                {
                    "sent": "Density looks like this.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "Where mu is the probability.",
                    "label": 0
                },
                {
                    "sent": "It's a coin, and it's the probability of the outcome of the coin being one.",
                    "label": 0
                },
                {
                    "sent": "The natural parameter happens to be.",
                    "label": 0
                },
                {
                    "sent": "This actually moves the expectation parameters you will see.",
                    "label": 0
                },
                {
                    "sent": "And this is the natural parameter.",
                    "label": 0
                },
                {
                    "sent": "Now I can write my density as.",
                    "label": 0
                },
                {
                    "sent": "PF Theta X.",
                    "label": 0
                },
                {
                    "sent": "Minus L and this is just straightforward algebra, which I didn't show, but it's not so hard.",
                    "label": 0
                },
                {
                    "sent": "If you have some time, it's linear minus this function.",
                    "label": 0
                },
                {
                    "sent": "This of course is a. Convex function.",
                    "label": 0
                },
                {
                    "sent": "Here.",
                    "label": 0
                },
                {
                    "sent": "And then you take the derivative of this, you get the softmax.",
                    "label": 0
                },
                {
                    "sent": "As the little G and it's the little F you get this function.",
                    "label": 0
                },
                {
                    "sent": "You can also plug in and compute the dual and you get this.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "The negative entropy.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "If you.",
                    "label": 0
                },
                {
                    "sent": "Take the log of this function and write it in the Theta domain.",
                    "label": 0
                },
                {
                    "sent": "It looks like this if you write it using the new parameter.",
                    "label": 0
                },
                {
                    "sent": "It looks like this so it looks sort of like a cross entropy.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So this all may seem like magic, but it follows a certain routine.",
                    "label": 0
                },
                {
                    "sent": "Once you have the routine, it's OK. And people have done this for very long.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm they wrote books and books of these exponential families and basically they were too hard to read for me, so I got rid of them and use pregnant emergencies which are easier.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Plus on another famous case.",
                    "label": 0
                },
                {
                    "sent": "The instances are natural numbers.",
                    "label": 0
                },
                {
                    "sent": "This is the distribution.",
                    "label": 0
                },
                {
                    "sent": "I wrote it again in terms of the expectation parameter.",
                    "label": 0
                },
                {
                    "sent": "The natural parameters log of mu.",
                    "label": 0
                },
                {
                    "sent": "If you write it as a function of the natural parameter, it becomes easy to the linear minus Y to the Theta.",
                    "label": 0
                },
                {
                    "sent": "This is your convex function.",
                    "label": 0
                },
                {
                    "sent": "Obviously the exponential is convex.",
                    "label": 0
                },
                {
                    "sent": "Taking the derivative of this function, you get either the theater back.",
                    "label": 0
                },
                {
                    "sent": "And now inverse of each of the Theta you get log of me.",
                    "label": 0
                },
                {
                    "sent": "So you take E to Theta equals mu solve from you and you get the other function here that that's not integral of that is the convex conjugate function.",
                    "label": 0
                },
                {
                    "sent": "These two are conjugates.",
                    "label": 0
                },
                {
                    "sent": "Loss.",
                    "label": 0
                },
                {
                    "sent": "Is simply the log of this.",
                    "label": 0
                },
                {
                    "sent": "An and this sort of looks like a normalized cross entropy.",
                    "label": 0
                },
                {
                    "sent": "Will make all of this a little bit more precise in a moment, so this is possible, but newly prosar.",
                    "label": 0
                },
                {
                    "sent": "Ha, let's do.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A more general observation, how do these two relate?",
                    "label": 0
                },
                {
                    "sent": "OK, so whenever you have a distribution, the only reasonable measure of divergent between two distributions, relative entropy is a coding theoretic interpretation.",
                    "label": 0
                },
                {
                    "sent": "Right in terms of the additional code book length, if you take the wrong code blah blah blah little bit too much, it's this.",
                    "label": 0
                },
                {
                    "sent": "It goes back to Shannon.",
                    "label": 0
                },
                {
                    "sent": "You can read the first couple of chapters covis book.",
                    "label": 0
                },
                {
                    "sent": "So this is the relative entropy and I measure the relative entropy between two distributions from the same family characterized by G1.",
                    "label": 0
                },
                {
                    "sent": "Parameter Theta one parameter Theta twiddle, and what I'm going to get out of this.",
                    "label": 0
                },
                {
                    "sent": "Is that this is a Bregman divergent?",
                    "label": 0
                },
                {
                    "sent": "This is a familiar Bregman divergences.",
                    "label": 0
                },
                {
                    "sent": "OK. How do we prove this well?",
                    "label": 0
                },
                {
                    "sent": "Look, this had this E to the linear form right?",
                    "label": 0
                },
                {
                    "sent": "And eat the linear matches with the log, because if you take logs, the linear pulls down and what do we know how to do linear?",
                    "label": 0
                },
                {
                    "sent": "OK, good so.",
                    "label": 0
                },
                {
                    "sent": "E to the linear log of each of the linear.",
                    "label": 0
                },
                {
                    "sent": "That's this part.",
                    "label": 0
                },
                {
                    "sent": "The reference density cancels out.",
                    "label": 0
                },
                {
                    "sent": "Then minus log either the each of the same thing becomes this piece these two terms.",
                    "label": 0
                },
                {
                    "sent": "And I have an integral over this.",
                    "label": 0
                },
                {
                    "sent": "Everybody understand this step from the idea.",
                    "label": 0
                },
                {
                    "sent": "OK, I just plugged in the E to the linear form and talk logs, so I'm here.",
                    "label": 0
                },
                {
                    "sent": "Now I distribute over this whole thing because everything is constant except X, so I have.",
                    "label": 0
                },
                {
                    "sent": "Here.",
                    "label": 0
                },
                {
                    "sent": "I have here.",
                    "label": 0
                },
                {
                    "sent": "The integral only is staying over the X, but this is an expectation.",
                    "label": 0
                },
                {
                    "sent": "So that is our mood.",
                    "label": 0
                },
                {
                    "sent": "And Wala and moves actually little G of Theta.",
                    "label": 0
                },
                {
                    "sent": "So this here.",
                    "label": 0
                },
                {
                    "sent": "Is our normal formula, which you should recognize now.",
                    "label": 0
                },
                {
                    "sent": "For this relative entropy, it is convex function minus the linear approximation, where this is G of Theta.",
                    "label": 0
                },
                {
                    "sent": "OK, now if you take this line here and plug in the definition of convex conjugate.",
                    "label": 0
                },
                {
                    "sent": "For differentiable function, then via transformation you end up with a very similar looking formula where now.",
                    "label": 0
                },
                {
                    "sent": "You use the convex conjugate function as the convex function.",
                    "label": 0
                },
                {
                    "sent": "F 12 minus the linear approximation, and here this is a little F of.",
                    "label": 0
                },
                {
                    "sent": "Mutual.",
                    "label": 0
                },
                {
                    "sent": "So this.",
                    "label": 0
                },
                {
                    "sent": "This.",
                    "label": 0
                },
                {
                    "sent": "It's the same as this.",
                    "label": 0
                },
                {
                    "sent": "Everything comes in pairs.",
                    "label": 0
                },
                {
                    "sent": "It's related to in some sense convex problems.",
                    "label": 0
                },
                {
                    "sent": "I've always the dual problem.",
                    "label": 0
                },
                {
                    "sent": "The dual of the dual is the original and you see here.",
                    "label": 0
                },
                {
                    "sent": "That as well, because if you take the convex conjugate contest operation applied twice, you would go back to here and then.",
                    "label": 0
                },
                {
                    "sent": "This argument would switch once more and go to the other domain and you would end up here.",
                    "label": 0
                },
                {
                    "sent": "So you can kind of see that if you apply twice you get back to the original.",
                    "label": 0
                },
                {
                    "sent": "So this is equal to this.",
                    "label": 0
                },
                {
                    "sent": "So what I have what have I done so far?",
                    "label": 0
                },
                {
                    "sent": "And I'm going to go through examples again in a moment.",
                    "label": 0
                },
                {
                    "sent": "Same kind of examples I see.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Find exponential family distribution very, very simple form.",
                    "label": 0
                },
                {
                    "sent": "This was the convex function that characterized the family.",
                    "label": 0
                },
                {
                    "sent": "It makes sure that things integrate to one.",
                    "label": 0
                },
                {
                    "sent": "I did.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Find another parameter expectation parameter, which is supposedly the derivative of the cumulant function.",
                    "label": 0
                },
                {
                    "sent": "Defined a second convex function convex conjugate differential case.",
                    "label": 0
                },
                {
                    "sent": "You don't need the soup, you have an explicit formula.",
                    "label": 0
                },
                {
                    "sent": "And then went through a bunch of examples and then.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Establish this relationship.",
                    "label": 0
                },
                {
                    "sent": "You never have a convex come a exponential family if you compute relative entropies, you get Bregman divergences, but it is not true that an arbitrary Bregman divergences corresponds to an exponential family, not at all.",
                    "label": 0
                },
                {
                    "sent": "Intuitively, what you need to assure for it to be an exponential family is that that the some kind of probabilistic interpretation and something integrates to one for arbitrary Bregman divergences.",
                    "label": 0
                },
                {
                    "sent": "You start start with a convex function.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "This form questions.",
                    "label": 0
                },
                {
                    "sent": "OK, this form of the Bregman divergent convex functions minus linear approximation was popularized by Bregman.",
                    "label": 0
                },
                {
                    "sent": "And actually.",
                    "label": 0
                },
                {
                    "sent": "Discovered or rediscovered this family in a different way as an integral.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Anne, it turns out that.",
                    "label": 0
                },
                {
                    "sent": "If you write down the sigmoid function and you compute these kind of integrals underneath the sigmoid, they become relative entropies and I was.",
                    "label": 0
                },
                {
                    "sent": "That's how I rediscovered this in more general terms.",
                    "label": 0
                },
                {
                    "sent": "If you have a little G function.",
                    "label": 0
                },
                {
                    "sent": "And you integrate from Theta Twiddle.",
                    "label": 0
                },
                {
                    "sent": "Two Theta should be Theta here.",
                    "label": 0
                },
                {
                    "sent": "Then the integral underneath happens to be the Bregman divergent.",
                    "label": 0
                },
                {
                    "sent": "Is this the kind of the matching loss type motivation that I talked about already?",
                    "label": 0
                },
                {
                    "sent": "And before I knew about Bregman divergences and even convex conjugacy in all of these things.",
                    "label": 0
                },
                {
                    "sent": "I there is a version, there is a very intuitive version of showing that they.",
                    "label": 0
                },
                {
                    "sent": "This kind of relationship, why?",
                    "label": 0
                },
                {
                    "sent": "Well there is.",
                    "label": 0
                },
                {
                    "sent": "This is an increasing function.",
                    "label": 0
                },
                {
                    "sent": "Of course.",
                    "label": 0
                },
                {
                    "sent": "If you mirror this function on this line, you get the.",
                    "label": 0
                },
                {
                    "sent": "Inverse of this increasing function.",
                    "label": 0
                },
                {
                    "sent": "So now you can do the integral over in this domain, or you can flip your transparency, which I can't do anymore because we have these.",
                    "label": 0
                },
                {
                    "sent": "Uh.",
                    "label": 0
                },
                {
                    "sent": "We have now, you know, dislike projectors.",
                    "label": 0
                },
                {
                    "sent": "You flip the transparency and you can do the integral on the other axis and what happens?",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This this way?",
                    "label": 0
                },
                {
                    "sent": "So you write your divergance the normal way you can write it as an integral over the G. This is the same as this.",
                    "label": 0
                },
                {
                    "sent": "More general case, you need to have a path integral OK and now here integrate over the G function.",
                    "label": 0
                },
                {
                    "sent": "But instead I could go to the other domain and integrate over the Moose which are the other domain you see.",
                    "label": 0
                },
                {
                    "sent": "He left.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here in this axis, live the status in this axis.",
                    "label": 0
                },
                {
                    "sent": "Stiff moves so.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I can flip the transparency integrate over the other domain and I get this, so this is another way of seeing that there's always a duality.",
                    "label": 0
                },
                {
                    "sent": "And why?",
                    "label": 0
                },
                {
                    "sent": "Because I flipped the arguments flip and so forth, OK?",
                    "label": 0
                },
                {
                    "sent": "So this is how I had discovered it.",
                    "label": 0
                },
                {
                    "sent": "Before I even knew about convex conjugacy.",
                    "label": 0
                },
                {
                    "sent": "Soleb",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's go through these examples.",
                    "label": 0
                },
                {
                    "sent": "That I had.",
                    "label": 0
                },
                {
                    "sent": "Bernoulli convex function.",
                    "label": 0
                },
                {
                    "sent": "Convex conjugate function.",
                    "label": 0
                },
                {
                    "sent": "This is sort of the log partition function.",
                    "label": 0
                },
                {
                    "sent": "Which always is associated with a minimum relative with a relative entropy.",
                    "label": 0
                },
                {
                    "sent": "So here's the here's the.",
                    "label": 0
                },
                {
                    "sent": "Actually the convex function is just the entropy.",
                    "label": 0
                },
                {
                    "sent": "For negative the entropy.",
                    "label": 0
                },
                {
                    "sent": "Here the corresponding link functions the softmax, and then this.",
                    "label": 0
                },
                {
                    "sent": "I think this is the probe.",
                    "label": 0
                },
                {
                    "sent": "It kind of thing.",
                    "label": 0
                },
                {
                    "sent": "Now if you go ahead.",
                    "label": 0
                },
                {
                    "sent": "And plug this function into.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This first line.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then you get this piece.",
                    "label": 0
                },
                {
                    "sent": "And this one maybe you don't recognize as clearly.",
                    "label": 0
                },
                {
                    "sent": "But if you would plug this function into.",
                    "label": 0
                },
                {
                    "sent": "I don't have that formula up to older versions into.",
                    "label": 0
                },
                {
                    "sent": "OK. And.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To this formula.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then you get the familiar looking relative entropy.",
                    "label": 0
                },
                {
                    "sent": "For single coin, so there's two outcomes.",
                    "label": 0
                },
                {
                    "sent": "One account with probability move, the other one 1 minus me.",
                    "label": 0
                },
                {
                    "sent": "And so it's the binary relative entropy.",
                    "label": 0
                },
                {
                    "sent": "And the sum of independent binary.",
                    "label": 0
                },
                {
                    "sent": "Entropies finally, relative entropies was used to motivate one of those entropic algorithms.",
                    "label": 0
                },
                {
                    "sent": "Binary exponentially gradient algorithm.",
                    "label": 0
                },
                {
                    "sent": "OK so again.",
                    "label": 0
                },
                {
                    "sent": "Whenever you write down these kind of relative entropies.",
                    "label": 0
                },
                {
                    "sent": "You sort of end up with Bernoulli or.",
                    "label": 0
                },
                {
                    "sent": "In a more general state case, multinomial.",
                    "label": 0
                },
                {
                    "sent": "Modeling that's happening.",
                    "label": 0
                },
                {
                    "sent": "So this was the binary relative entropy.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If you want to do, here it is.",
                    "label": 0
                },
                {
                    "sent": "The new lease for two outcomes you have N outcomes.",
                    "label": 0
                },
                {
                    "sent": "You get the normalized the normal entropy out of here.",
                    "label": 0
                },
                {
                    "sent": "OK, which motivated e.g exponentially creating algorithm.",
                    "label": 0
                },
                {
                    "sent": "K Dual divergance 4 plus saw.",
                    "label": 0
                },
                {
                    "sent": "This was the cumulant function.",
                    "label": 0
                },
                {
                    "sent": "This was the convex conjugate function.",
                    "label": 0
                },
                {
                    "sent": "Derivatives little G. They left ITA Theta log me.",
                    "label": 0
                },
                {
                    "sent": "Plug into the two formulas.",
                    "label": 0
                },
                {
                    "sent": "You get this relative entropy.",
                    "label": 0
                },
                {
                    "sent": "You know these formula.",
                    "label": 0
                },
                {
                    "sent": "These are always non negative right?",
                    "label": 0
                },
                {
                    "sent": "And have all these fine fancy properties?",
                    "label": 0
                },
                {
                    "sent": "They have Pythagorean theorem box equality.",
                    "label": 0
                },
                {
                    "sent": "All of these things that I said they always hold in general.",
                    "label": 0
                },
                {
                    "sent": "K bam, one.",
                    "label": 0
                },
                {
                    "sent": "If you do the if you plug this into the formula, bam, you get that these two are equal.",
                    "label": 0
                },
                {
                    "sent": "This is the a normalized relative entropy, so this motivates the unnormalized exponentially greater algorithm example window algorithm.",
                    "label": 0
                },
                {
                    "sent": "This is Claire.",
                    "label": 0
                },
                {
                    "sent": "So this is a normalized relative entropy.",
                    "label": 0
                },
                {
                    "sent": "OK, let me do a.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Case will be motivated the matching loss.",
                    "label": 1
                },
                {
                    "sent": "It's essentially using again.",
                    "label": 0
                },
                {
                    "sent": "The binary relative entropy so.",
                    "label": 1
                },
                {
                    "sent": "Your age of Z could be this.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "The tool I wrote this way.",
                    "label": 0
                },
                {
                    "sent": "Link function.",
                    "label": 0
                },
                {
                    "sent": "Inverse link function.",
                    "label": 0
                },
                {
                    "sent": "These are convex conjugates of each other, and now you plug into the formula.",
                    "label": 0
                },
                {
                    "sent": "So by duality.",
                    "label": 0
                },
                {
                    "sent": "The logistic loss.",
                    "label": 0
                },
                {
                    "sent": "Which.",
                    "label": 0
                },
                {
                    "sent": "Is this one is the same as the entropic loss, which is this one?",
                    "label": 1
                },
                {
                    "sent": "And we were using this as the matching loss for the logistic transfer function.",
                    "label": 1
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "Again, our model uses 2 divergences, one for the parameter domain and one for the last domain.",
                    "label": 0
                },
                {
                    "sent": "When the two are the same.",
                    "label": 0
                },
                {
                    "sent": "Then it's sort of the Canonical case.",
                    "label": 0
                },
                {
                    "sent": "It corresponds to what conjugate prior case.",
                    "label": 0
                },
                {
                    "sent": "But they don't have to be the same.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is what I wanted to say.",
                    "label": 0
                },
                {
                    "sent": "About Bregman divergences?",
                    "label": 0
                },
                {
                    "sent": "And how they relate to the exponential families.",
                    "label": 0
                },
                {
                    "sent": "You can always go back to the exponential families.",
                    "label": 0
                },
                {
                    "sent": "And sort of glean intuitions from statistics.",
                    "label": 0
                },
                {
                    "sent": "Exponential families is to make mainstay of statistics and whatever these guys have done, you can kind of look at and see how it fits in your thing and learn from.",
                    "label": 0
                },
                {
                    "sent": "The path that these guys have taken.",
                    "label": 0
                },
                {
                    "sent": "So that's why I linked.",
                    "label": 0
                },
                {
                    "sent": "I linked Bregman divergences back to.",
                    "label": 0
                },
                {
                    "sent": "The exponential family.",
                    "label": 0
                },
                {
                    "sent": "OK, but you can forget about all of this complicated stuff underlying probability distribution.",
                    "label": 0
                },
                {
                    "sent": "Maybe you're not so good at doing integrals.",
                    "label": 0
                },
                {
                    "sent": "So forget about that and just go back to the definition of Bregman divergent, which is convex function minus linear approximation.",
                    "label": 0
                },
                {
                    "sent": "You can completely characterize which Bregman divergences correspond to the exponential family, and basically it's it's pregnant divergences with a convex function has these log of sum of exponential form.",
                    "label": 0
                },
                {
                    "sent": "Not surprisingly, because that.",
                    "label": 0
                },
                {
                    "sent": "Corresponds to.",
                    "label": 0
                },
                {
                    "sent": "In some deep way to the to the what a cumulant is in general.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Oh, I always like to study.",
                    "label": 0
                },
                {
                    "sent": "The simplest problems.",
                    "label": 0
                },
                {
                    "sent": "So I talked about in this thing about the expert setting, which is rather simple setting.",
                    "label": 0
                },
                {
                    "sent": "I talked about linear regression, which was a large simple setting for online learning.",
                    "label": 0
                },
                {
                    "sent": "Now let's do the simplest density estimation.",
                    "label": 0
                },
                {
                    "sent": "The simplest case of density estimation.",
                    "label": 0
                },
                {
                    "sent": "Gaussian density estimation.",
                    "label": 0
                },
                {
                    "sent": "Right, and I'm going to tell you what we found out.",
                    "label": 0
                },
                {
                    "sent": "Using the methodology of divergencies.",
                    "label": 0
                },
                {
                    "sent": "And then I'm going to tell you.",
                    "label": 0
                },
                {
                    "sent": "A game theoretic and alternate game theoretic one which goes a little bit beyond this stuff.",
                    "label": 0
                },
                {
                    "sent": "And it's kind of interesting in its own right.",
                    "label": 0
                },
                {
                    "sent": "So what's Gaussian density estimation?",
                    "label": 0
                },
                {
                    "sent": "You get about cloud of points and you supposed to predict the mean.",
                    "label": 0
                },
                {
                    "sent": "Assume the variance is fixed simplest case.",
                    "label": 0
                },
                {
                    "sent": "So all you do is you take the mean.",
                    "label": 0
                },
                {
                    "sent": "You predict the average.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's a good thing to do, but it turns out that for online learning well, what's online?",
                    "label": 0
                },
                {
                    "sent": "Learning?",
                    "label": 0
                },
                {
                    "sent": "In this context, you get one point at a time, right?",
                    "label": 0
                },
                {
                    "sent": "You get one point.",
                    "label": 0
                },
                {
                    "sent": "You have to predict with the mean.",
                    "label": 0
                },
                {
                    "sent": "You incur some losses by how far you were off.",
                    "label": 0
                },
                {
                    "sent": "You get another point.",
                    "label": 0
                },
                {
                    "sent": "You have to predict with the mean, maybe of the previous points that you have seen, etc etc.",
                    "label": 0
                },
                {
                    "sent": "So you do this online and the question is, what's a reasonable model and so forth.",
                    "label": 0
                },
                {
                    "sent": "So the loss in this context would be log of Gaussians.",
                    "label": 0
                },
                {
                    "sent": "Densities, which is of course quadratic, very simple.",
                    "label": 0
                },
                {
                    "sent": "Now, why are we interested in quadratic?",
                    "label": 0
                },
                {
                    "sent": "Well, if we take, derivatives are linear and we're very good at linear.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Good so we want.",
                    "label": 0
                },
                {
                    "sent": "To derive our updates and to actually what we want to bound is this kind of a thing.",
                    "label": 0
                },
                {
                    "sent": "The total loss of the algorithm.",
                    "label": 0
                },
                {
                    "sent": "Minus.",
                    "label": 0
                },
                {
                    "sent": "The in hindsight best.",
                    "label": 0
                },
                {
                    "sent": "Loss of the best parameter.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "We get one point.",
                    "label": 0
                },
                {
                    "sent": "We have a mean.",
                    "label": 0
                },
                {
                    "sent": "We get a point where current loss.",
                    "label": 0
                },
                {
                    "sent": "We get another point.",
                    "label": 0
                },
                {
                    "sent": "We know we have a mean.",
                    "label": 0
                },
                {
                    "sent": "We get a point.",
                    "label": 0
                },
                {
                    "sent": "We incur loss, we make up another mean, get the second point incur a loss, make up another mean, get the Third Point, get a loss.",
                    "label": 0
                },
                {
                    "sent": "We sum these losses.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Overall trials.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "That's what this is.",
                    "label": 0
                },
                {
                    "sent": "This is a total loss of the algorithm we want to compare this against.",
                    "label": 0
                },
                {
                    "sent": "The in hindsight, best loss.",
                    "label": 0
                },
                {
                    "sent": "What's the in hindsight?",
                    "label": 0
                },
                {
                    "sent": "Best loss well.",
                    "label": 0
                },
                {
                    "sent": "You get all points.",
                    "label": 0
                },
                {
                    "sent": "And you get the one that minimizes the total loss, and actually that is always as Alex did yesterday.",
                    "label": 0
                },
                {
                    "sent": "The average point.",
                    "label": 0
                },
                {
                    "sent": "The average of all the points, including the future ones.",
                    "label": 0
                },
                {
                    "sent": "The online algorithm doesn't know the future points, so it doesn't know this, but I still can compare the total loss of the online algorithm against the best offline algorithm.",
                    "label": 0
                },
                {
                    "sent": "So this is called the regret.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "This is what we want to bound.",
                    "label": 0
                },
                {
                    "sent": "Again the offline algorithm.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "Has if you just want to minimize this, it puts you things at the average, but in a more fancy one.",
                    "label": 0
                },
                {
                    "sent": "If you want to compute an offline algorithm Now, what you would want to do is.",
                    "label": 0
                },
                {
                    "sent": "You would also maybe add some kind of a prior or some kind of initial divergance to some initial weight vector.",
                    "label": 0
                },
                {
                    "sent": "And if you minimize this, this is not a break.",
                    "label": 0
                },
                {
                    "sent": "Man divergences were G is is the cumulant function associated with the Gaussian which is quadratic the simplest case.",
                    "label": 0
                },
                {
                    "sent": "Then you can define.",
                    "label": 0
                },
                {
                    "sent": "Can minimize.",
                    "label": 0
                },
                {
                    "sent": "This term and what you get.",
                    "label": 0
                },
                {
                    "sent": "You see I didn't do it.",
                    "label": 0
                },
                {
                    "sent": "I didn't do the form yet, OK?",
                    "label": 0
                },
                {
                    "sent": "Duration of the updates.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is how you would motivate.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "The batch algorithm.",
                    "label": 0
                },
                {
                    "sent": "The online algorithm you would motivate it by taking it to virgins too.",
                    "label": 0
                },
                {
                    "sent": "Also the initial parameter, but only the loss.",
                    "label": 0
                },
                {
                    "sent": "So far in curd so far.",
                    "label": 0
                },
                {
                    "sent": "And these different.",
                    "label": 0
                },
                {
                    "sent": "This weightings of the initial distribution, this one.",
                    "label": 0
                },
                {
                    "sent": "Versus this one might be different.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "An alternate version of motivation of the online algorithms you take the divergance to the last.",
                    "label": 0
                },
                {
                    "sent": "And then just the loss the current loss occurred at the end.",
                    "label": 0
                },
                {
                    "sent": "And where your parameter is set this way.",
                    "label": 0
                },
                {
                    "sent": "And if you do this kind of updates and compute this minima, you get the following.",
                    "label": 0
                },
                {
                    "sent": "The offline algorithm basically.",
                    "label": 0
                },
                {
                    "sent": "Puts certain weight on the initial and then.",
                    "label": 0
                },
                {
                    "sent": "Sums all the instances and divides by.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "This trade off parameter plus the number of trials and number of trials, number of examples the online algorithm has a very similar form, except these weights might be different.",
                    "label": 0
                },
                {
                    "sent": "You can also.",
                    "label": 0
                },
                {
                    "sent": "Derive this express this in terms of the previous, so this is the previous 1 -- 8 AT plus one times this where this is sort of the gradient of the loss and this has the 1 / T type of behavior.",
                    "label": 0
                },
                {
                    "sent": "You can also see here.",
                    "label": 0
                },
                {
                    "sent": "That this update here.",
                    "label": 0
                },
                {
                    "sent": "Can be written in terms of a link function.",
                    "label": 0
                },
                {
                    "sent": "Remember when we derive things with pregnant divergences always?",
                    "label": 0
                },
                {
                    "sent": "You took a parameter.",
                    "label": 0
                },
                {
                    "sent": "You went to another domain.",
                    "label": 0
                },
                {
                    "sent": "This is not going to be the expiration expectation domain.",
                    "label": 0
                },
                {
                    "sent": "You add in a gradient and you go back, so this update.",
                    "label": 0
                },
                {
                    "sent": "You can write this way.",
                    "label": 0
                },
                {
                    "sent": "And then it's it's similar to what we used before.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The online algorithm has the freedom to choose this initial.",
                    "label": 0
                },
                {
                    "sent": "Trade off parameter which could be different from the initial trade off the trade off parameter of the batch algorithm.",
                    "label": 0
                },
                {
                    "sent": "If the two are the same, then the online algorithm is kind of an incremental offline algorithm.",
                    "label": 0
                },
                {
                    "sent": "But sometimes it's good to make the online parameter the online parameter a little bit bigger.",
                    "label": 0
                },
                {
                    "sent": "K so this could.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Response to.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The following situation.",
                    "label": 0
                },
                {
                    "sent": "If you plug in everything and you do it for Gaussians and so forth, these are the reasonable things.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "The plain offline algorithm would be you want to set this parameter to zero and you just sort of do maximum likelihood.",
                    "label": 0
                },
                {
                    "sent": "You have T examples, you divide by T. The online algorithm at trial T has seen T -- 1 examples.",
                    "label": 0
                },
                {
                    "sent": "But it turns out by setting the these eight parameters.",
                    "label": 0
                },
                {
                    "sent": "A little bit differently.",
                    "label": 0
                },
                {
                    "sent": "A better way to set it is to add here plus one.",
                    "label": 0
                },
                {
                    "sent": "So number of examples plus one.",
                    "label": 0
                },
                {
                    "sent": "It's a, it's like regularising it by adding an initial example at .0.",
                    "label": 0
                },
                {
                    "sent": "We call this the forward algorithm because it estimates it doesn't just.",
                    "label": 0
                },
                {
                    "sent": "Compute the maximum likelihood it estimates it by by putting another point at 0.",
                    "label": 0
                },
                {
                    "sent": "Before it before it.",
                    "label": 0
                },
                {
                    "sent": "Compute its current parameter.",
                    "label": 0
                },
                {
                    "sent": "It guesses that the parameter is actually at 0, and that includes that into the estimate and that gets you a plus one.",
                    "label": 0
                },
                {
                    "sent": "Imagine here plus zero, which doesn't show up.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "Can do the same thing.",
                    "label": 0
                },
                {
                    "sent": "For bernoulli maximum likelihood, again is the average, but.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "A fancier online algorithm would be something like Kasimov.",
                    "label": 0
                },
                {
                    "sent": "Trust him off.",
                    "label": 0
                },
                {
                    "sent": "I don't know.",
                    "label": 0
                },
                {
                    "sent": "It's to Russians.",
                    "label": 0
                },
                {
                    "sent": "Which put a half count here.",
                    "label": 0
                },
                {
                    "sent": "Put an additional example at a half and then divide by the number of examples plus one.",
                    "label": 0
                },
                {
                    "sent": "And that's sort of a regularised version.",
                    "label": 0
                },
                {
                    "sent": "Laplace estimators, another case where you have one here.",
                    "label": 0
                },
                {
                    "sent": "I'm repeating this because.",
                    "label": 0
                },
                {
                    "sent": "Using, but if you do this online algorithms very carefully, you see that these algorithms are not the best possible algorithms that much better ones.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So what's again happening?",
                    "label": 0
                },
                {
                    "sent": "Maximum likelihood is just averaging.",
                    "label": 0
                },
                {
                    "sent": "By setting some kind of initial counts differently, you get the forward algorithm which divides by one more number of examples plus one.",
                    "label": 0
                },
                {
                    "sent": "And here this this dummy example is at 0 and here the W example is at half.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can write very very general theorem for this kind of density estimation.",
                    "label": 0
                },
                {
                    "sent": "General framework.",
                    "label": 0
                },
                {
                    "sent": "Lots of the algorithm.",
                    "label": 0
                },
                {
                    "sent": "This is the regret is at most as big as.",
                    "label": 0
                },
                {
                    "sent": "This.",
                    "label": 0
                },
                {
                    "sent": "Telescoping things that are going to telescope when you sum them up.",
                    "label": 0
                },
                {
                    "sent": "Plus this additional term.",
                    "label": 0
                },
                {
                    "sent": "And this is sort of the cost of the update.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then you can.",
                    "label": 0
                },
                {
                    "sent": "You can sum up and telescope.",
                    "label": 0
                },
                {
                    "sent": "This is the total regret and then here is the initial divergent to the initial diversions to the last one.",
                    "label": 0
                },
                {
                    "sent": "This is not negative and can be dropped, and this is the cost of all of the updates.",
                    "label": 0
                },
                {
                    "sent": "And then you can get bounced by bounding this additional term.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What comes out of this?",
                    "label": 0
                },
                {
                    "sent": "Is pounds of the following type.",
                    "label": 0
                },
                {
                    "sent": "The regret for the Gaussian density estimation is at most as big as this.",
                    "label": 0
                },
                {
                    "sent": "It's the upper bound on the norms of the instances times essentially log T. For Bernoulli it is total regret for arbitrary sequences of examples is at most log T plus log \u03c0 / 2.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "I talked a lot.",
                    "label": 0
                },
                {
                    "sent": "About so I like to work on very simple problems like Gaussian density estimation, linear regression and try to get new algorithms.",
                    "label": 0
                },
                {
                    "sent": "So I talked.",
                    "label": 0
                },
                {
                    "sent": "About",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This trick of shrinking.",
                    "label": 0
                },
                {
                    "sent": "This is the maximum likelihood estimator.",
                    "label": 0
                },
                {
                    "sent": "This is sort of the online maximum likelihood, except there's a little thing you shrink a little bit more.",
                    "label": 0
                },
                {
                    "sent": "You add +10 here.",
                    "label": 0
                },
                {
                    "sent": "You also added additional counts.",
                    "label": 0
                },
                {
                    "sent": "The question I was obsessed with it.",
                    "label": 0
                },
                {
                    "sent": "What is the right shrinkage?",
                    "label": 0
                },
                {
                    "sent": "And why is this shrinkage there at all?",
                    "label": 0
                },
                {
                    "sent": "Turns out it's there.",
                    "label": 0
                },
                {
                    "sent": "In the worst case already, and it's quite an interesting story.",
                    "label": 0
                },
                {
                    "sent": "Little bit much for early in the morning, but.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "These forward albums are all the ones with half the additional shrinkage and the balance come out better that way.",
                    "label": 0
                },
                {
                    "sent": "If you don't do the shrinkage to bounce another's good.",
                    "label": 0
                },
                {
                    "sent": "So this is the balance I got 4.",
                    "label": 0
                },
                {
                    "sent": "Gaussian density estimation.",
                    "label": 0
                },
                {
                    "sent": "This is one for the.",
                    "label": 0
                },
                {
                    "sent": "For the Bernoulli, when you added the additional half and divided by one more example, you can also do this kind of a thing for linear regression.",
                    "label": 0
                },
                {
                    "sent": "Initially done by Valk, then by some other people.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "Normal linear regression has this inverse covariance matrix, but you take the inverse covariance matrix of the examples we have seen so far, so there would be a T -- 1.",
                    "label": 0
                },
                {
                    "sent": "Here is some the outer product over all the examples we have seen already lost T -- 1.",
                    "label": 0
                },
                {
                    "sent": "You regularize with this taken inverse and then you multiply by this and that's your current weight vector.",
                    "label": 0
                },
                {
                    "sent": "Want to Bellagio figured out via some very roundabout way and then we did the proof using Bregman.",
                    "label": 0
                },
                {
                    "sent": "Urgencies in a very sort of concise way in a collapsed way.",
                    "label": 0
                },
                {
                    "sent": "It's a long story.",
                    "label": 0
                },
                {
                    "sent": "Is you if you want to do linear regression good and you want to get good worst case loss pounds before you predict on an instance you should actually use the current instances you predict on and put it in the covariance matrix.",
                    "label": 0
                },
                {
                    "sent": "So at trial T you're going to predict with www.xt.",
                    "label": 0
                },
                {
                    "sent": "But the WT dot XT but UW T has in its government covariance matrix already the current instance.",
                    "label": 0
                },
                {
                    "sent": "So this kind of a nifty algorithm that came out of these are some of the most subtle algorithms that came out of these worst case analysis.",
                    "label": 0
                },
                {
                    "sent": "So this corresponds to adding plus one in Gaussian density estimation, we divided by the number of examples plus one.",
                    "label": 0
                },
                {
                    "sent": "In regression we use all the examples you have seen already in the past plus the current example that corresponds to the plus one.",
                    "label": 0
                },
                {
                    "sent": "In the motivation, it means that you add in your loss total loss, the loss on the past examples, plus the loss on the current example.",
                    "label": 0
                },
                {
                    "sent": "But you assume that its label is 0.",
                    "label": 0
                },
                {
                    "sent": "So this is very subtle shrinkage going on.",
                    "label": 0
                },
                {
                    "sent": "If you want to get good worst case lost pounds and optimize them, you should include the current example into the covariance matrix.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We got pretty subtle algorithms out of this, so and.",
                    "label": 0
                },
                {
                    "sent": "But let me summarize why Bregman divergences, so you know don't need to check whether the underlying exponential distribution.",
                    "label": 1
                },
                {
                    "sent": "Is in the exponential family, but there's an underlying distribution at all.",
                    "label": 0
                },
                {
                    "sent": "It's more general and exponential families.",
                    "label": 0
                },
                {
                    "sent": "We always use two divergences.",
                    "label": 0
                },
                {
                    "sent": "It's sort of fairly elegant because we have a parameter divergance analostan vergence.",
                    "label": 0
                },
                {
                    "sent": "And we used the same one in the motivation of the analysis and.",
                    "label": 0
                },
                {
                    "sent": "As a measure of progress in the analysis, so there's all these multiple users.",
                    "label": 0
                },
                {
                    "sent": "That's why pick Bregman divergences.",
                    "label": 1
                },
                {
                    "sent": "When a dog gets to Infinity, the updates morph into Bregman projections and then you have a general penalized for staggering theorem.",
                    "label": 0
                },
                {
                    "sent": "So you sort of get boosting as a special case.",
                    "label": 0
                },
                {
                    "sent": "K.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now let me take a step back.",
                    "label": 0
                },
                {
                    "sent": "I talked about online learning, deriving updates.",
                    "label": 1
                },
                {
                    "sent": "Using Bregman divergences now, I wanted to sort of a game theoretic point of view.",
                    "label": 0
                },
                {
                    "sent": "The general setup is we had some information from the learner and the relative loss time qualifies the price for hiding that information.",
                    "label": 1
                },
                {
                    "sent": "So far.",
                    "label": 1
                },
                {
                    "sent": "The future examples were hidden and the offline algorithm knows all the examples.",
                    "label": 0
                },
                {
                    "sent": "The online algorithm only knows the past examples.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this sort of leads you to game theoretic type of philosophy.",
                    "label": 0
                },
                {
                    "sent": "So imagine for a moment when Gaussian density estimation right, you have to predict.",
                    "label": 0
                },
                {
                    "sent": "I mean.",
                    "label": 0
                },
                {
                    "sent": "I am the algorithm, so I want to be lost small so I have to predict the mean.",
                    "label": 0
                },
                {
                    "sent": "Nature produces an instance.",
                    "label": 0
                },
                {
                    "sent": "I have to predict the second Queen nature produces an instance, so I have these nested in Supes horizon many times.",
                    "label": 0
                },
                {
                    "sent": "T is my horizon.",
                    "label": 0
                },
                {
                    "sent": "What's the payoff?",
                    "label": 0
                },
                {
                    "sent": "Total loss of my online algorithm minus total loss.",
                    "label": 0
                },
                {
                    "sent": "Of the best offline algorithm I used moves here.",
                    "label": 0
                },
                {
                    "sent": "For means in the case of Gaussians where they use Muszar, Theta is the same because the expectation and the natural parameter is the same.",
                    "label": 0
                },
                {
                    "sent": "Head.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "This is the minimax optimum.",
                    "label": 0
                },
                {
                    "sent": "The best you can do.",
                    "label": 0
                },
                {
                    "sent": "Any soup and soup and soups.",
                    "label": 0
                },
                {
                    "sent": "Total regret.",
                    "label": 0
                },
                {
                    "sent": "Online loss minus best in hindsight loss.",
                    "label": 0
                },
                {
                    "sent": "That's what we want to optimize.",
                    "label": 0
                },
                {
                    "sent": "OK, that's what we try to optimize using this complicated divergent stuff.",
                    "label": 0
                },
                {
                    "sent": "OK, to make sense of this you need to bound the instances.",
                    "label": 0
                },
                {
                    "sent": "Otherwise you can make this gap infinitely big.",
                    "label": 0
                },
                {
                    "sent": "And the minimax algorithms are usually intractable.",
                    "label": 0
                },
                {
                    "sent": "But it turns out for Bernoulli you can do it.",
                    "label": 0
                },
                {
                    "sent": "That's pretty much known, but we also figured out how to do that for Gaussian.",
                    "label": 0
                },
                {
                    "sent": "And then we found out something that is completely.",
                    "label": 0
                },
                {
                    "sent": "It's kind of wild because it gets it.",
                    "label": 0
                },
                {
                    "sent": "There's a shrinkage.",
                    "label": 0
                },
                {
                    "sent": "Factors are quite curious.",
                    "label": 0
                },
                {
                    "sent": "OK, so let me.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "He go back to Gaussian, the fanciest one I got.",
                    "label": 0
                },
                {
                    "sent": "Using divergences was average but plus one right?",
                    "label": 0
                },
                {
                    "sent": "So it's T -- 1 and T -- 1 + 1.",
                    "label": 0
                },
                {
                    "sent": "So this is the fanciest I got got with the Virgin season abound.",
                    "label": 0
                },
                {
                    "sent": "Had this form.",
                    "label": 0
                },
                {
                    "sent": "It turns out the minimax algorithm Gaussian density estimation when the horizon is T at trial T is supposed to predict with the roughly the past average instances.",
                    "label": 1
                },
                {
                    "sent": "But there is an additional.",
                    "label": 1
                },
                {
                    "sent": "A shrinkage factor.",
                    "label": 0
                },
                {
                    "sent": "The shrinkage is 1 plus log T minus log log T. And it's actually recurrence for the shrinkage factors, so this suggests.",
                    "label": 0
                },
                {
                    "sent": "And since it's the optimal algorithm.",
                    "label": 0
                },
                {
                    "sent": "We know it's the right thing.",
                    "label": 0
                },
                {
                    "sent": "So this suggests that the whole approach of this divergent stuff will never get these kind of shrinkage is right.",
                    "label": 0
                },
                {
                    "sent": "So you need to.",
                    "label": 0
                },
                {
                    "sent": "Really go to this minimax thing to get all the shrinkage is perfect.",
                    "label": 0
                },
                {
                    "sent": "And it was quite curious to figure out data recursive formula for the shrinkage.",
                    "label": 0
                },
                {
                    "sent": "And this is only an approximation, but it has this form.",
                    "label": 0
                },
                {
                    "sent": "K and abound also improves much slightly.",
                    "label": 0
                },
                {
                    "sent": "But this minimax algorithm needs to know T to get the shrinkage, right?",
                    "label": 1
                },
                {
                    "sent": "Questions.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So this thing.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's a little bit too complicated, right?",
                    "label": 0
                },
                {
                    "sent": "In soup and soup T many times.",
                    "label": 0
                },
                {
                    "sent": "How do you analyze something like this?",
                    "label": 0
                },
                {
                    "sent": "Can you don't worry, you know you.",
                    "label": 0
                },
                {
                    "sent": "You write down complicated things, you know you take a nap and sometimes things simplify.",
                    "label": 0
                },
                {
                    "sent": "Well, in this case, in general they didn't.",
                    "label": 0
                },
                {
                    "sent": "As far as I know.",
                    "label": 0
                },
                {
                    "sent": "I suppose I can do it, but what you can do is the following.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Simple trick, you always assume that the current trial is the last trial we call this last step, minimax.",
                    "label": 1
                },
                {
                    "sent": "So now the situation is.",
                    "label": 0
                },
                {
                    "sent": "I assume the current trial is the last round, so I have only one inch soup left.",
                    "label": 0
                },
                {
                    "sent": "And the current and the parameter vector I'm going to pick it.",
                    "label": 0
                },
                {
                    "sent": "Is the Ark in soup?",
                    "label": 0
                },
                {
                    "sent": "So what is this total loss so far minus in?",
                    "label": 0
                },
                {
                    "sent": "And the previous ones don't matter, so it simplifies to this.",
                    "label": 0
                },
                {
                    "sent": "So I'm left with this thing and there's a very simple formula for this in so it turns out this thing can be analyzed in many, many contexts.",
                    "label": 0
                },
                {
                    "sent": "And this very simple motivation without divergences, blah blah blah already gets you some of the fanciest algorithms that I got using divergences.",
                    "label": 0
                },
                {
                    "sent": "It got you to forward algorithms for Gaussian and linear regression.",
                    "label": 1
                },
                {
                    "sent": "So after seeing this, I have high respect for this game theoretic stuff.",
                    "label": 0
                },
                {
                    "sent": "OK, so it did the right thing for Gaussian and for linear regression.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's talk about Bernoulli a little bit.",
                    "label": 0
                },
                {
                    "sent": "Now these kind of problems have been studied for, you know 5060 years.",
                    "label": 0
                },
                {
                    "sent": "Turns out if you look at them in the worst case and do this very simple thing.",
                    "label": 0
                },
                {
                    "sent": "Here you get a better algorithm.",
                    "label": 0
                },
                {
                    "sent": "So I just want to give you these kind of little examples that you might.",
                    "label": 0
                },
                {
                    "sent": "Have seen before because.",
                    "label": 0
                },
                {
                    "sent": "They show the subtlety of this analysis.",
                    "label": 0
                },
                {
                    "sent": "Forward algorithm is kind of adjusting the counts and one of them is this throwing off algorithm OK to Russians.",
                    "label": 0
                },
                {
                    "sent": "You put in the half count.",
                    "label": 0
                },
                {
                    "sent": "Laplace would be the one adding the one count here as is the total number of this weekend Bernoulli case.",
                    "label": 0
                },
                {
                    "sent": "So we have coin flips, so this is the total number of flips.",
                    "label": 0
                },
                {
                    "sent": "Zeros is tails, one is heads, total number of ones and then you add a half and you divide by the number of flips plus one.",
                    "label": 0
                },
                {
                    "sent": "This is sort of the best algorithm in this context, it turns out.",
                    "label": 0
                },
                {
                    "sent": "That there is a better if you do the last step in Emacs, it has this form, which is seemingly completely unrelated.",
                    "label": 0
                },
                {
                    "sent": "Or at least not easily related to anything of this type.",
                    "label": 0
                },
                {
                    "sent": "It's certainly not related to maximum likelihood, kind of estimates in the exponential family.",
                    "label": 0
                },
                {
                    "sent": "Not obviously, at least.",
                    "label": 0
                },
                {
                    "sent": "The worst case regret bounds are also log T + 1 + C, But now the constant is slightly improved, so whenever you have an application.",
                    "label": 0
                },
                {
                    "sent": "That uses these counts well, why don't you try this algorithm and see whether it's slightly better?",
                    "label": 0
                },
                {
                    "sent": "So this was again.",
                    "label": 0
                },
                {
                    "sent": "The fancy of this laughs that minimax, and in some cases.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can even analyze this.",
                    "label": 0
                },
                {
                    "sent": "OK. Analyzing this showed that shrinkage is very important.",
                    "label": 0
                },
                {
                    "sent": "Shrinkage was a big thing.",
                    "label": 0
                },
                {
                    "sent": "In the statistics community, when they discovered Stein estimators.",
                    "label": 0
                },
                {
                    "sent": "Stein estimators uses shrinkage for some kind of a problem.",
                    "label": 0
                },
                {
                    "sent": "That is an expected loss type of problem.",
                    "label": 0
                },
                {
                    "sent": "Here we show shrinkage is already necessary in the worst case, so it's kind of a curious thing.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Synopsis game theoretic.",
                    "label": 0
                },
                {
                    "sent": "They have slightly better bounds, but they're harder to prove and harder to deal with divergences.",
                    "label": 0
                },
                {
                    "sent": "Closer to base and standard convex optimization, you have differentiation.",
                    "label": 0
                },
                {
                    "sent": "Usually because we look at differentiable case and.",
                    "label": 0
                },
                {
                    "sent": "It's.",
                    "label": 0
                },
                {
                    "sent": "More commonly used, more accessible for most people and gets you her istics very fast.",
                    "label": 0
                },
                {
                    "sent": "But if you wanted to really do your homework, then you should do this game theoretic stuff.",
                    "label": 0
                },
                {
                    "sent": "Now of course these are worst case bounds, and you could always be in a situation where this kind of worst.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Case thing is too overly pessimistic and then the divergents based stuff might be better.",
                    "label": 0
                },
                {
                    "sent": "OK, but if this is your goal then you should use game theory.",
                    "label": 0
                },
                {
                    "sent": "OK, now.",
                    "label": 0
                },
                {
                    "sent": "Where is my little open problem?",
                    "label": 0
                },
                {
                    "sent": "Actually I have fun making up lots of open problems.",
                    "label": 0
                },
                {
                    "sent": "It's one of my main hobbies so.",
                    "label": 0
                },
                {
                    "sent": "I did this for.",
                    "label": 0
                },
                {
                    "sent": "Gaussian density estimation.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Ended up.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With this funny shrinkage.",
                    "label": 0
                },
                {
                    "sent": "Now for linear regression.",
                    "label": 0
                },
                {
                    "sent": "The last step, mini Max, was his fancy algorithm.",
                    "label": 0
                },
                {
                    "sent": "That added one more count in the Gaussian case and in the linear regression case it added the current instance into the covariance matrix.",
                    "label": 0
                },
                {
                    "sent": "So imagine you're in the following situation where you have a bunch of labeled points and lots of unlabeled points.",
                    "label": 0
                },
                {
                    "sent": "And now you want to.",
                    "label": 0
                },
                {
                    "sent": "Set up one of those minimax problems.",
                    "label": 0
                },
                {
                    "sent": "And compute the minimax for.",
                    "label": 0
                },
                {
                    "sent": "Linear regression and that's the first problem.",
                    "label": 0
                },
                {
                    "sent": "I don't know.",
                    "label": 0
                },
                {
                    "sent": "It somehow would.",
                    "label": 0
                },
                {
                    "sent": "Involves shrinkage.",
                    "label": 0
                },
                {
                    "sent": "In terms of covariance matrices.",
                    "label": 0
                },
                {
                    "sent": "I have guesses as to what the recurrence is, but I don't know how to analyze it yet.",
                    "label": 0
                },
                {
                    "sent": "Basically I need a good student.",
                    "label": 0
                },
                {
                    "sent": "You know that's how you do it.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So this is this part of this.",
                    "label": 0
                },
                {
                    "sent": "Tutorial.",
                    "label": 0
                },
                {
                    "sent": "And what I'm going to do next is.",
                    "label": 0
                },
                {
                    "sent": "Talk a little bit about.",
                    "label": 0
                },
                {
                    "sent": "I talked a lot about online learning which is worst case loss bounds.",
                    "label": 0
                },
                {
                    "sent": "Now I want to talk about the case.",
                    "label": 0
                },
                {
                    "sent": "What happens if you have an online bound but you actually interested in the case when you are instances are examples of generated by distribution.",
                    "label": 0
                },
                {
                    "sent": "Well.",
                    "label": 0
                },
                {
                    "sent": "It turns out there's conversion algorithms.",
                    "label": 0
                },
                {
                    "sent": "I will talk about convergence algorithm set a little bit and then I will talk about applications because.",
                    "label": 0
                },
                {
                    "sent": "Kind of noticing there wasn't too many questions when you do thiery so.",
                    "label": 0
                },
                {
                    "sent": "I reshuffle things and you're going to get new slides where I talk about lots of applications of this online learning.",
                    "label": 0
                },
                {
                    "sent": "That should be fairly accessible.",
                    "label": 0
                },
                {
                    "sent": "For people, well, you get a sense for how you actually use these online algorithms, OK?",
                    "label": 0
                },
                {
                    "sent": "And I'm going to do that mainly in the second lecture today, but for the next 15 minutes I will start with conversions and.",
                    "label": 0
                },
                {
                    "sent": "A little bit of applications and then lots more applications in the second lecture, so let me switch for a moment.",
                    "label": 0
                },
                {
                    "sent": "Online to batch conversions.",
                    "label": 0
                },
                {
                    "sent": "Some simple cases.",
                    "label": 0
                },
                {
                    "sent": "Then I talk about caching, disk, spin, time and many other problems.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So, so we have an algorithm.",
                    "label": 0
                },
                {
                    "sent": "You have a worst case loss bound.",
                    "label": 0
                },
                {
                    "sent": "Now you want an expected loss bound, so you want to have something like that.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is small with high probability tail bound.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "You have some kind of a loss function.",
                    "label": 1
                },
                {
                    "sent": "Right, I'm going to do only sketch this.",
                    "label": 0
                },
                {
                    "sent": "Basically what you want is if you want to get good bounds my my.",
                    "label": 0
                },
                {
                    "sent": "Personal opinion is first try to prove them in the worst case.",
                    "label": 1
                },
                {
                    "sent": "Why?",
                    "label": 0
                },
                {
                    "sent": "Because very often you get the boost, the good the best probabilistic bounds.",
                    "label": 0
                },
                {
                    "sent": "That way it's kind of if you if you take that forward algorithm for linear regression and take one of those conversions and turn it into an expected bound expected regret bound or something like that.",
                    "label": 0
                },
                {
                    "sent": "You beat any kind of probabilistic bandits around.",
                    "label": 0
                },
                {
                    "sent": "Why this is the case, we don't know.",
                    "label": 0
                },
                {
                    "sent": "It's kind of lucky, don't know.",
                    "label": 0
                },
                {
                    "sent": "So you have a worst case lost found and now.",
                    "label": 0
                },
                {
                    "sent": "Imagine that your sequence is generated by a fixed but unknown distribution.",
                    "label": 0
                },
                {
                    "sent": "Right not what I said.",
                    "label": 0
                },
                {
                    "sent": "Talk to set out in this tutorial at all.",
                    "label": 0
                },
                {
                    "sent": "This toilet said well.",
                    "label": 0
                },
                {
                    "sent": "Examples are produced by an adversary.",
                    "label": 0
                },
                {
                    "sent": "Examples are produced by nature of no assumption probabilistic assumptions.",
                    "label": 1
                },
                {
                    "sent": "But now let's go back to the Canonical case that everybody else is looking at.",
                    "label": 0
                },
                {
                    "sent": "Where the instances are actually generated by a fixed distribution that they drawn independently at random IID.",
                    "label": 0
                },
                {
                    "sent": "Well, how do you recover that old case?",
                    "label": 0
                },
                {
                    "sent": "Well, you take your online algorithm, that is, that was proven for the worst case, and you do a general conversion.",
                    "label": 0
                },
                {
                    "sent": "You do some general trick on top of it, and then you immediately have guarantees that hold in the expected case.",
                    "label": 0
                },
                {
                    "sent": "And so I'm going to show you a little.",
                    "label": 0
                },
                {
                    "sent": "Basically, you need to do some averaging.",
                    "label": 0
                },
                {
                    "sent": "OK, the simplest.",
                    "label": 0
                },
                {
                    "sent": "Assume you have the perceptron algorithm.",
                    "label": 0
                },
                {
                    "sent": "You have the perceptron convergence theorem, which bounds the number of mistakes.",
                    "label": 1
                },
                {
                    "sent": "Perception album Now you want to say, well, if the things are generated at random, what's the expected loss expected?",
                    "label": 0
                },
                {
                    "sent": "Number of mistakes of the perceptron algorithm?",
                    "label": 0
                },
                {
                    "sent": "Well, the simplest thing to do is you run the perceptron algorithm over all your data and you take the last hypothesis.",
                    "label": 1
                },
                {
                    "sent": "Turns out that's not the right thing to do.",
                    "label": 0
                },
                {
                    "sent": "You need to do a little bit more.",
                    "label": 0
                },
                {
                    "sent": "Averaging are slightly sophisticated tricks, not too sophisticated.",
                    "label": 0
                },
                {
                    "sent": "So what we want to get is now a bound of the type you get about a sample, and then at the end you want to produce a hypothesis.",
                    "label": 0
                },
                {
                    "sent": "And it's supposed to have small expected loss.",
                    "label": 0
                },
                {
                    "sent": "So now I need to.",
                    "label": 1
                },
                {
                    "sent": "Define instantaneous loss of a hypothesis with respect to distribution.",
                    "label": 0
                },
                {
                    "sent": "It's just the expected loss of this hypothesis on an example drawn according to the same distribution.",
                    "label": 1
                },
                {
                    "sent": "Ceclor so this loss.",
                    "label": 0
                },
                {
                    "sent": "This consists of an instance and a label.",
                    "label": 0
                },
                {
                    "sent": "You predict the instance and then you measure the loss to the label.",
                    "label": 0
                },
                {
                    "sent": "So this is sort of a little bit concise notation.",
                    "label": 0
                },
                {
                    "sent": "But oh.",
                    "label": 0
                },
                {
                    "sent": "Somebody.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Go away.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So how do you get a conversion for the expected loss?",
                    "label": 0
                },
                {
                    "sent": "So you look at the total loss of the algorithm.",
                    "label": 1
                },
                {
                    "sent": "Right, expected to Lausanne, now you observe the following this one.",
                    "label": 1
                },
                {
                    "sent": "Is expand this out is the sum of these losses.",
                    "label": 0
                },
                {
                    "sent": "You take the algorithm on T -- 1 example you get the next, you incur loss and you sum over trials.",
                    "label": 0
                },
                {
                    "sent": "Now the expectation goes inside.",
                    "label": 0
                },
                {
                    "sent": "And this actually becomes the sum of the expectation expected instantaneous losses.",
                    "label": 0
                },
                {
                    "sent": "So, so what's happening is the following when you do.",
                    "label": 0
                },
                {
                    "sent": "When you have your stream of examples, you have T + 1 hypothesis one here, one here, one here, one here, one here, right until all the way to the end and what you want to do is you pick one at random.",
                    "label": 1
                },
                {
                    "sent": "So you pick a hypothesis.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Up the T Plus was about this at random and you predict on the new instance with this hypothesis and the instantaneous loss of this algorithm is the expected loss.",
                    "label": 1
                },
                {
                    "sent": "Expect a total loss of the original algorithm over T + 1 trials.",
                    "label": 1
                },
                {
                    "sent": "And.",
                    "label": 1
                },
                {
                    "sent": "So whenever you have a lost bound that holds in the worst case it's, let's say M, then we're this conversion.",
                    "label": 1
                },
                {
                    "sent": "Will you pick one of those?",
                    "label": 0
                },
                {
                    "sent": "Hypothesis at random immediately you get expected loss of M / T. And.",
                    "label": 0
                },
                {
                    "sent": "Again.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just going to the end and picking the last hypothesis is not good, because if you only have a guarantee on the total loss, you could have algorithms that go along and then curl off of loss at the end, which you don't know.",
                    "label": 0
                },
                {
                    "sent": "You only have a bound on the total loss so but the averaging trick hedges against that.",
                    "label": 0
                },
                {
                    "sent": "Now you could say does this occur for practical algorithm?",
                    "label": 0
                },
                {
                    "sent": "And yes, it occurs for the perceptron algorithm if you.",
                    "label": 0
                },
                {
                    "sent": "Want to convert the perceptron algorithm to A to a loss to an algorithm that that probably works well in the expected case?",
                    "label": 0
                },
                {
                    "sent": "This is actually a good thing to do.",
                    "label": 0
                },
                {
                    "sent": "Sometimes in the perception case, you take multiple.",
                    "label": 0
                },
                {
                    "sent": "Sorry, you take multiple.",
                    "label": 0
                },
                {
                    "sent": "Passes over your data an average.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So this is very close to averaging the hypothesis, of course.",
                    "label": 0
                },
                {
                    "sent": "Case also tailback.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for instance, you have a loss which has this range.",
                    "label": 0
                },
                {
                    "sent": "Again, you look at your T + 1 hypothesis you average.",
                    "label": 0
                },
                {
                    "sent": "They hypothesis.",
                    "label": 0
                },
                {
                    "sent": "And then you can show if the total worst case loss is M, then with probability at least one minus Delta.",
                    "label": 0
                },
                {
                    "sent": "The error of the average hypothesis is.",
                    "label": 0
                },
                {
                    "sent": "This big.",
                    "label": 0
                },
                {
                    "sent": "So this was the expectation.",
                    "label": 0
                },
                {
                    "sent": "Now you're going a little bit further out.",
                    "label": 0
                },
                {
                    "sent": "And you get a tail bound.",
                    "label": 0
                },
                {
                    "sent": "You get the error is small with high probability.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Again, my philosophy is.",
                    "label": 0
                },
                {
                    "sent": "Go ahead.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Do your worst case loss Fund 1st and then convert it.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "What I'm going to talk about next is lots of applications.",
                    "label": 0
                },
                {
                    "sent": "OK, and actually still have quite a few slides to go through.",
                    "label": 0
                },
                {
                    "sent": "But there's not so many formulas this time.",
                    "label": 0
                },
                {
                    "sent": "So whenever you pick up your telephone and you listen to your telephone very carefully.",
                    "label": 0
                },
                {
                    "sent": "It goes like shit.",
                    "label": 0
                },
                {
                    "sent": "So what happens is there's some kind of echo cancellation happening or.",
                    "label": 0
                },
                {
                    "sent": "Adaptive channel equalization where?",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "An online algorithm learns.",
                    "label": 0
                },
                {
                    "sent": "The average signal.",
                    "label": 0
                },
                {
                    "sent": "And then subtracts that average signal.",
                    "label": 0
                },
                {
                    "sent": "From the current signal.",
                    "label": 0
                },
                {
                    "sent": "And the average signal is supposed to be noise.",
                    "label": 0
                },
                {
                    "sent": "Subtracting that off gets rid of the noise and it clears your channel.",
                    "label": 0
                },
                {
                    "sent": "Very old thing.",
                    "label": 0
                },
                {
                    "sent": "People usually do this using.",
                    "label": 0
                },
                {
                    "sent": "The Witcher half algorithm.",
                    "label": 0
                },
                {
                    "sent": "That's where it was invented.",
                    "label": 0
                },
                {
                    "sent": "That's basically what it was invented for.",
                    "label": 0
                },
                {
                    "sent": "I went to Bell Labs and talk to some of the original researchers.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "And the typical algorithm is this algorithm, Woodruff algorithm.",
                    "label": 0
                },
                {
                    "sent": "And fans a slight fancy fications of it.",
                    "label": 0
                },
                {
                    "sent": "In certain settings in certain settings, certain rooms the echoes actually are quite sparse.",
                    "label": 0
                },
                {
                    "sent": "The weight vector has lots of zeros.",
                    "label": 0
                },
                {
                    "sent": "Then it turns out you can use the unnormalized exponential equation algorithm and.",
                    "label": 0
                },
                {
                    "sent": "This guy Mahoney I don't know and Williamson and some other people showed that in this case this other online album that we developed in the online learning community more recently.",
                    "label": 0
                },
                {
                    "sent": "And this the proximation of it actually performs much better than this algorithm.",
                    "label": 0
                },
                {
                    "sent": "The exponential gradient algorithm would be.",
                    "label": 0
                },
                {
                    "sent": "Ice new weight is I sold wait times E to this gradient, but you can approximate this gradient.",
                    "label": 0
                },
                {
                    "sent": "Each of the gradient using this factor.",
                    "label": 0
                },
                {
                    "sent": "This is sometimes called the Chi squared update.",
                    "label": 0
                },
                {
                    "sent": "Why?",
                    "label": 0
                },
                {
                    "sent": "Because in practice very often you want to be very fast, so exponentials are too hard to compute already.",
                    "label": 0
                },
                {
                    "sent": "Hey so.",
                    "label": 0
                },
                {
                    "sent": "Then I will talk.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Art cashin so, in caching occurs all over the place.",
                    "label": 0
                },
                {
                    "sent": "It occurs whenever you have a small fast memory.",
                    "label": 1
                },
                {
                    "sent": "And a much larger, slower secondary memory.",
                    "label": 1
                },
                {
                    "sent": "So the idea is you keep.",
                    "label": 1
                },
                {
                    "sent": "In the fast memory objects there likely to be.",
                    "label": 1
                },
                {
                    "sent": "Need it soon you have a hit.",
                    "label": 0
                },
                {
                    "sent": "If the next object resides in the cache in the miss otherwise.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Basically, I'm going to learn a good caching strategy and adapt to the particular data looked at.",
                    "label": 1
                },
                {
                    "sent": "Request sequence might change overtime, right?",
                    "label": 0
                },
                {
                    "sent": "Certain people might favor certain things you might want to change.",
                    "label": 0
                },
                {
                    "sent": "The user might change, and so forth, right?",
                    "label": 0
                },
                {
                    "sent": "Or the time of the day, dependencies all kinds of dependencies.",
                    "label": 0
                },
                {
                    "sent": "They are.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some fancy well known caching strategies.",
                    "label": 0
                },
                {
                    "sent": "Forecasting policy's seven most common policies might be least recently used random, first, in first out, last, first, last in first out.",
                    "label": 0
                },
                {
                    "sent": "These already fancy strategies.",
                    "label": 0
                },
                {
                    "sent": "Oh, which I don't know the acronyms for and then these are composite strategies.",
                    "label": 0
                },
                {
                    "sent": "So of course I'm not a caching special specialist, I'm just.",
                    "label": 0
                },
                {
                    "sent": "Taking things.",
                    "label": 0
                },
                {
                    "sent": "Throwing an online algorithm on top and I'm going to show you I'm going to do much better.",
                    "label": 0
                },
                {
                    "sent": "I'm going to beat the hell out of any of these individual strategies because I'm going to adapt online, right?",
                    "label": 0
                },
                {
                    "sent": "You got the game.",
                    "label": 0
                },
                {
                    "sent": "All of these strategies use sort of recency, frequency of access, size of objects, Costa fetching from secondary member.",
                    "label": 0
                },
                {
                    "sent": "The defector standard is least recently used.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Which policy do choose?",
                    "label": 0
                },
                {
                    "sent": "Well, first of all situation dependency.",
                    "label": 0
                },
                {
                    "sent": "Disk access, web web browser kind of thing, file server kind of applications, different time of the day.",
                    "label": 1
                },
                {
                    "sent": "It's application as well as time dependent as well as user dependent.",
                    "label": 1
                },
                {
                    "sent": "Choosing one is ridiculous.",
                    "label": 0
                },
                {
                    "sent": "Of course all of these algorithms already at particular fancy one they claim to be attractive, so the term adaptive is everywhere.",
                    "label": 0
                },
                {
                    "sent": "So our first most difficult task was.",
                    "label": 0
                },
                {
                    "sent": "To come up with a good comparator.",
                    "label": 0
                },
                {
                    "sent": "And I'm going to explain that to you in a moment.",
                    "label": 0
                },
                {
                    "sent": "We had a lot of fun.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is what it looks like.",
                    "label": 0
                },
                {
                    "sent": "Here's a a stream of requests and we have some kind of we get data from some large simulators right operating system, but they're very good at writing simulators.",
                    "label": 0
                },
                {
                    "sent": "And then I looked at a window of 300 and I looked at the miss rate.",
                    "label": 0
                },
                {
                    "sent": "A window of 300 and I wrote down the miss rate and then followed how the mystery changes overtime.",
                    "label": 0
                },
                {
                    "sent": "Least recently used, there's a different colors for the different strategies are 12 different strategies.",
                    "label": 0
                },
                {
                    "sent": "You can see sort of that.",
                    "label": 0
                },
                {
                    "sent": "It's data that kind of moves around a lot.",
                    "label": 0
                },
                {
                    "sent": "The Miss rates move around a lot, and different strategies are on the top.",
                    "label": 0
                },
                {
                    "sent": "And intuitively, we want to design an algorithm that's at least as good as the best one.",
                    "label": 0
                },
                {
                    "sent": "As the minute as it is, the minimum miss rate of this right, the best of these.",
                    "label": 0
                },
                {
                    "sent": "We want to hug this curve from below.",
                    "label": 0
                },
                {
                    "sent": "Turns out that's fairly easy.",
                    "label": 0
                },
                {
                    "sent": "We can do much better.",
                    "label": 0
                },
                {
                    "sent": "K now if you have an online problem, there's a very simple way to test.",
                    "label": 0
                },
                {
                    "sent": "How much online Ness you have?",
                    "label": 0
                },
                {
                    "sent": "What you do is you take your data and permute it.",
                    "label": 0
                },
                {
                    "sent": "Run the algorithm again and see whether or run your tests again and see whether something is worse.",
                    "label": 0
                },
                {
                    "sent": "If you do this in this case.",
                    "label": 0
                },
                {
                    "sent": "Look",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Like this?",
                    "label": 0
                },
                {
                    "sent": "So there's one guy that is always best.",
                    "label": 0
                },
                {
                    "sent": "Which is some kind of some kind of a frequency based thing.",
                    "label": 0
                },
                {
                    "sent": "But the miss rates in general shift up are actually the best one is down here 0.2.",
                    "label": 0
                },
                {
                    "sent": "Which is sort of this kind of thing OK?",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "At the overall miss rates.",
                    "label": 0
                },
                {
                    "sent": "Bam, bam.",
                    "label": 0
                },
                {
                    "sent": "Here work very close to 0.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The minimum ones average maybe about 0.1 now.",
                    "label": 0
                },
                {
                    "sent": "After permuting the data.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I made my day to worse.",
                    "label": 0
                },
                {
                    "sent": "I took the online Ness away.",
                    "label": 0
                },
                {
                    "sent": "Right, and of course.",
                    "label": 0
                },
                {
                    "sent": "Here I can't do anything with online.",
                    "label": 0
                },
                {
                    "sent": "But because I made it IID data when I've IID data, there's a fixed one that is best.",
                    "label": 0
                },
                {
                    "sent": "I cannot adapt.",
                    "label": 0
                },
                {
                    "sent": "What I have seen before doesn't influence in any way what depends on the future where it's here, I still have the online Ness.",
                    "label": 0
                },
                {
                    "sent": "OK, so I want to explore the difference between these two curves you see.",
                    "label": 0
                },
                {
                    "sent": "With more online algorithms and it turns out.",
                    "label": 0
                },
                {
                    "sent": "You can do that.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And I will do that in the second lecture.",
                    "label": 0
                },
                {
                    "sent": "OK. And give you other applications break time.",
                    "label": 0
                },
                {
                    "sent": "Extra online learning loss tutorial lecture.",
                    "label": 0
                },
                {
                    "sent": "And then there's going to be some research talks one this afternoon and PCA.",
                    "label": 0
                },
                {
                    "sent": "Where I generalize the exponential gradient algorithm to a matrix exponential integration algorithm.",
                    "label": 0
                },
                {
                    "sent": "Quite interesting, very recent research and then I. I have another talk tomorrow or generalized Bayes rule to a basal for positive density density to basically for density matrices.",
                    "label": 0
                },
                {
                    "sent": "It's actually related to.",
                    "label": 0
                },
                {
                    "sent": "Quantum physics anyway.",
                    "label": 0
                }
            ]
        }
    }
}