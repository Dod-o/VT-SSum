{
    "id": "xtjvcsvze4ndyd42j5fgfwssg3lhnrrx",
    "title": "Keep it simple!",
    "info": {
        "author": [
            "Olivier Nicol, SequeL, INRIA Lille - Nord Europe"
        ],
        "published": "July 25, 2011",
        "recorded": "July 2011",
        "category": [
            "Top->Computer Science->Machine Learning->Active Learning->Exploration vs. Exploitation"
        ]
    },
    "url": "http://videolectures.net/explorationexploitation2011_nicol_contributed/",
    "segmentation": [
        [
            "I would say and I'm going to present the best approach we came up with and who won the challenge."
        ],
        [
            "So if you were here this this morning, you must recognize this.",
            "It's Microsoft had predictor, so the ID is quite simple.",
            "You have a list of feature and for each different value or different possible value of each feature.",
            "Women gain weight, which is a aggression.",
            "So it's a way to keep an insurgency of the other.",
            "Wait?",
            "When we have to make a prediction so when we are given a visitor and an option."
        ],
        [
            "We set up the corresponding wait.",
            "We get another Goshen an we used we used.",
            "There is a.",
            "Exploration process.",
            "Which is just sampling according to the Goshen instead of just taking them in."
        ],
        [
            "There is an equation to get.",
            "Peak probability prediction, but we didn't use it.",
            "We just compare the discourse."
        ],
        [
            "So a little bit more, but the update equations.",
            "So when we get an outcome, what do we do?",
            "So let Y be the B1 if there is a clique minus one otherwise.",
            "The predicted score, so is a Goshen with mean and standard deviation.",
            "Sigma adjacent NT is Big Sigma square.",
            "Which is the same between Beta Square to parameter and Sigma Square.",
            "So the violence of the predicted score.",
            "Um, gamma is the correctness of our prediction.",
            "So it's the mean of the prediction.",
            "So if we were expecting if we expect to click, the mean is supposed to be positive and if we do not expect click, it's negative.",
            "So we multiply by Y.",
            "So it means that if it's positive we were right, if it's negative or wrong and we divide by the uncertainty meaning like if we were wrong but very uncertain, but the results were basically not so wrong.",
            "So the update equation for the mean.",
            "So at each time step we update the mean of each active.",
            "Values for each active wait so it's negative a date.",
            "If you were right, but when if there was a click.",
            "We add something is there was not click.",
            "We remove something so this something is.",
            "Computing as follows.",
            "So V is like a surprise function.",
            "It takes parameter, the correctness and the more we are correct, the less we is.",
            "So basically represent the surprise.",
            "Does it also depends on the uncertainties?",
            "So the more we were uncertain.",
            "About this particular weight tomorrow it is dated.",
            "And also depends on the insurgency or the total prediction.",
            "So the more we were uncertain.",
            "About the total prediction.",
            "Do less.",
            "We will update.",
            "So the small thing actually is we.",
            "We meaning that if we ever which weight low weight, negative weight.",
            "But he is in.",
            "Among a lot of weights which are strong, so the prediction is positive.",
            "It wants to transform the negative effects of data lots and the negative weight because.",
            "It was just a.",
            "Which feature among a lot of strong feature?",
            "So I think this is what is very smart but so great equation."
        ],
        [
            "So our first attempt so random in the first phase.",
            "Was doing something like that.",
            "And the first thing we did so, as you have noticed, we need categorical categorical features in the model.",
            "And there were twenty of 'em in the data set, so we use them.",
            "I wish we were doing recommendation.",
            "We did the Cartesian product with the option.",
            "So we had 20 features.",
            "And 1st result was quite promising."
        ],
        [
            "So then what about the continuous feature so far?",
            "90% of the.",
            "Of the features continuous features, so there are hundreds of them.",
            "We use this discretization and we just choose that looking at the.",
            "I the 59th of the day, they said that we were given.",
            "Oh, nothing, nothing smart.",
            "And then the results by cruise by doing the Cartesian product between all the features with the option, the results were less was not as good as just only with the category features.",
            "And by doing by taking the continuous features alone and taking the Cartesian product of before.",
            "In addition, we got after a few parameter optimization, almost 2000 and.",
            "With when we got rid entirely of the option, so just taking the features of the data set without any any changes.",
            "The results were bad."
        ],
        [
            "So we tried a few things, but the dynamics.",
            "The of the system.",
            "So in Microsoft Paper but.",
            "I predicted there is a mechanism.",
            "Which.",
            "Is another update.",
            "So at each time step they.",
            "Update each weight not only exceed one, but all of them and make the.",
            "The Goshen turned toward the day prior.",
            "Who just await forgets?",
            "Well, it didn't work actually.",
            "Is there is a partner who scales the.",
            "Forgetting.",
            "When the forgetting was equal to zero, it was the best performance.",
            "And we also came up with something else, which was.",
            "I hope it's clear actually we.",
            "We used model with lifetimes.",
            "So.",
            "Actually, at each time, at each moment there was two models that were updated.",
            "The blue one was the one we use and he was one was just trained for later.",
            "But we tried a lot of things.",
            "We tried to give a new model some prior information with the features were not very well not evolving through time and so to give them a lot of certainty and the other one less certainty.",
            "They were more moving more but didn't work."
        ],
        [
            "Then at this point.",
            "While this slide is blank on purpose because.",
            "We are no more ideal stuck up to sudden I almost tried.",
            "I tried different approaches but I almost completely Stover story this one.",
            "And the so I was just trying to.",
            "Just like that.",
            "I tried to completely shut down the exploration so again blank slide."
        ],
        [
            "And we got this.",
            "And that's basically what we submitted for the first phase.",
            "Answer About the future.",
            "Remember that we had the categorical features that were crossed with the option and choose all that went and our idea was that the categorical features.",
            "Where?",
            "The preferences of the user.",
            "And the other one was later general behavior.",
            "We were quite OK, we've decided."
        ],
        [
            "But then so this is even before phase two that I tried to do some experiments and I tried to remove the option again as before.",
            "This time we got this result.",
            "Which is better than when we were crossing the option with the feature so.",
            "They are actually in the model that was just the feature that were given in the datasets.",
            "No processing at all before.",
            "Though.",
            "OK, maybe.",
            "Teacher concerns there was a bug in your code or Miss Miss at Palmetto.",
            "Isn't the problem with you when you submit something and were completely blind.",
            "Don't know blind, you know that and you wouldn't have girl just as a number.",
            "So we got the one guy."
        ],
        [
            "Yeah.",
            "So does that mean that they absolutely no cross effects in the with that, for example, we can provide someone who is more likely to buy car than someone else and use that information.",
            "Well, that's not true.",
            "There were a lot of crossed effects we managed to identify him.",
            "We tried to use them, but.",
            "Well, this didn't work.",
            "We only we even try to identify them online.",
            "And the reason why it didn't work."
        ],
        [
            "Paul is so I try to picture the the reason so when we try to exploit the.",
            "Cross effect.",
            "So in green we.",
            "So let's imagine that for the click probability of.",
            "User and the option.",
            "There is a contribution which is given by the general behavior of the user and another one which is given by the matching between that and in green we have the general behavior and is red.",
            "We add the.",
            "The matching, so it's a lot less.",
            "And The thing is that with the user behavior it's very.",
            "We found that it was very easy to identify it and it was so generally is not.",
            "Evolving through time or very slowly.",
            "Even for example, for the 2nd and the 3rd the.",
            "The machine can make a difference in the click probability, but it's harder to find the right contribution.",
            "And it takes a lot more.",
            "It's like it takes a lot of features.",
            "So the model gets more unstable and we have more difficulties to identify the degree in contribution, so the performances are not as good."
        ],
        [
            "I'm another thing to give you an idea of why.",
            "The user selection works so well on this challenge is that for example, 1/4 of the continuous features were like that, so between zero and one.",
            "Almost all the clicks were there.",
            "So it's easy to see to see that.",
            "There is no need to cross with optional trying to crossing reaction is just going to slow the learning."
        ],
        [
            "Let's keep that."
        ],
        [
            "So to sum up, the challenge was a bit about three things.",
            "The exploration which basically we didn't do.",
            "The We tried that.",
            "The best policy is not to withdraw recommendation, which we didn't do because we did basically user selection.",
            "An adaptation and we.",
            "Didn't find any dynamics.",
            "We found them, but using them was decreasing."
        ],
        [
            "The performance."
        ],
        [
            "So this challenge made it to.",
            "Well, to conclude, this challenge made it think about the evaluation techniques which we mentioned earlier.",
            "So the most obvious one is to use the fraction fraction of the audience.",
            "But my personal web pages, but it's going to be difficult with it.",
            "There is another evaluation technique.",
            "Which is time acceleration.",
            "So we also mentioned it.",
            "It's like when you.",
            "Have a user you try to find the best option and if the line you are studying is not the option that the algorithm choose, which is you go down the database.",
            "Try to find another line, but well, a lot of users only shows up once or twice and you on your website so.",
            "Also difficult to do that.",
            "But we found maybe an evaluation technique which could.",
            "It would not be perfect, but maybe better would be to only take into database the.",
            "The lines where there is a click.",
            "And try to.",
            "When you are given the user to classify it.",
            "I'm basically to choose the the option that really is into the database.",
            "I don't know if it's clear."
        ],
        [
            "Um?",
            "We we felt about.",
            "Proof saying that so I won't go through what's written here.",
            "You just the idea is that the function which is mapping the user to the option in our classification problem.",
            "The optimal function would be the same in the classic recommendation problem if.",
            "The.",
            "If the data we used is taken uniformly.",
            "As it is and he does it."
        ],
        [
            "Though, thank you.",
            "Well, I think soon."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I would say and I'm going to present the best approach we came up with and who won the challenge.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if you were here this this morning, you must recognize this.",
                    "label": 0
                },
                {
                    "sent": "It's Microsoft had predictor, so the ID is quite simple.",
                    "label": 0
                },
                {
                    "sent": "You have a list of feature and for each different value or different possible value of each feature.",
                    "label": 0
                },
                {
                    "sent": "Women gain weight, which is a aggression.",
                    "label": 0
                },
                {
                    "sent": "So it's a way to keep an insurgency of the other.",
                    "label": 0
                },
                {
                    "sent": "Wait?",
                    "label": 0
                },
                {
                    "sent": "When we have to make a prediction so when we are given a visitor and an option.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We set up the corresponding wait.",
                    "label": 0
                },
                {
                    "sent": "We get another Goshen an we used we used.",
                    "label": 0
                },
                {
                    "sent": "There is a.",
                    "label": 0
                },
                {
                    "sent": "Exploration process.",
                    "label": 0
                },
                {
                    "sent": "Which is just sampling according to the Goshen instead of just taking them in.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There is an equation to get.",
                    "label": 0
                },
                {
                    "sent": "Peak probability prediction, but we didn't use it.",
                    "label": 0
                },
                {
                    "sent": "We just compare the discourse.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So a little bit more, but the update equations.",
                    "label": 1
                },
                {
                    "sent": "So when we get an outcome, what do we do?",
                    "label": 0
                },
                {
                    "sent": "So let Y be the B1 if there is a clique minus one otherwise.",
                    "label": 1
                },
                {
                    "sent": "The predicted score, so is a Goshen with mean and standard deviation.",
                    "label": 0
                },
                {
                    "sent": "Sigma adjacent NT is Big Sigma square.",
                    "label": 0
                },
                {
                    "sent": "Which is the same between Beta Square to parameter and Sigma Square.",
                    "label": 1
                },
                {
                    "sent": "So the violence of the predicted score.",
                    "label": 0
                },
                {
                    "sent": "Um, gamma is the correctness of our prediction.",
                    "label": 0
                },
                {
                    "sent": "So it's the mean of the prediction.",
                    "label": 0
                },
                {
                    "sent": "So if we were expecting if we expect to click, the mean is supposed to be positive and if we do not expect click, it's negative.",
                    "label": 0
                },
                {
                    "sent": "So we multiply by Y.",
                    "label": 0
                },
                {
                    "sent": "So it means that if it's positive we were right, if it's negative or wrong and we divide by the uncertainty meaning like if we were wrong but very uncertain, but the results were basically not so wrong.",
                    "label": 0
                },
                {
                    "sent": "So the update equation for the mean.",
                    "label": 1
                },
                {
                    "sent": "So at each time step we update the mean of each active.",
                    "label": 0
                },
                {
                    "sent": "Values for each active wait so it's negative a date.",
                    "label": 0
                },
                {
                    "sent": "If you were right, but when if there was a click.",
                    "label": 0
                },
                {
                    "sent": "We add something is there was not click.",
                    "label": 0
                },
                {
                    "sent": "We remove something so this something is.",
                    "label": 0
                },
                {
                    "sent": "Computing as follows.",
                    "label": 0
                },
                {
                    "sent": "So V is like a surprise function.",
                    "label": 0
                },
                {
                    "sent": "It takes parameter, the correctness and the more we are correct, the less we is.",
                    "label": 0
                },
                {
                    "sent": "So basically represent the surprise.",
                    "label": 0
                },
                {
                    "sent": "Does it also depends on the uncertainties?",
                    "label": 0
                },
                {
                    "sent": "So the more we were uncertain.",
                    "label": 0
                },
                {
                    "sent": "About this particular weight tomorrow it is dated.",
                    "label": 0
                },
                {
                    "sent": "And also depends on the insurgency or the total prediction.",
                    "label": 0
                },
                {
                    "sent": "So the more we were uncertain.",
                    "label": 0
                },
                {
                    "sent": "About the total prediction.",
                    "label": 0
                },
                {
                    "sent": "Do less.",
                    "label": 0
                },
                {
                    "sent": "We will update.",
                    "label": 0
                },
                {
                    "sent": "So the small thing actually is we.",
                    "label": 0
                },
                {
                    "sent": "We meaning that if we ever which weight low weight, negative weight.",
                    "label": 0
                },
                {
                    "sent": "But he is in.",
                    "label": 0
                },
                {
                    "sent": "Among a lot of weights which are strong, so the prediction is positive.",
                    "label": 0
                },
                {
                    "sent": "It wants to transform the negative effects of data lots and the negative weight because.",
                    "label": 0
                },
                {
                    "sent": "It was just a.",
                    "label": 0
                },
                {
                    "sent": "Which feature among a lot of strong feature?",
                    "label": 0
                },
                {
                    "sent": "So I think this is what is very smart but so great equation.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So our first attempt so random in the first phase.",
                    "label": 0
                },
                {
                    "sent": "Was doing something like that.",
                    "label": 0
                },
                {
                    "sent": "And the first thing we did so, as you have noticed, we need categorical categorical features in the model.",
                    "label": 0
                },
                {
                    "sent": "And there were twenty of 'em in the data set, so we use them.",
                    "label": 0
                },
                {
                    "sent": "I wish we were doing recommendation.",
                    "label": 0
                },
                {
                    "sent": "We did the Cartesian product with the option.",
                    "label": 0
                },
                {
                    "sent": "So we had 20 features.",
                    "label": 0
                },
                {
                    "sent": "And 1st result was quite promising.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So then what about the continuous feature so far?",
                    "label": 1
                },
                {
                    "sent": "90% of the.",
                    "label": 0
                },
                {
                    "sent": "Of the features continuous features, so there are hundreds of them.",
                    "label": 0
                },
                {
                    "sent": "We use this discretization and we just choose that looking at the.",
                    "label": 0
                },
                {
                    "sent": "I the 59th of the day, they said that we were given.",
                    "label": 0
                },
                {
                    "sent": "Oh, nothing, nothing smart.",
                    "label": 0
                },
                {
                    "sent": "And then the results by cruise by doing the Cartesian product between all the features with the option, the results were less was not as good as just only with the category features.",
                    "label": 0
                },
                {
                    "sent": "And by doing by taking the continuous features alone and taking the Cartesian product of before.",
                    "label": 0
                },
                {
                    "sent": "In addition, we got after a few parameter optimization, almost 2000 and.",
                    "label": 0
                },
                {
                    "sent": "With when we got rid entirely of the option, so just taking the features of the data set without any any changes.",
                    "label": 0
                },
                {
                    "sent": "The results were bad.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we tried a few things, but the dynamics.",
                    "label": 0
                },
                {
                    "sent": "The of the system.",
                    "label": 0
                },
                {
                    "sent": "So in Microsoft Paper but.",
                    "label": 0
                },
                {
                    "sent": "I predicted there is a mechanism.",
                    "label": 0
                },
                {
                    "sent": "Which.",
                    "label": 0
                },
                {
                    "sent": "Is another update.",
                    "label": 0
                },
                {
                    "sent": "So at each time step they.",
                    "label": 0
                },
                {
                    "sent": "Update each weight not only exceed one, but all of them and make the.",
                    "label": 0
                },
                {
                    "sent": "The Goshen turned toward the day prior.",
                    "label": 0
                },
                {
                    "sent": "Who just await forgets?",
                    "label": 0
                },
                {
                    "sent": "Well, it didn't work actually.",
                    "label": 0
                },
                {
                    "sent": "Is there is a partner who scales the.",
                    "label": 0
                },
                {
                    "sent": "Forgetting.",
                    "label": 0
                },
                {
                    "sent": "When the forgetting was equal to zero, it was the best performance.",
                    "label": 0
                },
                {
                    "sent": "And we also came up with something else, which was.",
                    "label": 0
                },
                {
                    "sent": "I hope it's clear actually we.",
                    "label": 0
                },
                {
                    "sent": "We used model with lifetimes.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Actually, at each time, at each moment there was two models that were updated.",
                    "label": 0
                },
                {
                    "sent": "The blue one was the one we use and he was one was just trained for later.",
                    "label": 0
                },
                {
                    "sent": "But we tried a lot of things.",
                    "label": 0
                },
                {
                    "sent": "We tried to give a new model some prior information with the features were not very well not evolving through time and so to give them a lot of certainty and the other one less certainty.",
                    "label": 0
                },
                {
                    "sent": "They were more moving more but didn't work.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then at this point.",
                    "label": 0
                },
                {
                    "sent": "While this slide is blank on purpose because.",
                    "label": 0
                },
                {
                    "sent": "We are no more ideal stuck up to sudden I almost tried.",
                    "label": 0
                },
                {
                    "sent": "I tried different approaches but I almost completely Stover story this one.",
                    "label": 0
                },
                {
                    "sent": "And the so I was just trying to.",
                    "label": 0
                },
                {
                    "sent": "Just like that.",
                    "label": 0
                },
                {
                    "sent": "I tried to completely shut down the exploration so again blank slide.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we got this.",
                    "label": 0
                },
                {
                    "sent": "And that's basically what we submitted for the first phase.",
                    "label": 0
                },
                {
                    "sent": "Answer About the future.",
                    "label": 0
                },
                {
                    "sent": "Remember that we had the categorical features that were crossed with the option and choose all that went and our idea was that the categorical features.",
                    "label": 0
                },
                {
                    "sent": "Where?",
                    "label": 0
                },
                {
                    "sent": "The preferences of the user.",
                    "label": 0
                },
                {
                    "sent": "And the other one was later general behavior.",
                    "label": 0
                },
                {
                    "sent": "We were quite OK, we've decided.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But then so this is even before phase two that I tried to do some experiments and I tried to remove the option again as before.",
                    "label": 0
                },
                {
                    "sent": "This time we got this result.",
                    "label": 0
                },
                {
                    "sent": "Which is better than when we were crossing the option with the feature so.",
                    "label": 0
                },
                {
                    "sent": "They are actually in the model that was just the feature that were given in the datasets.",
                    "label": 0
                },
                {
                    "sent": "No processing at all before.",
                    "label": 0
                },
                {
                    "sent": "Though.",
                    "label": 0
                },
                {
                    "sent": "OK, maybe.",
                    "label": 0
                },
                {
                    "sent": "Teacher concerns there was a bug in your code or Miss Miss at Palmetto.",
                    "label": 0
                },
                {
                    "sent": "Isn't the problem with you when you submit something and were completely blind.",
                    "label": 0
                },
                {
                    "sent": "Don't know blind, you know that and you wouldn't have girl just as a number.",
                    "label": 0
                },
                {
                    "sent": "So we got the one guy.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "So does that mean that they absolutely no cross effects in the with that, for example, we can provide someone who is more likely to buy car than someone else and use that information.",
                    "label": 0
                },
                {
                    "sent": "Well, that's not true.",
                    "label": 0
                },
                {
                    "sent": "There were a lot of crossed effects we managed to identify him.",
                    "label": 0
                },
                {
                    "sent": "We tried to use them, but.",
                    "label": 0
                },
                {
                    "sent": "Well, this didn't work.",
                    "label": 0
                },
                {
                    "sent": "We only we even try to identify them online.",
                    "label": 0
                },
                {
                    "sent": "And the reason why it didn't work.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Paul is so I try to picture the the reason so when we try to exploit the.",
                    "label": 0
                },
                {
                    "sent": "Cross effect.",
                    "label": 0
                },
                {
                    "sent": "So in green we.",
                    "label": 0
                },
                {
                    "sent": "So let's imagine that for the click probability of.",
                    "label": 0
                },
                {
                    "sent": "User and the option.",
                    "label": 0
                },
                {
                    "sent": "There is a contribution which is given by the general behavior of the user and another one which is given by the matching between that and in green we have the general behavior and is red.",
                    "label": 0
                },
                {
                    "sent": "We add the.",
                    "label": 0
                },
                {
                    "sent": "The matching, so it's a lot less.",
                    "label": 0
                },
                {
                    "sent": "And The thing is that with the user behavior it's very.",
                    "label": 0
                },
                {
                    "sent": "We found that it was very easy to identify it and it was so generally is not.",
                    "label": 0
                },
                {
                    "sent": "Evolving through time or very slowly.",
                    "label": 0
                },
                {
                    "sent": "Even for example, for the 2nd and the 3rd the.",
                    "label": 0
                },
                {
                    "sent": "The machine can make a difference in the click probability, but it's harder to find the right contribution.",
                    "label": 0
                },
                {
                    "sent": "And it takes a lot more.",
                    "label": 0
                },
                {
                    "sent": "It's like it takes a lot of features.",
                    "label": 0
                },
                {
                    "sent": "So the model gets more unstable and we have more difficulties to identify the degree in contribution, so the performances are not as good.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm another thing to give you an idea of why.",
                    "label": 0
                },
                {
                    "sent": "The user selection works so well on this challenge is that for example, 1/4 of the continuous features were like that, so between zero and one.",
                    "label": 0
                },
                {
                    "sent": "Almost all the clicks were there.",
                    "label": 0
                },
                {
                    "sent": "So it's easy to see to see that.",
                    "label": 0
                },
                {
                    "sent": "There is no need to cross with optional trying to crossing reaction is just going to slow the learning.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's keep that.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So to sum up, the challenge was a bit about three things.",
                    "label": 0
                },
                {
                    "sent": "The exploration which basically we didn't do.",
                    "label": 0
                },
                {
                    "sent": "The We tried that.",
                    "label": 0
                },
                {
                    "sent": "The best policy is not to withdraw recommendation, which we didn't do because we did basically user selection.",
                    "label": 0
                },
                {
                    "sent": "An adaptation and we.",
                    "label": 0
                },
                {
                    "sent": "Didn't find any dynamics.",
                    "label": 0
                },
                {
                    "sent": "We found them, but using them was decreasing.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The performance.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this challenge made it to.",
                    "label": 0
                },
                {
                    "sent": "Well, to conclude, this challenge made it think about the evaluation techniques which we mentioned earlier.",
                    "label": 0
                },
                {
                    "sent": "So the most obvious one is to use the fraction fraction of the audience.",
                    "label": 1
                },
                {
                    "sent": "But my personal web pages, but it's going to be difficult with it.",
                    "label": 0
                },
                {
                    "sent": "There is another evaluation technique.",
                    "label": 0
                },
                {
                    "sent": "Which is time acceleration.",
                    "label": 0
                },
                {
                    "sent": "So we also mentioned it.",
                    "label": 0
                },
                {
                    "sent": "It's like when you.",
                    "label": 0
                },
                {
                    "sent": "Have a user you try to find the best option and if the line you are studying is not the option that the algorithm choose, which is you go down the database.",
                    "label": 0
                },
                {
                    "sent": "Try to find another line, but well, a lot of users only shows up once or twice and you on your website so.",
                    "label": 0
                },
                {
                    "sent": "Also difficult to do that.",
                    "label": 0
                },
                {
                    "sent": "But we found maybe an evaluation technique which could.",
                    "label": 0
                },
                {
                    "sent": "It would not be perfect, but maybe better would be to only take into database the.",
                    "label": 0
                },
                {
                    "sent": "The lines where there is a click.",
                    "label": 0
                },
                {
                    "sent": "And try to.",
                    "label": 0
                },
                {
                    "sent": "When you are given the user to classify it.",
                    "label": 0
                },
                {
                    "sent": "I'm basically to choose the the option that really is into the database.",
                    "label": 0
                },
                {
                    "sent": "I don't know if it's clear.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "We we felt about.",
                    "label": 0
                },
                {
                    "sent": "Proof saying that so I won't go through what's written here.",
                    "label": 0
                },
                {
                    "sent": "You just the idea is that the function which is mapping the user to the option in our classification problem.",
                    "label": 0
                },
                {
                    "sent": "The optimal function would be the same in the classic recommendation problem if.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "If the data we used is taken uniformly.",
                    "label": 0
                },
                {
                    "sent": "As it is and he does it.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Though, thank you.",
                    "label": 0
                },
                {
                    "sent": "Well, I think soon.",
                    "label": 0
                }
            ]
        }
    }
}