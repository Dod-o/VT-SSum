{
    "id": "7ufxgq6fqmqculfuzqwincoodxmzjx2l",
    "title": "Learning Concept Importance Using a Weighted Dependence Model",
    "info": {
        "author": [
            "Michael Bendersky, Google, Inc."
        ],
        "published": "Feb. 22, 2010",
        "recorded": "February 2010",
        "category": [
            "Top->Computer Science->Web Search"
        ]
    },
    "url": "http://videolectures.net/wsdm2010_bendersky_lci/",
    "segmentation": [
        [
            "Hello everyone, my name is Michael.",
            "I'm from University, Massachusetts Amherst and this is joint work with Donald Nessler from Yahoo and Bruce Croft from His Majesty numbers, and today I'm going to talk about learning constant importance using a weighted."
        ],
        [
            "Dependence model.",
            "So the general setting we used to in web searches, we issue a query to search engine free tax query and a search engine retrieve us set of rank list of documents.",
            "Now this is very, very comfortable for us because we don't have to think about how to.",
            "Uh.",
            "The structure of the query.",
            "However, the search engine must accurately interpret the query intent from this free text.",
            "Specifically, in this work, we focus on two things.",
            "Detecting phrases in this search queries where you know New York Times not always equals time.",
            "New York and detecting relative relative importance of terms and phrases within the search query.",
            "So for instance, if you have a query like Continental airline booking terms, Continental and booking would be more important for this particular query than the term airline."
        ],
        [
            "Now the classical retrieval model which we will refer to as turn based model, usually treat the query as the bag of words.",
            "For example TF, IDF, BM 25 or query likelihood.",
            "Am I not among other models?",
            "No, although successful for many years, this is a very simple query model which assumes the term order within the queries interchangeable.",
            "And which assumes that turn within the query is fixed and does not depend on the context.",
            "So for example, we can use weights such as IDF weight, which are collection dependent, but do not depend on the."
        ],
        [
            "For itself.",
            "Recently Richard researchers started to work on what we call concept based model.",
            "There is models that do incorporate the term dependence into retrieval frameworks.",
            "Examples of such models are Markov random fields for information retrieval, an recently these term proximities and dependencies.",
            "We're incorporating other models, such as being 25 and divergent from randomness.",
            "These models are more realistic because they do model that the term order and model the dependencies between different terms.",
            "However they are waiting for these terms and concepts within the query are still rigid and ad hoc incense.",
            "These models still use some variants of measures like I do."
        ],
        [
            "Yes.",
            "Now before I start talking about our model, I would like to kind of give a definition for what we refer to as a concept in this talk.",
            "So instead of giving an exhaustive definition of what is a concept, we just like to in this particular talk, limit ourselves to practical definition for R, which says that the concept is any syntactic expression that can be matched within a document.",
            "So for instance, we here in our in our work we use three types of concepts, unigrams, which is basically a measure of any query term within a document.",
            "Exact phrases matching a phrase from a query within document, an matching unordered phrases within some proximity within a document, for example matching White House within a window of K terms within a document."
        ],
        [
            "Now we develop our framework on top of the existing Markov random field framework for information retrieval, which will give some.",
            "Details on briefly so Mark over Fields encode, document and query terms as a graph.",
            "Undirected graph G. Where vertices represent document or query term nodes.",
            "Here that you seed.",
            "Slide and edges encode some dependencies between this query terms and the document.",
            "Not to score the document, we look at potential over the clicks of graph G. These potentials are some negative non negative functions that are defined over these configuration of clicks and they somehow measure the match between the query in the document.",
            "Now to score document what we need to do is estimate the joint probability over the entire undirected graph G."
        ],
        [
            "In our work we use the sequential dependence model, which takes the assumption that not all the query terms are dependent, but only the adjacent terms are dependent.",
            "This gives us.",
            "Efficiency, effectiveness tradeoff is we don't have to estimate all the dependencies, but we do capture some important ones.",
            "So for example, in this example here terms Q1Q2R.",
            "Dependent but terms Q1Q3 are not an empirically.",
            "This model was proven to be both successful on track collections and web collections as well."
        ],
        [
            "Now the key point to take from this is the ranking function that sequential dependence model using this function is basically.",
            "Wait combination of different scores that.",
            "The graph assigns to the document.",
            "So there are three parts of this equation.",
            "One part is matches the bag of word matching.",
            "The FD function.",
            "Another part is the exact phrase matching the if function and a few function measures the non exact matches the proximity matches.",
            "And all these functions are linearly combined using the parameters Lambda, T, Lambda, Lambda, W. And in order to optimize, this framework will need to do is to find the parameters Lambda that optimize some retrieval performance measures such as map or anything."
        ],
        [
            "She.",
            "Now, although very successful, this model does have several limitations an.",
            "A more significantly the limitation that these lambdas are basically.",
            "Constant for any term or concept of inquiry.",
            "We do not change lambdas based on the terms or bigrams we see.",
            "This causes what we call.",
            "Parameter tying is all measures of the same time are equally weighted.",
            "And this could be especially the terminal for verbose queries.",
            "Longer queries where we have more terms and more concepts and the weights between these concepts and terms varies.",
            "So instead I would like to propose a model that actually allows these query concept weights to vary."
        ],
        [
            "In order to do this, we instead of assuming fixed parameters Lambda, we take parameters Lambda that actually depends on the concept.",
            "In our case we have.",
            "Unigrams and bigrams so we have parameters, Lambda, Qi, Lambda, Qi, Qi plus one which are.",
            "Farming tries using a weighted linear combination of features G. These features Ger concept important features which I will talk about soon and double is here at the three parameters that.",
            "Encode the importance of this different feature."
        ],
        [
            "No, as I said now we want to define what these important features are.",
            "How do we define the concept is important indeed.",
            "Now these features G. As you might note, they depend only on the concept, they do not depend on the underlying document collection or the document that we are scoring.",
            "It is there independent of these things and we can use different types of sources to actually.",
            "Calculate these features so in our work we divide these features into two types of features.",
            "One is endogenous features or collection dependent features.",
            "More traditional IR features and a type of features are exogenous features which do not depend on the collection we using, so we can actually leverage external data to improve our estimation of concept importance."
        ],
        [
            "So here's a table that details.",
            "The collections were using to actually calculate the features for endogenous features.",
            "We use the collection that retrieval is performed upon, so we use the two standard metrics information travel collection frequency and document frequency for that collection.",
            "In addition, we employ three external collections which include Google N Grams, which is large.",
            "Collection of ngram counts over web.",
            "A small query log sample of around 15 million queries.",
            "And Wikipedia titles which were found to be useful for determining constant importance in previous work.",
            "So overall we have 7 unigram features in our model.",
            "Ann have 11 more features for bigrams which include all the features we have for unigrams plus 4 features that describe the pointwise mutual information between the two terms in the bigram.",
            "Overall, we have 18 features as concept, important features and all these features are log scale and normalized to maker estimations better."
        ],
        [
            "Now I'm going to go back and talk about how we actually use this new concept dependent Landers that I described.",
            "So I'm sitting here in this equation, the lambdas, the fixed llamas from before with now waited.",
            "Concept important features.",
            "Now we said this is what we call the WSD ranking function.",
            "The ranking function, the way sequential dependence models using an you can see.",
            "Although this function is much more complicated than the one we saw before for sequential dependence model it is still linear.",
            "However the linearity here is not with respect to Lambda that we saw before it with respect to WS, which are the ways that defined the concept important scores.",
            "So again, we can use any.",
            "Learning to make algorithm that uses linear functions to actually optimize this WS the weights of content, important scores or features to optimize some retrieval metrics such as map or in DCG directly."
        ],
        [
            "And here describe some of the details of how we actually do it.",
            "So as I said, we want to learn the ways W to optimize their true performance metric.",
            "The double user here.",
            "And we can in this work we optimize map and DCG.",
            "We use a coordinate level Ascent algorithm, which is a simple algorithm, but it's very efficient for a small number of times like we have here less than.",
            "20 and has empirically good performances shown in previous work.",
            "However, we not limited to using this particular algorithm, we can use any other learning to rank algorithms that can take as input linear combination of features."
        ],
        [
            "Now just to give you a taste of what these ways we learn look like, I'll give you an example.",
            "So we have a query, civil War, battle reenactments, and for this query I show you the concept that we have from this query, the unigrams and bigrams.",
            "I show you the important features or some of the important features here, which is the Google frequency.",
            "The frequency in Google Ngram collection, and the document frequency and the weight we actually learn for this particular concept.",
            "So now that these weights actually differ from both the document frequency and Google frequency, they're not exactly correlated with none of them, and you can see if I would show you all the concepts, reports, features that you received it for every feature.",
            "We have some divergent between the actual weight and the feature.",
            "For example, for document frequency, which is a well known weighting method, we see that even though for terms were in battle, document frequency is actually quite similar the way that our model actually learns the way that actually help to optimize the performance are actually quite different from these two terms, so war is more important for improving performance in battle in this case."
        ],
        [
            "To give another example, here is quick is a concept civil war versus concept, but we're battle.",
            "So.",
            "In terms of query segmentation, civil war would be intuitively better segment to segment the query on.",
            "As for example, Google frequency shows, will anger figures shows for this particular concept.",
            "However, you can see that war battle which seems to be a less likely segment, is actually more important for improved performance than the segment Civil War, which is counter intuitive.",
            "But this is actually learn by our algorithm because directly optimize the performance of the retrieval method."
        ],
        [
            "Now I'm going to kind of go through the results we have in our work, an more detailed violation of our approach is given in the paper where we show results for tracking web document collections.",
            "For several types of queries, short and long queries, and we also analyzed the contribution of different feature types.",
            "The concept of features I talked about and contribution of different concepts, that is bigrams or unigrams.",
            "Here I'll just give some highlights on the."
        ],
        [
            "Results we have.",
            "So I'll start with that.",
            "Recollections Sofort recollection we looked at two types of queries, title queries and description queries.",
            "Title queries are short keyword queries that you know, kind of familiar from web search.",
            "And you see these even for these short queries we can improve performance significantly.",
            "User using our model.",
            "So in this graph here we plot map mineral precision and we do it for three retrieval models.",
            "Query likelihood, sequential dependence model and await sequential depends we propose.",
            "And the numbers here denote the percentage of improvement over sequential dependence model.",
            "So we see that all collections we improve the performance, especially for the TT Tanji collection, in which the performance improves by almost 8%.",
            "In all cases, the improvement are still significant."
        ],
        [
            "We also did the experiments on the track description queries which are longer versions of the same queries.",
            "More natural language for both queries.",
            "You see that in most cases the improvements here, even larger for weight, sequential dependence model reaching above 24% for TT10G collection and reaching 6% for robots collection, which is a newswire collection.",
            "Again, as well As for short title queries, they improvements for description.",
            "Long queries were also significant overall collections."
        ],
        [
            "Now I'm going to talk about a little bit about endogenous features that we use.",
            "So as I remember, we use two types of features to actually estimate the importance of certain concepts.",
            "And we looked at the results obtained when using either just the emergence or just the exogeneous features.",
            "And we found that the results using either one of those are actually compatible.",
            "And they found that using both types of features actually improves performance over the unweighted model and sequential dependence model.",
            "However, we found that in most cases, combining these two types of feature as we do in the results shown here actually results in better performance than just using either one of them alone, indicating that each of these feature types give some additional information that the other one does not have."
        ],
        [
            "Now we also looked at determined by ground weights and their importance for the query waiting, so until we found that for short web queries one to three terms long queries, we found that actually by graduates have more impact than term weights.",
            "That is the wedding of bigrams actually improves retrieval by more than waiting the unigrams.",
            "However, for more kind of informational TREC queries in longer web queries, we found that Unicorn rates actually have more impact than the bigram weight that is, again, awaiting.",
            "The unit is more important than waiting the bigrams.",
            "However, in the previous case, we find that in most cases, combining both types of weights result in better performance.",
            "Especially these performances are seen when you look at the longer queries.",
            "Which is reasonable since we want to kind of.",
            "With both types of content in these longer queries."
        ],
        [
            "Now finally I will show you the results we have for the large or for large scale commercial web search test collection.",
            "Where again we tested our method against the query likelihood model, which is a bag of words baseline, an sequential dependence model, which is a.",
            "The unweighted version of our.",
            "Weighted sequential dependence model.",
            "We found that this is the result given for a large sample of long web queries, that is, queries that have at least 4 words in them.",
            "This is the Temple of 1000 queries and all results are applied, obtained using five fold cross validation.",
            "And we found that in all the cases improvements by WD over sequential dependence model are significant.",
            "And reaches as high as 2.5% for DCG at 5, which is very significant result given the number of.",
            "The queries we have in our set."
        ],
        [
            "So to conclude, we showed in this work that we can improve the existing text retrieval models by doing two things better modeling of query concepts and better weighting of query concepts.",
            "Specifically, we show that concept weight when we determined it should be determined by a combination of both endogenous and exogenous features.",
            "Take into account not just the collection which we perform.",
            "The retrieval well, some external sources of information.",
            "And we empirically found the dynamic concept weighting that we propose at least a significant performance improvements in terms of MAP and ECG, especially for longer queries."
        ],
        [
            "And I concluded by thanking you all for coming, and I'd like to thank the WGM conference organizing for providing me with the Student Travel Award Ground.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hello everyone, my name is Michael.",
                    "label": 0
                },
                {
                    "sent": "I'm from University, Massachusetts Amherst and this is joint work with Donald Nessler from Yahoo and Bruce Croft from His Majesty numbers, and today I'm going to talk about learning constant importance using a weighted.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Dependence model.",
                    "label": 0
                },
                {
                    "sent": "So the general setting we used to in web searches, we issue a query to search engine free tax query and a search engine retrieve us set of rank list of documents.",
                    "label": 0
                },
                {
                    "sent": "Now this is very, very comfortable for us because we don't have to think about how to.",
                    "label": 0
                },
                {
                    "sent": "Uh.",
                    "label": 0
                },
                {
                    "sent": "The structure of the query.",
                    "label": 0
                },
                {
                    "sent": "However, the search engine must accurately interpret the query intent from this free text.",
                    "label": 1
                },
                {
                    "sent": "Specifically, in this work, we focus on two things.",
                    "label": 1
                },
                {
                    "sent": "Detecting phrases in this search queries where you know New York Times not always equals time.",
                    "label": 0
                },
                {
                    "sent": "New York and detecting relative relative importance of terms and phrases within the search query.",
                    "label": 0
                },
                {
                    "sent": "So for instance, if you have a query like Continental airline booking terms, Continental and booking would be more important for this particular query than the term airline.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now the classical retrieval model which we will refer to as turn based model, usually treat the query as the bag of words.",
                    "label": 1
                },
                {
                    "sent": "For example TF, IDF, BM 25 or query likelihood.",
                    "label": 0
                },
                {
                    "sent": "Am I not among other models?",
                    "label": 0
                },
                {
                    "sent": "No, although successful for many years, this is a very simple query model which assumes the term order within the queries interchangeable.",
                    "label": 1
                },
                {
                    "sent": "And which assumes that turn within the query is fixed and does not depend on the context.",
                    "label": 0
                },
                {
                    "sent": "So for example, we can use weights such as IDF weight, which are collection dependent, but do not depend on the.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For itself.",
                    "label": 0
                },
                {
                    "sent": "Recently Richard researchers started to work on what we call concept based model.",
                    "label": 0
                },
                {
                    "sent": "There is models that do incorporate the term dependence into retrieval frameworks.",
                    "label": 1
                },
                {
                    "sent": "Examples of such models are Markov random fields for information retrieval, an recently these term proximities and dependencies.",
                    "label": 1
                },
                {
                    "sent": "We're incorporating other models, such as being 25 and divergent from randomness.",
                    "label": 1
                },
                {
                    "sent": "These models are more realistic because they do model that the term order and model the dependencies between different terms.",
                    "label": 0
                },
                {
                    "sent": "However they are waiting for these terms and concepts within the query are still rigid and ad hoc incense.",
                    "label": 0
                },
                {
                    "sent": "These models still use some variants of measures like I do.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Now before I start talking about our model, I would like to kind of give a definition for what we refer to as a concept in this talk.",
                    "label": 0
                },
                {
                    "sent": "So instead of giving an exhaustive definition of what is a concept, we just like to in this particular talk, limit ourselves to practical definition for R, which says that the concept is any syntactic expression that can be matched within a document.",
                    "label": 1
                },
                {
                    "sent": "So for instance, we here in our in our work we use three types of concepts, unigrams, which is basically a measure of any query term within a document.",
                    "label": 0
                },
                {
                    "sent": "Exact phrases matching a phrase from a query within document, an matching unordered phrases within some proximity within a document, for example matching White House within a window of K terms within a document.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now we develop our framework on top of the existing Markov random field framework for information retrieval, which will give some.",
                    "label": 0
                },
                {
                    "sent": "Details on briefly so Mark over Fields encode, document and query terms as a graph.",
                    "label": 1
                },
                {
                    "sent": "Undirected graph G. Where vertices represent document or query term nodes.",
                    "label": 0
                },
                {
                    "sent": "Here that you seed.",
                    "label": 0
                },
                {
                    "sent": "Slide and edges encode some dependencies between this query terms and the document.",
                    "label": 0
                },
                {
                    "sent": "Not to score the document, we look at potential over the clicks of graph G. These potentials are some negative non negative functions that are defined over these configuration of clicks and they somehow measure the match between the query in the document.",
                    "label": 1
                },
                {
                    "sent": "Now to score document what we need to do is estimate the joint probability over the entire undirected graph G.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In our work we use the sequential dependence model, which takes the assumption that not all the query terms are dependent, but only the adjacent terms are dependent.",
                    "label": 1
                },
                {
                    "sent": "This gives us.",
                    "label": 0
                },
                {
                    "sent": "Efficiency, effectiveness tradeoff is we don't have to estimate all the dependencies, but we do capture some important ones.",
                    "label": 0
                },
                {
                    "sent": "So for example, in this example here terms Q1Q2R.",
                    "label": 0
                },
                {
                    "sent": "Dependent but terms Q1Q3 are not an empirically.",
                    "label": 0
                },
                {
                    "sent": "This model was proven to be both successful on track collections and web collections as well.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now the key point to take from this is the ranking function that sequential dependence model using this function is basically.",
                    "label": 0
                },
                {
                    "sent": "Wait combination of different scores that.",
                    "label": 0
                },
                {
                    "sent": "The graph assigns to the document.",
                    "label": 0
                },
                {
                    "sent": "So there are three parts of this equation.",
                    "label": 0
                },
                {
                    "sent": "One part is matches the bag of word matching.",
                    "label": 0
                },
                {
                    "sent": "The FD function.",
                    "label": 0
                },
                {
                    "sent": "Another part is the exact phrase matching the if function and a few function measures the non exact matches the proximity matches.",
                    "label": 0
                },
                {
                    "sent": "And all these functions are linearly combined using the parameters Lambda, T, Lambda, Lambda, W. And in order to optimize, this framework will need to do is to find the parameters Lambda that optimize some retrieval performance measures such as map or anything.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "She.",
                    "label": 0
                },
                {
                    "sent": "Now, although very successful, this model does have several limitations an.",
                    "label": 0
                },
                {
                    "sent": "A more significantly the limitation that these lambdas are basically.",
                    "label": 0
                },
                {
                    "sent": "Constant for any term or concept of inquiry.",
                    "label": 0
                },
                {
                    "sent": "We do not change lambdas based on the terms or bigrams we see.",
                    "label": 0
                },
                {
                    "sent": "This causes what we call.",
                    "label": 0
                },
                {
                    "sent": "Parameter tying is all measures of the same time are equally weighted.",
                    "label": 1
                },
                {
                    "sent": "And this could be especially the terminal for verbose queries.",
                    "label": 0
                },
                {
                    "sent": "Longer queries where we have more terms and more concepts and the weights between these concepts and terms varies.",
                    "label": 1
                },
                {
                    "sent": "So instead I would like to propose a model that actually allows these query concept weights to vary.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In order to do this, we instead of assuming fixed parameters Lambda, we take parameters Lambda that actually depends on the concept.",
                    "label": 1
                },
                {
                    "sent": "In our case we have.",
                    "label": 0
                },
                {
                    "sent": "Unigrams and bigrams so we have parameters, Lambda, Qi, Lambda, Qi, Qi plus one which are.",
                    "label": 0
                },
                {
                    "sent": "Farming tries using a weighted linear combination of features G. These features Ger concept important features which I will talk about soon and double is here at the three parameters that.",
                    "label": 0
                },
                {
                    "sent": "Encode the importance of this different feature.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "No, as I said now we want to define what these important features are.",
                    "label": 0
                },
                {
                    "sent": "How do we define the concept is important indeed.",
                    "label": 1
                },
                {
                    "sent": "Now these features G. As you might note, they depend only on the concept, they do not depend on the underlying document collection or the document that we are scoring.",
                    "label": 0
                },
                {
                    "sent": "It is there independent of these things and we can use different types of sources to actually.",
                    "label": 0
                },
                {
                    "sent": "Calculate these features so in our work we divide these features into two types of features.",
                    "label": 0
                },
                {
                    "sent": "One is endogenous features or collection dependent features.",
                    "label": 1
                },
                {
                    "sent": "More traditional IR features and a type of features are exogenous features which do not depend on the collection we using, so we can actually leverage external data to improve our estimation of concept importance.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's a table that details.",
                    "label": 0
                },
                {
                    "sent": "The collections were using to actually calculate the features for endogenous features.",
                    "label": 0
                },
                {
                    "sent": "We use the collection that retrieval is performed upon, so we use the two standard metrics information travel collection frequency and document frequency for that collection.",
                    "label": 1
                },
                {
                    "sent": "In addition, we employ three external collections which include Google N Grams, which is large.",
                    "label": 0
                },
                {
                    "sent": "Collection of ngram counts over web.",
                    "label": 1
                },
                {
                    "sent": "A small query log sample of around 15 million queries.",
                    "label": 0
                },
                {
                    "sent": "And Wikipedia titles which were found to be useful for determining constant importance in previous work.",
                    "label": 0
                },
                {
                    "sent": "So overall we have 7 unigram features in our model.",
                    "label": 1
                },
                {
                    "sent": "Ann have 11 more features for bigrams which include all the features we have for unigrams plus 4 features that describe the pointwise mutual information between the two terms in the bigram.",
                    "label": 0
                },
                {
                    "sent": "Overall, we have 18 features as concept, important features and all these features are log scale and normalized to maker estimations better.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now I'm going to go back and talk about how we actually use this new concept dependent Landers that I described.",
                    "label": 0
                },
                {
                    "sent": "So I'm sitting here in this equation, the lambdas, the fixed llamas from before with now waited.",
                    "label": 0
                },
                {
                    "sent": "Concept important features.",
                    "label": 0
                },
                {
                    "sent": "Now we said this is what we call the WSD ranking function.",
                    "label": 1
                },
                {
                    "sent": "The ranking function, the way sequential dependence models using an you can see.",
                    "label": 0
                },
                {
                    "sent": "Although this function is much more complicated than the one we saw before for sequential dependence model it is still linear.",
                    "label": 0
                },
                {
                    "sent": "However the linearity here is not with respect to Lambda that we saw before it with respect to WS, which are the ways that defined the concept important scores.",
                    "label": 0
                },
                {
                    "sent": "So again, we can use any.",
                    "label": 0
                },
                {
                    "sent": "Learning to make algorithm that uses linear functions to actually optimize this WS the weights of content, important scores or features to optimize some retrieval metrics such as map or in DCG directly.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And here describe some of the details of how we actually do it.",
                    "label": 0
                },
                {
                    "sent": "So as I said, we want to learn the ways W to optimize their true performance metric.",
                    "label": 0
                },
                {
                    "sent": "The double user here.",
                    "label": 0
                },
                {
                    "sent": "And we can in this work we optimize map and DCG.",
                    "label": 0
                },
                {
                    "sent": "We use a coordinate level Ascent algorithm, which is a simple algorithm, but it's very efficient for a small number of times like we have here less than.",
                    "label": 1
                },
                {
                    "sent": "20 and has empirically good performances shown in previous work.",
                    "label": 0
                },
                {
                    "sent": "However, we not limited to using this particular algorithm, we can use any other learning to rank algorithms that can take as input linear combination of features.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now just to give you a taste of what these ways we learn look like, I'll give you an example.",
                    "label": 0
                },
                {
                    "sent": "So we have a query, civil War, battle reenactments, and for this query I show you the concept that we have from this query, the unigrams and bigrams.",
                    "label": 1
                },
                {
                    "sent": "I show you the important features or some of the important features here, which is the Google frequency.",
                    "label": 0
                },
                {
                    "sent": "The frequency in Google Ngram collection, and the document frequency and the weight we actually learn for this particular concept.",
                    "label": 0
                },
                {
                    "sent": "So now that these weights actually differ from both the document frequency and Google frequency, they're not exactly correlated with none of them, and you can see if I would show you all the concepts, reports, features that you received it for every feature.",
                    "label": 0
                },
                {
                    "sent": "We have some divergent between the actual weight and the feature.",
                    "label": 0
                },
                {
                    "sent": "For example, for document frequency, which is a well known weighting method, we see that even though for terms were in battle, document frequency is actually quite similar the way that our model actually learns the way that actually help to optimize the performance are actually quite different from these two terms, so war is more important for improving performance in battle in this case.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To give another example, here is quick is a concept civil war versus concept, but we're battle.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "In terms of query segmentation, civil war would be intuitively better segment to segment the query on.",
                    "label": 0
                },
                {
                    "sent": "As for example, Google frequency shows, will anger figures shows for this particular concept.",
                    "label": 0
                },
                {
                    "sent": "However, you can see that war battle which seems to be a less likely segment, is actually more important for improved performance than the segment Civil War, which is counter intuitive.",
                    "label": 1
                },
                {
                    "sent": "But this is actually learn by our algorithm because directly optimize the performance of the retrieval method.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now I'm going to kind of go through the results we have in our work, an more detailed violation of our approach is given in the paper where we show results for tracking web document collections.",
                    "label": 0
                },
                {
                    "sent": "For several types of queries, short and long queries, and we also analyzed the contribution of different feature types.",
                    "label": 1
                },
                {
                    "sent": "The concept of features I talked about and contribution of different concepts, that is bigrams or unigrams.",
                    "label": 0
                },
                {
                    "sent": "Here I'll just give some highlights on the.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Results we have.",
                    "label": 0
                },
                {
                    "sent": "So I'll start with that.",
                    "label": 0
                },
                {
                    "sent": "Recollections Sofort recollection we looked at two types of queries, title queries and description queries.",
                    "label": 0
                },
                {
                    "sent": "Title queries are short keyword queries that you know, kind of familiar from web search.",
                    "label": 0
                },
                {
                    "sent": "And you see these even for these short queries we can improve performance significantly.",
                    "label": 1
                },
                {
                    "sent": "User using our model.",
                    "label": 0
                },
                {
                    "sent": "So in this graph here we plot map mineral precision and we do it for three retrieval models.",
                    "label": 0
                },
                {
                    "sent": "Query likelihood, sequential dependence model and await sequential depends we propose.",
                    "label": 0
                },
                {
                    "sent": "And the numbers here denote the percentage of improvement over sequential dependence model.",
                    "label": 0
                },
                {
                    "sent": "So we see that all collections we improve the performance, especially for the TT Tanji collection, in which the performance improves by almost 8%.",
                    "label": 0
                },
                {
                    "sent": "In all cases, the improvement are still significant.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We also did the experiments on the track description queries which are longer versions of the same queries.",
                    "label": 0
                },
                {
                    "sent": "More natural language for both queries.",
                    "label": 0
                },
                {
                    "sent": "You see that in most cases the improvements here, even larger for weight, sequential dependence model reaching above 24% for TT10G collection and reaching 6% for robots collection, which is a newswire collection.",
                    "label": 0
                },
                {
                    "sent": "Again, as well As for short title queries, they improvements for description.",
                    "label": 0
                },
                {
                    "sent": "Long queries were also significant overall collections.",
                    "label": 1
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now I'm going to talk about a little bit about endogenous features that we use.",
                    "label": 0
                },
                {
                    "sent": "So as I remember, we use two types of features to actually estimate the importance of certain concepts.",
                    "label": 0
                },
                {
                    "sent": "And we looked at the results obtained when using either just the emergence or just the exogeneous features.",
                    "label": 0
                },
                {
                    "sent": "And we found that the results using either one of those are actually compatible.",
                    "label": 0
                },
                {
                    "sent": "And they found that using both types of features actually improves performance over the unweighted model and sequential dependence model.",
                    "label": 1
                },
                {
                    "sent": "However, we found that in most cases, combining these two types of feature as we do in the results shown here actually results in better performance than just using either one of them alone, indicating that each of these feature types give some additional information that the other one does not have.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now we also looked at determined by ground weights and their importance for the query waiting, so until we found that for short web queries one to three terms long queries, we found that actually by graduates have more impact than term weights.",
                    "label": 1
                },
                {
                    "sent": "That is the wedding of bigrams actually improves retrieval by more than waiting the unigrams.",
                    "label": 0
                },
                {
                    "sent": "However, for more kind of informational TREC queries in longer web queries, we found that Unicorn rates actually have more impact than the bigram weight that is, again, awaiting.",
                    "label": 1
                },
                {
                    "sent": "The unit is more important than waiting the bigrams.",
                    "label": 0
                },
                {
                    "sent": "However, in the previous case, we find that in most cases, combining both types of weights result in better performance.",
                    "label": 1
                },
                {
                    "sent": "Especially these performances are seen when you look at the longer queries.",
                    "label": 0
                },
                {
                    "sent": "Which is reasonable since we want to kind of.",
                    "label": 0
                },
                {
                    "sent": "With both types of content in these longer queries.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now finally I will show you the results we have for the large or for large scale commercial web search test collection.",
                    "label": 1
                },
                {
                    "sent": "Where again we tested our method against the query likelihood model, which is a bag of words baseline, an sequential dependence model, which is a.",
                    "label": 0
                },
                {
                    "sent": "The unweighted version of our.",
                    "label": 0
                },
                {
                    "sent": "Weighted sequential dependence model.",
                    "label": 1
                },
                {
                    "sent": "We found that this is the result given for a large sample of long web queries, that is, queries that have at least 4 words in them.",
                    "label": 0
                },
                {
                    "sent": "This is the Temple of 1000 queries and all results are applied, obtained using five fold cross validation.",
                    "label": 0
                },
                {
                    "sent": "And we found that in all the cases improvements by WD over sequential dependence model are significant.",
                    "label": 0
                },
                {
                    "sent": "And reaches as high as 2.5% for DCG at 5, which is very significant result given the number of.",
                    "label": 0
                },
                {
                    "sent": "The queries we have in our set.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to conclude, we showed in this work that we can improve the existing text retrieval models by doing two things better modeling of query concepts and better weighting of query concepts.",
                    "label": 1
                },
                {
                    "sent": "Specifically, we show that concept weight when we determined it should be determined by a combination of both endogenous and exogenous features.",
                    "label": 1
                },
                {
                    "sent": "Take into account not just the collection which we perform.",
                    "label": 0
                },
                {
                    "sent": "The retrieval well, some external sources of information.",
                    "label": 0
                },
                {
                    "sent": "And we empirically found the dynamic concept weighting that we propose at least a significant performance improvements in terms of MAP and ECG, especially for longer queries.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And I concluded by thanking you all for coming, and I'd like to thank the WGM conference organizing for providing me with the Student Travel Award Ground.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}