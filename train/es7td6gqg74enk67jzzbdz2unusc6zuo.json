{
    "id": "es7td6gqg74enk67jzzbdz2unusc6zuo",
    "title": "Suboptimality of MDL and Bayes in Classification under Misspecification",
    "info": {
        "author": [
            "Peter Gr\u00fcnwald, Centrum Wiskunde & Informatica (CWI)"
        ],
        "published": "Feb. 25, 2007",
        "recorded": "October 2005",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/mcslw04_grunwald_smbcu/",
    "segmentation": [
        [
            "Yeah, so good afternoon everybody.",
            "This is joint work with John Langford who is also here and he will talk to you tomorrow and it was first presented at the Cold 2004 and by now I've extended it a little bit, but that's part hasn't been published yet.",
            "Will see that in a moment.",
            "So what?"
        ],
        [
            "We do here is we study Bayesian inference and minimum description length learning in classification problems.",
            "Now based on minimum description length are often used in practice because they supposedly deal well with overfitting phenomenon.",
            "When you have very large models, so that maximum likelihood will always lead you to overfit.",
            "So we show that there exist classification domains were based on MDL perform suboptimally in the sense that they overfit and this holds even asymptotically no matter how much data you have.",
            "Of course, there are many versions of Basin MDL, so we should immediately at the caveat when you apply them in a standard manner and what standard manner is, we will see in a moment.",
            "So why should this be interesting?",
            "Well, of course basic methods are used all the time."
        ],
        [
            "Man, some people claim that you should always be using basic methods I guess.",
            "This talk was meant for mixed computer science, based in audience originally against this audience.",
            "There would not be so many people who would claim this, but still there are many people claim this, so it's interesting to see.",
            "How they perform an for amneal methods?",
            "It's even in a way the case that they have been designed for dealing with overfitting.",
            "They model complexity as their starting point rather than a later at only analysis.",
            "So then it's interesting to see that even these methods can overfit.",
            "And then from a theoretical point of view, it's interesting because for Bashan, an actual so far meal methods they are very strong consistency results like Dupes Theorem or Blackwell Dubon theorem, so there seems to be some type of this in a way this might seem superficially impossible, so if you look at how it can be reconciled with the theory, we will get some new insights.",
            "And just to give you some first idea, it turns out that we get the inconsistency here because we use a misspecified model.",
            "So the true distribution is not in the model under consideration.",
            "However, we can have distributions in the model under consideration that are arbitrarily close and callback library divergents to the true distribution, and still this will happen.",
            "So."
        ],
        [
            "1st going to say yeah.",
            "But how you define?",
            "Well, we will see this wait till I go to it's you're right it's not clear but.",
            "But I'm going to show is that these methods are inconsistent in a certain sense and how it relates to overfitting L. Right, you will see it's kind of what you would intuitively call overfitting.",
            "So first a little bit about classification, and then I'll give an abstract statement of the main result and that will raise a lot of questions.",
            "So by filling in these questions I will get to a precise statement of the result, and then there will be discussion."
        ],
        [
            "Classification as usual you have some feature space and label space, which here I take to be binary into B -- 1 one, so not 01.",
            "It doesn't really matter, but that's just what I chose for this talk.",
            "Sample it's important to always remember if I use capital S, it stands for the training sample.",
            "The data you see on which you base your classifier.",
            "And then we work with our model, will be a set of hypothesis which are in this case not probability distributions but classifiers.",
            "So functions from X to Y.",
            "And the goal is to find a classifier that generalizes well.",
            "So this is your training sample.",
            "Based on this, you try to find a classifier in here, or maybe some somebody, a combination of classifiers.",
            "In here you use it to make predictions of future values given future X values, and you hope that the probability of making a mistake there is small that you find that classifier with a small expected 01 error or generalization error.",
            "I'll define it precisely in a moment."
        ],
        [
            "So note that I define classifiers as functions from the feature input space to minus one one, so these are hard classifiers like decision trees.",
            "Of course, in practice you much more often deal with soft classifiers like support vector machines with real valued output or probabilistic classifiers like naive base or base network classifiers or logistic regression which are just conditional distributions of Y given X, which you first infer from your data, and then you use those to find decisions for Y.",
            "Given XI will go to these later, but The thing is best explained remains easiest if you use these hard classifiers.",
            "Um so."
        ],
        [
            "We say we want to find a classifier which generalizes well.",
            "We measure that in a way which is usual in the statistical learning.",
            "Community, we assume there is some distribution on the joint.",
            "Feature label space, and we assume the data are IID according to the distribution.",
            "We'll call it.",
            "D is distribution.",
            "And if you take fixed classifier then your measures performance by zero one loss.",
            "And so it's generalization errors, and actually it's classic or classification risk is the expected 01 last expected difference between Y.",
            "And the prediction of Y made by the classifier.",
            "So this is either two or minus two, so divided by two.",
            "And this is of course equal to the probability that your classifier makes a mistake, just the misclassification probability.",
            "The smaller that is, the better we say, is the classifier with respect to the underlying distribution."
        ],
        [
            "So the next thing we have to define is learning algorithms.",
            "So we will talk about the result which holds for a variety of learning algorithms, including the base in algorithm or the minimum description of the algorithm.",
            "So learning algorithm is just about a statistician would call an estimator.",
            "And for each sample of arbitrary length, you can put that sample into the algorithm as an input, and the output is a classifier which can be used to classify the next wife value given the next X value.",
            "Now we call a learning algorithm consistent."
        ],
        [
            "Now we're moving closer to our result.",
            "If the following holds, so we get a sample, we get more and more data according to distribution D IID.",
            "We say the algorithm is consistent or asymptotically optimal.",
            "Facebook.",
            "No matter what this D is.",
            "Given enough data.",
            "The classifier your algorithm learns from the data, so this is the input S sample of length M. It outputs a classifier.",
            "Then you can look at what is the expected 01 loss, the classification risk of the classifier and that should converge to the minimum achievable within your class.",
            "So it might be that your class is very silly for the true distribution, and none of the classifiers will give you good predictions.",
            "That doesn't matter what we will.",
            "What we want that no matter what distribution you have, you always find the best within your class.",
            "Right, so you learn the best thing that is to be learned from the model set of classifiers you started with, and this should hold for example with probability one or in expectation or D probability.",
            "There various variations of this.",
            "It's clearly an ologist to ordinary statistical consistency.",
            "So again, on the left is what you learn."
        ],
        [
            "From your data and you look at how well will it perform in the future data from the same distribution and on the right is the best thing you can do with the model with your model assumptions."
        ],
        [
            "So now I have all the ingredients for main result.",
            "Still stated very abstractly here, without any.",
            "Numerical values.",
            "So there exists some input domain X.",
            "Then there exist some prior.",
            "Which is just a probability distribution.",
            "With support, accountable sets of classifiers functions from X to minus one one.",
            "There is some true distribution.",
            "And there is some constant K larger than 0.",
            "Such that the base in learning algorithm which I'll define in the moment and the base in learning algorithm depends on the prior for different priors becomes a different algorithm.",
            "And of course, it depends on the sample.",
            "That's the input to the algorithm, input sample and outcomes.",
            "A classifier for classifying the next outcome.",
            "So there are some prior and some domain.",
            "Some true distributions such that the probability.",
            "That the Bayesian classifier classifier selected by the basin algorithm has expected loss 01 risk.",
            "Larger than the best you can obtain within your class.",
            "Plus this constant K which is larger than zero, is 1.",
            "So what will happen is if you get more and more data base will not converge to the best classifier.",
            "It will keep out putting a classifier which is sub optimal.",
            "There is a classifier in your class which if you would know that classifier you could make better predictions.",
            "That's what we prove.",
            "Of course, to make this precise, there are lots of things.",
            "I have to make more precisely like what is the prior artists K. What is the true distribution?",
            "And first of all.",
            "I have to make precise what is the base in algorithm.",
            "But I would like to is this clear in an abstract way what I'm?",
            "Saying here.",
            "Yeah.",
            "You first.",
            "Does the prior, depending on the size of us, know?",
            "But we are being real basins here, so we are not allowed to have the prior.",
            "Depends on the size of S. Because the real basin would claim that.",
            "Even then, you don't get the priors fixed once and for all.",
            "What happens when you turn out to be Asians?",
            "It depends.",
            "I'll get back to that.",
            "There are different types of Bashan, some, like it and some, get very angry because they say it's not really basing.",
            "It depends also matter your subjective and objective base in the subjective basin doesn't believe in analysis like this.",
            "He doesn't believe that there is something like a true distribution and that you can measure performance with respect to that.",
            "An objective nation does so no clear cut answer.",
            "The truth.",
            "Yeah, that's crucial, but.",
            "Do some Nunzio fire?",
            "Yeah, this is the true version.",
            "Would say you do the best you can with your beliefs.",
            "And if so, that it becomes irrelevant in a way for true Bashan, because you say, like you.",
            "True Basin would say you should.",
            "Well, that's that's a very long story.",
            "Why you would consider relevant, irrelevant.",
            "Let's say a pragmatic Bashan would acknowledge that because you might choose this model and prior for pragmatic reasons, because he wants to compute things faster, he didn't have too much time to think it might be the case that the truth doesn't match his modeling prior completely.",
            "And in fact, that's I mean based on analysis is nowadays.",
            "Often it worked, for example.",
            "Classification of documents on the web.",
            "People use mixture models for where they assume words are generated.",
            "ID and documents.",
            "Clearly that's false, right?",
            "Any version would have to admit.",
            "I think that's a false assumption, but basins are doing it.",
            "So once you.",
            "You're right, but you can, even with more sophisticated models which are not cold.",
            "Now, if they still IID.",
            "So I think most bases actually would see this as something relevant.",
            "But the real in a way, the real killer is only coming because it's actually it's coming up now first of all."
        ],
        [
            "The same holds for MDL.",
            "But in this talk, I'll focus on base because it's much more well known, say little bit more.",
            "Yeah, yeah, exactly the same example.",
            "Anne."
        ],
        [
            "So what I'll do now is.",
            "First tell you what how exactly I defined the basic learning algorithm.",
            "And that's where you get into more disagreement with base.",
            "And then I'll say more about how exactly well how we get this theorem.",
            "How do these distributions and priors and so on look like?",
            "And then I'm going to say something about how dramatic is the result.",
            "How bad can we make the result B an?",
            "Why is it surprising?",
            "So first definition of the base in learning algorithm?"
        ],
        [
            "They immediately notice a problem because bases inferences, define distributions, or conditional distributions, and not on set of classifiers.",
            "So what does it mean to do based on inference with prior to final classifiers?",
            "Um?",
            "Well, there is a standard way of dealing with this if you're for some reasons you start out with a model which, like support vector machines or whatever, which are best thought of as classifiers, not distributions.",
            "And still you want to use the basic machinery.",
            "What you usually do is you turn them into probabilistic model by making some additional assumptions about the noise.",
            "So what is done in classification?",
            "Is the following you convert each classifier into your original set of distribution set of classifiers your model?",
            "Into a conditional distribution.",
            "Then you have a prior on here.",
            "Now becomes a prior unconditional probability distributions and now you apply base rule to find a posterior which is now posterior probability distributions and those probability distributions that posterior distribution over distributions you used to make classifications.",
            "So let me explain that in more detail."
        ],
        [
            "The standard way of doing this is the logistic transformation.",
            "So what you do is you have this original model.",
            "Then you add one extra parameter which will call B 10.",
            "It's a real value of parameter.",
            "And you simply define.",
            "The probability that Y is 1, remember why it's one or minus one given X.",
            "And given.",
            "End EXE, so this was a classifier, now becomes an index to the distribution and parameter B.",
            "See through the better times, the output of the classifier.",
            "And this is just to normalize so that this thing sums to one.",
            "If you have if you sum over wise one and Y zero for the same X, so now it becomes a conditional distribution of over Y given X.",
            "Now you can extend this to M outcomes by multiplication, so your active dates are IID.",
            "Now you define priors on the set of classifiers.",
            "And on this extra parameter.",
            "Um?",
            "And you simply set the prior on the joint.",
            "So this is now an element of your.",
            "This index is a conditional distribution in your newly created model of conditional distributions and the prior on that you usually just take the product of these two priors.",
            "You start out with and typically this will be a discrete prior because we're going to use a countable set of classifiers and this is a density, but you can still multiply."
        ],
        [
            "So why does this make any sense?",
            "If you look at hard classifiers and it's easy to see if you look at the minus log likelihood.",
            "The probability of a sequence according to the distribution you created for C and beta.",
            "You can rewrite it as this is beta.",
            "Times.",
            "The number of mistakes the classifier makes on the sample.",
            "So this is the empirical 01 loss, right?",
            "It's the average number number of misclassifications in the sample.",
            "So you have beats at times the number of mistakes you make on the sample.",
            "Or beta times to sample times the empirical loss rather than expected loss, plus something which does not depend on the sample.",
            "And only an M on the sample size.",
            "So basically if you fix beta and you have a Sam."
        ],
        [
            "Polanyi optimizer for C. What happens is that the log likelihood of the distributions you created.",
            "Becomes linear function of their performance in terms of 01 loss on the sample.",
            "So you've turned 01 classification loss into log likelihood.",
            "The higher the likelihood that the smaller the 01 lesson the sample.",
            "If you fix beta and very C Now, because if you would do base with, let's say, a finite set of distributions and given enough data, you would convert the posterior converges to the distribution which maximizes the likelihood of the data.",
            "Right base is just an extension of maximum likelihood, so if you want base to work well at all in terms in sense of 01 loss, but you really want what you want to do is turn 01 loss into logger, log arhythmic loss so that smaller arhythmic loss, which means large log likelihood becomes small.",
            "01 loss in the sample.",
            "Now similarly.",
            "If you were not similarly but.",
            "Additionally, if you fix.",
            "The classifier C. And you start varying beta.",
            "Then you're also doing something which makes some sense, because if you look back at these."
        ],
        [
            "It's easiest to see if you have hard classifiers which output minus one or."
        ],
        [
            "1.",
            "If you look at the definition.",
            "If I have a fixed classifier.",
            "And for some, for any fix C. This will just be a Bernoulli distribution.",
            "If beta is minus Infinity, it corresponds to probability 12.",
            "Why is minus one?",
            "And if it has infinite is probability one for wise one?",
            "So.",
            "Basically, different beaters correspond to different binary distributions.",
            "For Y given X."
        ],
        [
            "And if you maximize the likelihood for fixed C. You basically you can transform the two Bernoulli parameter.",
            "It basically means you find the Bernoulli pyramids are, which is exactly equal to the empirical error.",
            "So if your empirical error, you can think of that that's a number between zero and one.",
            "You can think of that as the relative frequency of having made a mistake, and the thing which maximizes your likelihood.",
            "Exactly sets.",
            "This beta such that this transform becomes the empirical error number of mistakes.",
            "The classifiers he makes on your data.",
            "I should add here that if you have a classifier.",
            "Which has makes more than 50% mistakes.",
            "So let's say it gives the wrong prediction on 90% of the cases.",
            "If you optimize over beta, beta becomes negative.",
            "An this means actually that in your probability flips and then your probability distribution actually becomes quite good model of the data.",
            "And So what happens here is that suppose you have a set of classifiers.",
            "And the best one.",
            "As a generalization, error of 0.2 and the worst one of 0.99.",
            "And actually the worst classifier is much better than the best classifier, because you can trivially change its predictions to very good prediction, and this will actually if you start optimizing beta you at this power of flipping the predictions of classifier so that they actually become better."
        ],
        [
            "So there are some reasons why it would make sense to do this.",
            "An another thing which may be more.",
            "Anne.",
            "Intuitive to statisticians is that your everybody knows.",
            "I guess that if you do regression with the squared loss and a set of functions, that's equivalent to doing maximum.",
            "If you do minimum least squared error, that's equivalent to doing maximum likelihood under the assumption that the wife values are given by FX plus independently normally distributed noise.",
            "So here you did exactly the same thing with classification for each classifier.",
            "You had a probabilistic.",
            "Probabilistic assumption on top PC subeta just distribution you created expresses that why is the classifier evaluated X plus?",
            "Actually this should be sore, so this thing is flipped with a certain probability and probability is given by beta.",
            "So beta determines the noise in your model, just as if you have regression, you connect an extra Sigma which determines the noise.",
            "So that's the intuition why this might be a reasonable thing to do now, of course.",
            "In a way it's not Bashan.",
            "Real Bashan always starts saying like there are some deep reasons why we should always model our uncertainty as distributions, not as classifiers.",
            "Anne.",
            "So we shouldn't do this, but in practice basins do it all the time because for several reasons they've come up with models like support vector machines which happen not to be distributions, but do work very well.",
            "And they still have to turn into distributions.",
            "Now if you look at papers at NIPS or UI, people always do it.",
            "In this way they start with a set of classifiers and then they do the logistic transformation.",
            "Now when we in this work was just finished, we told the basin about it and he protested and he said no, no as a base and you have to think very carefully about your noise model and if you are not sure that the noise is independent of the value of X, then you cannot do this and you're just not allowed to, and so on.",
            "In practice, people do do it so then John had this marvelous idea, I think.",
            "To just describe the problem without saying that we will show that base gives you strange results, but just described the problem.",
            "We have a set of classifiers set of support vector machines.",
            "We somehow want to use Bayesian inference for them extending with prior.",
            "And how would you do this?",
            "So we tested it with three people and they all three set do the majestic transformation.",
            "So therefore we do take this as evidence that this is the basic way of doing it anyway.",
            "Yeah.",
            "Correctly.",
            "This look like your loss function, which you yeah from this.",
            "Yeah, yeah.",
            "Maximizing, I still end up with this optimal 011.",
            "Yeah, exactly.",
            "Yeah, it has exactly.",
            "It has a property that both on the data but also in expectation of the true distribution.",
            "Yeah, yeah yeah yeah we now do a method which is good for minimizing expected log likelihood, and that's the callback library vergence or relative entropy."
        ],
        [
            "OK, so now we know what the algorithm is.",
            "An well, not exactly a little bit more precise even we know how we come from these classifiers to distributions.",
            "So we proved this both for the full basin algorithm and for the base in maximum posteriori algorithm.",
            "In this talk I'll concentrate on the full base.",
            "So what is what is full base?",
            "Anne works like this for."
        ],
        [
            "You convert all your classifiers to a set of conditional distributions.",
            "Jeff showed you how to do then you get these distributions indexed by C. That's the original classifier.",
            "NB 10 You have a prior on those and now you just use Bayes rule.",
            "To come up with a posterior.",
            "Right, so this is just prior times probability of data given prior.",
            "And this is the integral overall parameters.",
            "This is just based on marginal probability of the data.",
            "You get a posterior of the parameters given the sample.",
            "This sample is just the first MX in the first time wise together is S. So this is how you start to fear from the posterior.",
            "You can compute the predictive distribution.",
            "So this is if you.",
            "Have the posterior.",
            "Now you get a new xvalue.",
            "What's the probability of the Y value?",
            "According to base, that's you get it by averaging.",
            "The probabilities according to each conditional distribution according to your district, your posterior.",
            "So you average according to the posterior weights where things which had small loss on your trading sample will now get a large weight.",
            "And they will dominate you hope.",
            "The average, so the predicted distribution of the new Wi-Fi you're given X just the average.",
            "Over I see I made a mistake here the prior should.",
            "Should be gone here.",
            "Price should be at.",
            "It's just the average over the posterior.",
            "Of the probability according to the distribution of the next Y given XX.",
            "So now you have the predictive distribution and now you do the decision.",
            "That would be the base optimal decision if this were the distribution of the data.",
            "So if the probability that next, why is 1 given next X value is smaller than 1/2 you predict 0?",
            "Slide in one.",
            "Have you predict one?",
            "And if it's one, have you ever you toss a fair coin?",
            "To decide your prediction, and this is the base algorithm.",
            "So based on a simple S in a prior Pi, you get this predictive distribution and you use that for every new X value to get a prediction of the new I failure.",
            "So now how does it work?",
            "How do we get our result?",
            "So.",
            "We have to define feet."
        ],
        [
            "Space.",
            "And set of classifiers and the true distribution in the prior to make everything well defined.",
            "So first the feature space will have."
        ],
        [
            "XB affector with countably infinite number of components, all of which are either minus one or one.",
            "So X is X sub zero X one X2 etc.",
            "Or set of classifiers is also countably infinite.",
            "See sub zero C sub one season 2 etc.",
            "And it's defined it's very easily defined.",
            "Each classifier only listens to 1 feature.",
            "So the classifier say subject of X is just what the J feature says.",
            "So every classifier just OK these features is 1.",
            "Then I predict one I don't look at what the rest day.",
            "Now we need a prior over these classifiers.",
            "And basically our prior needs to decay slowly.",
            "That's essential, so we fix some small Alpha will later see exactly what Alpha and we make a prior such that the prior of classifier CCV is larger than 1 / N to the one plus Alpha.",
            "Note for A0 this is impossible.",
            "Because you would diverge because the series 1 / N diverges, but for every L far larger than zero you can make such a prior.",
            "The prior on beta can be any smooth prior.",
            "It can also be in that will be become important in the analysis.",
            "We can also take a discrete prior, let's say prior on all rational numbers that will also work, not you can describe a rational number by describing 2 numbers, so it's easy to see that you.",
            "Have a prior which gives rational more P / Q gets prior probability approximately 1 / P ^2 * 1 / Q ^2 so prior like that would also work and then you get a probability mass function here.",
            "So now how do we define a true distribution?",
            "Now it gets interesting.",
            "So we somehow have to come up with a true distribution that will serve to confuse base so that it doesn't converge, or does something strange.",
            "So what are we going to do?"
        ],
        [
            "Well, for each, each time we generate an example, we generate them ID, so we always do the same thing.",
            "We first as a fair coin to determine the value of Y.",
            "So what has to be predicted is even minus one or one of probably want to have.",
            "So now we trust another coin.",
            "With the bias 0.6 by Zero Point 6 will see in a moment.",
            "Anne, this coin determines whether the example will be easy or hard.",
            "So there are two types of examples.",
            "There's easy example.",
            "An easy example is very simple because then all classifiers will correctly predict why.",
            "So if you have an easy for example, then we set all X values equal to Y.",
            "If we have a hard example, then it's a bit different than X sub zero.",
            "So the first feature corresponding to the first classifier on our list will still be informative of why it will give you the right prediction with probability 2/3.",
            "But all other classifiers will say something random.",
            "They will just say XY with probability 1/2 and minus my otherwise.",
            "But importantly, they all do this in dependently.",
            "So they are not informative of why.",
            "If you have a hard example but also not of each other.",
            "If you know what one classifier predicts, you still don't know what the other predicts.",
            "Note that in this way we defined a joint distribution over X * Y.",
            "We begin with the distribution of Y, and here we defined the conditional distribution of X given Y.",
            "And if you do it this way, then you get of course that every feature on average tells you something about why."
        ],
        [
            "Because with probability, what was at 0.6 zero point 6, you get an easy example and then every feature says what, why is.",
            "But X zero is more informative than all the others because it's the only one which is still informative.",
            "If you have a hard example.",
            "So C sub zero which just outputs except here is the best classifier is if you calculate it with these numbers it has generalization or 0.2.",
            "So it makes a mistake 20% of the time.",
            "And all the others have generalization error.",
            "Zero point 3.",
            "Make a mistake 30% of the time.",
            "And still now it turns out.",
            "So now we've defined basically everything we have a prior over these classifiers and over beta so we know what the how the base algorithm works.",
            "We know the true distribution and we can now show that in this scenario with probability one.",
            "The classifier with maximum posterior probability.",
            "So this is the base and posterior given the sample.",
            "Of classifier J, the thing which maximizes the probability goes to Infinity.",
            "So basically base does not converge.",
            "No matter how much data you get, if you get more data.",
            "Then your posterior will concentrate classifiers with higher indices, so you keep going on the right and from the right on your list.",
            "You can show that.",
            "The probability of the classifier want to learn this is the right classifier, right?",
            "It's the best one.",
            "It has error zero, point 2, so this is what you want to converge to.",
            "Posterior probability of this classifier given the sample.",
            "Divided by the maximum posterior is exponentially small.",
            "So this order is smaller than some comes to the minus some constant Times Square root of M. So this means that the Bayesian maximum, a posterior algorithm which simply copies the classifier which has the highest posterior probability.",
            "Will always pick a bad one.",
            "Now a more involved analysis showed that actually.",
            "But you can more or less already see it here.",
            "That if you look at.",
            "The posterior weight of this classifier will be, so will be exponentially larger than the posterior weight on this one.",
            "So if you make predictions, then this classifier which maximizes will dominate this one completely, so the predictions you make will be the predictions that are optimal.",
            "According to this one and not this one.",
            "So therefore you make what base does is synthetically is achieved this generalization error.",
            "There is a complication because of course base doesn't put all its mass on one classifier.",
            "It may have like the posterior is as gifts, large mass to a set of classifiers.",
            "But if you do more involved analysis, you can show that for all the classifiers in which there are substantial posterior probability.",
            "Anne.",
            "Like you must have this for all these classifiers, so this one is can be completely neglected, neglected if you mix over the posterior.",
            "You only mix with things with much higher posterior probability.",
            "And those things the way they are defined.",
            "If you make a mix between if you have a mixture of them, you cannot classify better than with any single one of them 'cause you either have an easy example, then they're all OK, or you have a hard example.",
            "In the hard example, they're all random, so if you mix them you get something which is still completely random, but you can if you mix two things which predict why is one with probability 1/2 independently.",
            "Then the result of mixing those distribution can never be.",
            "A distribution with which predicts why correctly with probability larger than 1/2.",
            "It's impossible, so therefore even if you mix over the posterior, you cannot get better than this, so base converges to classifier with probability of error zero point 3.",
            "They should know that for each fixed.",
            "Classifier, which is not the optimal one.",
            "The.",
            "Posterior ratio.",
            "In the end, the best one does win.",
            "Battle of large numbers this thing.",
            "This thing is E 2 to some constant times to 01 error you make on the sample with the best classifier and this is equal to 01 error on the sample time.",
            "Some worst classifier.",
            "So by the law of large numbers this ratio will be exponentially large in favor of this one.",
            "But the problem is that this doesn't go.",
            "This doesn't happen fast enough.",
            "This happens for each fixed J.",
            "So if I take any fixed.",
            "Number from one 2K, let's say.",
            "And look at all classifiers in that sets, then the posterior within that set will converge to the optimal distribution.",
            "But as you make it set larger then of course because the prior decreases, you get basically intuitively the things get more and more complex, you get smaller smaller prior and therefore they are punished more and more in the basin posterior, but they're not punished enough.",
            "And therefore still, if you look at the whole thing, the infinite number of classifiers.",
            "Caesar always loses.",
            "Yeah, but it's it's essential.",
            "And then you can see that by balance out, yeah, yeah.",
            "Yeah, but the so the numbers I have here are not true for any Alpha.",
            "Because if Alpha goes to Infinity, basically your prior decreases faster and faster.",
            "And then the difference you can achieve by tweaking these parameters, like what is the probability of a hard example and so on.",
            "It gets smaller and smaller.",
            "So in the limit for Alpha to Infinity, the if you look at the.",
            "See if you look at the theorem again.",
            "The maximum K."
        ],
        [
            "You can achieve here depends on Alpha.",
            "But for every Alpha.",
            "Every finite Alpha is larger than 0.",
            "And you maximize it by taking the.",
            "By taking Elfina limit to 0.",
            "Slower your priority case, the less you punish things.",
            "With a large index and the more you overfit basically.",
            "So that's what overfitting means here.",
            "Table.",
            "Easy and party.",
            "One would have to use them.",
            "They don't."
        ],
        [
            "Creating differentiation.",
            "Ann, they are needed to play.",
            "We will come to that in a moment.",
            "There needed to play around with the problem because we want to look at what is the best value of K we can get.",
            "How much, how bad can base become?",
            "And it turns out that if you want to make basically have really bad, you need to have this as well.",
            "Basically, if you don't have easy examples, then based never performs then.",
            "This all classifiers except the first one never perform better than randomly.",
            "Right so then Abasin might tell you like look, this is a crazy problem.",
            "You'll never meet a problem.",
            "Practice where there's one classifier which performs well and all the others are like random guessing.",
            "So we want to say what we will also want to look at the case.",
            "What happens if all classifiers are reasonably good?",
            "Read by changing the probability of Z is 1.",
            "We can make all classifiers behave quite well, but still see zero behave better than the others an, but we'll see that in a moment.",
            "We want to know under what conditions on the classifiers we can get a result like this and therefore we need to play.",
            "We need to look at the case.",
            "Where the best classifiers are still quite good.",
            "Um?",
            "So now I'm coming to that actually.",
            "So if you look at the theorem more detail I didn't specify."
        ],
        [
            "Fight in full but.",
            "Then the following happens so.",
            "By varying the spread this parameter, what's the probability of hard example?",
            "You can, and also by varying the probability of how good the sub zero the one good classifier is.",
            "If you have a hard example, you can vary the promise.",
            "I said the generalization error the best classifier, so expect it to one of the thing you want to learn varies from anything between 0 and 1/2.",
            "That's why we need this, and then we want to look at.",
            "But how bad can be made based misbehave if we vary that probability of the best classifier and the other classifiers.",
            "Now it turns out.",
            "That's so if you look if you have the base in maximum security MDL algorithm.",
            "The curve.",
            "You get how bad the algorithm can get.",
            "Looks like this, so that's.",
            "A consistent learning algorithm which asymptotically learns the best classifier.",
            "This line is a straight line from zero to 0.5 in here.",
            "Also zero to 0.5.",
            "This line indicates.",
            "If you have asymptotical, if you have asymptotically many data and you have a consistent algorithm, what your generalization error will be.",
            "If the classifier learn it will be as good as the best classifier your model.",
            "So this is the best you can do within your model.",
            "If you use the base or MDL algorithm, you can overshoot by this.",
            "With our construction, so this means that if the true distribution is the.",
            "C Sub zero has 0 error.",
            "It's a perfect classifier.",
            "Then actually you are also.",
            "You then base will also be good base will not be inconsistent.",
            "The problem only starts when this moves away from zero when the optimal classifier is a small error, but then it goes up very quickly because these both of these curves have an infinite derivative at 0.",
            "And the base map algorithm actually comes back again.",
            "So if optimal classifier has generalization error close to 1/2 so close to random guessing.",
            "Then there's not much difference anymore between base and consistent algorithms, but.",
            "If you look at full base and this is interesting, is normally full based, people will say it's better than based on maximal pursuer, but in this case it's actually worse.",
            "Watching Spencer's in detail that was that's full base.",
            "Yeah yeah, so full basis, it's more Bashan.",
            "You don't just take the maximum you average over all things according to your posterior.",
            "You can by tweaking these parameters you can make base.",
            "Have generalization error all the way up to one so it starts at this point.",
            "Where is it?",
            "About 0.1 this means that I can set up the problem in a way such that C sub zero.",
            "The best classifier has a generalization error of zero point 12.",
            "Not very large, 88% correct and base starts performing worse than random guessing.",
            "No matter how much data you have.",
            "Um?",
            "So how is this possible?"
        ],
        [
            "Maybe I should give you a little clue.",
            "I'm not going to give you the proof, but I'm going to give you.",
            "Little Chris, I go back to the construction.",
            "Basically, I didn't tell you the whole story here."
        ],
        [
            "I sit here if you have a hard example.",
            "Then the classifiers are set equal to the wife value.",
            "The bad classifiers with probability 1/2.",
            "Actually, if you do it this way then base will never perform worse than random guessing.",
            "But what you can do is make them equal to this value with probability 1/2 minus Delta for some very small Delta.",
            "So this means that all these classifiers are slightly worse than random guessing just ever so slightly worse.",
            "But they all make their probability, their predictions independently.",
            "So now we're based.",
            "Thus is based concentrates on the bad classifier, so it forgets about the thing which works well for the hard examples.",
            "And if you have a hard example, what it does is it's posteriors, a mixture of things, all of which predict slightly worse than random.",
            "Then randomly, independently.",
            "So if you have some.",
            "IID sample.",
            "Of things which have a probability of different probability wise, one is 1/2 minus Delta.",
            "An all these probabilities are independent.",
            "Then you average over them.",
            "That actually your average will be.",
            "You will make the wrong prediction with probability tending to one.",
            "Because you have lots of things which have a probability of saying one.",
            "If the answer should be when this one with slightly larger than one half 1/2 plus Delta, but they're all independent.",
            "So you average over all of them.",
            "Is it more and more?",
            "Yeah, yeah yeah.",
            "And because that happens.",
            "And that was actually, that's not in our paper with John Langford.",
            "I proved that later it was very tough to prove it, but you can.",
            "It's exactly that's what happens.",
            "Your posterior gets.",
            "Flatter and flatter, it spreads out over like something like log off the sample size number of classifiers it has about equal posterior.",
            "And yeah, because they all make a mistake with this slide, probably slightly larger than 1/2 and they make the mistake independently.",
            "Your posterior will always guess the wrong thing.",
            "So.",
            "I have 15 minutes.",
            "That's OK, yeah?",
            "Um?",
            "So let me.",
            "Yeah, I kind of let me not let me go through this.",
            "How bad can base get?",
            "And we'll see whether this time for the rest.",
            "Because we have."
        ],
        [
            "The theorem.",
            "Yeah, I just wonder why using the word bad, because I mean if you detect that your classifier is misclassified, you just big decision and you are perfect and perfect classifiers, so right?",
            "What do you mean?",
            "And you know that it's actually misclassifying field Alpha.",
            "Yeah, that is true, so anyway OK, but that well I can, but I can change my problem so that it goes like this.",
            "And then I would say.",
            "Yes, you have.",
            "You have a good point.",
            "There's a yeah in a way, in a way base is very good yeah, But if you follow base without making any changes it is bad.",
            "You have to make.",
            "Yeah, in practice it's good.",
            "Yeah, but the problem is not practical.",
            "Anyway.",
            "The point here is not to show that this is happened, but it happens in practice with the community.",
            "They say it's not the right thing to do.",
            "Anyway, but I mean you definitely have a point, it's true.",
            "So our second theorem says that this curve is in a way tight, so this is what we can get with our problem by tweaking the parameters.",
            "But it turns out that their base can never still keep using the words.",
            "This apologies base can never get worse in this, no matter how your true distribution.",
            "How your set of classifiers looks, likes look, look like.",
            "So our problem is what we showed here is actually the worst that can happen with base.",
            "Anne.",
            "So how does this work?",
            "I'm going to explain it now.",
            "So first the definition.",
            "So S soup.",
            "I is the sample."
        ],
        [
            "Outcome ice and then we have the following theorem.",
            "If I have an arbitrary set of countable classifiers.",
            "And arbitrary prior.",
            "On them.",
            "And I have an arbitrary true distribution.",
            "Such that the best classifier in the set has error mu.",
            "And you can be anything between 0 and 1/2, so I should have also said for all meal you feel free to choose it.",
            "Then basically what will happen with probability tending to one according to the true distribution.",
            "Is that on the?",
            "Sample you actually get.",
            "The classification error made by base based on the past.",
            "If you sum that overall outcomes.",
            "Then this will be smaller than the entropy of mu plus Delta for all Delta larger than zero, and HST binary entropy.",
            "Some user number between zero and 1/2, so it has a well defined this entropy for Bernoulli random variable with that bias.",
            "And you can show that the average error of base over the sample.",
            "Bill with probability almost one.",
            "It's 1 minus something exponentially small.",
            "Is smaller equal in this entropy?",
            "So we are not able to show that the generalization error of base the classification risk is bounded by this.",
            "We are only to show some different weaker property that the average error you make if you actually use base for prediction on an actual sample with very high probability be smaller than this, so it's not exactly the same thing.",
            "But this is the thing we could prove.",
            "But notice that."
        ],
        [
            "This is exactly the same function.",
            "As this function, so this is we can go we can achieve this closest we want from below in terms of generalization error of the basin algorithm.",
            "So how do you prove Theorem 2 actually, for people who know about prediction of individual sequences, it's very straightforward.",
            "Anne.",
            "First of all, you notice that if you have a seat."
        ],
        [
            "Points of M outcomes.",
            "And now you use the basin algorithm for prediction with respect to log loss.",
            "So for each point in time you look at the base and predictive distribution.",
            "I call this piece of bread before given the sample in the past, the new X value prediction of the new wife value and you look at the log squared minus log probability of the outcome.",
            "You some that overall outcomes.",
            "So this is the individual prediction error.",
            "If you do sequential prediction based on what you've seen in the past, the next outcome you see the next outcome you condition on that as well predict next when you add the errors.",
            "So every time.",
            "The Bayesian classifier makes a mistake.",
            "You must have seen a white value which had probability smaller than 1/2 according to the basin prediction algorithm, right?",
            "Otherwise you would have predicted correctly, this is binary logarithm, so every time base makes a mistake in a 01 sense, if you're minus lock something smaller than 1/2, so that's something larger or equal than one.",
            "So this means that every time base made a prediction mistake, this thing must have been larger than one.",
            "So this accumulated log loss is larger equal in accumulated 01 loss of the basic classifier.",
            "So this gives you this bound situation.",
            "01 loss in terms of the log loss.",
            "But the log loss of the basic classifier is bounded by the log loss of the best.",
            "See.",
            "Plus something which is logarithmic in the sample size.",
            "And that is, it's actually.",
            "It's a very standard thing based on prediction.",
            "Why did so?",
            "If you look?"
        ],
        [
            "The basin log loss.",
            "You can rewrite it as follows first, because all distributions are conditional, you put all the X values in the right of the commissioning bar like this.",
            "So now you can use the chain rule to rewrite this.",
            "So this sum becomes first product.",
            "Now use the chain rule of probability distributions to right.",
            "This is the probability for the whole sequence, because this is just a product of conditional probabilities by the definition of conditional probabilities that look like this if you write out the product and everything cancels except the very last term with ice equal to M and you get this.",
            "So this summer from algorithmic prediction errors.",
            "It's just the minus log marginal probability of the whole sequence of wise given X.",
            "Now.",
            "This is the base and marginal probability.",
            "So now for convenience I use a discrete prior.",
            "I use a prior which is overall rational valued B test.",
            "Then it will work.",
            "So this is the base and some of the probability according to the classifier and beta according to the prior on the Classroom, beta summed over all classifiers and beat us.",
            "That's just the definition of this.",
            "So because the sum is larger than each of its terms.",
            "The minus log of the summer smaller than the minus log of each of these terms.",
            "So in particular this.",
            "Smaller than the minus log of the probability you would have obtained.",
            "With the optimal classifier.",
            "And the beta, which is optimized for your sample.",
            "Now, if you choose this prior in a clever way, then.",
            "This beta will have a prior probability logarithmically in the sample size.",
            "And this thing has a prior probability which is a constant because you have a countable set of classifiers, every single classifier is a constant prior probability.",
            "This means that the sum of the logarithm prediction errors of base is bounded by.",
            "The minus log likelihood of the best classifier which is equal to the sum of the logarithm prediction errors of the best classifier and the best pizza.",
            "Plus something logarithmic.",
            "Or is this will typically be linear.",
            "So basically what this says is what people in prediction know that for prediction."
        ],
        [
            "This is always pretty good.",
            "An in all sequences because.",
            "The prediction of the base in terms of log loss.",
            "Because base always bases never much worse than any individual predictor.",
            "Because the sum is always larger than each of its terms.",
            "So now you have two bounds here.",
            "You know that the base and lock predictions bound the 01 sum of 01 losses.",
            "And you know that they are themselves bounded by this minus log likelihood, according to the best classifier.",
            "No, because we generate data IID.",
            "This is a log likelihood.",
            "Anne."
        ],
        [
            "Often iid.",
            "According to an IID distribution, so it will converge to its expectation.",
            "The expectation of this is just the expectation of a Bernie distribution CAS for fixed classifier.",
            "If you would fix beta.",
            "This would just be a binary distribution.",
            "Basically, beta determines the probability that Y is not equal to X.",
            "So if you take the expectation of this, this will approximately equal to M times the expected.",
            "Minus log probability according to ability distribution, which is the entropy for any distribution.",
            "And then you have to be careful.",
            "Look at what happens with this beta, but it turns out that this is equal to this plus, well, it's the usual order square root of M, right?",
            "If you divide by M converges.",
            "So this means that if you divide this by M. You can also divide this by M, so then you get the total number of classification errors you make with base is bounded by the entropy.",
            "Plus something which goes to 0.",
            "So there's something."
        ],
        [
            "Age here.",
            "We showed here that the accumulated log loss.",
            "If you predict with base.",
            "It's always close to the log loss of the optimal.",
            "Think this is optimal, both in the sense of.",
            "Expected lock Lawson and sense of expected 01 loss.",
            "So base is good with respect to log loss and this even if the true distribution is is far removed from your set of distribution.",
            "But on the other hand base, that's our main theorem shows base can be bad with respect to 01 loss, you converge to something which is.",
            "Which is much worse 01 loss than the optimal classifier.",
            "So how is this possible?",
            "Well?",
            "Basically what happens is everything basis.",
            "You get more and more data.",
            "The posterior is a mix of bad classifiers.",
            "And it turns out that if you mix these bad classifiers, you get a probability distribution which is closer in callback library vergence to the true distribution.",
            "Then the best distribution in your model.",
            "But in terms of 01, loss is actually much worse.",
            "Then the.",
            "Best distribution in your model.",
            "So this is in a way, a strange thing.",
            "Based always is good with respect to log loss, but because it is so good with respect to log loss, it actually starts making better predictions than the best thing inside your model.",
            "And because it makes better predictions in the best thing in your model.",
            "It screws up in terms of the 01 loss.",
            "So you can actually prove that, yeah.",
            "Sorry.",
            "So think of these what I said.",
            "You have these for these hard examples.",
            "Uh, these features predict the value of wiker correctly with probability 1/2 minus Delta.",
            "They take a mixture of many of those probability distributions.",
            "Yeah.",
            "So this mixture will still have that the probability that Y is one will be very close to 1/2.",
            "So in terms of low class it will not be so bad.",
            "But on the other hand.",
            "If you take the base act with respect to the distribution, it will always err on the wrong side, so it will be if you have something very close so you have a mixture of things which they probably why is 1/2.",
            "Then the low class is guaranteed to be one whether the outcome is zero or one is minus.",
            "Log 1/2 is 1, but if the air on the wrong side of 1/2.",
            "Then the 01 loss can always be one because.",
            "Log loss loss is smooth, near 1/2 and 01 losses is not differentiable.",
            "So it turns out you can even showed for say you have an arbitrary set of IID distributions.",
            "And you have a prior on those which satisfy some very weak conditions.",
            "You're not going to go into.",
            "You can show that the only way."
        ],
        [
            "In which base cannot converge to the distribution that's closest in KL divergent to the true distribution?",
            "Is if the posterior predictive becomes closer than the best single distribution so?",
            "There are two possibilities.",
            "Either.",
            "The base and posterior if you use it.",
            "If you look at the callback library, diversions between the true distribution and the base and posterior.",
            "Either that.",
            "Either the base and posterior converges puts all its mess on the best distribution in your model.",
            "So you have consistency.",
            "Or it becomes a mixture of different distributions which are all worse.",
            "But in that case the mixture must be better than the best distribution in your model.",
            "So the only way in which base can be inconsistent.",
            "Is by having the posterior.",
            "Not converging to any single thing in your model, but becoming a mixture of things where the mixture is better.",
            "Then the best thing in your model.",
            "Sis.",
            "So.",
            "One more thing like how is this related to base income?"
        ],
        [
            "This is the result.",
            "Suppose you have a countable set of conditional distributions and containing the true conditional distribution.",
            "Then you can show this is well known.",
            "A basic consistency theorem that the Bayesian posterior predictive distribution must converge.",
            "The true distribution, for example, in terms of Challenger distance.",
            "Slightly simplified here, it's if some conditions on the prior.",
            "And if you have reconvergence in there, there are no no further conditions at all, just holds.",
            "Anne."
        ],
        [
            "So.",
            "If.",
            "The base predictive distribution converges to the true conditional distribution.",
            "Of course, if you use the distribution for classification.",
            "So you take the base optimal classifier with respect to your posterior.",
            "Then the generalization error of that thing must converge to the best achievable class generalization error to the base act.",
            "Compare relative to the true distribution.",
            "But in our in our case, this doesn't happen.",
            "We have base base.",
            "In our case, the basin algorithm, the basic posterior.",
            "Predictive distribution converges goes to something which does not achieve the optimal classification error.",
            "So it seems to be.",
            "It seems to contradict Dupps consistency theorem.",
            "And the reason it doesn't is because we have misspecification.",
            "And basically what happens is that the way we set up our distribution.",
            "We have our model assumes homoskedastic noise.",
            "So basically, each classifier C expresses that Y is equal to CX and CX.",
            "Maybe flip with probability independent of X.",
            "But the way we construct AD.",
            "If you have one classifier, it only listens to a particular component of the X vector and the other exact knowledge of the other X factors actually changes the probability that the classification is right.",
            "So reality the noise depends on The X Factor.",
            "So the true distributions heteroskedastic.",
            "So therefore we have misspecification.",
            "True distribution is not in the model we constructed, and therefore we have inconsistency.",
            "We can have inconsistency.",
            "Note, however, that we do have.",
            "The base X in our model, so we have the set of distributions do not contain the true distribution, but the set of classifiers we started with.",
            "Does contain the base optimal classifier with respect to the true distribution?",
            "So in basic textbooks."
        ],
        [
            "You often find that if you've misspecification based, still works in the sense that you converge to the distribution in your model which is closest in Cape Colbeck library versions to the true distribution.",
            "The way we set with this logistic transformation, the way we transform classifiers to distributions.",
            "Can we make sure that the thing closest in KL divergent to the true distribution in R model is actually a thing with the smallest classification error?",
            "Anne.",
            "So this means that these claims that base converges under misspecification to the distribution in your model closest in KL divergences.",
            "True distribution is we have a counterexample to that.",
            "It just doesn't happen here.",
            "Because the distribution corresponding to each subject to see sub zero, the best classifier is the closest OK leverage and we do not converge to it.",
            "So if you look at the literature, the precise theorems you indeed see that the conditions for consistency under special."
        ],
        [
            "Vacation are actually much, much stronger than the conditions for standard consistency.",
            "Basically, on a misspecification, your model must either be finite dimensional parametric and then of course most methods will converge in the end.",
            "So maybe not so interesting.",
            "Or it must be convex?",
            "For example, if your model is the set of all Gaussian distributions or mixtures of Gaussians with fixed variance in an arbitrary number of convert of components, it's not parametric if arbitrating many components, but it's convex.",
            "And then you do converge to the closest in KL Divergent.",
            "And intuitively the reason for that is.",
            "That the base and posterior predictive distribution is a mixture of distributions in your model.",
            "If your model is convex, then the basin predictive distribution is always in your model, so you can never get this phenomenon.",
            "I talk to you about that.",
            "The base in predictive distribution is better than the best distribution in your model, right?",
            "It can never be better because it's in your model.",
            "And similarly, if.",
            "The model contains the true distribution and also the basin predicted distribution can never be better than the best distribution model because there is no distribution.",
            "Better model.",
            "That is what you need for basic consistency that by mixing your model you can obtain something better.",
            "Then what is in your model?",
            "So I guess that's all I wanted to tell you.",
            "So.",
            "Showed that."
        ],
        [
            "Admittedly a very unrealistic problem, but the point is mainly to see that it can happen.",
            "Just under wells face, it cannot happen.",
            "Base can be inconsistent.",
            "You might argue that basic machinery was never used, intended to use for misspecified models.",
            "But of course I would claim that in practice it is done all the time.",
            "Still, I don't want this to be.",
            "Don't take this as don't use base.",
            "I think in many practical problems Basics Basin methods are among the very best methods there are.",
            "But claims that it is always the optimal thing to do I think are.",
            "Shown by this examples and actually there are so many others earlier appeared in the literature.",
            "Make sure that it's not as easy as that, so thank you.",
            "So.",
            "The structure of adding up.",
            "Actual 01 losses.",
            "If you if you take that as the criterion capital, what is the what is the Bayes rule which would actually minimize that?",
            "But I can control theory.",
            "They had a great deviations overtime so that they have something for the offer.",
            "Here directly fully.",
            "Well, The thing is you need in order to do that.",
            "You can interpret this is doing just that.",
            "If you start out with if you start out with a set of conditional distributions and you have a prior on those, then you have a marginal distribution.",
            "And then you can try to do this, but then you will do exactly the same as we do.",
            "I didn't talk about that, it is yeah, but The thing is is.",
            "But I had a preliminary step by first constructed these distributions out of classifiers.",
            "Um?",
            "You gotta love someone so you could just dynamic program over actually do anything biopic one step ahead rule to minimize that.",
            "Whole thing.",
            "Is that So what do you think John?",
            "So you?",
            "Which forms well whenever you have.",
            "A priori classifiers encouraged.",
            "Minimizing open vision.",
            "That is.",
            "Think about having a varying month running direction for classifier depends upon the prior.",
            "Minimizes, it's about measuring.",
            "But that's.",
            "I would have to think about what you, what, what you would get then I guess I don't know whether you would get something completely different or not.",
            "Can't answer it right now.",
            "This type of standing."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yeah, so good afternoon everybody.",
                    "label": 0
                },
                {
                    "sent": "This is joint work with John Langford who is also here and he will talk to you tomorrow and it was first presented at the Cold 2004 and by now I've extended it a little bit, but that's part hasn't been published yet.",
                    "label": 1
                },
                {
                    "sent": "Will see that in a moment.",
                    "label": 0
                },
                {
                    "sent": "So what?",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We do here is we study Bayesian inference and minimum description length learning in classification problems.",
                    "label": 1
                },
                {
                    "sent": "Now based on minimum description length are often used in practice because they supposedly deal well with overfitting phenomenon.",
                    "label": 0
                },
                {
                    "sent": "When you have very large models, so that maximum likelihood will always lead you to overfit.",
                    "label": 1
                },
                {
                    "sent": "So we show that there exist classification domains were based on MDL perform suboptimally in the sense that they overfit and this holds even asymptotically no matter how much data you have.",
                    "label": 0
                },
                {
                    "sent": "Of course, there are many versions of Basin MDL, so we should immediately at the caveat when you apply them in a standard manner and what standard manner is, we will see in a moment.",
                    "label": 0
                },
                {
                    "sent": "So why should this be interesting?",
                    "label": 0
                },
                {
                    "sent": "Well, of course basic methods are used all the time.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Man, some people claim that you should always be using basic methods I guess.",
                    "label": 0
                },
                {
                    "sent": "This talk was meant for mixed computer science, based in audience originally against this audience.",
                    "label": 0
                },
                {
                    "sent": "There would not be so many people who would claim this, but still there are many people claim this, so it's interesting to see.",
                    "label": 0
                },
                {
                    "sent": "How they perform an for amneal methods?",
                    "label": 0
                },
                {
                    "sent": "It's even in a way the case that they have been designed for dealing with overfitting.",
                    "label": 1
                },
                {
                    "sent": "They model complexity as their starting point rather than a later at only analysis.",
                    "label": 0
                },
                {
                    "sent": "So then it's interesting to see that even these methods can overfit.",
                    "label": 0
                },
                {
                    "sent": "And then from a theoretical point of view, it's interesting because for Bashan, an actual so far meal methods they are very strong consistency results like Dupes Theorem or Blackwell Dubon theorem, so there seems to be some type of this in a way this might seem superficially impossible, so if you look at how it can be reconciled with the theory, we will get some new insights.",
                    "label": 1
                },
                {
                    "sent": "And just to give you some first idea, it turns out that we get the inconsistency here because we use a misspecified model.",
                    "label": 0
                },
                {
                    "sent": "So the true distribution is not in the model under consideration.",
                    "label": 0
                },
                {
                    "sent": "However, we can have distributions in the model under consideration that are arbitrarily close and callback library divergents to the true distribution, and still this will happen.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "1st going to say yeah.",
                    "label": 0
                },
                {
                    "sent": "But how you define?",
                    "label": 0
                },
                {
                    "sent": "Well, we will see this wait till I go to it's you're right it's not clear but.",
                    "label": 0
                },
                {
                    "sent": "But I'm going to show is that these methods are inconsistent in a certain sense and how it relates to overfitting L. Right, you will see it's kind of what you would intuitively call overfitting.",
                    "label": 0
                },
                {
                    "sent": "So first a little bit about classification, and then I'll give an abstract statement of the main result and that will raise a lot of questions.",
                    "label": 1
                },
                {
                    "sent": "So by filling in these questions I will get to a precise statement of the result, and then there will be discussion.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Classification as usual you have some feature space and label space, which here I take to be binary into B -- 1 one, so not 01.",
                    "label": 1
                },
                {
                    "sent": "It doesn't really matter, but that's just what I chose for this talk.",
                    "label": 0
                },
                {
                    "sent": "Sample it's important to always remember if I use capital S, it stands for the training sample.",
                    "label": 0
                },
                {
                    "sent": "The data you see on which you base your classifier.",
                    "label": 0
                },
                {
                    "sent": "And then we work with our model, will be a set of hypothesis which are in this case not probability distributions but classifiers.",
                    "label": 0
                },
                {
                    "sent": "So functions from X to Y.",
                    "label": 1
                },
                {
                    "sent": "And the goal is to find a classifier that generalizes well.",
                    "label": 0
                },
                {
                    "sent": "So this is your training sample.",
                    "label": 0
                },
                {
                    "sent": "Based on this, you try to find a classifier in here, or maybe some somebody, a combination of classifiers.",
                    "label": 0
                },
                {
                    "sent": "In here you use it to make predictions of future values given future X values, and you hope that the probability of making a mistake there is small that you find that classifier with a small expected 01 error or generalization error.",
                    "label": 0
                },
                {
                    "sent": "I'll define it precisely in a moment.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So note that I define classifiers as functions from the feature input space to minus one one, so these are hard classifiers like decision trees.",
                    "label": 1
                },
                {
                    "sent": "Of course, in practice you much more often deal with soft classifiers like support vector machines with real valued output or probabilistic classifiers like naive base or base network classifiers or logistic regression which are just conditional distributions of Y given X, which you first infer from your data, and then you use those to find decisions for Y.",
                    "label": 1
                },
                {
                    "sent": "Given XI will go to these later, but The thing is best explained remains easiest if you use these hard classifiers.",
                    "label": 0
                },
                {
                    "sent": "Um so.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We say we want to find a classifier which generalizes well.",
                    "label": 1
                },
                {
                    "sent": "We measure that in a way which is usual in the statistical learning.",
                    "label": 0
                },
                {
                    "sent": "Community, we assume there is some distribution on the joint.",
                    "label": 0
                },
                {
                    "sent": "Feature label space, and we assume the data are IID according to the distribution.",
                    "label": 0
                },
                {
                    "sent": "We'll call it.",
                    "label": 0
                },
                {
                    "sent": "D is distribution.",
                    "label": 0
                },
                {
                    "sent": "And if you take fixed classifier then your measures performance by zero one loss.",
                    "label": 0
                },
                {
                    "sent": "And so it's generalization errors, and actually it's classic or classification risk is the expected 01 last expected difference between Y.",
                    "label": 1
                },
                {
                    "sent": "And the prediction of Y made by the classifier.",
                    "label": 0
                },
                {
                    "sent": "So this is either two or minus two, so divided by two.",
                    "label": 0
                },
                {
                    "sent": "And this is of course equal to the probability that your classifier makes a mistake, just the misclassification probability.",
                    "label": 0
                },
                {
                    "sent": "The smaller that is, the better we say, is the classifier with respect to the underlying distribution.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the next thing we have to define is learning algorithms.",
                    "label": 0
                },
                {
                    "sent": "So we will talk about the result which holds for a variety of learning algorithms, including the base in algorithm or the minimum description of the algorithm.",
                    "label": 0
                },
                {
                    "sent": "So learning algorithm is just about a statistician would call an estimator.",
                    "label": 0
                },
                {
                    "sent": "And for each sample of arbitrary length, you can put that sample into the algorithm as an input, and the output is a classifier which can be used to classify the next wife value given the next X value.",
                    "label": 1
                },
                {
                    "sent": "Now we call a learning algorithm consistent.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now we're moving closer to our result.",
                    "label": 0
                },
                {
                    "sent": "If the following holds, so we get a sample, we get more and more data according to distribution D IID.",
                    "label": 0
                },
                {
                    "sent": "We say the algorithm is consistent or asymptotically optimal.",
                    "label": 1
                },
                {
                    "sent": "Facebook.",
                    "label": 1
                },
                {
                    "sent": "No matter what this D is.",
                    "label": 0
                },
                {
                    "sent": "Given enough data.",
                    "label": 0
                },
                {
                    "sent": "The classifier your algorithm learns from the data, so this is the input S sample of length M. It outputs a classifier.",
                    "label": 0
                },
                {
                    "sent": "Then you can look at what is the expected 01 loss, the classification risk of the classifier and that should converge to the minimum achievable within your class.",
                    "label": 0
                },
                {
                    "sent": "So it might be that your class is very silly for the true distribution, and none of the classifiers will give you good predictions.",
                    "label": 0
                },
                {
                    "sent": "That doesn't matter what we will.",
                    "label": 0
                },
                {
                    "sent": "What we want that no matter what distribution you have, you always find the best within your class.",
                    "label": 0
                },
                {
                    "sent": "Right, so you learn the best thing that is to be learned from the model set of classifiers you started with, and this should hold for example with probability one or in expectation or D probability.",
                    "label": 0
                },
                {
                    "sent": "There various variations of this.",
                    "label": 0
                },
                {
                    "sent": "It's clearly an ologist to ordinary statistical consistency.",
                    "label": 0
                },
                {
                    "sent": "So again, on the left is what you learn.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "From your data and you look at how well will it perform in the future data from the same distribution and on the right is the best thing you can do with the model with your model assumptions.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now I have all the ingredients for main result.",
                    "label": 1
                },
                {
                    "sent": "Still stated very abstractly here, without any.",
                    "label": 0
                },
                {
                    "sent": "Numerical values.",
                    "label": 0
                },
                {
                    "sent": "So there exists some input domain X.",
                    "label": 1
                },
                {
                    "sent": "Then there exist some prior.",
                    "label": 1
                },
                {
                    "sent": "Which is just a probability distribution.",
                    "label": 0
                },
                {
                    "sent": "With support, accountable sets of classifiers functions from X to minus one one.",
                    "label": 1
                },
                {
                    "sent": "There is some true distribution.",
                    "label": 0
                },
                {
                    "sent": "And there is some constant K larger than 0.",
                    "label": 0
                },
                {
                    "sent": "Such that the base in learning algorithm which I'll define in the moment and the base in learning algorithm depends on the prior for different priors becomes a different algorithm.",
                    "label": 1
                },
                {
                    "sent": "And of course, it depends on the sample.",
                    "label": 0
                },
                {
                    "sent": "That's the input to the algorithm, input sample and outcomes.",
                    "label": 1
                },
                {
                    "sent": "A classifier for classifying the next outcome.",
                    "label": 0
                },
                {
                    "sent": "So there are some prior and some domain.",
                    "label": 0
                },
                {
                    "sent": "Some true distributions such that the probability.",
                    "label": 0
                },
                {
                    "sent": "That the Bayesian classifier classifier selected by the basin algorithm has expected loss 01 risk.",
                    "label": 0
                },
                {
                    "sent": "Larger than the best you can obtain within your class.",
                    "label": 0
                },
                {
                    "sent": "Plus this constant K which is larger than zero, is 1.",
                    "label": 0
                },
                {
                    "sent": "So what will happen is if you get more and more data base will not converge to the best classifier.",
                    "label": 0
                },
                {
                    "sent": "It will keep out putting a classifier which is sub optimal.",
                    "label": 0
                },
                {
                    "sent": "There is a classifier in your class which if you would know that classifier you could make better predictions.",
                    "label": 0
                },
                {
                    "sent": "That's what we prove.",
                    "label": 0
                },
                {
                    "sent": "Of course, to make this precise, there are lots of things.",
                    "label": 0
                },
                {
                    "sent": "I have to make more precisely like what is the prior artists K. What is the true distribution?",
                    "label": 0
                },
                {
                    "sent": "And first of all.",
                    "label": 0
                },
                {
                    "sent": "I have to make precise what is the base in algorithm.",
                    "label": 0
                },
                {
                    "sent": "But I would like to is this clear in an abstract way what I'm?",
                    "label": 0
                },
                {
                    "sent": "Saying here.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 1
                },
                {
                    "sent": "You first.",
                    "label": 0
                },
                {
                    "sent": "Does the prior, depending on the size of us, know?",
                    "label": 0
                },
                {
                    "sent": "But we are being real basins here, so we are not allowed to have the prior.",
                    "label": 0
                },
                {
                    "sent": "Depends on the size of S. Because the real basin would claim that.",
                    "label": 0
                },
                {
                    "sent": "Even then, you don't get the priors fixed once and for all.",
                    "label": 0
                },
                {
                    "sent": "What happens when you turn out to be Asians?",
                    "label": 0
                },
                {
                    "sent": "It depends.",
                    "label": 0
                },
                {
                    "sent": "I'll get back to that.",
                    "label": 0
                },
                {
                    "sent": "There are different types of Bashan, some, like it and some, get very angry because they say it's not really basing.",
                    "label": 0
                },
                {
                    "sent": "It depends also matter your subjective and objective base in the subjective basin doesn't believe in analysis like this.",
                    "label": 0
                },
                {
                    "sent": "He doesn't believe that there is something like a true distribution and that you can measure performance with respect to that.",
                    "label": 0
                },
                {
                    "sent": "An objective nation does so no clear cut answer.",
                    "label": 0
                },
                {
                    "sent": "The truth.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that's crucial, but.",
                    "label": 0
                },
                {
                    "sent": "Do some Nunzio fire?",
                    "label": 0
                },
                {
                    "sent": "Yeah, this is the true version.",
                    "label": 0
                },
                {
                    "sent": "Would say you do the best you can with your beliefs.",
                    "label": 0
                },
                {
                    "sent": "And if so, that it becomes irrelevant in a way for true Bashan, because you say, like you.",
                    "label": 0
                },
                {
                    "sent": "True Basin would say you should.",
                    "label": 0
                },
                {
                    "sent": "Well, that's that's a very long story.",
                    "label": 0
                },
                {
                    "sent": "Why you would consider relevant, irrelevant.",
                    "label": 0
                },
                {
                    "sent": "Let's say a pragmatic Bashan would acknowledge that because you might choose this model and prior for pragmatic reasons, because he wants to compute things faster, he didn't have too much time to think it might be the case that the truth doesn't match his modeling prior completely.",
                    "label": 0
                },
                {
                    "sent": "And in fact, that's I mean based on analysis is nowadays.",
                    "label": 0
                },
                {
                    "sent": "Often it worked, for example.",
                    "label": 0
                },
                {
                    "sent": "Classification of documents on the web.",
                    "label": 0
                },
                {
                    "sent": "People use mixture models for where they assume words are generated.",
                    "label": 0
                },
                {
                    "sent": "ID and documents.",
                    "label": 0
                },
                {
                    "sent": "Clearly that's false, right?",
                    "label": 0
                },
                {
                    "sent": "Any version would have to admit.",
                    "label": 0
                },
                {
                    "sent": "I think that's a false assumption, but basins are doing it.",
                    "label": 0
                },
                {
                    "sent": "So once you.",
                    "label": 0
                },
                {
                    "sent": "You're right, but you can, even with more sophisticated models which are not cold.",
                    "label": 0
                },
                {
                    "sent": "Now, if they still IID.",
                    "label": 0
                },
                {
                    "sent": "So I think most bases actually would see this as something relevant.",
                    "label": 0
                },
                {
                    "sent": "But the real in a way, the real killer is only coming because it's actually it's coming up now first of all.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The same holds for MDL.",
                    "label": 0
                },
                {
                    "sent": "But in this talk, I'll focus on base because it's much more well known, say little bit more.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah, exactly the same example.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what I'll do now is.",
                    "label": 0
                },
                {
                    "sent": "First tell you what how exactly I defined the basic learning algorithm.",
                    "label": 0
                },
                {
                    "sent": "And that's where you get into more disagreement with base.",
                    "label": 0
                },
                {
                    "sent": "And then I'll say more about how exactly well how we get this theorem.",
                    "label": 0
                },
                {
                    "sent": "How do these distributions and priors and so on look like?",
                    "label": 1
                },
                {
                    "sent": "And then I'm going to say something about how dramatic is the result.",
                    "label": 1
                },
                {
                    "sent": "How bad can we make the result B an?",
                    "label": 1
                },
                {
                    "sent": "Why is it surprising?",
                    "label": 0
                },
                {
                    "sent": "So first definition of the base in learning algorithm?",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "They immediately notice a problem because bases inferences, define distributions, or conditional distributions, and not on set of classifiers.",
                    "label": 0
                },
                {
                    "sent": "So what does it mean to do based on inference with prior to final classifiers?",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Well, there is a standard way of dealing with this if you're for some reasons you start out with a model which, like support vector machines or whatever, which are best thought of as classifiers, not distributions.",
                    "label": 0
                },
                {
                    "sent": "And still you want to use the basic machinery.",
                    "label": 0
                },
                {
                    "sent": "What you usually do is you turn them into probabilistic model by making some additional assumptions about the noise.",
                    "label": 0
                },
                {
                    "sent": "So what is done in classification?",
                    "label": 0
                },
                {
                    "sent": "Is the following you convert each classifier into your original set of distribution set of classifiers your model?",
                    "label": 1
                },
                {
                    "sent": "Into a conditional distribution.",
                    "label": 0
                },
                {
                    "sent": "Then you have a prior on here.",
                    "label": 1
                },
                {
                    "sent": "Now becomes a prior unconditional probability distributions and now you apply base rule to find a posterior which is now posterior probability distributions and those probability distributions that posterior distribution over distributions you used to make classifications.",
                    "label": 0
                },
                {
                    "sent": "So let me explain that in more detail.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The standard way of doing this is the logistic transformation.",
                    "label": 0
                },
                {
                    "sent": "So what you do is you have this original model.",
                    "label": 0
                },
                {
                    "sent": "Then you add one extra parameter which will call B 10.",
                    "label": 0
                },
                {
                    "sent": "It's a real value of parameter.",
                    "label": 0
                },
                {
                    "sent": "And you simply define.",
                    "label": 0
                },
                {
                    "sent": "The probability that Y is 1, remember why it's one or minus one given X.",
                    "label": 0
                },
                {
                    "sent": "And given.",
                    "label": 0
                },
                {
                    "sent": "End EXE, so this was a classifier, now becomes an index to the distribution and parameter B.",
                    "label": 0
                },
                {
                    "sent": "See through the better times, the output of the classifier.",
                    "label": 0
                },
                {
                    "sent": "And this is just to normalize so that this thing sums to one.",
                    "label": 0
                },
                {
                    "sent": "If you have if you sum over wise one and Y zero for the same X, so now it becomes a conditional distribution of over Y given X.",
                    "label": 0
                },
                {
                    "sent": "Now you can extend this to M outcomes by multiplication, so your active dates are IID.",
                    "label": 0
                },
                {
                    "sent": "Now you define priors on the set of classifiers.",
                    "label": 1
                },
                {
                    "sent": "And on this extra parameter.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And you simply set the prior on the joint.",
                    "label": 0
                },
                {
                    "sent": "So this is now an element of your.",
                    "label": 0
                },
                {
                    "sent": "This index is a conditional distribution in your newly created model of conditional distributions and the prior on that you usually just take the product of these two priors.",
                    "label": 0
                },
                {
                    "sent": "You start out with and typically this will be a discrete prior because we're going to use a countable set of classifiers and this is a density, but you can still multiply.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So why does this make any sense?",
                    "label": 0
                },
                {
                    "sent": "If you look at hard classifiers and it's easy to see if you look at the minus log likelihood.",
                    "label": 0
                },
                {
                    "sent": "The probability of a sequence according to the distribution you created for C and beta.",
                    "label": 0
                },
                {
                    "sent": "You can rewrite it as this is beta.",
                    "label": 0
                },
                {
                    "sent": "Times.",
                    "label": 0
                },
                {
                    "sent": "The number of mistakes the classifier makes on the sample.",
                    "label": 0
                },
                {
                    "sent": "So this is the empirical 01 loss, right?",
                    "label": 0
                },
                {
                    "sent": "It's the average number number of misclassifications in the sample.",
                    "label": 0
                },
                {
                    "sent": "So you have beats at times the number of mistakes you make on the sample.",
                    "label": 0
                },
                {
                    "sent": "Or beta times to sample times the empirical loss rather than expected loss, plus something which does not depend on the sample.",
                    "label": 0
                },
                {
                    "sent": "And only an M on the sample size.",
                    "label": 0
                },
                {
                    "sent": "So basically if you fix beta and you have a Sam.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Polanyi optimizer for C. What happens is that the log likelihood of the distributions you created.",
                    "label": 0
                },
                {
                    "sent": "Becomes linear function of their performance in terms of 01 loss on the sample.",
                    "label": 0
                },
                {
                    "sent": "So you've turned 01 classification loss into log likelihood.",
                    "label": 0
                },
                {
                    "sent": "The higher the likelihood that the smaller the 01 lesson the sample.",
                    "label": 0
                },
                {
                    "sent": "If you fix beta and very C Now, because if you would do base with, let's say, a finite set of distributions and given enough data, you would convert the posterior converges to the distribution which maximizes the likelihood of the data.",
                    "label": 0
                },
                {
                    "sent": "Right base is just an extension of maximum likelihood, so if you want base to work well at all in terms in sense of 01 loss, but you really want what you want to do is turn 01 loss into logger, log arhythmic loss so that smaller arhythmic loss, which means large log likelihood becomes small.",
                    "label": 0
                },
                {
                    "sent": "01 loss in the sample.",
                    "label": 0
                },
                {
                    "sent": "Now similarly.",
                    "label": 0
                },
                {
                    "sent": "If you were not similarly but.",
                    "label": 0
                },
                {
                    "sent": "Additionally, if you fix.",
                    "label": 0
                },
                {
                    "sent": "The classifier C. And you start varying beta.",
                    "label": 0
                },
                {
                    "sent": "Then you're also doing something which makes some sense, because if you look back at these.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's easiest to see if you have hard classifiers which output minus one or.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "1.",
                    "label": 0
                },
                {
                    "sent": "If you look at the definition.",
                    "label": 0
                },
                {
                    "sent": "If I have a fixed classifier.",
                    "label": 0
                },
                {
                    "sent": "And for some, for any fix C. This will just be a Bernoulli distribution.",
                    "label": 0
                },
                {
                    "sent": "If beta is minus Infinity, it corresponds to probability 12.",
                    "label": 0
                },
                {
                    "sent": "Why is minus one?",
                    "label": 0
                },
                {
                    "sent": "And if it has infinite is probability one for wise one?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Basically, different beaters correspond to different binary distributions.",
                    "label": 0
                },
                {
                    "sent": "For Y given X.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And if you maximize the likelihood for fixed C. You basically you can transform the two Bernoulli parameter.",
                    "label": 0
                },
                {
                    "sent": "It basically means you find the Bernoulli pyramids are, which is exactly equal to the empirical error.",
                    "label": 0
                },
                {
                    "sent": "So if your empirical error, you can think of that that's a number between zero and one.",
                    "label": 0
                },
                {
                    "sent": "You can think of that as the relative frequency of having made a mistake, and the thing which maximizes your likelihood.",
                    "label": 0
                },
                {
                    "sent": "Exactly sets.",
                    "label": 0
                },
                {
                    "sent": "This beta such that this transform becomes the empirical error number of mistakes.",
                    "label": 0
                },
                {
                    "sent": "The classifiers he makes on your data.",
                    "label": 0
                },
                {
                    "sent": "I should add here that if you have a classifier.",
                    "label": 0
                },
                {
                    "sent": "Which has makes more than 50% mistakes.",
                    "label": 0
                },
                {
                    "sent": "So let's say it gives the wrong prediction on 90% of the cases.",
                    "label": 0
                },
                {
                    "sent": "If you optimize over beta, beta becomes negative.",
                    "label": 0
                },
                {
                    "sent": "An this means actually that in your probability flips and then your probability distribution actually becomes quite good model of the data.",
                    "label": 0
                },
                {
                    "sent": "And So what happens here is that suppose you have a set of classifiers.",
                    "label": 0
                },
                {
                    "sent": "And the best one.",
                    "label": 0
                },
                {
                    "sent": "As a generalization, error of 0.2 and the worst one of 0.99.",
                    "label": 0
                },
                {
                    "sent": "And actually the worst classifier is much better than the best classifier, because you can trivially change its predictions to very good prediction, and this will actually if you start optimizing beta you at this power of flipping the predictions of classifier so that they actually become better.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So there are some reasons why it would make sense to do this.",
                    "label": 0
                },
                {
                    "sent": "An another thing which may be more.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "Intuitive to statisticians is that your everybody knows.",
                    "label": 0
                },
                {
                    "sent": "I guess that if you do regression with the squared loss and a set of functions, that's equivalent to doing maximum.",
                    "label": 0
                },
                {
                    "sent": "If you do minimum least squared error, that's equivalent to doing maximum likelihood under the assumption that the wife values are given by FX plus independently normally distributed noise.",
                    "label": 1
                },
                {
                    "sent": "So here you did exactly the same thing with classification for each classifier.",
                    "label": 0
                },
                {
                    "sent": "You had a probabilistic.",
                    "label": 0
                },
                {
                    "sent": "Probabilistic assumption on top PC subeta just distribution you created expresses that why is the classifier evaluated X plus?",
                    "label": 0
                },
                {
                    "sent": "Actually this should be sore, so this thing is flipped with a certain probability and probability is given by beta.",
                    "label": 0
                },
                {
                    "sent": "So beta determines the noise in your model, just as if you have regression, you connect an extra Sigma which determines the noise.",
                    "label": 0
                },
                {
                    "sent": "So that's the intuition why this might be a reasonable thing to do now, of course.",
                    "label": 0
                },
                {
                    "sent": "In a way it's not Bashan.",
                    "label": 0
                },
                {
                    "sent": "Real Bashan always starts saying like there are some deep reasons why we should always model our uncertainty as distributions, not as classifiers.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "So we shouldn't do this, but in practice basins do it all the time because for several reasons they've come up with models like support vector machines which happen not to be distributions, but do work very well.",
                    "label": 0
                },
                {
                    "sent": "And they still have to turn into distributions.",
                    "label": 0
                },
                {
                    "sent": "Now if you look at papers at NIPS or UI, people always do it.",
                    "label": 1
                },
                {
                    "sent": "In this way they start with a set of classifiers and then they do the logistic transformation.",
                    "label": 0
                },
                {
                    "sent": "Now when we in this work was just finished, we told the basin about it and he protested and he said no, no as a base and you have to think very carefully about your noise model and if you are not sure that the noise is independent of the value of X, then you cannot do this and you're just not allowed to, and so on.",
                    "label": 0
                },
                {
                    "sent": "In practice, people do do it so then John had this marvelous idea, I think.",
                    "label": 0
                },
                {
                    "sent": "To just describe the problem without saying that we will show that base gives you strange results, but just described the problem.",
                    "label": 0
                },
                {
                    "sent": "We have a set of classifiers set of support vector machines.",
                    "label": 0
                },
                {
                    "sent": "We somehow want to use Bayesian inference for them extending with prior.",
                    "label": 0
                },
                {
                    "sent": "And how would you do this?",
                    "label": 0
                },
                {
                    "sent": "So we tested it with three people and they all three set do the majestic transformation.",
                    "label": 1
                },
                {
                    "sent": "So therefore we do take this as evidence that this is the basic way of doing it anyway.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Correctly.",
                    "label": 0
                },
                {
                    "sent": "This look like your loss function, which you yeah from this.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah.",
                    "label": 0
                },
                {
                    "sent": "Maximizing, I still end up with this optimal 011.",
                    "label": 0
                },
                {
                    "sent": "Yeah, exactly.",
                    "label": 0
                },
                {
                    "sent": "Yeah, it has exactly.",
                    "label": 0
                },
                {
                    "sent": "It has a property that both on the data but also in expectation of the true distribution.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah yeah yeah we now do a method which is good for minimizing expected log likelihood, and that's the callback library vergence or relative entropy.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so now we know what the algorithm is.",
                    "label": 1
                },
                {
                    "sent": "An well, not exactly a little bit more precise even we know how we come from these classifiers to distributions.",
                    "label": 0
                },
                {
                    "sent": "So we proved this both for the full basin algorithm and for the base in maximum posteriori algorithm.",
                    "label": 1
                },
                {
                    "sent": "In this talk I'll concentrate on the full base.",
                    "label": 0
                },
                {
                    "sent": "So what is what is full base?",
                    "label": 0
                },
                {
                    "sent": "Anne works like this for.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You convert all your classifiers to a set of conditional distributions.",
                    "label": 0
                },
                {
                    "sent": "Jeff showed you how to do then you get these distributions indexed by C. That's the original classifier.",
                    "label": 0
                },
                {
                    "sent": "NB 10 You have a prior on those and now you just use Bayes rule.",
                    "label": 0
                },
                {
                    "sent": "To come up with a posterior.",
                    "label": 0
                },
                {
                    "sent": "Right, so this is just prior times probability of data given prior.",
                    "label": 0
                },
                {
                    "sent": "And this is the integral overall parameters.",
                    "label": 0
                },
                {
                    "sent": "This is just based on marginal probability of the data.",
                    "label": 0
                },
                {
                    "sent": "You get a posterior of the parameters given the sample.",
                    "label": 0
                },
                {
                    "sent": "This sample is just the first MX in the first time wise together is S. So this is how you start to fear from the posterior.",
                    "label": 0
                },
                {
                    "sent": "You can compute the predictive distribution.",
                    "label": 1
                },
                {
                    "sent": "So this is if you.",
                    "label": 0
                },
                {
                    "sent": "Have the posterior.",
                    "label": 0
                },
                {
                    "sent": "Now you get a new xvalue.",
                    "label": 0
                },
                {
                    "sent": "What's the probability of the Y value?",
                    "label": 0
                },
                {
                    "sent": "According to base, that's you get it by averaging.",
                    "label": 0
                },
                {
                    "sent": "The probabilities according to each conditional distribution according to your district, your posterior.",
                    "label": 0
                },
                {
                    "sent": "So you average according to the posterior weights where things which had small loss on your trading sample will now get a large weight.",
                    "label": 0
                },
                {
                    "sent": "And they will dominate you hope.",
                    "label": 0
                },
                {
                    "sent": "The average, so the predicted distribution of the new Wi-Fi you're given X just the average.",
                    "label": 0
                },
                {
                    "sent": "Over I see I made a mistake here the prior should.",
                    "label": 0
                },
                {
                    "sent": "Should be gone here.",
                    "label": 0
                },
                {
                    "sent": "Price should be at.",
                    "label": 0
                },
                {
                    "sent": "It's just the average over the posterior.",
                    "label": 0
                },
                {
                    "sent": "Of the probability according to the distribution of the next Y given XX.",
                    "label": 0
                },
                {
                    "sent": "So now you have the predictive distribution and now you do the decision.",
                    "label": 0
                },
                {
                    "sent": "That would be the base optimal decision if this were the distribution of the data.",
                    "label": 0
                },
                {
                    "sent": "So if the probability that next, why is 1 given next X value is smaller than 1/2 you predict 0?",
                    "label": 0
                },
                {
                    "sent": "Slide in one.",
                    "label": 0
                },
                {
                    "sent": "Have you predict one?",
                    "label": 0
                },
                {
                    "sent": "And if it's one, have you ever you toss a fair coin?",
                    "label": 0
                },
                {
                    "sent": "To decide your prediction, and this is the base algorithm.",
                    "label": 0
                },
                {
                    "sent": "So based on a simple S in a prior Pi, you get this predictive distribution and you use that for every new X value to get a prediction of the new I failure.",
                    "label": 0
                },
                {
                    "sent": "So now how does it work?",
                    "label": 0
                },
                {
                    "sent": "How do we get our result?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We have to define feet.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Space.",
                    "label": 0
                },
                {
                    "sent": "And set of classifiers and the true distribution in the prior to make everything well defined.",
                    "label": 0
                },
                {
                    "sent": "So first the feature space will have.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "XB affector with countably infinite number of components, all of which are either minus one or one.",
                    "label": 0
                },
                {
                    "sent": "So X is X sub zero X one X2 etc.",
                    "label": 0
                },
                {
                    "sent": "Or set of classifiers is also countably infinite.",
                    "label": 1
                },
                {
                    "sent": "See sub zero C sub one season 2 etc.",
                    "label": 0
                },
                {
                    "sent": "And it's defined it's very easily defined.",
                    "label": 0
                },
                {
                    "sent": "Each classifier only listens to 1 feature.",
                    "label": 0
                },
                {
                    "sent": "So the classifier say subject of X is just what the J feature says.",
                    "label": 0
                },
                {
                    "sent": "So every classifier just OK these features is 1.",
                    "label": 0
                },
                {
                    "sent": "Then I predict one I don't look at what the rest day.",
                    "label": 0
                },
                {
                    "sent": "Now we need a prior over these classifiers.",
                    "label": 0
                },
                {
                    "sent": "And basically our prior needs to decay slowly.",
                    "label": 0
                },
                {
                    "sent": "That's essential, so we fix some small Alpha will later see exactly what Alpha and we make a prior such that the prior of classifier CCV is larger than 1 / N to the one plus Alpha.",
                    "label": 0
                },
                {
                    "sent": "Note for A0 this is impossible.",
                    "label": 0
                },
                {
                    "sent": "Because you would diverge because the series 1 / N diverges, but for every L far larger than zero you can make such a prior.",
                    "label": 0
                },
                {
                    "sent": "The prior on beta can be any smooth prior.",
                    "label": 1
                },
                {
                    "sent": "It can also be in that will be become important in the analysis.",
                    "label": 0
                },
                {
                    "sent": "We can also take a discrete prior, let's say prior on all rational numbers that will also work, not you can describe a rational number by describing 2 numbers, so it's easy to see that you.",
                    "label": 0
                },
                {
                    "sent": "Have a prior which gives rational more P / Q gets prior probability approximately 1 / P ^2 * 1 / Q ^2 so prior like that would also work and then you get a probability mass function here.",
                    "label": 0
                },
                {
                    "sent": "So now how do we define a true distribution?",
                    "label": 0
                },
                {
                    "sent": "Now it gets interesting.",
                    "label": 0
                },
                {
                    "sent": "So we somehow have to come up with a true distribution that will serve to confuse base so that it doesn't converge, or does something strange.",
                    "label": 0
                },
                {
                    "sent": "So what are we going to do?",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well, for each, each time we generate an example, we generate them ID, so we always do the same thing.",
                    "label": 0
                },
                {
                    "sent": "We first as a fair coin to determine the value of Y.",
                    "label": 1
                },
                {
                    "sent": "So what has to be predicted is even minus one or one of probably want to have.",
                    "label": 0
                },
                {
                    "sent": "So now we trust another coin.",
                    "label": 0
                },
                {
                    "sent": "With the bias 0.6 by Zero Point 6 will see in a moment.",
                    "label": 0
                },
                {
                    "sent": "Anne, this coin determines whether the example will be easy or hard.",
                    "label": 0
                },
                {
                    "sent": "So there are two types of examples.",
                    "label": 0
                },
                {
                    "sent": "There's easy example.",
                    "label": 0
                },
                {
                    "sent": "An easy example is very simple because then all classifiers will correctly predict why.",
                    "label": 0
                },
                {
                    "sent": "So if you have an easy for example, then we set all X values equal to Y.",
                    "label": 0
                },
                {
                    "sent": "If we have a hard example, then it's a bit different than X sub zero.",
                    "label": 0
                },
                {
                    "sent": "So the first feature corresponding to the first classifier on our list will still be informative of why it will give you the right prediction with probability 2/3.",
                    "label": 0
                },
                {
                    "sent": "But all other classifiers will say something random.",
                    "label": 0
                },
                {
                    "sent": "They will just say XY with probability 1/2 and minus my otherwise.",
                    "label": 0
                },
                {
                    "sent": "But importantly, they all do this in dependently.",
                    "label": 0
                },
                {
                    "sent": "So they are not informative of why.",
                    "label": 0
                },
                {
                    "sent": "If you have a hard example but also not of each other.",
                    "label": 0
                },
                {
                    "sent": "If you know what one classifier predicts, you still don't know what the other predicts.",
                    "label": 0
                },
                {
                    "sent": "Note that in this way we defined a joint distribution over X * Y.",
                    "label": 0
                },
                {
                    "sent": "We begin with the distribution of Y, and here we defined the conditional distribution of X given Y.",
                    "label": 0
                },
                {
                    "sent": "And if you do it this way, then you get of course that every feature on average tells you something about why.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Because with probability, what was at 0.6 zero point 6, you get an easy example and then every feature says what, why is.",
                    "label": 0
                },
                {
                    "sent": "But X zero is more informative than all the others because it's the only one which is still informative.",
                    "label": 1
                },
                {
                    "sent": "If you have a hard example.",
                    "label": 0
                },
                {
                    "sent": "So C sub zero which just outputs except here is the best classifier is if you calculate it with these numbers it has generalization or 0.2.",
                    "label": 0
                },
                {
                    "sent": "So it makes a mistake 20% of the time.",
                    "label": 0
                },
                {
                    "sent": "And all the others have generalization error.",
                    "label": 0
                },
                {
                    "sent": "Zero point 3.",
                    "label": 0
                },
                {
                    "sent": "Make a mistake 30% of the time.",
                    "label": 0
                },
                {
                    "sent": "And still now it turns out.",
                    "label": 0
                },
                {
                    "sent": "So now we've defined basically everything we have a prior over these classifiers and over beta so we know what the how the base algorithm works.",
                    "label": 0
                },
                {
                    "sent": "We know the true distribution and we can now show that in this scenario with probability one.",
                    "label": 0
                },
                {
                    "sent": "The classifier with maximum posterior probability.",
                    "label": 0
                },
                {
                    "sent": "So this is the base and posterior given the sample.",
                    "label": 0
                },
                {
                    "sent": "Of classifier J, the thing which maximizes the probability goes to Infinity.",
                    "label": 0
                },
                {
                    "sent": "So basically base does not converge.",
                    "label": 0
                },
                {
                    "sent": "No matter how much data you get, if you get more data.",
                    "label": 0
                },
                {
                    "sent": "Then your posterior will concentrate classifiers with higher indices, so you keep going on the right and from the right on your list.",
                    "label": 0
                },
                {
                    "sent": "You can show that.",
                    "label": 0
                },
                {
                    "sent": "The probability of the classifier want to learn this is the right classifier, right?",
                    "label": 0
                },
                {
                    "sent": "It's the best one.",
                    "label": 0
                },
                {
                    "sent": "It has error zero, point 2, so this is what you want to converge to.",
                    "label": 0
                },
                {
                    "sent": "Posterior probability of this classifier given the sample.",
                    "label": 0
                },
                {
                    "sent": "Divided by the maximum posterior is exponentially small.",
                    "label": 0
                },
                {
                    "sent": "So this order is smaller than some comes to the minus some constant Times Square root of M. So this means that the Bayesian maximum, a posterior algorithm which simply copies the classifier which has the highest posterior probability.",
                    "label": 0
                },
                {
                    "sent": "Will always pick a bad one.",
                    "label": 0
                },
                {
                    "sent": "Now a more involved analysis showed that actually.",
                    "label": 0
                },
                {
                    "sent": "But you can more or less already see it here.",
                    "label": 0
                },
                {
                    "sent": "That if you look at.",
                    "label": 0
                },
                {
                    "sent": "The posterior weight of this classifier will be, so will be exponentially larger than the posterior weight on this one.",
                    "label": 0
                },
                {
                    "sent": "So if you make predictions, then this classifier which maximizes will dominate this one completely, so the predictions you make will be the predictions that are optimal.",
                    "label": 0
                },
                {
                    "sent": "According to this one and not this one.",
                    "label": 0
                },
                {
                    "sent": "So therefore you make what base does is synthetically is achieved this generalization error.",
                    "label": 0
                },
                {
                    "sent": "There is a complication because of course base doesn't put all its mass on one classifier.",
                    "label": 0
                },
                {
                    "sent": "It may have like the posterior is as gifts, large mass to a set of classifiers.",
                    "label": 0
                },
                {
                    "sent": "But if you do more involved analysis, you can show that for all the classifiers in which there are substantial posterior probability.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "Like you must have this for all these classifiers, so this one is can be completely neglected, neglected if you mix over the posterior.",
                    "label": 0
                },
                {
                    "sent": "You only mix with things with much higher posterior probability.",
                    "label": 0
                },
                {
                    "sent": "And those things the way they are defined.",
                    "label": 0
                },
                {
                    "sent": "If you make a mix between if you have a mixture of them, you cannot classify better than with any single one of them 'cause you either have an easy example, then they're all OK, or you have a hard example.",
                    "label": 0
                },
                {
                    "sent": "In the hard example, they're all random, so if you mix them you get something which is still completely random, but you can if you mix two things which predict why is one with probability 1/2 independently.",
                    "label": 0
                },
                {
                    "sent": "Then the result of mixing those distribution can never be.",
                    "label": 0
                },
                {
                    "sent": "A distribution with which predicts why correctly with probability larger than 1/2.",
                    "label": 0
                },
                {
                    "sent": "It's impossible, so therefore even if you mix over the posterior, you cannot get better than this, so base converges to classifier with probability of error zero point 3.",
                    "label": 0
                },
                {
                    "sent": "They should know that for each fixed.",
                    "label": 0
                },
                {
                    "sent": "Classifier, which is not the optimal one.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "Posterior ratio.",
                    "label": 0
                },
                {
                    "sent": "In the end, the best one does win.",
                    "label": 0
                },
                {
                    "sent": "Battle of large numbers this thing.",
                    "label": 0
                },
                {
                    "sent": "This thing is E 2 to some constant times to 01 error you make on the sample with the best classifier and this is equal to 01 error on the sample time.",
                    "label": 0
                },
                {
                    "sent": "Some worst classifier.",
                    "label": 0
                },
                {
                    "sent": "So by the law of large numbers this ratio will be exponentially large in favor of this one.",
                    "label": 0
                },
                {
                    "sent": "But the problem is that this doesn't go.",
                    "label": 0
                },
                {
                    "sent": "This doesn't happen fast enough.",
                    "label": 1
                },
                {
                    "sent": "This happens for each fixed J.",
                    "label": 0
                },
                {
                    "sent": "So if I take any fixed.",
                    "label": 0
                },
                {
                    "sent": "Number from one 2K, let's say.",
                    "label": 0
                },
                {
                    "sent": "And look at all classifiers in that sets, then the posterior within that set will converge to the optimal distribution.",
                    "label": 0
                },
                {
                    "sent": "But as you make it set larger then of course because the prior decreases, you get basically intuitively the things get more and more complex, you get smaller smaller prior and therefore they are punished more and more in the basin posterior, but they're not punished enough.",
                    "label": 0
                },
                {
                    "sent": "And therefore still, if you look at the whole thing, the infinite number of classifiers.",
                    "label": 0
                },
                {
                    "sent": "Caesar always loses.",
                    "label": 0
                },
                {
                    "sent": "Yeah, but it's it's essential.",
                    "label": 0
                },
                {
                    "sent": "And then you can see that by balance out, yeah, yeah.",
                    "label": 0
                },
                {
                    "sent": "Yeah, but the so the numbers I have here are not true for any Alpha.",
                    "label": 0
                },
                {
                    "sent": "Because if Alpha goes to Infinity, basically your prior decreases faster and faster.",
                    "label": 0
                },
                {
                    "sent": "And then the difference you can achieve by tweaking these parameters, like what is the probability of a hard example and so on.",
                    "label": 0
                },
                {
                    "sent": "It gets smaller and smaller.",
                    "label": 0
                },
                {
                    "sent": "So in the limit for Alpha to Infinity, the if you look at the.",
                    "label": 0
                },
                {
                    "sent": "See if you look at the theorem again.",
                    "label": 0
                },
                {
                    "sent": "The maximum K.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can achieve here depends on Alpha.",
                    "label": 0
                },
                {
                    "sent": "But for every Alpha.",
                    "label": 0
                },
                {
                    "sent": "Every finite Alpha is larger than 0.",
                    "label": 0
                },
                {
                    "sent": "And you maximize it by taking the.",
                    "label": 0
                },
                {
                    "sent": "By taking Elfina limit to 0.",
                    "label": 0
                },
                {
                    "sent": "Slower your priority case, the less you punish things.",
                    "label": 0
                },
                {
                    "sent": "With a large index and the more you overfit basically.",
                    "label": 0
                },
                {
                    "sent": "So that's what overfitting means here.",
                    "label": 0
                },
                {
                    "sent": "Table.",
                    "label": 0
                },
                {
                    "sent": "Easy and party.",
                    "label": 0
                },
                {
                    "sent": "One would have to use them.",
                    "label": 0
                },
                {
                    "sent": "They don't.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Creating differentiation.",
                    "label": 0
                },
                {
                    "sent": "Ann, they are needed to play.",
                    "label": 0
                },
                {
                    "sent": "We will come to that in a moment.",
                    "label": 0
                },
                {
                    "sent": "There needed to play around with the problem because we want to look at what is the best value of K we can get.",
                    "label": 0
                },
                {
                    "sent": "How much, how bad can base become?",
                    "label": 0
                },
                {
                    "sent": "And it turns out that if you want to make basically have really bad, you need to have this as well.",
                    "label": 0
                },
                {
                    "sent": "Basically, if you don't have easy examples, then based never performs then.",
                    "label": 0
                },
                {
                    "sent": "This all classifiers except the first one never perform better than randomly.",
                    "label": 0
                },
                {
                    "sent": "Right so then Abasin might tell you like look, this is a crazy problem.",
                    "label": 0
                },
                {
                    "sent": "You'll never meet a problem.",
                    "label": 0
                },
                {
                    "sent": "Practice where there's one classifier which performs well and all the others are like random guessing.",
                    "label": 0
                },
                {
                    "sent": "So we want to say what we will also want to look at the case.",
                    "label": 0
                },
                {
                    "sent": "What happens if all classifiers are reasonably good?",
                    "label": 0
                },
                {
                    "sent": "Read by changing the probability of Z is 1.",
                    "label": 0
                },
                {
                    "sent": "We can make all classifiers behave quite well, but still see zero behave better than the others an, but we'll see that in a moment.",
                    "label": 0
                },
                {
                    "sent": "We want to know under what conditions on the classifiers we can get a result like this and therefore we need to play.",
                    "label": 0
                },
                {
                    "sent": "We need to look at the case.",
                    "label": 0
                },
                {
                    "sent": "Where the best classifiers are still quite good.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So now I'm coming to that actually.",
                    "label": 0
                },
                {
                    "sent": "So if you look at the theorem more detail I didn't specify.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Fight in full but.",
                    "label": 0
                },
                {
                    "sent": "Then the following happens so.",
                    "label": 0
                },
                {
                    "sent": "By varying the spread this parameter, what's the probability of hard example?",
                    "label": 0
                },
                {
                    "sent": "You can, and also by varying the probability of how good the sub zero the one good classifier is.",
                    "label": 0
                },
                {
                    "sent": "If you have a hard example, you can vary the promise.",
                    "label": 0
                },
                {
                    "sent": "I said the generalization error the best classifier, so expect it to one of the thing you want to learn varies from anything between 0 and 1/2.",
                    "label": 0
                },
                {
                    "sent": "That's why we need this, and then we want to look at.",
                    "label": 0
                },
                {
                    "sent": "But how bad can be made based misbehave if we vary that probability of the best classifier and the other classifiers.",
                    "label": 0
                },
                {
                    "sent": "Now it turns out.",
                    "label": 0
                },
                {
                    "sent": "That's so if you look if you have the base in maximum security MDL algorithm.",
                    "label": 0
                },
                {
                    "sent": "The curve.",
                    "label": 0
                },
                {
                    "sent": "You get how bad the algorithm can get.",
                    "label": 0
                },
                {
                    "sent": "Looks like this, so that's.",
                    "label": 0
                },
                {
                    "sent": "A consistent learning algorithm which asymptotically learns the best classifier.",
                    "label": 0
                },
                {
                    "sent": "This line is a straight line from zero to 0.5 in here.",
                    "label": 0
                },
                {
                    "sent": "Also zero to 0.5.",
                    "label": 0
                },
                {
                    "sent": "This line indicates.",
                    "label": 0
                },
                {
                    "sent": "If you have asymptotical, if you have asymptotically many data and you have a consistent algorithm, what your generalization error will be.",
                    "label": 0
                },
                {
                    "sent": "If the classifier learn it will be as good as the best classifier your model.",
                    "label": 0
                },
                {
                    "sent": "So this is the best you can do within your model.",
                    "label": 0
                },
                {
                    "sent": "If you use the base or MDL algorithm, you can overshoot by this.",
                    "label": 0
                },
                {
                    "sent": "With our construction, so this means that if the true distribution is the.",
                    "label": 0
                },
                {
                    "sent": "C Sub zero has 0 error.",
                    "label": 0
                },
                {
                    "sent": "It's a perfect classifier.",
                    "label": 0
                },
                {
                    "sent": "Then actually you are also.",
                    "label": 0
                },
                {
                    "sent": "You then base will also be good base will not be inconsistent.",
                    "label": 0
                },
                {
                    "sent": "The problem only starts when this moves away from zero when the optimal classifier is a small error, but then it goes up very quickly because these both of these curves have an infinite derivative at 0.",
                    "label": 0
                },
                {
                    "sent": "And the base map algorithm actually comes back again.",
                    "label": 0
                },
                {
                    "sent": "So if optimal classifier has generalization error close to 1/2 so close to random guessing.",
                    "label": 0
                },
                {
                    "sent": "Then there's not much difference anymore between base and consistent algorithms, but.",
                    "label": 0
                },
                {
                    "sent": "If you look at full base and this is interesting, is normally full based, people will say it's better than based on maximal pursuer, but in this case it's actually worse.",
                    "label": 0
                },
                {
                    "sent": "Watching Spencer's in detail that was that's full base.",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah, so full basis, it's more Bashan.",
                    "label": 0
                },
                {
                    "sent": "You don't just take the maximum you average over all things according to your posterior.",
                    "label": 0
                },
                {
                    "sent": "You can by tweaking these parameters you can make base.",
                    "label": 0
                },
                {
                    "sent": "Have generalization error all the way up to one so it starts at this point.",
                    "label": 0
                },
                {
                    "sent": "Where is it?",
                    "label": 0
                },
                {
                    "sent": "About 0.1 this means that I can set up the problem in a way such that C sub zero.",
                    "label": 0
                },
                {
                    "sent": "The best classifier has a generalization error of zero point 12.",
                    "label": 0
                },
                {
                    "sent": "Not very large, 88% correct and base starts performing worse than random guessing.",
                    "label": 0
                },
                {
                    "sent": "No matter how much data you have.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So how is this possible?",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Maybe I should give you a little clue.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to give you the proof, but I'm going to give you.",
                    "label": 0
                },
                {
                    "sent": "Little Chris, I go back to the construction.",
                    "label": 0
                },
                {
                    "sent": "Basically, I didn't tell you the whole story here.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I sit here if you have a hard example.",
                    "label": 1
                },
                {
                    "sent": "Then the classifiers are set equal to the wife value.",
                    "label": 0
                },
                {
                    "sent": "The bad classifiers with probability 1/2.",
                    "label": 0
                },
                {
                    "sent": "Actually, if you do it this way then base will never perform worse than random guessing.",
                    "label": 0
                },
                {
                    "sent": "But what you can do is make them equal to this value with probability 1/2 minus Delta for some very small Delta.",
                    "label": 0
                },
                {
                    "sent": "So this means that all these classifiers are slightly worse than random guessing just ever so slightly worse.",
                    "label": 0
                },
                {
                    "sent": "But they all make their probability, their predictions independently.",
                    "label": 0
                },
                {
                    "sent": "So now we're based.",
                    "label": 0
                },
                {
                    "sent": "Thus is based concentrates on the bad classifier, so it forgets about the thing which works well for the hard examples.",
                    "label": 0
                },
                {
                    "sent": "And if you have a hard example, what it does is it's posteriors, a mixture of things, all of which predict slightly worse than random.",
                    "label": 0
                },
                {
                    "sent": "Then randomly, independently.",
                    "label": 0
                },
                {
                    "sent": "So if you have some.",
                    "label": 0
                },
                {
                    "sent": "IID sample.",
                    "label": 0
                },
                {
                    "sent": "Of things which have a probability of different probability wise, one is 1/2 minus Delta.",
                    "label": 0
                },
                {
                    "sent": "An all these probabilities are independent.",
                    "label": 1
                },
                {
                    "sent": "Then you average over them.",
                    "label": 0
                },
                {
                    "sent": "That actually your average will be.",
                    "label": 0
                },
                {
                    "sent": "You will make the wrong prediction with probability tending to one.",
                    "label": 0
                },
                {
                    "sent": "Because you have lots of things which have a probability of saying one.",
                    "label": 0
                },
                {
                    "sent": "If the answer should be when this one with slightly larger than one half 1/2 plus Delta, but they're all independent.",
                    "label": 0
                },
                {
                    "sent": "So you average over all of them.",
                    "label": 0
                },
                {
                    "sent": "Is it more and more?",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah yeah.",
                    "label": 0
                },
                {
                    "sent": "And because that happens.",
                    "label": 0
                },
                {
                    "sent": "And that was actually, that's not in our paper with John Langford.",
                    "label": 0
                },
                {
                    "sent": "I proved that later it was very tough to prove it, but you can.",
                    "label": 0
                },
                {
                    "sent": "It's exactly that's what happens.",
                    "label": 0
                },
                {
                    "sent": "Your posterior gets.",
                    "label": 0
                },
                {
                    "sent": "Flatter and flatter, it spreads out over like something like log off the sample size number of classifiers it has about equal posterior.",
                    "label": 0
                },
                {
                    "sent": "And yeah, because they all make a mistake with this slide, probably slightly larger than 1/2 and they make the mistake independently.",
                    "label": 0
                },
                {
                    "sent": "Your posterior will always guess the wrong thing.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "I have 15 minutes.",
                    "label": 0
                },
                {
                    "sent": "That's OK, yeah?",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So let me.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I kind of let me not let me go through this.",
                    "label": 0
                },
                {
                    "sent": "How bad can base get?",
                    "label": 0
                },
                {
                    "sent": "And we'll see whether this time for the rest.",
                    "label": 0
                },
                {
                    "sent": "Because we have.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The theorem.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I just wonder why using the word bad, because I mean if you detect that your classifier is misclassified, you just big decision and you are perfect and perfect classifiers, so right?",
                    "label": 0
                },
                {
                    "sent": "What do you mean?",
                    "label": 0
                },
                {
                    "sent": "And you know that it's actually misclassifying field Alpha.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that is true, so anyway OK, but that well I can, but I can change my problem so that it goes like this.",
                    "label": 0
                },
                {
                    "sent": "And then I would say.",
                    "label": 0
                },
                {
                    "sent": "Yes, you have.",
                    "label": 0
                },
                {
                    "sent": "You have a good point.",
                    "label": 0
                },
                {
                    "sent": "There's a yeah in a way, in a way base is very good yeah, But if you follow base without making any changes it is bad.",
                    "label": 0
                },
                {
                    "sent": "You have to make.",
                    "label": 0
                },
                {
                    "sent": "Yeah, in practice it's good.",
                    "label": 0
                },
                {
                    "sent": "Yeah, but the problem is not practical.",
                    "label": 0
                },
                {
                    "sent": "Anyway.",
                    "label": 0
                },
                {
                    "sent": "The point here is not to show that this is happened, but it happens in practice with the community.",
                    "label": 0
                },
                {
                    "sent": "They say it's not the right thing to do.",
                    "label": 0
                },
                {
                    "sent": "Anyway, but I mean you definitely have a point, it's true.",
                    "label": 0
                },
                {
                    "sent": "So our second theorem says that this curve is in a way tight, so this is what we can get with our problem by tweaking the parameters.",
                    "label": 0
                },
                {
                    "sent": "But it turns out that their base can never still keep using the words.",
                    "label": 0
                },
                {
                    "sent": "This apologies base can never get worse in this, no matter how your true distribution.",
                    "label": 0
                },
                {
                    "sent": "How your set of classifiers looks, likes look, look like.",
                    "label": 0
                },
                {
                    "sent": "So our problem is what we showed here is actually the worst that can happen with base.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "So how does this work?",
                    "label": 0
                },
                {
                    "sent": "I'm going to explain it now.",
                    "label": 0
                },
                {
                    "sent": "So first the definition.",
                    "label": 0
                },
                {
                    "sent": "So S soup.",
                    "label": 0
                },
                {
                    "sent": "I is the sample.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Outcome ice and then we have the following theorem.",
                    "label": 0
                },
                {
                    "sent": "If I have an arbitrary set of countable classifiers.",
                    "label": 0
                },
                {
                    "sent": "And arbitrary prior.",
                    "label": 0
                },
                {
                    "sent": "On them.",
                    "label": 0
                },
                {
                    "sent": "And I have an arbitrary true distribution.",
                    "label": 0
                },
                {
                    "sent": "Such that the best classifier in the set has error mu.",
                    "label": 0
                },
                {
                    "sent": "And you can be anything between 0 and 1/2, so I should have also said for all meal you feel free to choose it.",
                    "label": 0
                },
                {
                    "sent": "Then basically what will happen with probability tending to one according to the true distribution.",
                    "label": 0
                },
                {
                    "sent": "Is that on the?",
                    "label": 0
                },
                {
                    "sent": "Sample you actually get.",
                    "label": 0
                },
                {
                    "sent": "The classification error made by base based on the past.",
                    "label": 0
                },
                {
                    "sent": "If you sum that overall outcomes.",
                    "label": 0
                },
                {
                    "sent": "Then this will be smaller than the entropy of mu plus Delta for all Delta larger than zero, and HST binary entropy.",
                    "label": 0
                },
                {
                    "sent": "Some user number between zero and 1/2, so it has a well defined this entropy for Bernoulli random variable with that bias.",
                    "label": 0
                },
                {
                    "sent": "And you can show that the average error of base over the sample.",
                    "label": 0
                },
                {
                    "sent": "Bill with probability almost one.",
                    "label": 0
                },
                {
                    "sent": "It's 1 minus something exponentially small.",
                    "label": 0
                },
                {
                    "sent": "Is smaller equal in this entropy?",
                    "label": 0
                },
                {
                    "sent": "So we are not able to show that the generalization error of base the classification risk is bounded by this.",
                    "label": 0
                },
                {
                    "sent": "We are only to show some different weaker property that the average error you make if you actually use base for prediction on an actual sample with very high probability be smaller than this, so it's not exactly the same thing.",
                    "label": 0
                },
                {
                    "sent": "But this is the thing we could prove.",
                    "label": 0
                },
                {
                    "sent": "But notice that.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is exactly the same function.",
                    "label": 0
                },
                {
                    "sent": "As this function, so this is we can go we can achieve this closest we want from below in terms of generalization error of the basin algorithm.",
                    "label": 0
                },
                {
                    "sent": "So how do you prove Theorem 2 actually, for people who know about prediction of individual sequences, it's very straightforward.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "First of all, you notice that if you have a seat.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Points of M outcomes.",
                    "label": 0
                },
                {
                    "sent": "And now you use the basin algorithm for prediction with respect to log loss.",
                    "label": 0
                },
                {
                    "sent": "So for each point in time you look at the base and predictive distribution.",
                    "label": 0
                },
                {
                    "sent": "I call this piece of bread before given the sample in the past, the new X value prediction of the new wife value and you look at the log squared minus log probability of the outcome.",
                    "label": 0
                },
                {
                    "sent": "You some that overall outcomes.",
                    "label": 0
                },
                {
                    "sent": "So this is the individual prediction error.",
                    "label": 0
                },
                {
                    "sent": "If you do sequential prediction based on what you've seen in the past, the next outcome you see the next outcome you condition on that as well predict next when you add the errors.",
                    "label": 0
                },
                {
                    "sent": "So every time.",
                    "label": 0
                },
                {
                    "sent": "The Bayesian classifier makes a mistake.",
                    "label": 0
                },
                {
                    "sent": "You must have seen a white value which had probability smaller than 1/2 according to the basin prediction algorithm, right?",
                    "label": 0
                },
                {
                    "sent": "Otherwise you would have predicted correctly, this is binary logarithm, so every time base makes a mistake in a 01 sense, if you're minus lock something smaller than 1/2, so that's something larger or equal than one.",
                    "label": 0
                },
                {
                    "sent": "So this means that every time base made a prediction mistake, this thing must have been larger than one.",
                    "label": 0
                },
                {
                    "sent": "So this accumulated log loss is larger equal in accumulated 01 loss of the basic classifier.",
                    "label": 1
                },
                {
                    "sent": "So this gives you this bound situation.",
                    "label": 0
                },
                {
                    "sent": "01 loss in terms of the log loss.",
                    "label": 0
                },
                {
                    "sent": "But the log loss of the basic classifier is bounded by the log loss of the best.",
                    "label": 1
                },
                {
                    "sent": "See.",
                    "label": 0
                },
                {
                    "sent": "Plus something which is logarithmic in the sample size.",
                    "label": 0
                },
                {
                    "sent": "And that is, it's actually.",
                    "label": 0
                },
                {
                    "sent": "It's a very standard thing based on prediction.",
                    "label": 0
                },
                {
                    "sent": "Why did so?",
                    "label": 0
                },
                {
                    "sent": "If you look?",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The basin log loss.",
                    "label": 0
                },
                {
                    "sent": "You can rewrite it as follows first, because all distributions are conditional, you put all the X values in the right of the commissioning bar like this.",
                    "label": 0
                },
                {
                    "sent": "So now you can use the chain rule to rewrite this.",
                    "label": 0
                },
                {
                    "sent": "So this sum becomes first product.",
                    "label": 0
                },
                {
                    "sent": "Now use the chain rule of probability distributions to right.",
                    "label": 0
                },
                {
                    "sent": "This is the probability for the whole sequence, because this is just a product of conditional probabilities by the definition of conditional probabilities that look like this if you write out the product and everything cancels except the very last term with ice equal to M and you get this.",
                    "label": 0
                },
                {
                    "sent": "So this summer from algorithmic prediction errors.",
                    "label": 0
                },
                {
                    "sent": "It's just the minus log marginal probability of the whole sequence of wise given X.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "This is the base and marginal probability.",
                    "label": 0
                },
                {
                    "sent": "So now for convenience I use a discrete prior.",
                    "label": 0
                },
                {
                    "sent": "I use a prior which is overall rational valued B test.",
                    "label": 0
                },
                {
                    "sent": "Then it will work.",
                    "label": 0
                },
                {
                    "sent": "So this is the base and some of the probability according to the classifier and beta according to the prior on the Classroom, beta summed over all classifiers and beat us.",
                    "label": 0
                },
                {
                    "sent": "That's just the definition of this.",
                    "label": 0
                },
                {
                    "sent": "So because the sum is larger than each of its terms.",
                    "label": 0
                },
                {
                    "sent": "The minus log of the summer smaller than the minus log of each of these terms.",
                    "label": 0
                },
                {
                    "sent": "So in particular this.",
                    "label": 0
                },
                {
                    "sent": "Smaller than the minus log of the probability you would have obtained.",
                    "label": 0
                },
                {
                    "sent": "With the optimal classifier.",
                    "label": 0
                },
                {
                    "sent": "And the beta, which is optimized for your sample.",
                    "label": 0
                },
                {
                    "sent": "Now, if you choose this prior in a clever way, then.",
                    "label": 0
                },
                {
                    "sent": "This beta will have a prior probability logarithmically in the sample size.",
                    "label": 0
                },
                {
                    "sent": "And this thing has a prior probability which is a constant because you have a countable set of classifiers, every single classifier is a constant prior probability.",
                    "label": 0
                },
                {
                    "sent": "This means that the sum of the logarithm prediction errors of base is bounded by.",
                    "label": 0
                },
                {
                    "sent": "The minus log likelihood of the best classifier which is equal to the sum of the logarithm prediction errors of the best classifier and the best pizza.",
                    "label": 0
                },
                {
                    "sent": "Plus something logarithmic.",
                    "label": 0
                },
                {
                    "sent": "Or is this will typically be linear.",
                    "label": 0
                },
                {
                    "sent": "So basically what this says is what people in prediction know that for prediction.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is always pretty good.",
                    "label": 0
                },
                {
                    "sent": "An in all sequences because.",
                    "label": 0
                },
                {
                    "sent": "The prediction of the base in terms of log loss.",
                    "label": 1
                },
                {
                    "sent": "Because base always bases never much worse than any individual predictor.",
                    "label": 0
                },
                {
                    "sent": "Because the sum is always larger than each of its terms.",
                    "label": 0
                },
                {
                    "sent": "So now you have two bounds here.",
                    "label": 1
                },
                {
                    "sent": "You know that the base and lock predictions bound the 01 sum of 01 losses.",
                    "label": 0
                },
                {
                    "sent": "And you know that they are themselves bounded by this minus log likelihood, according to the best classifier.",
                    "label": 0
                },
                {
                    "sent": "No, because we generate data IID.",
                    "label": 0
                },
                {
                    "sent": "This is a log likelihood.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Often iid.",
                    "label": 0
                },
                {
                    "sent": "According to an IID distribution, so it will converge to its expectation.",
                    "label": 0
                },
                {
                    "sent": "The expectation of this is just the expectation of a Bernie distribution CAS for fixed classifier.",
                    "label": 0
                },
                {
                    "sent": "If you would fix beta.",
                    "label": 0
                },
                {
                    "sent": "This would just be a binary distribution.",
                    "label": 0
                },
                {
                    "sent": "Basically, beta determines the probability that Y is not equal to X.",
                    "label": 0
                },
                {
                    "sent": "So if you take the expectation of this, this will approximately equal to M times the expected.",
                    "label": 0
                },
                {
                    "sent": "Minus log probability according to ability distribution, which is the entropy for any distribution.",
                    "label": 0
                },
                {
                    "sent": "And then you have to be careful.",
                    "label": 0
                },
                {
                    "sent": "Look at what happens with this beta, but it turns out that this is equal to this plus, well, it's the usual order square root of M, right?",
                    "label": 0
                },
                {
                    "sent": "If you divide by M converges.",
                    "label": 0
                },
                {
                    "sent": "So this means that if you divide this by M. You can also divide this by M, so then you get the total number of classification errors you make with base is bounded by the entropy.",
                    "label": 0
                },
                {
                    "sent": "Plus something which goes to 0.",
                    "label": 0
                },
                {
                    "sent": "So there's something.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Age here.",
                    "label": 0
                },
                {
                    "sent": "We showed here that the accumulated log loss.",
                    "label": 0
                },
                {
                    "sent": "If you predict with base.",
                    "label": 0
                },
                {
                    "sent": "It's always close to the log loss of the optimal.",
                    "label": 0
                },
                {
                    "sent": "Think this is optimal, both in the sense of.",
                    "label": 0
                },
                {
                    "sent": "Expected lock Lawson and sense of expected 01 loss.",
                    "label": 0
                },
                {
                    "sent": "So base is good with respect to log loss and this even if the true distribution is is far removed from your set of distribution.",
                    "label": 0
                },
                {
                    "sent": "But on the other hand base, that's our main theorem shows base can be bad with respect to 01 loss, you converge to something which is.",
                    "label": 0
                },
                {
                    "sent": "Which is much worse 01 loss than the optimal classifier.",
                    "label": 0
                },
                {
                    "sent": "So how is this possible?",
                    "label": 1
                },
                {
                    "sent": "Well?",
                    "label": 0
                },
                {
                    "sent": "Basically what happens is everything basis.",
                    "label": 0
                },
                {
                    "sent": "You get more and more data.",
                    "label": 0
                },
                {
                    "sent": "The posterior is a mix of bad classifiers.",
                    "label": 0
                },
                {
                    "sent": "And it turns out that if you mix these bad classifiers, you get a probability distribution which is closer in callback library vergence to the true distribution.",
                    "label": 0
                },
                {
                    "sent": "Then the best distribution in your model.",
                    "label": 1
                },
                {
                    "sent": "But in terms of 01, loss is actually much worse.",
                    "label": 0
                },
                {
                    "sent": "Then the.",
                    "label": 0
                },
                {
                    "sent": "Best distribution in your model.",
                    "label": 0
                },
                {
                    "sent": "So this is in a way, a strange thing.",
                    "label": 0
                },
                {
                    "sent": "Based always is good with respect to log loss, but because it is so good with respect to log loss, it actually starts making better predictions than the best thing inside your model.",
                    "label": 1
                },
                {
                    "sent": "And because it makes better predictions in the best thing in your model.",
                    "label": 0
                },
                {
                    "sent": "It screws up in terms of the 01 loss.",
                    "label": 0
                },
                {
                    "sent": "So you can actually prove that, yeah.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "So think of these what I said.",
                    "label": 1
                },
                {
                    "sent": "You have these for these hard examples.",
                    "label": 0
                },
                {
                    "sent": "Uh, these features predict the value of wiker correctly with probability 1/2 minus Delta.",
                    "label": 0
                },
                {
                    "sent": "They take a mixture of many of those probability distributions.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "So this mixture will still have that the probability that Y is one will be very close to 1/2.",
                    "label": 0
                },
                {
                    "sent": "So in terms of low class it will not be so bad.",
                    "label": 0
                },
                {
                    "sent": "But on the other hand.",
                    "label": 0
                },
                {
                    "sent": "If you take the base act with respect to the distribution, it will always err on the wrong side, so it will be if you have something very close so you have a mixture of things which they probably why is 1/2.",
                    "label": 0
                },
                {
                    "sent": "Then the low class is guaranteed to be one whether the outcome is zero or one is minus.",
                    "label": 0
                },
                {
                    "sent": "Log 1/2 is 1, but if the air on the wrong side of 1/2.",
                    "label": 0
                },
                {
                    "sent": "Then the 01 loss can always be one because.",
                    "label": 0
                },
                {
                    "sent": "Log loss loss is smooth, near 1/2 and 01 losses is not differentiable.",
                    "label": 0
                },
                {
                    "sent": "So it turns out you can even showed for say you have an arbitrary set of IID distributions.",
                    "label": 0
                },
                {
                    "sent": "And you have a prior on those which satisfy some very weak conditions.",
                    "label": 0
                },
                {
                    "sent": "You're not going to go into.",
                    "label": 0
                },
                {
                    "sent": "You can show that the only way.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In which base cannot converge to the distribution that's closest in KL divergent to the true distribution?",
                    "label": 0
                },
                {
                    "sent": "Is if the posterior predictive becomes closer than the best single distribution so?",
                    "label": 1
                },
                {
                    "sent": "There are two possibilities.",
                    "label": 0
                },
                {
                    "sent": "Either.",
                    "label": 0
                },
                {
                    "sent": "The base and posterior if you use it.",
                    "label": 0
                },
                {
                    "sent": "If you look at the callback library, diversions between the true distribution and the base and posterior.",
                    "label": 0
                },
                {
                    "sent": "Either that.",
                    "label": 0
                },
                {
                    "sent": "Either the base and posterior converges puts all its mess on the best distribution in your model.",
                    "label": 0
                },
                {
                    "sent": "So you have consistency.",
                    "label": 0
                },
                {
                    "sent": "Or it becomes a mixture of different distributions which are all worse.",
                    "label": 0
                },
                {
                    "sent": "But in that case the mixture must be better than the best distribution in your model.",
                    "label": 1
                },
                {
                    "sent": "So the only way in which base can be inconsistent.",
                    "label": 0
                },
                {
                    "sent": "Is by having the posterior.",
                    "label": 0
                },
                {
                    "sent": "Not converging to any single thing in your model, but becoming a mixture of things where the mixture is better.",
                    "label": 0
                },
                {
                    "sent": "Then the best thing in your model.",
                    "label": 0
                },
                {
                    "sent": "Sis.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "One more thing like how is this related to base income?",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is the result.",
                    "label": 0
                },
                {
                    "sent": "Suppose you have a countable set of conditional distributions and containing the true conditional distribution.",
                    "label": 0
                },
                {
                    "sent": "Then you can show this is well known.",
                    "label": 0
                },
                {
                    "sent": "A basic consistency theorem that the Bayesian posterior predictive distribution must converge.",
                    "label": 0
                },
                {
                    "sent": "The true distribution, for example, in terms of Challenger distance.",
                    "label": 0
                },
                {
                    "sent": "Slightly simplified here, it's if some conditions on the prior.",
                    "label": 0
                },
                {
                    "sent": "And if you have reconvergence in there, there are no no further conditions at all, just holds.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "If.",
                    "label": 0
                },
                {
                    "sent": "The base predictive distribution converges to the true conditional distribution.",
                    "label": 0
                },
                {
                    "sent": "Of course, if you use the distribution for classification.",
                    "label": 0
                },
                {
                    "sent": "So you take the base optimal classifier with respect to your posterior.",
                    "label": 0
                },
                {
                    "sent": "Then the generalization error of that thing must converge to the best achievable class generalization error to the base act.",
                    "label": 0
                },
                {
                    "sent": "Compare relative to the true distribution.",
                    "label": 0
                },
                {
                    "sent": "But in our in our case, this doesn't happen.",
                    "label": 1
                },
                {
                    "sent": "We have base base.",
                    "label": 1
                },
                {
                    "sent": "In our case, the basin algorithm, the basic posterior.",
                    "label": 0
                },
                {
                    "sent": "Predictive distribution converges goes to something which does not achieve the optimal classification error.",
                    "label": 0
                },
                {
                    "sent": "So it seems to be.",
                    "label": 0
                },
                {
                    "sent": "It seems to contradict Dupps consistency theorem.",
                    "label": 0
                },
                {
                    "sent": "And the reason it doesn't is because we have misspecification.",
                    "label": 0
                },
                {
                    "sent": "And basically what happens is that the way we set up our distribution.",
                    "label": 0
                },
                {
                    "sent": "We have our model assumes homoskedastic noise.",
                    "label": 1
                },
                {
                    "sent": "So basically, each classifier C expresses that Y is equal to CX and CX.",
                    "label": 0
                },
                {
                    "sent": "Maybe flip with probability independent of X.",
                    "label": 0
                },
                {
                    "sent": "But the way we construct AD.",
                    "label": 0
                },
                {
                    "sent": "If you have one classifier, it only listens to a particular component of the X vector and the other exact knowledge of the other X factors actually changes the probability that the classification is right.",
                    "label": 0
                },
                {
                    "sent": "So reality the noise depends on The X Factor.",
                    "label": 0
                },
                {
                    "sent": "So the true distributions heteroskedastic.",
                    "label": 0
                },
                {
                    "sent": "So therefore we have misspecification.",
                    "label": 0
                },
                {
                    "sent": "True distribution is not in the model we constructed, and therefore we have inconsistency.",
                    "label": 0
                },
                {
                    "sent": "We can have inconsistency.",
                    "label": 0
                },
                {
                    "sent": "Note, however, that we do have.",
                    "label": 0
                },
                {
                    "sent": "The base X in our model, so we have the set of distributions do not contain the true distribution, but the set of classifiers we started with.",
                    "label": 0
                },
                {
                    "sent": "Does contain the base optimal classifier with respect to the true distribution?",
                    "label": 0
                },
                {
                    "sent": "So in basic textbooks.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You often find that if you've misspecification based, still works in the sense that you converge to the distribution in your model which is closest in Cape Colbeck library versions to the true distribution.",
                    "label": 0
                },
                {
                    "sent": "The way we set with this logistic transformation, the way we transform classifiers to distributions.",
                    "label": 1
                },
                {
                    "sent": "Can we make sure that the thing closest in KL divergent to the true distribution in R model is actually a thing with the smallest classification error?",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 1
                },
                {
                    "sent": "So this means that these claims that base converges under misspecification to the distribution in your model closest in KL divergences.",
                    "label": 0
                },
                {
                    "sent": "True distribution is we have a counterexample to that.",
                    "label": 0
                },
                {
                    "sent": "It just doesn't happen here.",
                    "label": 0
                },
                {
                    "sent": "Because the distribution corresponding to each subject to see sub zero, the best classifier is the closest OK leverage and we do not converge to it.",
                    "label": 1
                },
                {
                    "sent": "So if you look at the literature, the precise theorems you indeed see that the conditions for consistency under special.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Vacation are actually much, much stronger than the conditions for standard consistency.",
                    "label": 0
                },
                {
                    "sent": "Basically, on a misspecification, your model must either be finite dimensional parametric and then of course most methods will converge in the end.",
                    "label": 0
                },
                {
                    "sent": "So maybe not so interesting.",
                    "label": 0
                },
                {
                    "sent": "Or it must be convex?",
                    "label": 0
                },
                {
                    "sent": "For example, if your model is the set of all Gaussian distributions or mixtures of Gaussians with fixed variance in an arbitrary number of convert of components, it's not parametric if arbitrating many components, but it's convex.",
                    "label": 0
                },
                {
                    "sent": "And then you do converge to the closest in KL Divergent.",
                    "label": 0
                },
                {
                    "sent": "And intuitively the reason for that is.",
                    "label": 0
                },
                {
                    "sent": "That the base and posterior predictive distribution is a mixture of distributions in your model.",
                    "label": 0
                },
                {
                    "sent": "If your model is convex, then the basin predictive distribution is always in your model, so you can never get this phenomenon.",
                    "label": 0
                },
                {
                    "sent": "I talk to you about that.",
                    "label": 0
                },
                {
                    "sent": "The base in predictive distribution is better than the best distribution in your model, right?",
                    "label": 0
                },
                {
                    "sent": "It can never be better because it's in your model.",
                    "label": 0
                },
                {
                    "sent": "And similarly, if.",
                    "label": 0
                },
                {
                    "sent": "The model contains the true distribution and also the basin predicted distribution can never be better than the best distribution model because there is no distribution.",
                    "label": 0
                },
                {
                    "sent": "Better model.",
                    "label": 0
                },
                {
                    "sent": "That is what you need for basic consistency that by mixing your model you can obtain something better.",
                    "label": 0
                },
                {
                    "sent": "Then what is in your model?",
                    "label": 0
                },
                {
                    "sent": "So I guess that's all I wanted to tell you.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Showed that.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Admittedly a very unrealistic problem, but the point is mainly to see that it can happen.",
                    "label": 0
                },
                {
                    "sent": "Just under wells face, it cannot happen.",
                    "label": 0
                },
                {
                    "sent": "Base can be inconsistent.",
                    "label": 0
                },
                {
                    "sent": "You might argue that basic machinery was never used, intended to use for misspecified models.",
                    "label": 1
                },
                {
                    "sent": "But of course I would claim that in practice it is done all the time.",
                    "label": 0
                },
                {
                    "sent": "Still, I don't want this to be.",
                    "label": 0
                },
                {
                    "sent": "Don't take this as don't use base.",
                    "label": 0
                },
                {
                    "sent": "I think in many practical problems Basics Basin methods are among the very best methods there are.",
                    "label": 0
                },
                {
                    "sent": "But claims that it is always the optimal thing to do I think are.",
                    "label": 0
                },
                {
                    "sent": "Shown by this examples and actually there are so many others earlier appeared in the literature.",
                    "label": 0
                },
                {
                    "sent": "Make sure that it's not as easy as that, so thank you.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The structure of adding up.",
                    "label": 0
                },
                {
                    "sent": "Actual 01 losses.",
                    "label": 0
                },
                {
                    "sent": "If you if you take that as the criterion capital, what is the what is the Bayes rule which would actually minimize that?",
                    "label": 0
                },
                {
                    "sent": "But I can control theory.",
                    "label": 0
                },
                {
                    "sent": "They had a great deviations overtime so that they have something for the offer.",
                    "label": 0
                },
                {
                    "sent": "Here directly fully.",
                    "label": 0
                },
                {
                    "sent": "Well, The thing is you need in order to do that.",
                    "label": 0
                },
                {
                    "sent": "You can interpret this is doing just that.",
                    "label": 0
                },
                {
                    "sent": "If you start out with if you start out with a set of conditional distributions and you have a prior on those, then you have a marginal distribution.",
                    "label": 0
                },
                {
                    "sent": "And then you can try to do this, but then you will do exactly the same as we do.",
                    "label": 0
                },
                {
                    "sent": "I didn't talk about that, it is yeah, but The thing is is.",
                    "label": 0
                },
                {
                    "sent": "But I had a preliminary step by first constructed these distributions out of classifiers.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "You gotta love someone so you could just dynamic program over actually do anything biopic one step ahead rule to minimize that.",
                    "label": 0
                },
                {
                    "sent": "Whole thing.",
                    "label": 0
                },
                {
                    "sent": "Is that So what do you think John?",
                    "label": 0
                },
                {
                    "sent": "So you?",
                    "label": 0
                },
                {
                    "sent": "Which forms well whenever you have.",
                    "label": 0
                },
                {
                    "sent": "A priori classifiers encouraged.",
                    "label": 0
                },
                {
                    "sent": "Minimizing open vision.",
                    "label": 0
                },
                {
                    "sent": "That is.",
                    "label": 0
                },
                {
                    "sent": "Think about having a varying month running direction for classifier depends upon the prior.",
                    "label": 0
                },
                {
                    "sent": "Minimizes, it's about measuring.",
                    "label": 0
                },
                {
                    "sent": "But that's.",
                    "label": 0
                },
                {
                    "sent": "I would have to think about what you, what, what you would get then I guess I don't know whether you would get something completely different or not.",
                    "label": 0
                },
                {
                    "sent": "Can't answer it right now.",
                    "label": 0
                },
                {
                    "sent": "This type of standing.",
                    "label": 0
                }
            ]
        }
    }
}