{
    "id": "22epsxsvivl4o6cae55uy7jxaquvirgx",
    "title": "University of Karlsruhe Acoustic Speaker Tracking System",
    "info": {
        "author": [
            "Tobias Gehrig, University of Karlsruhe"
        ],
        "published": "Feb. 25, 2007",
        "recorded": "June 2005",
        "category": [
            "Top->Computer Science->Speech Analysis"
        ]
    },
    "url": "http://videolectures.net/mlmi04uk_gehrig_ukast/",
    "segmentation": [
        [
            "We made it casserole.",
            "At first I will too."
        ],
        [
            "Talk about audio features and then explain the common filter we use and afterwards show you how to incorporate dynamic models for speaker motion.",
            "And afterwards I show you how to make the common filter bit more robust against outliers.",
            "And then some experimental results.",
            "And if there's time I will also show you some things how to also incorporate with your features.",
            "So as we saw, we also used."
        ],
        [
            "The time delay of arrival estimation using the phase transformation.",
            "Face transform and.",
            "Then use the maximum of this.",
            "Now we use the time delay that maximizes this phase transform.",
            "And yet at the.",
            "ABC, How we theoretically get a time delay for specific possession.",
            "Position X.",
            "And now we want to minimize this difference between the estimated and the calculated time delay.",
            "And we do that with the iterated count."
        ],
        [
            "Extended common filter.",
            "Extended, filter is needed because the time delay of arrival function is nonlinear, so we need some linearisation.",
            "And the iterated Kalman filter we use because we want to minimize the error between curing through the linearisation and by doing many local iterations we can minimize this error.",
            "NBF here the time dilay.",
            "And that's the last position estimate.",
            "And we get this innovation vector by taking the difference between the time delay and estimate come a time delay calculated from the less precision estimate and then.",
            "And.",
            "By multiplying the difference between less precision estimate and the last local position estimate by the gradient of the time delay of arrival function, we get then edit with innovation vector and then multiplied by the common gain we get the new precision estimate.",
            "And this local iteration is then iterated until the difference between the position estimate the less precision estimate ended last local precision estimate is below some threshold.",
            "And then to get to the next time step we have to.",
            "Transition metrics.",
            "Which we can use for dynamic models then?"
        ],
        [
            "To model the motion of speaker.",
            "And then here we get to the next time step by introducing a delay.",
            "So the motion of the speaker is then modeled like I said by that transition matrix F. And we could think of many of more than one model like static.",
            "Aesthetic position or constant position or constant velocity or constant acceleration, but we only used constant position so we have a transition matrix.",
            "That's the identity and process noise it's given here.",
            "By this metrics the time between the last update and current time.",
            "And multiplied by the covariance."
        ],
        [
            "And to make the comment field a bit more robust, we be compared the innovation vector to the square root of the diagonal elements of the innovation covariance matrix.",
            "That's given into the common filter.",
            "And that gives us the possibility to detect outliers.",
            "So if the position estimate is outside of this.",
            "The area that's covered by the innovation covariance?",
            "Then you say it's not lying.",
            "If if it's in it's in this area, then we have valid position estimate.",
            "So here."
        ],
        [
            "Is the set up as we saw before, and so the develop on the development set.",
            "We did experiments.",
            "But without.",
            "Speech activity detection and got an error message error of 3553 centimeters.",
            "And also tried to use speech activity labels that were processed on the close talking microphone and discover improvement of Rant Free CMS.",
            "We used to pass 12132 and three and three and four of the TRS B&D and at maximum the local iterations of the common filter five times.",
            "And here we have to process nice 50 centimeters, 18 centimeters."
        ],
        [
            "2nd and three centimeters per second so xyc.",
            "And measurement noise of 0.09 milliseconds.",
            "And the threshold we used on the time delay to detect.",
            "Yeah, it's somehow speech activity takes from, but that's.",
            "Well, that's good, but we use this threshold on this time delay function on the cross correlation and that was given by 0.8818.",
            "And we use the Hamming window of 20 milliseconds.",
            "Shifted by 10 milliseconds.",
            "And yeah, like I said, we use the simple constant threshold overall seminar segments on the correlation values.",
            "And."
        ],
        [
            "As John said before, they had some trouble with the results, so here's the revised results.",
            "Now with 38.5.",
            "CM RMS error.",
            "And every frame is now 15 since.",
            "Yeah, there was some frames.",
            "To Excel."
        ],
        [
            "And it's now with video features.",
            "We use face detector, let's run on all the four cameras in the corners of the room and then we will check the we have here.",
            "The position of the face detector that's returned or face sector.",
            "And we have the last estimate of the speaker from the common filter.",
            "This is projected into the image plane of the camera and the difference between those two points gives us the new innovation vector.",
            "And then further processing the common filter like for the other side and.",
            "We have been not gradient of the time delay of real function, but the gradient of the projection function.",
            "And.",
            "Sad."
        ],
        [
            "I don't have the results for the head, not the time to prove.",
            "To process the results for the evaluation sets with the same system.",
            "So that's some older results.",
            "That's why the audio only is in centimeters, but we see that combined version is is around 11 centimeters better than audio only, and that's.",
            "Worth processed on the relation set of the Chill Revelation 2005.",
            "And I used the same parameters for each mode.",
            "So that there was a good comparison between between those three modes.",
            "And here I use all the combination of microphone pass not only the T of the tiare, but all combinations of the areas, B&D and all four cameras in the corner.",
            "And yeah, we you saw that we don't use any closed form estimation.",
            "Position estimation, but it's.",
            "Yeah, rather incorporated into common film into the carbon filter.",
            "And it was processed on the read seminar data like all this."
        ],
        [
            "Done.",
            "And.",
            "When we video only as we saw here is not very good.",
            "So if you can improve that number then we probably also get better combined result.",
            "And also if we introduce speech activity detection and nice reduction techniques, then probably also the audio features get better results so that we get yeah better this organization.",
            "Thank you."
        ],
        [
            "I feed you.",
            "So here's a video of seminar with the.",
            "The Red dot red rectangle."
        ],
        [
            "What is the position estimate from the common filter and the yellow rectangle?",
            "Is the position given by the video labels?",
            "And that's audio only, so.",
            "It's somehow yeah incorrect.",
            "Should be.",
            "So."
        ],
        [
            "That or you video.",
            "They should be.",
            "Yeah, yeah you see in green rectangle that's when face is detected.",
            "And yeah, the other things.",
            "Same As for the audio only."
        ],
        [
            "And if I would show the video little bit longer, then it would seem that for video, if I would show you the video only, so then you would see that video only at some point lose track and that combined version gives us the possibility to avoid this."
        ],
        [
            "Show this audio video source localization.",
            "Because we're proposing that as a task for next time.",
            "Discuss that.",
            "Questions are.",
            "Also.",
            "Very difficult.",
            "Is worth the combination.",
            "Search quite challenges."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We made it casserole.",
                    "label": 0
                },
                {
                    "sent": "At first I will too.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Talk about audio features and then explain the common filter we use and afterwards show you how to incorporate dynamic models for speaker motion.",
                    "label": 1
                },
                {
                    "sent": "And afterwards I show you how to make the common filter bit more robust against outliers.",
                    "label": 0
                },
                {
                    "sent": "And then some experimental results.",
                    "label": 0
                },
                {
                    "sent": "And if there's time I will also show you some things how to also incorporate with your features.",
                    "label": 0
                },
                {
                    "sent": "So as we saw, we also used.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The time delay of arrival estimation using the phase transformation.",
                    "label": 1
                },
                {
                    "sent": "Face transform and.",
                    "label": 0
                },
                {
                    "sent": "Then use the maximum of this.",
                    "label": 1
                },
                {
                    "sent": "Now we use the time delay that maximizes this phase transform.",
                    "label": 0
                },
                {
                    "sent": "And yet at the.",
                    "label": 0
                },
                {
                    "sent": "ABC, How we theoretically get a time delay for specific possession.",
                    "label": 0
                },
                {
                    "sent": "Position X.",
                    "label": 0
                },
                {
                    "sent": "And now we want to minimize this difference between the estimated and the calculated time delay.",
                    "label": 1
                },
                {
                    "sent": "And we do that with the iterated count.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Extended common filter.",
                    "label": 0
                },
                {
                    "sent": "Extended, filter is needed because the time delay of arrival function is nonlinear, so we need some linearisation.",
                    "label": 0
                },
                {
                    "sent": "And the iterated Kalman filter we use because we want to minimize the error between curing through the linearisation and by doing many local iterations we can minimize this error.",
                    "label": 0
                },
                {
                    "sent": "NBF here the time dilay.",
                    "label": 0
                },
                {
                    "sent": "And that's the last position estimate.",
                    "label": 0
                },
                {
                    "sent": "And we get this innovation vector by taking the difference between the time delay and estimate come a time delay calculated from the less precision estimate and then.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "By multiplying the difference between less precision estimate and the last local position estimate by the gradient of the time delay of arrival function, we get then edit with innovation vector and then multiplied by the common gain we get the new precision estimate.",
                    "label": 0
                },
                {
                    "sent": "And this local iteration is then iterated until the difference between the position estimate the less precision estimate ended last local precision estimate is below some threshold.",
                    "label": 0
                },
                {
                    "sent": "And then to get to the next time step we have to.",
                    "label": 0
                },
                {
                    "sent": "Transition metrics.",
                    "label": 0
                },
                {
                    "sent": "Which we can use for dynamic models then?",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To model the motion of speaker.",
                    "label": 0
                },
                {
                    "sent": "And then here we get to the next time step by introducing a delay.",
                    "label": 0
                },
                {
                    "sent": "So the motion of the speaker is then modeled like I said by that transition matrix F. And we could think of many of more than one model like static.",
                    "label": 1
                },
                {
                    "sent": "Aesthetic position or constant position or constant velocity or constant acceleration, but we only used constant position so we have a transition matrix.",
                    "label": 0
                },
                {
                    "sent": "That's the identity and process noise it's given here.",
                    "label": 0
                },
                {
                    "sent": "By this metrics the time between the last update and current time.",
                    "label": 0
                },
                {
                    "sent": "And multiplied by the covariance.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And to make the comment field a bit more robust, we be compared the innovation vector to the square root of the diagonal elements of the innovation covariance matrix.",
                    "label": 0
                },
                {
                    "sent": "That's given into the common filter.",
                    "label": 0
                },
                {
                    "sent": "And that gives us the possibility to detect outliers.",
                    "label": 0
                },
                {
                    "sent": "So if the position estimate is outside of this.",
                    "label": 0
                },
                {
                    "sent": "The area that's covered by the innovation covariance?",
                    "label": 0
                },
                {
                    "sent": "Then you say it's not lying.",
                    "label": 0
                },
                {
                    "sent": "If if it's in it's in this area, then we have valid position estimate.",
                    "label": 0
                },
                {
                    "sent": "So here.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is the set up as we saw before, and so the develop on the development set.",
                    "label": 0
                },
                {
                    "sent": "We did experiments.",
                    "label": 0
                },
                {
                    "sent": "But without.",
                    "label": 0
                },
                {
                    "sent": "Speech activity detection and got an error message error of 3553 centimeters.",
                    "label": 0
                },
                {
                    "sent": "And also tried to use speech activity labels that were processed on the close talking microphone and discover improvement of Rant Free CMS.",
                    "label": 0
                },
                {
                    "sent": "We used to pass 12132 and three and three and four of the TRS B&D and at maximum the local iterations of the common filter five times.",
                    "label": 0
                },
                {
                    "sent": "And here we have to process nice 50 centimeters, 18 centimeters.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "2nd and three centimeters per second so xyc.",
                    "label": 0
                },
                {
                    "sent": "And measurement noise of 0.09 milliseconds.",
                    "label": 0
                },
                {
                    "sent": "And the threshold we used on the time delay to detect.",
                    "label": 0
                },
                {
                    "sent": "Yeah, it's somehow speech activity takes from, but that's.",
                    "label": 0
                },
                {
                    "sent": "Well, that's good, but we use this threshold on this time delay function on the cross correlation and that was given by 0.8818.",
                    "label": 0
                },
                {
                    "sent": "And we use the Hamming window of 20 milliseconds.",
                    "label": 0
                },
                {
                    "sent": "Shifted by 10 milliseconds.",
                    "label": 0
                },
                {
                    "sent": "And yeah, like I said, we use the simple constant threshold overall seminar segments on the correlation values.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As John said before, they had some trouble with the results, so here's the revised results.",
                    "label": 0
                },
                {
                    "sent": "Now with 38.5.",
                    "label": 0
                },
                {
                    "sent": "CM RMS error.",
                    "label": 0
                },
                {
                    "sent": "And every frame is now 15 since.",
                    "label": 0
                },
                {
                    "sent": "Yeah, there was some frames.",
                    "label": 0
                },
                {
                    "sent": "To Excel.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And it's now with video features.",
                    "label": 0
                },
                {
                    "sent": "We use face detector, let's run on all the four cameras in the corners of the room and then we will check the we have here.",
                    "label": 0
                },
                {
                    "sent": "The position of the face detector that's returned or face sector.",
                    "label": 1
                },
                {
                    "sent": "And we have the last estimate of the speaker from the common filter.",
                    "label": 0
                },
                {
                    "sent": "This is projected into the image plane of the camera and the difference between those two points gives us the new innovation vector.",
                    "label": 1
                },
                {
                    "sent": "And then further processing the common filter like for the other side and.",
                    "label": 0
                },
                {
                    "sent": "We have been not gradient of the time delay of real function, but the gradient of the projection function.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Sad.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I don't have the results for the head, not the time to prove.",
                    "label": 0
                },
                {
                    "sent": "To process the results for the evaluation sets with the same system.",
                    "label": 0
                },
                {
                    "sent": "So that's some older results.",
                    "label": 0
                },
                {
                    "sent": "That's why the audio only is in centimeters, but we see that combined version is is around 11 centimeters better than audio only, and that's.",
                    "label": 0
                },
                {
                    "sent": "Worth processed on the relation set of the Chill Revelation 2005.",
                    "label": 0
                },
                {
                    "sent": "And I used the same parameters for each mode.",
                    "label": 1
                },
                {
                    "sent": "So that there was a good comparison between between those three modes.",
                    "label": 0
                },
                {
                    "sent": "And here I use all the combination of microphone pass not only the T of the tiare, but all combinations of the areas, B&D and all four cameras in the corner.",
                    "label": 1
                },
                {
                    "sent": "And yeah, we you saw that we don't use any closed form estimation.",
                    "label": 0
                },
                {
                    "sent": "Position estimation, but it's.",
                    "label": 0
                },
                {
                    "sent": "Yeah, rather incorporated into common film into the carbon filter.",
                    "label": 0
                },
                {
                    "sent": "And it was processed on the read seminar data like all this.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Done.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "When we video only as we saw here is not very good.",
                    "label": 0
                },
                {
                    "sent": "So if you can improve that number then we probably also get better combined result.",
                    "label": 0
                },
                {
                    "sent": "And also if we introduce speech activity detection and nice reduction techniques, then probably also the audio features get better results so that we get yeah better this organization.",
                    "label": 1
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I feed you.",
                    "label": 0
                },
                {
                    "sent": "So here's a video of seminar with the.",
                    "label": 0
                },
                {
                    "sent": "The Red dot red rectangle.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What is the position estimate from the common filter and the yellow rectangle?",
                    "label": 1
                },
                {
                    "sent": "Is the position given by the video labels?",
                    "label": 0
                },
                {
                    "sent": "And that's audio only, so.",
                    "label": 0
                },
                {
                    "sent": "It's somehow yeah incorrect.",
                    "label": 0
                },
                {
                    "sent": "Should be.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That or you video.",
                    "label": 0
                },
                {
                    "sent": "They should be.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah you see in green rectangle that's when face is detected.",
                    "label": 0
                },
                {
                    "sent": "And yeah, the other things.",
                    "label": 0
                },
                {
                    "sent": "Same As for the audio only.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And if I would show the video little bit longer, then it would seem that for video, if I would show you the video only, so then you would see that video only at some point lose track and that combined version gives us the possibility to avoid this.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Show this audio video source localization.",
                    "label": 0
                },
                {
                    "sent": "Because we're proposing that as a task for next time.",
                    "label": 0
                },
                {
                    "sent": "Discuss that.",
                    "label": 0
                },
                {
                    "sent": "Questions are.",
                    "label": 0
                },
                {
                    "sent": "Also.",
                    "label": 0
                },
                {
                    "sent": "Very difficult.",
                    "label": 0
                },
                {
                    "sent": "Is worth the combination.",
                    "label": 0
                },
                {
                    "sent": "Search quite challenges.",
                    "label": 0
                }
            ]
        }
    }
}