{
    "id": "eyrvnwveyktmm3aelcgo3nzlmhkbcaqp",
    "title": "FBLG: A Simple and Effective Approach for Temporal Dependence Discovery from Time Series Data",
    "info": {
        "author": [
            "Dehua Cheng, Computer Science Department, University of Southern California"
        ],
        "published": "Oct. 7, 2014",
        "recorded": "August 2014",
        "category": [
            "Top->Computer Science->Data Mining",
            "Top->Computer Science->Knowledge Extraction"
        ]
    },
    "url": "http://videolectures.net/kdd2014_cheng_temporal_dependence/",
    "segmentation": [
        [
            "Hello everyone, my name is still home and I'm here to present our research on improving the temporal dependency discovery.",
            "This is joint work with as introduced.",
            "It's with my lab mates, Amitabh powdery and my advisor yellow."
        ],
        [
            "Let's first let's discuss the problem of the temporal dependency discovery and let me first start with an application in the social network analysis.",
            "Many applications in social social network analysis that actually requires us to accurately accurately identify the influence between the users.",
            "For example, if you want to pay someone to advertise for you, then you better pick up the set of user that will maximize the total influence.",
            "However, to achieve that, you need to know the influence between the users and.",
            "However, this inference network is hidden from us and what we have is just tons of data on the user activities.",
            "So natural question to ask is how can we use the data we have to find this underlying influence network.",
            "We want.",
            "One possible approach is to use the temporal dependence discovery algorithms for time series.",
            "To do that, first we need to convert the data to a multivariate time series about all the users.",
            "For example, on the Twitter we can count the number of tweets are user have treated within a time interval and this naturally becomes becomes a multivariate time series and then we can apply the algorithm on it to discover the temporal dependency between these users and this will serve as approximation to the underlying influence networks.",
            "And of course the temporal dependence discoveries are not limited to the social network analysis.",
            "You can also use it for.",
            "Gene regulatory network discovery and also we can also use for the climate science and many more."
        ],
        [
            "There is a lot of remarkable works having proposed on this problem and across many disciplines.",
            "For example, in economics there is a large family of the algorithm that is based on the Granger causality.",
            "For example, there is a significant significance test based algorithm and the one we want to remark is the Lasso Granger approach.",
            "You can see that this is the objective function and the first part is to a fit vector autoregressive model and the last term is to impose one type of regulator on the coefficient matrix and this loss of Ranger actually provides more robust inference results, especially in the high dimensional setting when we don't have.",
            "Enough data.",
            "And also there are some other algorithms.",
            "For example there are based on the generalized linear model, which is more versatile than the VAR model.",
            "And also there are kernelized regression xanim.",
            "Anymore there is another life research that is nonparametric approaches for example in physics they are using some information theoretic approach, for example as transfer entropy to measure the director information flow on the network and also in statistics there are.",
            "Techniques as the auto correlations."
        ],
        [
            "But they're all facing similar challenges nowadays.",
            "The first one is that because for the real world data, we never know the underlying model, so we are facing the problem of the model misspecification and how can we provide a robust, reasonable estimation under this case.",
            "Another challenge is that high dimensional case we are, we don't have enough data or the size of network is much larger than the data we have.",
            "Under this case, how can we use?",
            "How can we dig all the information in the data we have?",
            "I will motivate our approach by a simple toy example.",
            "This is a bivariate time series and you can consider this as a 2 user tweeting and the time series captures tweeting activities.",
            "User B actually retweets a sometimes but not the other way around, so for this time series temporal dependence Discovery algorithm should suggest that a triggers be.",
            "The question will actually, how about we reverse the time by changing the time label from Tita minus T?",
            "Actually the underlying trigonal relationship is still there with the only difference is that now a will post after be.",
            "So intuitively, a reasonable algorithm should suggest that it looked like B triggers a, so the edge is still there, only the direction of the edge flipped.",
            "And from now on we will call the original time series as a forward time series and the time reversed one as backward time series and we will also make very bold assertion that dependency graph of the forward Time series will be very similar to the transpose.",
            "The dependency graph of the backward Time series and this transpose operation actually representing the flip of the direction of the graph of the edges.",
            "Our approach is to combine the forward time series and the Backward Time series to provide a more reliable estimations."
        ],
        [
            "Before we move on, let's first answer several questions.",
            "The first one, is that OK there any new information in the backward Time series?",
            "Technically no right, because exactly the same data containing exactly the same information.",
            "But however this doesn't mean that we are not able to use this approach to help with the help with our task, because it's possible that there are some information that cannot has been overlooked by the algorithm in the forward time series, but it can be later.",
            "Pick it up from the Backward Time series and the data if the data actually.",
            "Owners our arguments, then by enforcing this type for relationship might help to provide more robust estimations.",
            "And indeed, this similar idea has been applied in the natural language processing as in the backward language model, where they actually estimating the Markov chain from the other direction, and indeed they can.",
            "They say that they can provide some complementary informations to the forward language model and combining both forward and backward language model.",
            "They can improve the performance.",
            "The next question is OK then how we do this combination?",
            "Because we have said that the similarity between the dependency graph.",
            "So let's just think in the simplest way, the simplest way to combine the result is just to combine their dependency graph.",
            "For example, if your algorithm actually provides a numerical value for each edge, that indicating the strength of this dependency, then the way to combine it just too average on both graphs.",
            "The core advantage of this simplest approach is that you only need to run your algorithm twice, so basically that means it's as efficient as your own algorithm.",
            "And of course we can use more sophisticated approach to do the combination.",
            "For example, we can use group loss or type of penalty to enforce this relationship.",
            "The next question will be OK. Is something intuitive and makes sense.",
            "Hopefully for the simple toy example, but does that actually generalize to other models that we use in the real real applications?",
            "Our answer is yes for many model that it is true for."
        ],
        [
            "Sample we have studied the well known vector autoregressive model.",
            "We have proved that if the forward time series follows the vector autoregressive model with coefficient matrix A, then the backward time serves backward.",
            "Time series will also follow the VAR model with the coefficient matrix B which is approximately equals to the transpose of A.",
            "We also prove something for the time series with binary values, similar as in the motivating example.",
            "But here we did not specify.",
            "A model we just have a several general assumptions, and if this model satisfies this set of assumptions and we will say that OK, it is also true for this model."
        ],
        [
            "As next step, besides this general methodology, we also combine it with a specific temporal dependency discovery algorithms to to test its performance will choose the loss of grandeur that we remarked previously and are the result of the algorithm is extremely simple, so the first step is just to apply the loss of grandeur on the forward time series.",
            "The next step is just applied again, but on the backward time series and in the end we just output the average with appropriate transposing.",
            "We have to evaluate this algorithm on both synthetic data and real world data.",
            "For synthetic data we have generated data time series from the bar model and the several generalized linear model.",
            "The Poly actually representing a type of generalized linear model where instead of using the linear function as link function, we use a higher order polynomial trying to simulate the nonlinear ality in the time series.",
            "And the log in.",
            "I see our time zero.",
            "Also generalized linear model with binary values and they all satisfies our set of assumptions.",
            "We also vary the length of the time series we generated trying to study the high dimensional or low dimensional case where we have a sufficient data or limited data on the real world.",
            "Data we have tested on the Twitter Haiti data which is tweeting activity we collected after the Haiti earthquake.",
            "And also we tested on the biologic data, the microarray data to predict the gene regulatory networks."
        ],
        [
            "OK, now let's see the experiment result on the synthetic data.",
            "Let's first see the result on the VAR model and Poly model.",
            "This is under high dimensional case where data is limited and you can see that the forward backward loss of grandeur outperforms the original loss of grandeur and the CLG for the Poly model is actually popular.",
            "Lots of grandeur where we first apply a copular transformation trying to address the non rat issue and then apply lots of grandeur.",
            "For the low demand case, when we have sufficient data, the performance is there's no significant difference in there.",
            "The most interesting case here is the the log an IC model.",
            "So no matter it's Heidi mental case or the low demand in case the forward backward version always outperforms the original original.",
            "Also Granger an hour explanation is that this is exactly the case of the model misspecification.",
            "Because it's a binary value time series and our forward backward approach indeed can help under this type of case.",
            "To provide more robust estimations."
        ],
        [
            "Next, this is result on the heavy data set and rulers at first like.",
            "See the heavy data.",
            "The task here is to discover the underlying dependence graph between the users.",
            "The ground truth we use is.",
            "Perfect is the actual retreat network, but this is the best we have right now.",
            "You can see that the forward backward loss of grandeur outperform the loss of grandeur as expected and also more interesting.",
            "Interestingly, we also apply this approach on the transfer entropy that we previously mentioned.",
            "It also helps under that case.",
            "On the right hand side, it's result on the micro rate data and the ground truth you provided by the website.",
            "The bio grade and you can see that in terms of the you see the forward backward loss of Ranger outperforms originally, so Granger."
        ],
        [
            "So in conclusion, we think that this forward backward approach is indeed an intuitive and effective way to improve the temporal dependence discovery on time series data and also the forward backward loss of Granger.",
            "The algorithm is also an efficient and effective algorithm under various circumstances.",
            "And if you want to ask me the question when should we apply this algorithm, then I think first it's reasonable to assume that the forward only lost grandeur should provide you with a reasonable result for us to improve upon.",
            "And also especially helpful if it's under the high dimensional case, as future work we think that it's worth to study other more sophisticated approach to do the combination.",
            "An also inspired by the result on the transfer entropy with things that this approach.",
            "Indeed we need to study this approach on the other temporal dependence discovery algorithms, and indeed because the simplest combination approach is basically free.",
            "So if you have evaluated very good evaluation metrics for your problem, I encourage encourage you guys to try this out, and I will thank you for that.",
            "And thank you for listening.",
            "I'll take questions from now."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hello everyone, my name is still home and I'm here to present our research on improving the temporal dependency discovery.",
                    "label": 0
                },
                {
                    "sent": "This is joint work with as introduced.",
                    "label": 0
                },
                {
                    "sent": "It's with my lab mates, Amitabh powdery and my advisor yellow.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let's first let's discuss the problem of the temporal dependency discovery and let me first start with an application in the social network analysis.",
                    "label": 0
                },
                {
                    "sent": "Many applications in social social network analysis that actually requires us to accurately accurately identify the influence between the users.",
                    "label": 0
                },
                {
                    "sent": "For example, if you want to pay someone to advertise for you, then you better pick up the set of user that will maximize the total influence.",
                    "label": 0
                },
                {
                    "sent": "However, to achieve that, you need to know the influence between the users and.",
                    "label": 0
                },
                {
                    "sent": "However, this inference network is hidden from us and what we have is just tons of data on the user activities.",
                    "label": 0
                },
                {
                    "sent": "So natural question to ask is how can we use the data we have to find this underlying influence network.",
                    "label": 0
                },
                {
                    "sent": "We want.",
                    "label": 0
                },
                {
                    "sent": "One possible approach is to use the temporal dependence discovery algorithms for time series.",
                    "label": 0
                },
                {
                    "sent": "To do that, first we need to convert the data to a multivariate time series about all the users.",
                    "label": 0
                },
                {
                    "sent": "For example, on the Twitter we can count the number of tweets are user have treated within a time interval and this naturally becomes becomes a multivariate time series and then we can apply the algorithm on it to discover the temporal dependency between these users and this will serve as approximation to the underlying influence networks.",
                    "label": 0
                },
                {
                    "sent": "And of course the temporal dependence discoveries are not limited to the social network analysis.",
                    "label": 1
                },
                {
                    "sent": "You can also use it for.",
                    "label": 1
                },
                {
                    "sent": "Gene regulatory network discovery and also we can also use for the climate science and many more.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There is a lot of remarkable works having proposed on this problem and across many disciplines.",
                    "label": 0
                },
                {
                    "sent": "For example, in economics there is a large family of the algorithm that is based on the Granger causality.",
                    "label": 1
                },
                {
                    "sent": "For example, there is a significant significance test based algorithm and the one we want to remark is the Lasso Granger approach.",
                    "label": 0
                },
                {
                    "sent": "You can see that this is the objective function and the first part is to a fit vector autoregressive model and the last term is to impose one type of regulator on the coefficient matrix and this loss of Ranger actually provides more robust inference results, especially in the high dimensional setting when we don't have.",
                    "label": 0
                },
                {
                    "sent": "Enough data.",
                    "label": 0
                },
                {
                    "sent": "And also there are some other algorithms.",
                    "label": 0
                },
                {
                    "sent": "For example there are based on the generalized linear model, which is more versatile than the VAR model.",
                    "label": 1
                },
                {
                    "sent": "And also there are kernelized regression xanim.",
                    "label": 1
                },
                {
                    "sent": "Anymore there is another life research that is nonparametric approaches for example in physics they are using some information theoretic approach, for example as transfer entropy to measure the director information flow on the network and also in statistics there are.",
                    "label": 0
                },
                {
                    "sent": "Techniques as the auto correlations.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But they're all facing similar challenges nowadays.",
                    "label": 0
                },
                {
                    "sent": "The first one is that because for the real world data, we never know the underlying model, so we are facing the problem of the model misspecification and how can we provide a robust, reasonable estimation under this case.",
                    "label": 0
                },
                {
                    "sent": "Another challenge is that high dimensional case we are, we don't have enough data or the size of network is much larger than the data we have.",
                    "label": 0
                },
                {
                    "sent": "Under this case, how can we use?",
                    "label": 1
                },
                {
                    "sent": "How can we dig all the information in the data we have?",
                    "label": 0
                },
                {
                    "sent": "I will motivate our approach by a simple toy example.",
                    "label": 0
                },
                {
                    "sent": "This is a bivariate time series and you can consider this as a 2 user tweeting and the time series captures tweeting activities.",
                    "label": 0
                },
                {
                    "sent": "User B actually retweets a sometimes but not the other way around, so for this time series temporal dependence Discovery algorithm should suggest that a triggers be.",
                    "label": 0
                },
                {
                    "sent": "The question will actually, how about we reverse the time by changing the time label from Tita minus T?",
                    "label": 1
                },
                {
                    "sent": "Actually the underlying trigonal relationship is still there with the only difference is that now a will post after be.",
                    "label": 0
                },
                {
                    "sent": "So intuitively, a reasonable algorithm should suggest that it looked like B triggers a, so the edge is still there, only the direction of the edge flipped.",
                    "label": 0
                },
                {
                    "sent": "And from now on we will call the original time series as a forward time series and the time reversed one as backward time series and we will also make very bold assertion that dependency graph of the forward Time series will be very similar to the transpose.",
                    "label": 1
                },
                {
                    "sent": "The dependency graph of the backward Time series and this transpose operation actually representing the flip of the direction of the graph of the edges.",
                    "label": 0
                },
                {
                    "sent": "Our approach is to combine the forward time series and the Backward Time series to provide a more reliable estimations.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Before we move on, let's first answer several questions.",
                    "label": 0
                },
                {
                    "sent": "The first one, is that OK there any new information in the backward Time series?",
                    "label": 1
                },
                {
                    "sent": "Technically no right, because exactly the same data containing exactly the same information.",
                    "label": 0
                },
                {
                    "sent": "But however this doesn't mean that we are not able to use this approach to help with the help with our task, because it's possible that there are some information that cannot has been overlooked by the algorithm in the forward time series, but it can be later.",
                    "label": 0
                },
                {
                    "sent": "Pick it up from the Backward Time series and the data if the data actually.",
                    "label": 0
                },
                {
                    "sent": "Owners our arguments, then by enforcing this type for relationship might help to provide more robust estimations.",
                    "label": 0
                },
                {
                    "sent": "And indeed, this similar idea has been applied in the natural language processing as in the backward language model, where they actually estimating the Markov chain from the other direction, and indeed they can.",
                    "label": 0
                },
                {
                    "sent": "They say that they can provide some complementary informations to the forward language model and combining both forward and backward language model.",
                    "label": 0
                },
                {
                    "sent": "They can improve the performance.",
                    "label": 0
                },
                {
                    "sent": "The next question is OK then how we do this combination?",
                    "label": 0
                },
                {
                    "sent": "Because we have said that the similarity between the dependency graph.",
                    "label": 0
                },
                {
                    "sent": "So let's just think in the simplest way, the simplest way to combine the result is just to combine their dependency graph.",
                    "label": 0
                },
                {
                    "sent": "For example, if your algorithm actually provides a numerical value for each edge, that indicating the strength of this dependency, then the way to combine it just too average on both graphs.",
                    "label": 0
                },
                {
                    "sent": "The core advantage of this simplest approach is that you only need to run your algorithm twice, so basically that means it's as efficient as your own algorithm.",
                    "label": 0
                },
                {
                    "sent": "And of course we can use more sophisticated approach to do the combination.",
                    "label": 0
                },
                {
                    "sent": "For example, we can use group loss or type of penalty to enforce this relationship.",
                    "label": 0
                },
                {
                    "sent": "The next question will be OK. Is something intuitive and makes sense.",
                    "label": 0
                },
                {
                    "sent": "Hopefully for the simple toy example, but does that actually generalize to other models that we use in the real real applications?",
                    "label": 0
                },
                {
                    "sent": "Our answer is yes for many model that it is true for.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Sample we have studied the well known vector autoregressive model.",
                    "label": 0
                },
                {
                    "sent": "We have proved that if the forward time series follows the vector autoregressive model with coefficient matrix A, then the backward time serves backward.",
                    "label": 1
                },
                {
                    "sent": "Time series will also follow the VAR model with the coefficient matrix B which is approximately equals to the transpose of A.",
                    "label": 0
                },
                {
                    "sent": "We also prove something for the time series with binary values, similar as in the motivating example.",
                    "label": 0
                },
                {
                    "sent": "But here we did not specify.",
                    "label": 0
                },
                {
                    "sent": "A model we just have a several general assumptions, and if this model satisfies this set of assumptions and we will say that OK, it is also true for this model.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As next step, besides this general methodology, we also combine it with a specific temporal dependency discovery algorithms to to test its performance will choose the loss of grandeur that we remarked previously and are the result of the algorithm is extremely simple, so the first step is just to apply the loss of grandeur on the forward time series.",
                    "label": 0
                },
                {
                    "sent": "The next step is just applied again, but on the backward time series and in the end we just output the average with appropriate transposing.",
                    "label": 0
                },
                {
                    "sent": "We have to evaluate this algorithm on both synthetic data and real world data.",
                    "label": 0
                },
                {
                    "sent": "For synthetic data we have generated data time series from the bar model and the several generalized linear model.",
                    "label": 1
                },
                {
                    "sent": "The Poly actually representing a type of generalized linear model where instead of using the linear function as link function, we use a higher order polynomial trying to simulate the nonlinear ality in the time series.",
                    "label": 0
                },
                {
                    "sent": "And the log in.",
                    "label": 0
                },
                {
                    "sent": "I see our time zero.",
                    "label": 0
                },
                {
                    "sent": "Also generalized linear model with binary values and they all satisfies our set of assumptions.",
                    "label": 1
                },
                {
                    "sent": "We also vary the length of the time series we generated trying to study the high dimensional or low dimensional case where we have a sufficient data or limited data on the real world.",
                    "label": 1
                },
                {
                    "sent": "Data we have tested on the Twitter Haiti data which is tweeting activity we collected after the Haiti earthquake.",
                    "label": 0
                },
                {
                    "sent": "And also we tested on the biologic data, the microarray data to predict the gene regulatory networks.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, now let's see the experiment result on the synthetic data.",
                    "label": 0
                },
                {
                    "sent": "Let's first see the result on the VAR model and Poly model.",
                    "label": 1
                },
                {
                    "sent": "This is under high dimensional case where data is limited and you can see that the forward backward loss of grandeur outperforms the original loss of grandeur and the CLG for the Poly model is actually popular.",
                    "label": 0
                },
                {
                    "sent": "Lots of grandeur where we first apply a copular transformation trying to address the non rat issue and then apply lots of grandeur.",
                    "label": 0
                },
                {
                    "sent": "For the low demand case, when we have sufficient data, the performance is there's no significant difference in there.",
                    "label": 0
                },
                {
                    "sent": "The most interesting case here is the the log an IC model.",
                    "label": 0
                },
                {
                    "sent": "So no matter it's Heidi mental case or the low demand in case the forward backward version always outperforms the original original.",
                    "label": 0
                },
                {
                    "sent": "Also Granger an hour explanation is that this is exactly the case of the model misspecification.",
                    "label": 0
                },
                {
                    "sent": "Because it's a binary value time series and our forward backward approach indeed can help under this type of case.",
                    "label": 0
                },
                {
                    "sent": "To provide more robust estimations.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Next, this is result on the heavy data set and rulers at first like.",
                    "label": 0
                },
                {
                    "sent": "See the heavy data.",
                    "label": 0
                },
                {
                    "sent": "The task here is to discover the underlying dependence graph between the users.",
                    "label": 1
                },
                {
                    "sent": "The ground truth we use is.",
                    "label": 0
                },
                {
                    "sent": "Perfect is the actual retreat network, but this is the best we have right now.",
                    "label": 0
                },
                {
                    "sent": "You can see that the forward backward loss of grandeur outperform the loss of grandeur as expected and also more interesting.",
                    "label": 0
                },
                {
                    "sent": "Interestingly, we also apply this approach on the transfer entropy that we previously mentioned.",
                    "label": 0
                },
                {
                    "sent": "It also helps under that case.",
                    "label": 1
                },
                {
                    "sent": "On the right hand side, it's result on the micro rate data and the ground truth you provided by the website.",
                    "label": 0
                },
                {
                    "sent": "The bio grade and you can see that in terms of the you see the forward backward loss of Ranger outperforms originally, so Granger.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in conclusion, we think that this forward backward approach is indeed an intuitive and effective way to improve the temporal dependence discovery on time series data and also the forward backward loss of Granger.",
                    "label": 1
                },
                {
                    "sent": "The algorithm is also an efficient and effective algorithm under various circumstances.",
                    "label": 0
                },
                {
                    "sent": "And if you want to ask me the question when should we apply this algorithm, then I think first it's reasonable to assume that the forward only lost grandeur should provide you with a reasonable result for us to improve upon.",
                    "label": 0
                },
                {
                    "sent": "And also especially helpful if it's under the high dimensional case, as future work we think that it's worth to study other more sophisticated approach to do the combination.",
                    "label": 0
                },
                {
                    "sent": "An also inspired by the result on the transfer entropy with things that this approach.",
                    "label": 0
                },
                {
                    "sent": "Indeed we need to study this approach on the other temporal dependence discovery algorithms, and indeed because the simplest combination approach is basically free.",
                    "label": 0
                },
                {
                    "sent": "So if you have evaluated very good evaluation metrics for your problem, I encourage encourage you guys to try this out, and I will thank you for that.",
                    "label": 0
                },
                {
                    "sent": "And thank you for listening.",
                    "label": 0
                },
                {
                    "sent": "I'll take questions from now.",
                    "label": 0
                }
            ]
        }
    }
}