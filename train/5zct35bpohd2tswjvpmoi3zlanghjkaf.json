{
    "id": "5zct35bpohd2tswjvpmoi3zlanghjkaf",
    "title": "Scalable Diffusion-Aware Optimization of Network Topology",
    "info": {
        "author": [
            "Elias Boutros Khalil, College of Computing, Georgia Institute of Technology"
        ],
        "published": "Oct. 7, 2014",
        "recorded": "August 2014",
        "category": [
            "Top->Computer Science->Data Mining",
            "Top->Computer Science->Knowledge Extraction"
        ]
    },
    "url": "http://videolectures.net/kdd2014_khalil_network_topology/",
    "segmentation": [
        [
            "I am a Lias Ann I will presenting this joint work with timely song Georgia Tech.",
            "So."
        ],
        [
            "I don't need to convince you much about the importance of studying diffusion on networks.",
            "Simply it is a phenomenon that has been observed in many different contexts, such as the ones illustrated here, and this has generated a lot of interest from the KDD community over the years, so again, I don't need to convince you of the importance of studying this topic simply because it exists in many different contexts and this has generated lots of interest.",
            "So am I."
        ],
        [
            "The problems that have been addressed one is how do we model this kind of cascading behavior networks?",
            "Another important topic with a very large body of work is how do we select some source nodes in the network such that we maximize the expected spread of influence and this has been studied in from many different aspects an in very different flavors.",
            "Of course this is not meant to be exhaustive.",
            "There are other problems, but these are the ones that are of interest to us.",
            "So in recent years I've been interested in a new kind of problem.",
            "And that's how to optimize the actual structure of the network with respect to diffusion processes.",
            "So what do we mean?"
        ],
        [
            "By that we illustrate this with this simple figure in a given network.",
            "We might have some nodes that we know are possible sources of diffusion, and one question we might."
        ],
        [
            "Want to ask is which K edges should we delete in order to minimize the expected set of influence and so?"
        ],
        [
            "The question is how do we pick these sets of edges?"
        ],
        [
            "Another question."
        ],
        [
            "How do we add some edges?"
        ],
        [
            "In order to maximize the expected thread of influence and the unify."
        ],
        [
            "My question for both of these problems is, how do we strategically optimize the structure of the network in order to optimize the diffusion?",
            "So here the word strategically is key because changing the structure of the network is not a cost this operation, and so we think that changing the structure should be something we look at in the in the future, and the evolution of the network.",
            "So it's kind of a strategic task that we."
        ],
        [
            "What has been done in this field?",
            "Well, some of these structure optimization problems."
        ],
        [
            "And address on the different models.",
            "So under the susceptible, infected recovered model, there are some algorithms that are based on optimizing the eigenvalue of the graph, and these are generally algorithms with approximation guarantees and at our scale."
        ],
        [
            "But this is generally regarded as a positive result."
        ],
        [
            "Moving onto the independent Cascade model, which is very widely adopted and very simple there is."
        ],
        [
            "Odds are not not so positive because although we have a principled approach, it is not in fact scalable to large networks."
        ],
        [
            "Finally, for the linear threshold model."
        ],
        [
            "We do not know much especially about the stochastic linear threshold model, which is of interest to us and the hope."
        ],
        [
            "This paper is that we."
        ],
        [
            "Vince that we have indeed some positive results for these problems, both in terms of approximation and in terms of scalability."
        ],
        [
            "So our contributions are twofold.",
            "One on the theoretical level, we will be devising a new framework for analyzing the linear threshold model based on that framework will be able to obtain some new properties that were not exploited before and use them to prove super modularity, mathematical property of our objective functions.",
            "Thanks to this property, we're able to leverage some existing optimization approaches that have approximation guarantees to solve the problems, however.",
            "Directly applying these optimization approach would result in quadratic time algorithms and this is where algorithmic contribution comes in.",
            "So for the main problems, edge deletion edge addition we will be using some special data structures for deletion an some randomized subroutines for edge addition and this will help us obtain linear time and space algorithms in the size of the network.",
            "Once we have those linear time, algorithms were able to experiment with networks.",
            "With millions of nodes and edges and we also show that our methods consistently output for an array of exhaustive heuristics for both problems."
        ],
        [
            "So first I will define a few basic terms that will be using along this talk.",
            "One is that of a graph G VW.",
            "So here's W is just a wait function that expresses the diffusion probabilities on the edges.",
            "Now, given this toy triangle graph, you could think of 1 possible cascade, such as."
        ],
        [
            "This one right a is infected, passes on the infection to be bees infected passes on the infection to see.",
            "So this is one such possible cascade here will be used."
        ],
        [
            "The term live edge graph to describe such possible cascades, and this is a mathematical construct that was used by Capital K DDR3 to analyze this type of model and this turns out to be a successful approach for that for that work so will be using the same approach and refering to this sub graph as live edge graphs."
        ],
        [
            "So this is 1 possible cascade, but you could."
        ],
        [
            "Also, think of this cascade where B does not infect C or this one."
        ],
        [
            "That one or the other."
        ],
        [
            "So these are kind of the possible test case when we take the Union of all of these cascades, we obtain what we call the space of live edge graphs.",
            "So this is just the set of all such possible life edge graphs an important property under the new threshold model is that in those live edge graphs, each node has at most a single parent, so this will be a fundamental property that will exploit later on, and I'll detail how."
        ],
        [
            "So two quantities that we associate with these live edge graphs.",
            "One is the probability of the live edge graph.",
            "So here is defined by PR of XI given G. So what's the probability of generating this live edge graph given the network G and the diffusion parameters?",
            "The other quantities of importance?"
        ],
        [
            "Is the reachability of a given source node, for example, a in a given live edge graphics?",
            "I for example in the upper one we can see that our of reach the number of reachable nodes from a in X one is 2 because they can reach BNC.",
            "Now the most important definition in this slide is that of influence."
        ],
        [
            "So how do we compute the influence of a given node A in a diffusion network G?",
            "Well, it is simply a weighted linear combination of these number of reachable nodes are IXI weighted by the probability of the occurrence of that given live edge graph.",
            "So in this case it's simply a sum over these five larger jobs of this weighted combination."
        ],
        [
            "So how do we formulate this optimization problems that we proposed edge deletion and tradition for edge deletion?",
            "We simply want to find the K edges that minimize the sum of the influence of a set of source node when the graph G is modified by deleting the set of edges as.",
            "So here the notation GV y -- S W refers to deleting the set of edges South from the original edge set.",
            "You might wonder why we have a sum over the set of source source nodes.",
            "The reason is we think that this is a strategic kind of optimization problem, so we might know that the big A is a set of possible sources, but we don't know exactly which of these will be sources of diffusion in the future, and so here we optimize over the sum of those, and you could think of areas where you have different weights for each source node.",
            "Because you have some prior knowledge about which sources are more likely or different combinations of nodes for education, you have a similar definition except.",
            "Instead of picking the set of edges E out of the set of edges S out of the existing, a set of edges E, we pick them out of a set of candidate edges, which we refer to as C. So here we have a set of edges, a pool of candidate edges that we might want to add, and we only want to add a subset of those of size K. And the influence is also a sum over the sources, except we are adding a set of edges instead of deleting it."
        ],
        [
            "Now we want to analyze these objective functions in a way to to obtain some algorithms to solve them.",
            "And here we will use the objective function from the source selection paper by campaign to illustrate the difficulties in analyzing objectives in our case so."
        ],
        [
            "In that case, if you look at the objective function is simply asking to find the K nodes such that once those are chosen as sources, the spread of influence is maximized and expectation.",
            "So in that case, let's say you want to prove something really simple like that.",
            "This function is monotone increasing, so you know that the influences the sum over the Season 5 edge graph.",
            "So it's a linear combination.",
            "We fix one live edge graph.",
            "We call that type of graph X, and to prove that a function is monotone, we simply subtract the influence of asset South from the influence of a super set.",
            "As Union V now we have these two terms.",
            "Turns out that the probability of occurrence for this live edge graph X is common to both terms right?",
            "Because the probability of it occurring in both cases is the same.",
            "So we factor that out and then we get a simple difference of reach abilities and that's allowed to be positive, which completes the proof.",
            "This is a monotone increasing function.",
            "Let's try to see if we can apply this to our case.",
            "For example, for the edge deletion objective."
        ],
        [
            "We want to prove that this objective function is monotone decreasing with respect to the edge set E -- S. You could also fix a source node A because we have a linear combination over the set of source nodes and then we look at the function.",
            "The influence function when we modify the edge set, so we subtract the influence of the of the South and from the from the larger set.",
            "And what happens is that we have."
        ],
        [
            "Sums as before, except now the sums are over different spaces of live edge graphs as we find them before.",
            "Why?",
            "Because when you change an edge you generate a new space of live edge graphs with different live edge graphs as well as different probability of them occurring because the probability space is simply different and the consequences of that is that there is no way to analyze this kind of expression directly.",
            "So we need to know more about this live edge graphs in order to be able to evaluate this.",
            "And this is the."
        ],
        [
            "The point that modifying the structure of the network affects the space of live edge graphs, and this was not the case.",
            "For example, in the source node influence maximization paper."
        ],
        [
            "So to overcome this issue, we dive deeper into the linear threshold model and we uncover four properties that we think described at a very deep level.",
            "So the first 2 properties above explain how space Live Edge, graph spaceflight edge graphs is structured internally with respect to a given edge.",
            "The two other properties explain how different spaces of live edge graphs interact among each other, so I will not go into the details of these properties.",
            "But we do have illustrations and explanations in the papers with proofs so."
        ],
        [
            "So thanks to these four properties, were able to prove two things.",
            "One is that this, for example edge deletion objective is monotone decreasing and the other thing is that it is super modular and will be able to use this results for edge addition and other node based variants."
        ],
        [
            "So what super modularity.",
            "It simply is simply a mathematical property of set functions that has the increasing differences property so."
        ],
        [
            "Just illustrate this property with an example.",
            "Take this edge addition situation here on the right.",
            "Let's say we are considering adding the edge E. Now adding the edge E to the left helps the source W Connect to one more node, right?",
            "So that's a gain of plus one.",
            "Now if you consider the case on the right where we've already added an edge below, then in that Case No.",
            "W not only reaches node exit also reaches.",
            "So in that case we have a gain of two, so adding the edge later helps more and this is the increasing difference property that that we're expressing here."
        ],
        [
            "So we want to leverage this nice property and for edge deletion we will do so by.",
            "Considering that this minimization problem minimizing supermodular function is equivalent to maximizing uh, shifted submodel inverse, and for that there's a famous result by by Nemhauser which says that a greedy approach, in our case deleting at each iteration the edge that best decreases the influence over the set of source node is near optimal, and there's an approximation guarantee which are probably familiar with."
        ],
        [
            "So how do we do experimentally consider this experiment on them in tracker data set, which is a news meme diffusion data set.",
            "First of all, we compare to hear a set of five other heuristics.",
            "So one is random.",
            "Basically deleting K edges chosen at random, wanted to await switches, deleting K edges with the highest diffusion diffusion weights.",
            "One is between us, which is where we delete K edges with the highest edge betweeness centrality.",
            "And the weighted graph Eigen which deletes the K edges that decrease the reading Ivan value of the adjacency matrix the most and finally degree which deletes the cages with highest weighted out degree.",
            "So it's at 5 you risztics we compared to on the X axis you have the budget of edges deleted and then on the Y axis you have the relative influence with respect to the initial influence.",
            "So here 1 means that the edges you've deleted have not affected the influence.",
            "0.5 means you've deleted it.",
            "Decrease the influence to half of its initial value when the network is unmodified."
        ],
        [
            "So our method here is shown in red and we out."
        ],
        [
            "Perform the other other methods.",
            "For example, if we delete."
        ],
        [
            "Only 2% of the edges.",
            "In this case we're able to decrease the."
        ],
        [
            "He wants to up to 23% of its initial value, whereas the next best is somewhere around 33%."
        ],
        [
            "For edge addition, we also leverage super modularity.",
            "Basically, here we have a maximizing submodular supermodular function problem and we translate that into a minimization problem of modular function, and then we leverage a very recent results by Aretta, which helps approximate the objective function by a modular by another modular function, which is much simpler to evaluate, and in our case it helps us decouples the problem.",
            "I will not go into the details, but basically we still get an approximation algorithm.",
            "Although I guarantee here is not constant factor, but it's also good to have."
        ],
        [
            "So in practice, the gap is even larger for edge deletion.",
            "Here we also compare to most of these heuristics."
        ],
        [
            "Some of them are not applica."
        ],
        [
            "And our method is usually around 80%, one 100% better.",
            "So here this means that you're so 0.1 for example here on the Y axis means that you've increased the influence 10% relative to no edge, no edges added."
        ],
        [
            "So these algorithms perform well as we show in these experiments, but directly applying them gives quadratic time algorithms in the number of nodes, and so we want to scale up and overcome these problems.",
            "Our solution would be to exploit the problem structure and four."
        ],
        [
            "Edge deletion I will show details of how we do that, whereas for edge addition I will refer you to the paper for more details."
        ],
        [
            "So how would we typically apply this naive edge deletion?",
            "This basic greedy algorithm?",
            "Well, first we would sample some live edge graphs.",
            "This is typical, so we need to sample some some of these graphs induced subgraphs from the source nodes because we consider a particular set of source nodes and then basically for each unit of budget that's line two, we look at each sub graph, consider each edge inside it, and then evaluate the impact of deleting this edge.",
            "So basically the impact here is how many nodes does this does.",
            "Removing this edge disconnect the source from?",
            "So this is our car stereo and then after we do that over all these subgraphs, we can take the average score for the edges and then pick the best one added to the solution set, delete it from the graph, and then repeat the reach budget K. So this is typical greedy algorithm."
        ],
        [
            "Except the twist here is that if you consider each edge in a sub graph, you have order of the of those, and if you want to evaluate this impact of the edge, basically you need some sort of breadth first search traversal so you have a."
        ],
        [
            "Drastic time complexity algorithm typically, and even if you try to use some lazy evaluation approaches, although they've been shown to speed up in practice, they don't improve the worst case time complexity of the app."
        ],
        [
            "And so necklace or question is how do we go out?"
        ],
        [
            "Others.",
            "To scale up edge deletion, our first main observation is that these live edge graphs that we've described are always trees, so the reason goes back to the fact that each node can have at most one parent.",
            "Which means when you induce a subgraph from a given source, you can only get a tree, and the other observation is."
        ],
        [
            "That the score of each edge, the impact is basically simply for in the case of edge.",
            "Maybe it's simply the number of descendants of not be in that in that 3 + 1.",
            "And this is really simple to see.",
            "So the question now is can we compute this number of descendants really quickly?"
        ],
        [
            "Well, we can.",
            "It's really simple approach.",
            "Basically we first have a bottom down breadth first search in that we stack the edges traversed such that the last edge traversed is on the top of the stack.",
            "By the end of stage one, and then in stage two will propagate some labels initialized at zero from the bottom of the three up and basically by the end of the algorithm.",
            "We know for each node how many descendants it has and the score of each edge can be computed as in the simulation above.",
            "For example in this case.",
            "We should remove edge.",
            "Maybe if we had only this simple one live edge graph we should remove edge maybe because it disconnects the source from 5 nodes."
        ],
        [
            "So what happened here is that we've moved from my office squared algorithm as I've shown the previous slide to an RV algorithm, and this is a significant speedup so."
        ],
        [
            "In practice, for edge deletion on a commodity PC, were able to handle networks with up to 32 million edges.",
            "For edge addition, were able to handle up to 2 million edges.",
            "The algorithm is a bit slower because of some constant factors, but basically the trend in both cases is linear October ethnic factor, the logarithmic factor here comes from the fact that we just assume that the number of sources is logarithmic in the number of nodes, so we get something like linear programming sectors."
        ],
        [
            "In the paper, we have additional experiments on both synthetic networks and real networks, so we consistently outperform.",
            "These are some result for edge deletion."
        ],
        [
            "Addition, the gap again is even larger, you know.",
            "Sometimes even more than twice as good as the next pessimistic, whatever that heuristic is, because they don't perform consistently."
        ],
        [
            "So to summarize, we present some problems.",
            "The network optimization problems under the linear threshold model.",
            "We divide some new theoretical frameworks and proof techniques to analyze this model and based on that come up with near optimal algorithms that we scale up using some algorithmic techniques.",
            "Experimentally, we show that our method consistently outperforms an exhaustive exhaustive set of heuristics over large array of datasets.",
            "Thanks for your attention."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I am a Lias Ann I will presenting this joint work with timely song Georgia Tech.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I don't need to convince you much about the importance of studying diffusion on networks.",
                    "label": 1
                },
                {
                    "sent": "Simply it is a phenomenon that has been observed in many different contexts, such as the ones illustrated here, and this has generated a lot of interest from the KDD community over the years, so again, I don't need to convince you of the importance of studying this topic simply because it exists in many different contexts and this has generated lots of interest.",
                    "label": 0
                },
                {
                    "sent": "So am I.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The problems that have been addressed one is how do we model this kind of cascading behavior networks?",
                    "label": 1
                },
                {
                    "sent": "Another important topic with a very large body of work is how do we select some source nodes in the network such that we maximize the expected spread of influence and this has been studied in from many different aspects an in very different flavors.",
                    "label": 0
                },
                {
                    "sent": "Of course this is not meant to be exhaustive.",
                    "label": 0
                },
                {
                    "sent": "There are other problems, but these are the ones that are of interest to us.",
                    "label": 0
                },
                {
                    "sent": "So in recent years I've been interested in a new kind of problem.",
                    "label": 0
                },
                {
                    "sent": "And that's how to optimize the actual structure of the network with respect to diffusion processes.",
                    "label": 1
                },
                {
                    "sent": "So what do we mean?",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "By that we illustrate this with this simple figure in a given network.",
                    "label": 0
                },
                {
                    "sent": "We might have some nodes that we know are possible sources of diffusion, and one question we might.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Want to ask is which K edges should we delete in order to minimize the expected set of influence and so?",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The question is how do we pick these sets of edges?",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another question.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How do we add some edges?",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In order to maximize the expected thread of influence and the unify.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "My question for both of these problems is, how do we strategically optimize the structure of the network in order to optimize the diffusion?",
                    "label": 0
                },
                {
                    "sent": "So here the word strategically is key because changing the structure of the network is not a cost this operation, and so we think that changing the structure should be something we look at in the in the future, and the evolution of the network.",
                    "label": 0
                },
                {
                    "sent": "So it's kind of a strategic task that we.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What has been done in this field?",
                    "label": 0
                },
                {
                    "sent": "Well, some of these structure optimization problems.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And address on the different models.",
                    "label": 0
                },
                {
                    "sent": "So under the susceptible, infected recovered model, there are some algorithms that are based on optimizing the eigenvalue of the graph, and these are generally algorithms with approximation guarantees and at our scale.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But this is generally regarded as a positive result.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Moving onto the independent Cascade model, which is very widely adopted and very simple there is.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Odds are not not so positive because although we have a principled approach, it is not in fact scalable to large networks.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Finally, for the linear threshold model.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We do not know much especially about the stochastic linear threshold model, which is of interest to us and the hope.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This paper is that we.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Vince that we have indeed some positive results for these problems, both in terms of approximation and in terms of scalability.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So our contributions are twofold.",
                    "label": 0
                },
                {
                    "sent": "One on the theoretical level, we will be devising a new framework for analyzing the linear threshold model based on that framework will be able to obtain some new properties that were not exploited before and use them to prove super modularity, mathematical property of our objective functions.",
                    "label": 1
                },
                {
                    "sent": "Thanks to this property, we're able to leverage some existing optimization approaches that have approximation guarantees to solve the problems, however.",
                    "label": 0
                },
                {
                    "sent": "Directly applying these optimization approach would result in quadratic time algorithms and this is where algorithmic contribution comes in.",
                    "label": 0
                },
                {
                    "sent": "So for the main problems, edge deletion edge addition we will be using some special data structures for deletion an some randomized subroutines for edge addition and this will help us obtain linear time and space algorithms in the size of the network.",
                    "label": 1
                },
                {
                    "sent": "Once we have those linear time, algorithms were able to experiment with networks.",
                    "label": 0
                },
                {
                    "sent": "With millions of nodes and edges and we also show that our methods consistently output for an array of exhaustive heuristics for both problems.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So first I will define a few basic terms that will be using along this talk.",
                    "label": 0
                },
                {
                    "sent": "One is that of a graph G VW.",
                    "label": 0
                },
                {
                    "sent": "So here's W is just a wait function that expresses the diffusion probabilities on the edges.",
                    "label": 0
                },
                {
                    "sent": "Now, given this toy triangle graph, you could think of 1 possible cascade, such as.",
                    "label": 1
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This one right a is infected, passes on the infection to be bees infected passes on the infection to see.",
                    "label": 0
                },
                {
                    "sent": "So this is one such possible cascade here will be used.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The term live edge graph to describe such possible cascades, and this is a mathematical construct that was used by Capital K DDR3 to analyze this type of model and this turns out to be a successful approach for that for that work so will be using the same approach and refering to this sub graph as live edge graphs.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is 1 possible cascade, but you could.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Also, think of this cascade where B does not infect C or this one.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That one or the other.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So these are kind of the possible test case when we take the Union of all of these cascades, we obtain what we call the space of live edge graphs.",
                    "label": 0
                },
                {
                    "sent": "So this is just the set of all such possible life edge graphs an important property under the new threshold model is that in those live edge graphs, each node has at most a single parent, so this will be a fundamental property that will exploit later on, and I'll detail how.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So two quantities that we associate with these live edge graphs.",
                    "label": 0
                },
                {
                    "sent": "One is the probability of the live edge graph.",
                    "label": 0
                },
                {
                    "sent": "So here is defined by PR of XI given G. So what's the probability of generating this live edge graph given the network G and the diffusion parameters?",
                    "label": 0
                },
                {
                    "sent": "The other quantities of importance?",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is the reachability of a given source node, for example, a in a given live edge graphics?",
                    "label": 0
                },
                {
                    "sent": "I for example in the upper one we can see that our of reach the number of reachable nodes from a in X one is 2 because they can reach BNC.",
                    "label": 0
                },
                {
                    "sent": "Now the most important definition in this slide is that of influence.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how do we compute the influence of a given node A in a diffusion network G?",
                    "label": 0
                },
                {
                    "sent": "Well, it is simply a weighted linear combination of these number of reachable nodes are IXI weighted by the probability of the occurrence of that given live edge graph.",
                    "label": 0
                },
                {
                    "sent": "So in this case it's simply a sum over these five larger jobs of this weighted combination.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how do we formulate this optimization problems that we proposed edge deletion and tradition for edge deletion?",
                    "label": 0
                },
                {
                    "sent": "We simply want to find the K edges that minimize the sum of the influence of a set of source node when the graph G is modified by deleting the set of edges as.",
                    "label": 0
                },
                {
                    "sent": "So here the notation GV y -- S W refers to deleting the set of edges South from the original edge set.",
                    "label": 0
                },
                {
                    "sent": "You might wonder why we have a sum over the set of source source nodes.",
                    "label": 0
                },
                {
                    "sent": "The reason is we think that this is a strategic kind of optimization problem, so we might know that the big A is a set of possible sources, but we don't know exactly which of these will be sources of diffusion in the future, and so here we optimize over the sum of those, and you could think of areas where you have different weights for each source node.",
                    "label": 0
                },
                {
                    "sent": "Because you have some prior knowledge about which sources are more likely or different combinations of nodes for education, you have a similar definition except.",
                    "label": 0
                },
                {
                    "sent": "Instead of picking the set of edges E out of the set of edges S out of the existing, a set of edges E, we pick them out of a set of candidate edges, which we refer to as C. So here we have a set of edges, a pool of candidate edges that we might want to add, and we only want to add a subset of those of size K. And the influence is also a sum over the sources, except we are adding a set of edges instead of deleting it.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now we want to analyze these objective functions in a way to to obtain some algorithms to solve them.",
                    "label": 0
                },
                {
                    "sent": "And here we will use the objective function from the source selection paper by campaign to illustrate the difficulties in analyzing objectives in our case so.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In that case, if you look at the objective function is simply asking to find the K nodes such that once those are chosen as sources, the spread of influence is maximized and expectation.",
                    "label": 0
                },
                {
                    "sent": "So in that case, let's say you want to prove something really simple like that.",
                    "label": 0
                },
                {
                    "sent": "This function is monotone increasing, so you know that the influences the sum over the Season 5 edge graph.",
                    "label": 1
                },
                {
                    "sent": "So it's a linear combination.",
                    "label": 0
                },
                {
                    "sent": "We fix one live edge graph.",
                    "label": 1
                },
                {
                    "sent": "We call that type of graph X, and to prove that a function is monotone, we simply subtract the influence of asset South from the influence of a super set.",
                    "label": 0
                },
                {
                    "sent": "As Union V now we have these two terms.",
                    "label": 0
                },
                {
                    "sent": "Turns out that the probability of occurrence for this live edge graph X is common to both terms right?",
                    "label": 0
                },
                {
                    "sent": "Because the probability of it occurring in both cases is the same.",
                    "label": 0
                },
                {
                    "sent": "So we factor that out and then we get a simple difference of reach abilities and that's allowed to be positive, which completes the proof.",
                    "label": 0
                },
                {
                    "sent": "This is a monotone increasing function.",
                    "label": 0
                },
                {
                    "sent": "Let's try to see if we can apply this to our case.",
                    "label": 0
                },
                {
                    "sent": "For example, for the edge deletion objective.",
                    "label": 1
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We want to prove that this objective function is monotone decreasing with respect to the edge set E -- S. You could also fix a source node A because we have a linear combination over the set of source nodes and then we look at the function.",
                    "label": 1
                },
                {
                    "sent": "The influence function when we modify the edge set, so we subtract the influence of the of the South and from the from the larger set.",
                    "label": 0
                },
                {
                    "sent": "And what happens is that we have.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sums as before, except now the sums are over different spaces of live edge graphs as we find them before.",
                    "label": 0
                },
                {
                    "sent": "Why?",
                    "label": 0
                },
                {
                    "sent": "Because when you change an edge you generate a new space of live edge graphs with different live edge graphs as well as different probability of them occurring because the probability space is simply different and the consequences of that is that there is no way to analyze this kind of expression directly.",
                    "label": 0
                },
                {
                    "sent": "So we need to know more about this live edge graphs in order to be able to evaluate this.",
                    "label": 0
                },
                {
                    "sent": "And this is the.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The point that modifying the structure of the network affects the space of live edge graphs, and this was not the case.",
                    "label": 0
                },
                {
                    "sent": "For example, in the source node influence maximization paper.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So to overcome this issue, we dive deeper into the linear threshold model and we uncover four properties that we think described at a very deep level.",
                    "label": 0
                },
                {
                    "sent": "So the first 2 properties above explain how space Live Edge, graph spaceflight edge graphs is structured internally with respect to a given edge.",
                    "label": 0
                },
                {
                    "sent": "The two other properties explain how different spaces of live edge graphs interact among each other, so I will not go into the details of these properties.",
                    "label": 0
                },
                {
                    "sent": "But we do have illustrations and explanations in the papers with proofs so.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So thanks to these four properties, were able to prove two things.",
                    "label": 0
                },
                {
                    "sent": "One is that this, for example edge deletion objective is monotone decreasing and the other thing is that it is super modular and will be able to use this results for edge addition and other node based variants.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what super modularity.",
                    "label": 0
                },
                {
                    "sent": "It simply is simply a mathematical property of set functions that has the increasing differences property so.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just illustrate this property with an example.",
                    "label": 0
                },
                {
                    "sent": "Take this edge addition situation here on the right.",
                    "label": 0
                },
                {
                    "sent": "Let's say we are considering adding the edge E. Now adding the edge E to the left helps the source W Connect to one more node, right?",
                    "label": 0
                },
                {
                    "sent": "So that's a gain of plus one.",
                    "label": 0
                },
                {
                    "sent": "Now if you consider the case on the right where we've already added an edge below, then in that Case No.",
                    "label": 0
                },
                {
                    "sent": "W not only reaches node exit also reaches.",
                    "label": 0
                },
                {
                    "sent": "So in that case we have a gain of two, so adding the edge later helps more and this is the increasing difference property that that we're expressing here.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we want to leverage this nice property and for edge deletion we will do so by.",
                    "label": 0
                },
                {
                    "sent": "Considering that this minimization problem minimizing supermodular function is equivalent to maximizing uh, shifted submodel inverse, and for that there's a famous result by by Nemhauser which says that a greedy approach, in our case deleting at each iteration the edge that best decreases the influence over the set of source node is near optimal, and there's an approximation guarantee which are probably familiar with.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how do we do experimentally consider this experiment on them in tracker data set, which is a news meme diffusion data set.",
                    "label": 0
                },
                {
                    "sent": "First of all, we compare to hear a set of five other heuristics.",
                    "label": 0
                },
                {
                    "sent": "So one is random.",
                    "label": 0
                },
                {
                    "sent": "Basically deleting K edges chosen at random, wanted to await switches, deleting K edges with the highest diffusion diffusion weights.",
                    "label": 0
                },
                {
                    "sent": "One is between us, which is where we delete K edges with the highest edge betweeness centrality.",
                    "label": 0
                },
                {
                    "sent": "And the weighted graph Eigen which deletes the K edges that decrease the reading Ivan value of the adjacency matrix the most and finally degree which deletes the cages with highest weighted out degree.",
                    "label": 0
                },
                {
                    "sent": "So it's at 5 you risztics we compared to on the X axis you have the budget of edges deleted and then on the Y axis you have the relative influence with respect to the initial influence.",
                    "label": 0
                },
                {
                    "sent": "So here 1 means that the edges you've deleted have not affected the influence.",
                    "label": 0
                },
                {
                    "sent": "0.5 means you've deleted it.",
                    "label": 0
                },
                {
                    "sent": "Decrease the influence to half of its initial value when the network is unmodified.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So our method here is shown in red and we out.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Perform the other other methods.",
                    "label": 0
                },
                {
                    "sent": "For example, if we delete.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Only 2% of the edges.",
                    "label": 0
                },
                {
                    "sent": "In this case we're able to decrease the.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "He wants to up to 23% of its initial value, whereas the next best is somewhere around 33%.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For edge addition, we also leverage super modularity.",
                    "label": 0
                },
                {
                    "sent": "Basically, here we have a maximizing submodular supermodular function problem and we translate that into a minimization problem of modular function, and then we leverage a very recent results by Aretta, which helps approximate the objective function by a modular by another modular function, which is much simpler to evaluate, and in our case it helps us decouples the problem.",
                    "label": 0
                },
                {
                    "sent": "I will not go into the details, but basically we still get an approximation algorithm.",
                    "label": 0
                },
                {
                    "sent": "Although I guarantee here is not constant factor, but it's also good to have.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in practice, the gap is even larger for edge deletion.",
                    "label": 0
                },
                {
                    "sent": "Here we also compare to most of these heuristics.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some of them are not applica.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And our method is usually around 80%, one 100% better.",
                    "label": 0
                },
                {
                    "sent": "So here this means that you're so 0.1 for example here on the Y axis means that you've increased the influence 10% relative to no edge, no edges added.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So these algorithms perform well as we show in these experiments, but directly applying them gives quadratic time algorithms in the number of nodes, and so we want to scale up and overcome these problems.",
                    "label": 0
                },
                {
                    "sent": "Our solution would be to exploit the problem structure and four.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Edge deletion I will show details of how we do that, whereas for edge addition I will refer you to the paper for more details.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So how would we typically apply this naive edge deletion?",
                    "label": 0
                },
                {
                    "sent": "This basic greedy algorithm?",
                    "label": 0
                },
                {
                    "sent": "Well, first we would sample some live edge graphs.",
                    "label": 0
                },
                {
                    "sent": "This is typical, so we need to sample some some of these graphs induced subgraphs from the source nodes because we consider a particular set of source nodes and then basically for each unit of budget that's line two, we look at each sub graph, consider each edge inside it, and then evaluate the impact of deleting this edge.",
                    "label": 0
                },
                {
                    "sent": "So basically the impact here is how many nodes does this does.",
                    "label": 0
                },
                {
                    "sent": "Removing this edge disconnect the source from?",
                    "label": 0
                },
                {
                    "sent": "So this is our car stereo and then after we do that over all these subgraphs, we can take the average score for the edges and then pick the best one added to the solution set, delete it from the graph, and then repeat the reach budget K. So this is typical greedy algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Except the twist here is that if you consider each edge in a sub graph, you have order of the of those, and if you want to evaluate this impact of the edge, basically you need some sort of breadth first search traversal so you have a.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Drastic time complexity algorithm typically, and even if you try to use some lazy evaluation approaches, although they've been shown to speed up in practice, they don't improve the worst case time complexity of the app.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so necklace or question is how do we go out?",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Others.",
                    "label": 0
                },
                {
                    "sent": "To scale up edge deletion, our first main observation is that these live edge graphs that we've described are always trees, so the reason goes back to the fact that each node can have at most one parent.",
                    "label": 0
                },
                {
                    "sent": "Which means when you induce a subgraph from a given source, you can only get a tree, and the other observation is.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That the score of each edge, the impact is basically simply for in the case of edge.",
                    "label": 1
                },
                {
                    "sent": "Maybe it's simply the number of descendants of not be in that in that 3 + 1.",
                    "label": 0
                },
                {
                    "sent": "And this is really simple to see.",
                    "label": 1
                },
                {
                    "sent": "So the question now is can we compute this number of descendants really quickly?",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, we can.",
                    "label": 0
                },
                {
                    "sent": "It's really simple approach.",
                    "label": 0
                },
                {
                    "sent": "Basically we first have a bottom down breadth first search in that we stack the edges traversed such that the last edge traversed is on the top of the stack.",
                    "label": 0
                },
                {
                    "sent": "By the end of stage one, and then in stage two will propagate some labels initialized at zero from the bottom of the three up and basically by the end of the algorithm.",
                    "label": 0
                },
                {
                    "sent": "We know for each node how many descendants it has and the score of each edge can be computed as in the simulation above.",
                    "label": 0
                },
                {
                    "sent": "For example in this case.",
                    "label": 0
                },
                {
                    "sent": "We should remove edge.",
                    "label": 0
                },
                {
                    "sent": "Maybe if we had only this simple one live edge graph we should remove edge maybe because it disconnects the source from 5 nodes.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what happened here is that we've moved from my office squared algorithm as I've shown the previous slide to an RV algorithm, and this is a significant speedup so.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In practice, for edge deletion on a commodity PC, were able to handle networks with up to 32 million edges.",
                    "label": 0
                },
                {
                    "sent": "For edge addition, were able to handle up to 2 million edges.",
                    "label": 0
                },
                {
                    "sent": "The algorithm is a bit slower because of some constant factors, but basically the trend in both cases is linear October ethnic factor, the logarithmic factor here comes from the fact that we just assume that the number of sources is logarithmic in the number of nodes, so we get something like linear programming sectors.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the paper, we have additional experiments on both synthetic networks and real networks, so we consistently outperform.",
                    "label": 0
                },
                {
                    "sent": "These are some result for edge deletion.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Addition, the gap again is even larger, you know.",
                    "label": 0
                },
                {
                    "sent": "Sometimes even more than twice as good as the next pessimistic, whatever that heuristic is, because they don't perform consistently.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So to summarize, we present some problems.",
                    "label": 0
                },
                {
                    "sent": "The network optimization problems under the linear threshold model.",
                    "label": 0
                },
                {
                    "sent": "We divide some new theoretical frameworks and proof techniques to analyze this model and based on that come up with near optimal algorithms that we scale up using some algorithmic techniques.",
                    "label": 0
                },
                {
                    "sent": "Experimentally, we show that our method consistently outperforms an exhaustive exhaustive set of heuristics over large array of datasets.",
                    "label": 0
                },
                {
                    "sent": "Thanks for your attention.",
                    "label": 0
                }
            ]
        }
    }
}