{
    "id": "ggixuyz3mbao6v74aqewm354efpe2unv",
    "title": "Online Multiscale Dynamic Topic Models",
    "info": {
        "author": [
            "Tomoharu Iwata, NTT Communication Science Laboratories"
        ],
        "published": "Oct. 1, 2010",
        "recorded": "July 2010",
        "category": [
            "Top->Computer Science->Data Mining",
            "Top->Computer Science->Artificial Intelligence",
            "Top->Computer Science->Pattern Recognition"
        ]
    },
    "url": "http://videolectures.net/kdd2010_iwata_omdtm/",
    "segmentation": [
        [
            "Thank you, my name is Tomoharu bottle from NTT communication Science Laboratories in Japan.",
            "I talk about online much scale dynamic topic models."
        ],
        [
            "Many topic models for analyze document that makes our proposed, for example, a dynamic topic, model topic, overtime dynamic mixture model and topic tracking model."
        ],
        [
            "This model can analyze data such as scientific papers, news articles, blogs and emails.",
            "Here we consider a different kind of dynamics that is much scale dynamics topics not naturally able with much full time scale.",
            "For example, let's consider politic topics in news articles was like Constitution, Congress President, our user for many years on their head.",
            "On the other hand, what like names of members in Congress?"
        ],
        [
            "User for 10s of years.",
            "Add an AIDS or abuse under discussion.",
            "May only appear for few days.",
            "So here we propose a topic model for analyzing organizing dynamics with multiple time scale, which we call much dynamic topic model.",
            "Our model is robust becausw information loss is reduced by concerning short and long time scale dynamics and also we present efficient online influence algorithm in which the model is updated using only newly obtained data.",
            "So we can compute.",
            "The model."
        ],
        [
            "In efficiently and.",
            "In this algorithm, we do not need to store the past later, so we can also deduce computational reduce the memory requirement.",
            "And.",
            "Before I explain about our model, we briefly review the standard topic model.",
            "It's a late industrial kitchen, it's it is a basis of our model.",
            "So in the in your day, a document is modeled as a mixture of topics.",
            "Each.",
            "Each document has its own topic proportion filter, and for each word a topic Z is generated according to the topic proportions.",
            "And.",
            "What are these generated depending on the topic and also each topic has its own?",
            "What distribution file and the file distribution file is generated from the symmetric symmetric distribution with parameter beta?",
            "So in this model there is no dynamics and there's no much scale dynamics.",
            "So here we incorporate multiple.",
            "Simscape dynamics in the water district."
        ],
        [
            "June 5 XI S is a what distribution at scale as and here.",
            "We set the length of scale so that guy S represents the war distribution from T minus.",
            "2 two that is minus 1 two T -- 1 It means that the other one is what distribution for one Apple and excited represent.",
            "Our distribution for two epochs and exhi four dental water distribution for eight epochs longer.",
            "Water distribution are likely to be more smooth becausw we can observe the more data in the long time scale and short timescale.",
            "What this vision are likely to be picky.",
            "And.",
            "Two incomplete this much full time scale water distribution into the water distribution at at empty.",
            "Why?",
            "We assume that file is generated depending on the weighted sum of this much scale water distribution.",
            "So here Lambda is that weight and we also use a uniform while distribution with weight Lambda zero in order to avoid a zero probability problem.",
            "In particular, we assume that."
        ],
        [
            "That what the distribution file is generated from this distribution.",
            "We use this distribution 'cause it's going to get to the marginal distribution.",
            "And because of that conjugacy, the influence procedure becomes very simple, and by this we can incorporate the much spare time scale dynamics into the water distribution.",
            "Also, we consider the dynamics in the topic proportion becausw.",
            "Popularity of topics change overtime, so for that we added that topic proportion.",
            "Player Alpha is generated depending on the previous value, so Alpha at empty is generated from this gamma distribution within the parameters there is a previous value.",
            "And this is a graphical model of our.",
            "Method and difference between this proposed model and the standard topic model is a top part and the bottom part.",
            "The Alpha is above according to the.",
            "Depending on the previous value and also five is generated from depending on the match.",
            "Scale water distribution with weight Lambda.",
            "So not that other much scale, what distribution?"
        ],
        [
            "XI is.",
            "Here is a hyperparameter, so it is a generative model of documents at a party.",
            "And for the influence, we update the model at each book using the newly obtained data and the previous model.",
            "So we observe the data for each Apple and update the model in an online fashion.",
            "For each book.",
            "We infer the model using a secure stick EM algorithm.",
            "In the instep.",
            "We sample latent topics Z using a.",
            "Collapse, give something.",
            "According to this probability and in M step we sound too we optimize the parameters Alpha and Lambda.",
            "So as to maximize the joint likelihood.",
            "Using these"
        ],
        [
            "Update Hulu and here we need explain about the how to estimate the much scale water distribution with.",
            "I guess 'cause IS is a water distribution of scale South the.",
            "Maximum likelihood estimator is just the proportional to the water count in that scale.",
            "So the word count of that scale is just a summation of what account are to each Apple in that scale.",
            "So this figure shows up and each boxes represent what count.",
            "At a book so and."
        ],
        [
            "The set of boxes can be dispensed did represent what count of scale S, so it suggests a measure of account so we can online update the value in online fashion.",
            "The current value.",
            "An S is calculated from the previous value.",
            "Just adding the current value count and the sub structure.",
            "The first word count in that scale so.",
            "For the updating, just throw away this first one and other at the new or newly obtained account.",
            "It's computationally efficient, but it requires.",
            "To do the X -- 1 memory.",
            "So when we want to want is a very long time very long.",
            "Times scale.",
            "Dependencies it needs.",
            "We need a very large memory so."
        ],
        [
            "For.",
            "To solve that problem, we propose a approximated efficient estimation for much scale water distribution.",
            "Here we update.",
            "The count.",
            "Overscale an S at every two to the X -- 1 at box it means that.",
            "We decrease the operating frequency for long time scale distribution.",
            "Using this algorithm we can just store only the previous app account.",
            "So this."
        ],
        [
            "Images show how this uploads met method works at each boxes represent account at that book, so this box represents account at a box 3 and a set of this set of.",
            "Boxes represent account of.",
            "Scale 3, so here we assume that we have a three time scale.",
            "What account and in the next Apple at the book 5 we newly obtained count counter at Epic 5.",
            "Inadequate, we only update scale one count.",
            "Here, and we do not operate a scale to count and scale.",
            "See count and in the.",
            "Epic Six we update scale one count and also scale to account for the updating of scale.",
            "To count we use the previous count of scale one and client count of scale one.",
            "And at the.",
            "Epic Seven we only update the scale scale one count as in about 5 and at Apoc.",
            "Why we update scale 123 count for the operating three scale, 3 count?",
            "We use a previous.",
            "Count of schedule and current count of scale 2.",
            "Using this procedure, we just need to store only previous counts, so the required memory is linear to the."
        ],
        [
            "Gumball was scared so we can.",
            "Models are very long time scale dynamics.",
            "Using this uploads magic procedures.",
            "For the evaluation we use for data set.",
            "NIPS is conference papers and be an essay titles and degrees of data from web and the address is.",
            "This is a state of the union addresses and we compare our method MD TM.",
            "This is online much scale dynamic topic model with four other method.",
            "DTM DTM is online influence version of Dynamic Topic model.",
            "It actually the model MDM with.",
            "The number of scale set to the one.",
            "And the idea of is a latent addition allocation that is all past data for the influence and LDA one is ideas that use just the client data for the influence.",
            "And LDA online is idea.",
            "With the online influence."
        ],
        [
            "This table shows the average publicae and our method can achieve the lowest publicity for all the datasets.",
            "From this result, we can say that model can appropriately model the dynamics through its use of large scale properties.",
            "Dynamic Topic model does not model the long time scale properties, so the the public G or the DTM.",
            "Become higher than a model and the idea oh, and idea online does not model the dynamics, so the performance is.",
            "Watch the hours and area one ignore the.",
            "If the past information.",
            "So for the modeling of dynamics in the text is.",
            "Not a good.",
            "For the for this model and this graph."
        ],
        [
            "Show the publicity with different number of skills so as you can see the publicity decreased as the number of scales we use increase.",
            "So from this result this result indicates the importance of considering multiple scale dynamics."
        ],
        [
            "And this graph show estimated weights for each scale.",
            "And the weight decreased at the time scale length, and so it means that decent short time scale distribution are more informative for estimated current division it much with our intuition."
        ],
        [
            "So this is a accepted topic from NIPSCO parsnips conference papers.",
            "So in this topic, speech recognition created was extracted.",
            "When we see the long time scale water distribution, speech recognition while speaker training set that kind of speech recognition, typical was extracted when we see them, or shorter timescale distribution we can analyze.",
            "Much scale dynamics in this topic, for example from 92 to 95.",
            "What like system data data, later state letters.",
            "New New Lawrence was phenom classification popular words in this topic.",
            "So from this result we can say that in the speech recognition we the.",
            "What data classification using a follow me formation is a popular work and?",
            "On the other hand, we see the distribution from 1996.",
            "The words like state HMM system probabilities models become popular.",
            "So from this result in the speech recognition them or providing model like HMM is used.",
            "We can see and this is a."
        ],
        [
            "Another topic from NIPS corpus.",
            "So in this topics, landforms mentalizing words are extracted like learning state control, action, time policy, lens format, optimal options, recognition.",
            "And like this weekend using our model, we can analyze the dynamics of what?",
            "Oh, in the multiple time scale."
        ],
        [
            "So in conclusion, we propose a topic model with multiple multi scale dynamics and we also present efficient online influence procedures.",
            "And we experimentally confirmed the high predicted performance.",
            "For the future work, we need to estimate the length of scales.",
            "So in here we just fix the banks of scale.",
            "To do the.",
            "Power of S and but it's better to automatically determine from the data.",
            "And also we need to estimate the number of topics from the data using kind of nonparametric Bayesian model and here.",
            "We just use a text corpus and we want to evaluate our model using other data such as web access log, blog or emails that it thank you.",
            "Any questions?",
            "Does this level of reduction in perplexity result in an improvement in classification accuracy?",
            "So I didn't check the classification accuracy, so.",
            "I gotta say anything.",
            "But yeah, for the publicity, higher policy means that the extra topic might be better.",
            "So if I use.",
            "Oh, that topic for the future for classification.",
            "It might.",
            "It can be a possibility.",
            "It has a possibility to become a better classification of Jesse.",
            "Any others?",
            "I have one on the slide that you have the different scales and then the lowering of perplexity.",
            "How would that manifest?",
            "Maybe back right there.",
            "So how would you automatically try to determine those skills?",
            "Actually, yeah, I sit in the in this experiment we use just.",
            "The long, long times, many as many as time scale.",
            "What I can use, so usually just use a number scale up to six and nine is OK. Yeah, OK. Well, let's thank the speaker again, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you, my name is Tomoharu bottle from NTT communication Science Laboratories in Japan.",
                    "label": 0
                },
                {
                    "sent": "I talk about online much scale dynamic topic models.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Many topic models for analyze document that makes our proposed, for example, a dynamic topic, model topic, overtime dynamic mixture model and topic tracking model.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This model can analyze data such as scientific papers, news articles, blogs and emails.",
                    "label": 0
                },
                {
                    "sent": "Here we consider a different kind of dynamics that is much scale dynamics topics not naturally able with much full time scale.",
                    "label": 0
                },
                {
                    "sent": "For example, let's consider politic topics in news articles was like Constitution, Congress President, our user for many years on their head.",
                    "label": 1
                },
                {
                    "sent": "On the other hand, what like names of members in Congress?",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "User for 10s of years.",
                    "label": 0
                },
                {
                    "sent": "Add an AIDS or abuse under discussion.",
                    "label": 0
                },
                {
                    "sent": "May only appear for few days.",
                    "label": 0
                },
                {
                    "sent": "So here we propose a topic model for analyzing organizing dynamics with multiple time scale, which we call much dynamic topic model.",
                    "label": 1
                },
                {
                    "sent": "Our model is robust becausw information loss is reduced by concerning short and long time scale dynamics and also we present efficient online influence algorithm in which the model is updated using only newly obtained data.",
                    "label": 1
                },
                {
                    "sent": "So we can compute.",
                    "label": 0
                },
                {
                    "sent": "The model.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In efficiently and.",
                    "label": 0
                },
                {
                    "sent": "In this algorithm, we do not need to store the past later, so we can also deduce computational reduce the memory requirement.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Before I explain about our model, we briefly review the standard topic model.",
                    "label": 1
                },
                {
                    "sent": "It's a late industrial kitchen, it's it is a basis of our model.",
                    "label": 0
                },
                {
                    "sent": "So in the in your day, a document is modeled as a mixture of topics.",
                    "label": 1
                },
                {
                    "sent": "Each.",
                    "label": 0
                },
                {
                    "sent": "Each document has its own topic proportion filter, and for each word a topic Z is generated according to the topic proportions.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "What are these generated depending on the topic and also each topic has its own?",
                    "label": 0
                },
                {
                    "sent": "What distribution file and the file distribution file is generated from the symmetric symmetric distribution with parameter beta?",
                    "label": 0
                },
                {
                    "sent": "So in this model there is no dynamics and there's no much scale dynamics.",
                    "label": 0
                },
                {
                    "sent": "So here we incorporate multiple.",
                    "label": 0
                },
                {
                    "sent": "Simscape dynamics in the water district.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "June 5 XI S is a what distribution at scale as and here.",
                    "label": 1
                },
                {
                    "sent": "We set the length of scale so that guy S represents the war distribution from T minus.",
                    "label": 0
                },
                {
                    "sent": "2 two that is minus 1 two T -- 1 It means that the other one is what distribution for one Apple and excited represent.",
                    "label": 0
                },
                {
                    "sent": "Our distribution for two epochs and exhi four dental water distribution for eight epochs longer.",
                    "label": 0
                },
                {
                    "sent": "Water distribution are likely to be more smooth becausw we can observe the more data in the long time scale and short timescale.",
                    "label": 0
                },
                {
                    "sent": "What this vision are likely to be picky.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Two incomplete this much full time scale water distribution into the water distribution at at empty.",
                    "label": 0
                },
                {
                    "sent": "Why?",
                    "label": 0
                },
                {
                    "sent": "We assume that file is generated depending on the weighted sum of this much scale water distribution.",
                    "label": 1
                },
                {
                    "sent": "So here Lambda is that weight and we also use a uniform while distribution with weight Lambda zero in order to avoid a zero probability problem.",
                    "label": 0
                },
                {
                    "sent": "In particular, we assume that.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That what the distribution file is generated from this distribution.",
                    "label": 1
                },
                {
                    "sent": "We use this distribution 'cause it's going to get to the marginal distribution.",
                    "label": 0
                },
                {
                    "sent": "And because of that conjugacy, the influence procedure becomes very simple, and by this we can incorporate the much spare time scale dynamics into the water distribution.",
                    "label": 0
                },
                {
                    "sent": "Also, we consider the dynamics in the topic proportion becausw.",
                    "label": 0
                },
                {
                    "sent": "Popularity of topics change overtime, so for that we added that topic proportion.",
                    "label": 0
                },
                {
                    "sent": "Player Alpha is generated depending on the previous value, so Alpha at empty is generated from this gamma distribution within the parameters there is a previous value.",
                    "label": 0
                },
                {
                    "sent": "And this is a graphical model of our.",
                    "label": 0
                },
                {
                    "sent": "Method and difference between this proposed model and the standard topic model is a top part and the bottom part.",
                    "label": 0
                },
                {
                    "sent": "The Alpha is above according to the.",
                    "label": 0
                },
                {
                    "sent": "Depending on the previous value and also five is generated from depending on the match.",
                    "label": 1
                },
                {
                    "sent": "Scale water distribution with weight Lambda.",
                    "label": 0
                },
                {
                    "sent": "So not that other much scale, what distribution?",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "XI is.",
                    "label": 0
                },
                {
                    "sent": "Here is a hyperparameter, so it is a generative model of documents at a party.",
                    "label": 0
                },
                {
                    "sent": "And for the influence, we update the model at each book using the newly obtained data and the previous model.",
                    "label": 1
                },
                {
                    "sent": "So we observe the data for each Apple and update the model in an online fashion.",
                    "label": 0
                },
                {
                    "sent": "For each book.",
                    "label": 0
                },
                {
                    "sent": "We infer the model using a secure stick EM algorithm.",
                    "label": 0
                },
                {
                    "sent": "In the instep.",
                    "label": 0
                },
                {
                    "sent": "We sample latent topics Z using a.",
                    "label": 0
                },
                {
                    "sent": "Collapse, give something.",
                    "label": 0
                },
                {
                    "sent": "According to this probability and in M step we sound too we optimize the parameters Alpha and Lambda.",
                    "label": 0
                },
                {
                    "sent": "So as to maximize the joint likelihood.",
                    "label": 0
                },
                {
                    "sent": "Using these",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Update Hulu and here we need explain about the how to estimate the much scale water distribution with.",
                    "label": 0
                },
                {
                    "sent": "I guess 'cause IS is a water distribution of scale South the.",
                    "label": 1
                },
                {
                    "sent": "Maximum likelihood estimator is just the proportional to the water count in that scale.",
                    "label": 0
                },
                {
                    "sent": "So the word count of that scale is just a summation of what account are to each Apple in that scale.",
                    "label": 1
                },
                {
                    "sent": "So this figure shows up and each boxes represent what count.",
                    "label": 0
                },
                {
                    "sent": "At a book so and.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The set of boxes can be dispensed did represent what count of scale S, so it suggests a measure of account so we can online update the value in online fashion.",
                    "label": 1
                },
                {
                    "sent": "The current value.",
                    "label": 1
                },
                {
                    "sent": "An S is calculated from the previous value.",
                    "label": 0
                },
                {
                    "sent": "Just adding the current value count and the sub structure.",
                    "label": 1
                },
                {
                    "sent": "The first word count in that scale so.",
                    "label": 0
                },
                {
                    "sent": "For the updating, just throw away this first one and other at the new or newly obtained account.",
                    "label": 0
                },
                {
                    "sent": "It's computationally efficient, but it requires.",
                    "label": 0
                },
                {
                    "sent": "To do the X -- 1 memory.",
                    "label": 0
                },
                {
                    "sent": "So when we want to want is a very long time very long.",
                    "label": 0
                },
                {
                    "sent": "Times scale.",
                    "label": 0
                },
                {
                    "sent": "Dependencies it needs.",
                    "label": 0
                },
                {
                    "sent": "We need a very large memory so.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For.",
                    "label": 0
                },
                {
                    "sent": "To solve that problem, we propose a approximated efficient estimation for much scale water distribution.",
                    "label": 0
                },
                {
                    "sent": "Here we update.",
                    "label": 0
                },
                {
                    "sent": "The count.",
                    "label": 0
                },
                {
                    "sent": "Overscale an S at every two to the X -- 1 at box it means that.",
                    "label": 0
                },
                {
                    "sent": "We decrease the operating frequency for long time scale distribution.",
                    "label": 1
                },
                {
                    "sent": "Using this algorithm we can just store only the previous app account.",
                    "label": 1
                },
                {
                    "sent": "So this.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Images show how this uploads met method works at each boxes represent account at that book, so this box represents account at a box 3 and a set of this set of.",
                    "label": 0
                },
                {
                    "sent": "Boxes represent account of.",
                    "label": 0
                },
                {
                    "sent": "Scale 3, so here we assume that we have a three time scale.",
                    "label": 0
                },
                {
                    "sent": "What account and in the next Apple at the book 5 we newly obtained count counter at Epic 5.",
                    "label": 1
                },
                {
                    "sent": "Inadequate, we only update scale one count.",
                    "label": 0
                },
                {
                    "sent": "Here, and we do not operate a scale to count and scale.",
                    "label": 0
                },
                {
                    "sent": "See count and in the.",
                    "label": 0
                },
                {
                    "sent": "Epic Six we update scale one count and also scale to account for the updating of scale.",
                    "label": 0
                },
                {
                    "sent": "To count we use the previous count of scale one and client count of scale one.",
                    "label": 1
                },
                {
                    "sent": "And at the.",
                    "label": 0
                },
                {
                    "sent": "Epic Seven we only update the scale scale one count as in about 5 and at Apoc.",
                    "label": 0
                },
                {
                    "sent": "Why we update scale 123 count for the operating three scale, 3 count?",
                    "label": 0
                },
                {
                    "sent": "We use a previous.",
                    "label": 1
                },
                {
                    "sent": "Count of schedule and current count of scale 2.",
                    "label": 0
                },
                {
                    "sent": "Using this procedure, we just need to store only previous counts, so the required memory is linear to the.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Gumball was scared so we can.",
                    "label": 0
                },
                {
                    "sent": "Models are very long time scale dynamics.",
                    "label": 0
                },
                {
                    "sent": "Using this uploads magic procedures.",
                    "label": 0
                },
                {
                    "sent": "For the evaluation we use for data set.",
                    "label": 0
                },
                {
                    "sent": "NIPS is conference papers and be an essay titles and degrees of data from web and the address is.",
                    "label": 0
                },
                {
                    "sent": "This is a state of the union addresses and we compare our method MD TM.",
                    "label": 1
                },
                {
                    "sent": "This is online much scale dynamic topic model with four other method.",
                    "label": 1
                },
                {
                    "sent": "DTM DTM is online influence version of Dynamic Topic model.",
                    "label": 0
                },
                {
                    "sent": "It actually the model MDM with.",
                    "label": 0
                },
                {
                    "sent": "The number of scale set to the one.",
                    "label": 0
                },
                {
                    "sent": "And the idea of is a latent addition allocation that is all past data for the influence and LDA one is ideas that use just the client data for the influence.",
                    "label": 1
                },
                {
                    "sent": "And LDA online is idea.",
                    "label": 0
                },
                {
                    "sent": "With the online influence.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This table shows the average publicae and our method can achieve the lowest publicity for all the datasets.",
                    "label": 0
                },
                {
                    "sent": "From this result, we can say that model can appropriately model the dynamics through its use of large scale properties.",
                    "label": 1
                },
                {
                    "sent": "Dynamic Topic model does not model the long time scale properties, so the the public G or the DTM.",
                    "label": 1
                },
                {
                    "sent": "Become higher than a model and the idea oh, and idea online does not model the dynamics, so the performance is.",
                    "label": 0
                },
                {
                    "sent": "Watch the hours and area one ignore the.",
                    "label": 0
                },
                {
                    "sent": "If the past information.",
                    "label": 0
                },
                {
                    "sent": "So for the modeling of dynamics in the text is.",
                    "label": 0
                },
                {
                    "sent": "Not a good.",
                    "label": 0
                },
                {
                    "sent": "For the for this model and this graph.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Show the publicity with different number of skills so as you can see the publicity decreased as the number of scales we use increase.",
                    "label": 0
                },
                {
                    "sent": "So from this result this result indicates the importance of considering multiple scale dynamics.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this graph show estimated weights for each scale.",
                    "label": 0
                },
                {
                    "sent": "And the weight decreased at the time scale length, and so it means that decent short time scale distribution are more informative for estimated current division it much with our intuition.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is a accepted topic from NIPSCO parsnips conference papers.",
                    "label": 0
                },
                {
                    "sent": "So in this topic, speech recognition created was extracted.",
                    "label": 0
                },
                {
                    "sent": "When we see the long time scale water distribution, speech recognition while speaker training set that kind of speech recognition, typical was extracted when we see them, or shorter timescale distribution we can analyze.",
                    "label": 1
                },
                {
                    "sent": "Much scale dynamics in this topic, for example from 92 to 95.",
                    "label": 0
                },
                {
                    "sent": "What like system data data, later state letters.",
                    "label": 0
                },
                {
                    "sent": "New New Lawrence was phenom classification popular words in this topic.",
                    "label": 0
                },
                {
                    "sent": "So from this result we can say that in the speech recognition we the.",
                    "label": 0
                },
                {
                    "sent": "What data classification using a follow me formation is a popular work and?",
                    "label": 0
                },
                {
                    "sent": "On the other hand, we see the distribution from 1996.",
                    "label": 1
                },
                {
                    "sent": "The words like state HMM system probabilities models become popular.",
                    "label": 0
                },
                {
                    "sent": "So from this result in the speech recognition them or providing model like HMM is used.",
                    "label": 0
                },
                {
                    "sent": "We can see and this is a.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Another topic from NIPS corpus.",
                    "label": 0
                },
                {
                    "sent": "So in this topics, landforms mentalizing words are extracted like learning state control, action, time policy, lens format, optimal options, recognition.",
                    "label": 1
                },
                {
                    "sent": "And like this weekend using our model, we can analyze the dynamics of what?",
                    "label": 0
                },
                {
                    "sent": "Oh, in the multiple time scale.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in conclusion, we propose a topic model with multiple multi scale dynamics and we also present efficient online influence procedures.",
                    "label": 0
                },
                {
                    "sent": "And we experimentally confirmed the high predicted performance.",
                    "label": 1
                },
                {
                    "sent": "For the future work, we need to estimate the length of scales.",
                    "label": 0
                },
                {
                    "sent": "So in here we just fix the banks of scale.",
                    "label": 0
                },
                {
                    "sent": "To do the.",
                    "label": 0
                },
                {
                    "sent": "Power of S and but it's better to automatically determine from the data.",
                    "label": 0
                },
                {
                    "sent": "And also we need to estimate the number of topics from the data using kind of nonparametric Bayesian model and here.",
                    "label": 0
                },
                {
                    "sent": "We just use a text corpus and we want to evaluate our model using other data such as web access log, blog or emails that it thank you.",
                    "label": 1
                },
                {
                    "sent": "Any questions?",
                    "label": 0
                },
                {
                    "sent": "Does this level of reduction in perplexity result in an improvement in classification accuracy?",
                    "label": 0
                },
                {
                    "sent": "So I didn't check the classification accuracy, so.",
                    "label": 0
                },
                {
                    "sent": "I gotta say anything.",
                    "label": 0
                },
                {
                    "sent": "But yeah, for the publicity, higher policy means that the extra topic might be better.",
                    "label": 0
                },
                {
                    "sent": "So if I use.",
                    "label": 0
                },
                {
                    "sent": "Oh, that topic for the future for classification.",
                    "label": 0
                },
                {
                    "sent": "It might.",
                    "label": 0
                },
                {
                    "sent": "It can be a possibility.",
                    "label": 0
                },
                {
                    "sent": "It has a possibility to become a better classification of Jesse.",
                    "label": 0
                },
                {
                    "sent": "Any others?",
                    "label": 0
                },
                {
                    "sent": "I have one on the slide that you have the different scales and then the lowering of perplexity.",
                    "label": 0
                },
                {
                    "sent": "How would that manifest?",
                    "label": 0
                },
                {
                    "sent": "Maybe back right there.",
                    "label": 0
                },
                {
                    "sent": "So how would you automatically try to determine those skills?",
                    "label": 0
                },
                {
                    "sent": "Actually, yeah, I sit in the in this experiment we use just.",
                    "label": 0
                },
                {
                    "sent": "The long, long times, many as many as time scale.",
                    "label": 0
                },
                {
                    "sent": "What I can use, so usually just use a number scale up to six and nine is OK. Yeah, OK. Well, let's thank the speaker again, thank you.",
                    "label": 0
                }
            ]
        }
    }
}