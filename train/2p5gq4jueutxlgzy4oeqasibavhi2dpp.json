{
    "id": "2p5gq4jueutxlgzy4oeqasibavhi2dpp",
    "title": "Causal Structure Search: Philosophical Foundations and Future Problems",
    "info": {
        "author": [
            "Richard Scheines, Carnegie Mellon University",
            "Peter Spirtes, Carnegie Mellon University"
        ],
        "published": "Dec. 20, 2008",
        "recorded": "December 2008",
        "category": [
            "Top->Computer Science->Machine Learning->Structured Data"
        ]
    },
    "url": "http://videolectures.net/coa08_spirtes_scheines_csspffp/",
    "segmentation": [
        [
            "It's trying to get some grip on when we know that we don't know the known unknowns.",
            "In the Rumsfeld lingo right when don't we have enough information in the data to tell us anything about what causes what and when, we do have enough information in the data and with the assumptions we've all agreed upon that we."
        ],
        [
            "Something about what's causing what?",
            "So it's clear that causal learning is harder than predictable, because you know.",
            "More that you do to get where you're going.",
            "So I start with some data over vectors of X&Y and I do machine learning on it.",
            "I arrive at some model of.",
            "The variables Y&X and it could be a probability distribution or some other functional model, and then I can use that distribution that I've learned or estimated to make something of a prediction about what one looks like given I have a certain X."
        ],
        [
            "But if I'm doing causal prediction and I've tried to put the causal notions in red and the statistical probabilistic notions in green so we can all separate the two cleanly.",
            "I have to take the data and put it through a causal structure learning algorithm.",
            "Generate something as an output.",
            "That's the structure may be a graph, maybe a set of graphs under that structure to the constraints of that structure.",
            "Estimate the model or the probability distribution and use that distribution and the model to make the sort of predictions that Judy was talking about.",
            "Counterfactual, what would Y look like if we?",
            "Set X to a particular value, so this is quite activity.",
            "And the basic basic view I have of how this causes some population that's sitting there in the background, right with some distribution over X&Y, for example, and there's some causal graph, some causal process that is running the world, and from that probability distribution we get a sample data X&Y, and then the experimental setup we used to get that data which can involve just simply passively observing all the variables or actively random.",
            "Some of the variables or semi randomizing some of the variables right, whatever it is and with background knowledge we apply all those things to a causal."
        ],
        [
            "Structure learning algorithm and we get out.",
            "Not a single graph, but once class of causal structures.",
            "Which is to say a set of causal structures that in that from that data and from that thermostat.",
            "From what we assume background knowledge wise, we could not distinguish those models with that data.",
            "And then if we have a particular question in mind, like what's the probability distribution of Y going to look like if we set X to any particular value?",
            "Sometimes we can answer the question, sometimes we can't, right?",
            "That's the that's the sense in which this is.",
            "Not limited, but it swims in the sense that we should be able to tell when we can answer the question and when we can't."
        ],
        [
            "So here's a simple example.",
            "If I have a population over three variables X1 and X2 and X3 and the causal structure that generates the variables is a change next one through X2 to X3.",
            "And in my distribution there's one independence that holds.",
            "And I gather data from passive observation, ULL experiment and I assume that X2 is prior to X3.",
            "So I ruled out some causal possibilities.",
            "And I say also that there's no confounding.",
            "Right, which is a strong assumption.",
            "And then I run that through and learning algorithm and when I get out.",
            "Is an equivalence class that looks like this.",
            "In which X1 and X2 are connected but we don't know which way.",
            "And X2 is a cause of X3, right?",
            "Because we have illuminated the other possibility with this background knowledge here.",
            "OK. And then we say, well, if we then ask, what questions can we answer with this equivalence class, right?",
            "It's simple to apply an algorithm to figure out which we can, in which we cannot.",
            "So if I'm looking at the probability distribution of X1, given I've set X2 to something right?",
            "I've got all the information I need here, but if I'm looking at the probability of X3 given next to right, I'm sorry the way around.",
            "If I want to X2 given X, X1 given X2, I don't have enough information 'cause I don't know which it's oriented.",
            "But if I wanted three given X2, I do have enough information.",
            "OK, simple enough."
        ],
        [
            "And in this framework, learning any representation like today, I said there's been this wonderful list of successes over the last couple of decades, right?",
            "We had to do calculus.",
            "We can identify.",
            "We have results about when models or one particular counterfactuals are identified.",
            "We can bound things in other cases.",
            "There's been a huge amount of really good work on Bayesian search.",
            "There's been a good amount of work on other courts and models like dynamic Bayesian networks, and there's been, I think, a crucial part of the effort has been in.",
            "Specify equivalence classes for different sorts of models, so the simplest forms of equivalence classes are patterns.",
            "Perlin Verma introduced these in the late 80s, and they represent equivalence classes up bags, but.",
            "If you want to include the possibility that there's latent variables that you haven't measured, there's selection bias.",
            "Thomas Richardson, and Peter's parties and others have done really nice work on this class of models called partial ancestral graphs.",
            "And there's recent work by Ricardo Silva and other people on factor analytic measurement models, and I won't."
        ],
        [
            "Into that because it's complicated.",
            "From these equivalence classes, there's been a lot of really nice work on specifying and proving that there's algorithms that, under the assumptions articulated point, which is to say that is the data grows in the limit, their probability of getting the equivalence class that has as a member of the correct object those we can't.",
            "Develop uniformly consistent algorithms, which is to say we can't in most cases have error bounds or error bars on our causal outputs from these algorithms.",
            "There's been really nice work on discovery in time series.",
            "You probably have heard of Granger instruction.",
            "There's a columnist Kevin Hoover and Dessler and newly Alessio Manetta have done really nice work.",
            "And there's this phenomenal work.",
            "I think lately by Patrick Oyer who's talking this morning and his collaborators in Helsinki on linear models that have non Gaussian error.",
            "And it turns out that in such models we can discover an equivalence class.",
            "It's a unique DAG, right?",
            "We can tell.",
            "Pretty much everything that's going on.",
            "In certain cases.",
            "There's been work on active search lately that's really nice.",
            "Usually the whole field has looked at.",
            "What can we learn if we just do passive observation?",
            "ULL experiments right?",
            "But of course in the world of science one does experiments and if you have big sets of variables, it's very complicated and difficult to know what sequence of experiments what to do to get optimal information out.",
            "So Greg Cooper started this off a few years back and Fedrick Everhart.",
            "Tom Kohler Murphy and recently handgun have developed a beautiful theory of optimal sorts of sequences of experiments under which you can discover the unique structure that generated the data.",
            "There's work now, and overlapping sets of variables.",
            "So if I have two datasets and they share a Common Core but they don't share another core right?",
            "You can still tell a lot about what's causing what, even among variables that only occur in one of the datasets.",
            "There's been lots of applications and I think the work that's going on that Isabel and her team is organizing in the Card Lab challenge is wonderful and good."
        ],
        [
            "OK, so now let me get to.",
            "The philosophical foundations of all this work, see if I can get those articulated and simple and.",
            "Fairly fairly quick way and then talk about the problems that I think we're having.",
            "So the setup all begins with some set of variables V which you can partition into a measured set and a latent set that you have observed.",
            "But the idea is that if you look at the whole set of variables, there's a causal structure over that entire set, and that calls a structure has to be connected now to constraints in the probability distribution that would be generated by that cause of structure.",
            "If we're going to have any chance to go the other way, which is.",
            "To observe data to look at what constraints holding the data and to go back and try to figure out something about the causal structure of the generated data, right?",
            "So you didn't say much about this.",
            "He said that you give me a causal structure and I can answer all these counter factual questions and other sorts of questions.",
            "That's alright, but we still need a way to make the bridge from causal structures to observable constraints, right?",
            "In a plausible way so that we can actually get learning, often found in the first place.",
            "And there's been two sort of paths to that connection, and they both share one assumption, which I'll call assumption one.",
            "And also called the weak causal Markov assumption in simple terms.",
            "And I've left out some of the subtleties if you have.",
            "Causally disconnected which is to say V1 is not a cause of V2V2 is not cause one.",
            "There's nothing that's a common cause of both of them.",
            "Then they're independent.",
            "Right, that's the simplest possible.",
            "I think constraint you could impose upon how causal structure connects to probability.",
            "That's not enough.",
            "You need more if you're going to lose, get conditional independence off the ground.",
            "An route my group took in the late 80s was to just axiomatize the connection fully and the root Pearl took.",
            "Was to actually introduce determinism and say that we have enough variables in this big system, right?",
            "Measured union latent, so that when we put those all together, we can generate a set of structural equations which are really assignment operators for each variable.",
            "If we know the parents of that variable causally, all of them, then we can simply determine the value of that variable.",
            "Every unit in the sample or population, and therefore right have a fully specified system.",
            "And it turns out that the weak Markov assumption plus structural equations entail the causal Marco vaccine, so you don't need determinism.",
            "But if you have it and you have this right, you have all you need."
        ],
        [
            "Yeah.",
            "Cases in which variables interact with one another and there is no one way or the other, but it's in equilibrium.",
            "I'll get to that.",
            "I'll get to that little later.",
            "That's one of the I think the worry cases.",
            "So this is the statement of the mark of Axiom, and you can see in the green there's probability statements, and in the red there's causal statements, and so this serves as a bridge to connect the two.",
            "Graph or what exactly was the status of this?",
            "That's an axiom, which says if you give me a causal graph.",
            "And PA probability distribution.",
            "And I'll tell you when the pair satisfies this axiom.",
            "And I can drive the.",
            "Well, I'm assuming that it's a causal graph, and so I'm saying it is the definition of know.",
            "It's a definition of how causal graphs connect the probability.",
            "I mean but but.",
            "We can get more of that later, but I think.",
            "Take take the take the structural equation model setting you were getting in the earlier part of the day.",
            "And then say all I need to assume is that the variables that are called disconnected in that system are independent and I can derive this.",
            "Yeah.",
            "Cause the graph is a deck."
        ],
        [
            "OK.",
            "So the second assumption is not required for all learning algorithms, but for some is faithfulness an?",
            "I don't want to go into a lot of detail here, but it really just says that the constraints that holding the probably the probability distribution generated by a causal structure hold for all parameterisations of the graph, not just for some or some special ones, right?",
            "So here's the case where it doesn't, it doesn't hold.",
            "So if I have tax rate in the economy and tax revenues on a simple simple linear model.",
            "Right tax rate.",
            "If it goes up, should increase tax revenues, so a should be positive.",
            "An IF tax rate goes up that should depress economic activity, so be should be negative.",
            "And if the economy economic activity increases, doing positive.",
            "And people debate whether or not lowering the tax rate in certain circumstance.",
            "Official for the tax revenues or hurts it, right?",
            "But nobody says that.",
            "Exactly cause negative BC and if it did, we'd have tax rate independent of tax revenues.",
            "So the trade on tax revenues would be 0.",
            "In that case, we violate faithfulness.",
            "Facebook that we're off that little right measure 0 surface in the parameter space."
        ],
        [
            "Alright, the third big assumption, I think, forgetting causal learning off the ground Pearl also talked about as modularity and to illustrate it, I'll give you a call graph with education, income and longevity.",
            "And I'll build structural equations for that model by saying education is equal to someone deserved stochastic error term or noise.",
            "Longevity is some function of education plus its own error term.",
            "Income is some function of education plus its own error term.",
            "These structural equations right constrain me in terms of how I can.",
            "Model represent what's going to happen if I do something, or if I intervene into this system.",
            "Key assumption is.",
            "But if I go ahead and intervene on something like income and I do it by taking over income and determining its value.",
            "Or its distribution?",
            "Then I annihilate.",
            "First education head, but I leave alone the rest of the model and that's the modularity section.",
            "The equations that were in the pre intervened pawn graph education one equation can be taken and moved over to the manipulated structural equation system as it is.",
            "But the only equation to be replaced is the one.",
            "Manipulating nails actually taking over and producing a surgical intervention on income, right?",
            "So I might flip a coin if it comes up heads, you get $100,000 tails, you get 50,000.",
            "So that's my income.",
            "Now I don't have to actually do a surgical intervention."
        ],
        [
            "I don't have to do that to preserve.",
            "Alert so if I do an intervention income where I flip a coin and if it comes up heads, I just give you an extra $25,000.",
            "And if it comes up tails, I just give you an extra $5000, but you still make you had prior to my intervention.",
            "Right?",
            "Then I replaced the original in communication with one in which now income depends upon my intervention variable M2 plus education and it's error term originally, so I don't have to surgically intervene to get modularity.",
            "That's right in some sense.",
            "A special case, but the modularity assigned to the parts of the model.",
            "Get brought over as is.",
            "OK. Big."
        ],
        [
            "Assumptions drive the learning, and so the standard setup is.",
            "I get measured variables.",
            "I assume that some list of the measured guys plus latent right are driven by a culture satisfies these three.",
            "Axioms.",
            "And then my tasks are discovered.",
            "The structure about the measured guys or estimate causal parameters.",
            "Once I have it and less often to try to see if I can discover the existence of latency and maybe the causal relations and estimation of those relationship strengths among the weights."
        ],
        [
            "OK, so now I'm going to go to the problems with standards.",
            "At least the problems that we've been sort of playing around thinking about, and these are sort of meant to stimulate your interest.",
            "I don't have solutions to many of them, and some of them are already solved with another context, but I tend to as a community studying, learning, ignore completely.",
            "Alright, so I'll try to make that clear as I go.",
            "So the first thing I'll talk about is faithfulness, which looks challenged in redundant or thermostatic mechanisms.",
            "I'll talk about measurement problems which are going to appear in some of the causality challenges that you were discussing this morning.",
            "There's a really interesting problem about whether ambiguous, whether manipulations are always right vigorous in terms of what their effect will be.",
            "We have these systems in which we had a brief discussion about this morning.",
            "Denver asked a question about what about PV equals NRT?",
            "Reversible constraint based systems and then finally I want to talk about this problem of constructing variables from raw data before you can even begin the process of trying to learn what's cause."
        ],
        [
            "What?",
            "So I'll try to go fast through here 'cause it shouldn't be too complicated, so if I have redundant mechanisms, such as if I have a gene a that usually codes for a protein right and at the same time as it's on that codes for protein, it suppresses gene B.",
            "Right?",
            "When Gina gets turned off for some reason, right, it's suppressing of Gene B goes away and jinbe comes up, and then Gene B codes for the protein.",
            "So because this mechanism is redundant at some level of Measurement, Genie in the protein will look totally independent.",
            "There's no difference right in the protein output no matter what we do to Jeanie.",
            "Right, so that's a violation of faithfulness.",
            "And then.",
            "Yeah.",
            "There are actual jeans that do this.",
            "Yeah, and there's mechanisms of biology all over the place to do this.",
            "So totally simple version of a thermostatic equilibrium is how the air temperature affects your core.",
            "Body temperature will certainly it does, but your core temperature is re is a thermostatically equilibrated by right some device in your body.",
            "Figuring out what it is and if it's too low, it heats you up, and if it's too high induced sweat to cool it down.",
            "So it looks like if you measure it, the course enough grain in time at least their temperature in core temperature are independent, right?",
            "In any thermostatic mechanism?",
            "Right, if you measure it coarsely enough in time will look independent of the thing it's actually reacting to.",
            "So that's problem."
        ],
        [
            "Now there's also a whole bunch of problems associated with measurement error or measurement issues, because really, the whole foundation of learning is applied to take independence.",
            "Detecting conditional independence, right?",
            "And then using those things to constrain the kind of causal structures that we think are generating the data.",
            "So I just modified.",
            "In this case, this example to go with the 1:00 today use this morning if I'm looking to see whether you're discriminating on the basis of gender, right?",
            "If this is the causal structure, then the answer is you're not.",
            "Gender might cause qualifications and qualifications.",
            "Certainly ought salary, but because there's no direct edge from gender to salary, you're not discriminating.",
            "Yeah, so that's good.",
            "And let's assume that moment there's no confounding out there, so that all you should have to really worry about is whether general salary are independent.",
            "No one qualifications.",
            "But if we measure qualifications, of course it's very difficult to get a quick and clean handle on that.",
            "And so if we put together some measure called QM, right?",
            "That's a measure of the actual thing, but with error.",
            "So QM is a measure of quality plus error.",
            "And it turns out that even though gender and salary are going to be independent on qualifications, gender and Sally will not be independent on the measure we've constructed of qualifications.",
            "So this is a classic problem in economics.",
            "It's called errors in variables, and everybody knows about it right?",
            "Even so, it's rare that I see anybody in the causal learning community take this."
        ],
        [
            "Bruce Lee and the first problem, which is I think not measurement error problem but one of in some sense how coarsely want discuss is a variable.",
            "So if I think that smoking talked about measured very precisely, exactly how much you've smoked before age 50 is a common cause of lung cancer at 60, and how much tar stains you have in your fingers at 50, right?",
            "It's clear that lung cancer and tar stains will be cleaned off by smoking measured precisely.",
            "But instead of measuring or even thinking about smoking precisely, I projected onto a course variable that's just yes, no.",
            "Right?",
            "Well, unless spectrum stances apply in that case, lung cancer and tar stains will not be screened off course version of smoking.",
            "Right, so this is a different problem than measurement error.",
            "I'm not saying I'm measuring this badly, I'm saying I'm measuring it coarsely, or even articulating it."
        ],
        [
            "Firstly.",
            "Now this is not.",
            "This is not an artificial problem in the TV and obesity, which.",
            "Why don't I get a few more than that?",
            "10 minutes.",
            "Alright, I'll skip."
        ],
        [
            "I'll skip through this thing.",
            "The short story is, in a real study on TV and obesity, people measured exercise continuously, but then projected it's very discrete scales and lo and behold, found."
        ],
        [
            "TV and obesity were not screened off the exercise and diet, even though both theory said they needed to be, and they had no way to estimate."
        ],
        [
            "Each mechanism independently.",
            "OK. Another interesting problem will affect, I think, one of the challenges is in genetic regulatory network discovery.",
            "What we all think happens in jeans is that in each cell there might be Gene Z that is a common cause of X&Y and so in each cell.",
            "I have X&Y, are independent onsie, the expression of X, the expression Y right is independent.",
            "Once we know the expression of Z, but the measurements in microarrays, they don't take individual expressions from cells to take tissue samples much them all up and then have the aggregate expression right each of these dots is an aggregate expression of thousands and thousands of cells with ZX and WISE, and in that kind of situation when we sum those expressions together we don't get the independence that we had.",
            "In the original cells, we lose conditional independence in all but the very special cases."
        ],
        [
            "FMRI, the same basic thing happens, but it's even worse.",
            "So if I have a brain region and I have lots of different cells or neurons communicating with each other in that region, right?",
            "And then there's three regions and it turns out that every cell in region X, right?",
            "If it's going to have any effect on region Y goes through region Z right, causally?",
            "Well, that means that for every cell in Axon, every cell in why they'll be independent if I condition on all the guys in Z.",
            "But in fMRI, you aggregate not only over voxels that are groups of loss of neurons, but you construct variables that are many, many, many voxels, and sometimes they are like these regions are colored, not even continuous or adjacent to each other.",
            "And when you do that.",
            "The summation of the activities in the regions are not independent.",
            "You know every cell in the region is screened off by the other region, so again by aggregating."
        ],
        [
            "So you lose conditional independence.",
            "So ambiguous manipulations is sort of a more fundamental problem about the whole.",
            "The whole paradigm, and you can illustrate it with this thing of total cholesterol.",
            "So in the 1960s.",
            "In randomized clinical trials, drugs that reduce total cholesterol, right reduce the risk of heart disease.",
            "So it really did seem that the probability of heart disease given we set total cholesterol was identifiable in the causal structure was clear.",
            "But it turns out later on we learned that total cholesterol is really composed of high density and low density lipids, right?",
            "And then in some sense, total cholesterol was just a another name for all the high density and low density you."
        ],
        [
            "Add going on your blood.",
            "But it also turned out that high density and low density had different effects.",
            "That actually is a mislabeled graph that should be HDL, and there should be LDL.",
            "And I'm using the BF hours now to describe the conditional links, so the total cholesterol is just simply defined logically to be the sum of HDL and LDL.",
            "And if we define the system in such a way that total cholesterol.",
            "Is either high, medium or low.",
            "High density is higher.",
            "Low low density is higher low and heart disease is yes or no.",
            "And then we project.",
            "The combination of HDL and LDL into TC like this so that if you have low HDL and LDL you have low total cholesterol.",
            "If you have low of 1 high of the other you have medium and if you have high of both have high right that's perfectly."
        ],
        [
            "Ansible.",
            "But then it turns out.",
            "Conceptually, not just measurement wise, conceptually, there isn't a well defined result of manipulating your total cholesterol.",
            "So.",
            "I can't manipulate or cluster without independently, independently of both these guys.",
            "And if I set total cholesterol to medium.",
            "Then that's ambiguous over whether I set HDL high and LDL low.",
            "Or HDL low and HDL high that's ambiguous over that, that's."
        ],
        [
            "The problem itself, but it turns out that.",
            "The result of high HDL and low LDL is preventative for heart disease.",
            "But low HDL and high LDL you actually be able to yell promotes heart disease.",
            "So what is the probability of heart disease given I've set total cholesterol to medium, it's undefined.",
            "So I think this is true of any system in which I've given a variable that's supervenient upon components that act differentially."
        ],
        [
            "Now reversible constraint systems I think pose another really complicated but fun problem to think about.",
            "If I have a system like the ideal gas law where pressure and volume equals some constant times temperature.",
            "I don't think that's an equation.",
            "That structural way Pearl was talking about this morning.",
            "PV is not assigned to be this function of temperature.",
            "That isn't equation of the sort he was arguing doesn't.",
            "Actually hold in causal systems.",
            "This poor constraint is going to persist no matter what intervention I do.",
            "Right, even with surgical interventions, it turns out that.",
            "The joint part of the distribution.",
            "Well, first of all, I can't do all the interventions I might.",
            "I can only intervene upon subsets of 2P V of TPV&T.",
            "The interesting thing is that there's.",
            "No matter what intervention I do including the non revention, that constraint will persist in the joint distribution and so the question is, is there any causal graph?",
            "And parameterisation of that graph such that the constraint holds for any permissible set of surgical surgically altered equations including the preintervention equation.",
            "I don't know if such a way to solve the system, and I don't think anybody does right.",
            "And then the question is, can we learn?",
            "Whether or not the system is like this, or like this right from data, I don't think anybody knows that either."
        ],
        [
            "Alright, final topic, just three more minutes.",
            "So the next question really is, well, we don't really use the raw data.",
            "We gather in lots of contexts, we use variables that are constructed on top of that raw data, and then how we construct those variables.",
            "Turns out matters quite a lot, and in a different way.",
            "For causal learning than it does for regular machine learning.",
            "Right, so if I'm looking at voxels in fMRI?",
            "Or if I'm looking at online learning with log data.",
            "Right and I build features that are like activity in a brain region or in the online web case.",
            "I might look at what's the average time the student takes after getting a bottom out hint from a tutor?",
            "In hard problems, that's a constructed variable.",
            "Right, I can apply my machine learning prediction algorithms to those variables.",
            "Doesn't matter how we define them, I just do as well as I can.",
            "But if I'm causal learning, it might matter quite a lot.",
            "And it's maybe a different set of utilities that we're actually trying to optimize.",
            "So it's a search problem and then we can frame it as this."
        ],
        [
            "Problem.",
            "And just to give you a sense of how that goes in fMRI, which always through very quickly in fMRI right, you scan the brain in lots of different places.",
            "You record the activity in voxels.",
            "And then after all this other activity is going on.",
            "We can construct these regions that have colored here, some of which are actually discontinuous, not only in their own hemisphere but across different hemispheres.",
            "And then record activity in those regions and use those as the variables that we're going to input to some."
        ],
        [
            "Running out."
        ],
        [
            "I'll skip through that.",
            "So we want to have a situation in which we wanted to use the causal knowledge to control something.",
            "Suppose we wanted to actually increase output from a baseline, either learning by a student on a web based course or maybe brain activity in a region that's associated with emotional intelligence among autistic children, right?",
            "So we want to do an intervention, and we want to actually influence that thing.",
            "So consider just the simplest case or intervene on a single variable, and we leave cost aside.",
            "So I'm just not going to worry about that.",
            "For now I start with these raw data.",
            "I construct these variables and then I apply my causal search algorithm.",
            "And then I compute the expected utility of the intervention if I can, incorporating uncertainty over the causal structure from the algorithm, which I don't know, it's an equivalence class.",
            "And maybe then certainty over the parameters even given."
        ],
        [
            "Particular causal structure.",
            "So even if I have in my search output write two different equivalence classes.",
            "That look like this, and I'm looking at what the effects on why is in this equivalence class there's only one member, right every every member shares the XY causal output, so I can parameterise it with Alpha no matter what member of the Class I use, I'll estimated to be Alpha, but here.",
            "Right, I don't have a unique member there quivalence class with respect to XY, so I have to do something a little more.",
            "But what I can do is model average, perhaps because this equivalence class.",
            "Stands for lots of different models.",
            "I might actually put some prior over the models in the model averaging so I can compute the expected utility of doing X.",
            "As a function of the expected utility of doing X in equivalence class, one times its probability plus equivalence Class 2 times its probability, and then in the equivalence class I can say what's the probability what you expected.",
            "Utility of doing X right but ranging over each of the Dags in that equivalence class times their probability.",
            "And then for each of the tags I have to integrate out over the probability of that parameter being a particular value.",
            "So I have this three level right integration as it were to get the expected utility of doing X even."
        ],
        [
            "I have the output I have.",
            "So the problem is there might be actually many sets of equivalence classes that each get generated.",
            "As a function of a different set of constructed variables, so you give me the same voxel information, I construct one set of brain regions and you create another right.",
            "So VV, prime and double prime correspond to different variables you constructed from the same raw data.",
            "Right, how do I compute or how would I even think about really computing the expected value of doing X versus the expected value of doing X prime versus the expected value of doing X double prime?",
            "Right, because now these are just variables given to me.",
            "I've built them out of the data and so there's now maybe a choice to be had about what variables like instruct.",
            "And can I even put meaningful priors over models once I've actually built the variables on top of the raw data?"
        ],
        [
            "OK, then I'll stop, sorry."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's trying to get some grip on when we know that we don't know the known unknowns.",
                    "label": 0
                },
                {
                    "sent": "In the Rumsfeld lingo right when don't we have enough information in the data to tell us anything about what causes what and when, we do have enough information in the data and with the assumptions we've all agreed upon that we.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Something about what's causing what?",
                    "label": 0
                },
                {
                    "sent": "So it's clear that causal learning is harder than predictable, because you know.",
                    "label": 1
                },
                {
                    "sent": "More that you do to get where you're going.",
                    "label": 0
                },
                {
                    "sent": "So I start with some data over vectors of X&Y and I do machine learning on it.",
                    "label": 0
                },
                {
                    "sent": "I arrive at some model of.",
                    "label": 0
                },
                {
                    "sent": "The variables Y&X and it could be a probability distribution or some other functional model, and then I can use that distribution that I've learned or estimated to make something of a prediction about what one looks like given I have a certain X.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But if I'm doing causal prediction and I've tried to put the causal notions in red and the statistical probabilistic notions in green so we can all separate the two cleanly.",
                    "label": 0
                },
                {
                    "sent": "I have to take the data and put it through a causal structure learning algorithm.",
                    "label": 0
                },
                {
                    "sent": "Generate something as an output.",
                    "label": 0
                },
                {
                    "sent": "That's the structure may be a graph, maybe a set of graphs under that structure to the constraints of that structure.",
                    "label": 0
                },
                {
                    "sent": "Estimate the model or the probability distribution and use that distribution and the model to make the sort of predictions that Judy was talking about.",
                    "label": 0
                },
                {
                    "sent": "Counterfactual, what would Y look like if we?",
                    "label": 0
                },
                {
                    "sent": "Set X to a particular value, so this is quite activity.",
                    "label": 0
                },
                {
                    "sent": "And the basic basic view I have of how this causes some population that's sitting there in the background, right with some distribution over X&Y, for example, and there's some causal graph, some causal process that is running the world, and from that probability distribution we get a sample data X&Y, and then the experimental setup we used to get that data which can involve just simply passively observing all the variables or actively random.",
                    "label": 0
                },
                {
                    "sent": "Some of the variables or semi randomizing some of the variables right, whatever it is and with background knowledge we apply all those things to a causal.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Structure learning algorithm and we get out.",
                    "label": 1
                },
                {
                    "sent": "Not a single graph, but once class of causal structures.",
                    "label": 0
                },
                {
                    "sent": "Which is to say a set of causal structures that in that from that data and from that thermostat.",
                    "label": 0
                },
                {
                    "sent": "From what we assume background knowledge wise, we could not distinguish those models with that data.",
                    "label": 0
                },
                {
                    "sent": "And then if we have a particular question in mind, like what's the probability distribution of Y going to look like if we set X to any particular value?",
                    "label": 0
                },
                {
                    "sent": "Sometimes we can answer the question, sometimes we can't, right?",
                    "label": 0
                },
                {
                    "sent": "That's the that's the sense in which this is.",
                    "label": 0
                },
                {
                    "sent": "Not limited, but it swims in the sense that we should be able to tell when we can answer the question and when we can't.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's a simple example.",
                    "label": 0
                },
                {
                    "sent": "If I have a population over three variables X1 and X2 and X3 and the causal structure that generates the variables is a change next one through X2 to X3.",
                    "label": 1
                },
                {
                    "sent": "And in my distribution there's one independence that holds.",
                    "label": 0
                },
                {
                    "sent": "And I gather data from passive observation, ULL experiment and I assume that X2 is prior to X3.",
                    "label": 1
                },
                {
                    "sent": "So I ruled out some causal possibilities.",
                    "label": 0
                },
                {
                    "sent": "And I say also that there's no confounding.",
                    "label": 0
                },
                {
                    "sent": "Right, which is a strong assumption.",
                    "label": 0
                },
                {
                    "sent": "And then I run that through and learning algorithm and when I get out.",
                    "label": 0
                },
                {
                    "sent": "Is an equivalence class that looks like this.",
                    "label": 0
                },
                {
                    "sent": "In which X1 and X2 are connected but we don't know which way.",
                    "label": 0
                },
                {
                    "sent": "And X2 is a cause of X3, right?",
                    "label": 0
                },
                {
                    "sent": "Because we have illuminated the other possibility with this background knowledge here.",
                    "label": 0
                },
                {
                    "sent": "OK. And then we say, well, if we then ask, what questions can we answer with this equivalence class, right?",
                    "label": 0
                },
                {
                    "sent": "It's simple to apply an algorithm to figure out which we can, in which we cannot.",
                    "label": 0
                },
                {
                    "sent": "So if I'm looking at the probability distribution of X1, given I've set X2 to something right?",
                    "label": 0
                },
                {
                    "sent": "I've got all the information I need here, but if I'm looking at the probability of X3 given next to right, I'm sorry the way around.",
                    "label": 0
                },
                {
                    "sent": "If I want to X2 given X, X1 given X2, I don't have enough information 'cause I don't know which it's oriented.",
                    "label": 0
                },
                {
                    "sent": "But if I wanted three given X2, I do have enough information.",
                    "label": 0
                },
                {
                    "sent": "OK, simple enough.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And in this framework, learning any representation like today, I said there's been this wonderful list of successes over the last couple of decades, right?",
                    "label": 0
                },
                {
                    "sent": "We had to do calculus.",
                    "label": 0
                },
                {
                    "sent": "We can identify.",
                    "label": 0
                },
                {
                    "sent": "We have results about when models or one particular counterfactuals are identified.",
                    "label": 0
                },
                {
                    "sent": "We can bound things in other cases.",
                    "label": 0
                },
                {
                    "sent": "There's been a huge amount of really good work on Bayesian search.",
                    "label": 1
                },
                {
                    "sent": "There's been a good amount of work on other courts and models like dynamic Bayesian networks, and there's been, I think, a crucial part of the effort has been in.",
                    "label": 0
                },
                {
                    "sent": "Specify equivalence classes for different sorts of models, so the simplest forms of equivalence classes are patterns.",
                    "label": 0
                },
                {
                    "sent": "Perlin Verma introduced these in the late 80s, and they represent equivalence classes up bags, but.",
                    "label": 0
                },
                {
                    "sent": "If you want to include the possibility that there's latent variables that you haven't measured, there's selection bias.",
                    "label": 0
                },
                {
                    "sent": "Thomas Richardson, and Peter's parties and others have done really nice work on this class of models called partial ancestral graphs.",
                    "label": 0
                },
                {
                    "sent": "And there's recent work by Ricardo Silva and other people on factor analytic measurement models, and I won't.",
                    "label": 1
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Into that because it's complicated.",
                    "label": 0
                },
                {
                    "sent": "From these equivalence classes, there's been a lot of really nice work on specifying and proving that there's algorithms that, under the assumptions articulated point, which is to say that is the data grows in the limit, their probability of getting the equivalence class that has as a member of the correct object those we can't.",
                    "label": 0
                },
                {
                    "sent": "Develop uniformly consistent algorithms, which is to say we can't in most cases have error bounds or error bars on our causal outputs from these algorithms.",
                    "label": 0
                },
                {
                    "sent": "There's been really nice work on discovery in time series.",
                    "label": 1
                },
                {
                    "sent": "You probably have heard of Granger instruction.",
                    "label": 0
                },
                {
                    "sent": "There's a columnist Kevin Hoover and Dessler and newly Alessio Manetta have done really nice work.",
                    "label": 0
                },
                {
                    "sent": "And there's this phenomenal work.",
                    "label": 0
                },
                {
                    "sent": "I think lately by Patrick Oyer who's talking this morning and his collaborators in Helsinki on linear models that have non Gaussian error.",
                    "label": 0
                },
                {
                    "sent": "And it turns out that in such models we can discover an equivalence class.",
                    "label": 0
                },
                {
                    "sent": "It's a unique DAG, right?",
                    "label": 0
                },
                {
                    "sent": "We can tell.",
                    "label": 0
                },
                {
                    "sent": "Pretty much everything that's going on.",
                    "label": 0
                },
                {
                    "sent": "In certain cases.",
                    "label": 1
                },
                {
                    "sent": "There's been work on active search lately that's really nice.",
                    "label": 0
                },
                {
                    "sent": "Usually the whole field has looked at.",
                    "label": 0
                },
                {
                    "sent": "What can we learn if we just do passive observation?",
                    "label": 0
                },
                {
                    "sent": "ULL experiments right?",
                    "label": 0
                },
                {
                    "sent": "But of course in the world of science one does experiments and if you have big sets of variables, it's very complicated and difficult to know what sequence of experiments what to do to get optimal information out.",
                    "label": 0
                },
                {
                    "sent": "So Greg Cooper started this off a few years back and Fedrick Everhart.",
                    "label": 0
                },
                {
                    "sent": "Tom Kohler Murphy and recently handgun have developed a beautiful theory of optimal sorts of sequences of experiments under which you can discover the unique structure that generated the data.",
                    "label": 0
                },
                {
                    "sent": "There's work now, and overlapping sets of variables.",
                    "label": 1
                },
                {
                    "sent": "So if I have two datasets and they share a Common Core but they don't share another core right?",
                    "label": 0
                },
                {
                    "sent": "You can still tell a lot about what's causing what, even among variables that only occur in one of the datasets.",
                    "label": 0
                },
                {
                    "sent": "There's been lots of applications and I think the work that's going on that Isabel and her team is organizing in the Card Lab challenge is wonderful and good.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so now let me get to.",
                    "label": 0
                },
                {
                    "sent": "The philosophical foundations of all this work, see if I can get those articulated and simple and.",
                    "label": 0
                },
                {
                    "sent": "Fairly fairly quick way and then talk about the problems that I think we're having.",
                    "label": 0
                },
                {
                    "sent": "So the setup all begins with some set of variables V which you can partition into a measured set and a latent set that you have observed.",
                    "label": 0
                },
                {
                    "sent": "But the idea is that if you look at the whole set of variables, there's a causal structure over that entire set, and that calls a structure has to be connected now to constraints in the probability distribution that would be generated by that cause of structure.",
                    "label": 0
                },
                {
                    "sent": "If we're going to have any chance to go the other way, which is.",
                    "label": 0
                },
                {
                    "sent": "To observe data to look at what constraints holding the data and to go back and try to figure out something about the causal structure of the generated data, right?",
                    "label": 0
                },
                {
                    "sent": "So you didn't say much about this.",
                    "label": 0
                },
                {
                    "sent": "He said that you give me a causal structure and I can answer all these counter factual questions and other sorts of questions.",
                    "label": 0
                },
                {
                    "sent": "That's alright, but we still need a way to make the bridge from causal structures to observable constraints, right?",
                    "label": 0
                },
                {
                    "sent": "In a plausible way so that we can actually get learning, often found in the first place.",
                    "label": 0
                },
                {
                    "sent": "And there's been two sort of paths to that connection, and they both share one assumption, which I'll call assumption one.",
                    "label": 0
                },
                {
                    "sent": "And also called the weak causal Markov assumption in simple terms.",
                    "label": 1
                },
                {
                    "sent": "And I've left out some of the subtleties if you have.",
                    "label": 0
                },
                {
                    "sent": "Causally disconnected which is to say V1 is not a cause of V2V2 is not cause one.",
                    "label": 0
                },
                {
                    "sent": "There's nothing that's a common cause of both of them.",
                    "label": 0
                },
                {
                    "sent": "Then they're independent.",
                    "label": 0
                },
                {
                    "sent": "Right, that's the simplest possible.",
                    "label": 0
                },
                {
                    "sent": "I think constraint you could impose upon how causal structure connects to probability.",
                    "label": 0
                },
                {
                    "sent": "That's not enough.",
                    "label": 0
                },
                {
                    "sent": "You need more if you're going to lose, get conditional independence off the ground.",
                    "label": 0
                },
                {
                    "sent": "An route my group took in the late 80s was to just axiomatize the connection fully and the root Pearl took.",
                    "label": 0
                },
                {
                    "sent": "Was to actually introduce determinism and say that we have enough variables in this big system, right?",
                    "label": 0
                },
                {
                    "sent": "Measured union latent, so that when we put those all together, we can generate a set of structural equations which are really assignment operators for each variable.",
                    "label": 0
                },
                {
                    "sent": "If we know the parents of that variable causally, all of them, then we can simply determine the value of that variable.",
                    "label": 0
                },
                {
                    "sent": "Every unit in the sample or population, and therefore right have a fully specified system.",
                    "label": 0
                },
                {
                    "sent": "And it turns out that the weak Markov assumption plus structural equations entail the causal Marco vaccine, so you don't need determinism.",
                    "label": 0
                },
                {
                    "sent": "But if you have it and you have this right, you have all you need.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Cases in which variables interact with one another and there is no one way or the other, but it's in equilibrium.",
                    "label": 0
                },
                {
                    "sent": "I'll get to that.",
                    "label": 0
                },
                {
                    "sent": "I'll get to that little later.",
                    "label": 0
                },
                {
                    "sent": "That's one of the I think the worry cases.",
                    "label": 0
                },
                {
                    "sent": "So this is the statement of the mark of Axiom, and you can see in the green there's probability statements, and in the red there's causal statements, and so this serves as a bridge to connect the two.",
                    "label": 0
                },
                {
                    "sent": "Graph or what exactly was the status of this?",
                    "label": 0
                },
                {
                    "sent": "That's an axiom, which says if you give me a causal graph.",
                    "label": 0
                },
                {
                    "sent": "And PA probability distribution.",
                    "label": 0
                },
                {
                    "sent": "And I'll tell you when the pair satisfies this axiom.",
                    "label": 0
                },
                {
                    "sent": "And I can drive the.",
                    "label": 0
                },
                {
                    "sent": "Well, I'm assuming that it's a causal graph, and so I'm saying it is the definition of know.",
                    "label": 1
                },
                {
                    "sent": "It's a definition of how causal graphs connect the probability.",
                    "label": 0
                },
                {
                    "sent": "I mean but but.",
                    "label": 0
                },
                {
                    "sent": "We can get more of that later, but I think.",
                    "label": 0
                },
                {
                    "sent": "Take take the take the structural equation model setting you were getting in the earlier part of the day.",
                    "label": 0
                },
                {
                    "sent": "And then say all I need to assume is that the variables that are called disconnected in that system are independent and I can derive this.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 1
                },
                {
                    "sent": "Cause the graph is a deck.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So the second assumption is not required for all learning algorithms, but for some is faithfulness an?",
                    "label": 0
                },
                {
                    "sent": "I don't want to go into a lot of detail here, but it really just says that the constraints that holding the probably the probability distribution generated by a causal structure hold for all parameterisations of the graph, not just for some or some special ones, right?",
                    "label": 0
                },
                {
                    "sent": "So here's the case where it doesn't, it doesn't hold.",
                    "label": 0
                },
                {
                    "sent": "So if I have tax rate in the economy and tax revenues on a simple simple linear model.",
                    "label": 0
                },
                {
                    "sent": "Right tax rate.",
                    "label": 0
                },
                {
                    "sent": "If it goes up, should increase tax revenues, so a should be positive.",
                    "label": 0
                },
                {
                    "sent": "An IF tax rate goes up that should depress economic activity, so be should be negative.",
                    "label": 0
                },
                {
                    "sent": "And if the economy economic activity increases, doing positive.",
                    "label": 0
                },
                {
                    "sent": "And people debate whether or not lowering the tax rate in certain circumstance.",
                    "label": 0
                },
                {
                    "sent": "Official for the tax revenues or hurts it, right?",
                    "label": 0
                },
                {
                    "sent": "But nobody says that.",
                    "label": 0
                },
                {
                    "sent": "Exactly cause negative BC and if it did, we'd have tax rate independent of tax revenues.",
                    "label": 0
                },
                {
                    "sent": "So the trade on tax revenues would be 0.",
                    "label": 0
                },
                {
                    "sent": "In that case, we violate faithfulness.",
                    "label": 0
                },
                {
                    "sent": "Facebook that we're off that little right measure 0 surface in the parameter space.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, the third big assumption, I think, forgetting causal learning off the ground Pearl also talked about as modularity and to illustrate it, I'll give you a call graph with education, income and longevity.",
                    "label": 0
                },
                {
                    "sent": "And I'll build structural equations for that model by saying education is equal to someone deserved stochastic error term or noise.",
                    "label": 1
                },
                {
                    "sent": "Longevity is some function of education plus its own error term.",
                    "label": 0
                },
                {
                    "sent": "Income is some function of education plus its own error term.",
                    "label": 0
                },
                {
                    "sent": "These structural equations right constrain me in terms of how I can.",
                    "label": 1
                },
                {
                    "sent": "Model represent what's going to happen if I do something, or if I intervene into this system.",
                    "label": 0
                },
                {
                    "sent": "Key assumption is.",
                    "label": 0
                },
                {
                    "sent": "But if I go ahead and intervene on something like income and I do it by taking over income and determining its value.",
                    "label": 0
                },
                {
                    "sent": "Or its distribution?",
                    "label": 0
                },
                {
                    "sent": "Then I annihilate.",
                    "label": 0
                },
                {
                    "sent": "First education head, but I leave alone the rest of the model and that's the modularity section.",
                    "label": 0
                },
                {
                    "sent": "The equations that were in the pre intervened pawn graph education one equation can be taken and moved over to the manipulated structural equation system as it is.",
                    "label": 1
                },
                {
                    "sent": "But the only equation to be replaced is the one.",
                    "label": 0
                },
                {
                    "sent": "Manipulating nails actually taking over and producing a surgical intervention on income, right?",
                    "label": 0
                },
                {
                    "sent": "So I might flip a coin if it comes up heads, you get $100,000 tails, you get 50,000.",
                    "label": 0
                },
                {
                    "sent": "So that's my income.",
                    "label": 0
                },
                {
                    "sent": "Now I don't have to actually do a surgical intervention.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I don't have to do that to preserve.",
                    "label": 0
                },
                {
                    "sent": "Alert so if I do an intervention income where I flip a coin and if it comes up heads, I just give you an extra $25,000.",
                    "label": 0
                },
                {
                    "sent": "And if it comes up tails, I just give you an extra $5000, but you still make you had prior to my intervention.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "Then I replaced the original in communication with one in which now income depends upon my intervention variable M2 plus education and it's error term originally, so I don't have to surgically intervene to get modularity.",
                    "label": 0
                },
                {
                    "sent": "That's right in some sense.",
                    "label": 0
                },
                {
                    "sent": "A special case, but the modularity assigned to the parts of the model.",
                    "label": 0
                },
                {
                    "sent": "Get brought over as is.",
                    "label": 0
                },
                {
                    "sent": "OK. Big.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Assumptions drive the learning, and so the standard setup is.",
                    "label": 1
                },
                {
                    "sent": "I get measured variables.",
                    "label": 0
                },
                {
                    "sent": "I assume that some list of the measured guys plus latent right are driven by a culture satisfies these three.",
                    "label": 0
                },
                {
                    "sent": "Axioms.",
                    "label": 0
                },
                {
                    "sent": "And then my tasks are discovered.",
                    "label": 1
                },
                {
                    "sent": "The structure about the measured guys or estimate causal parameters.",
                    "label": 0
                },
                {
                    "sent": "Once I have it and less often to try to see if I can discover the existence of latency and maybe the causal relations and estimation of those relationship strengths among the weights.",
                    "label": 1
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so now I'm going to go to the problems with standards.",
                    "label": 0
                },
                {
                    "sent": "At least the problems that we've been sort of playing around thinking about, and these are sort of meant to stimulate your interest.",
                    "label": 0
                },
                {
                    "sent": "I don't have solutions to many of them, and some of them are already solved with another context, but I tend to as a community studying, learning, ignore completely.",
                    "label": 0
                },
                {
                    "sent": "Alright, so I'll try to make that clear as I go.",
                    "label": 0
                },
                {
                    "sent": "So the first thing I'll talk about is faithfulness, which looks challenged in redundant or thermostatic mechanisms.",
                    "label": 1
                },
                {
                    "sent": "I'll talk about measurement problems which are going to appear in some of the causality challenges that you were discussing this morning.",
                    "label": 0
                },
                {
                    "sent": "There's a really interesting problem about whether ambiguous, whether manipulations are always right vigorous in terms of what their effect will be.",
                    "label": 0
                },
                {
                    "sent": "We have these systems in which we had a brief discussion about this morning.",
                    "label": 0
                },
                {
                    "sent": "Denver asked a question about what about PV equals NRT?",
                    "label": 0
                },
                {
                    "sent": "Reversible constraint based systems and then finally I want to talk about this problem of constructing variables from raw data before you can even begin the process of trying to learn what's cause.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What?",
                    "label": 0
                },
                {
                    "sent": "So I'll try to go fast through here 'cause it shouldn't be too complicated, so if I have redundant mechanisms, such as if I have a gene a that usually codes for a protein right and at the same time as it's on that codes for protein, it suppresses gene B.",
                    "label": 1
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "When Gina gets turned off for some reason, right, it's suppressing of Gene B goes away and jinbe comes up, and then Gene B codes for the protein.",
                    "label": 0
                },
                {
                    "sent": "So because this mechanism is redundant at some level of Measurement, Genie in the protein will look totally independent.",
                    "label": 0
                },
                {
                    "sent": "There's no difference right in the protein output no matter what we do to Jeanie.",
                    "label": 0
                },
                {
                    "sent": "Right, so that's a violation of faithfulness.",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "There are actual jeans that do this.",
                    "label": 0
                },
                {
                    "sent": "Yeah, and there's mechanisms of biology all over the place to do this.",
                    "label": 0
                },
                {
                    "sent": "So totally simple version of a thermostatic equilibrium is how the air temperature affects your core.",
                    "label": 0
                },
                {
                    "sent": "Body temperature will certainly it does, but your core temperature is re is a thermostatically equilibrated by right some device in your body.",
                    "label": 0
                },
                {
                    "sent": "Figuring out what it is and if it's too low, it heats you up, and if it's too high induced sweat to cool it down.",
                    "label": 0
                },
                {
                    "sent": "So it looks like if you measure it, the course enough grain in time at least their temperature in core temperature are independent, right?",
                    "label": 0
                },
                {
                    "sent": "In any thermostatic mechanism?",
                    "label": 0
                },
                {
                    "sent": "Right, if you measure it coarsely enough in time will look independent of the thing it's actually reacting to.",
                    "label": 0
                },
                {
                    "sent": "So that's problem.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now there's also a whole bunch of problems associated with measurement error or measurement issues, because really, the whole foundation of learning is applied to take independence.",
                    "label": 0
                },
                {
                    "sent": "Detecting conditional independence, right?",
                    "label": 0
                },
                {
                    "sent": "And then using those things to constrain the kind of causal structures that we think are generating the data.",
                    "label": 0
                },
                {
                    "sent": "So I just modified.",
                    "label": 0
                },
                {
                    "sent": "In this case, this example to go with the 1:00 today use this morning if I'm looking to see whether you're discriminating on the basis of gender, right?",
                    "label": 0
                },
                {
                    "sent": "If this is the causal structure, then the answer is you're not.",
                    "label": 0
                },
                {
                    "sent": "Gender might cause qualifications and qualifications.",
                    "label": 0
                },
                {
                    "sent": "Certainly ought salary, but because there's no direct edge from gender to salary, you're not discriminating.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so that's good.",
                    "label": 0
                },
                {
                    "sent": "And let's assume that moment there's no confounding out there, so that all you should have to really worry about is whether general salary are independent.",
                    "label": 0
                },
                {
                    "sent": "No one qualifications.",
                    "label": 0
                },
                {
                    "sent": "But if we measure qualifications, of course it's very difficult to get a quick and clean handle on that.",
                    "label": 0
                },
                {
                    "sent": "And so if we put together some measure called QM, right?",
                    "label": 0
                },
                {
                    "sent": "That's a measure of the actual thing, but with error.",
                    "label": 0
                },
                {
                    "sent": "So QM is a measure of quality plus error.",
                    "label": 0
                },
                {
                    "sent": "And it turns out that even though gender and salary are going to be independent on qualifications, gender and Sally will not be independent on the measure we've constructed of qualifications.",
                    "label": 0
                },
                {
                    "sent": "So this is a classic problem in economics.",
                    "label": 0
                },
                {
                    "sent": "It's called errors in variables, and everybody knows about it right?",
                    "label": 0
                },
                {
                    "sent": "Even so, it's rare that I see anybody in the causal learning community take this.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Bruce Lee and the first problem, which is I think not measurement error problem but one of in some sense how coarsely want discuss is a variable.",
                    "label": 0
                },
                {
                    "sent": "So if I think that smoking talked about measured very precisely, exactly how much you've smoked before age 50 is a common cause of lung cancer at 60, and how much tar stains you have in your fingers at 50, right?",
                    "label": 1
                },
                {
                    "sent": "It's clear that lung cancer and tar stains will be cleaned off by smoking measured precisely.",
                    "label": 0
                },
                {
                    "sent": "But instead of measuring or even thinking about smoking precisely, I projected onto a course variable that's just yes, no.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "Well, unless spectrum stances apply in that case, lung cancer and tar stains will not be screened off course version of smoking.",
                    "label": 0
                },
                {
                    "sent": "Right, so this is a different problem than measurement error.",
                    "label": 0
                },
                {
                    "sent": "I'm not saying I'm measuring this badly, I'm saying I'm measuring it coarsely, or even articulating it.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Firstly.",
                    "label": 0
                },
                {
                    "sent": "Now this is not.",
                    "label": 0
                },
                {
                    "sent": "This is not an artificial problem in the TV and obesity, which.",
                    "label": 0
                },
                {
                    "sent": "Why don't I get a few more than that?",
                    "label": 0
                },
                {
                    "sent": "10 minutes.",
                    "label": 0
                },
                {
                    "sent": "Alright, I'll skip.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'll skip through this thing.",
                    "label": 0
                },
                {
                    "sent": "The short story is, in a real study on TV and obesity, people measured exercise continuously, but then projected it's very discrete scales and lo and behold, found.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "TV and obesity were not screened off the exercise and diet, even though both theory said they needed to be, and they had no way to estimate.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Each mechanism independently.",
                    "label": 0
                },
                {
                    "sent": "OK. Another interesting problem will affect, I think, one of the challenges is in genetic regulatory network discovery.",
                    "label": 1
                },
                {
                    "sent": "What we all think happens in jeans is that in each cell there might be Gene Z that is a common cause of X&Y and so in each cell.",
                    "label": 0
                },
                {
                    "sent": "I have X&Y, are independent onsie, the expression of X, the expression Y right is independent.",
                    "label": 0
                },
                {
                    "sent": "Once we know the expression of Z, but the measurements in microarrays, they don't take individual expressions from cells to take tissue samples much them all up and then have the aggregate expression right each of these dots is an aggregate expression of thousands and thousands of cells with ZX and WISE, and in that kind of situation when we sum those expressions together we don't get the independence that we had.",
                    "label": 0
                },
                {
                    "sent": "In the original cells, we lose conditional independence in all but the very special cases.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "FMRI, the same basic thing happens, but it's even worse.",
                    "label": 0
                },
                {
                    "sent": "So if I have a brain region and I have lots of different cells or neurons communicating with each other in that region, right?",
                    "label": 0
                },
                {
                    "sent": "And then there's three regions and it turns out that every cell in region X, right?",
                    "label": 0
                },
                {
                    "sent": "If it's going to have any effect on region Y goes through region Z right, causally?",
                    "label": 1
                },
                {
                    "sent": "Well, that means that for every cell in Axon, every cell in why they'll be independent if I condition on all the guys in Z.",
                    "label": 0
                },
                {
                    "sent": "But in fMRI, you aggregate not only over voxels that are groups of loss of neurons, but you construct variables that are many, many, many voxels, and sometimes they are like these regions are colored, not even continuous or adjacent to each other.",
                    "label": 0
                },
                {
                    "sent": "And when you do that.",
                    "label": 0
                },
                {
                    "sent": "The summation of the activities in the regions are not independent.",
                    "label": 0
                },
                {
                    "sent": "You know every cell in the region is screened off by the other region, so again by aggregating.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So you lose conditional independence.",
                    "label": 0
                },
                {
                    "sent": "So ambiguous manipulations is sort of a more fundamental problem about the whole.",
                    "label": 0
                },
                {
                    "sent": "The whole paradigm, and you can illustrate it with this thing of total cholesterol.",
                    "label": 0
                },
                {
                    "sent": "So in the 1960s.",
                    "label": 0
                },
                {
                    "sent": "In randomized clinical trials, drugs that reduce total cholesterol, right reduce the risk of heart disease.",
                    "label": 1
                },
                {
                    "sent": "So it really did seem that the probability of heart disease given we set total cholesterol was identifiable in the causal structure was clear.",
                    "label": 0
                },
                {
                    "sent": "But it turns out later on we learned that total cholesterol is really composed of high density and low density lipids, right?",
                    "label": 0
                },
                {
                    "sent": "And then in some sense, total cholesterol was just a another name for all the high density and low density you.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Add going on your blood.",
                    "label": 0
                },
                {
                    "sent": "But it also turned out that high density and low density had different effects.",
                    "label": 0
                },
                {
                    "sent": "That actually is a mislabeled graph that should be HDL, and there should be LDL.",
                    "label": 0
                },
                {
                    "sent": "And I'm using the BF hours now to describe the conditional links, so the total cholesterol is just simply defined logically to be the sum of HDL and LDL.",
                    "label": 0
                },
                {
                    "sent": "And if we define the system in such a way that total cholesterol.",
                    "label": 1
                },
                {
                    "sent": "Is either high, medium or low.",
                    "label": 0
                },
                {
                    "sent": "High density is higher.",
                    "label": 1
                },
                {
                    "sent": "Low low density is higher low and heart disease is yes or no.",
                    "label": 0
                },
                {
                    "sent": "And then we project.",
                    "label": 0
                },
                {
                    "sent": "The combination of HDL and LDL into TC like this so that if you have low HDL and LDL you have low total cholesterol.",
                    "label": 0
                },
                {
                    "sent": "If you have low of 1 high of the other you have medium and if you have high of both have high right that's perfectly.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Ansible.",
                    "label": 0
                },
                {
                    "sent": "But then it turns out.",
                    "label": 0
                },
                {
                    "sent": "Conceptually, not just measurement wise, conceptually, there isn't a well defined result of manipulating your total cholesterol.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "I can't manipulate or cluster without independently, independently of both these guys.",
                    "label": 1
                },
                {
                    "sent": "And if I set total cholesterol to medium.",
                    "label": 0
                },
                {
                    "sent": "Then that's ambiguous over whether I set HDL high and LDL low.",
                    "label": 0
                },
                {
                    "sent": "Or HDL low and HDL high that's ambiguous over that, that's.",
                    "label": 1
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The problem itself, but it turns out that.",
                    "label": 0
                },
                {
                    "sent": "The result of high HDL and low LDL is preventative for heart disease.",
                    "label": 0
                },
                {
                    "sent": "But low HDL and high LDL you actually be able to yell promotes heart disease.",
                    "label": 0
                },
                {
                    "sent": "So what is the probability of heart disease given I've set total cholesterol to medium, it's undefined.",
                    "label": 1
                },
                {
                    "sent": "So I think this is true of any system in which I've given a variable that's supervenient upon components that act differentially.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now reversible constraint systems I think pose another really complicated but fun problem to think about.",
                    "label": 0
                },
                {
                    "sent": "If I have a system like the ideal gas law where pressure and volume equals some constant times temperature.",
                    "label": 0
                },
                {
                    "sent": "I don't think that's an equation.",
                    "label": 0
                },
                {
                    "sent": "That structural way Pearl was talking about this morning.",
                    "label": 0
                },
                {
                    "sent": "PV is not assigned to be this function of temperature.",
                    "label": 0
                },
                {
                    "sent": "That isn't equation of the sort he was arguing doesn't.",
                    "label": 0
                },
                {
                    "sent": "Actually hold in causal systems.",
                    "label": 0
                },
                {
                    "sent": "This poor constraint is going to persist no matter what intervention I do.",
                    "label": 0
                },
                {
                    "sent": "Right, even with surgical interventions, it turns out that.",
                    "label": 1
                },
                {
                    "sent": "The joint part of the distribution.",
                    "label": 0
                },
                {
                    "sent": "Well, first of all, I can't do all the interventions I might.",
                    "label": 0
                },
                {
                    "sent": "I can only intervene upon subsets of 2P V of TPV&T.",
                    "label": 0
                },
                {
                    "sent": "The interesting thing is that there's.",
                    "label": 0
                },
                {
                    "sent": "No matter what intervention I do including the non revention, that constraint will persist in the joint distribution and so the question is, is there any causal graph?",
                    "label": 0
                },
                {
                    "sent": "And parameterisation of that graph such that the constraint holds for any permissible set of surgical surgically altered equations including the preintervention equation.",
                    "label": 1
                },
                {
                    "sent": "I don't know if such a way to solve the system, and I don't think anybody does right.",
                    "label": 0
                },
                {
                    "sent": "And then the question is, can we learn?",
                    "label": 0
                },
                {
                    "sent": "Whether or not the system is like this, or like this right from data, I don't think anybody knows that either.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, final topic, just three more minutes.",
                    "label": 0
                },
                {
                    "sent": "So the next question really is, well, we don't really use the raw data.",
                    "label": 0
                },
                {
                    "sent": "We gather in lots of contexts, we use variables that are constructed on top of that raw data, and then how we construct those variables.",
                    "label": 0
                },
                {
                    "sent": "Turns out matters quite a lot, and in a different way.",
                    "label": 0
                },
                {
                    "sent": "For causal learning than it does for regular machine learning.",
                    "label": 1
                },
                {
                    "sent": "Right, so if I'm looking at voxels in fMRI?",
                    "label": 0
                },
                {
                    "sent": "Or if I'm looking at online learning with log data.",
                    "label": 0
                },
                {
                    "sent": "Right and I build features that are like activity in a brain region or in the online web case.",
                    "label": 1
                },
                {
                    "sent": "I might look at what's the average time the student takes after getting a bottom out hint from a tutor?",
                    "label": 0
                },
                {
                    "sent": "In hard problems, that's a constructed variable.",
                    "label": 0
                },
                {
                    "sent": "Right, I can apply my machine learning prediction algorithms to those variables.",
                    "label": 0
                },
                {
                    "sent": "Doesn't matter how we define them, I just do as well as I can.",
                    "label": 0
                },
                {
                    "sent": "But if I'm causal learning, it might matter quite a lot.",
                    "label": 0
                },
                {
                    "sent": "And it's maybe a different set of utilities that we're actually trying to optimize.",
                    "label": 0
                },
                {
                    "sent": "So it's a search problem and then we can frame it as this.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Problem.",
                    "label": 0
                },
                {
                    "sent": "And just to give you a sense of how that goes in fMRI, which always through very quickly in fMRI right, you scan the brain in lots of different places.",
                    "label": 0
                },
                {
                    "sent": "You record the activity in voxels.",
                    "label": 1
                },
                {
                    "sent": "And then after all this other activity is going on.",
                    "label": 0
                },
                {
                    "sent": "We can construct these regions that have colored here, some of which are actually discontinuous, not only in their own hemisphere but across different hemispheres.",
                    "label": 0
                },
                {
                    "sent": "And then record activity in those regions and use those as the variables that we're going to input to some.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Running out.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'll skip through that.",
                    "label": 0
                },
                {
                    "sent": "So we want to have a situation in which we wanted to use the causal knowledge to control something.",
                    "label": 0
                },
                {
                    "sent": "Suppose we wanted to actually increase output from a baseline, either learning by a student on a web based course or maybe brain activity in a region that's associated with emotional intelligence among autistic children, right?",
                    "label": 1
                },
                {
                    "sent": "So we want to do an intervention, and we want to actually influence that thing.",
                    "label": 0
                },
                {
                    "sent": "So consider just the simplest case or intervene on a single variable, and we leave cost aside.",
                    "label": 0
                },
                {
                    "sent": "So I'm just not going to worry about that.",
                    "label": 1
                },
                {
                    "sent": "For now I start with these raw data.",
                    "label": 1
                },
                {
                    "sent": "I construct these variables and then I apply my causal search algorithm.",
                    "label": 0
                },
                {
                    "sent": "And then I compute the expected utility of the intervention if I can, incorporating uncertainty over the causal structure from the algorithm, which I don't know, it's an equivalence class.",
                    "label": 0
                },
                {
                    "sent": "And maybe then certainty over the parameters even given.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Particular causal structure.",
                    "label": 0
                },
                {
                    "sent": "So even if I have in my search output write two different equivalence classes.",
                    "label": 0
                },
                {
                    "sent": "That look like this, and I'm looking at what the effects on why is in this equivalence class there's only one member, right every every member shares the XY causal output, so I can parameterise it with Alpha no matter what member of the Class I use, I'll estimated to be Alpha, but here.",
                    "label": 0
                },
                {
                    "sent": "Right, I don't have a unique member there quivalence class with respect to XY, so I have to do something a little more.",
                    "label": 0
                },
                {
                    "sent": "But what I can do is model average, perhaps because this equivalence class.",
                    "label": 0
                },
                {
                    "sent": "Stands for lots of different models.",
                    "label": 0
                },
                {
                    "sent": "I might actually put some prior over the models in the model averaging so I can compute the expected utility of doing X.",
                    "label": 0
                },
                {
                    "sent": "As a function of the expected utility of doing X in equivalence class, one times its probability plus equivalence Class 2 times its probability, and then in the equivalence class I can say what's the probability what you expected.",
                    "label": 0
                },
                {
                    "sent": "Utility of doing X right but ranging over each of the Dags in that equivalence class times their probability.",
                    "label": 0
                },
                {
                    "sent": "And then for each of the tags I have to integrate out over the probability of that parameter being a particular value.",
                    "label": 0
                },
                {
                    "sent": "So I have this three level right integration as it were to get the expected utility of doing X even.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I have the output I have.",
                    "label": 0
                },
                {
                    "sent": "So the problem is there might be actually many sets of equivalence classes that each get generated.",
                    "label": 1
                },
                {
                    "sent": "As a function of a different set of constructed variables, so you give me the same voxel information, I construct one set of brain regions and you create another right.",
                    "label": 0
                },
                {
                    "sent": "So VV, prime and double prime correspond to different variables you constructed from the same raw data.",
                    "label": 0
                },
                {
                    "sent": "Right, how do I compute or how would I even think about really computing the expected value of doing X versus the expected value of doing X prime versus the expected value of doing X double prime?",
                    "label": 0
                },
                {
                    "sent": "Right, because now these are just variables given to me.",
                    "label": 1
                },
                {
                    "sent": "I've built them out of the data and so there's now maybe a choice to be had about what variables like instruct.",
                    "label": 0
                },
                {
                    "sent": "And can I even put meaningful priors over models once I've actually built the variables on top of the raw data?",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, then I'll stop, sorry.",
                    "label": 0
                }
            ]
        }
    }
}