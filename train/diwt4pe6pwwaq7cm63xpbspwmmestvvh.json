{
    "id": "diwt4pe6pwwaq7cm63xpbspwmmestvvh",
    "title": "Detecting Actions, Poses, and Objects with Relational Phraselets",
    "info": {
        "author": [
            "Deva Ramanan, University of California, Irvine"
        ],
        "chairman": [
            "Michael J. Black, Max Planck Institute for Intelligent Systems, Max Planck Institute",
            "Ivan Laptev, INRIA - The French National Institute for Research in Computer Science and Control"
        ],
        "published": "Nov. 12, 2012",
        "recorded": "October 2012",
        "category": [
            "Top->Computer Science->Computer Vision->Object Recognition",
            "Top->Computer Science->Computer Vision->Motion and Tracking"
        ]
    },
    "url": "http://videolectures.net/eccv2012_ramanan_actions/",
    "segmentation": [
        [
            "Good afternoon, I'll be presenting our work on detecting actions, poses, and objects with relational phrase let's."
        ],
        [
            "Lead author of this work continued as I unfortunately couldn't be here."
        ],
        [
            "So First off, how do we traditionally approach the action recognition problem?",
            "Well, oftentimes it's cast as a multi way classification problem where given the input such as the image on the left, the goal is to output one of K class labels.",
            "This is for example how the Pascal action classification challenges framed."
        ],
        [
            "This makes a somewhat restrictive assumption that bounding boxes are provided at Test time on test images.",
            "Now clearly."
        ],
        [
            "Deployable system has to address this initial detection localization task, which is likely to be challenging of itself Furthermore."
        ],
        [
            "A kwei class label fails to capture all the complexities with which someone could perform an action.",
            "Normally when you ride a bike, you grip the handlebars with your hands and you place your feet on the pedals, but not always, and this finding these rare interactions might be interesting.",
            "So instead."
        ],
        [
            "Will try to formulate a slightly more general version of the problem where given an image with no bounding box annotations, nothing labeled.",
            "We want to fully automatically produce the kind of output here and specifically we will."
        ],
        [
            "To localize each person an interacting object.",
            "We want to."
        ],
        [
            "Classify the action of each detected instance.",
            "In"
        ],
        [
            "Finally, we want to estimate the detailed pose of the person and the interacting object.",
            "Now, why is this the hard task I think."
        ],
        [
            "The primary reason is that human pose estimation is still rather challenging for unconstrained images, and that's because people come in all shapes and sizes and can deform themselves into extreme poses."
        ],
        [
            "But in our case, for actions involving other objects, we also must deal with significant inclusions, and in fact we find inclusions to be such a central issue that will tap."
        ],
        [
            "Ask them on to the desired output for our problem formulation and that is in addition to the first three things.",
            "We also want to explicitly estimate what parts of the human and what parts of the object are included in the rest of the talk.",
            "I'll visualize secluded parts with open circles, an visible parts with filled in circles.",
            "So in this example the rear leg of the right or the yellow circles indicate that it's actually an included leg."
        ],
        [
            "Now there's a rich body work of action recognition, and I'll focus on methods that benchmarks benchmark themselves on Pascal as we do now.",
            "Most methods perform action classification without explicitly computing a human skeleton, and I think this is an indication of the difficulty of the problem of pose estimation for these kinds of images."
        ],
        [
            "We will describe an approach that does try to address pose estimation in action understanding by integrating 3 lines of thought and I'll describe each in turn.",
            "The first"
        ],
        [
            "Our pictorial structure models, which are somewhat classic representations for factoring the appearance of the human body into local appearance.",
            "Templates or parts, together with constraints on the relative arrangements of parts, often visualized as Springs.",
            "Now in particular, will follow a particular variant that we introduced that models articulation through mixtures of small translating patches."
        ],
        [
            "Now almost all part models make the basic assumption that local appearance is independent of global geometry.",
            "So what I mean by this is no matter where I place the head template, and no matter where the other parts lie, I'm going to use the same head template.",
            "It's going to look the same, and somehow this seems that the core of what it means to be apart.",
            "But this independence assumption dramatic."
        ],
        [
            "He breaks down at occlusions if I configure the geometry of my body to place my hand in front of my face.",
            "Well, all of a sudden my my face looks very different than it did before."
        ],
        [
            "Visual phrases is a recent technique that tries to correctly reason about occlusions by defining a large composite template tuned for particular spatial interactions of multiple objects.",
            "So in this case, the included leg of the writer doesn't appear in the template because it was trained using included data.",
            "But the diff."
        ],
        [
            "Quality here is that one may need lots of composite templates to model all types of spatial interactions between these two objects."
        ],
        [
            "And finally, our last inspiration is pose.",
            "Let's, which is an alternative definition of apart as a locally consistent geometric pose.",
            "From our perspective, we can.",
            "We can think of a puzzle it as a little miniature visual phrase or visual composite where it's a composite of two body parts such as the arm and torso, and so for particular configuration of the arm and torso.",
            "Suppose it will correctly score the occlusion because it's trained using those configurations."
        ],
        [
            "But one difficulty here is that these composite templates are trained and detected independently, and this makes it difficult to ensure that a globally consistent or anatomically consistent arrangement imposed its will fire on a given person.",
            "So now we."
        ],
        [
            "Describe a really simple way to combine all three approaches."
        ],
        [
            "Goes as follows.",
            "So we start by defining an articulated model for a person object pair, instantiating parts on both the human and the objects."
        ],
        [
            "Next we define local mixtures at each part to capture different inclusion states, so one local mixture could be the hand by itself.",
            "Another local mixture could be the hand partially included by the Handlebar, another local mixture for the hand could be a hand partially included by another hand.",
            "We call these local mixture phrase let's since they can correspond to parts that actually span multiple objects."
        ],
        [
            "Learn part mixtures or phrase.",
            "Let's will will closely follow the clustering approach introduced in the pose that framework.",
            "So we assume that we are given images with Landmark annotations.",
            "Now for each, for each image and for each landmark will construct a vector of the relative location of all the other landmarks in that image and then will cluster these vectors to learn commonly occur in geometric configurations.",
            "So for example."
        ],
        [
            "Given a bunch of images of people riding bicycles, let's say we cluster these vectors for the hand landmark, we might see two clusters corresponding to frontal views and side views of people riding bicycles."
        ],
        [
            "Now, when clustering, we separately cluster data corresponding to included versus visible parts, and this produces a set of clusters or local mixtures that correspond to different geometric configurations and different visibility states.",
            "OK. And now will put the."
        ],
        [
            "Is into into a pictorial structure or part model framework.",
            "So given an image X, we define a scoring function associated with a particular placement of parts and a particular assignment of local mixtures at each part.",
            "Then it goes as follows."
        ],
        [
            "There is a somewhat standard appearance term, which is simply the local dot product of placing a template tuned for mixture TI at location Pi in the image where Phi is just an appearance vector such as a hog descriptor extracted from that location.",
            "And what's more interesting?"
        ],
        [
            "Is the second term, which defines a quadratic deformation cost between a pair of parts.",
            "But crucially, it is defined for a particular set of local mixtures, for example, of each part has four local mixtures, then there exist 16 possible Springs that define the ideal relative arrangement for each combination of local mixtures.",
            "OK.",
            "So."
        ],
        [
            "We can visualize our learn models by examining modes of deformation in the learn Springs.",
            "As the models deformed different local mixtures of parts become selected due to the mixture dependants, spring terms and so, changing mixtures are denoted by the changing color docs and so this allows our model to reason about local appearance changes due to global geometry such as self occlusions and viewpoint viewpoint changes."
        ],
        [
            "Now, inference corresponds to estimating both part locations and local mixture labels, and we can simply read off the local mixture label and determine where was this an included mixture or visible mixture, and so this will tell us if this was a visible part Aurora excluded part.",
            "Learning is done in a fully supervised setting or linear parameters, including the occlusion model.",
            "These mixture dependent spring turns are all tuned using an SVM solver."
        ],
        [
            "OK, now let's let's address some possible criticisms of this model.",
            "SO11 complaint might be that it seems strange to score Image Evans during occlusion.",
            "If you can't see something, then you shouldn't score any image features."
        ],
        [
            "But our response is well, why not let the learning algorithm decide it can choose to learn a template of all zeros.",
            "Alternatively, it may decide that there exists some characteristic visual pattern associated with an inclusion, such as, say, AT junction."
        ],
        [
            "Another criticism might be that smaller patches won't be as discriminative as large templates used by, say, visual phrases or pose let's."
        ],
        [
            "And our response here is that any connected set of visual phrases can learn any connected set of phrase.",
            "Let's can learn to behave like a larger rigid template by simply learning rigid Springs.",
            "So again, it's kind of up to the learner to decide what things should behave like large postlets or large visual phrases, and what things should be more flexible."
        ],
        [
            "Now let's turn to experimental results.",
            "We perform experiments in the 2010 and 2011 Pascal Action Recognition Benchmark where we've augmented both the train and test set with landmark annotations to both train and evaluate our models.",
            "So let's start off by."
        ],
        [
            "Showing some pictures.",
            "So these are high confidence detections, so again, recall their model processes.",
            "Fully unannotated image returns back detection's action class labels articulated pose results for both the person and object and occlusion flags.",
            "And we see that in his high precision regime it does a fairly reasonable job at all all these tasks."
        ],
        [
            "It's also interesting to examine the false positives.",
            "The high scoring false positives.",
            "So in our problem, formulation of false positive could still be useful because it can provide reports of human pose, which could still be used by some downstream application.",
            "For example, our phoning detector gets confused when people take pictures or when people scratch their head, but in both cases it still returns back reasonable poses."
        ],
        [
            "So we quantitatively evaluate our model on three concrete tasks.",
            "The first one is."
        ],
        [
            "K Way classification an in terms of classification, we're sort of in the middle of the pack where performance is on par with pose.",
            "Let's just in the interest of time refer that the viewer to the paper for precise numbers into."
        ],
        [
            "Suppose estimation we actually do a fair bit better than prior art based on pictorial structures, and we think that's because previous approaches tend not to model occlusion, and occlusion is sort of a fundamental aspect of these types of interacting images.",
            "And I'll focus."
        ],
        [
            "A bit more on action detection and localization.",
            "So."
        ],
        [
            "In this setting we can evaluate ourselves by considering each action, such as writing a bike as an object category and simply use standard measures for evaluating object detection or object localization.",
            "So under this criteria we somewhat.",
            "Reasonably outperformed the previous state of the art based on a visual phrase approach which is provided in blue.",
            "So our model here is red, and so we think that the increase in performance from the blue red curves really is due to the added supervision that we use.",
            "We use annotated landmarks and we also explicitly reason about occlusion.",
            "An geometric appearance changes in our model.",
            "So."
        ],
        [
            "In conclusion, I sort of hope you take away two things from this talk.",
            "So firstly, rather than treating action recognition as a K weight classification task, we can ask much richer questions about detailed spatial understanding involving detection, localization and pose estimation.",
            "Inside"
        ],
        [
            "Only a basic assumption of most if not all part models is that local appearance is independent of global geometry and this breaks down during changes in viewpoint and occlusion.",
            "So in general, as we ask more detailed questions about the spatial layout of objects, I think we'll need models that reason about the interdependence of appearance in geometry, and we describe a simple approach based on local mixtures of geometric parts or phrase.",
            "Let's."
        ],
        [
            "Thank you very much for your attention.",
            "Your model seems to be tree structured, and in particular the bicycle model.",
            "The Forks of the bicycle seem to be attached to the hands, but not the bicycle.",
            "Is that a problem?",
            "Yeah, so that's a great question.",
            "So right now we sort of plugged in this architecture into standard tree models and the way we learn that restructures with some statistical approach.",
            "That child you algorithm.",
            "But I think one of the interesting questions that still unclear.",
            "Is even if it seems like one general story about spatial constraints, is that empirically we can get away with fairly sparsely connected graphs such as stars or trees.",
            "So once we add in these sorts of occlusion constraints and local mixture constraints, it's not so clear to me that that trees will do so.",
            "I think this is an active area of research, so yeah, so we're considering that as well.",
            "So essentially, when you're doing this, is it correct that you're breaking the class into smaller classes and then you're biasing each of your models towards that specific subclass and therefore it's kind of natural not considering the improvements to the model that you made, which is really nice.",
            "You tend to perform better, but what can we say about solving the actual origonal problem?",
            "Which is I don't know, pose estimation not biased in specific poses, but.",
            "General pose estimation or detection.",
            "Um, let me see if I can re interpret your question.",
            "So I guess the hope is is that you can.",
            "You can imagine that.",
            "Visual phrases or we use global templates that that sort of is your subclass approach where you focus only on images where people are standing or focus images focus on where people are sitting and so one of the arguments we make is that one nice aspect of that approach is that you'll correctly score the occlusions associated with that, so the hope was is that we want to sort of create less of a biased model by cutting up those big templates into little templates, spatially smaller patches, and allow these to deform and swap out with each other.",
            "So the hope is that we're trying to explicitly address this sort of biased question by getting this model to behave like a global template that correctly scores occlusions, but in a way where you can generate an effective large set of global templates.",
            "Maybe I missed this, but I think you mentioned that it's completely supervised, so perhaps your data set also has an annotations for occlusions.",
            "Have you thought about at some point making them latent variables and inferring them from data that doesn't have that and latent SPMS or something?",
            "Sure, that makes a lot of sense.",
            "Our thinking was that if you're going to put forth the effort into annotating landmarks in the 1st place, you'll see that if you can't see landmark right away, it's kind of annoying to annotate.",
            "So just labeling that is not visible seems like it's not.",
            "Not that sort of occlusion flag is not that much extra effort, but one thing that this approach does require which is strange is you still need the location of an included part, and that could be hard to do, so I think that's a very natural place to throw in some latent estimation where maybe a user could guess, or I think the leg is here.",
            "I'm not really sure 'cause I can't see it, but then the model itself sort of refines it during some later re estimation process.",
            "Thank you for vigorous set of questions anymore.",
            "Alright, let's thank Dave again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Good afternoon, I'll be presenting our work on detecting actions, poses, and objects with relational phrase let's.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Lead author of this work continued as I unfortunately couldn't be here.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So First off, how do we traditionally approach the action recognition problem?",
                    "label": 0
                },
                {
                    "sent": "Well, oftentimes it's cast as a multi way classification problem where given the input such as the image on the left, the goal is to output one of K class labels.",
                    "label": 0
                },
                {
                    "sent": "This is for example how the Pascal action classification challenges framed.",
                    "label": 1
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This makes a somewhat restrictive assumption that bounding boxes are provided at Test time on test images.",
                    "label": 0
                },
                {
                    "sent": "Now clearly.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Deployable system has to address this initial detection localization task, which is likely to be challenging of itself Furthermore.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A kwei class label fails to capture all the complexities with which someone could perform an action.",
                    "label": 0
                },
                {
                    "sent": "Normally when you ride a bike, you grip the handlebars with your hands and you place your feet on the pedals, but not always, and this finding these rare interactions might be interesting.",
                    "label": 0
                },
                {
                    "sent": "So instead.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Will try to formulate a slightly more general version of the problem where given an image with no bounding box annotations, nothing labeled.",
                    "label": 0
                },
                {
                    "sent": "We want to fully automatically produce the kind of output here and specifically we will.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To localize each person an interacting object.",
                    "label": 0
                },
                {
                    "sent": "We want to.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Classify the action of each detected instance.",
                    "label": 0
                },
                {
                    "sent": "In",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Finally, we want to estimate the detailed pose of the person and the interacting object.",
                    "label": 0
                },
                {
                    "sent": "Now, why is this the hard task I think.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The primary reason is that human pose estimation is still rather challenging for unconstrained images, and that's because people come in all shapes and sizes and can deform themselves into extreme poses.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But in our case, for actions involving other objects, we also must deal with significant inclusions, and in fact we find inclusions to be such a central issue that will tap.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Ask them on to the desired output for our problem formulation and that is in addition to the first three things.",
                    "label": 1
                },
                {
                    "sent": "We also want to explicitly estimate what parts of the human and what parts of the object are included in the rest of the talk.",
                    "label": 1
                },
                {
                    "sent": "I'll visualize secluded parts with open circles, an visible parts with filled in circles.",
                    "label": 0
                },
                {
                    "sent": "So in this example the rear leg of the right or the yellow circles indicate that it's actually an included leg.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now there's a rich body work of action recognition, and I'll focus on methods that benchmarks benchmark themselves on Pascal as we do now.",
                    "label": 0
                },
                {
                    "sent": "Most methods perform action classification without explicitly computing a human skeleton, and I think this is an indication of the difficulty of the problem of pose estimation for these kinds of images.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We will describe an approach that does try to address pose estimation in action understanding by integrating 3 lines of thought and I'll describe each in turn.",
                    "label": 0
                },
                {
                    "sent": "The first",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Our pictorial structure models, which are somewhat classic representations for factoring the appearance of the human body into local appearance.",
                    "label": 0
                },
                {
                    "sent": "Templates or parts, together with constraints on the relative arrangements of parts, often visualized as Springs.",
                    "label": 0
                },
                {
                    "sent": "Now in particular, will follow a particular variant that we introduced that models articulation through mixtures of small translating patches.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now almost all part models make the basic assumption that local appearance is independent of global geometry.",
                    "label": 1
                },
                {
                    "sent": "So what I mean by this is no matter where I place the head template, and no matter where the other parts lie, I'm going to use the same head template.",
                    "label": 0
                },
                {
                    "sent": "It's going to look the same, and somehow this seems that the core of what it means to be apart.",
                    "label": 0
                },
                {
                    "sent": "But this independence assumption dramatic.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "He breaks down at occlusions if I configure the geometry of my body to place my hand in front of my face.",
                    "label": 0
                },
                {
                    "sent": "Well, all of a sudden my my face looks very different than it did before.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Visual phrases is a recent technique that tries to correctly reason about occlusions by defining a large composite template tuned for particular spatial interactions of multiple objects.",
                    "label": 0
                },
                {
                    "sent": "So in this case, the included leg of the writer doesn't appear in the template because it was trained using included data.",
                    "label": 0
                },
                {
                    "sent": "But the diff.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Quality here is that one may need lots of composite templates to model all types of spatial interactions between these two objects.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And finally, our last inspiration is pose.",
                    "label": 0
                },
                {
                    "sent": "Let's, which is an alternative definition of apart as a locally consistent geometric pose.",
                    "label": 0
                },
                {
                    "sent": "From our perspective, we can.",
                    "label": 0
                },
                {
                    "sent": "We can think of a puzzle it as a little miniature visual phrase or visual composite where it's a composite of two body parts such as the arm and torso, and so for particular configuration of the arm and torso.",
                    "label": 0
                },
                {
                    "sent": "Suppose it will correctly score the occlusion because it's trained using those configurations.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But one difficulty here is that these composite templates are trained and detected independently, and this makes it difficult to ensure that a globally consistent or anatomically consistent arrangement imposed its will fire on a given person.",
                    "label": 0
                },
                {
                    "sent": "So now we.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Describe a really simple way to combine all three approaches.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Goes as follows.",
                    "label": 0
                },
                {
                    "sent": "So we start by defining an articulated model for a person object pair, instantiating parts on both the human and the objects.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Next we define local mixtures at each part to capture different inclusion states, so one local mixture could be the hand by itself.",
                    "label": 0
                },
                {
                    "sent": "Another local mixture could be the hand partially included by the Handlebar, another local mixture for the hand could be a hand partially included by another hand.",
                    "label": 0
                },
                {
                    "sent": "We call these local mixture phrase let's since they can correspond to parts that actually span multiple objects.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Learn part mixtures or phrase.",
                    "label": 0
                },
                {
                    "sent": "Let's will will closely follow the clustering approach introduced in the pose that framework.",
                    "label": 0
                },
                {
                    "sent": "So we assume that we are given images with Landmark annotations.",
                    "label": 0
                },
                {
                    "sent": "Now for each, for each image and for each landmark will construct a vector of the relative location of all the other landmarks in that image and then will cluster these vectors to learn commonly occur in geometric configurations.",
                    "label": 0
                },
                {
                    "sent": "So for example.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Given a bunch of images of people riding bicycles, let's say we cluster these vectors for the hand landmark, we might see two clusters corresponding to frontal views and side views of people riding bicycles.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now, when clustering, we separately cluster data corresponding to included versus visible parts, and this produces a set of clusters or local mixtures that correspond to different geometric configurations and different visibility states.",
                    "label": 0
                },
                {
                    "sent": "OK. And now will put the.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is into into a pictorial structure or part model framework.",
                    "label": 0
                },
                {
                    "sent": "So given an image X, we define a scoring function associated with a particular placement of parts and a particular assignment of local mixtures at each part.",
                    "label": 0
                },
                {
                    "sent": "Then it goes as follows.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "There is a somewhat standard appearance term, which is simply the local dot product of placing a template tuned for mixture TI at location Pi in the image where Phi is just an appearance vector such as a hog descriptor extracted from that location.",
                    "label": 0
                },
                {
                    "sent": "And what's more interesting?",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is the second term, which defines a quadratic deformation cost between a pair of parts.",
                    "label": 0
                },
                {
                    "sent": "But crucially, it is defined for a particular set of local mixtures, for example, of each part has four local mixtures, then there exist 16 possible Springs that define the ideal relative arrangement for each combination of local mixtures.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We can visualize our learn models by examining modes of deformation in the learn Springs.",
                    "label": 0
                },
                {
                    "sent": "As the models deformed different local mixtures of parts become selected due to the mixture dependants, spring terms and so, changing mixtures are denoted by the changing color docs and so this allows our model to reason about local appearance changes due to global geometry such as self occlusions and viewpoint viewpoint changes.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now, inference corresponds to estimating both part locations and local mixture labels, and we can simply read off the local mixture label and determine where was this an included mixture or visible mixture, and so this will tell us if this was a visible part Aurora excluded part.",
                    "label": 0
                },
                {
                    "sent": "Learning is done in a fully supervised setting or linear parameters, including the occlusion model.",
                    "label": 0
                },
                {
                    "sent": "These mixture dependent spring turns are all tuned using an SVM solver.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, now let's let's address some possible criticisms of this model.",
                    "label": 0
                },
                {
                    "sent": "SO11 complaint might be that it seems strange to score Image Evans during occlusion.",
                    "label": 0
                },
                {
                    "sent": "If you can't see something, then you shouldn't score any image features.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But our response is well, why not let the learning algorithm decide it can choose to learn a template of all zeros.",
                    "label": 0
                },
                {
                    "sent": "Alternatively, it may decide that there exists some characteristic visual pattern associated with an inclusion, such as, say, AT junction.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another criticism might be that smaller patches won't be as discriminative as large templates used by, say, visual phrases or pose let's.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And our response here is that any connected set of visual phrases can learn any connected set of phrase.",
                    "label": 1
                },
                {
                    "sent": "Let's can learn to behave like a larger rigid template by simply learning rigid Springs.",
                    "label": 1
                },
                {
                    "sent": "So again, it's kind of up to the learner to decide what things should behave like large postlets or large visual phrases, and what things should be more flexible.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now let's turn to experimental results.",
                    "label": 0
                },
                {
                    "sent": "We perform experiments in the 2010 and 2011 Pascal Action Recognition Benchmark where we've augmented both the train and test set with landmark annotations to both train and evaluate our models.",
                    "label": 1
                },
                {
                    "sent": "So let's start off by.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Showing some pictures.",
                    "label": 0
                },
                {
                    "sent": "So these are high confidence detections, so again, recall their model processes.",
                    "label": 0
                },
                {
                    "sent": "Fully unannotated image returns back detection's action class labels articulated pose results for both the person and object and occlusion flags.",
                    "label": 0
                },
                {
                    "sent": "And we see that in his high precision regime it does a fairly reasonable job at all all these tasks.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's also interesting to examine the false positives.",
                    "label": 0
                },
                {
                    "sent": "The high scoring false positives.",
                    "label": 0
                },
                {
                    "sent": "So in our problem, formulation of false positive could still be useful because it can provide reports of human pose, which could still be used by some downstream application.",
                    "label": 0
                },
                {
                    "sent": "For example, our phoning detector gets confused when people take pictures or when people scratch their head, but in both cases it still returns back reasonable poses.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we quantitatively evaluate our model on three concrete tasks.",
                    "label": 0
                },
                {
                    "sent": "The first one is.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "K Way classification an in terms of classification, we're sort of in the middle of the pack where performance is on par with pose.",
                    "label": 0
                },
                {
                    "sent": "Let's just in the interest of time refer that the viewer to the paper for precise numbers into.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Suppose estimation we actually do a fair bit better than prior art based on pictorial structures, and we think that's because previous approaches tend not to model occlusion, and occlusion is sort of a fundamental aspect of these types of interacting images.",
                    "label": 0
                },
                {
                    "sent": "And I'll focus.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A bit more on action detection and localization.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In this setting we can evaluate ourselves by considering each action, such as writing a bike as an object category and simply use standard measures for evaluating object detection or object localization.",
                    "label": 0
                },
                {
                    "sent": "So under this criteria we somewhat.",
                    "label": 0
                },
                {
                    "sent": "Reasonably outperformed the previous state of the art based on a visual phrase approach which is provided in blue.",
                    "label": 0
                },
                {
                    "sent": "So our model here is red, and so we think that the increase in performance from the blue red curves really is due to the added supervision that we use.",
                    "label": 0
                },
                {
                    "sent": "We use annotated landmarks and we also explicitly reason about occlusion.",
                    "label": 0
                },
                {
                    "sent": "An geometric appearance changes in our model.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In conclusion, I sort of hope you take away two things from this talk.",
                    "label": 0
                },
                {
                    "sent": "So firstly, rather than treating action recognition as a K weight classification task, we can ask much richer questions about detailed spatial understanding involving detection, localization and pose estimation.",
                    "label": 0
                },
                {
                    "sent": "Inside",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Only a basic assumption of most if not all part models is that local appearance is independent of global geometry and this breaks down during changes in viewpoint and occlusion.",
                    "label": 0
                },
                {
                    "sent": "So in general, as we ask more detailed questions about the spatial layout of objects, I think we'll need models that reason about the interdependence of appearance in geometry, and we describe a simple approach based on local mixtures of geometric parts or phrase.",
                    "label": 1
                },
                {
                    "sent": "Let's.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you very much for your attention.",
                    "label": 0
                },
                {
                    "sent": "Your model seems to be tree structured, and in particular the bicycle model.",
                    "label": 0
                },
                {
                    "sent": "The Forks of the bicycle seem to be attached to the hands, but not the bicycle.",
                    "label": 0
                },
                {
                    "sent": "Is that a problem?",
                    "label": 0
                },
                {
                    "sent": "Yeah, so that's a great question.",
                    "label": 0
                },
                {
                    "sent": "So right now we sort of plugged in this architecture into standard tree models and the way we learn that restructures with some statistical approach.",
                    "label": 0
                },
                {
                    "sent": "That child you algorithm.",
                    "label": 0
                },
                {
                    "sent": "But I think one of the interesting questions that still unclear.",
                    "label": 0
                },
                {
                    "sent": "Is even if it seems like one general story about spatial constraints, is that empirically we can get away with fairly sparsely connected graphs such as stars or trees.",
                    "label": 0
                },
                {
                    "sent": "So once we add in these sorts of occlusion constraints and local mixture constraints, it's not so clear to me that that trees will do so.",
                    "label": 0
                },
                {
                    "sent": "I think this is an active area of research, so yeah, so we're considering that as well.",
                    "label": 0
                },
                {
                    "sent": "So essentially, when you're doing this, is it correct that you're breaking the class into smaller classes and then you're biasing each of your models towards that specific subclass and therefore it's kind of natural not considering the improvements to the model that you made, which is really nice.",
                    "label": 0
                },
                {
                    "sent": "You tend to perform better, but what can we say about solving the actual origonal problem?",
                    "label": 0
                },
                {
                    "sent": "Which is I don't know, pose estimation not biased in specific poses, but.",
                    "label": 0
                },
                {
                    "sent": "General pose estimation or detection.",
                    "label": 0
                },
                {
                    "sent": "Um, let me see if I can re interpret your question.",
                    "label": 0
                },
                {
                    "sent": "So I guess the hope is is that you can.",
                    "label": 0
                },
                {
                    "sent": "You can imagine that.",
                    "label": 0
                },
                {
                    "sent": "Visual phrases or we use global templates that that sort of is your subclass approach where you focus only on images where people are standing or focus images focus on where people are sitting and so one of the arguments we make is that one nice aspect of that approach is that you'll correctly score the occlusions associated with that, so the hope was is that we want to sort of create less of a biased model by cutting up those big templates into little templates, spatially smaller patches, and allow these to deform and swap out with each other.",
                    "label": 0
                },
                {
                    "sent": "So the hope is that we're trying to explicitly address this sort of biased question by getting this model to behave like a global template that correctly scores occlusions, but in a way where you can generate an effective large set of global templates.",
                    "label": 0
                },
                {
                    "sent": "Maybe I missed this, but I think you mentioned that it's completely supervised, so perhaps your data set also has an annotations for occlusions.",
                    "label": 0
                },
                {
                    "sent": "Have you thought about at some point making them latent variables and inferring them from data that doesn't have that and latent SPMS or something?",
                    "label": 0
                },
                {
                    "sent": "Sure, that makes a lot of sense.",
                    "label": 0
                },
                {
                    "sent": "Our thinking was that if you're going to put forth the effort into annotating landmarks in the 1st place, you'll see that if you can't see landmark right away, it's kind of annoying to annotate.",
                    "label": 0
                },
                {
                    "sent": "So just labeling that is not visible seems like it's not.",
                    "label": 0
                },
                {
                    "sent": "Not that sort of occlusion flag is not that much extra effort, but one thing that this approach does require which is strange is you still need the location of an included part, and that could be hard to do, so I think that's a very natural place to throw in some latent estimation where maybe a user could guess, or I think the leg is here.",
                    "label": 0
                },
                {
                    "sent": "I'm not really sure 'cause I can't see it, but then the model itself sort of refines it during some later re estimation process.",
                    "label": 0
                },
                {
                    "sent": "Thank you for vigorous set of questions anymore.",
                    "label": 0
                },
                {
                    "sent": "Alright, let's thank Dave again.",
                    "label": 0
                }
            ]
        }
    }
}