{
    "id": "6hujbpgw7j56rhfyhnj2ieniiynahbpk",
    "title": "Hierarchical Vision-Language Alignment for Video Captioning",
    "info": {
        "author": [
            "Junchao Zhang, Institute of Statistical Mathematics"
        ],
        "published": "Jan. 29, 2019",
        "recorded": "January 2019",
        "category": [
            "Top->Computers->Multimedia"
        ]
    },
    "url": "http://videolectures.net/multimediamodeling2019_zhang_video_captioning/",
    "segmentation": [
        [
            "Hello everyone, I'm glad to have the chance to introduce our work hierarchical vision language alignment for video captioning.",
            "I'm gentle down from Peking University and Co.",
            "Author is Professor Palm."
        ],
        [
            "This work is to address the video captioning task, which aims to generate natural language sentence to describe the input.",
            "Video content is are introduced.",
            "Research across computer vision and natural language processing."
        ],
        [
            "Oh, and its challenges are from 2 aspects.",
            "The first one.",
            "That it needs to fully understand the complex of video content, including recognizing objects.",
            "Detect visual relations and analyzing.",
            "Student ratings and so on.",
            "A second idea is further to transform the video.",
            "The visual content to into the language sentence.",
            "I think the weird I think the key point is to seek the alignment between the visual content and language components."
        ],
        [
            "Is it works already includes two categories in the early stage template based language models contract mainstream.",
            "These methods first predict the visual words in video and then organize them into subject.",
            "Verb object topples and finally formed sentence according to the predefined language templates and rulers.",
            "However, the predefined templates and rulers make the sentence of lack of diversity diversity.",
            "This is the other limitation."
        ],
        [
            "Nowadays, with the advances of deep learning techniques, sequence learning based methods are proposed.",
            "They adopt adopt the encoder decoder framework that can train the content.",
            "To end and visual attention and attributes and multimodal clothes are usually used for encoding and decoding.",
            "However, how to align the visual content to language components remains to be resolved."
        ],
        [
            "We argue that for video captioning is important to employ, the correspondences between visual elements such as the object relations or are interested regions and language components.",
            "There are multi level vision language alignments.",
            "The first we can see we can say that the object in the frames can be present by the individual words such as the man.",
            "Tim St this is this means the object word alignment.",
            "Second, the visual relations among objects can be described by by the by the phrases of the sentence, such as man, in costume, or man in street.",
            "This means the relation of relation of phrase alignment.",
            "Again, the third, uh, we can see that the entreated regions in frames usually come early, convert the main video content which are corresponding to the whole sentence.",
            "This index, the region sentence alignment this this three.",
            "A multi level.",
            "This remote level visual language laments can provide acquired guidance on sentence generation."
        ],
        [
            "Not in this paper are we propose an attention guide hierarchical alignment approach.",
            "Our our man comes American contributions includes two aspects.",
            "First, the hierarchical vision language alignments are appointed to provide the cost to find gardens on video description generation on the second multi grain granularity with visual features are employed to fully model the complex visual content.",
            "Oh"
        ],
        [
            "Always first introduce a.",
            "So we first introduced the multi granularity visual feature extraction.",
            "Oh, I'm sorry, the this is the overview.",
            "Or this is the overview of our overall framework of for each, for each input video we first set of refer to it as the multi granularity visual features and then away feed them into the three parallel encoder decoder streams.",
            "Include the Object stream, relation stream and androgen streams.",
            "And finally we integrate these three of these three stream to obtain the final results, and 1st we introduce the multi granularity visual feature, HSL."
        ],
        [
            "And in this, a step in the subway, there are total four or different.",
            "Granularities of visual features are that are extracted and we take four different specific models.",
            "As the feature extractor feature extractors in detail of the global, the global feature is expected for the for the whole frame by a population model.",
            "Then the the region specific features are attractive for the interested regions.",
            "Uh, and we use and we use Imagine captioned model to as their feature extractors.",
            "Then the relation specific features are our trusted are extracted by the relation detection model and finally the objective specific features I changed by the object detection model.",
            "We think that we think that these features represent the video content, video content from different skills, so we can capture cost to find our visual visual information of a video frame, which is the helpful to understand the video content and Furthermore the vision language alignment.",
            "Alignment information is also implicit in these features."
        ],
        [
            "Now we introduce the parallel encoder decoder streams.",
            "All three streams have the same same structure than each of them.",
            "Discount consist of, or consist of, an attention based encoder and alignment element.",
            "Embedded coder."
        ],
        [
            "Here is the attention based encoder for.",
            "For each frame we detect multiple multiple objects relations, an interested regions.",
            "So we first apply the soft attention to selected.",
            "Use the useful and silent visual elements and then.",
            "We always are.",
            "We designed the LSTM with double memories and double states to encoding to encode the individual information.",
            "Here.",
            "Here is the formulas formulas for the for the double memories and double states.",
            "And in this way each stream can include global information, global information, and one of the other other specific information, such as objects, relation and and region information, which makes the encoding more specific and accurate."
        ],
        [
            "And then there are alignment.",
            "Embedded decoder is designed to to process the vision, language alignment information and generate the language sentence.",
            "Here is also other formulas about about the about coder, for each.",
            "For each stream, the global information serves as the surface as the constraint, a constraint of the global global contest, and for each stream way.",
            "Oh, it's uh each stream.",
            "Uh, and employed the object, applied one specific once with the elevation of vision, language alignment information, namely particular word alignment relation or phrase alignment, androgen sentence alignment.",
            "And in such A and in such way the three elements are employed respectively to provide guidance on sentence generation."
        ],
        [
            "And finally, three streams are integrated to employ the complete complementarity's among different version language elements information."
        ],
        [
            "Now the next wave of I will introduce a partments.",
            "We conduct the improvements on the widely used.",
            "They said MSVD and we and in total way we adopt 606 widely used metrics for evaluation including blue, blue at 124 minutes.",
            "Ear and cider."
        ],
        [
            "Here here shows additions.",
            "The comparisons of our our with our proposed HHA approach with the with the term state of the art compared methods.",
            "All this computer methods are recent works.",
            "The first row shows the results of our proposed approach and from the comparisons we can see that our Ath approach outperformed the other other compared compared methods.",
            "This verify, which verify the effectiveness effectiveness of our approach."
        ],
        [
            "As for the operation study, we first compare the baseline setting and our three hour 3 specific streams.",
            "And, uh, is noted at the base and presenting baseline setting means that only the global feature is a global feature is used.",
            "From the from the bar graph we can see that all three streams achieve achieve better performance bonuses than the baseline and baseline setting, which shows that which shows the effectiveness of the three different vision language element information."
        ],
        [
            "And then I then comparing the comparing our HHA approach with these three with three streams, we can see that our approach further improved the performance.",
            "This index that our our approach successfully employs the complaint.",
            "Complainant artist.",
            "Among the three streams."
        ],
        [
            "And here I also show some some captioning examples and here we select.",
            "I select one of the recent work to compare SDMS published the ASM Multimeter 2017.",
            "This work proposed to the proposal to detect.",
            "Are the silent regions in frames during the during the video during video captioning?",
            "Which is similar as the region stream in our approach.",
            "And we we right away run some, uh, source code or released by the author and get the and obtained its results.",
            "And and away or I use the green and the green color.",
            "Green color shows the credit words and the red and red color index the wrong generated words."
        ],
        [
            "And here, here is another two examples and from this pharmacy comparisons a weekend say that our HSA approach obtain better, better result is because that our approach employs the multi level multi level vision language elements that it can generate accurate and meaningful sentence."
        ],
        [
            "Now I conclude conclude our work.",
            "In this work away, proposed attention guided hierarchical hierarchical alignment approach.",
            "File video captioning an 88 employees hierarchal vision language alignment and manage their complementarity to capture the semantic correspondence.",
            "Correspondence between visual content and language sentence.",
            "And it also improves multi granularity visual features to capture culture.",
            "File official information for complex video content understanding.",
            "As for the future work.",
            "Sorry for the future work of on the one hand we are going to we are going to April the interactions among different alignment information and on the other hand we we're going to employ one sort of future learning to use less training data."
        ],
        [
            "That's all, thanks for your attention."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Hello everyone, I'm glad to have the chance to introduce our work hierarchical vision language alignment for video captioning.",
                    "label": 1
                },
                {
                    "sent": "I'm gentle down from Peking University and Co.",
                    "label": 0
                },
                {
                    "sent": "Author is Professor Palm.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This work is to address the video captioning task, which aims to generate natural language sentence to describe the input.",
                    "label": 1
                },
                {
                    "sent": "Video content is are introduced.",
                    "label": 1
                },
                {
                    "sent": "Research across computer vision and natural language processing.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Oh, and its challenges are from 2 aspects.",
                    "label": 1
                },
                {
                    "sent": "The first one.",
                    "label": 0
                },
                {
                    "sent": "That it needs to fully understand the complex of video content, including recognizing objects.",
                    "label": 0
                },
                {
                    "sent": "Detect visual relations and analyzing.",
                    "label": 0
                },
                {
                    "sent": "Student ratings and so on.",
                    "label": 0
                },
                {
                    "sent": "A second idea is further to transform the video.",
                    "label": 0
                },
                {
                    "sent": "The visual content to into the language sentence.",
                    "label": 1
                },
                {
                    "sent": "I think the weird I think the key point is to seek the alignment between the visual content and language components.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is it works already includes two categories in the early stage template based language models contract mainstream.",
                    "label": 1
                },
                {
                    "sent": "These methods first predict the visual words in video and then organize them into subject.",
                    "label": 0
                },
                {
                    "sent": "Verb object topples and finally formed sentence according to the predefined language templates and rulers.",
                    "label": 1
                },
                {
                    "sent": "However, the predefined templates and rulers make the sentence of lack of diversity diversity.",
                    "label": 0
                },
                {
                    "sent": "This is the other limitation.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Nowadays, with the advances of deep learning techniques, sequence learning based methods are proposed.",
                    "label": 0
                },
                {
                    "sent": "They adopt adopt the encoder decoder framework that can train the content.",
                    "label": 1
                },
                {
                    "sent": "To end and visual attention and attributes and multimodal clothes are usually used for encoding and decoding.",
                    "label": 0
                },
                {
                    "sent": "However, how to align the visual content to language components remains to be resolved.",
                    "label": 1
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We argue that for video captioning is important to employ, the correspondences between visual elements such as the object relations or are interested regions and language components.",
                    "label": 1
                },
                {
                    "sent": "There are multi level vision language alignments.",
                    "label": 1
                },
                {
                    "sent": "The first we can see we can say that the object in the frames can be present by the individual words such as the man.",
                    "label": 0
                },
                {
                    "sent": "Tim St this is this means the object word alignment.",
                    "label": 1
                },
                {
                    "sent": "Second, the visual relations among objects can be described by by the by the phrases of the sentence, such as man, in costume, or man in street.",
                    "label": 0
                },
                {
                    "sent": "This means the relation of relation of phrase alignment.",
                    "label": 0
                },
                {
                    "sent": "Again, the third, uh, we can see that the entreated regions in frames usually come early, convert the main video content which are corresponding to the whole sentence.",
                    "label": 0
                },
                {
                    "sent": "This index, the region sentence alignment this this three.",
                    "label": 0
                },
                {
                    "sent": "A multi level.",
                    "label": 0
                },
                {
                    "sent": "This remote level visual language laments can provide acquired guidance on sentence generation.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Not in this paper are we propose an attention guide hierarchical alignment approach.",
                    "label": 0
                },
                {
                    "sent": "Our our man comes American contributions includes two aspects.",
                    "label": 0
                },
                {
                    "sent": "First, the hierarchical vision language alignments are appointed to provide the cost to find gardens on video description generation on the second multi grain granularity with visual features are employed to fully model the complex visual content.",
                    "label": 1
                },
                {
                    "sent": "Oh",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Always first introduce a.",
                    "label": 0
                },
                {
                    "sent": "So we first introduced the multi granularity visual feature extraction.",
                    "label": 1
                },
                {
                    "sent": "Oh, I'm sorry, the this is the overview.",
                    "label": 0
                },
                {
                    "sent": "Or this is the overview of our overall framework of for each, for each input video we first set of refer to it as the multi granularity visual features and then away feed them into the three parallel encoder decoder streams.",
                    "label": 0
                },
                {
                    "sent": "Include the Object stream, relation stream and androgen streams.",
                    "label": 1
                },
                {
                    "sent": "And finally we integrate these three of these three stream to obtain the final results, and 1st we introduce the multi granularity visual feature, HSL.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And in this, a step in the subway, there are total four or different.",
                    "label": 0
                },
                {
                    "sent": "Granularities of visual features are that are extracted and we take four different specific models.",
                    "label": 1
                },
                {
                    "sent": "As the feature extractor feature extractors in detail of the global, the global feature is expected for the for the whole frame by a population model.",
                    "label": 0
                },
                {
                    "sent": "Then the the region specific features are attractive for the interested regions.",
                    "label": 0
                },
                {
                    "sent": "Uh, and we use and we use Imagine captioned model to as their feature extractors.",
                    "label": 0
                },
                {
                    "sent": "Then the relation specific features are our trusted are extracted by the relation detection model and finally the objective specific features I changed by the object detection model.",
                    "label": 1
                },
                {
                    "sent": "We think that we think that these features represent the video content, video content from different skills, so we can capture cost to find our visual visual information of a video frame, which is the helpful to understand the video content and Furthermore the vision language alignment.",
                    "label": 0
                },
                {
                    "sent": "Alignment information is also implicit in these features.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now we introduce the parallel encoder decoder streams.",
                    "label": 1
                },
                {
                    "sent": "All three streams have the same same structure than each of them.",
                    "label": 1
                },
                {
                    "sent": "Discount consist of, or consist of, an attention based encoder and alignment element.",
                    "label": 0
                },
                {
                    "sent": "Embedded coder.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here is the attention based encoder for.",
                    "label": 1
                },
                {
                    "sent": "For each frame we detect multiple multiple objects relations, an interested regions.",
                    "label": 1
                },
                {
                    "sent": "So we first apply the soft attention to selected.",
                    "label": 0
                },
                {
                    "sent": "Use the useful and silent visual elements and then.",
                    "label": 0
                },
                {
                    "sent": "We always are.",
                    "label": 0
                },
                {
                    "sent": "We designed the LSTM with double memories and double states to encoding to encode the individual information.",
                    "label": 1
                },
                {
                    "sent": "Here.",
                    "label": 0
                },
                {
                    "sent": "Here is the formulas formulas for the for the double memories and double states.",
                    "label": 0
                },
                {
                    "sent": "And in this way each stream can include global information, global information, and one of the other other specific information, such as objects, relation and and region information, which makes the encoding more specific and accurate.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then there are alignment.",
                    "label": 0
                },
                {
                    "sent": "Embedded decoder is designed to to process the vision, language alignment information and generate the language sentence.",
                    "label": 1
                },
                {
                    "sent": "Here is also other formulas about about the about coder, for each.",
                    "label": 0
                },
                {
                    "sent": "For each stream, the global information serves as the surface as the constraint, a constraint of the global global contest, and for each stream way.",
                    "label": 0
                },
                {
                    "sent": "Oh, it's uh each stream.",
                    "label": 0
                },
                {
                    "sent": "Uh, and employed the object, applied one specific once with the elevation of vision, language alignment information, namely particular word alignment relation or phrase alignment, androgen sentence alignment.",
                    "label": 1
                },
                {
                    "sent": "And in such A and in such way the three elements are employed respectively to provide guidance on sentence generation.",
                    "label": 1
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And finally, three streams are integrated to employ the complete complementarity's among different version language elements information.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now the next wave of I will introduce a partments.",
                    "label": 0
                },
                {
                    "sent": "We conduct the improvements on the widely used.",
                    "label": 0
                },
                {
                    "sent": "They said MSVD and we and in total way we adopt 606 widely used metrics for evaluation including blue, blue at 124 minutes.",
                    "label": 0
                },
                {
                    "sent": "Ear and cider.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here here shows additions.",
                    "label": 0
                },
                {
                    "sent": "The comparisons of our our with our proposed HHA approach with the with the term state of the art compared methods.",
                    "label": 0
                },
                {
                    "sent": "All this computer methods are recent works.",
                    "label": 0
                },
                {
                    "sent": "The first row shows the results of our proposed approach and from the comparisons we can see that our Ath approach outperformed the other other compared compared methods.",
                    "label": 0
                },
                {
                    "sent": "This verify, which verify the effectiveness effectiveness of our approach.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As for the operation study, we first compare the baseline setting and our three hour 3 specific streams.",
                    "label": 0
                },
                {
                    "sent": "And, uh, is noted at the base and presenting baseline setting means that only the global feature is a global feature is used.",
                    "label": 0
                },
                {
                    "sent": "From the from the bar graph we can see that all three streams achieve achieve better performance bonuses than the baseline and baseline setting, which shows that which shows the effectiveness of the three different vision language element information.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then I then comparing the comparing our HHA approach with these three with three streams, we can see that our approach further improved the performance.",
                    "label": 0
                },
                {
                    "sent": "This index that our our approach successfully employs the complaint.",
                    "label": 0
                },
                {
                    "sent": "Complainant artist.",
                    "label": 0
                },
                {
                    "sent": "Among the three streams.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here I also show some some captioning examples and here we select.",
                    "label": 0
                },
                {
                    "sent": "I select one of the recent work to compare SDMS published the ASM Multimeter 2017.",
                    "label": 0
                },
                {
                    "sent": "This work proposed to the proposal to detect.",
                    "label": 0
                },
                {
                    "sent": "Are the silent regions in frames during the during the video during video captioning?",
                    "label": 0
                },
                {
                    "sent": "Which is similar as the region stream in our approach.",
                    "label": 0
                },
                {
                    "sent": "And we we right away run some, uh, source code or released by the author and get the and obtained its results.",
                    "label": 0
                },
                {
                    "sent": "And and away or I use the green and the green color.",
                    "label": 0
                },
                {
                    "sent": "Green color shows the credit words and the red and red color index the wrong generated words.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here, here is another two examples and from this pharmacy comparisons a weekend say that our HSA approach obtain better, better result is because that our approach employs the multi level multi level vision language elements that it can generate accurate and meaningful sentence.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now I conclude conclude our work.",
                    "label": 0
                },
                {
                    "sent": "In this work away, proposed attention guided hierarchical hierarchical alignment approach.",
                    "label": 1
                },
                {
                    "sent": "File video captioning an 88 employees hierarchal vision language alignment and manage their complementarity to capture the semantic correspondence.",
                    "label": 1
                },
                {
                    "sent": "Correspondence between visual content and language sentence.",
                    "label": 1
                },
                {
                    "sent": "And it also improves multi granularity visual features to capture culture.",
                    "label": 0
                },
                {
                    "sent": "File official information for complex video content understanding.",
                    "label": 1
                },
                {
                    "sent": "As for the future work.",
                    "label": 0
                },
                {
                    "sent": "Sorry for the future work of on the one hand we are going to we are going to April the interactions among different alignment information and on the other hand we we're going to employ one sort of future learning to use less training data.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's all, thanks for your attention.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": []
        }
    }
}