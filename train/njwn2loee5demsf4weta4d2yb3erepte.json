{
    "id": "njwn2loee5demsf4weta4d2yb3erepte",
    "title": "Training Restricted Boltzmann Machines using Approximations to the Likelihood Gradient",
    "info": {
        "author": [
            "Tijmen Tieleman, Department of Computer Science, University of Toronto"
        ],
        "published": "July 29, 2008",
        "recorded": "July 2008",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/icml08_tieleman_trb/",
    "segmentation": [
        [
            "So the final talk of the session will be on training restricted Boltzmann machines using approximations like gradient by attachment element.",
            "Yes, thank you.",
            "Can you guys hear me?",
            "Alright.",
            "So I am time until Amanda indeed part of the same group addresses and I'm going to talk about how to train these restricted Boltzmann machines and related models.",
            "We have seen many model strength using contrastive divergent, but there are."
        ],
        [
            "Always.",
            "So let's talk a bit about Markov random fields.",
            "MRF's, also known as undirected graphical models.",
            "With or without hidden units, these are getting somewhat popular.",
            "Boltzmann machines are an example, but there are also fully visible ones with connections between the visible units.",
            "I'm.",
            "And this can be used for for modeling the training data set that is.",
            "Unsupervised learning nothing conditional here.",
            "The other problem, which is that pretty much everything you may want to do with this, is intractable.",
            "Unless, of course, you specify a very restricted connectivity, like true connectivity or linear connectivity, but then you know then you're throwing out most of the potential of these models.",
            "If you have a fully connected model, then many things become intractable.",
            "So there are some work arounds.",
            "Number one I mentioned you have some very restrictive connectivity.",
            "Number two, there are gradients approximate us such as contrastive divergent or pseudo likelihood and some others, but these are fairly inaccurate.",
            "As Russ has shown, you using CD1 contrastive divergent with one step.",
            "You can get pretty bad models.",
            "And then another very popular work around is this one.",
            "Just do something else using a directed model or so.",
            "But that's good news.",
            "There is a solution that works a lot better than all of these."
        ],
        [
            "So let's have a look at what exactly is the issue here.",
            "It is that microphone and fields are unnormalized models.",
            "Which means that.",
            "They define a normalized probability.",
            "From which you cannot immediately see the probability because it has to be divided by the sum of these and normalized probabilities.",
            "And that is what makes so many things in these intractable.",
            "Um?",
            "The training procedure for these models for these anomalous models consists of two parts.",
            "First, we must increase the normalized probability of the training data.",
            "But second, we must reduce the probability of other states.",
            "Other configurations that do not appear in the training data on Sunday.",
            "One of the best papers by first learning when called this, what was it taking probability away from some area?",
            "And that's what we have to do here.",
            "Um?",
            "Yeah, so you have some mobile and it may have.",
            "They assign large and normalized probability to your training data, but if it assigns larger and normalized probability elsewhere, then it's still not a good model.",
            "So we must reduce that, and I'm last probability elsewhere and the reducing itself is not too difficult.",
            "But the problem is to find those areas.",
            "Ideal would be if we could draw samples from the level, but that's one of the things that's intractable in these models, so hence the difficulty.",
            "Um?",
            "To get samples, what when to get approximate samples?",
            "What one usually does is set up a Markov chain with Gibbs transition operator or some other transition operator.",
            "Initialize it at some state, perform any updates, and after a long time, say the state that we're in now is an approximate sample.",
            "Here we're going to do the unlearning.",
            "We're going to reduce a normalized probability.",
            "But that takes a lot of time if you want to do infinitely many bedsits well takes infinite time."
        ],
        [
            "Is not available.",
            "So some algorithms do this a bit more approximately, but are faster.",
            "They use sort of samples, not really samples, but it looks a bit like samples, but it's always close to the training data.",
            "So.",
            "Um?",
            "Right, I made a mistake there contrastive divergent.",
            "I mentioned and a pseudo likelihood are the best examples of these.",
            "In pseudo likelihood also firstly explained you take one.",
            "You take a training data point and change one of the values in it and then you decide that what you get that way is.",
            "You use that as a surrogate sample, and you do unlearning there.",
            "But of course it's very close to the training data.",
            "Some was contrasted vergence, especially contrastive divergent, with one step, which is the most popular approach because it's the fastest.",
            "Um?",
            "You initialize a Markov chain at some at your training data, and you do one or a few transitions and you say, OK, well, we end up now we're going to unlearning.",
            "We're going to treat this as a sample from the mobile.",
            "But it's not really a sample from the level.",
            "It's very close to the training data.",
            "And that is the problem.",
            "This balancing that has to be done for a normalized models only happens locally.",
            "This way you only do unlearning of excessive high probability areas close to the training data.",
            "And.",
            "If there's an area of high anomalous probability far from the training data, these algorithms have no control over what happens there, but they do come into play when evaluating the model.",
            "One of the things that could happen and in fact does happen.",
            "Is that?",
            "Mobile strained using CD1 contrastive divergent with one step left and found that you get enormous probability on some very weird configurations such as the configuration in which all the units are off would certainly does not appear in the training data, so that's a mistake, but because it is so unlike the training data, these local methods can never find it, so they never come around to doing the unlearning there.",
            "That is the problem here."
        ],
        [
            "So here's the same story in pictures with some training data.",
            "The red points here, and you know these local algorithms.",
            "They're going to increase the normalized probability probability on the training data as they should."
        ],
        [
            "And they're going to do unlearning in areas where there's no training data, but that are close enough to the training data to find it.",
            "That are close enough that these algorithms pseudo likelihood and contrastive divergent.",
            "Can actually get there from the training data in a short time.",
            "And then you say, OK, this looks like the kind of model we would want.",
            "But if you look a little bit far."
        ],
        [
            "No way it's not.",
            "And that's what happens here.",
            "So let's has already shown it.",
            "But you train an IBM on the MNIST digits."
        ],
        [
            "You're trying to see one and draw samples from the model.",
            "Well, this is what they look like.",
            "There must be black.",
            "That's what I meant by all units off.",
            "And that does not resemble the training data, so something was wrong here.",
            "And what went wrong is the balancing.",
            "This this, you know, black configuration did not see enough unlearning because it is simply too far from the training data to be reached by these.",
            "Surrogate sampling procedures.",
            "What we would want and what we get indeed, with the method that I'm about to present, is something more like this.",
            "You don't see the black configuration.",
            "You see things that resemble the training data as it should be."
        ],
        [
            "So the solution is the following.",
            "Gradient descent, which is used to train these models, is an iterative procedure.",
            "We initialize a model in some way with random parameters or very small random parameters usually.",
            "And then we estimate the gradient, change the parameters slightly in the direction of the gradient and estimate the gradient again on the new model, change him again, etc.",
            "And usually when we estimate the gradient first time, well we remember the gradient, but we don't remember any data that was produced in the process of estimating it.",
            "That is what is changed in the new algorithm.",
            "We're going to use some so-called static data, some persistent data.",
            "Well, as usual as in C1, for example, we set up a lack of chain and we're going to hope to get pretty good samples from it from the model, we initialize it in some random place.",
            "We design A Gibbs transition operator as it is done in C1.",
            "And then yeah, so as I said, we're going to keep this this Markov chain.",
            "We're going to really keep it close to the model distribution to the equilibrium distribution for the Markov chain.",
            "That is what we want, and it seems to be doable with this model with this algorithm.",
            "After each weight update, after we changed the model.",
            "Nickel ebrium distribution changes, obviously, so the Markov chain that had reached the equilibrium distribution before is now at the wrong distribution.",
            "So what we do is we perform a few transitions so that it has the time to catch up with the slight change in the model.",
            "Slight change in the distribution.",
            "And the hope is that after these few transitions were again very close to the mobile distribution to the equilibrium distribution for this new model.",
            "The main point is that we do not as CD1 does it or CD whatever number.",
            "We do not reset the Markov chain after every weighted dead CD it goes back to the training data each time what we do.",
            "As we make this Markov chain, a so-called static variable, it's not reset.",
            "Between gradient estimates and that's how we can stay close to the equilibrium distribution for the level that we're working with.",
            "That is the main idea here.",
            "And that's why the algorithm is called persistent CD persistent contrastive divergent.",
            "We use a persistent chain instead of resetting it all the time.",
            "So.",
            "My hope is that we always have, you know, samples from.",
            "Almost similar way better than the sample she gets using CD1."
        ],
        [
            "So there's a few more things to say.",
            "Run this if we would not change the model, then this would really be a regular Markov chain on on the constant distribution, as Markov chains are now.",
            "That's not what we do, but it's interesting to consider this.",
            "So for example, if we have an infinitesimally small learning rate, if we change the mobile infinitesimally middle each time.",
            "Then you will indeed, after the burning.",
            "That is associated with Markov chains, be sampling from the correct distribution.",
            "It's not what happens.",
            "We do change the level slightly, which means that we're always slightly behind the model distribution because it turns out this distance is not.",
            "It's not too large to prevent it from working, and certainly the distance is much smaller than what you get using CD1.",
            "This method has been known for a dinar.",
            "Thinks about 50 years in statistics.",
            "It's called stochastic approximation.",
            "And very intelligent statisticians whose work I cannot understand.",
            "Have studied carefully the conditions that are required on the learning rate and on the number of transitions performed each time.",
            "To guarantee.",
            "That you reach the optimal solution.",
            "Given of course, infinite training time.",
            "So some notes about if you want to implement this algorithm.",
            "First of all, it's real."
        ],
        [
            "Simple.",
            "And then how it works in practice?",
            "I said you do a few updates after each way to bed.",
            "Actually do only one.",
            "But you make the learning rate small so that the model does not change a lot between rate of death, so that in effect the Markov chain.",
            "Can run fast enough to keep up with the model.",
            "Also, use more than one chain I have.",
            "I usually use 100 so that way you get 100 pretty good samples instead of one.",
            "It reduces variance a bit in your gradient estimates.",
            "As I mentioned, a smaller learning rate is needed here.",
            "Smaller in particular than the same program that using a CD1.",
            "But still you can get levels that are sufficiently powerful, so.",
            "Well it well the learning rate is smaller.",
            "These gradient estimates themselves are larger, so you still learn the same amount.",
            "And also if you have a CD1 program that is very easy to convert it to a PCD program, you just write static or global in front of your negative data variable and will refrain from the setting it, that's all."
        ],
        [
            "So we've got some experiments.",
            "First of them on fully visible MRF's.",
            "And with the.",
            "No hidden unit says the name says.",
            "What we did is we took the M as digits and we took all 5 by 5 five perfect pixel patches from it.",
            "So we have a mobile with 25 visible units, no hidden units.",
            "And full connectivity.",
            "Among those 25 visible units.",
            "Because there are no hidden units in this model, the algorithm is even nicer for this model then it is for our VMS.",
            "The tractable part of the gradient where you are increasing the anomalous probability of your training data becomes very simple.",
            "For this model, all you need to do is basically get the average of the training set.",
            "Another bit of that.",
            "Into each gradient estimate.",
            "The unlearning part is still the difficult part, but that's what this algorithm source to make easier.",
            "So here's the result.",
            "I compared the pseudo likelihood training to persistent contrastive divergent, straining the new algorithm.",
            "I'm.",
            "If we look carefully at this X axis, you see that after about 13 seconds of training time, the PCD performance is better, so it doesn't have to be expensive.",
            "And also if you do training with the exact likelihood gradient, which is what which takes a lot of time but is tractable for this term model because it's only 25 visible units.",
            "Well.",
            "That's what you what you ask him talk to with persistent contrasts with the versions.",
            "If you have a lot of training time.",
            "So I took to the nine.",
            "That's 500 seconds, like 7 minutes.",
            "This had a small learning rate and you indeed what this this result that with a small learning rate it is almost exactly the gradient that you need.",
            "I also calculated the entropy of the data set, which is a bit less.",
            "This would be the best possible that can be achieved, but apparently these MRF models do not have sufficient capacity to model that.",
            "But you do see that with PhD you can get as good as you can get with exact likelihood.",
            "Trading gradient training."
        ],
        [
            "Summer experiments with our VM's.",
            "This is for a Toyota BM with 25 hidden units so that again everything is tractable.",
            "We did better density modeling.",
            "We compiled a few algorithms and well as you can see, given a fixed amount of training time, the PC works better.",
            "We also did classification with the model that was described to you by Hugo Level Shell.",
            "And, well, the picture is the same.",
            "If you have a fixed amount of training time, and especially if it is not too small.",
            "Well, persistent contrastive divergent works better."
        ],
        [
            "Amber, well as I said this way we do get samples from the model so we don't get this ugly artifacts of.",
            "Regions of the state space far far away from the training data that have too much probability.",
            "Those who got unlearned as they should be some other balancing works and these are the samples you get from an IBM trend with persistent contrastive divergent."
        ],
        [
            "Any conclusion well edge store will have a very simple algorithm.",
            "If you have a contrastive divergent implementation, you need change only two or three lines.",
            "I will well, you get a better approximation to the likelihood gradient.",
            "Much better if you have a small enough learning rate."
        ],
        [
            "And with that, we've reached the end.",
            "Any questions yes.",
            "Start from being close to the model solution, so of course it is initializing initialization problem like how you write.",
            "This is a good question.",
            "I said that we're going to always stay close to the mobile distribution to the equilibrium distribution, but the question is how do we guarantee that when we start up?",
            "Well, it's like this.",
            "The initialization of the training procedure is with small parameters, small weights.",
            "It could in fact be with zero width, so works fine.",
            "And if you have also rates, then after one transition you're at equilibrium.",
            "So that's how you start in the right place.",
            "Yes, this is.",
            "And that your total number of samples you have to see the burning time of the final model, and that in itself is intractable.",
            "So I mean, I think it's really better than just doing CD1, right?",
            "But it's true that.",
            "We do not have the final model.",
            "Indeed, get exact samples.",
            "We never get exact samples.",
            "We will get pretty close and that's why it's better.",
            "That statement is not true because your total number of samples.",
            "Let's pretend that you're doing this with the right model from day one, yes.",
            "Sample that's at least the burning for that model.",
            "You may not total number of transitions.",
            "And that is intractable.",
            "In the worst case, right?",
            "You need an exponential number of such transitions, that's true.",
            "But the fact that we can sample from these models after they've been trained?",
            "Using a Markov chain indicates that we can get somewhat close.",
            "It's true that for the worst case we cannot get close.",
            "But these models apparently are not the worst case.",
            "Yes.",
            "Modes.",
            "Posterior distribution be learning in the final model.",
            "There are indeed, for example, when you train on the Ms digits, supposedly there are about 10 modes, one for each digit.",
            "And as Russ explained before, that's why many methods that approximate the model with a tree do not work.",
            "So yes it did.",
            "It is a fairly multimodal distribution, except of course when you train with the wrong algorithm and there's only one mode which I showed you, which is the black one.",
            "Is that the answer?",
            "Why you run with multiple trains?",
            "And I'm just wondering how you ensure that the Chinese.",
            "Occupy and after the model for me this is always a possibility, but there's a big amount of sitting somewhere off in some of these parts of space.",
            "There is of course, but.",
            "The thing with Marcus changes that if you perform enough transitions on them, they will reach any part of the space.",
            "Of course, you need enough transition.",
            "Low.",
            "The problem here is that in general there's more than 100 most.",
            "It's not one big mode, it's too many months.",
            "Each digit has multiple modes and you only have 100 change.",
            "We guys are talking about different things I guess.",
            "Alright, OK so see that there are more than 100 modes.",
            "Indeed.",
            "If you have only 100 Markov chains, they cannot be occupying all of them at the same time.",
            "So what happens in practice is that they jump around a little and they keep moving fairly rapidly.",
            "Amazon.",
            "You don't have to cover all of the modes at the same time.",
            "What is important is that some unlearning some reduction of anomalous probability occurs in all modes, but it doesn't have to be at the same time because you are using.",
            "Gradient optimization.",
            "If you do a reduction in one mode at time T is 100 and they would later attempt is 110.",
            "You do some other modes.",
            "Well, it's still approximately the same level.",
            "So if an area can cover all modes, though not necessarily at the same time, you can keep this model balanced, and that's what I've used.",
            "Extremely limited, and that's not going to happen.",
            "Then.",
            "I'm gonna sample that you.",
            "Sounds great.",
            "Yeah, right.",
            "So it's true that.",
            "These models.",
            "In the end, I get fairly slowly mixing Markov chains.",
            "Um?",
            "With in some way.",
            "This this algorithm, it seems to to actually have better mixing then what you get if you work on the final model because the samples that I showed you.",
            "Let's go back to that.",
            "Well, like nice.",
            "Level up 10 for the Markov chain with 500,000 transitions between each image to get mixing.",
            "That's longer than the training time that I took, so something funny is going on here.",
            "Right, you starting with the new model.",
            "That's that's actually makes it easy to transition that you know in the beginning the modes through the most, so it's easier to mix in the beginning, it's.",
            "But in the beginning, it is indeed a simple model.",
            "So well, let me control by saying that we're not entirely sure.",
            "How come all modes are visited, but that is one of the things that we're working on and put that thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the final talk of the session will be on training restricted Boltzmann machines using approximations like gradient by attachment element.",
                    "label": 1
                },
                {
                    "sent": "Yes, thank you.",
                    "label": 0
                },
                {
                    "sent": "Can you guys hear me?",
                    "label": 0
                },
                {
                    "sent": "Alright.",
                    "label": 0
                },
                {
                    "sent": "So I am time until Amanda indeed part of the same group addresses and I'm going to talk about how to train these restricted Boltzmann machines and related models.",
                    "label": 0
                },
                {
                    "sent": "We have seen many model strength using contrastive divergent, but there are.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Always.",
                    "label": 0
                },
                {
                    "sent": "So let's talk a bit about Markov random fields.",
                    "label": 1
                },
                {
                    "sent": "MRF's, also known as undirected graphical models.",
                    "label": 0
                },
                {
                    "sent": "With or without hidden units, these are getting somewhat popular.",
                    "label": 0
                },
                {
                    "sent": "Boltzmann machines are an example, but there are also fully visible ones with connections between the visible units.",
                    "label": 0
                },
                {
                    "sent": "I'm.",
                    "label": 0
                },
                {
                    "sent": "And this can be used for for modeling the training data set that is.",
                    "label": 0
                },
                {
                    "sent": "Unsupervised learning nothing conditional here.",
                    "label": 0
                },
                {
                    "sent": "The other problem, which is that pretty much everything you may want to do with this, is intractable.",
                    "label": 0
                },
                {
                    "sent": "Unless, of course, you specify a very restricted connectivity, like true connectivity or linear connectivity, but then you know then you're throwing out most of the potential of these models.",
                    "label": 0
                },
                {
                    "sent": "If you have a fully connected model, then many things become intractable.",
                    "label": 0
                },
                {
                    "sent": "So there are some work arounds.",
                    "label": 0
                },
                {
                    "sent": "Number one I mentioned you have some very restrictive connectivity.",
                    "label": 0
                },
                {
                    "sent": "Number two, there are gradients approximate us such as contrastive divergent or pseudo likelihood and some others, but these are fairly inaccurate.",
                    "label": 0
                },
                {
                    "sent": "As Russ has shown, you using CD1 contrastive divergent with one step.",
                    "label": 0
                },
                {
                    "sent": "You can get pretty bad models.",
                    "label": 0
                },
                {
                    "sent": "And then another very popular work around is this one.",
                    "label": 0
                },
                {
                    "sent": "Just do something else using a directed model or so.",
                    "label": 0
                },
                {
                    "sent": "But that's good news.",
                    "label": 1
                },
                {
                    "sent": "There is a solution that works a lot better than all of these.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's have a look at what exactly is the issue here.",
                    "label": 0
                },
                {
                    "sent": "It is that microphone and fields are unnormalized models.",
                    "label": 1
                },
                {
                    "sent": "Which means that.",
                    "label": 0
                },
                {
                    "sent": "They define a normalized probability.",
                    "label": 0
                },
                {
                    "sent": "From which you cannot immediately see the probability because it has to be divided by the sum of these and normalized probabilities.",
                    "label": 0
                },
                {
                    "sent": "And that is what makes so many things in these intractable.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "The training procedure for these models for these anomalous models consists of two parts.",
                    "label": 1
                },
                {
                    "sent": "First, we must increase the normalized probability of the training data.",
                    "label": 0
                },
                {
                    "sent": "But second, we must reduce the probability of other states.",
                    "label": 0
                },
                {
                    "sent": "Other configurations that do not appear in the training data on Sunday.",
                    "label": 0
                },
                {
                    "sent": "One of the best papers by first learning when called this, what was it taking probability away from some area?",
                    "label": 0
                },
                {
                    "sent": "And that's what we have to do here.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Yeah, so you have some mobile and it may have.",
                    "label": 0
                },
                {
                    "sent": "They assign large and normalized probability to your training data, but if it assigns larger and normalized probability elsewhere, then it's still not a good model.",
                    "label": 0
                },
                {
                    "sent": "So we must reduce that, and I'm last probability elsewhere and the reducing itself is not too difficult.",
                    "label": 0
                },
                {
                    "sent": "But the problem is to find those areas.",
                    "label": 1
                },
                {
                    "sent": "Ideal would be if we could draw samples from the level, but that's one of the things that's intractable in these models, so hence the difficulty.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "To get samples, what when to get approximate samples?",
                    "label": 0
                },
                {
                    "sent": "What one usually does is set up a Markov chain with Gibbs transition operator or some other transition operator.",
                    "label": 0
                },
                {
                    "sent": "Initialize it at some state, perform any updates, and after a long time, say the state that we're in now is an approximate sample.",
                    "label": 0
                },
                {
                    "sent": "Here we're going to do the unlearning.",
                    "label": 1
                },
                {
                    "sent": "We're going to reduce a normalized probability.",
                    "label": 0
                },
                {
                    "sent": "But that takes a lot of time if you want to do infinitely many bedsits well takes infinite time.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is not available.",
                    "label": 0
                },
                {
                    "sent": "So some algorithms do this a bit more approximately, but are faster.",
                    "label": 0
                },
                {
                    "sent": "They use sort of samples, not really samples, but it looks a bit like samples, but it's always close to the training data.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Right, I made a mistake there contrastive divergent.",
                    "label": 0
                },
                {
                    "sent": "I mentioned and a pseudo likelihood are the best examples of these.",
                    "label": 0
                },
                {
                    "sent": "In pseudo likelihood also firstly explained you take one.",
                    "label": 0
                },
                {
                    "sent": "You take a training data point and change one of the values in it and then you decide that what you get that way is.",
                    "label": 0
                },
                {
                    "sent": "You use that as a surrogate sample, and you do unlearning there.",
                    "label": 0
                },
                {
                    "sent": "But of course it's very close to the training data.",
                    "label": 0
                },
                {
                    "sent": "Some was contrasted vergence, especially contrastive divergent, with one step, which is the most popular approach because it's the fastest.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "You initialize a Markov chain at some at your training data, and you do one or a few transitions and you say, OK, well, we end up now we're going to unlearning.",
                    "label": 0
                },
                {
                    "sent": "We're going to treat this as a sample from the mobile.",
                    "label": 0
                },
                {
                    "sent": "But it's not really a sample from the level.",
                    "label": 0
                },
                {
                    "sent": "It's very close to the training data.",
                    "label": 1
                },
                {
                    "sent": "And that is the problem.",
                    "label": 0
                },
                {
                    "sent": "This balancing that has to be done for a normalized models only happens locally.",
                    "label": 0
                },
                {
                    "sent": "This way you only do unlearning of excessive high probability areas close to the training data.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 1
                },
                {
                    "sent": "If there's an area of high anomalous probability far from the training data, these algorithms have no control over what happens there, but they do come into play when evaluating the model.",
                    "label": 0
                },
                {
                    "sent": "One of the things that could happen and in fact does happen.",
                    "label": 0
                },
                {
                    "sent": "Is that?",
                    "label": 0
                },
                {
                    "sent": "Mobile strained using CD1 contrastive divergent with one step left and found that you get enormous probability on some very weird configurations such as the configuration in which all the units are off would certainly does not appear in the training data, so that's a mistake, but because it is so unlike the training data, these local methods can never find it, so they never come around to doing the unlearning there.",
                    "label": 0
                },
                {
                    "sent": "That is the problem here.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's the same story in pictures with some training data.",
                    "label": 0
                },
                {
                    "sent": "The red points here, and you know these local algorithms.",
                    "label": 0
                },
                {
                    "sent": "They're going to increase the normalized probability probability on the training data as they should.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And they're going to do unlearning in areas where there's no training data, but that are close enough to the training data to find it.",
                    "label": 0
                },
                {
                    "sent": "That are close enough that these algorithms pseudo likelihood and contrastive divergent.",
                    "label": 0
                },
                {
                    "sent": "Can actually get there from the training data in a short time.",
                    "label": 0
                },
                {
                    "sent": "And then you say, OK, this looks like the kind of model we would want.",
                    "label": 0
                },
                {
                    "sent": "But if you look a little bit far.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "No way it's not.",
                    "label": 0
                },
                {
                    "sent": "And that's what happens here.",
                    "label": 0
                },
                {
                    "sent": "So let's has already shown it.",
                    "label": 0
                },
                {
                    "sent": "But you train an IBM on the MNIST digits.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You're trying to see one and draw samples from the model.",
                    "label": 1
                },
                {
                    "sent": "Well, this is what they look like.",
                    "label": 0
                },
                {
                    "sent": "There must be black.",
                    "label": 0
                },
                {
                    "sent": "That's what I meant by all units off.",
                    "label": 0
                },
                {
                    "sent": "And that does not resemble the training data, so something was wrong here.",
                    "label": 0
                },
                {
                    "sent": "And what went wrong is the balancing.",
                    "label": 0
                },
                {
                    "sent": "This this, you know, black configuration did not see enough unlearning because it is simply too far from the training data to be reached by these.",
                    "label": 0
                },
                {
                    "sent": "Surrogate sampling procedures.",
                    "label": 0
                },
                {
                    "sent": "What we would want and what we get indeed, with the method that I'm about to present, is something more like this.",
                    "label": 0
                },
                {
                    "sent": "You don't see the black configuration.",
                    "label": 0
                },
                {
                    "sent": "You see things that resemble the training data as it should be.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the solution is the following.",
                    "label": 0
                },
                {
                    "sent": "Gradient descent, which is used to train these models, is an iterative procedure.",
                    "label": 0
                },
                {
                    "sent": "We initialize a model in some way with random parameters or very small random parameters usually.",
                    "label": 0
                },
                {
                    "sent": "And then we estimate the gradient, change the parameters slightly in the direction of the gradient and estimate the gradient again on the new model, change him again, etc.",
                    "label": 0
                },
                {
                    "sent": "And usually when we estimate the gradient first time, well we remember the gradient, but we don't remember any data that was produced in the process of estimating it.",
                    "label": 0
                },
                {
                    "sent": "That is what is changed in the new algorithm.",
                    "label": 0
                },
                {
                    "sent": "We're going to use some so-called static data, some persistent data.",
                    "label": 0
                },
                {
                    "sent": "Well, as usual as in C1, for example, we set up a lack of chain and we're going to hope to get pretty good samples from it from the model, we initialize it in some random place.",
                    "label": 0
                },
                {
                    "sent": "We design A Gibbs transition operator as it is done in C1.",
                    "label": 0
                },
                {
                    "sent": "And then yeah, so as I said, we're going to keep this this Markov chain.",
                    "label": 0
                },
                {
                    "sent": "We're going to really keep it close to the model distribution to the equilibrium distribution for the Markov chain.",
                    "label": 1
                },
                {
                    "sent": "That is what we want, and it seems to be doable with this model with this algorithm.",
                    "label": 0
                },
                {
                    "sent": "After each weight update, after we changed the model.",
                    "label": 1
                },
                {
                    "sent": "Nickel ebrium distribution changes, obviously, so the Markov chain that had reached the equilibrium distribution before is now at the wrong distribution.",
                    "label": 0
                },
                {
                    "sent": "So what we do is we perform a few transitions so that it has the time to catch up with the slight change in the model.",
                    "label": 0
                },
                {
                    "sent": "Slight change in the distribution.",
                    "label": 0
                },
                {
                    "sent": "And the hope is that after these few transitions were again very close to the mobile distribution to the equilibrium distribution for this new model.",
                    "label": 0
                },
                {
                    "sent": "The main point is that we do not as CD1 does it or CD whatever number.",
                    "label": 0
                },
                {
                    "sent": "We do not reset the Markov chain after every weighted dead CD it goes back to the training data each time what we do.",
                    "label": 1
                },
                {
                    "sent": "As we make this Markov chain, a so-called static variable, it's not reset.",
                    "label": 0
                },
                {
                    "sent": "Between gradient estimates and that's how we can stay close to the equilibrium distribution for the level that we're working with.",
                    "label": 0
                },
                {
                    "sent": "That is the main idea here.",
                    "label": 0
                },
                {
                    "sent": "And that's why the algorithm is called persistent CD persistent contrastive divergent.",
                    "label": 0
                },
                {
                    "sent": "We use a persistent chain instead of resetting it all the time.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "My hope is that we always have, you know, samples from.",
                    "label": 0
                },
                {
                    "sent": "Almost similar way better than the sample she gets using CD1.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So there's a few more things to say.",
                    "label": 0
                },
                {
                    "sent": "Run this if we would not change the model, then this would really be a regular Markov chain on on the constant distribution, as Markov chains are now.",
                    "label": 1
                },
                {
                    "sent": "That's not what we do, but it's interesting to consider this.",
                    "label": 0
                },
                {
                    "sent": "So for example, if we have an infinitesimally small learning rate, if we change the mobile infinitesimally middle each time.",
                    "label": 0
                },
                {
                    "sent": "Then you will indeed, after the burning.",
                    "label": 0
                },
                {
                    "sent": "That is associated with Markov chains, be sampling from the correct distribution.",
                    "label": 0
                },
                {
                    "sent": "It's not what happens.",
                    "label": 0
                },
                {
                    "sent": "We do change the level slightly, which means that we're always slightly behind the model distribution because it turns out this distance is not.",
                    "label": 0
                },
                {
                    "sent": "It's not too large to prevent it from working, and certainly the distance is much smaller than what you get using CD1.",
                    "label": 0
                },
                {
                    "sent": "This method has been known for a dinar.",
                    "label": 0
                },
                {
                    "sent": "Thinks about 50 years in statistics.",
                    "label": 0
                },
                {
                    "sent": "It's called stochastic approximation.",
                    "label": 0
                },
                {
                    "sent": "And very intelligent statisticians whose work I cannot understand.",
                    "label": 0
                },
                {
                    "sent": "Have studied carefully the conditions that are required on the learning rate and on the number of transitions performed each time.",
                    "label": 0
                },
                {
                    "sent": "To guarantee.",
                    "label": 0
                },
                {
                    "sent": "That you reach the optimal solution.",
                    "label": 0
                },
                {
                    "sent": "Given of course, infinite training time.",
                    "label": 0
                },
                {
                    "sent": "So some notes about if you want to implement this algorithm.",
                    "label": 0
                },
                {
                    "sent": "First of all, it's real.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Simple.",
                    "label": 0
                },
                {
                    "sent": "And then how it works in practice?",
                    "label": 1
                },
                {
                    "sent": "I said you do a few updates after each way to bed.",
                    "label": 0
                },
                {
                    "sent": "Actually do only one.",
                    "label": 0
                },
                {
                    "sent": "But you make the learning rate small so that the model does not change a lot between rate of death, so that in effect the Markov chain.",
                    "label": 0
                },
                {
                    "sent": "Can run fast enough to keep up with the model.",
                    "label": 0
                },
                {
                    "sent": "Also, use more than one chain I have.",
                    "label": 0
                },
                {
                    "sent": "I usually use 100 so that way you get 100 pretty good samples instead of one.",
                    "label": 0
                },
                {
                    "sent": "It reduces variance a bit in your gradient estimates.",
                    "label": 0
                },
                {
                    "sent": "As I mentioned, a smaller learning rate is needed here.",
                    "label": 1
                },
                {
                    "sent": "Smaller in particular than the same program that using a CD1.",
                    "label": 0
                },
                {
                    "sent": "But still you can get levels that are sufficiently powerful, so.",
                    "label": 0
                },
                {
                    "sent": "Well it well the learning rate is smaller.",
                    "label": 0
                },
                {
                    "sent": "These gradient estimates themselves are larger, so you still learn the same amount.",
                    "label": 0
                },
                {
                    "sent": "And also if you have a CD1 program that is very easy to convert it to a PCD program, you just write static or global in front of your negative data variable and will refrain from the setting it, that's all.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we've got some experiments.",
                    "label": 0
                },
                {
                    "sent": "First of them on fully visible MRF's.",
                    "label": 1
                },
                {
                    "sent": "And with the.",
                    "label": 0
                },
                {
                    "sent": "No hidden unit says the name says.",
                    "label": 0
                },
                {
                    "sent": "What we did is we took the M as digits and we took all 5 by 5 five perfect pixel patches from it.",
                    "label": 0
                },
                {
                    "sent": "So we have a mobile with 25 visible units, no hidden units.",
                    "label": 0
                },
                {
                    "sent": "And full connectivity.",
                    "label": 0
                },
                {
                    "sent": "Among those 25 visible units.",
                    "label": 0
                },
                {
                    "sent": "Because there are no hidden units in this model, the algorithm is even nicer for this model then it is for our VMS.",
                    "label": 0
                },
                {
                    "sent": "The tractable part of the gradient where you are increasing the anomalous probability of your training data becomes very simple.",
                    "label": 0
                },
                {
                    "sent": "For this model, all you need to do is basically get the average of the training set.",
                    "label": 0
                },
                {
                    "sent": "Another bit of that.",
                    "label": 0
                },
                {
                    "sent": "Into each gradient estimate.",
                    "label": 0
                },
                {
                    "sent": "The unlearning part is still the difficult part, but that's what this algorithm source to make easier.",
                    "label": 0
                },
                {
                    "sent": "So here's the result.",
                    "label": 0
                },
                {
                    "sent": "I compared the pseudo likelihood training to persistent contrastive divergent, straining the new algorithm.",
                    "label": 0
                },
                {
                    "sent": "I'm.",
                    "label": 0
                },
                {
                    "sent": "If we look carefully at this X axis, you see that after about 13 seconds of training time, the PCD performance is better, so it doesn't have to be expensive.",
                    "label": 0
                },
                {
                    "sent": "And also if you do training with the exact likelihood gradient, which is what which takes a lot of time but is tractable for this term model because it's only 25 visible units.",
                    "label": 0
                },
                {
                    "sent": "Well.",
                    "label": 0
                },
                {
                    "sent": "That's what you what you ask him talk to with persistent contrasts with the versions.",
                    "label": 0
                },
                {
                    "sent": "If you have a lot of training time.",
                    "label": 0
                },
                {
                    "sent": "So I took to the nine.",
                    "label": 0
                },
                {
                    "sent": "That's 500 seconds, like 7 minutes.",
                    "label": 0
                },
                {
                    "sent": "This had a small learning rate and you indeed what this this result that with a small learning rate it is almost exactly the gradient that you need.",
                    "label": 0
                },
                {
                    "sent": "I also calculated the entropy of the data set, which is a bit less.",
                    "label": 0
                },
                {
                    "sent": "This would be the best possible that can be achieved, but apparently these MRF models do not have sufficient capacity to model that.",
                    "label": 0
                },
                {
                    "sent": "But you do see that with PhD you can get as good as you can get with exact likelihood.",
                    "label": 0
                },
                {
                    "sent": "Trading gradient training.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Summer experiments with our VM's.",
                    "label": 0
                },
                {
                    "sent": "This is for a Toyota BM with 25 hidden units so that again everything is tractable.",
                    "label": 0
                },
                {
                    "sent": "We did better density modeling.",
                    "label": 1
                },
                {
                    "sent": "We compiled a few algorithms and well as you can see, given a fixed amount of training time, the PC works better.",
                    "label": 0
                },
                {
                    "sent": "We also did classification with the model that was described to you by Hugo Level Shell.",
                    "label": 0
                },
                {
                    "sent": "And, well, the picture is the same.",
                    "label": 0
                },
                {
                    "sent": "If you have a fixed amount of training time, and especially if it is not too small.",
                    "label": 0
                },
                {
                    "sent": "Well, persistent contrastive divergent works better.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Amber, well as I said this way we do get samples from the model so we don't get this ugly artifacts of.",
                    "label": 0
                },
                {
                    "sent": "Regions of the state space far far away from the training data that have too much probability.",
                    "label": 0
                },
                {
                    "sent": "Those who got unlearned as they should be some other balancing works and these are the samples you get from an IBM trend with persistent contrastive divergent.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Any conclusion well edge store will have a very simple algorithm.",
                    "label": 1
                },
                {
                    "sent": "If you have a contrastive divergent implementation, you need change only two or three lines.",
                    "label": 0
                },
                {
                    "sent": "I will well, you get a better approximation to the likelihood gradient.",
                    "label": 1
                },
                {
                    "sent": "Much better if you have a small enough learning rate.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And with that, we've reached the end.",
                    "label": 0
                },
                {
                    "sent": "Any questions yes.",
                    "label": 0
                },
                {
                    "sent": "Start from being close to the model solution, so of course it is initializing initialization problem like how you write.",
                    "label": 0
                },
                {
                    "sent": "This is a good question.",
                    "label": 0
                },
                {
                    "sent": "I said that we're going to always stay close to the mobile distribution to the equilibrium distribution, but the question is how do we guarantee that when we start up?",
                    "label": 0
                },
                {
                    "sent": "Well, it's like this.",
                    "label": 0
                },
                {
                    "sent": "The initialization of the training procedure is with small parameters, small weights.",
                    "label": 0
                },
                {
                    "sent": "It could in fact be with zero width, so works fine.",
                    "label": 0
                },
                {
                    "sent": "And if you have also rates, then after one transition you're at equilibrium.",
                    "label": 0
                },
                {
                    "sent": "So that's how you start in the right place.",
                    "label": 0
                },
                {
                    "sent": "Yes, this is.",
                    "label": 0
                },
                {
                    "sent": "And that your total number of samples you have to see the burning time of the final model, and that in itself is intractable.",
                    "label": 0
                },
                {
                    "sent": "So I mean, I think it's really better than just doing CD1, right?",
                    "label": 0
                },
                {
                    "sent": "But it's true that.",
                    "label": 0
                },
                {
                    "sent": "We do not have the final model.",
                    "label": 0
                },
                {
                    "sent": "Indeed, get exact samples.",
                    "label": 0
                },
                {
                    "sent": "We never get exact samples.",
                    "label": 0
                },
                {
                    "sent": "We will get pretty close and that's why it's better.",
                    "label": 0
                },
                {
                    "sent": "That statement is not true because your total number of samples.",
                    "label": 0
                },
                {
                    "sent": "Let's pretend that you're doing this with the right model from day one, yes.",
                    "label": 0
                },
                {
                    "sent": "Sample that's at least the burning for that model.",
                    "label": 0
                },
                {
                    "sent": "You may not total number of transitions.",
                    "label": 0
                },
                {
                    "sent": "And that is intractable.",
                    "label": 0
                },
                {
                    "sent": "In the worst case, right?",
                    "label": 0
                },
                {
                    "sent": "You need an exponential number of such transitions, that's true.",
                    "label": 0
                },
                {
                    "sent": "But the fact that we can sample from these models after they've been trained?",
                    "label": 0
                },
                {
                    "sent": "Using a Markov chain indicates that we can get somewhat close.",
                    "label": 0
                },
                {
                    "sent": "It's true that for the worst case we cannot get close.",
                    "label": 0
                },
                {
                    "sent": "But these models apparently are not the worst case.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Modes.",
                    "label": 0
                },
                {
                    "sent": "Posterior distribution be learning in the final model.",
                    "label": 0
                },
                {
                    "sent": "There are indeed, for example, when you train on the Ms digits, supposedly there are about 10 modes, one for each digit.",
                    "label": 0
                },
                {
                    "sent": "And as Russ explained before, that's why many methods that approximate the model with a tree do not work.",
                    "label": 0
                },
                {
                    "sent": "So yes it did.",
                    "label": 0
                },
                {
                    "sent": "It is a fairly multimodal distribution, except of course when you train with the wrong algorithm and there's only one mode which I showed you, which is the black one.",
                    "label": 0
                },
                {
                    "sent": "Is that the answer?",
                    "label": 0
                },
                {
                    "sent": "Why you run with multiple trains?",
                    "label": 0
                },
                {
                    "sent": "And I'm just wondering how you ensure that the Chinese.",
                    "label": 0
                },
                {
                    "sent": "Occupy and after the model for me this is always a possibility, but there's a big amount of sitting somewhere off in some of these parts of space.",
                    "label": 0
                },
                {
                    "sent": "There is of course, but.",
                    "label": 0
                },
                {
                    "sent": "The thing with Marcus changes that if you perform enough transitions on them, they will reach any part of the space.",
                    "label": 0
                },
                {
                    "sent": "Of course, you need enough transition.",
                    "label": 0
                },
                {
                    "sent": "Low.",
                    "label": 0
                },
                {
                    "sent": "The problem here is that in general there's more than 100 most.",
                    "label": 0
                },
                {
                    "sent": "It's not one big mode, it's too many months.",
                    "label": 0
                },
                {
                    "sent": "Each digit has multiple modes and you only have 100 change.",
                    "label": 0
                },
                {
                    "sent": "We guys are talking about different things I guess.",
                    "label": 0
                },
                {
                    "sent": "Alright, OK so see that there are more than 100 modes.",
                    "label": 0
                },
                {
                    "sent": "Indeed.",
                    "label": 0
                },
                {
                    "sent": "If you have only 100 Markov chains, they cannot be occupying all of them at the same time.",
                    "label": 0
                },
                {
                    "sent": "So what happens in practice is that they jump around a little and they keep moving fairly rapidly.",
                    "label": 0
                },
                {
                    "sent": "Amazon.",
                    "label": 0
                },
                {
                    "sent": "You don't have to cover all of the modes at the same time.",
                    "label": 0
                },
                {
                    "sent": "What is important is that some unlearning some reduction of anomalous probability occurs in all modes, but it doesn't have to be at the same time because you are using.",
                    "label": 0
                },
                {
                    "sent": "Gradient optimization.",
                    "label": 0
                },
                {
                    "sent": "If you do a reduction in one mode at time T is 100 and they would later attempt is 110.",
                    "label": 0
                },
                {
                    "sent": "You do some other modes.",
                    "label": 0
                },
                {
                    "sent": "Well, it's still approximately the same level.",
                    "label": 0
                },
                {
                    "sent": "So if an area can cover all modes, though not necessarily at the same time, you can keep this model balanced, and that's what I've used.",
                    "label": 0
                },
                {
                    "sent": "Extremely limited, and that's not going to happen.",
                    "label": 0
                },
                {
                    "sent": "Then.",
                    "label": 0
                },
                {
                    "sent": "I'm gonna sample that you.",
                    "label": 0
                },
                {
                    "sent": "Sounds great.",
                    "label": 0
                },
                {
                    "sent": "Yeah, right.",
                    "label": 0
                },
                {
                    "sent": "So it's true that.",
                    "label": 0
                },
                {
                    "sent": "These models.",
                    "label": 0
                },
                {
                    "sent": "In the end, I get fairly slowly mixing Markov chains.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "With in some way.",
                    "label": 0
                },
                {
                    "sent": "This this algorithm, it seems to to actually have better mixing then what you get if you work on the final model because the samples that I showed you.",
                    "label": 0
                },
                {
                    "sent": "Let's go back to that.",
                    "label": 0
                },
                {
                    "sent": "Well, like nice.",
                    "label": 0
                },
                {
                    "sent": "Level up 10 for the Markov chain with 500,000 transitions between each image to get mixing.",
                    "label": 0
                },
                {
                    "sent": "That's longer than the training time that I took, so something funny is going on here.",
                    "label": 0
                },
                {
                    "sent": "Right, you starting with the new model.",
                    "label": 0
                },
                {
                    "sent": "That's that's actually makes it easy to transition that you know in the beginning the modes through the most, so it's easier to mix in the beginning, it's.",
                    "label": 0
                },
                {
                    "sent": "But in the beginning, it is indeed a simple model.",
                    "label": 0
                },
                {
                    "sent": "So well, let me control by saying that we're not entirely sure.",
                    "label": 0
                },
                {
                    "sent": "How come all modes are visited, but that is one of the things that we're working on and put that thank you.",
                    "label": 0
                }
            ]
        }
    }
}