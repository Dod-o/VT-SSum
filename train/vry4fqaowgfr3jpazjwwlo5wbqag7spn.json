{
    "id": "vry4fqaowgfr3jpazjwwlo5wbqag7spn",
    "title": "A formal analysis of stability - lessons and open questions",
    "info": {
        "author": [
            "Shai Ben-David, University of Waterloo"
        ],
        "published": "July 28, 2007",
        "recorded": "July 2007",
        "category": [
            "Top->Computer Science->Machine Learning->Clustering"
        ]
    },
    "url": "http://videolectures.net/srmc07_ben_david_fas/",
    "segmentation": [
        [
            "OK, so I'll talk about the formal analysis of stability and then.",
            "Yeah, I I'm, I'll try.",
            "I don't know what exactly is the background of everybody, so I'm assuming.",
            "Very little background and let me know if everything is clear and I bought you or if you have objections and so on."
        ],
        [
            "OK, so.",
            "But I think that the big question that we have to ask and it goes back to the morning I what is a good clustering?",
            "And that's really the big question that we have to ask and they don't know where the call is.",
            "Not here but.",
            "He raised this problem that yeah, what's that's the essential problem.",
            "So there are many different ways to cluster the same data set.",
            "So is this the correct clustering of this data set or?"
        ],
        [
            "Clustering or is this a good clustering of this data set?",
            "How do we define the quality of a given clustering and I?"
        ],
        [
            "We can't avoid this question.",
            "And they are even here.",
            "Which of these two is better?",
            "Clustering of these sets so, and you can say that you know people from saying from Eric's point of view you don't want to cross a.",
            "High density areas, but you can just think of the same picture with these two stabs closer together and you will have high density here and still you will prefer this petition over this petition for some reasons.",
            "So what measures do we have to decide what is a good a good clustering?"
        ],
        [
            "And then.",
            "What is 1 immediate answer that comes to mind is say that's what we have.",
            "An objective function is full.",
            "So if my objective function is K means clustering, then I can calculate my camins cost and I'll decide what's a good clustering.",
            "But note that even if we fix our objective function so we see that we decided what we care about is.",
            "Anne.",
            "Vector quantization, so it's the average square distance of your code words to your input.",
            "I give you a concrete clustering so we get a data set.",
            "You run your 5 means clustering algorithm and get the clustering.",
            "You compute the 5 min costs and your outcome is .7.",
            "Now I ask you, is this a good clustering or not?",
            "And it tells you nothing.",
            ".7.",
            "Becausw, what do you compare it to?",
            "I mean, even if we have an objective function and we really it really reflects our interest, it doesn't yet give us an answer to how good is my clustering.",
            "Maybe this point 7 is very bad because my points are compactly located, then any partitioning will get me something like .7.",
            "You already don't agree with me already, OK?",
            "For better presentation, for example, in many times there is a concrete implementation of.",
            "What is this open setting which is open 7 so OK, but I'm asking the question of not.",
            "No, I ask you.",
            "Is this a good clustering so?",
            "You can decide that if I if.",
            "Somewhere to move into me.",
            "Some supplies is open.",
            "7 Penn State.",
            "So how much money I'm going to know.",
            "Know if I it's OK so maybe I chose an example that on which you can easily attack.",
            "But I I'm advising to Bell Canada and they want to do a target marketing for customers and they give me a data set of all the customers and output a clustering and ask me is this a good clustering?",
            "Is does this reflect will structure in my collection of customers and the fact that I have .7 doesn't tell me if this reflects real structure of my customers.",
            "Maybe every partitioning will get me .7 or less?",
            "I don't know.",
            "Something which you basically could calculate, but you know your your objective, your objective not only gives you the the global or local minimum, but it also gives you all the ranking of all the other clusters.",
            "How?",
            "How do you does it?",
            "Give me a ranking of other clustering?",
            "Define a different partition.",
            "OK, so you here.",
            "And then comes out OK, OK, OK, so I hear I got my my .7.",
            "Then I follow your dreams advice and I take my clustering and divide my customers according to the 1st letter of the family name of the last name and I get a score 1.3 so I know that my clustering is better than dividing by your first letter of your last name.",
            "But that's not very promising news.",
            "For well.",
            "I mean, that's not.",
            "That doesn't tell them that the structure that I found is real structure.",
            "The fact that they can beat some silly arbitrary partitionings doesn't tell him that what I have in my hand is a good clustering.",
            "What what are you assuming?",
            "If you have a cost function objective, right?",
            "Any partitioning this objective?",
            "I know, yes, yes, that's right.",
            "Ocean of objective values.",
            "You know what?",
            "Open seven?",
            "No, I don't know because I don't know all the other positions.",
            "If you gave me a list of all possible partitioning an in those list, I could see where my .7 seats then I'll know.",
            "But I don't have such a list.",
            "There are exponentially many different partitionings I worked hard and came up with one clustering and now I want to know is it good or bad.",
            "Now I can generate another 10 clustering and all will be worse than this one.",
            "Does it tell me that I'm close to optimum?",
            "Doesn't tell me.",
            "That's important because Mexico.",
            "You know this became subjective, and if you're consulting for Bell Canada, then the Caymans objective is not really the true objective that they want to optimize.",
            "OK, so something they really object, the real objective that they care about is that they want their partitioning will be similar to the true way in which the true partitioning of users.",
            "The problem is that this position is an observable, right?",
            "Instead of using it.",
            "Actually has the Kings objective, which maybe you can prove it has some relationship to this other objective, but it is not.",
            "This other objective is OK, OK?",
            "Is not what you care about, but sometimes that aims objective is exactly the correct thing.",
            "Well, I'm trying to say is a different point when I'm trying to make a different point that even if I knew that the K means objectively correct, objective and number tells me nothing unless I can see how it stands with respect to all other costs of other partitions.",
            "Yeah.",
            "Trying to solve some reconciliation, trying to locate utilities.",
            "Then the King Introductive is the correct objectives and then that's all I care about.",
            "If that's no, it's good.",
            "But what is low and high?",
            "What is?",
            "Well, low and high is not effective.",
            "If I give you this petition, and then you realize the next day and the next year after you invested $1,000,000 based on this that another petition would give you value .1 and you could have saved $1,000,000.",
            "Will be very mad although the .7.",
            ".7 it can be taken, measured in dollars.",
            "No, no.",
            "That I don't.",
            "Also what I'm what I'm saying here is that.",
            "When I.",
            "Think think I again I I'm I'm I'm very my point is very clear but I'm not sure that I conveyed clearly.",
            "The point is that if.",
            "I give you.",
            "The structure and of guess some kind of conjecture structure about the data, and you I want to tell you I want you to tell me is this.",
            "Will structure in the data or is just an artifact of randomness or noise or whatever and all you have access to is the K means cost.",
            "You cannot tell me this.",
            "You cannot tell me if this is a meaningful partition or useful partitioning, or if it's where does it stand with respect to other partitioning.",
            "If you see only one, I give you a cost.",
            "Even if we assume that if I knew all the costs, the minimal cost is exactly what I'm after, seeing one partitioning doesn't tell me if it's good or bad when I define good or bad as its ranking among all the other partitionings in terms of the K means cost.",
            "What?",
            "Right, but I'm saying that in practice this is many times the situation that you encounter.",
            "I want to cluster your jeans and you get some score and you get some score.",
            "You want to know is this meaningful clustering or not meaningful classroom will mean that compared to other clustering, that it does.",
            "OK, OK.",
            "I'm not sure I understand what you want to say.",
            "I do you make the point that computationally you have a problem or model theoretic you have a problem computation happen.",
            "I cannot.",
            "I don't ignore that.",
            "I want to ask the following question.",
            "I give you a clustering.",
            "And I just give you this clustering.",
            "An ask you is it a good or not good clustering?",
            "Now intuitively we have answers.",
            "If I give you what now I don't have the game in console.",
            "OK so then I would just calculate all the possible partitioning.",
            "Well, all the all the ones which are within an approximation factor of 1.3 from the from the from the minimum.",
            "You can do that in polynomial time.",
            "Whether it might be not feasible in practice but for a theoretician that's right, no, no, no.",
            "OK, so I'm asking just a question.",
            "The following question, given a partitioning, is it good or bad?",
            "And your answer is, it depends on doing many other partitionings and comparing to them, and I want to ask.",
            "What I'm saying is that we as humans, when I when I show you a partitioning, you can tell me if it's good or bad without running other partitioning.",
            "No, because you have you have some structure.",
            "Being better than other things, no no.",
            "OK, so that's no, but that's exactly my question.",
            "My question is, what is a good classroom?",
            "Yes, that's my question.",
            "That's exactly what I want to say, and my question is, how do you define good clustering?",
            "And I want to say that an objective function is not does not give you the complete answer.",
            "Again, without the computer on the key, but what you said to have you answer before it was exactly to find good in terms of being better than other things.",
            "Can you share the data?",
            "Even even yeah, right, right?",
            "I mean what I'm saying is the question of defining what's a good clustering is the question that we have an intuition about and we don't have a way of of formalizing it.",
            "I mean.",
            "Even if you, if you compare it to other classrooms, it doesn't really give you the answer.",
            "I mean, if all the classrooms have roughly the same cost, and this is marginally better than the others, you will still feel that this is a not good partitioning.",
            "Can you show me the data?",
            "Under slide, the next was the next slide, the next slide.",
            "This tell me.",
            "K means is the game.",
            "Then I would tell you I would like to get the solution in the middle.",
            "Yes, that's OK. That's no.",
            "No, that's OK, that's OK.",
            "But but if I I I'm so that's why I don't understand your game because I'm saying that.",
            "OK, I how do you know?",
            "Assume that my data is a complete notice.",
            "Nice picture but a complete cloud of points.",
            "Yeah, and I give you some partitioning of this data and ask you is that this partitioning reflect real structure of the data or not?",
            "Even if you saw the K means cause of all the other partitionings and.",
            "Does it say that is a good clustering or not?",
            "I don't think it's obvious that it is, even if it's the minimal one.",
            "If any other partitioning comes to within very small epsilon to the same cost, you will not tell me that this is a meaningful structure.",
            "So the question is, did the clustering that I found.",
            "Does it mean a good meaningful clustering?",
            "What I'm saying we don't have a good answer, it's a difficult question and objective function doesn't give me the answer, that's what I'm trying to say.",
            "OK, so can you conclude the seasonal clustering?",
            "OK?",
            "How can we verify that the structure described by C is not just noise?",
            "And even if this is the minimal cost among all the other clustering, it does not yet give me a guarantee that this is not just noise.",
            "Because maybe they're all very similar in cost."
        ],
        [
            "And I think that this is the problem that we're trying to solve, and we're trying to solve even harder question.",
            "And this is if I just give you a data set and I ask you, does this data set has a good K clustering becausw?",
            "To choose the right K if we go back to the question of what is the right K, the right K is such a K for which the K clustering will be meaningful.",
            "So if I ask you what is the right K for my data set, it is asking does my data set has a clustering which is a good K petition, so we don't know how to define what's a good K partitioning yet.",
            "We want to say does my data set has a good K partitioning which is even harder question.",
            "So can we have an efficient algorithm for this kind of task?",
            "I give you a clustering set at data set and ask you does it have a good K partitioning because that's.",
            "If at least implicitly, our definition of what is the right K for this data set, it's a K for which we have a good partitioning.",
            "So I think this is a hard problem that we're trying to solve.",
            "And.",
            "Telling whether the data set has a good K partitioning.",
            "And then we're trying to have to do this even.",
            "Concerned about efficiency because we want to choose the K before we run our expensive clustering algorithm.",
            "So we want to be able to tell is this K good choice even before I run an exhaustive clustering algorithm over my data set, so I want it to be.",
            "Efficiency in sub linear time.",
            "To be able to tell that my data has a nice class ring and even approximating the cost of the optimal K, clustering is NP hard.",
            "What is NP hard in the setting in which the number of dimensions is a variable?",
            "Yeah, but usually that's not.",
            "Yeah, but when they all say it's exponential in the dimension, so if you get a dimension a couple of hundreds, it's become infeasible.",
            "OK, NP hard is an aseptic notion, but all the algorithms that we have are exponential in the dimension.",
            "So this means that in high dimensions even approximating the cost of the optimum is very hard, and therefore this problem is very hard.",
            "This statement from a theoretical point of view is not is only frightening if you say it's hard on average to approximate.",
            "This case, distribution results seem to be a misfit to do the questions in Kettering.",
            "OK, now that's a completely side issue, but it's definitely very time consuming to find the best clustering for data set.",
            "By approximating I mean the constant constant.",
            "Doctor approximations, which are not exponential.",
            "Yeah, so to a certain within certain constants you can and there is a constant above which below which it's NP hard.",
            "You have.",
            "What I'm saying is that the problem is hard.",
            "What I'm saying is that this problem is a hard problem and we want to do it in sub linear time and we don't have any pizzas that run in sublinear time and this is the kind of question we're trying to solve."
        ],
        [
            "And.",
            "OK, So what I'm looking for is can we answer these kind of questions in a way which is?",
            "Independent of any particular algorithm of any particular objective function and of any specific generative data model, so in this respect, the quest is for an answer which is more general than the setting that you are describing, right?",
            "Can we have some general principles that will tell us what is a good clustering, and those principles will apply?",
            "Regardless of what is my algorithm or objective function or generative model?",
            "And.",
            "Of course it's a very ambitious task, but.",
            "In some sense, it's not.",
            "We know that we have similar success success to answer in a similar fashion when it comes to classification, so why not in clustering?",
            "And I think that the feeling is.",
            "OK, what what do you want to say?",
            "I well, we we are here.",
            "Classification I don't know any classification.",
            "You mimic the teacher here.",
            "You don't have a teacher and you have a general principle.",
            "So, so it's a far more.",
            "It's far more difficult and that's why we haven't done anything so far.",
            "But can we have such a theory so or?"
        ],
        [
            "So what I'm saying is that let's look at the most more modest approach rather than formulate conditions that should be satisfied by any conceivable good clustering.",
            "Let us sidestep the issue of what is a good clustering and just settle for a necessary condition for good clustering, and that's where stability will come in.",
            "So stability says it's too hard for us to define what's a good clustering.",
            "Let us settle for.",
            "Necessary conditions that just filtering out anything it will not satisfy this condition will not be considered good clustering and we just narrow our domain of search for a good collection and this may be less ambitious and maybe we can achieve this goal.",
            "So we want a necessary condition which is independent of, which is very general and indeed."
        ],
        [
            "And the generative model that will be a necessary condition for clustering to be a good clustering.",
            "And the stability comes in exactly this.",
            "Man spot and says here is the stability idea.",
            "You cluster independent samples of the data.",
            "You'd compare the clusterings generated by the different samples and meaningful clusterings should not change much from one independent sample to another.",
            "That's the idea that we discussed throughout the morning and.",
            "Of course, he said, yeah, I've been employed and lots of times and you employ it all the time and it turns out to be a useful idea.",
            "So that's the basic idea of stability, and it seems to be."
        ],
        [
            "Very general idea.",
            "So.",
            "The problem is that we have theoretical support that justifies the use of this method.",
            "So here is the formal definition and the.",
            "Language already gave this formal definition early in the morning, so the setting is as follows in the probability distribution of your domain.",
            "Hey, you have an clustering algorithm that takes as input a subset of the domain and generates a clustering of the full domain and we have a similarity measure that measures how similar two clusterings are one to the other.",
            "And then we define for a fixed sample size and the instability of this algorithm over the data set is the expected distance if I take 2 samples of size M2 independent samples of size MI cluster, the first one a class for the second one is the expected.",
            "Distance or disagreement between these two clusterings.",
            "So this is well defined measure of the instability with respect to M size samples.",
            "And that's what we're trying to say that this should be low as a necessary condition for clustering to be considered meaningful."
        ],
        [
            "And then.",
            "Of course, the first example is instability detects.",
            "Anne.",
            "Non clusterable it.",
            "So if my data is the uniform distribution over the circle.",
            "And I generate random samples and cluster them no matter what is the number of clusters that I take.",
            "If it's bigger than one, it will never be stable becausw.",
            "Each sample will give me different partitioning, saying two sets, so into three sets.",
            "So here we detect the stability indeed.",
            "Hey, why the instability?",
            "Will be large for any nontrivial clustering function.",
            "So.",
            "This is a success of stability.",
            "It detects that the uniform distribution over the circle is not clusterable."
        ],
        [
            "And here is another success.",
            "It distinguishes between relevant and irrelevant clustering paradigms.",
            "So if this is, my data is generated by two circles, uniform distribution over here and a uniform distribution over here, say with half and half weights, then the instability will be large for every center based clustering.",
            "If I try K means it will be very unstable becausw each time it will put the centers in different places.",
            "But if I do linkage based.",
            "Algorithms, then, if I find a good threshold for stopping connecting points, then it will really become stable and detect the two circles.",
            "So here is a success of the stability idea in detecting the better paradigm for clustering, it detects that here linkage based does better than center based clustering algorithms."
        ],
        [
            "And here is another success and success in detecting the correct number of clusters.",
            "So if I try here to do a two clustering with two set."
        ],
        [
            "Then I'll fluctuate between these two partitioning.",
            "It will be unstable, but of course if I try four sets then it will be stable.",
            "So the stability here allows me to detect the correct number of K. So it looks like a very promising tool.",
            "It can detect uncrustable data, it can tell me which paradigm is better for my data.",
            "It can tell me what is the right key."
        ],
        [
            "So that was the conclusion as of December 2005.",
            "Then we set say invited Orica to come and work with me on this problem.",
            "It looks very promising that we wanted to just to prove it prove that stability really works.",
            "And what could we do?",
            "We could formally we formally define the measure of stability that you saw.",
            "And it not.",
            "It feels like a necessary property for any clustering method to be considered meaningful.",
            "And stability I mean, what is the view that is a measure of fit between your clustering algorithm and parameters?",
            "How well it fits your data set.",
            "And we could even show I have results that show that this measure can be reliably estimated from finest samples.",
            "I think someone asked it in the morning, but there are convergence results.",
            "You can show that if you take sufficiently many samples, then the estimate of the instability from your samples gives you a good estimate of the true expectation of the instability.",
            "So these are all very promising and nice results, and we thought we just go ahead and."
        ],
        [
            "Improve with everything works.",
            "Anne.",
            "So we wanted to prove that stability is a reliable model selection tool.",
            "Ann is another interesting question.",
            "How can you show such a positive statement?",
            "I mean, how can I tell you that statistic that stability detects the correct number of clusters?",
            "I mean, if I generate my data from a mixture of three Gaussians, then I know that the correct number of cluster is 3 and I can prove to you that in this case stability will detect three.",
            "But if I give you, how can I prove that it always will detect the correct number of clusters?",
            "It's not even clear how to formulate it, but that's what we were."
        ],
        [
            "Wanted to approximating OK, so here are some.",
            "Bothers some examples, so I sent it to Rick and David Paul.",
            "My student to work in a coffee shop while I was lecturing and they were supposed to prove that everything works and they came back with this kind of example.",
            "So what is bothering here?",
            "If I look at this distribution, a perfect uniform distribution circle distribution, it's unstable for every K. Assume that we're talking about K means, no matter what care you choose K bigger than one.",
            "It will be unstable because you take a sample here.",
            "You will get two centers here or two sentence here or two centers there.",
            "It will fluctuate all the time, but the minute I change my distribution a little bit and get rid of the symmetry.",
            "Now no matter what K is, even if K is 3, then practically if you take large enough samples you'll get three centers here and it will be stable.",
            "So stability this will look stable.",
            "This distribution distribution will not so stable and the only difference is that we broke the symmetry little bit, but if into it if you look at it and you ask me which of the two is more 3 clusterable.",
            "Both of them are not strictly stable.",
            "Both of them are just one cloud of uniform distribution.",
            "But the stability completely breaks down.",
            "This is the worst value of stability, and that's the best value of stability.",
            "And those examples don't differ by so much.",
            "Yes.",
            "I think.",
            "See through the view of the candies clustering function, you can still say that the right is more crossword.",
            "Because I can eat.",
            "Components.",
            "Data structure is in that sense more clustering, yeah, But you you're talking for the point of view of a mathematician, but I'm now talking from the point of view of.",
            "It is there.",
            "Intuition, do you see in this structure, three clusters or not?",
            "Do there exist three clusters in this structure or not?",
            "Because if you if I go to your kind of criteria and say find me the largest K for which this is stable, the largest K for this, which is stable, there's no such as escape it stable for every K, and this is unstable for every K, and the only difference is a slight breaking of symmetry.",
            "I think stability only breaks down if you limit yourself to convince them.",
            "If you would have limited ourselves to convince them inside this ability.",
            "So I agree that I am now discussing K means, but I think I discussed K means as this is a test case to this notion.",
            "I mean, it's a very I don't think it's specifically K means.",
            "I think it's any center based.",
            "Any center based clustering but any center based clustering becomes suddenly sensitive to and that's what we're going to show that.",
            "In practice, you will never see data set.",
            "It is so perfect and symmetrical, so in practice always no matter what data set you try, it will be stable.",
            "So this is a necessary condition, but it's a vacuous necessary condition.",
            "It always will hold for real data, but let me let me continue and see exactly what the theorem is, and then we can.",
            "Let's talk about the facts, not not about the way of phrasing OK."
        ],
        [
            "So.",
            "Yeah, so the bottom line of our formal analysis, so we had to papers that while stability does very nice model selection job on simple synthetic distributions.",
            "If my distribution comes from a well defined domain of distributions, is a mixture of nice Gaussians, then stability does a good job.",
            "But we have a full characterization of.",
            "For K means the optimization algorithms, and we conclude that this success of stability should be considered as a coincidence rather than its rule.",
            "So what is the?"
        ],
        [
            "The.",
            "The theorem the theorem says as follows, so I just repeated the definition of instability.",
            "So I'm saying that data is stable if in the limit as a sample size going to Infinity, the instability goes to 0.",
            "And the theorem says that if you have a cost minimization algorithm, so your algorithm is just trying to minimize the K means cost.",
            "If you have a cost minimisation algorithm, then that data set is stable if and only if there is a unique clustering solution to the minimization problem.",
            "So rather than measuring some vague notion of the number of clusters, what it actually detects is is there a unique solution to dimension problem?",
            "Or there is no unique solution to the message?",
            "This is a theorem you can't argue with this in terms of whether you like it or not.",
            "I know the argument is not with respect to the correctness of the theorem, but with respect to the interpretation.",
            "OK, OK, so yeah so.",
            "But at least this theorem gives us an understanding.",
            "What does stability detect detect the uniqueness of a minimum now?",
            "From here, we could I want I want to continue as follows.",
            "I want to give you some.",
            "Idea of the proof of the theorem.",
            "I mean this is something very good centric.",
            "I mean we work so hard to prove it and nobody cares about the proof because they just argue about the result.",
            "So I want to now that you are captive audience.",
            "I want to sell you something about the proof.",
            "And then discuss what are the implications OK?"
        ],
        [
            "So.",
            "The two directions One Direction is that if you have a unique minimizer then you get stability and this actually I mean after you clean it up, it basically follows from uniform convergence of clustering costs that I had in call to four that says that.",
            "You can get.",
            "If you take some samples of growing size, you can get a uniform bound on the rate on which the cost of the best clustering for the sample converges to the true best clustering of the data set.",
            "So if you take samples and find the best clustering for the sample, it will converge to the best clustering of the full data set.",
            "So if there is unique optimal of the of the full data set, then your samples, once they become big enough, they will get values which are very close to this unique optimum and therefore they will get clustering that are very close to this optimal clustering.",
            "So those clusterings will become close to each other.",
            "So what we're saying is the cost of clustering samples converges to the cost of clustering the whole data set.",
            "If the whole data set has only one solution, that gives you very low cost.",
            "Since the samples has to converge to this cost, they also has to converge to this solution.",
            "So once the samples become big enough, all the clustering solutions that coming from the samples are close to the true optimum and therefore they are close to each other and therefore the stability.",
            "The instability is low.",
            "Yes.",
            "Applying this to discuss to see if you prefer postponing the technical answers later explained is so is this only for you saying you're always talking about the optimal the complete data set using this.",
            "Actually my source solution is discrete, or you're allowing also continued sources.",
            "He may allow also continuous or situation.",
            "OK so I I look at the family of owner diagrams in an Internet, so I use.",
            "I use uniform convergence of honor Dragons.",
            "Your innocence limiting yourself to centuries question right?",
            "It doesn't mean that the paper has more general conditions, but something that I can explain in one sentence.",
            "Think of Bona dangles, but the paper itself is more general conditions under which this convergence holds.",
            "OK."
        ],
        [
            "Now.",
            "For the other direction, so the other action is, assume you have multiple solutions you want to, so you have multiple multiple multiple optimal solutions to your clustering, so that different clustering, different partitioning, that give you the same optimal cost.",
            "You want to show that random samples will jump between the different solutions.",
            "So here we have to assume that the support of the data is finite.",
            "So there are finitely many different solutions and say this is the set of optimal solutions.",
            "And.",
            "What we want to show basically.",
            "Is that?",
            "No solution becomes, so here is I look at samples and I the samples will converge to the optimal solutions.",
            "But I have several optimal solutions.",
            "I want to show that some samples with some probability samples will go to get close to one solution and with some non negligible probability they will get close to the other solution.",
            "So the hard part is to show that if I have two optimal solutions.",
            "The samples do not all converge to one solution.",
            "Because in that case they will get stability.",
            "Although I have two optimal solutions, all the samples tend to drift into one solution and not visit the other one.",
            "So here we show that the limit of the probability that you will get a solution which is close to one of them is never 01.",
            "So both solutions have non negligible probability of being visited and therefore you will get.",
            "Instability becausw some samples will be fair.",
            "One solution in some samples will prefer the other solution and you can lower bound the probability of each of them being visited."
        ],
        [
            "So technically we can think of it as a high dimensional space of all partitioning is this is this the boundary between all the samples that we fell one solution and all the samples that prefer the other solution and you want to show that each of them has a bounded away from zero.",
            "Fraction of the samples.",
            "If all the samples prefer one solution, then it will be stable, but if some samples always prefer the other solution then it will be unstable.",
            "So we have to analyze the boundary function between preferring one solution."
        ],
        [
            "We find another solution and it turns out that in the limit it begins to look like a Gaussian and then we take the Taylor expansion around the point of.",
            "Equivalent of a balance between the two and in the limit, everything becomes the Gaussian.",
            "And when you cut the Gaussian through the center with the hyperplane, you get probability of half on each side.",
            "So because in the limit when we take more and more samples, their concentration in the simplex of distributions looks like a multidimensional Gaussian.",
            "We can show that this boundary between preferring one solution to another solution.",
            "Get significant probability in one side and significant probability in the other side, and therefore you'll get instability.",
            "So thank you for being so patient and now I'm back to the intuitive."
        ],
        [
            "Discussion, so here are some examples.",
            "So now we know that stability detects uniqueness of the solution.",
            "So what does it mean here?",
            "Some just does it.",
            "Comply with our intuition of what is a good Class A good K. So if I have if my distribution just linear distribution 50% here and 50% here."
        ],
        [
            "Then if I take K = 2, it's M, K = 2.",
            "It's stable because there's only one good solution for."
        ],
        [
            "New sentence if I take a quiz three it's unstable becausw this is 1 optimal solution for K = 3."
        ],
        [
            "And this is 2 points here and one point here is another solution for K = 3.",
            "So I have two optimal solution for K = 3.",
            "So to be stable for K equals to unstable for K = 3 and we're happy it agrees with our intuition that here the number of cluster."
        ],
        [
            "These two, but what happens if it breaks the symmetry?",
            "If I break the symmetry, if the probability here is slightly higher than here, then 4K equal to."
        ],
        [
            "Who I will still get?"
        ],
        [
            "The stability but also for K = 3.",
            "Now there's only one solution.",
            "One optimal solution for K = 3 put two centers in the heavier side and just one center in the lighter side, so it will still be stable for K = 3 and you will conclude that the number of clusters is free if you just use stability.",
            "So what I'm trying to show you is that uniqueness of this solution doesn't indicate the correct number of clusters.",
            "Oh, the intuitive number of clusters."
        ],
        [
            "And we can even create examples in which.",
            "If I distribute my my if my weight nicely, I can create a situation where this solution has the same cost as this solution.",
            "So in this case K = 2 will not be.",
            "A stable and K = 3 will be stable.",
            "And if you just use stability as equity will conclude that you have three classes here rather than two.",
            "So this is just to demonstrate that the number of optimal solutions, the uniqueness of optimal solution, is not an indication of our intuition of what's the correct number of clusters.",
            "But it depends on your intuition, right?",
            "It depends if.",
            "You did asymptotically any vector quantization of your data is stable, because you go down the rate distortion curve to arbitrary low distortions, and so so so and therefore.",
            "There is no model order selection issue because you cannot select the correct model or you just selected, and that's exactly what came in stats.",
            "I would argue convinced us a reasonable job and it depends on your expectation on cable.",
            "OK, what I'm saying is this.",
            "I mean, we agree the fact that so in practice.",
            "Everything will look stable and it's the necessary condition.",
            "But the vacuous necessary condition.",
            "Because everything will look stable everywhere.",
            "Data set will look stable because it won't have."
        ],
        [
            "Symmetry.",
            "Yes, because you would like to use K means you would like to act.",
            "Use K means for a mixture, right?",
            "Because I'm right so.",
            "So yeah, OK.",
            "It's about your densities.",
            "Then you know already from Surface theorem that you cannot estimate the density.",
            "I'm not right, yeah, but I'm trying to do.",
            "I'm trying to do something much less ambitious than estimated density.",
            "Just dividing into clusters and the, but it brings out a different argument.",
            "I want to respond to the end because we I think one of the different points of view between me and you is that you are looking at the.",
            "Parametric parameters setting where you have family of hunters, family of distributions and you say if my data comes from these parameters family then I can guarantee something.",
            "I'm coming from the point of view of nonparametric statistics.",
            "I don't want to make any assumptions about my data in practice.",
            "I think that this is reflects many situations in reality that you use.",
            "It doesn't know anything about.",
            "How is distribution is made up?",
            "He still takes from the shelf.",
            "The K means algorithm and applies to his data and wants to conclude you want to tell me that this user is stupid.",
            "I don't care about him, but no, I'm not saying this user.",
            "This user is rarely in a situation that on one hand he or she can get an infinite amount of data and on the other hand he would like to OK to to stick to the infinite.",
            "The infinite amount of data is different.",
            "So what I'm saying is that in practice no data set is nicely symmetric.",
            "So there will always be a unique minimization solution.",
            "I think we agree to this.",
            "So in practice, any choice of clustering parameters on any real data set will always look stable.",
            "For K means clustering.",
            "So stability does not detect the number of clusters.",
            "List if we restrict to K means clustering, yes.",
            "Based on.",
            "OK, so there are two right there.",
            "The two lines of attacks that you can take here.",
            "One of them is saying this is a simple what will happen with finite samples.",
            "That's one line.",
            "The other line is saying.",
            "Maybe it's not so bad that it detects uniqueness of optimal.",
            "Maybe uniqueness of optimum does tell me something about the right number of clusters, right?",
            "OK, so yeah.",
            "Really, the code here is not instability, but with using center based clustering or painting for India or other symbols frustrate were really what we care about is inherently nuts interface because you don't have to go to stability Pacific areas within their own thing.",
            "For example, then it looks like this everyone segment and then another short segment here.",
            "Teens will fight with two means, will find will be one center.",
            "Basically, if you have these type of settings then it's not that this bill comes doesn't stability.",
            "The problem is really what you want to do is something very very different in sending these clustering and so I'm not know but I now know.",
            "The problem with using centerpiece testing for a non center based.",
            "Intuitive objective if I want to use center based clustering I can use K = 2.",
            "Two Centers for this data set and everything will find.",
            "The optimal things customer pick will be one cluster over here in another cluster.",
            "Over here it will not be the intuitive one segment another second.",
            "OK, so well, you say what I'm blaming is the combination of K means clustering with stability.",
            "Thing is not nothing to do with stability, or I mean there's also a future with disability, but it seems that in most of your examples the problem is not is really that intuitively you have some intuitive notion of finding clusters which are these connected components?",
            "Maybe I'm not sure what and then for some reason you're deciding to do that using some center based methods, but the center based methods really what they do is vectorization, which is something very different, and so it seems that you're just before you can get the stability here, just using completely the wrong tools.",
            "But yeah, it's not.",
            "I I right no no OK, OK but what I'm saying is that this is something that's being done in practice.",
            "People use K means algorithm.",
            "People use stability to detect a number of classes.",
            "I want to tell them you are doing something wrong and I have a proof and now what should be corrected?",
            "One answer to this.",
            "We can also do any, I mean many of them holds for any kind of objective function.",
            "So you something that you don't respect your customer normalized right?",
            "Because in our we have in our paper we have similar results for a spectral clustering.",
            "We really some have some kind of.",
            "Assumptions about what your objective function should satisfy an.",
            "Under those assumptions, you get those results.",
            "Do you have any case where you know that the model selection problem has been solved sufficiently?",
            "But the model of this election problem should now be determined by stability.",
            "Because I think the your counterexamples boiled down to the to the situation that stability is fooled.",
            "By by.",
            "By solving the model selection problem in the wrong right by my answer is that in practice you never have a correct solution to the model.",
            "I know, but I think this is no, but this is this is a virtual definition you're playing now the theoretician and say in my theory I have this distinction between model selection and the model complexity, and this is in your theory and what I'm saying is if you if you.",
            "If you assume this agnostic position, then you have to make very clear why you are not attacking a problem.",
            "Which has already been shown to be unsolvable, namely, the general density is because I don't want to try to end it.",
            "I don't want to accidentally information I'm doing clustering, which is much, much less.",
            "Am I am I unable to actually code any density estimation problem in the in terms of a clustering problem?",
            "When I when I use the degrees of freedom which you give me to define a classroom algorithm, I would I it's not apparent to me that that that that solving the clustering, the cluster clustering design problem.",
            "Is it easier in any case than the general density estimation?",
            "I mean, it's not clear to you that it's not OK, but it's not a valid argument.",
            "Functions on the way you define you.",
            "You densities well.",
            "You see what you're trying to tell me is if I try to follow your logic, you think we know the density estimation is hard is impossible.",
            "Now you tell me that clustering is impossible.",
            "Now maybe it follows from what we already know, because maybe clustering can be shown to be as hard as that information, but that's maybe we don't know that clustering is as hard as density estimation.",
            "Do it, do a connected component analysis on the asymptotic densities and you will get always the right number of clusters.",
            "So use using video setting the right tool to analyze your data and stability will actually tell you exactly when you do that, so this actually goes back to where they wanted.",
            "The theorem holds also for other objectives, like for example, just to talk about the low density regions order.",
            "But now as far as matching up with the theorem tells us about doing some stability with their twisted notion.",
            "Do you have examples there which which also we have such an intuitive notion that actually fits the model of a certain number of clusters and Linux admissibility will tell us something else?",
            "Because it's something like a means examples, but for another week consumption, yes?",
            "I've never thought about that.",
            "I can think.",
            "I'm sure we can make some up, but I.",
            "It does not.",
            "All these examples are fail when we look at this.",
            "But it's really.",
            "I see what I'm I'm coming and telling you I'm I have to show you this.",
            "OK. See I tell you that I have a complete analysis of what stability does and it has never been done before theoretical and you tell me, but you're missing this.",
            "I know I haven't solved all the world's problems, but I am."
        ],
        [
            "This is so let me, I think that the same applies.",
            "The same applies to other notions of stability.",
            "So while we prove it, the different notions of stability, I mean as in only conventions, is not only stability and the resampling.",
            "You can think of stability and the perturbation and different notions of stability.",
            "Our proof applies at the moment just to resampling stability, but if I look at the intuition behind the proof, I believe that it applies to why the family of notions of stability.",
            "That's one comment."
        ],
        [
            "To make.",
            "And the other comment I want to make is that there are two different topics of discussions here and one of them is that we said stability detects the uniqueness of optimal solution and I think part of the argument here was maybe that's the correct answer.",
            "Maybe it's not the correct answer, so we can argue about is uniqueness of optimal solution a good answer or not?",
            "But we know now that this is what stability detects.",
            "The other line of question is what you are raising.",
            "Our results are symbiotic nature.",
            "What happens with finite samples?",
            "And I think these are two separate issues that each of them with wealthier, separate discussion and so for the sense of I don't know.",
            "I don't remember which is my, which of the two.",
            "My next slides address."
        ],
        [
            "That same.",
            "So yeah, about something about the final sample Ness and then I'll talk about something about whether unique solution is the correct notion so clearly.",
            "But when I make this claim that practice, any data set has a unique clustering minimizer.",
            "It's this statement may fail if I relax it to almost minimal.",
            "So in practice, no exactly optimal solution.",
            "I have only one, but.",
            "Approximately optimal, I may have several solutions, and so it may be that if we take the sample size is not large enough to detect the difference between the two solutions, then from the point of view of this sample size it will look as if I have two optimums and it will look unstable.",
            "So in practice.",
            "It may be the case that where you're in some certain region of samples, you still detect the instability that you are expecting, and only when the samples begin become too much, then everything becomes stable and this is a very strange phenomena in sampling.",
            "Usually the larger the sample, the better your results and he loving this funny situation where it may be the case that you have some meaningful results for medium sized samples when you increase them.",
            "Everything becomes trivial, everything becomes stable.",
            "This is not correct.",
            "The.",
            "When you go to a syntonix also the dynamic range of the quantity you look at is getting smaller and smaller.",
            "You notice that the the stability the dynamic range of the stability is changing the scale when you go to the assembly.",
            "So not only do you get more and more samples, but the signal you measure at the final example is getting smaller when the sample is much larger.",
            "So what you would like to, but you have to show, is that the ordering.",
            "Off of my.",
            "Of different case.",
            "Compared to the range of this they preserve.",
            "Crossing over.",
            "You tell me at between N1 and N25 is the right answer.",
            "Then between and two and three I get 7 and I have such I have.",
            "I have such example.",
            "I have such a sample.",
            "I have such examples, but I don't have any slides, but we have such examples.",
            "Weather ordering changes.",
            "You can have such OK. Yeah.",
            "So I have such examples when they cross, you can create such examples.",
            "Yeah, maybe not.",
            "People mentioned we talked about mentioned maybe not even mentioned in his talk tomorrow.",
            "We have such examples where things cross.",
            "When they order crosses.",
            "And.",
            "OK, but if you take a practical, practically useful contribution will be to say OK, so the user comes to me and he asked me what is the correct sample size.",
            "So I tell you if you take M to be 2 much everything trivializes if you take take em to be too small then of course you are susceptible to sampling noise.",
            "What is the correct MI?",
            "Don't believe that we can give.",
            "Any bound which is independent of the data.",
            "So what practically reject to be able to say is tell the user you should use sample sizes of size of thousands when you want to check stability, it will not be too much, but those sample sizes will vary from them.",
            "That is set to another and you don't know what your data set when you're doing stability, so I don't believe this will be able to give a satisfactory answer here.",
            "Ann, you OK?"
        ],
        [
            "And now let me just go to the other issue weather.",
            "Uniqueness is the correct notion of correct number of clusterings Ann.",
            "This is source coming work.",
            "Investigate the notion of cluster ability and how do you measure cluster quality and there are many terms of their many different.",
            "Conceivable notions, and they don't agree with each other.",
            "So here are some examples.",
            "So one of them is clustering super ability, so you look at the ratio between the K means cost.",
            "Hey, the Caymans cost and the K -- 1 means cost and you say that the data is K clusterable if by going from K -- 1 two K you improve the cost dramatically.",
            "That's one notion that for saying that K is a good number of clusters.",
            "That, and this notion, when you apply it, even 2K means on those examples that you don't like that you say that K means is not good for them.",
            "If you long interval in short interval, you take this notion that tells you by how much do you improve your cost when you go from K to K -- 1, this will detect that the correct number is 2, not 3.",
            "So it's not that it's impossible to detect based on K means that you're shooting for two when you have two intervals.",
            "With this kind of measure you can do it.",
            "This measure has other problems, but that's something that.",
            "You compare your K -- 1 means cost to your came in scores and you want to see how much of an improvement did you get.",
            "You look at the ratio between the two.",
            "And it turns out that when this ratio is big enough, it really indicates the existence of separate clusters in the sense of having low density area between them.",
            "Not yeah, it's it's.",
            "It's an interesting measure and it captures much more than you would expect.",
            "It's a K means is not suitable for this data, so forget about it.",
            "It does capture something that it can tell you about those examples, yes.",
            "Is it like in the gap statistic you simply try to figure out?",
            "Essentially what you do is you plot.",
            "The K means cost and you want to look, I mean.",
            "They have a formal procedure for that, but you look at when, how long does it improve and when does it stop to improve, right?",
            "But here here this is theoretical measure that talks about the optimal clustering.",
            "You compare the cost of the optimal came in clustering to the optimal course of the K means clustering.",
            "Yes.",
            "There's this paper.",
            "And.",
            "Right, yeah no, it only works for very separated.",
            "I know, I know, I know only for extremely separate their separation should be.",
            "Separations will be in the order of 60.",
            "I mean the ratio between yeah between the ratio between the variants and the distance between them is right.",
            "It has its problems.",
            "And another one is the variance.",
            "Another measure flexibility is the variance within clusters divided by the variance between clusters.",
            "So there's another measure that people useful stability you look.",
            "Compare the variance within and between and say if this is big, then I have a meaningful structure.",
            "And another one is clustering you bartnes robustness to data population.",
            "So there are several different notions of quality of clustering, not necessarily uniqueness of solution.",
            "It turns out that all of them are inconsistent with each other.",
            "They all agree on very nicely separated clusters, but once the clusters become not so nicely separated, they give you different answers.",
            "OK, so that's all I can say right now, thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so I'll talk about the formal analysis of stability and then.",
                    "label": 1
                },
                {
                    "sent": "Yeah, I I'm, I'll try.",
                    "label": 0
                },
                {
                    "sent": "I don't know what exactly is the background of everybody, so I'm assuming.",
                    "label": 0
                },
                {
                    "sent": "Very little background and let me know if everything is clear and I bought you or if you have objections and so on.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "But I think that the big question that we have to ask and it goes back to the morning I what is a good clustering?",
                    "label": 1
                },
                {
                    "sent": "And that's really the big question that we have to ask and they don't know where the call is.",
                    "label": 0
                },
                {
                    "sent": "Not here but.",
                    "label": 0
                },
                {
                    "sent": "He raised this problem that yeah, what's that's the essential problem.",
                    "label": 0
                },
                {
                    "sent": "So there are many different ways to cluster the same data set.",
                    "label": 1
                },
                {
                    "sent": "So is this the correct clustering of this data set or?",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Clustering or is this a good clustering of this data set?",
                    "label": 0
                },
                {
                    "sent": "How do we define the quality of a given clustering and I?",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We can't avoid this question.",
                    "label": 0
                },
                {
                    "sent": "And they are even here.",
                    "label": 0
                },
                {
                    "sent": "Which of these two is better?",
                    "label": 0
                },
                {
                    "sent": "Clustering of these sets so, and you can say that you know people from saying from Eric's point of view you don't want to cross a.",
                    "label": 0
                },
                {
                    "sent": "High density areas, but you can just think of the same picture with these two stabs closer together and you will have high density here and still you will prefer this petition over this petition for some reasons.",
                    "label": 0
                },
                {
                    "sent": "So what measures do we have to decide what is a good a good clustering?",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then.",
                    "label": 0
                },
                {
                    "sent": "What is 1 immediate answer that comes to mind is say that's what we have.",
                    "label": 0
                },
                {
                    "sent": "An objective function is full.",
                    "label": 0
                },
                {
                    "sent": "So if my objective function is K means clustering, then I can calculate my camins cost and I'll decide what's a good clustering.",
                    "label": 0
                },
                {
                    "sent": "But note that even if we fix our objective function so we see that we decided what we care about is.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "Vector quantization, so it's the average square distance of your code words to your input.",
                    "label": 0
                },
                {
                    "sent": "I give you a concrete clustering so we get a data set.",
                    "label": 1
                },
                {
                    "sent": "You run your 5 means clustering algorithm and get the clustering.",
                    "label": 1
                },
                {
                    "sent": "You compute the 5 min costs and your outcome is .7.",
                    "label": 0
                },
                {
                    "sent": "Now I ask you, is this a good clustering or not?",
                    "label": 0
                },
                {
                    "sent": "And it tells you nothing.",
                    "label": 0
                },
                {
                    "sent": ".7.",
                    "label": 0
                },
                {
                    "sent": "Becausw, what do you compare it to?",
                    "label": 0
                },
                {
                    "sent": "I mean, even if we have an objective function and we really it really reflects our interest, it doesn't yet give us an answer to how good is my clustering.",
                    "label": 0
                },
                {
                    "sent": "Maybe this point 7 is very bad because my points are compactly located, then any partitioning will get me something like .7.",
                    "label": 0
                },
                {
                    "sent": "You already don't agree with me already, OK?",
                    "label": 0
                },
                {
                    "sent": "For better presentation, for example, in many times there is a concrete implementation of.",
                    "label": 0
                },
                {
                    "sent": "What is this open setting which is open 7 so OK, but I'm asking the question of not.",
                    "label": 0
                },
                {
                    "sent": "No, I ask you.",
                    "label": 0
                },
                {
                    "sent": "Is this a good clustering so?",
                    "label": 0
                },
                {
                    "sent": "You can decide that if I if.",
                    "label": 0
                },
                {
                    "sent": "Somewhere to move into me.",
                    "label": 0
                },
                {
                    "sent": "Some supplies is open.",
                    "label": 0
                },
                {
                    "sent": "7 Penn State.",
                    "label": 0
                },
                {
                    "sent": "So how much money I'm going to know.",
                    "label": 0
                },
                {
                    "sent": "Know if I it's OK so maybe I chose an example that on which you can easily attack.",
                    "label": 0
                },
                {
                    "sent": "But I I'm advising to Bell Canada and they want to do a target marketing for customers and they give me a data set of all the customers and output a clustering and ask me is this a good clustering?",
                    "label": 0
                },
                {
                    "sent": "Is does this reflect will structure in my collection of customers and the fact that I have .7 doesn't tell me if this reflects real structure of my customers.",
                    "label": 0
                },
                {
                    "sent": "Maybe every partitioning will get me .7 or less?",
                    "label": 0
                },
                {
                    "sent": "I don't know.",
                    "label": 0
                },
                {
                    "sent": "Something which you basically could calculate, but you know your your objective, your objective not only gives you the the global or local minimum, but it also gives you all the ranking of all the other clusters.",
                    "label": 1
                },
                {
                    "sent": "How?",
                    "label": 0
                },
                {
                    "sent": "How do you does it?",
                    "label": 0
                },
                {
                    "sent": "Give me a ranking of other clustering?",
                    "label": 0
                },
                {
                    "sent": "Define a different partition.",
                    "label": 0
                },
                {
                    "sent": "OK, so you here.",
                    "label": 0
                },
                {
                    "sent": "And then comes out OK, OK, OK, so I hear I got my my .7.",
                    "label": 0
                },
                {
                    "sent": "Then I follow your dreams advice and I take my clustering and divide my customers according to the 1st letter of the family name of the last name and I get a score 1.3 so I know that my clustering is better than dividing by your first letter of your last name.",
                    "label": 0
                },
                {
                    "sent": "But that's not very promising news.",
                    "label": 0
                },
                {
                    "sent": "For well.",
                    "label": 0
                },
                {
                    "sent": "I mean, that's not.",
                    "label": 0
                },
                {
                    "sent": "That doesn't tell them that the structure that I found is real structure.",
                    "label": 0
                },
                {
                    "sent": "The fact that they can beat some silly arbitrary partitionings doesn't tell him that what I have in my hand is a good clustering.",
                    "label": 0
                },
                {
                    "sent": "What what are you assuming?",
                    "label": 0
                },
                {
                    "sent": "If you have a cost function objective, right?",
                    "label": 0
                },
                {
                    "sent": "Any partitioning this objective?",
                    "label": 0
                },
                {
                    "sent": "I know, yes, yes, that's right.",
                    "label": 0
                },
                {
                    "sent": "Ocean of objective values.",
                    "label": 0
                },
                {
                    "sent": "You know what?",
                    "label": 0
                },
                {
                    "sent": "Open seven?",
                    "label": 0
                },
                {
                    "sent": "No, I don't know because I don't know all the other positions.",
                    "label": 0
                },
                {
                    "sent": "If you gave me a list of all possible partitioning an in those list, I could see where my .7 seats then I'll know.",
                    "label": 0
                },
                {
                    "sent": "But I don't have such a list.",
                    "label": 0
                },
                {
                    "sent": "There are exponentially many different partitionings I worked hard and came up with one clustering and now I want to know is it good or bad.",
                    "label": 0
                },
                {
                    "sent": "Now I can generate another 10 clustering and all will be worse than this one.",
                    "label": 0
                },
                {
                    "sent": "Does it tell me that I'm close to optimum?",
                    "label": 0
                },
                {
                    "sent": "Doesn't tell me.",
                    "label": 0
                },
                {
                    "sent": "That's important because Mexico.",
                    "label": 0
                },
                {
                    "sent": "You know this became subjective, and if you're consulting for Bell Canada, then the Caymans objective is not really the true objective that they want to optimize.",
                    "label": 0
                },
                {
                    "sent": "OK, so something they really object, the real objective that they care about is that they want their partitioning will be similar to the true way in which the true partitioning of users.",
                    "label": 0
                },
                {
                    "sent": "The problem is that this position is an observable, right?",
                    "label": 0
                },
                {
                    "sent": "Instead of using it.",
                    "label": 0
                },
                {
                    "sent": "Actually has the Kings objective, which maybe you can prove it has some relationship to this other objective, but it is not.",
                    "label": 0
                },
                {
                    "sent": "This other objective is OK, OK?",
                    "label": 0
                },
                {
                    "sent": "Is not what you care about, but sometimes that aims objective is exactly the correct thing.",
                    "label": 0
                },
                {
                    "sent": "Well, I'm trying to say is a different point when I'm trying to make a different point that even if I knew that the K means objectively correct, objective and number tells me nothing unless I can see how it stands with respect to all other costs of other partitions.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Trying to solve some reconciliation, trying to locate utilities.",
                    "label": 0
                },
                {
                    "sent": "Then the King Introductive is the correct objectives and then that's all I care about.",
                    "label": 0
                },
                {
                    "sent": "If that's no, it's good.",
                    "label": 0
                },
                {
                    "sent": "But what is low and high?",
                    "label": 0
                },
                {
                    "sent": "What is?",
                    "label": 0
                },
                {
                    "sent": "Well, low and high is not effective.",
                    "label": 0
                },
                {
                    "sent": "If I give you this petition, and then you realize the next day and the next year after you invested $1,000,000 based on this that another petition would give you value .1 and you could have saved $1,000,000.",
                    "label": 0
                },
                {
                    "sent": "Will be very mad although the .7.",
                    "label": 0
                },
                {
                    "sent": ".7 it can be taken, measured in dollars.",
                    "label": 0
                },
                {
                    "sent": "No, no.",
                    "label": 0
                },
                {
                    "sent": "That I don't.",
                    "label": 0
                },
                {
                    "sent": "Also what I'm what I'm saying here is that.",
                    "label": 0
                },
                {
                    "sent": "When I.",
                    "label": 0
                },
                {
                    "sent": "Think think I again I I'm I'm I'm very my point is very clear but I'm not sure that I conveyed clearly.",
                    "label": 0
                },
                {
                    "sent": "The point is that if.",
                    "label": 0
                },
                {
                    "sent": "I give you.",
                    "label": 0
                },
                {
                    "sent": "The structure and of guess some kind of conjecture structure about the data, and you I want to tell you I want you to tell me is this.",
                    "label": 0
                },
                {
                    "sent": "Will structure in the data or is just an artifact of randomness or noise or whatever and all you have access to is the K means cost.",
                    "label": 0
                },
                {
                    "sent": "You cannot tell me this.",
                    "label": 0
                },
                {
                    "sent": "You cannot tell me if this is a meaningful partition or useful partitioning, or if it's where does it stand with respect to other partitioning.",
                    "label": 0
                },
                {
                    "sent": "If you see only one, I give you a cost.",
                    "label": 0
                },
                {
                    "sent": "Even if we assume that if I knew all the costs, the minimal cost is exactly what I'm after, seeing one partitioning doesn't tell me if it's good or bad when I define good or bad as its ranking among all the other partitionings in terms of the K means cost.",
                    "label": 0
                },
                {
                    "sent": "What?",
                    "label": 0
                },
                {
                    "sent": "Right, but I'm saying that in practice this is many times the situation that you encounter.",
                    "label": 0
                },
                {
                    "sent": "I want to cluster your jeans and you get some score and you get some score.",
                    "label": 0
                },
                {
                    "sent": "You want to know is this meaningful clustering or not meaningful classroom will mean that compared to other clustering, that it does.",
                    "label": 0
                },
                {
                    "sent": "OK, OK.",
                    "label": 0
                },
                {
                    "sent": "I'm not sure I understand what you want to say.",
                    "label": 0
                },
                {
                    "sent": "I do you make the point that computationally you have a problem or model theoretic you have a problem computation happen.",
                    "label": 0
                },
                {
                    "sent": "I cannot.",
                    "label": 0
                },
                {
                    "sent": "I don't ignore that.",
                    "label": 0
                },
                {
                    "sent": "I want to ask the following question.",
                    "label": 0
                },
                {
                    "sent": "I give you a clustering.",
                    "label": 0
                },
                {
                    "sent": "And I just give you this clustering.",
                    "label": 0
                },
                {
                    "sent": "An ask you is it a good or not good clustering?",
                    "label": 0
                },
                {
                    "sent": "Now intuitively we have answers.",
                    "label": 0
                },
                {
                    "sent": "If I give you what now I don't have the game in console.",
                    "label": 0
                },
                {
                    "sent": "OK so then I would just calculate all the possible partitioning.",
                    "label": 0
                },
                {
                    "sent": "Well, all the all the ones which are within an approximation factor of 1.3 from the from the from the minimum.",
                    "label": 0
                },
                {
                    "sent": "You can do that in polynomial time.",
                    "label": 0
                },
                {
                    "sent": "Whether it might be not feasible in practice but for a theoretician that's right, no, no, no.",
                    "label": 0
                },
                {
                    "sent": "OK, so I'm asking just a question.",
                    "label": 0
                },
                {
                    "sent": "The following question, given a partitioning, is it good or bad?",
                    "label": 0
                },
                {
                    "sent": "And your answer is, it depends on doing many other partitionings and comparing to them, and I want to ask.",
                    "label": 0
                },
                {
                    "sent": "What I'm saying is that we as humans, when I when I show you a partitioning, you can tell me if it's good or bad without running other partitioning.",
                    "label": 0
                },
                {
                    "sent": "No, because you have you have some structure.",
                    "label": 0
                },
                {
                    "sent": "Being better than other things, no no.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's no, but that's exactly my question.",
                    "label": 0
                },
                {
                    "sent": "My question is, what is a good classroom?",
                    "label": 0
                },
                {
                    "sent": "Yes, that's my question.",
                    "label": 0
                },
                {
                    "sent": "That's exactly what I want to say, and my question is, how do you define good clustering?",
                    "label": 0
                },
                {
                    "sent": "And I want to say that an objective function is not does not give you the complete answer.",
                    "label": 0
                },
                {
                    "sent": "Again, without the computer on the key, but what you said to have you answer before it was exactly to find good in terms of being better than other things.",
                    "label": 0
                },
                {
                    "sent": "Can you share the data?",
                    "label": 0
                },
                {
                    "sent": "Even even yeah, right, right?",
                    "label": 0
                },
                {
                    "sent": "I mean what I'm saying is the question of defining what's a good clustering is the question that we have an intuition about and we don't have a way of of formalizing it.",
                    "label": 0
                },
                {
                    "sent": "I mean.",
                    "label": 0
                },
                {
                    "sent": "Even if you, if you compare it to other classrooms, it doesn't really give you the answer.",
                    "label": 0
                },
                {
                    "sent": "I mean, if all the classrooms have roughly the same cost, and this is marginally better than the others, you will still feel that this is a not good partitioning.",
                    "label": 0
                },
                {
                    "sent": "Can you show me the data?",
                    "label": 0
                },
                {
                    "sent": "Under slide, the next was the next slide, the next slide.",
                    "label": 0
                },
                {
                    "sent": "This tell me.",
                    "label": 0
                },
                {
                    "sent": "K means is the game.",
                    "label": 0
                },
                {
                    "sent": "Then I would tell you I would like to get the solution in the middle.",
                    "label": 0
                },
                {
                    "sent": "Yes, that's OK. That's no.",
                    "label": 0
                },
                {
                    "sent": "No, that's OK, that's OK.",
                    "label": 0
                },
                {
                    "sent": "But but if I I I'm so that's why I don't understand your game because I'm saying that.",
                    "label": 0
                },
                {
                    "sent": "OK, I how do you know?",
                    "label": 0
                },
                {
                    "sent": "Assume that my data is a complete notice.",
                    "label": 0
                },
                {
                    "sent": "Nice picture but a complete cloud of points.",
                    "label": 0
                },
                {
                    "sent": "Yeah, and I give you some partitioning of this data and ask you is that this partitioning reflect real structure of the data or not?",
                    "label": 0
                },
                {
                    "sent": "Even if you saw the K means cause of all the other partitionings and.",
                    "label": 1
                },
                {
                    "sent": "Does it say that is a good clustering or not?",
                    "label": 0
                },
                {
                    "sent": "I don't think it's obvious that it is, even if it's the minimal one.",
                    "label": 0
                },
                {
                    "sent": "If any other partitioning comes to within very small epsilon to the same cost, you will not tell me that this is a meaningful structure.",
                    "label": 0
                },
                {
                    "sent": "So the question is, did the clustering that I found.",
                    "label": 1
                },
                {
                    "sent": "Does it mean a good meaningful clustering?",
                    "label": 0
                },
                {
                    "sent": "What I'm saying we don't have a good answer, it's a difficult question and objective function doesn't give me the answer, that's what I'm trying to say.",
                    "label": 0
                },
                {
                    "sent": "OK, so can you conclude the seasonal clustering?",
                    "label": 0
                },
                {
                    "sent": "OK?",
                    "label": 0
                },
                {
                    "sent": "How can we verify that the structure described by C is not just noise?",
                    "label": 1
                },
                {
                    "sent": "And even if this is the minimal cost among all the other clustering, it does not yet give me a guarantee that this is not just noise.",
                    "label": 0
                },
                {
                    "sent": "Because maybe they're all very similar in cost.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And I think that this is the problem that we're trying to solve, and we're trying to solve even harder question.",
                    "label": 0
                },
                {
                    "sent": "And this is if I just give you a data set and I ask you, does this data set has a good K clustering becausw?",
                    "label": 0
                },
                {
                    "sent": "To choose the right K if we go back to the question of what is the right K, the right K is such a K for which the K clustering will be meaningful.",
                    "label": 0
                },
                {
                    "sent": "So if I ask you what is the right K for my data set, it is asking does my data set has a clustering which is a good K petition, so we don't know how to define what's a good K partitioning yet.",
                    "label": 0
                },
                {
                    "sent": "We want to say does my data set has a good K partitioning which is even harder question.",
                    "label": 0
                },
                {
                    "sent": "So can we have an efficient algorithm for this kind of task?",
                    "label": 1
                },
                {
                    "sent": "I give you a clustering set at data set and ask you does it have a good K partitioning because that's.",
                    "label": 0
                },
                {
                    "sent": "If at least implicitly, our definition of what is the right K for this data set, it's a K for which we have a good partitioning.",
                    "label": 0
                },
                {
                    "sent": "So I think this is a hard problem that we're trying to solve.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 1
                },
                {
                    "sent": "Telling whether the data set has a good K partitioning.",
                    "label": 0
                },
                {
                    "sent": "And then we're trying to have to do this even.",
                    "label": 0
                },
                {
                    "sent": "Concerned about efficiency because we want to choose the K before we run our expensive clustering algorithm.",
                    "label": 0
                },
                {
                    "sent": "So we want to be able to tell is this K good choice even before I run an exhaustive clustering algorithm over my data set, so I want it to be.",
                    "label": 1
                },
                {
                    "sent": "Efficiency in sub linear time.",
                    "label": 0
                },
                {
                    "sent": "To be able to tell that my data has a nice class ring and even approximating the cost of the optimal K, clustering is NP hard.",
                    "label": 1
                },
                {
                    "sent": "What is NP hard in the setting in which the number of dimensions is a variable?",
                    "label": 0
                },
                {
                    "sent": "Yeah, but usually that's not.",
                    "label": 0
                },
                {
                    "sent": "Yeah, but when they all say it's exponential in the dimension, so if you get a dimension a couple of hundreds, it's become infeasible.",
                    "label": 0
                },
                {
                    "sent": "OK, NP hard is an aseptic notion, but all the algorithms that we have are exponential in the dimension.",
                    "label": 0
                },
                {
                    "sent": "So this means that in high dimensions even approximating the cost of the optimum is very hard, and therefore this problem is very hard.",
                    "label": 0
                },
                {
                    "sent": "This statement from a theoretical point of view is not is only frightening if you say it's hard on average to approximate.",
                    "label": 0
                },
                {
                    "sent": "This case, distribution results seem to be a misfit to do the questions in Kettering.",
                    "label": 0
                },
                {
                    "sent": "OK, now that's a completely side issue, but it's definitely very time consuming to find the best clustering for data set.",
                    "label": 0
                },
                {
                    "sent": "By approximating I mean the constant constant.",
                    "label": 0
                },
                {
                    "sent": "Doctor approximations, which are not exponential.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so to a certain within certain constants you can and there is a constant above which below which it's NP hard.",
                    "label": 0
                },
                {
                    "sent": "You have.",
                    "label": 0
                },
                {
                    "sent": "What I'm saying is that the problem is hard.",
                    "label": 0
                },
                {
                    "sent": "What I'm saying is that this problem is a hard problem and we want to do it in sub linear time and we don't have any pizzas that run in sublinear time and this is the kind of question we're trying to solve.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "OK, So what I'm looking for is can we answer these kind of questions in a way which is?",
                    "label": 0
                },
                {
                    "sent": "Independent of any particular algorithm of any particular objective function and of any specific generative data model, so in this respect, the quest is for an answer which is more general than the setting that you are describing, right?",
                    "label": 1
                },
                {
                    "sent": "Can we have some general principles that will tell us what is a good clustering, and those principles will apply?",
                    "label": 0
                },
                {
                    "sent": "Regardless of what is my algorithm or objective function or generative model?",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Of course it's a very ambitious task, but.",
                    "label": 0
                },
                {
                    "sent": "In some sense, it's not.",
                    "label": 0
                },
                {
                    "sent": "We know that we have similar success success to answer in a similar fashion when it comes to classification, so why not in clustering?",
                    "label": 0
                },
                {
                    "sent": "And I think that the feeling is.",
                    "label": 0
                },
                {
                    "sent": "OK, what what do you want to say?",
                    "label": 0
                },
                {
                    "sent": "I well, we we are here.",
                    "label": 0
                },
                {
                    "sent": "Classification I don't know any classification.",
                    "label": 0
                },
                {
                    "sent": "You mimic the teacher here.",
                    "label": 0
                },
                {
                    "sent": "You don't have a teacher and you have a general principle.",
                    "label": 0
                },
                {
                    "sent": "So, so it's a far more.",
                    "label": 0
                },
                {
                    "sent": "It's far more difficult and that's why we haven't done anything so far.",
                    "label": 0
                },
                {
                    "sent": "But can we have such a theory so or?",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what I'm saying is that let's look at the most more modest approach rather than formulate conditions that should be satisfied by any conceivable good clustering.",
                    "label": 1
                },
                {
                    "sent": "Let us sidestep the issue of what is a good clustering and just settle for a necessary condition for good clustering, and that's where stability will come in.",
                    "label": 0
                },
                {
                    "sent": "So stability says it's too hard for us to define what's a good clustering.",
                    "label": 0
                },
                {
                    "sent": "Let us settle for.",
                    "label": 0
                },
                {
                    "sent": "Necessary conditions that just filtering out anything it will not satisfy this condition will not be considered good clustering and we just narrow our domain of search for a good collection and this may be less ambitious and maybe we can achieve this goal.",
                    "label": 0
                },
                {
                    "sent": "So we want a necessary condition which is independent of, which is very general and indeed.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the generative model that will be a necessary condition for clustering to be a good clustering.",
                    "label": 0
                },
                {
                    "sent": "And the stability comes in exactly this.",
                    "label": 0
                },
                {
                    "sent": "Man spot and says here is the stability idea.",
                    "label": 0
                },
                {
                    "sent": "You cluster independent samples of the data.",
                    "label": 1
                },
                {
                    "sent": "You'd compare the clusterings generated by the different samples and meaningful clusterings should not change much from one independent sample to another.",
                    "label": 1
                },
                {
                    "sent": "That's the idea that we discussed throughout the morning and.",
                    "label": 0
                },
                {
                    "sent": "Of course, he said, yeah, I've been employed and lots of times and you employ it all the time and it turns out to be a useful idea.",
                    "label": 0
                },
                {
                    "sent": "So that's the basic idea of stability, and it seems to be.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Very general idea.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The problem is that we have theoretical support that justifies the use of this method.",
                    "label": 0
                },
                {
                    "sent": "So here is the formal definition and the.",
                    "label": 1
                },
                {
                    "sent": "Language already gave this formal definition early in the morning, so the setting is as follows in the probability distribution of your domain.",
                    "label": 0
                },
                {
                    "sent": "Hey, you have an clustering algorithm that takes as input a subset of the domain and generates a clustering of the full domain and we have a similarity measure that measures how similar two clusterings are one to the other.",
                    "label": 0
                },
                {
                    "sent": "And then we define for a fixed sample size and the instability of this algorithm over the data set is the expected distance if I take 2 samples of size M2 independent samples of size MI cluster, the first one a class for the second one is the expected.",
                    "label": 1
                },
                {
                    "sent": "Distance or disagreement between these two clusterings.",
                    "label": 0
                },
                {
                    "sent": "So this is well defined measure of the instability with respect to M size samples.",
                    "label": 0
                },
                {
                    "sent": "And that's what we're trying to say that this should be low as a necessary condition for clustering to be considered meaningful.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And then.",
                    "label": 0
                },
                {
                    "sent": "Of course, the first example is instability detects.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "Non clusterable it.",
                    "label": 0
                },
                {
                    "sent": "So if my data is the uniform distribution over the circle.",
                    "label": 0
                },
                {
                    "sent": "And I generate random samples and cluster them no matter what is the number of clusters that I take.",
                    "label": 0
                },
                {
                    "sent": "If it's bigger than one, it will never be stable becausw.",
                    "label": 0
                },
                {
                    "sent": "Each sample will give me different partitioning, saying two sets, so into three sets.",
                    "label": 0
                },
                {
                    "sent": "So here we detect the stability indeed.",
                    "label": 0
                },
                {
                    "sent": "Hey, why the instability?",
                    "label": 0
                },
                {
                    "sent": "Will be large for any nontrivial clustering function.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "This is a success of stability.",
                    "label": 0
                },
                {
                    "sent": "It detects that the uniform distribution over the circle is not clusterable.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And here is another success.",
                    "label": 0
                },
                {
                    "sent": "It distinguishes between relevant and irrelevant clustering paradigms.",
                    "label": 1
                },
                {
                    "sent": "So if this is, my data is generated by two circles, uniform distribution over here and a uniform distribution over here, say with half and half weights, then the instability will be large for every center based clustering.",
                    "label": 1
                },
                {
                    "sent": "If I try K means it will be very unstable becausw each time it will put the centers in different places.",
                    "label": 0
                },
                {
                    "sent": "But if I do linkage based.",
                    "label": 0
                },
                {
                    "sent": "Algorithms, then, if I find a good threshold for stopping connecting points, then it will really become stable and detect the two circles.",
                    "label": 0
                },
                {
                    "sent": "So here is a success of the stability idea in detecting the better paradigm for clustering, it detects that here linkage based does better than center based clustering algorithms.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here is another success and success in detecting the correct number of clusters.",
                    "label": 0
                },
                {
                    "sent": "So if I try here to do a two clustering with two set.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then I'll fluctuate between these two partitioning.",
                    "label": 0
                },
                {
                    "sent": "It will be unstable, but of course if I try four sets then it will be stable.",
                    "label": 1
                },
                {
                    "sent": "So the stability here allows me to detect the correct number of K. So it looks like a very promising tool.",
                    "label": 0
                },
                {
                    "sent": "It can detect uncrustable data, it can tell me which paradigm is better for my data.",
                    "label": 0
                },
                {
                    "sent": "It can tell me what is the right key.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that was the conclusion as of December 2005.",
                    "label": 0
                },
                {
                    "sent": "Then we set say invited Orica to come and work with me on this problem.",
                    "label": 0
                },
                {
                    "sent": "It looks very promising that we wanted to just to prove it prove that stability really works.",
                    "label": 0
                },
                {
                    "sent": "And what could we do?",
                    "label": 0
                },
                {
                    "sent": "We could formally we formally define the measure of stability that you saw.",
                    "label": 1
                },
                {
                    "sent": "And it not.",
                    "label": 0
                },
                {
                    "sent": "It feels like a necessary property for any clustering method to be considered meaningful.",
                    "label": 1
                },
                {
                    "sent": "And stability I mean, what is the view that is a measure of fit between your clustering algorithm and parameters?",
                    "label": 0
                },
                {
                    "sent": "How well it fits your data set.",
                    "label": 1
                },
                {
                    "sent": "And we could even show I have results that show that this measure can be reliably estimated from finest samples.",
                    "label": 0
                },
                {
                    "sent": "I think someone asked it in the morning, but there are convergence results.",
                    "label": 0
                },
                {
                    "sent": "You can show that if you take sufficiently many samples, then the estimate of the instability from your samples gives you a good estimate of the true expectation of the instability.",
                    "label": 0
                },
                {
                    "sent": "So these are all very promising and nice results, and we thought we just go ahead and.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Improve with everything works.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "So we wanted to prove that stability is a reliable model selection tool.",
                    "label": 1
                },
                {
                    "sent": "Ann is another interesting question.",
                    "label": 0
                },
                {
                    "sent": "How can you show such a positive statement?",
                    "label": 0
                },
                {
                    "sent": "I mean, how can I tell you that statistic that stability detects the correct number of clusters?",
                    "label": 0
                },
                {
                    "sent": "I mean, if I generate my data from a mixture of three Gaussians, then I know that the correct number of cluster is 3 and I can prove to you that in this case stability will detect three.",
                    "label": 0
                },
                {
                    "sent": "But if I give you, how can I prove that it always will detect the correct number of clusters?",
                    "label": 0
                },
                {
                    "sent": "It's not even clear how to formulate it, but that's what we were.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Wanted to approximating OK, so here are some.",
                    "label": 0
                },
                {
                    "sent": "Bothers some examples, so I sent it to Rick and David Paul.",
                    "label": 0
                },
                {
                    "sent": "My student to work in a coffee shop while I was lecturing and they were supposed to prove that everything works and they came back with this kind of example.",
                    "label": 0
                },
                {
                    "sent": "So what is bothering here?",
                    "label": 0
                },
                {
                    "sent": "If I look at this distribution, a perfect uniform distribution circle distribution, it's unstable for every K. Assume that we're talking about K means, no matter what care you choose K bigger than one.",
                    "label": 0
                },
                {
                    "sent": "It will be unstable because you take a sample here.",
                    "label": 0
                },
                {
                    "sent": "You will get two centers here or two sentence here or two centers there.",
                    "label": 0
                },
                {
                    "sent": "It will fluctuate all the time, but the minute I change my distribution a little bit and get rid of the symmetry.",
                    "label": 0
                },
                {
                    "sent": "Now no matter what K is, even if K is 3, then practically if you take large enough samples you'll get three centers here and it will be stable.",
                    "label": 0
                },
                {
                    "sent": "So stability this will look stable.",
                    "label": 0
                },
                {
                    "sent": "This distribution distribution will not so stable and the only difference is that we broke the symmetry little bit, but if into it if you look at it and you ask me which of the two is more 3 clusterable.",
                    "label": 0
                },
                {
                    "sent": "Both of them are not strictly stable.",
                    "label": 0
                },
                {
                    "sent": "Both of them are just one cloud of uniform distribution.",
                    "label": 0
                },
                {
                    "sent": "But the stability completely breaks down.",
                    "label": 0
                },
                {
                    "sent": "This is the worst value of stability, and that's the best value of stability.",
                    "label": 0
                },
                {
                    "sent": "And those examples don't differ by so much.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "I think.",
                    "label": 0
                },
                {
                    "sent": "See through the view of the candies clustering function, you can still say that the right is more crossword.",
                    "label": 0
                },
                {
                    "sent": "Because I can eat.",
                    "label": 0
                },
                {
                    "sent": "Components.",
                    "label": 0
                },
                {
                    "sent": "Data structure is in that sense more clustering, yeah, But you you're talking for the point of view of a mathematician, but I'm now talking from the point of view of.",
                    "label": 0
                },
                {
                    "sent": "It is there.",
                    "label": 0
                },
                {
                    "sent": "Intuition, do you see in this structure, three clusters or not?",
                    "label": 0
                },
                {
                    "sent": "Do there exist three clusters in this structure or not?",
                    "label": 0
                },
                {
                    "sent": "Because if you if I go to your kind of criteria and say find me the largest K for which this is stable, the largest K for this, which is stable, there's no such as escape it stable for every K, and this is unstable for every K, and the only difference is a slight breaking of symmetry.",
                    "label": 1
                },
                {
                    "sent": "I think stability only breaks down if you limit yourself to convince them.",
                    "label": 0
                },
                {
                    "sent": "If you would have limited ourselves to convince them inside this ability.",
                    "label": 0
                },
                {
                    "sent": "So I agree that I am now discussing K means, but I think I discussed K means as this is a test case to this notion.",
                    "label": 0
                },
                {
                    "sent": "I mean, it's a very I don't think it's specifically K means.",
                    "label": 0
                },
                {
                    "sent": "I think it's any center based.",
                    "label": 0
                },
                {
                    "sent": "Any center based clustering but any center based clustering becomes suddenly sensitive to and that's what we're going to show that.",
                    "label": 0
                },
                {
                    "sent": "In practice, you will never see data set.",
                    "label": 0
                },
                {
                    "sent": "It is so perfect and symmetrical, so in practice always no matter what data set you try, it will be stable.",
                    "label": 0
                },
                {
                    "sent": "So this is a necessary condition, but it's a vacuous necessary condition.",
                    "label": 0
                },
                {
                    "sent": "It always will hold for real data, but let me let me continue and see exactly what the theorem is, and then we can.",
                    "label": 0
                },
                {
                    "sent": "Let's talk about the facts, not not about the way of phrasing OK.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so the bottom line of our formal analysis, so we had to papers that while stability does very nice model selection job on simple synthetic distributions.",
                    "label": 1
                },
                {
                    "sent": "If my distribution comes from a well defined domain of distributions, is a mixture of nice Gaussians, then stability does a good job.",
                    "label": 0
                },
                {
                    "sent": "But we have a full characterization of.",
                    "label": 1
                },
                {
                    "sent": "For K means the optimization algorithms, and we conclude that this success of stability should be considered as a coincidence rather than its rule.",
                    "label": 0
                },
                {
                    "sent": "So what is the?",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "The theorem the theorem says as follows, so I just repeated the definition of instability.",
                    "label": 0
                },
                {
                    "sent": "So I'm saying that data is stable if in the limit as a sample size going to Infinity, the instability goes to 0.",
                    "label": 0
                },
                {
                    "sent": "And the theorem says that if you have a cost minimization algorithm, so your algorithm is just trying to minimize the K means cost.",
                    "label": 0
                },
                {
                    "sent": "If you have a cost minimisation algorithm, then that data set is stable if and only if there is a unique clustering solution to the minimization problem.",
                    "label": 1
                },
                {
                    "sent": "So rather than measuring some vague notion of the number of clusters, what it actually detects is is there a unique solution to dimension problem?",
                    "label": 0
                },
                {
                    "sent": "Or there is no unique solution to the message?",
                    "label": 0
                },
                {
                    "sent": "This is a theorem you can't argue with this in terms of whether you like it or not.",
                    "label": 0
                },
                {
                    "sent": "I know the argument is not with respect to the correctness of the theorem, but with respect to the interpretation.",
                    "label": 0
                },
                {
                    "sent": "OK, OK, so yeah so.",
                    "label": 0
                },
                {
                    "sent": "But at least this theorem gives us an understanding.",
                    "label": 0
                },
                {
                    "sent": "What does stability detect detect the uniqueness of a minimum now?",
                    "label": 0
                },
                {
                    "sent": "From here, we could I want I want to continue as follows.",
                    "label": 0
                },
                {
                    "sent": "I want to give you some.",
                    "label": 0
                },
                {
                    "sent": "Idea of the proof of the theorem.",
                    "label": 0
                },
                {
                    "sent": "I mean this is something very good centric.",
                    "label": 0
                },
                {
                    "sent": "I mean we work so hard to prove it and nobody cares about the proof because they just argue about the result.",
                    "label": 0
                },
                {
                    "sent": "So I want to now that you are captive audience.",
                    "label": 0
                },
                {
                    "sent": "I want to sell you something about the proof.",
                    "label": 0
                },
                {
                    "sent": "And then discuss what are the implications OK?",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The two directions One Direction is that if you have a unique minimizer then you get stability and this actually I mean after you clean it up, it basically follows from uniform convergence of clustering costs that I had in call to four that says that.",
                    "label": 0
                },
                {
                    "sent": "You can get.",
                    "label": 0
                },
                {
                    "sent": "If you take some samples of growing size, you can get a uniform bound on the rate on which the cost of the best clustering for the sample converges to the true best clustering of the data set.",
                    "label": 0
                },
                {
                    "sent": "So if you take samples and find the best clustering for the sample, it will converge to the best clustering of the full data set.",
                    "label": 0
                },
                {
                    "sent": "So if there is unique optimal of the of the full data set, then your samples, once they become big enough, they will get values which are very close to this unique optimum and therefore they will get clustering that are very close to this optimal clustering.",
                    "label": 0
                },
                {
                    "sent": "So those clusterings will become close to each other.",
                    "label": 0
                },
                {
                    "sent": "So what we're saying is the cost of clustering samples converges to the cost of clustering the whole data set.",
                    "label": 0
                },
                {
                    "sent": "If the whole data set has only one solution, that gives you very low cost.",
                    "label": 0
                },
                {
                    "sent": "Since the samples has to converge to this cost, they also has to converge to this solution.",
                    "label": 0
                },
                {
                    "sent": "So once the samples become big enough, all the clustering solutions that coming from the samples are close to the true optimum and therefore they are close to each other and therefore the stability.",
                    "label": 0
                },
                {
                    "sent": "The instability is low.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Applying this to discuss to see if you prefer postponing the technical answers later explained is so is this only for you saying you're always talking about the optimal the complete data set using this.",
                    "label": 0
                },
                {
                    "sent": "Actually my source solution is discrete, or you're allowing also continued sources.",
                    "label": 0
                },
                {
                    "sent": "He may allow also continuous or situation.",
                    "label": 0
                },
                {
                    "sent": "OK so I I look at the family of owner diagrams in an Internet, so I use.",
                    "label": 0
                },
                {
                    "sent": "I use uniform convergence of honor Dragons.",
                    "label": 0
                },
                {
                    "sent": "Your innocence limiting yourself to centuries question right?",
                    "label": 0
                },
                {
                    "sent": "It doesn't mean that the paper has more general conditions, but something that I can explain in one sentence.",
                    "label": 0
                },
                {
                    "sent": "Think of Bona dangles, but the paper itself is more general conditions under which this convergence holds.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "For the other direction, so the other action is, assume you have multiple solutions you want to, so you have multiple multiple multiple optimal solutions to your clustering, so that different clustering, different partitioning, that give you the same optimal cost.",
                    "label": 0
                },
                {
                    "sent": "You want to show that random samples will jump between the different solutions.",
                    "label": 0
                },
                {
                    "sent": "So here we have to assume that the support of the data is finite.",
                    "label": 0
                },
                {
                    "sent": "So there are finitely many different solutions and say this is the set of optimal solutions.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "What we want to show basically.",
                    "label": 0
                },
                {
                    "sent": "Is that?",
                    "label": 0
                },
                {
                    "sent": "No solution becomes, so here is I look at samples and I the samples will converge to the optimal solutions.",
                    "label": 0
                },
                {
                    "sent": "But I have several optimal solutions.",
                    "label": 0
                },
                {
                    "sent": "I want to show that some samples with some probability samples will go to get close to one solution and with some non negligible probability they will get close to the other solution.",
                    "label": 0
                },
                {
                    "sent": "So the hard part is to show that if I have two optimal solutions.",
                    "label": 0
                },
                {
                    "sent": "The samples do not all converge to one solution.",
                    "label": 0
                },
                {
                    "sent": "Because in that case they will get stability.",
                    "label": 0
                },
                {
                    "sent": "Although I have two optimal solutions, all the samples tend to drift into one solution and not visit the other one.",
                    "label": 0
                },
                {
                    "sent": "So here we show that the limit of the probability that you will get a solution which is close to one of them is never 01.",
                    "label": 0
                },
                {
                    "sent": "So both solutions have non negligible probability of being visited and therefore you will get.",
                    "label": 0
                },
                {
                    "sent": "Instability becausw some samples will be fair.",
                    "label": 0
                },
                {
                    "sent": "One solution in some samples will prefer the other solution and you can lower bound the probability of each of them being visited.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So technically we can think of it as a high dimensional space of all partitioning is this is this the boundary between all the samples that we fell one solution and all the samples that prefer the other solution and you want to show that each of them has a bounded away from zero.",
                    "label": 0
                },
                {
                    "sent": "Fraction of the samples.",
                    "label": 0
                },
                {
                    "sent": "If all the samples prefer one solution, then it will be stable, but if some samples always prefer the other solution then it will be unstable.",
                    "label": 0
                },
                {
                    "sent": "So we have to analyze the boundary function between preferring one solution.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We find another solution and it turns out that in the limit it begins to look like a Gaussian and then we take the Taylor expansion around the point of.",
                    "label": 0
                },
                {
                    "sent": "Equivalent of a balance between the two and in the limit, everything becomes the Gaussian.",
                    "label": 0
                },
                {
                    "sent": "And when you cut the Gaussian through the center with the hyperplane, you get probability of half on each side.",
                    "label": 0
                },
                {
                    "sent": "So because in the limit when we take more and more samples, their concentration in the simplex of distributions looks like a multidimensional Gaussian.",
                    "label": 0
                },
                {
                    "sent": "We can show that this boundary between preferring one solution to another solution.",
                    "label": 0
                },
                {
                    "sent": "Get significant probability in one side and significant probability in the other side, and therefore you'll get instability.",
                    "label": 0
                },
                {
                    "sent": "So thank you for being so patient and now I'm back to the intuitive.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Discussion, so here are some examples.",
                    "label": 0
                },
                {
                    "sent": "So now we know that stability detects uniqueness of the solution.",
                    "label": 0
                },
                {
                    "sent": "So what does it mean here?",
                    "label": 0
                },
                {
                    "sent": "Some just does it.",
                    "label": 0
                },
                {
                    "sent": "Comply with our intuition of what is a good Class A good K. So if I have if my distribution just linear distribution 50% here and 50% here.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then if I take K = 2, it's M, K = 2.",
                    "label": 0
                },
                {
                    "sent": "It's stable because there's only one good solution for.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "New sentence if I take a quiz three it's unstable becausw this is 1 optimal solution for K = 3.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is 2 points here and one point here is another solution for K = 3.",
                    "label": 0
                },
                {
                    "sent": "So I have two optimal solution for K = 3.",
                    "label": 0
                },
                {
                    "sent": "So to be stable for K equals to unstable for K = 3 and we're happy it agrees with our intuition that here the number of cluster.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "These two, but what happens if it breaks the symmetry?",
                    "label": 0
                },
                {
                    "sent": "If I break the symmetry, if the probability here is slightly higher than here, then 4K equal to.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Who I will still get?",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The stability but also for K = 3.",
                    "label": 0
                },
                {
                    "sent": "Now there's only one solution.",
                    "label": 0
                },
                {
                    "sent": "One optimal solution for K = 3 put two centers in the heavier side and just one center in the lighter side, so it will still be stable for K = 3 and you will conclude that the number of clusters is free if you just use stability.",
                    "label": 0
                },
                {
                    "sent": "So what I'm trying to show you is that uniqueness of this solution doesn't indicate the correct number of clusters.",
                    "label": 0
                },
                {
                    "sent": "Oh, the intuitive number of clusters.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we can even create examples in which.",
                    "label": 0
                },
                {
                    "sent": "If I distribute my my if my weight nicely, I can create a situation where this solution has the same cost as this solution.",
                    "label": 0
                },
                {
                    "sent": "So in this case K = 2 will not be.",
                    "label": 0
                },
                {
                    "sent": "A stable and K = 3 will be stable.",
                    "label": 0
                },
                {
                    "sent": "And if you just use stability as equity will conclude that you have three classes here rather than two.",
                    "label": 0
                },
                {
                    "sent": "So this is just to demonstrate that the number of optimal solutions, the uniqueness of optimal solution, is not an indication of our intuition of what's the correct number of clusters.",
                    "label": 0
                },
                {
                    "sent": "But it depends on your intuition, right?",
                    "label": 0
                },
                {
                    "sent": "It depends if.",
                    "label": 0
                },
                {
                    "sent": "You did asymptotically any vector quantization of your data is stable, because you go down the rate distortion curve to arbitrary low distortions, and so so so and therefore.",
                    "label": 0
                },
                {
                    "sent": "There is no model order selection issue because you cannot select the correct model or you just selected, and that's exactly what came in stats.",
                    "label": 0
                },
                {
                    "sent": "I would argue convinced us a reasonable job and it depends on your expectation on cable.",
                    "label": 0
                },
                {
                    "sent": "OK, what I'm saying is this.",
                    "label": 0
                },
                {
                    "sent": "I mean, we agree the fact that so in practice.",
                    "label": 0
                },
                {
                    "sent": "Everything will look stable and it's the necessary condition.",
                    "label": 0
                },
                {
                    "sent": "But the vacuous necessary condition.",
                    "label": 0
                },
                {
                    "sent": "Because everything will look stable everywhere.",
                    "label": 0
                },
                {
                    "sent": "Data set will look stable because it won't have.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Symmetry.",
                    "label": 0
                },
                {
                    "sent": "Yes, because you would like to use K means you would like to act.",
                    "label": 0
                },
                {
                    "sent": "Use K means for a mixture, right?",
                    "label": 0
                },
                {
                    "sent": "Because I'm right so.",
                    "label": 0
                },
                {
                    "sent": "So yeah, OK.",
                    "label": 0
                },
                {
                    "sent": "It's about your densities.",
                    "label": 0
                },
                {
                    "sent": "Then you know already from Surface theorem that you cannot estimate the density.",
                    "label": 0
                },
                {
                    "sent": "I'm not right, yeah, but I'm trying to do.",
                    "label": 0
                },
                {
                    "sent": "I'm trying to do something much less ambitious than estimated density.",
                    "label": 0
                },
                {
                    "sent": "Just dividing into clusters and the, but it brings out a different argument.",
                    "label": 0
                },
                {
                    "sent": "I want to respond to the end because we I think one of the different points of view between me and you is that you are looking at the.",
                    "label": 0
                },
                {
                    "sent": "Parametric parameters setting where you have family of hunters, family of distributions and you say if my data comes from these parameters family then I can guarantee something.",
                    "label": 0
                },
                {
                    "sent": "I'm coming from the point of view of nonparametric statistics.",
                    "label": 0
                },
                {
                    "sent": "I don't want to make any assumptions about my data in practice.",
                    "label": 0
                },
                {
                    "sent": "I think that this is reflects many situations in reality that you use.",
                    "label": 0
                },
                {
                    "sent": "It doesn't know anything about.",
                    "label": 0
                },
                {
                    "sent": "How is distribution is made up?",
                    "label": 0
                },
                {
                    "sent": "He still takes from the shelf.",
                    "label": 0
                },
                {
                    "sent": "The K means algorithm and applies to his data and wants to conclude you want to tell me that this user is stupid.",
                    "label": 0
                },
                {
                    "sent": "I don't care about him, but no, I'm not saying this user.",
                    "label": 0
                },
                {
                    "sent": "This user is rarely in a situation that on one hand he or she can get an infinite amount of data and on the other hand he would like to OK to to stick to the infinite.",
                    "label": 0
                },
                {
                    "sent": "The infinite amount of data is different.",
                    "label": 0
                },
                {
                    "sent": "So what I'm saying is that in practice no data set is nicely symmetric.",
                    "label": 1
                },
                {
                    "sent": "So there will always be a unique minimization solution.",
                    "label": 1
                },
                {
                    "sent": "I think we agree to this.",
                    "label": 0
                },
                {
                    "sent": "So in practice, any choice of clustering parameters on any real data set will always look stable.",
                    "label": 1
                },
                {
                    "sent": "For K means clustering.",
                    "label": 0
                },
                {
                    "sent": "So stability does not detect the number of clusters.",
                    "label": 0
                },
                {
                    "sent": "List if we restrict to K means clustering, yes.",
                    "label": 0
                },
                {
                    "sent": "Based on.",
                    "label": 0
                },
                {
                    "sent": "OK, so there are two right there.",
                    "label": 0
                },
                {
                    "sent": "The two lines of attacks that you can take here.",
                    "label": 0
                },
                {
                    "sent": "One of them is saying this is a simple what will happen with finite samples.",
                    "label": 0
                },
                {
                    "sent": "That's one line.",
                    "label": 0
                },
                {
                    "sent": "The other line is saying.",
                    "label": 0
                },
                {
                    "sent": "Maybe it's not so bad that it detects uniqueness of optimal.",
                    "label": 0
                },
                {
                    "sent": "Maybe uniqueness of optimum does tell me something about the right number of clusters, right?",
                    "label": 0
                },
                {
                    "sent": "OK, so yeah.",
                    "label": 0
                },
                {
                    "sent": "Really, the code here is not instability, but with using center based clustering or painting for India or other symbols frustrate were really what we care about is inherently nuts interface because you don't have to go to stability Pacific areas within their own thing.",
                    "label": 0
                },
                {
                    "sent": "For example, then it looks like this everyone segment and then another short segment here.",
                    "label": 0
                },
                {
                    "sent": "Teens will fight with two means, will find will be one center.",
                    "label": 0
                },
                {
                    "sent": "Basically, if you have these type of settings then it's not that this bill comes doesn't stability.",
                    "label": 0
                },
                {
                    "sent": "The problem is really what you want to do is something very very different in sending these clustering and so I'm not know but I now know.",
                    "label": 0
                },
                {
                    "sent": "The problem with using centerpiece testing for a non center based.",
                    "label": 0
                },
                {
                    "sent": "Intuitive objective if I want to use center based clustering I can use K = 2.",
                    "label": 0
                },
                {
                    "sent": "Two Centers for this data set and everything will find.",
                    "label": 0
                },
                {
                    "sent": "The optimal things customer pick will be one cluster over here in another cluster.",
                    "label": 0
                },
                {
                    "sent": "Over here it will not be the intuitive one segment another second.",
                    "label": 0
                },
                {
                    "sent": "OK, so well, you say what I'm blaming is the combination of K means clustering with stability.",
                    "label": 0
                },
                {
                    "sent": "Thing is not nothing to do with stability, or I mean there's also a future with disability, but it seems that in most of your examples the problem is not is really that intuitively you have some intuitive notion of finding clusters which are these connected components?",
                    "label": 0
                },
                {
                    "sent": "Maybe I'm not sure what and then for some reason you're deciding to do that using some center based methods, but the center based methods really what they do is vectorization, which is something very different, and so it seems that you're just before you can get the stability here, just using completely the wrong tools.",
                    "label": 0
                },
                {
                    "sent": "But yeah, it's not.",
                    "label": 0
                },
                {
                    "sent": "I I right no no OK, OK but what I'm saying is that this is something that's being done in practice.",
                    "label": 0
                },
                {
                    "sent": "People use K means algorithm.",
                    "label": 0
                },
                {
                    "sent": "People use stability to detect a number of classes.",
                    "label": 0
                },
                {
                    "sent": "I want to tell them you are doing something wrong and I have a proof and now what should be corrected?",
                    "label": 0
                },
                {
                    "sent": "One answer to this.",
                    "label": 0
                },
                {
                    "sent": "We can also do any, I mean many of them holds for any kind of objective function.",
                    "label": 0
                },
                {
                    "sent": "So you something that you don't respect your customer normalized right?",
                    "label": 0
                },
                {
                    "sent": "Because in our we have in our paper we have similar results for a spectral clustering.",
                    "label": 0
                },
                {
                    "sent": "We really some have some kind of.",
                    "label": 0
                },
                {
                    "sent": "Assumptions about what your objective function should satisfy an.",
                    "label": 0
                },
                {
                    "sent": "Under those assumptions, you get those results.",
                    "label": 0
                },
                {
                    "sent": "Do you have any case where you know that the model selection problem has been solved sufficiently?",
                    "label": 0
                },
                {
                    "sent": "But the model of this election problem should now be determined by stability.",
                    "label": 0
                },
                {
                    "sent": "Because I think the your counterexamples boiled down to the to the situation that stability is fooled.",
                    "label": 0
                },
                {
                    "sent": "By by.",
                    "label": 0
                },
                {
                    "sent": "By solving the model selection problem in the wrong right by my answer is that in practice you never have a correct solution to the model.",
                    "label": 0
                },
                {
                    "sent": "I know, but I think this is no, but this is this is a virtual definition you're playing now the theoretician and say in my theory I have this distinction between model selection and the model complexity, and this is in your theory and what I'm saying is if you if you.",
                    "label": 0
                },
                {
                    "sent": "If you assume this agnostic position, then you have to make very clear why you are not attacking a problem.",
                    "label": 0
                },
                {
                    "sent": "Which has already been shown to be unsolvable, namely, the general density is because I don't want to try to end it.",
                    "label": 0
                },
                {
                    "sent": "I don't want to accidentally information I'm doing clustering, which is much, much less.",
                    "label": 0
                },
                {
                    "sent": "Am I am I unable to actually code any density estimation problem in the in terms of a clustering problem?",
                    "label": 0
                },
                {
                    "sent": "When I when I use the degrees of freedom which you give me to define a classroom algorithm, I would I it's not apparent to me that that that that solving the clustering, the cluster clustering design problem.",
                    "label": 0
                },
                {
                    "sent": "Is it easier in any case than the general density estimation?",
                    "label": 0
                },
                {
                    "sent": "I mean, it's not clear to you that it's not OK, but it's not a valid argument.",
                    "label": 0
                },
                {
                    "sent": "Functions on the way you define you.",
                    "label": 0
                },
                {
                    "sent": "You densities well.",
                    "label": 0
                },
                {
                    "sent": "You see what you're trying to tell me is if I try to follow your logic, you think we know the density estimation is hard is impossible.",
                    "label": 0
                },
                {
                    "sent": "Now you tell me that clustering is impossible.",
                    "label": 0
                },
                {
                    "sent": "Now maybe it follows from what we already know, because maybe clustering can be shown to be as hard as that information, but that's maybe we don't know that clustering is as hard as density estimation.",
                    "label": 0
                },
                {
                    "sent": "Do it, do a connected component analysis on the asymptotic densities and you will get always the right number of clusters.",
                    "label": 0
                },
                {
                    "sent": "So use using video setting the right tool to analyze your data and stability will actually tell you exactly when you do that, so this actually goes back to where they wanted.",
                    "label": 0
                },
                {
                    "sent": "The theorem holds also for other objectives, like for example, just to talk about the low density regions order.",
                    "label": 0
                },
                {
                    "sent": "But now as far as matching up with the theorem tells us about doing some stability with their twisted notion.",
                    "label": 0
                },
                {
                    "sent": "Do you have examples there which which also we have such an intuitive notion that actually fits the model of a certain number of clusters and Linux admissibility will tell us something else?",
                    "label": 0
                },
                {
                    "sent": "Because it's something like a means examples, but for another week consumption, yes?",
                    "label": 0
                },
                {
                    "sent": "I've never thought about that.",
                    "label": 0
                },
                {
                    "sent": "I can think.",
                    "label": 0
                },
                {
                    "sent": "I'm sure we can make some up, but I.",
                    "label": 0
                },
                {
                    "sent": "It does not.",
                    "label": 0
                },
                {
                    "sent": "All these examples are fail when we look at this.",
                    "label": 0
                },
                {
                    "sent": "But it's really.",
                    "label": 0
                },
                {
                    "sent": "I see what I'm I'm coming and telling you I'm I have to show you this.",
                    "label": 0
                },
                {
                    "sent": "OK. See I tell you that I have a complete analysis of what stability does and it has never been done before theoretical and you tell me, but you're missing this.",
                    "label": 0
                },
                {
                    "sent": "I know I haven't solved all the world's problems, but I am.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is so let me, I think that the same applies.",
                    "label": 0
                },
                {
                    "sent": "The same applies to other notions of stability.",
                    "label": 1
                },
                {
                    "sent": "So while we prove it, the different notions of stability, I mean as in only conventions, is not only stability and the resampling.",
                    "label": 0
                },
                {
                    "sent": "You can think of stability and the perturbation and different notions of stability.",
                    "label": 0
                },
                {
                    "sent": "Our proof applies at the moment just to resampling stability, but if I look at the intuition behind the proof, I believe that it applies to why the family of notions of stability.",
                    "label": 1
                },
                {
                    "sent": "That's one comment.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To make.",
                    "label": 0
                },
                {
                    "sent": "And the other comment I want to make is that there are two different topics of discussions here and one of them is that we said stability detects the uniqueness of optimal solution and I think part of the argument here was maybe that's the correct answer.",
                    "label": 0
                },
                {
                    "sent": "Maybe it's not the correct answer, so we can argue about is uniqueness of optimal solution a good answer or not?",
                    "label": 1
                },
                {
                    "sent": "But we know now that this is what stability detects.",
                    "label": 0
                },
                {
                    "sent": "The other line of question is what you are raising.",
                    "label": 1
                },
                {
                    "sent": "Our results are symbiotic nature.",
                    "label": 0
                },
                {
                    "sent": "What happens with finite samples?",
                    "label": 0
                },
                {
                    "sent": "And I think these are two separate issues that each of them with wealthier, separate discussion and so for the sense of I don't know.",
                    "label": 0
                },
                {
                    "sent": "I don't remember which is my, which of the two.",
                    "label": 0
                },
                {
                    "sent": "My next slides address.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That same.",
                    "label": 0
                },
                {
                    "sent": "So yeah, about something about the final sample Ness and then I'll talk about something about whether unique solution is the correct notion so clearly.",
                    "label": 0
                },
                {
                    "sent": "But when I make this claim that practice, any data set has a unique clustering minimizer.",
                    "label": 1
                },
                {
                    "sent": "It's this statement may fail if I relax it to almost minimal.",
                    "label": 0
                },
                {
                    "sent": "So in practice, no exactly optimal solution.",
                    "label": 0
                },
                {
                    "sent": "I have only one, but.",
                    "label": 0
                },
                {
                    "sent": "Approximately optimal, I may have several solutions, and so it may be that if we take the sample size is not large enough to detect the difference between the two solutions, then from the point of view of this sample size it will look as if I have two optimums and it will look unstable.",
                    "label": 0
                },
                {
                    "sent": "So in practice.",
                    "label": 0
                },
                {
                    "sent": "It may be the case that where you're in some certain region of samples, you still detect the instability that you are expecting, and only when the samples begin become too much, then everything becomes stable and this is a very strange phenomena in sampling.",
                    "label": 0
                },
                {
                    "sent": "Usually the larger the sample, the better your results and he loving this funny situation where it may be the case that you have some meaningful results for medium sized samples when you increase them.",
                    "label": 0
                },
                {
                    "sent": "Everything becomes trivial, everything becomes stable.",
                    "label": 0
                },
                {
                    "sent": "This is not correct.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "When you go to a syntonix also the dynamic range of the quantity you look at is getting smaller and smaller.",
                    "label": 0
                },
                {
                    "sent": "You notice that the the stability the dynamic range of the stability is changing the scale when you go to the assembly.",
                    "label": 0
                },
                {
                    "sent": "So not only do you get more and more samples, but the signal you measure at the final example is getting smaller when the sample is much larger.",
                    "label": 0
                },
                {
                    "sent": "So what you would like to, but you have to show, is that the ordering.",
                    "label": 0
                },
                {
                    "sent": "Off of my.",
                    "label": 0
                },
                {
                    "sent": "Of different case.",
                    "label": 0
                },
                {
                    "sent": "Compared to the range of this they preserve.",
                    "label": 0
                },
                {
                    "sent": "Crossing over.",
                    "label": 0
                },
                {
                    "sent": "You tell me at between N1 and N25 is the right answer.",
                    "label": 0
                },
                {
                    "sent": "Then between and two and three I get 7 and I have such I have.",
                    "label": 1
                },
                {
                    "sent": "I have such example.",
                    "label": 0
                },
                {
                    "sent": "I have such a sample.",
                    "label": 0
                },
                {
                    "sent": "I have such examples, but I don't have any slides, but we have such examples.",
                    "label": 0
                },
                {
                    "sent": "Weather ordering changes.",
                    "label": 0
                },
                {
                    "sent": "You can have such OK. Yeah.",
                    "label": 0
                },
                {
                    "sent": "So I have such examples when they cross, you can create such examples.",
                    "label": 0
                },
                {
                    "sent": "Yeah, maybe not.",
                    "label": 0
                },
                {
                    "sent": "People mentioned we talked about mentioned maybe not even mentioned in his talk tomorrow.",
                    "label": 0
                },
                {
                    "sent": "We have such examples where things cross.",
                    "label": 0
                },
                {
                    "sent": "When they order crosses.",
                    "label": 1
                },
                {
                    "sent": "And.",
                    "label": 1
                },
                {
                    "sent": "OK, but if you take a practical, practically useful contribution will be to say OK, so the user comes to me and he asked me what is the correct sample size.",
                    "label": 0
                },
                {
                    "sent": "So I tell you if you take M to be 2 much everything trivializes if you take take em to be too small then of course you are susceptible to sampling noise.",
                    "label": 0
                },
                {
                    "sent": "What is the correct MI?",
                    "label": 0
                },
                {
                    "sent": "Don't believe that we can give.",
                    "label": 0
                },
                {
                    "sent": "Any bound which is independent of the data.",
                    "label": 0
                },
                {
                    "sent": "So what practically reject to be able to say is tell the user you should use sample sizes of size of thousands when you want to check stability, it will not be too much, but those sample sizes will vary from them.",
                    "label": 0
                },
                {
                    "sent": "That is set to another and you don't know what your data set when you're doing stability, so I don't believe this will be able to give a satisfactory answer here.",
                    "label": 0
                },
                {
                    "sent": "Ann, you OK?",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And now let me just go to the other issue weather.",
                    "label": 0
                },
                {
                    "sent": "Uniqueness is the correct notion of correct number of clusterings Ann.",
                    "label": 0
                },
                {
                    "sent": "This is source coming work.",
                    "label": 0
                },
                {
                    "sent": "Investigate the notion of cluster ability and how do you measure cluster quality and there are many terms of their many different.",
                    "label": 0
                },
                {
                    "sent": "Conceivable notions, and they don't agree with each other.",
                    "label": 0
                },
                {
                    "sent": "So here are some examples.",
                    "label": 0
                },
                {
                    "sent": "So one of them is clustering super ability, so you look at the ratio between the K means cost.",
                    "label": 0
                },
                {
                    "sent": "Hey, the Caymans cost and the K -- 1 means cost and you say that the data is K clusterable if by going from K -- 1 two K you improve the cost dramatically.",
                    "label": 0
                },
                {
                    "sent": "That's one notion that for saying that K is a good number of clusters.",
                    "label": 0
                },
                {
                    "sent": "That, and this notion, when you apply it, even 2K means on those examples that you don't like that you say that K means is not good for them.",
                    "label": 0
                },
                {
                    "sent": "If you long interval in short interval, you take this notion that tells you by how much do you improve your cost when you go from K to K -- 1, this will detect that the correct number is 2, not 3.",
                    "label": 0
                },
                {
                    "sent": "So it's not that it's impossible to detect based on K means that you're shooting for two when you have two intervals.",
                    "label": 0
                },
                {
                    "sent": "With this kind of measure you can do it.",
                    "label": 0
                },
                {
                    "sent": "This measure has other problems, but that's something that.",
                    "label": 0
                },
                {
                    "sent": "You compare your K -- 1 means cost to your came in scores and you want to see how much of an improvement did you get.",
                    "label": 0
                },
                {
                    "sent": "You look at the ratio between the two.",
                    "label": 0
                },
                {
                    "sent": "And it turns out that when this ratio is big enough, it really indicates the existence of separate clusters in the sense of having low density area between them.",
                    "label": 0
                },
                {
                    "sent": "Not yeah, it's it's.",
                    "label": 0
                },
                {
                    "sent": "It's an interesting measure and it captures much more than you would expect.",
                    "label": 0
                },
                {
                    "sent": "It's a K means is not suitable for this data, so forget about it.",
                    "label": 0
                },
                {
                    "sent": "It does capture something that it can tell you about those examples, yes.",
                    "label": 0
                },
                {
                    "sent": "Is it like in the gap statistic you simply try to figure out?",
                    "label": 0
                },
                {
                    "sent": "Essentially what you do is you plot.",
                    "label": 0
                },
                {
                    "sent": "The K means cost and you want to look, I mean.",
                    "label": 0
                },
                {
                    "sent": "They have a formal procedure for that, but you look at when, how long does it improve and when does it stop to improve, right?",
                    "label": 0
                },
                {
                    "sent": "But here here this is theoretical measure that talks about the optimal clustering.",
                    "label": 0
                },
                {
                    "sent": "You compare the cost of the optimal came in clustering to the optimal course of the K means clustering.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "There's this paper.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "Right, yeah no, it only works for very separated.",
                    "label": 0
                },
                {
                    "sent": "I know, I know, I know only for extremely separate their separation should be.",
                    "label": 0
                },
                {
                    "sent": "Separations will be in the order of 60.",
                    "label": 0
                },
                {
                    "sent": "I mean the ratio between yeah between the ratio between the variants and the distance between them is right.",
                    "label": 1
                },
                {
                    "sent": "It has its problems.",
                    "label": 0
                },
                {
                    "sent": "And another one is the variance.",
                    "label": 1
                },
                {
                    "sent": "Another measure flexibility is the variance within clusters divided by the variance between clusters.",
                    "label": 0
                },
                {
                    "sent": "So there's another measure that people useful stability you look.",
                    "label": 1
                },
                {
                    "sent": "Compare the variance within and between and say if this is big, then I have a meaningful structure.",
                    "label": 1
                },
                {
                    "sent": "And another one is clustering you bartnes robustness to data population.",
                    "label": 0
                },
                {
                    "sent": "So there are several different notions of quality of clustering, not necessarily uniqueness of solution.",
                    "label": 0
                },
                {
                    "sent": "It turns out that all of them are inconsistent with each other.",
                    "label": 0
                },
                {
                    "sent": "They all agree on very nicely separated clusters, but once the clusters become not so nicely separated, they give you different answers.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's all I can say right now, thank you.",
                    "label": 0
                }
            ]
        }
    }
}