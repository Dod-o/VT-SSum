{
    "id": "yvz7h4jt2kvxgg5fombohqbucwu5ynm4",
    "title": "Efficient space-variant blind deconvolution",
    "info": {
        "author": [
            "Stefan Harmeling, Max Planck Institute for Biological Cybernetics, Max Planck Institute"
        ],
        "published": "Jan. 13, 2011",
        "recorded": "December 2010",
        "category": [
            "Top->Mathematics"
        ]
    },
    "url": "http://videolectures.net/nipsworkshops2010_harmeling_esv/",
    "segmentation": [
        [
            "I would like to talk about space Ring planted convolution and how to efficiently implement it and use it in algorithms and the work that I'm presenting is a spin out has been done jointly with my colleagues at Max markets is region tripping.",
            "So."
        ],
        [
            "First question, So what is space variant convolution?",
            "You're probably all familiar with the usual convolution."
        ],
        [
            "The so called space invariant convolution, which basically says suppose X is some image and why some observed image, then the pixel value at some location is a linear combination of local pixel values in the original image.",
            "OK and The thing is, these coefficients ease that determines a linear combinations are the same all over the place.",
            "So in any location of the image basically are performing the same operation and so these A is called space invariant point spread function.",
            "So why is it called a function?",
            "Let's say your image is like a continuous image.",
            "In that sense, it's actually a function of the location in the image, but in this case this is the kind of simple point spread function, so it doesn't depend on the location in Y. OK, so now."
        ],
        [
            "To have space variant convolution, basically now this filter coefficients depend not only on the summation variable, but also on the location in the observed image OK and Now B is quite a space variant points function.",
            "Now it is really a function of the location in the observed image.",
            "OK, because now it depends.",
            "Depends on where."
        ],
        [
            "Where you are and why?",
            "And now suppose we have some observed image.",
            "Why then, as I said, X is usually the true underlying image that we would like to recover, and what's important for this kind of model to set the point spread functions when disguise by Jay will fully describe how excess transform.",
            "So for example, you have a photo camera or you have some other optical systems and basically the optical system is fully described by the point spread functions.",
            "And for the physicists among users is basically the greens function OK?"
        ],
        [
            "So now let's first look at some examples of why is it relevant to consider space variant convolutions?",
            "Why not just use the usual convolution space in very?"
        ],
        [
            "So here are some examples.",
            "So suppose you take an image with a long exposure time and you're not using a flash.",
            "Then usually what you will do, you will shake the camera when you don't have a tripod, and in that case you will blur the image and unfortunately in different regions of the image deblur will be different, so it's spatially invariant, especially variant.",
            "So the simple reason is suppose if you're an expert camera shakers and you would really shake the camera only in one plane and you would not do any rotations.",
            "But there's a pure model camera Shaker said will also put rotations on it with this rotation.",
            "We have spatially varying blurs on the image and to convince you that this is really true, we perform."
        ],
        [
            "Want some experiments in the lab so we built this nice device with some Eli D array OK and we did real handshakes of real shaking images of this device and with the lid.",
            "So actually if so if it would be a sharp image then this would be all single leads.",
            "But now as you can see in different parts.",
            "Of this panel there is a blur.",
            "Looks very different.",
            "OK, but the other thing to observe here said it's really smoothly varying, so it's not like abruptly changing and this is something that we will use in our efficient implementation of space variant convolution.",
            "That's a blur, smoothly varying.",
            "Why is it not all the same?",
            "So another example is supposed to have a camera and you just rotate it around the center.",
            "Then the center dot will be sharp, but the further you go outside, the longer will be your trail that you generate.",
            "And here's the same thing.",
            "So depending on where I am and how I rotate and move the camera like I will generate different shapes at different locations.",
            "OK."
        ],
        [
            "So here's another example.",
            "For example, it can be very small support, and here's the point.",
            "Function is a very large report, so those and our goal is to recover such kind of blurs.",
            "Of course, we're looking at smaller blocks, but in principle we would like to recover an image that has been."
        ],
        [
            "Destroyed by such blurs.",
            "So here's another example.",
            "We also did recently some work on Lens aberration.",
            "So basically the point spread function describes also the lens right?",
            "And so if your lenses, chromatic aberrations or at spherical aberrations of whatever operational ends can have, it is fully described by the point spread function OK, and we have made a method where we can we measure the properties of the lens and then we try to recover the image and we would try to figure out the limits of our method.",
            "So we built a lens which is only a single piece of glass in there, so there's only a single lens.",
            "So if you take images with."
        ],
        [
            "Such a camera they really look crappy, so they might be sharp in the center that sits in on an EOS 5D, so it has a good order focus but like going towards the corners.",
            "Everything like it's totally distorted and it's also differently distorted in the different color channels because of chromatic aberration.",
            "So that's really a tough problem and they tend to talk.",
            "I will show you results what we can recover from such an image."
        ],
        [
            "So this is the point spread function of a lens operation.",
            "So as you can see towards the corner you see these wings OK."
        ],
        [
            "In the center at Sharp this is."
        ],
        [
            "An exaggerated version.",
            "Here's another image.",
            "Another example.",
            "We are also looking at air turbulence, so we are actually starting these projects by looking at looking through telescope and then having like the atmospheric turbulence.",
            "Isn't that what we want to get rid of?",
            "So this is now a multiframe situation.",
            "Then basically here we wanted to have a simulated air turbulence.",
            "We went up on the roof and the photographs of the exhaust wind of our air conditioning system and we got this nice blurry wobbling around sequence of images.",
            "And the good thing in this situation is we can get a ground truth image, right?",
            "But just.",
            "Shutting off the air conditioning and so I will show you later results in this data set."
        ],
        [
            "So now, assuming that the point spread function is this, this is smoothly running across the image.",
            "How can we implement space Ryan convolution?"
        ],
        [
            "Sufficiently.",
            "And for that, let's first look at a similar problem.",
            "So let's revisit time invariant convolution.",
            "So why now time in principle be interested in space?",
            "But if we talk about 1 dimensional signal, then we would now say it's at time invariant convolution.",
            "OK, so let's look how is."
        ],
        [
            "Time invariant, convolution done then basically the usual way to do it.",
            "So let's ignore the formula for a second.",
            "I just say it in words you gota Fria space.",
            "With your signal you go to full space with your kernel.",
            "You don't multiply and you go back.",
            "And that's not exactly written in our notation over here.",
            "And why am I bothering with this notation?",
            "Because it will show you later how to implement our space variant convolution.",
            "So when you understand this and you'll immediately could also reimplement the stuff that we were doing.",
            "So basically what it's saying is all our signals are 1D vector, so X is 1.",
            "The vector.",
            "We take the full transform.",
            "And you take, you don't multiply it with zero padded version.",
            "Taking the full transform of the filter and then you take the inverse Fourier transform into dropouts are valid part, and that's the recorded signal.",
            "OK, this is the usual convolution.",
            "It's time invariant, so the whole signal we blurred with the same."
        ],
        [
            "Now this is a.",
            "This is a great thing to do it in log and all this stuff is fully magic, but unfortunately it is still inefficient if X is very long audio signal.",
            "For example in the filter is short because you have 0 pets, a filter A to the same length as X and then the free trial."
        ],
        [
            "It's very expensive, but Luckily in 1966 Thomas Occam came up with the idea of high speed convolution and correlation and basically."
        ],
        [
            "But what he's doing is he's invented the overlap add method, which is basically chopping up the long signal into pieces and then doing the full trick on each of the pieces."
        ],
        [
            "We know in our notation this reads like this.",
            "So instead of having one big expression or we have a sum of expression where we have an additional matrix, it's shops out one piece of the X and later on we need to glue it together.",
            "OK now this is a representation of the overlap add."
        ],
        [
            "So now how do we get from time invariant to time variant?"
        ],
        [
            "Evolution, and there was a work by Jondel in 1977.",
            "He proposed basically the short time for you transform and so taking the short time to retransform is called analysis.",
            "So you get like an analysis of your signal and then you can modify it like you can put filters on the different parts that you get and then you can synthesize it back again so."
        ],
        [
            "How does this look in our notation?",
            "So I've just rewritten the stuff on the previous slide and so the back part here.",
            "So the X transform it into the full space, like dropping up in pieces of the analysis part and then filtering it is a modification part and this is the synthesis part.",
            "OK, so this is just stockings overlap.",
            "Add it's just a few short time Fourier transform."
        ],
        [
            "What is this instances?",
            "But now the difference that they did to get a time variant filtering is that they use different filters for the different patches.",
            "OK, so the filter here depends on the Patch that you're looking at at the segment."
        ],
        [
            "And the other important things that you need to do.",
            "You need to put here some waiting here.",
            "So you want to smoothly wait in smoothly fade in and out the segments."
        ],
        [
            "OK, now having having now now we what we have shown you is how to get from time invariant filter.",
            "Two time variant filter.",
            "Now how do we get to space variant?"
        ],
        [
            "Convolution, there was a paper in 1984.",
            "Basically generalize this time invariant subspace invariants.",
            "OK, it was nicely written with typewriters in that time.",
            "It's an icast paper and."
        ],
        [
            "Basically what they were doing in our notation is.",
            "Exactly the same thing that we had before, but now."
        ],
        [
            "Instead of implementing this.",
            "With 1D operations, you implement this with studio operations OK, and then you have.",
            "Then you basically have the same thing for images that stocking introduced for one dimensional signals.",
            "So now here comes the beauty of this notation.",
            "So basically, how do we now implement this?",
            "Super Duper inloggen algorithms?",
            "You just read it from right to left and you do the 2D operation, so the cropping now must be a 2D crop.",
            "The zero padding here must be a 2D zero padding.",
            "The full Transformers 2 default transform and so forth, and then you have your algorithm.",
            "Let's say you are working in Krayem were having some molecule data.",
            "You can also use the same formula.",
            "Get your 3D algorithms or your 40 algorithms, so that's convenient here.",
            "So in our notation that's not so much different here but now."
        ],
        [
            "The plug in now there's a trick of Alan basically putting different filters at different locations and having different ways at different locations.",
            "Now we get space varying convolution OK."
        ],
        [
            "And so again, here's a cartoon of our space varying convolution.",
            "How we do it.",
            "So basically we start with some image X up here and we need to chop it into overlapping pieces.",
            "So those are the overlapping pieces and then we fade out and in these patches so that the overlap gets nicely and smoothly faded in and out.",
            "We filter the different patches with different filters and finally we do everything together and we have our space varying convolution.",
            "Of course for such an approximation to be like a good approximation of a real PSF.",
            "Assumption is always it's a PSF is mostly varying across the image, so we can't have abrupt changes, but."
        ],
        [
            "Many applications, that's fine.",
            "Now, OK, great, so we have to start this gigantics matrix A and let's say you have like a lazy programming language and you would have all these matrices implemented in a lazy fashion.",
            "Then you can now just write down this stuff and it will be your code for the forward model.",
            "OK, but similarly we can also exchange roles of X and a so we can stack all these filters a into a big vector called a without 9 indexing.",
            "And we exchanged the role of A and X and here now we see that this whole expression is also linear from the perspective of A of the filter.",
            "Efficients and this gives us some matrix capital X.",
            "So now we have like our forward model can be written in two ways, either as a linear expression in terms of the EXO as a linear expression in terms of the A."
        ],
        [
            "So now for these fast vector multiplications, I told you already too fast vector modulation for A and X will implement this stuff from right to left.",
            "But now I'm blind convolution and non branded convolution also needs the gradients.",
            "Usually usually offer these query expression and there you also need the A transpose and the X transpose.",
            "And how do you do that?",
            "So if you figure that out by hand with indexing or double indices then you won't get anywhere but in this case in this rotation or just read it from left to right and you implement it with your 2D operations from left to right and you immediately get your.",
            "And look and implementations for a transport index, transpose.",
            "And again if you have a fancy programming language with lazy evaluation, you get it basically for free.",
            "It can do it symbolically, right?"
        ],
        [
            "OK. We are interested in."
        ],
        [
            "In space variant."
        ],
        [
            "Convolution, now I'm showing you some what it is is I basically repeat what it is and what we need for it, but only for the single image case.",
            "So in the non blinding convolution the task is that given an observed image Y and the filters for the different patches, so it's not online.",
            "So we know the filters already recover their true image X. OK so we have all this information we traveled want to recover the trim it X Now as I showed you, the forward model is linear in X.",
            "So if you have some lease square expression or something.",
            "Basically what you need to calculate the.",
            "Gradients is you need fast matrix vector multiplications with A and a transpose, which I just showed you in the previous slide.",
            "How to do it and?"
        ],
        [
            "And log in.",
            "So now for the blind convolution task, it's slightly more difficult, so here you're only given the blurry image and you want to recover the true image X.",
            "But this is single now.",
            "No it's still there then, but you also possibly have to estimate the filters.",
            "I mean, we're not interested in the filters, but if you have some then you can apply the non blind deconvolution.",
            "So this is now a much harder problem and you will get expressions with Aleve for the least square term in terms of A and in terms of eggs.",
            "So now we also need the X&X transposed operation.",
            "OK, but I showed you on the previous slide.",
            "Do it fast."
        ],
        [
            "Now what I like properties of our space, right?"
        ],
        [
            "Convolution, as I already said, the runtime precisely is like N log N and depending on the amount of overlap it will be a bit more.",
            "So let's say every pixel is is dead by dealt with by three overlapping patches and you will have a factor of three in this formula, but it's very mild compared to other approximation to this thing.",
            "So actually it's not much slower than the usual convolution.",
            "So of course algorithms will run much slower because you have many more parameters.",
            "Now you don't have one blur kernel, but you have maybe like 20 blur kernel, so there's of course some cost.",
            "Plus the additional flexibility, but in principle the forward operation is as fast as the usual convolution."
        ],
        [
            "Now OK, is it really expressive or not?",
            "Now?",
            "The one question that I'm often asked is now is his point function.",
            "At the end piecewise constant?",
            "So like droppings, image into patches and having a different broker neutral for image and the answer is."
        ],
        [
            "No, because we choose the patches to overlap and the more overlap you have, the more flexibly appointment function becomes.",
            "So one way to view it is at this point spread function can be seen like being approximated by a spline.",
            "OK, so each on each of the Patch have a control point, which in this case is a blur kernel and the resulting point spread functions overall will be like living in some spline words, so it's like a smoothly interpolated points."
        ],
        [
            "Function.",
            "Next question."
        ],
        [
            "So is it piecewise linear?",
            "That depends entirely on your window function.",
            "So if you take like a triangular window functions and it will be piecewise linear.",
            "But if you choose nonlinear window functions and you will be fine.",
            "So then it's really something."
        ],
        [
            "Something more fancy, so is a differentiable allow."
        ],
        [
            "The image yes, also that can be achieved if you choose a window functions carefully.",
            "Basically that's a Windows function Rolex, mostly to zero and smoothly meet."
        ],
        [
            "Shazzam OK, what else?",
            "Again I want to point out the limitation.",
            "So the true point spread function must try only smoothly, otherwise we will get artifacts.",
            "OK, so an easy way to see that why that's the case.",
            "Suppose we have two patches and one purchase like a Delta P on one side and another Patch as a Delta peak on the other side.",
            "Now if you linearly interpolate between them in the in the middle, you will have two peaks, so you will get an echo image.",
            "So what you want to make sure when you apply this stuff that between patches the point spread functions of the blur kernels are only.",
            "Making small changes and then the approximation is very good."
        ],
        [
            "OK, here's an example.",
            "So this is one of our real camera shakes that we took with our fantastic device, and here's an approximation where we use the three by three grid or filters and basically nearly interpolated between these filters.",
            "OK, and as you can see, like we get a lot of variation, even that we're only losing using like 3 by three filters and we get a good approximation to the true camera shake.",
            "Of course, if you do really some really crazy shaped because you want to break our system, then you have to use more than you have to use more control points like in this blind language.",
            "OK, and then you can also do that, but of course there's a limit with your data might only have a mega pixel and then you don't want to use too many black kernels because you have no chance to estimate them.",
            "So there's a usual trade off."
        ],
        [
            "OK, at the beginning I showed you a video where there was cycle is blurry to air turbulence and I will show you the results where we applied some online blind deconvolution method for multi frames to this method.",
            "But now we use it with the space specially varying blur kernels and I hope this works yes.",
            "So what you see is this is the raw sequence and in the middle we see the reconstruction it as you see already after a few frames like the image looks almost like the ground truth.",
            "OK and if you want I can show you offline a couple of more videos like this.",
            "So it's really surprising after few frames it will recover the true image and actually on another sequence something surprising happens.",
            "The reconstruction actually looks better than the ground truth image, and the reason is of course like having 100 crappy images is better than only having one sharp image.",
            "So there's more information in these 100 images, possibly then in this one true image.",
            "So this suggests it.",
            "You can also use this scheme together with super resolution, something that we've tried.",
            "I don't have control your pictures, but since this is all linear.",
            "You can also plug in some additional downsampling operators into the model and you will have immediately super resolution with the same algorithm.",
            "Then for spatially wranglers."
        ],
        [
            "So here's again, I will shake an image and we this is now this this years on this new snips work.",
            "So some of you might have seen it already."
        ],
        [
            "My poster.",
            "We are able to recover it and having in different locations so you see is a number plate.",
            "It's now sharp.",
            "L is a different location up here this.",
            "The scale to become sharp or here.",
            "Alright, so it's a lamp.",
            "And so this is how much more flexible than having a single blur kernel.",
            "So there's a state of the art method."
        ],
        [
            "Single image plant deconvolution and of course the images taken with a nonstationary blur.",
            "So this method must fail right?",
            "Because it's assuming a single blur kernel for the whole image.",
            "But just to show you that it's you can't just solve it with the usual convolution, you need really the space, specially variants."
        ],
        [
            "OK, so last example.",
            "So this is a picture we've seen at the beginning that we took with this self Woodlands which only had a single piece of glass and I would like to show you the reconstruction."
        ],
        [
            "This this is a reconstruction that we get with our algorithm and I would like to stress here that in this application, basically, since we have the lens, we measure it with an artificial star.",
            "So we have some set up in our basement in some 10 meter long room where we can put an artificial style where we can make sure that it should be only a single picture on the ship.",
            "But due to the blur of the lens, basically it gets like washed out and by this we can really measure the point spread function very precisely for the different locations on the center and.",
            "Then basically we are using the non blind deconvolution with this framework to recover the image."
        ],
        [
            "Once again doing it back and forth.",
            "So here we see actually on a higher resolution you would see that in different color channels is differently blur."
        ],
        [
            "And will be able to.",
            "They all align nicely once they are recovered with riot points, but Funk."
        ],
        [
            "Of course yes.",
            "Lots of related work, and as usual you do your work or you have your problem.",
            "You come up with your solution and then you look into the literature.",
            "So now what have been other people been doing right?",
            "I mean actually you often do it the other way around, but the problem is often that you don't understand the literature before you thought about the problem yourself, so there is related work and but it's all a little bit different.",
            "So there are some work by Negan.",
            "Door Leary from 98 also do space rank deconvolution with a similar approach.",
            "But they only use rectangular.",
            "Triangular windows, so there are some tricks to make it work for these nonlinear windows, so you have to be careful in choosing an right normalization, otherwise you get artifact and also they don't have fast implementation for X&X transpose, so they can only do the non blind deconvolution.",
            "The counters aplenty convolution and recently there was a lot of interest, income and interest in camera shake and so in 2009 there's a tech report by Tien colleagues with a projective motion path model where they basically tried to model the path that the camera is taken and then integrating the images that you see.",
            "And this is also model which will produce space Wrangler, but it's only for camera shake, so you can't use it for lens correction for example.",
            "And you can also apply to air turbulence.",
            "Similarly recent work by YT and Goopta.",
            "Basically they're using a similar approach as Thai.",
            "Sing some ography tricks.",
            "Again, this is only for camera shake.",
            "Then there's a recent See graph publication from Yoshi and I and what they did.",
            "They glue to actually meet a ransom gyroscopes with a camera, and so they record basically is the trajectory of the camera, and from that they're able to reconstruct the point spread function, which is quite amazing that you can do that.",
            "It's a big engineering effort, but again I would like to stress this model is only for camera shake.",
            "It's not for the for the general problem of approximating point spread functions."
        ],
        [
            "So anyway, so I'm not sure I'm on time, yeah?"
        ],
        [
            "So he's already is a summary, So what I would like to show you what's an efficient way to implement space Rang convolution?",
            "Basically the idea.",
            "So how we came up with this idea where based on this overlap add idea of stock him and short space free analysis and synthesis of jondel and and we did it in a way that it can be written default model as a matrix vector multiplication.",
            "And maybe I didn't add a slide on this, but so why were we so eager to write it like this?",
            "The main reason is 'cause there are so many algorithms already out there for the usual convolution and we just want to recycle them.",
            "So we just want to.",
            "Like in a different fast matrix vector multiplication and then immediately turns it into some spatially varying version of it.",
            "For example, for blind deconvolution work we use the algorithm of true entry, which is the state of the art for space invariant convolution.",
            "Then with some additional tricks and tweaking we get a version with these matrix vector multiplications.",
            "Now for the space variant case.",
            "Similarly we are using last year's NIPS method from Krishnan Fergus, which I think if not the state of the art method for non blind deblurring and just by replacing these operations we get immediately.",
            "Especially variant deconvolution method.",
            "I hope I convince you that these operations can be done all very fast and this allows us to to generalize many existing algorithm."
        ],
        [
            "So I showed you results for removing space rain blurs with camera shake, lens aberrations and air turbulence."
        ],
        [
            "And but we have many more applications, so we did work on atmospheric turbulence.",
            "So we have image sequences from the Moon where the atmosphere with the different layers of AI is producing some, some spackle blur, and we're currently working also on microscopies.",
            "Or there's confocal microscopy where we have definitely Wrangler and in principle it approximately should fit our model, and we also have some experiments with biomedical data where you have like MRI sequence, where you basically want to get rid of like object motion.",
            "And also probably of like.",
            "Little deformations of the image across during the recording process.",
            "So nonrigid registration, because in principle can also do nonrigid registration with it, because it's just like an optical system in a way, right you just stored locally the points differently, and this can be expressed in our framework.",
            "If it."
        ],
        [
            "This movie Brian.",
            "OK, thank you very much.",
            "Question.",
            "Yeah.",
            "Right?",
            "Online because of my mental conditions change.",
            "Yes.",
            "Correct, yeah?",
            "So right now we are having.",
            "Processing the data offline.",
            "I mean we have an algorithm which we called online because it looks at each frame only ones, but we haven't run it like black your camera onto the telescope and then look on your screen how the picture gets better.",
            "So we haven't done that, but we're about to do that.",
            "One of my colleagues, they implemented our operations on a GPU and so that you can do these updates now, really fast, and so we are hoping that you can do it like in real time.",
            "OK.",
            "Emergency landing.",
            "OK.",
            "Right, right?",
            "Yeah, yeah, that's a very nice application.",
            "So yeah, I'd like to discuss it.",
            "So I think in principle it is possible because this forward operation is very fast.",
            "And of course there are many parameters to estimate, so maybe you really have to do some GPU massage ING, but I guess it can be done and maybe if it can't be done now then maybe in two years so.",
            "OK.",
            "Feels right.",
            "OK, actually it is interesting that you pointed out there's a challenge to great Ten challenge which you might have known that.",
            "So that's a change of the Pascal network, and it's exactly on gravitational lensing, and so the problem, say looking there at is that if you take a picture of the Sky with a wide angle lens, then basically will have different blur in different locations of the Sky, right?",
            "So the technical term is set is beyond the isoperimetric Patch, and so in that case it's really you have the style and the left side will have a very different specular patterns and this down the right side on this, exactly a challenge.",
            "On this topic, where we've of course hope to find the student who applies or method to this challenge.",
            "OK, yeah, but think about this in the limit patches just continuously everywhere.",
            "Change and.",
            "So it's pretty much almost a black box type thing.",
            "I wonder how critical this chunking office, that I mean in the I mean.",
            "In the limit there is no chunking up into patches, just continuous kind of changing the window.",
            "Or you could be a window.",
            "I mean, how critical is that?",
            "So in principle I guess the on the one extreme UFC identity transformation, right?",
            "So your vector goes in and it goes out and in the other extreme case really have a dense matrix between it.",
            "So you really have a dense matrix vector multiplication that then has a full flexibility for any pixel it can use.",
            "Any other pixel and use all the combinations.",
            "And somehow we are now in between with this kind of thing and there are some obvious generalization to our work, so right now we're using like patches which have the same size and which are like equally.",
            "Located but on this one rotational blur that I showed you there were like on the top left there were small blur kernels and on the bottom right we had very large blur kernels, so this can be very simply actually generalized to like arbitrary Patch sizes.",
            "So you could have like larger page sizes in areas where you know the blur kernel is more smooth and you have smaller pitch sizes where you know the blur kernel is more rapidly changing.",
            "And similarly you can have larger blur kernels where you know the blur is very large and smaller blur kernels.",
            "Where the blue is very small, so in principle there's like a whole continuum of things that you could try.",
            "In the box.",
            "Yeah, but in each pet see if it 50 could have a different size, so that should be fine.",
            "Multiscale yeah right yeah one could think of like this I don't know some quadtree approximation to the true PSF right?",
            "First take 1.5 one kernel for the whole image and then you look out with the fit is you drop it into four pieces.",
            "You kind of recursively go down.",
            "So one could think of these kind of algorithms that should be possible.",
            "Then yes, we will be about to finish this tool box with the GPU stuff and actually we were planning to release some code for this too, but it's not done yet.",
            "And so it will be beginning of the next year.",
            "I guess we thank the speaker again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I would like to talk about space Ring planted convolution and how to efficiently implement it and use it in algorithms and the work that I'm presenting is a spin out has been done jointly with my colleagues at Max markets is region tripping.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "First question, So what is space variant convolution?",
                    "label": 0
                },
                {
                    "sent": "You're probably all familiar with the usual convolution.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The so called space invariant convolution, which basically says suppose X is some image and why some observed image, then the pixel value at some location is a linear combination of local pixel values in the original image.",
                    "label": 0
                },
                {
                    "sent": "OK and The thing is, these coefficients ease that determines a linear combinations are the same all over the place.",
                    "label": 0
                },
                {
                    "sent": "So in any location of the image basically are performing the same operation and so these A is called space invariant point spread function.",
                    "label": 0
                },
                {
                    "sent": "So why is it called a function?",
                    "label": 0
                },
                {
                    "sent": "Let's say your image is like a continuous image.",
                    "label": 0
                },
                {
                    "sent": "In that sense, it's actually a function of the location in the image, but in this case this is the kind of simple point spread function, so it doesn't depend on the location in Y. OK, so now.",
                    "label": 1
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To have space variant convolution, basically now this filter coefficients depend not only on the summation variable, but also on the location in the observed image OK and Now B is quite a space variant points function.",
                    "label": 1
                },
                {
                    "sent": "Now it is really a function of the location in the observed image.",
                    "label": 0
                },
                {
                    "sent": "OK, because now it depends.",
                    "label": 0
                },
                {
                    "sent": "Depends on where.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Where you are and why?",
                    "label": 0
                },
                {
                    "sent": "And now suppose we have some observed image.",
                    "label": 0
                },
                {
                    "sent": "Why then, as I said, X is usually the true underlying image that we would like to recover, and what's important for this kind of model to set the point spread functions when disguise by Jay will fully describe how excess transform.",
                    "label": 1
                },
                {
                    "sent": "So for example, you have a photo camera or you have some other optical systems and basically the optical system is fully described by the point spread functions.",
                    "label": 0
                },
                {
                    "sent": "And for the physicists among users is basically the greens function OK?",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now let's first look at some examples of why is it relevant to consider space variant convolutions?",
                    "label": 0
                },
                {
                    "sent": "Why not just use the usual convolution space in very?",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here are some examples.",
                    "label": 0
                },
                {
                    "sent": "So suppose you take an image with a long exposure time and you're not using a flash.",
                    "label": 0
                },
                {
                    "sent": "Then usually what you will do, you will shake the camera when you don't have a tripod, and in that case you will blur the image and unfortunately in different regions of the image deblur will be different, so it's spatially invariant, especially variant.",
                    "label": 0
                },
                {
                    "sent": "So the simple reason is suppose if you're an expert camera shakers and you would really shake the camera only in one plane and you would not do any rotations.",
                    "label": 0
                },
                {
                    "sent": "But there's a pure model camera Shaker said will also put rotations on it with this rotation.",
                    "label": 0
                },
                {
                    "sent": "We have spatially varying blurs on the image and to convince you that this is really true, we perform.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Want some experiments in the lab so we built this nice device with some Eli D array OK and we did real handshakes of real shaking images of this device and with the lid.",
                    "label": 0
                },
                {
                    "sent": "So actually if so if it would be a sharp image then this would be all single leads.",
                    "label": 0
                },
                {
                    "sent": "But now as you can see in different parts.",
                    "label": 0
                },
                {
                    "sent": "Of this panel there is a blur.",
                    "label": 0
                },
                {
                    "sent": "Looks very different.",
                    "label": 0
                },
                {
                    "sent": "OK, but the other thing to observe here said it's really smoothly varying, so it's not like abruptly changing and this is something that we will use in our efficient implementation of space variant convolution.",
                    "label": 0
                },
                {
                    "sent": "That's a blur, smoothly varying.",
                    "label": 0
                },
                {
                    "sent": "Why is it not all the same?",
                    "label": 0
                },
                {
                    "sent": "So another example is supposed to have a camera and you just rotate it around the center.",
                    "label": 0
                },
                {
                    "sent": "Then the center dot will be sharp, but the further you go outside, the longer will be your trail that you generate.",
                    "label": 0
                },
                {
                    "sent": "And here's the same thing.",
                    "label": 0
                },
                {
                    "sent": "So depending on where I am and how I rotate and move the camera like I will generate different shapes at different locations.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's another example.",
                    "label": 0
                },
                {
                    "sent": "For example, it can be very small support, and here's the point.",
                    "label": 0
                },
                {
                    "sent": "Function is a very large report, so those and our goal is to recover such kind of blurs.",
                    "label": 0
                },
                {
                    "sent": "Of course, we're looking at smaller blocks, but in principle we would like to recover an image that has been.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Destroyed by such blurs.",
                    "label": 0
                },
                {
                    "sent": "So here's another example.",
                    "label": 0
                },
                {
                    "sent": "We also did recently some work on Lens aberration.",
                    "label": 0
                },
                {
                    "sent": "So basically the point spread function describes also the lens right?",
                    "label": 0
                },
                {
                    "sent": "And so if your lenses, chromatic aberrations or at spherical aberrations of whatever operational ends can have, it is fully described by the point spread function OK, and we have made a method where we can we measure the properties of the lens and then we try to recover the image and we would try to figure out the limits of our method.",
                    "label": 0
                },
                {
                    "sent": "So we built a lens which is only a single piece of glass in there, so there's only a single lens.",
                    "label": 0
                },
                {
                    "sent": "So if you take images with.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Such a camera they really look crappy, so they might be sharp in the center that sits in on an EOS 5D, so it has a good order focus but like going towards the corners.",
                    "label": 0
                },
                {
                    "sent": "Everything like it's totally distorted and it's also differently distorted in the different color channels because of chromatic aberration.",
                    "label": 0
                },
                {
                    "sent": "So that's really a tough problem and they tend to talk.",
                    "label": 0
                },
                {
                    "sent": "I will show you results what we can recover from such an image.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is the point spread function of a lens operation.",
                    "label": 0
                },
                {
                    "sent": "So as you can see towards the corner you see these wings OK.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the center at Sharp this is.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "An exaggerated version.",
                    "label": 0
                },
                {
                    "sent": "Here's another image.",
                    "label": 0
                },
                {
                    "sent": "Another example.",
                    "label": 0
                },
                {
                    "sent": "We are also looking at air turbulence, so we are actually starting these projects by looking at looking through telescope and then having like the atmospheric turbulence.",
                    "label": 0
                },
                {
                    "sent": "Isn't that what we want to get rid of?",
                    "label": 0
                },
                {
                    "sent": "So this is now a multiframe situation.",
                    "label": 0
                },
                {
                    "sent": "Then basically here we wanted to have a simulated air turbulence.",
                    "label": 1
                },
                {
                    "sent": "We went up on the roof and the photographs of the exhaust wind of our air conditioning system and we got this nice blurry wobbling around sequence of images.",
                    "label": 0
                },
                {
                    "sent": "And the good thing in this situation is we can get a ground truth image, right?",
                    "label": 0
                },
                {
                    "sent": "But just.",
                    "label": 0
                },
                {
                    "sent": "Shutting off the air conditioning and so I will show you later results in this data set.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now, assuming that the point spread function is this, this is smoothly running across the image.",
                    "label": 0
                },
                {
                    "sent": "How can we implement space Ryan convolution?",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sufficiently.",
                    "label": 0
                },
                {
                    "sent": "And for that, let's first look at a similar problem.",
                    "label": 0
                },
                {
                    "sent": "So let's revisit time invariant convolution.",
                    "label": 0
                },
                {
                    "sent": "So why now time in principle be interested in space?",
                    "label": 0
                },
                {
                    "sent": "But if we talk about 1 dimensional signal, then we would now say it's at time invariant convolution.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's look how is.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Time invariant, convolution done then basically the usual way to do it.",
                    "label": 0
                },
                {
                    "sent": "So let's ignore the formula for a second.",
                    "label": 0
                },
                {
                    "sent": "I just say it in words you gota Fria space.",
                    "label": 0
                },
                {
                    "sent": "With your signal you go to full space with your kernel.",
                    "label": 0
                },
                {
                    "sent": "You don't multiply and you go back.",
                    "label": 0
                },
                {
                    "sent": "And that's not exactly written in our notation over here.",
                    "label": 0
                },
                {
                    "sent": "And why am I bothering with this notation?",
                    "label": 0
                },
                {
                    "sent": "Because it will show you later how to implement our space variant convolution.",
                    "label": 0
                },
                {
                    "sent": "So when you understand this and you'll immediately could also reimplement the stuff that we were doing.",
                    "label": 0
                },
                {
                    "sent": "So basically what it's saying is all our signals are 1D vector, so X is 1.",
                    "label": 0
                },
                {
                    "sent": "The vector.",
                    "label": 0
                },
                {
                    "sent": "We take the full transform.",
                    "label": 0
                },
                {
                    "sent": "And you take, you don't multiply it with zero padded version.",
                    "label": 0
                },
                {
                    "sent": "Taking the full transform of the filter and then you take the inverse Fourier transform into dropouts are valid part, and that's the recorded signal.",
                    "label": 0
                },
                {
                    "sent": "OK, this is the usual convolution.",
                    "label": 0
                },
                {
                    "sent": "It's time invariant, so the whole signal we blurred with the same.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now this is a.",
                    "label": 0
                },
                {
                    "sent": "This is a great thing to do it in log and all this stuff is fully magic, but unfortunately it is still inefficient if X is very long audio signal.",
                    "label": 1
                },
                {
                    "sent": "For example in the filter is short because you have 0 pets, a filter A to the same length as X and then the free trial.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's very expensive, but Luckily in 1966 Thomas Occam came up with the idea of high speed convolution and correlation and basically.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But what he's doing is he's invented the overlap add method, which is basically chopping up the long signal into pieces and then doing the full trick on each of the pieces.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We know in our notation this reads like this.",
                    "label": 1
                },
                {
                    "sent": "So instead of having one big expression or we have a sum of expression where we have an additional matrix, it's shops out one piece of the X and later on we need to glue it together.",
                    "label": 1
                },
                {
                    "sent": "OK now this is a representation of the overlap add.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now how do we get from time invariant to time variant?",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Evolution, and there was a work by Jondel in 1977.",
                    "label": 0
                },
                {
                    "sent": "He proposed basically the short time for you transform and so taking the short time to retransform is called analysis.",
                    "label": 0
                },
                {
                    "sent": "So you get like an analysis of your signal and then you can modify it like you can put filters on the different parts that you get and then you can synthesize it back again so.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How does this look in our notation?",
                    "label": 0
                },
                {
                    "sent": "So I've just rewritten the stuff on the previous slide and so the back part here.",
                    "label": 0
                },
                {
                    "sent": "So the X transform it into the full space, like dropping up in pieces of the analysis part and then filtering it is a modification part and this is the synthesis part.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is just stockings overlap.",
                    "label": 0
                },
                {
                    "sent": "Add it's just a few short time Fourier transform.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What is this instances?",
                    "label": 0
                },
                {
                    "sent": "But now the difference that they did to get a time variant filtering is that they use different filters for the different patches.",
                    "label": 0
                },
                {
                    "sent": "OK, so the filter here depends on the Patch that you're looking at at the segment.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the other important things that you need to do.",
                    "label": 0
                },
                {
                    "sent": "You need to put here some waiting here.",
                    "label": 0
                },
                {
                    "sent": "So you want to smoothly wait in smoothly fade in and out the segments.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, now having having now now we what we have shown you is how to get from time invariant filter.",
                    "label": 0
                },
                {
                    "sent": "Two time variant filter.",
                    "label": 0
                },
                {
                    "sent": "Now how do we get to space variant?",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Convolution, there was a paper in 1984.",
                    "label": 0
                },
                {
                    "sent": "Basically generalize this time invariant subspace invariants.",
                    "label": 0
                },
                {
                    "sent": "OK, it was nicely written with typewriters in that time.",
                    "label": 0
                },
                {
                    "sent": "It's an icast paper and.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Basically what they were doing in our notation is.",
                    "label": 0
                },
                {
                    "sent": "Exactly the same thing that we had before, but now.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Instead of implementing this.",
                    "label": 0
                },
                {
                    "sent": "With 1D operations, you implement this with studio operations OK, and then you have.",
                    "label": 0
                },
                {
                    "sent": "Then you basically have the same thing for images that stocking introduced for one dimensional signals.",
                    "label": 0
                },
                {
                    "sent": "So now here comes the beauty of this notation.",
                    "label": 0
                },
                {
                    "sent": "So basically, how do we now implement this?",
                    "label": 0
                },
                {
                    "sent": "Super Duper inloggen algorithms?",
                    "label": 0
                },
                {
                    "sent": "You just read it from right to left and you do the 2D operation, so the cropping now must be a 2D crop.",
                    "label": 1
                },
                {
                    "sent": "The zero padding here must be a 2D zero padding.",
                    "label": 0
                },
                {
                    "sent": "The full Transformers 2 default transform and so forth, and then you have your algorithm.",
                    "label": 0
                },
                {
                    "sent": "Let's say you are working in Krayem were having some molecule data.",
                    "label": 0
                },
                {
                    "sent": "You can also use the same formula.",
                    "label": 0
                },
                {
                    "sent": "Get your 3D algorithms or your 40 algorithms, so that's convenient here.",
                    "label": 1
                },
                {
                    "sent": "So in our notation that's not so much different here but now.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The plug in now there's a trick of Alan basically putting different filters at different locations and having different ways at different locations.",
                    "label": 0
                },
                {
                    "sent": "Now we get space varying convolution OK.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And so again, here's a cartoon of our space varying convolution.",
                    "label": 1
                },
                {
                    "sent": "How we do it.",
                    "label": 0
                },
                {
                    "sent": "So basically we start with some image X up here and we need to chop it into overlapping pieces.",
                    "label": 0
                },
                {
                    "sent": "So those are the overlapping pieces and then we fade out and in these patches so that the overlap gets nicely and smoothly faded in and out.",
                    "label": 0
                },
                {
                    "sent": "We filter the different patches with different filters and finally we do everything together and we have our space varying convolution.",
                    "label": 0
                },
                {
                    "sent": "Of course for such an approximation to be like a good approximation of a real PSF.",
                    "label": 0
                },
                {
                    "sent": "Assumption is always it's a PSF is mostly varying across the image, so we can't have abrupt changes, but.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Many applications, that's fine.",
                    "label": 0
                },
                {
                    "sent": "Now, OK, great, so we have to start this gigantics matrix A and let's say you have like a lazy programming language and you would have all these matrices implemented in a lazy fashion.",
                    "label": 0
                },
                {
                    "sent": "Then you can now just write down this stuff and it will be your code for the forward model.",
                    "label": 0
                },
                {
                    "sent": "OK, but similarly we can also exchange roles of X and a so we can stack all these filters a into a big vector called a without 9 indexing.",
                    "label": 0
                },
                {
                    "sent": "And we exchanged the role of A and X and here now we see that this whole expression is also linear from the perspective of A of the filter.",
                    "label": 0
                },
                {
                    "sent": "Efficients and this gives us some matrix capital X.",
                    "label": 0
                },
                {
                    "sent": "So now we have like our forward model can be written in two ways, either as a linear expression in terms of the EXO as a linear expression in terms of the A.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now for these fast vector multiplications, I told you already too fast vector modulation for A and X will implement this stuff from right to left.",
                    "label": 1
                },
                {
                    "sent": "But now I'm blind convolution and non branded convolution also needs the gradients.",
                    "label": 0
                },
                {
                    "sent": "Usually usually offer these query expression and there you also need the A transpose and the X transpose.",
                    "label": 0
                },
                {
                    "sent": "And how do you do that?",
                    "label": 0
                },
                {
                    "sent": "So if you figure that out by hand with indexing or double indices then you won't get anywhere but in this case in this rotation or just read it from left to right and you implement it with your 2D operations from left to right and you immediately get your.",
                    "label": 0
                },
                {
                    "sent": "And look and implementations for a transport index, transpose.",
                    "label": 0
                },
                {
                    "sent": "And again if you have a fancy programming language with lazy evaluation, you get it basically for free.",
                    "label": 0
                },
                {
                    "sent": "It can do it symbolically, right?",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK. We are interested in.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In space variant.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Convolution, now I'm showing you some what it is is I basically repeat what it is and what we need for it, but only for the single image case.",
                    "label": 0
                },
                {
                    "sent": "So in the non blinding convolution the task is that given an observed image Y and the filters for the different patches, so it's not online.",
                    "label": 1
                },
                {
                    "sent": "So we know the filters already recover their true image X. OK so we have all this information we traveled want to recover the trim it X Now as I showed you, the forward model is linear in X.",
                    "label": 0
                },
                {
                    "sent": "So if you have some lease square expression or something.",
                    "label": 0
                },
                {
                    "sent": "Basically what you need to calculate the.",
                    "label": 0
                },
                {
                    "sent": "Gradients is you need fast matrix vector multiplications with A and a transpose, which I just showed you in the previous slide.",
                    "label": 0
                },
                {
                    "sent": "How to do it and?",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And log in.",
                    "label": 0
                },
                {
                    "sent": "So now for the blind convolution task, it's slightly more difficult, so here you're only given the blurry image and you want to recover the true image X.",
                    "label": 0
                },
                {
                    "sent": "But this is single now.",
                    "label": 0
                },
                {
                    "sent": "No it's still there then, but you also possibly have to estimate the filters.",
                    "label": 0
                },
                {
                    "sent": "I mean, we're not interested in the filters, but if you have some then you can apply the non blind deconvolution.",
                    "label": 0
                },
                {
                    "sent": "So this is now a much harder problem and you will get expressions with Aleve for the least square term in terms of A and in terms of eggs.",
                    "label": 0
                },
                {
                    "sent": "So now we also need the X&X transposed operation.",
                    "label": 0
                },
                {
                    "sent": "OK, but I showed you on the previous slide.",
                    "label": 0
                },
                {
                    "sent": "Do it fast.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now what I like properties of our space, right?",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Convolution, as I already said, the runtime precisely is like N log N and depending on the amount of overlap it will be a bit more.",
                    "label": 0
                },
                {
                    "sent": "So let's say every pixel is is dead by dealt with by three overlapping patches and you will have a factor of three in this formula, but it's very mild compared to other approximation to this thing.",
                    "label": 0
                },
                {
                    "sent": "So actually it's not much slower than the usual convolution.",
                    "label": 1
                },
                {
                    "sent": "So of course algorithms will run much slower because you have many more parameters.",
                    "label": 0
                },
                {
                    "sent": "Now you don't have one blur kernel, but you have maybe like 20 blur kernel, so there's of course some cost.",
                    "label": 0
                },
                {
                    "sent": "Plus the additional flexibility, but in principle the forward operation is as fast as the usual convolution.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now OK, is it really expressive or not?",
                    "label": 0
                },
                {
                    "sent": "Now?",
                    "label": 0
                },
                {
                    "sent": "The one question that I'm often asked is now is his point function.",
                    "label": 1
                },
                {
                    "sent": "At the end piecewise constant?",
                    "label": 1
                },
                {
                    "sent": "So like droppings, image into patches and having a different broker neutral for image and the answer is.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "No, because we choose the patches to overlap and the more overlap you have, the more flexibly appointment function becomes.",
                    "label": 0
                },
                {
                    "sent": "So one way to view it is at this point spread function can be seen like being approximated by a spline.",
                    "label": 0
                },
                {
                    "sent": "OK, so each on each of the Patch have a control point, which in this case is a blur kernel and the resulting point spread functions overall will be like living in some spline words, so it's like a smoothly interpolated points.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Function.",
                    "label": 0
                },
                {
                    "sent": "Next question.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So is it piecewise linear?",
                    "label": 0
                },
                {
                    "sent": "That depends entirely on your window function.",
                    "label": 0
                },
                {
                    "sent": "So if you take like a triangular window functions and it will be piecewise linear.",
                    "label": 1
                },
                {
                    "sent": "But if you choose nonlinear window functions and you will be fine.",
                    "label": 0
                },
                {
                    "sent": "So then it's really something.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Something more fancy, so is a differentiable allow.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The image yes, also that can be achieved if you choose a window functions carefully.",
                    "label": 0
                },
                {
                    "sent": "Basically that's a Windows function Rolex, mostly to zero and smoothly meet.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Shazzam OK, what else?",
                    "label": 0
                },
                {
                    "sent": "Again I want to point out the limitation.",
                    "label": 0
                },
                {
                    "sent": "So the true point spread function must try only smoothly, otherwise we will get artifacts.",
                    "label": 0
                },
                {
                    "sent": "OK, so an easy way to see that why that's the case.",
                    "label": 0
                },
                {
                    "sent": "Suppose we have two patches and one purchase like a Delta P on one side and another Patch as a Delta peak on the other side.",
                    "label": 0
                },
                {
                    "sent": "Now if you linearly interpolate between them in the in the middle, you will have two peaks, so you will get an echo image.",
                    "label": 0
                },
                {
                    "sent": "So what you want to make sure when you apply this stuff that between patches the point spread functions of the blur kernels are only.",
                    "label": 0
                },
                {
                    "sent": "Making small changes and then the approximation is very good.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, here's an example.",
                    "label": 0
                },
                {
                    "sent": "So this is one of our real camera shakes that we took with our fantastic device, and here's an approximation where we use the three by three grid or filters and basically nearly interpolated between these filters.",
                    "label": 0
                },
                {
                    "sent": "OK, and as you can see, like we get a lot of variation, even that we're only losing using like 3 by three filters and we get a good approximation to the true camera shake.",
                    "label": 0
                },
                {
                    "sent": "Of course, if you do really some really crazy shaped because you want to break our system, then you have to use more than you have to use more control points like in this blind language.",
                    "label": 0
                },
                {
                    "sent": "OK, and then you can also do that, but of course there's a limit with your data might only have a mega pixel and then you don't want to use too many black kernels because you have no chance to estimate them.",
                    "label": 0
                },
                {
                    "sent": "So there's a usual trade off.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, at the beginning I showed you a video where there was cycle is blurry to air turbulence and I will show you the results where we applied some online blind deconvolution method for multi frames to this method.",
                    "label": 0
                },
                {
                    "sent": "But now we use it with the space specially varying blur kernels and I hope this works yes.",
                    "label": 0
                },
                {
                    "sent": "So what you see is this is the raw sequence and in the middle we see the reconstruction it as you see already after a few frames like the image looks almost like the ground truth.",
                    "label": 0
                },
                {
                    "sent": "OK and if you want I can show you offline a couple of more videos like this.",
                    "label": 0
                },
                {
                    "sent": "So it's really surprising after few frames it will recover the true image and actually on another sequence something surprising happens.",
                    "label": 0
                },
                {
                    "sent": "The reconstruction actually looks better than the ground truth image, and the reason is of course like having 100 crappy images is better than only having one sharp image.",
                    "label": 0
                },
                {
                    "sent": "So there's more information in these 100 images, possibly then in this one true image.",
                    "label": 0
                },
                {
                    "sent": "So this suggests it.",
                    "label": 0
                },
                {
                    "sent": "You can also use this scheme together with super resolution, something that we've tried.",
                    "label": 0
                },
                {
                    "sent": "I don't have control your pictures, but since this is all linear.",
                    "label": 0
                },
                {
                    "sent": "You can also plug in some additional downsampling operators into the model and you will have immediately super resolution with the same algorithm.",
                    "label": 0
                },
                {
                    "sent": "Then for spatially wranglers.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's again, I will shake an image and we this is now this this years on this new snips work.",
                    "label": 0
                },
                {
                    "sent": "So some of you might have seen it already.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "My poster.",
                    "label": 0
                },
                {
                    "sent": "We are able to recover it and having in different locations so you see is a number plate.",
                    "label": 0
                },
                {
                    "sent": "It's now sharp.",
                    "label": 0
                },
                {
                    "sent": "L is a different location up here this.",
                    "label": 0
                },
                {
                    "sent": "The scale to become sharp or here.",
                    "label": 0
                },
                {
                    "sent": "Alright, so it's a lamp.",
                    "label": 0
                },
                {
                    "sent": "And so this is how much more flexible than having a single blur kernel.",
                    "label": 0
                },
                {
                    "sent": "So there's a state of the art method.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Single image plant deconvolution and of course the images taken with a nonstationary blur.",
                    "label": 0
                },
                {
                    "sent": "So this method must fail right?",
                    "label": 0
                },
                {
                    "sent": "Because it's assuming a single blur kernel for the whole image.",
                    "label": 0
                },
                {
                    "sent": "But just to show you that it's you can't just solve it with the usual convolution, you need really the space, specially variants.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so last example.",
                    "label": 0
                },
                {
                    "sent": "So this is a picture we've seen at the beginning that we took with this self Woodlands which only had a single piece of glass and I would like to show you the reconstruction.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This this is a reconstruction that we get with our algorithm and I would like to stress here that in this application, basically, since we have the lens, we measure it with an artificial star.",
                    "label": 0
                },
                {
                    "sent": "So we have some set up in our basement in some 10 meter long room where we can put an artificial style where we can make sure that it should be only a single picture on the ship.",
                    "label": 0
                },
                {
                    "sent": "But due to the blur of the lens, basically it gets like washed out and by this we can really measure the point spread function very precisely for the different locations on the center and.",
                    "label": 0
                },
                {
                    "sent": "Then basically we are using the non blind deconvolution with this framework to recover the image.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Once again doing it back and forth.",
                    "label": 0
                },
                {
                    "sent": "So here we see actually on a higher resolution you would see that in different color channels is differently blur.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And will be able to.",
                    "label": 0
                },
                {
                    "sent": "They all align nicely once they are recovered with riot points, but Funk.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Of course yes.",
                    "label": 0
                },
                {
                    "sent": "Lots of related work, and as usual you do your work or you have your problem.",
                    "label": 0
                },
                {
                    "sent": "You come up with your solution and then you look into the literature.",
                    "label": 0
                },
                {
                    "sent": "So now what have been other people been doing right?",
                    "label": 0
                },
                {
                    "sent": "I mean actually you often do it the other way around, but the problem is often that you don't understand the literature before you thought about the problem yourself, so there is related work and but it's all a little bit different.",
                    "label": 0
                },
                {
                    "sent": "So there are some work by Negan.",
                    "label": 0
                },
                {
                    "sent": "Door Leary from 98 also do space rank deconvolution with a similar approach.",
                    "label": 0
                },
                {
                    "sent": "But they only use rectangular.",
                    "label": 0
                },
                {
                    "sent": "Triangular windows, so there are some tricks to make it work for these nonlinear windows, so you have to be careful in choosing an right normalization, otherwise you get artifact and also they don't have fast implementation for X&X transpose, so they can only do the non blind deconvolution.",
                    "label": 0
                },
                {
                    "sent": "The counters aplenty convolution and recently there was a lot of interest, income and interest in camera shake and so in 2009 there's a tech report by Tien colleagues with a projective motion path model where they basically tried to model the path that the camera is taken and then integrating the images that you see.",
                    "label": 0
                },
                {
                    "sent": "And this is also model which will produce space Wrangler, but it's only for camera shake, so you can't use it for lens correction for example.",
                    "label": 1
                },
                {
                    "sent": "And you can also apply to air turbulence.",
                    "label": 0
                },
                {
                    "sent": "Similarly recent work by YT and Goopta.",
                    "label": 0
                },
                {
                    "sent": "Basically they're using a similar approach as Thai.",
                    "label": 0
                },
                {
                    "sent": "Sing some ography tricks.",
                    "label": 0
                },
                {
                    "sent": "Again, this is only for camera shake.",
                    "label": 1
                },
                {
                    "sent": "Then there's a recent See graph publication from Yoshi and I and what they did.",
                    "label": 0
                },
                {
                    "sent": "They glue to actually meet a ransom gyroscopes with a camera, and so they record basically is the trajectory of the camera, and from that they're able to reconstruct the point spread function, which is quite amazing that you can do that.",
                    "label": 1
                },
                {
                    "sent": "It's a big engineering effort, but again I would like to stress this model is only for camera shake.",
                    "label": 0
                },
                {
                    "sent": "It's not for the for the general problem of approximating point spread functions.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So anyway, so I'm not sure I'm on time, yeah?",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So he's already is a summary, So what I would like to show you what's an efficient way to implement space Rang convolution?",
                    "label": 0
                },
                {
                    "sent": "Basically the idea.",
                    "label": 0
                },
                {
                    "sent": "So how we came up with this idea where based on this overlap add idea of stock him and short space free analysis and synthesis of jondel and and we did it in a way that it can be written default model as a matrix vector multiplication.",
                    "label": 1
                },
                {
                    "sent": "And maybe I didn't add a slide on this, but so why were we so eager to write it like this?",
                    "label": 0
                },
                {
                    "sent": "The main reason is 'cause there are so many algorithms already out there for the usual convolution and we just want to recycle them.",
                    "label": 0
                },
                {
                    "sent": "So we just want to.",
                    "label": 0
                },
                {
                    "sent": "Like in a different fast matrix vector multiplication and then immediately turns it into some spatially varying version of it.",
                    "label": 0
                },
                {
                    "sent": "For example, for blind deconvolution work we use the algorithm of true entry, which is the state of the art for space invariant convolution.",
                    "label": 0
                },
                {
                    "sent": "Then with some additional tricks and tweaking we get a version with these matrix vector multiplications.",
                    "label": 0
                },
                {
                    "sent": "Now for the space variant case.",
                    "label": 0
                },
                {
                    "sent": "Similarly we are using last year's NIPS method from Krishnan Fergus, which I think if not the state of the art method for non blind deblurring and just by replacing these operations we get immediately.",
                    "label": 0
                },
                {
                    "sent": "Especially variant deconvolution method.",
                    "label": 0
                },
                {
                    "sent": "I hope I convince you that these operations can be done all very fast and this allows us to to generalize many existing algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I showed you results for removing space rain blurs with camera shake, lens aberrations and air turbulence.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And but we have many more applications, so we did work on atmospheric turbulence.",
                    "label": 1
                },
                {
                    "sent": "So we have image sequences from the Moon where the atmosphere with the different layers of AI is producing some, some spackle blur, and we're currently working also on microscopies.",
                    "label": 0
                },
                {
                    "sent": "Or there's confocal microscopy where we have definitely Wrangler and in principle it approximately should fit our model, and we also have some experiments with biomedical data where you have like MRI sequence, where you basically want to get rid of like object motion.",
                    "label": 0
                },
                {
                    "sent": "And also probably of like.",
                    "label": 0
                },
                {
                    "sent": "Little deformations of the image across during the recording process.",
                    "label": 1
                },
                {
                    "sent": "So nonrigid registration, because in principle can also do nonrigid registration with it, because it's just like an optical system in a way, right you just stored locally the points differently, and this can be expressed in our framework.",
                    "label": 0
                },
                {
                    "sent": "If it.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This movie Brian.",
                    "label": 0
                },
                {
                    "sent": "OK, thank you very much.",
                    "label": 0
                },
                {
                    "sent": "Question.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "Online because of my mental conditions change.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Correct, yeah?",
                    "label": 0
                },
                {
                    "sent": "So right now we are having.",
                    "label": 0
                },
                {
                    "sent": "Processing the data offline.",
                    "label": 0
                },
                {
                    "sent": "I mean we have an algorithm which we called online because it looks at each frame only ones, but we haven't run it like black your camera onto the telescope and then look on your screen how the picture gets better.",
                    "label": 0
                },
                {
                    "sent": "So we haven't done that, but we're about to do that.",
                    "label": 0
                },
                {
                    "sent": "One of my colleagues, they implemented our operations on a GPU and so that you can do these updates now, really fast, and so we are hoping that you can do it like in real time.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Emergency landing.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Right, right?",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah, that's a very nice application.",
                    "label": 0
                },
                {
                    "sent": "So yeah, I'd like to discuss it.",
                    "label": 0
                },
                {
                    "sent": "So I think in principle it is possible because this forward operation is very fast.",
                    "label": 0
                },
                {
                    "sent": "And of course there are many parameters to estimate, so maybe you really have to do some GPU massage ING, but I guess it can be done and maybe if it can't be done now then maybe in two years so.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Feels right.",
                    "label": 0
                },
                {
                    "sent": "OK, actually it is interesting that you pointed out there's a challenge to great Ten challenge which you might have known that.",
                    "label": 0
                },
                {
                    "sent": "So that's a change of the Pascal network, and it's exactly on gravitational lensing, and so the problem, say looking there at is that if you take a picture of the Sky with a wide angle lens, then basically will have different blur in different locations of the Sky, right?",
                    "label": 0
                },
                {
                    "sent": "So the technical term is set is beyond the isoperimetric Patch, and so in that case it's really you have the style and the left side will have a very different specular patterns and this down the right side on this, exactly a challenge.",
                    "label": 0
                },
                {
                    "sent": "On this topic, where we've of course hope to find the student who applies or method to this challenge.",
                    "label": 0
                },
                {
                    "sent": "OK, yeah, but think about this in the limit patches just continuously everywhere.",
                    "label": 0
                },
                {
                    "sent": "Change and.",
                    "label": 0
                },
                {
                    "sent": "So it's pretty much almost a black box type thing.",
                    "label": 0
                },
                {
                    "sent": "I wonder how critical this chunking office, that I mean in the I mean.",
                    "label": 0
                },
                {
                    "sent": "In the limit there is no chunking up into patches, just continuous kind of changing the window.",
                    "label": 0
                },
                {
                    "sent": "Or you could be a window.",
                    "label": 0
                },
                {
                    "sent": "I mean, how critical is that?",
                    "label": 0
                },
                {
                    "sent": "So in principle I guess the on the one extreme UFC identity transformation, right?",
                    "label": 0
                },
                {
                    "sent": "So your vector goes in and it goes out and in the other extreme case really have a dense matrix between it.",
                    "label": 0
                },
                {
                    "sent": "So you really have a dense matrix vector multiplication that then has a full flexibility for any pixel it can use.",
                    "label": 0
                },
                {
                    "sent": "Any other pixel and use all the combinations.",
                    "label": 0
                },
                {
                    "sent": "And somehow we are now in between with this kind of thing and there are some obvious generalization to our work, so right now we're using like patches which have the same size and which are like equally.",
                    "label": 0
                },
                {
                    "sent": "Located but on this one rotational blur that I showed you there were like on the top left there were small blur kernels and on the bottom right we had very large blur kernels, so this can be very simply actually generalized to like arbitrary Patch sizes.",
                    "label": 0
                },
                {
                    "sent": "So you could have like larger page sizes in areas where you know the blur kernel is more smooth and you have smaller pitch sizes where you know the blur kernel is more rapidly changing.",
                    "label": 0
                },
                {
                    "sent": "And similarly you can have larger blur kernels where you know the blur is very large and smaller blur kernels.",
                    "label": 0
                },
                {
                    "sent": "Where the blue is very small, so in principle there's like a whole continuum of things that you could try.",
                    "label": 0
                },
                {
                    "sent": "In the box.",
                    "label": 0
                },
                {
                    "sent": "Yeah, but in each pet see if it 50 could have a different size, so that should be fine.",
                    "label": 0
                },
                {
                    "sent": "Multiscale yeah right yeah one could think of like this I don't know some quadtree approximation to the true PSF right?",
                    "label": 0
                },
                {
                    "sent": "First take 1.5 one kernel for the whole image and then you look out with the fit is you drop it into four pieces.",
                    "label": 0
                },
                {
                    "sent": "You kind of recursively go down.",
                    "label": 0
                },
                {
                    "sent": "So one could think of these kind of algorithms that should be possible.",
                    "label": 0
                },
                {
                    "sent": "Then yes, we will be about to finish this tool box with the GPU stuff and actually we were planning to release some code for this too, but it's not done yet.",
                    "label": 0
                },
                {
                    "sent": "And so it will be beginning of the next year.",
                    "label": 0
                },
                {
                    "sent": "I guess we thank the speaker again.",
                    "label": 0
                }
            ]
        }
    }
}