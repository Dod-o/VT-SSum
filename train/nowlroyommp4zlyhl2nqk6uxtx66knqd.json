{
    "id": "nowlroyommp4zlyhl2nqk6uxtx66knqd",
    "title": "Online Learning by Ellipsoid Method",
    "info": {
        "author": [
            "Liu Yang, School of Computer Science, Carnegie Mellon University"
        ],
        "published": "Aug. 26, 2009",
        "recorded": "June 2009",
        "category": [
            "Top->Computer Science->Machine Learning->On-line Learning"
        ]
    },
    "url": "http://videolectures.net/icml09_yang_olbem/",
    "segmentation": [
        [
            "So today I'm going to talk about online learning by ellipsoid method.",
            "Yep, so."
        ],
        [
            "When I look this is for people who are familiar with ellipsoid method.",
            "We know its original design, for, you know, is in physics and also used for convex programming problem and in this work we're trying to borrow this technique and apply that to online learning for good reasons.",
            "So what is good reasons?",
            "Because we want to when we look at online learning the previous work they all updating a single classifier every iteration but somehow you know think about as a base and separated.",
            "Spirit, we want to look at the version space, which means a set of classifier that consistent with all the training examples which received so far.",
            "So that's the motivation.",
            "We want to look at the version space and somehow geometrically represented.",
            "So then the next question is how to represent the version space and you know, like there's probably many ways to do this job, but we we think we look at ellipsoid method, we find out is well studied and it's suddenly in a good place to start ways.",
            "So we use ellipsoid method so as to our knowledge is work.",
            "The first attempt to explicitly represent version space for online learning.",
            "So precisely we want to use ellipsoid as the outer approximation of the site of hypothesis that is consistent with header side.",
            "So the outline of this talk will be we start with introduction motivation and then I will introduce algorithm.",
            "You know I will introduce what is ellipsoid method and how that works, and then we'll talk about how it will sort method can be used for online learning and eventually we have evaluation section."
        ],
        [
            "So as I mentioned from a business viewpoint, we want to represent in the version space we're looking at the distribution of the version space which is set of classifiers that consistent with the training examples which received so far so.",
            "Then they so the reason we want to have the version space other than what I mentioned is like many other online learners, they don't have such and such a property.",
            "They only look at single classifier and also is because.",
            "We're not like this.",
            "We're not just stop at the point.",
            "Estimation will catch the most likely solution we want.",
            "Also look at distribution are possible solutions, so there's some other good reasons why it's so important to represent version space particularly explicitly.",
            "There are probably there's some some other efforts like theoretical work has been done for online learning.",
            "They talk about the version space and they come up with nice bounds over, you know convergence properties on that for you.",
            "This work we particularly want to explicitly represent the version space, so why?",
            "Why is it so important?",
            "So you think about a very example, like in the selective sampling.",
            "As we can recall, the selective sampling basically only request label.",
            "In the region of disagreement, so that means we want somehow, you know, we can have have some insights about the interplay between the version space and the the data region.",
            "So by having such except explicit representation of the version space, it will help us will allow us to do so, which is to help you know, to give review some interchangeability between the model space and the data rate.",
            "OK, so."
        ],
        [
            "Now the question comes through how we represent the workspace.",
            "As I said, we interesting ellipsoid because it looks so in method is well studied and have many nice properties.",
            "Let's look at some of them.",
            "First, we know for online learning we want the updating rule to be simple as interesting as possible with me, which means we can efficiently update the classifier.",
            "So Fortunately ellipsoid have a very simple updating formulas for the you know for the necessary quantities for these.",
            "I believe so it which is a center and the shape metrics.",
            "There are the property.",
            "Ellipsoid enjoy is so we think you may think of it as ellipsoid we have.",
            "We have access and we have center in the youth so method.",
            "Maybe they they Max it.",
            "The maximum axis will you know have some dilation over for the next iteration.",
            "However the overall volumes of the soil they're going to guarantee to be shrinked so you know the volume of shrinking kind of thing is desirable because it will help us to narrow down to the target solution especially very quickly, which is the next property is that volume?",
            "Actually reduce exponentially over iterations.",
            "So we have seen we have seen all the while we want ellipsoid to represent various space and then there is additional reason that we want to use ellipsoid because as you know we have to leave.",
            "So we have centroids and the shape metrics which is a metrics for this case.",
            "It's two dimension is 2 * 2 metrics that somehow represent the shape of the ellipsoid and it has to be positive positive definite.",
            "So such such information is more informative than most existing online learners.",
            "We have more information.",
            "We have more control about updating because we have additional shape metrics."
        ],
        [
            "So we can really work in online learning Mills to them additive, which means, like perceptually updates the W the by if there if there is a mistake.",
            "Examples we will update W by AA XI an there's quasi additive framework try to unify perceptual and we know algorithm and also people extend online learning to multiple label case because most I'm learning we're starting battery case and then extend to multiple label case.",
            "And there is a graph based approach for learning.",
            "And also there's work trying to do formulation of optimization for online learning.",
            "So now."
        ],
        [
            "So we're going to we're done with the introduction and motivation.",
            "Well now we're going to talk about their rhythm.",
            "First, we will."
        ],
        [
            "Start Waze.",
            "What is ellipsoid method?",
            "So it looks complicated.",
            "Alot of things here but actually the idea is very simple.",
            "So every time you have and you start with the big ellipsoid here every time you have and you you have a new example you come up with, you come up with a great what is called gradient of FX at this point XK and then you construct 1/2 plan which basically is.",
            "Something like this and then we are in line.",
            "Interesting this section and we somehow long to figure out late soy that can alter approximate this section which is a new side.",
            "However, we want this ellipsoid is the smallest possible in terms of volume right?",
            "So based on this spirit we can come up with the updation function about the.",
            "Too late and the shape metrics this you know based on this formula which P is the shape matrix and X is the center."
        ],
        [
            "OK, so.",
            "So I didn't I ideally I should show you a picture that by this mechanism the ellipsoid going to shrink, shrink and narrow down arrow down to the target.",
            "You know you can see the volume shrink down to the target solutions.",
            "So so based on the.",
            "Now the ellipsoid method we're trying to think how can we apply that method to online learning.",
            "So basically we naturally think think about other learning as a feasibility problem, which is we want to find a solution W which is the classifier.",
            "We tried to learn that is close to the gamma margin classifier U which is optimal classifier given all these sequential received training examples.",
            "So we start with come up with such a set a actually at iteration T80 which includes all the classifiers that is able to classify with margin gamma.",
            "Here is constant that can be adjusted with.",
            "For other examples received so far they all they are class class class, classified perfectly with the margin gamma.",
            "And with such a set we want to somehow construct ellipsoid.",
            "That outer includes this site.",
            "We can think about as outer approximation of this set, so let's see.",
            "Suppose we have Poly Hydra and you somehow want to come up with that include including this this Poly Hydra, so there's.",
            "So by doing that, we can quickly narrow down our job is to reduce the volume little side so that we can find the solution."
        ],
        [
            "OK so yeah.",
            "Next thing will be how can we efficiently update?",
            "You avoid given a misclassify example the we will follow exactly the same.",
            "You know the algorithm updating function similar function proposed by Lucas Oil method.",
            "However we need little by little bit.",
            "We rewrite this.",
            "We rewrite such a half plane generated by the misclassified example, rewriting the certain form.",
            "So."
        ],
        [
            "And then we can somehow prove that in Theorem one we can prove that actually the nucleus ellipsoid absolutely plus one covers the intersection of epsilon T and they have flying we just constructed by the misclassified example.",
            "And we come up with the updating function for the center and if the shape metrics is just, you know."
        ],
        [
            "Some mass.",
            "You can look look for in the paper and so.",
            "Now we have the algorithm for we called classical soil method for online learning.",
            "Because we're in this case, we're dealing with a separable case, which means very easy target classifier that can perfectly separate the positive negative examples.",
            "So we cut the classical.",
            "And the algorithm.",
            "Basically we start with some big lease OID, which it basically is.",
            "A ball is about, and it's big enough to somehow contain the target classifier and then for over iterations we receive a instance XD We practice label if it's correct.",
            "This flying we do not think if it's not correct.",
            "We use update based on these rules."
        ],
        [
            "So we want to.",
            "We also derive the mistake bounds for these classical ellipsoid algorithm.",
            "So they basically were saying for any normalized.",
            "Zyan normalized classifier optimal class from you will be able to find such.",
            "So the the number of mistakes made by the algorithm just proposed on this side of data point is actually upper bounding by such such such quantity.",
            "Actually if you manipulate quality or find that your font is exactly the same as mistake bound by perception algorithm just after the factor of constant."
        ],
        [
            "To get the percentage so that remember the a parameter actually is used to somehow to tune the gamma yearly.",
            "We can see if we set gamma to be 0.1, something that the aim parameters constant which is assigned to the proper value.",
            "So a printer is no problem here.",
            "So the message here is this mistake balances actually same with Mystic balance by perception algorithm up to a factor of constant.",
            "Yeah, so we just talk about the realizable case, which means there is a target classifier that can perfectly self raise the positive negative examples.",
            "However, in real case you know there's unrealized, which means those are no such such such optimal classifier exists, and in that case people.",
            "Usually they really look at the regret bound, right?",
            "So we have we have some some manipulation about the geometric property here.",
            "Which is we would try to we try to trade the center in the shape.",
            "Metrics are the summarization of receiving training examples which if you look at this so the beauty the same.",
            "It's like a combination of previous like training examples and you can look at it first.",
            "Order statistics for the training information you received so far.",
            "However, it's also attention will pay more attention, like at the peak, which is shaped metrics.",
            "So we can.",
            "We can write it in.",
            "Formica citize ropy.",
            "One, plus the summation over iterations, so it's like a mixture of the previous P metrics and the 2nd order statistic information of all the training example which received so far.",
            "Somehow this is inverse of PPT metrics.",
            "You can view it as weighted covariance matrix that stores the second out information between examples."
        ],
        [
            "So by doing so we can we can we can think about this, so it's kind of a memory, right?",
            "So we can somehow it just depends on how we write it.",
            "We could also write it in this way.",
            "The CT here actually is have exponential firm which is decayed exponentially overtime, which is here the C&B is just some constant we find out be equals to 0.3 as the reasonable one.",
            "The details in the paper.",
            "So basically we can see if we make cities such exponential firm than the influence of the 2nd order statistics of the training examples actually decayed exponentially overtime.",
            "Right, so by varying such see and be the constant, we can somehow adjust this memory of the shape metrics."
        ],
        [
            "So similarly, we will have the improved version of our learning method.",
            "In the unreliable case.",
            "So the only difference is this basically outlines the same as before.",
            "The only difference is the PP metrics updating rules about the P metrics or be modified a little bit."
        ],
        [
            "And we will get the mistake bounds for for the improved ellipsoid method as well as Commission here.",
            "Right?"
        ],
        [
            "So I will skip the extension to the multiple label learning because."
        ],
        [
            "It's it's straightforward, and now we're going to look at it."
        ],
        [
            "Elation station we do evaluate experiment several datasets, including USPS UCI letter you you see a shuttle this sites and we have two baseline here.",
            "The one is the algorithm called outline passive aggressive algorithm.",
            "Another is margin, infuse relaxed algorithm.",
            "So they are state of our online learning algorithm in terms of performance and we're going to look at linear case basically means for other parameter.",
            "Here we got going.",
            "Set it to be a linear one, and we assume the margin gamma is 0.1 for all the baselines.",
            "The test error will just be the number of mistakes made on the given sequence is divided by the length of the sequence."
        ],
        [
            "So here is the result results.",
            "We can, we can.",
            "So the first row is the mystery number mistake and the 2nd row is number of the applications need OK so we can find out.",
            "So the there is 3 method here.",
            "Pieza passive aggressive and Mira is the other other one.",
            "Just mention is margin infused relaxed algorithm and there is not one ellipsoid is our algorithm so this is on different data site.",
            "Um?",
            "And this is 1 Apple.",
            "This is another one is there are three apox entirely by Hawks.",
            "We mean we somehow permutate the data set randomly and come up with different Apple.",
            "So from this result you can find out actually the algorithm we proposed is.",
            "They can parable or even better than the two baselines across data sites.",
            "And also we find out we need less number of number of iterations to achieve such results.",
            "OK."
        ],
        [
            "So as a conclusion, so this work basically is the first attempt to explicitly represent the version space I talk about why we want to explicit represent and why we're interested very space, and how learning can benefit from such explicit representations of very space, and we somehow we represent, you know, we represent the version space available storage, so we can capture our classifiers that is consistent with hindsight.",
            "And we derive the missing bounds which we have where we have shown that is the same with perceptual up to the constant factor and the shape metrics P allows us to store more information of the training examples and additional controls of the updating process.",
            "So empirical study shows the ellipsoid method somehow is compatible with the states of ours online learners.",
            "Thank you."
        ],
        [
            "So do you have bounds on the unrelated case?",
            "Other.",
            "Yeah.",
            "Tool.",
            "Hence the best offline or something.",
            "I mean, I have a bound, but what about if you tune those providers, and all of those?",
            "You're saying which planet are you talking about?",
            "the B or the sea?",
            "You can see this is just up to a constant constant factor.",
            "Sorry yeah.",
            "How much?",
            "How much more expensive is the algorithm?",
            "Actually, it's it's not.",
            "It's not.",
            "It's not slow as I as I show, you know empirical study.",
            "The number of iterations, right?",
            "You're.",
            "So we actually the the time for this algorithm is relative.",
            "So this is this is the number of iterations is algorithm needs compared to perception.",
            "Oh, it's very fast because you left side by nature is very efficiently updating.",
            "Remember, I talked in the beginning like it's rule is very simple.",
            "Yes, there is a step of matrix inverse.",
            "So as I remember."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So today I'm going to talk about online learning by ellipsoid method.",
                    "label": 0
                },
                {
                    "sent": "Yep, so.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "When I look this is for people who are familiar with ellipsoid method.",
                    "label": 0
                },
                {
                    "sent": "We know its original design, for, you know, is in physics and also used for convex programming problem and in this work we're trying to borrow this technique and apply that to online learning for good reasons.",
                    "label": 0
                },
                {
                    "sent": "So what is good reasons?",
                    "label": 0
                },
                {
                    "sent": "Because we want to when we look at online learning the previous work they all updating a single classifier every iteration but somehow you know think about as a base and separated.",
                    "label": 0
                },
                {
                    "sent": "Spirit, we want to look at the version space, which means a set of classifier that consistent with all the training examples which received so far.",
                    "label": 0
                },
                {
                    "sent": "So that's the motivation.",
                    "label": 0
                },
                {
                    "sent": "We want to look at the version space and somehow geometrically represented.",
                    "label": 1
                },
                {
                    "sent": "So then the next question is how to represent the version space and you know, like there's probably many ways to do this job, but we we think we look at ellipsoid method, we find out is well studied and it's suddenly in a good place to start ways.",
                    "label": 0
                },
                {
                    "sent": "So we use ellipsoid method so as to our knowledge is work.",
                    "label": 0
                },
                {
                    "sent": "The first attempt to explicitly represent version space for online learning.",
                    "label": 1
                },
                {
                    "sent": "So precisely we want to use ellipsoid as the outer approximation of the site of hypothesis that is consistent with header side.",
                    "label": 0
                },
                {
                    "sent": "So the outline of this talk will be we start with introduction motivation and then I will introduce algorithm.",
                    "label": 0
                },
                {
                    "sent": "You know I will introduce what is ellipsoid method and how that works, and then we'll talk about how it will sort method can be used for online learning and eventually we have evaluation section.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So as I mentioned from a business viewpoint, we want to represent in the version space we're looking at the distribution of the version space which is set of classifiers that consistent with the training examples which received so far so.",
                    "label": 1
                },
                {
                    "sent": "Then they so the reason we want to have the version space other than what I mentioned is like many other online learners, they don't have such and such a property.",
                    "label": 0
                },
                {
                    "sent": "They only look at single classifier and also is because.",
                    "label": 0
                },
                {
                    "sent": "We're not like this.",
                    "label": 0
                },
                {
                    "sent": "We're not just stop at the point.",
                    "label": 1
                },
                {
                    "sent": "Estimation will catch the most likely solution we want.",
                    "label": 0
                },
                {
                    "sent": "Also look at distribution are possible solutions, so there's some other good reasons why it's so important to represent version space particularly explicitly.",
                    "label": 0
                },
                {
                    "sent": "There are probably there's some some other efforts like theoretical work has been done for online learning.",
                    "label": 0
                },
                {
                    "sent": "They talk about the version space and they come up with nice bounds over, you know convergence properties on that for you.",
                    "label": 0
                },
                {
                    "sent": "This work we particularly want to explicitly represent the version space, so why?",
                    "label": 1
                },
                {
                    "sent": "Why is it so important?",
                    "label": 0
                },
                {
                    "sent": "So you think about a very example, like in the selective sampling.",
                    "label": 0
                },
                {
                    "sent": "As we can recall, the selective sampling basically only request label.",
                    "label": 1
                },
                {
                    "sent": "In the region of disagreement, so that means we want somehow, you know, we can have have some insights about the interplay between the version space and the the data region.",
                    "label": 0
                },
                {
                    "sent": "So by having such except explicit representation of the version space, it will help us will allow us to do so, which is to help you know, to give review some interchangeability between the model space and the data rate.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now the question comes through how we represent the workspace.",
                    "label": 0
                },
                {
                    "sent": "As I said, we interesting ellipsoid because it looks so in method is well studied and have many nice properties.",
                    "label": 0
                },
                {
                    "sent": "Let's look at some of them.",
                    "label": 0
                },
                {
                    "sent": "First, we know for online learning we want the updating rule to be simple as interesting as possible with me, which means we can efficiently update the classifier.",
                    "label": 0
                },
                {
                    "sent": "So Fortunately ellipsoid have a very simple updating formulas for the you know for the necessary quantities for these.",
                    "label": 0
                },
                {
                    "sent": "I believe so it which is a center and the shape metrics.",
                    "label": 1
                },
                {
                    "sent": "There are the property.",
                    "label": 0
                },
                {
                    "sent": "Ellipsoid enjoy is so we think you may think of it as ellipsoid we have.",
                    "label": 0
                },
                {
                    "sent": "We have access and we have center in the youth so method.",
                    "label": 0
                },
                {
                    "sent": "Maybe they they Max it.",
                    "label": 0
                },
                {
                    "sent": "The maximum axis will you know have some dilation over for the next iteration.",
                    "label": 0
                },
                {
                    "sent": "However the overall volumes of the soil they're going to guarantee to be shrinked so you know the volume of shrinking kind of thing is desirable because it will help us to narrow down to the target solution especially very quickly, which is the next property is that volume?",
                    "label": 0
                },
                {
                    "sent": "Actually reduce exponentially over iterations.",
                    "label": 0
                },
                {
                    "sent": "So we have seen we have seen all the while we want ellipsoid to represent various space and then there is additional reason that we want to use ellipsoid because as you know we have to leave.",
                    "label": 0
                },
                {
                    "sent": "So we have centroids and the shape metrics which is a metrics for this case.",
                    "label": 0
                },
                {
                    "sent": "It's two dimension is 2 * 2 metrics that somehow represent the shape of the ellipsoid and it has to be positive positive definite.",
                    "label": 1
                },
                {
                    "sent": "So such such information is more informative than most existing online learners.",
                    "label": 1
                },
                {
                    "sent": "We have more information.",
                    "label": 0
                },
                {
                    "sent": "We have more control about updating because we have additional shape metrics.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we can really work in online learning Mills to them additive, which means, like perceptually updates the W the by if there if there is a mistake.",
                    "label": 0
                },
                {
                    "sent": "Examples we will update W by AA XI an there's quasi additive framework try to unify perceptual and we know algorithm and also people extend online learning to multiple label case because most I'm learning we're starting battery case and then extend to multiple label case.",
                    "label": 1
                },
                {
                    "sent": "And there is a graph based approach for learning.",
                    "label": 0
                },
                {
                    "sent": "And also there's work trying to do formulation of optimization for online learning.",
                    "label": 1
                },
                {
                    "sent": "So now.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we're going to we're done with the introduction and motivation.",
                    "label": 0
                },
                {
                    "sent": "Well now we're going to talk about their rhythm.",
                    "label": 0
                },
                {
                    "sent": "First, we will.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Start Waze.",
                    "label": 0
                },
                {
                    "sent": "What is ellipsoid method?",
                    "label": 0
                },
                {
                    "sent": "So it looks complicated.",
                    "label": 0
                },
                {
                    "sent": "Alot of things here but actually the idea is very simple.",
                    "label": 0
                },
                {
                    "sent": "So every time you have and you start with the big ellipsoid here every time you have and you you have a new example you come up with, you come up with a great what is called gradient of FX at this point XK and then you construct 1/2 plan which basically is.",
                    "label": 0
                },
                {
                    "sent": "Something like this and then we are in line.",
                    "label": 0
                },
                {
                    "sent": "Interesting this section and we somehow long to figure out late soy that can alter approximate this section which is a new side.",
                    "label": 0
                },
                {
                    "sent": "However, we want this ellipsoid is the smallest possible in terms of volume right?",
                    "label": 0
                },
                {
                    "sent": "So based on this spirit we can come up with the updation function about the.",
                    "label": 0
                },
                {
                    "sent": "Too late and the shape metrics this you know based on this formula which P is the shape matrix and X is the center.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "So I didn't I ideally I should show you a picture that by this mechanism the ellipsoid going to shrink, shrink and narrow down arrow down to the target.",
                    "label": 0
                },
                {
                    "sent": "You know you can see the volume shrink down to the target solutions.",
                    "label": 0
                },
                {
                    "sent": "So so based on the.",
                    "label": 0
                },
                {
                    "sent": "Now the ellipsoid method we're trying to think how can we apply that method to online learning.",
                    "label": 1
                },
                {
                    "sent": "So basically we naturally think think about other learning as a feasibility problem, which is we want to find a solution W which is the classifier.",
                    "label": 1
                },
                {
                    "sent": "We tried to learn that is close to the gamma margin classifier U which is optimal classifier given all these sequential received training examples.",
                    "label": 1
                },
                {
                    "sent": "So we start with come up with such a set a actually at iteration T80 which includes all the classifiers that is able to classify with margin gamma.",
                    "label": 1
                },
                {
                    "sent": "Here is constant that can be adjusted with.",
                    "label": 0
                },
                {
                    "sent": "For other examples received so far they all they are class class class, classified perfectly with the margin gamma.",
                    "label": 0
                },
                {
                    "sent": "And with such a set we want to somehow construct ellipsoid.",
                    "label": 0
                },
                {
                    "sent": "That outer includes this site.",
                    "label": 0
                },
                {
                    "sent": "We can think about as outer approximation of this set, so let's see.",
                    "label": 0
                },
                {
                    "sent": "Suppose we have Poly Hydra and you somehow want to come up with that include including this this Poly Hydra, so there's.",
                    "label": 0
                },
                {
                    "sent": "So by doing that, we can quickly narrow down our job is to reduce the volume little side so that we can find the solution.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK so yeah.",
                    "label": 0
                },
                {
                    "sent": "Next thing will be how can we efficiently update?",
                    "label": 1
                },
                {
                    "sent": "You avoid given a misclassify example the we will follow exactly the same.",
                    "label": 0
                },
                {
                    "sent": "You know the algorithm updating function similar function proposed by Lucas Oil method.",
                    "label": 0
                },
                {
                    "sent": "However we need little by little bit.",
                    "label": 0
                },
                {
                    "sent": "We rewrite this.",
                    "label": 0
                },
                {
                    "sent": "We rewrite such a half plane generated by the misclassified example, rewriting the certain form.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then we can somehow prove that in Theorem one we can prove that actually the nucleus ellipsoid absolutely plus one covers the intersection of epsilon T and they have flying we just constructed by the misclassified example.",
                    "label": 0
                },
                {
                    "sent": "And we come up with the updating function for the center and if the shape metrics is just, you know.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Some mass.",
                    "label": 0
                },
                {
                    "sent": "You can look look for in the paper and so.",
                    "label": 0
                },
                {
                    "sent": "Now we have the algorithm for we called classical soil method for online learning.",
                    "label": 1
                },
                {
                    "sent": "Because we're in this case, we're dealing with a separable case, which means very easy target classifier that can perfectly separate the positive negative examples.",
                    "label": 0
                },
                {
                    "sent": "So we cut the classical.",
                    "label": 0
                },
                {
                    "sent": "And the algorithm.",
                    "label": 0
                },
                {
                    "sent": "Basically we start with some big lease OID, which it basically is.",
                    "label": 0
                },
                {
                    "sent": "A ball is about, and it's big enough to somehow contain the target classifier and then for over iterations we receive a instance XD We practice label if it's correct.",
                    "label": 0
                },
                {
                    "sent": "This flying we do not think if it's not correct.",
                    "label": 0
                },
                {
                    "sent": "We use update based on these rules.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we want to.",
                    "label": 0
                },
                {
                    "sent": "We also derive the mistake bounds for these classical ellipsoid algorithm.",
                    "label": 0
                },
                {
                    "sent": "So they basically were saying for any normalized.",
                    "label": 1
                },
                {
                    "sent": "Zyan normalized classifier optimal class from you will be able to find such.",
                    "label": 0
                },
                {
                    "sent": "So the the number of mistakes made by the algorithm just proposed on this side of data point is actually upper bounding by such such such quantity.",
                    "label": 1
                },
                {
                    "sent": "Actually if you manipulate quality or find that your font is exactly the same as mistake bound by perception algorithm just after the factor of constant.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To get the percentage so that remember the a parameter actually is used to somehow to tune the gamma yearly.",
                    "label": 0
                },
                {
                    "sent": "We can see if we set gamma to be 0.1, something that the aim parameters constant which is assigned to the proper value.",
                    "label": 0
                },
                {
                    "sent": "So a printer is no problem here.",
                    "label": 0
                },
                {
                    "sent": "So the message here is this mistake balances actually same with Mystic balance by perception algorithm up to a factor of constant.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so we just talk about the realizable case, which means there is a target classifier that can perfectly self raise the positive negative examples.",
                    "label": 0
                },
                {
                    "sent": "However, in real case you know there's unrealized, which means those are no such such such optimal classifier exists, and in that case people.",
                    "label": 0
                },
                {
                    "sent": "Usually they really look at the regret bound, right?",
                    "label": 0
                },
                {
                    "sent": "So we have we have some some manipulation about the geometric property here.",
                    "label": 0
                },
                {
                    "sent": "Which is we would try to we try to trade the center in the shape.",
                    "label": 0
                },
                {
                    "sent": "Metrics are the summarization of receiving training examples which if you look at this so the beauty the same.",
                    "label": 1
                },
                {
                    "sent": "It's like a combination of previous like training examples and you can look at it first.",
                    "label": 1
                },
                {
                    "sent": "Order statistics for the training information you received so far.",
                    "label": 0
                },
                {
                    "sent": "However, it's also attention will pay more attention, like at the peak, which is shaped metrics.",
                    "label": 0
                },
                {
                    "sent": "So we can.",
                    "label": 0
                },
                {
                    "sent": "We can write it in.",
                    "label": 0
                },
                {
                    "sent": "Formica citize ropy.",
                    "label": 0
                },
                {
                    "sent": "One, plus the summation over iterations, so it's like a mixture of the previous P metrics and the 2nd order statistic information of all the training example which received so far.",
                    "label": 1
                },
                {
                    "sent": "Somehow this is inverse of PPT metrics.",
                    "label": 0
                },
                {
                    "sent": "You can view it as weighted covariance matrix that stores the second out information between examples.",
                    "label": 1
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So by doing so we can we can we can think about this, so it's kind of a memory, right?",
                    "label": 0
                },
                {
                    "sent": "So we can somehow it just depends on how we write it.",
                    "label": 0
                },
                {
                    "sent": "We could also write it in this way.",
                    "label": 0
                },
                {
                    "sent": "The CT here actually is have exponential firm which is decayed exponentially overtime, which is here the C&B is just some constant we find out be equals to 0.3 as the reasonable one.",
                    "label": 0
                },
                {
                    "sent": "The details in the paper.",
                    "label": 0
                },
                {
                    "sent": "So basically we can see if we make cities such exponential firm than the influence of the 2nd order statistics of the training examples actually decayed exponentially overtime.",
                    "label": 0
                },
                {
                    "sent": "Right, so by varying such see and be the constant, we can somehow adjust this memory of the shape metrics.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So similarly, we will have the improved version of our learning method.",
                    "label": 0
                },
                {
                    "sent": "In the unreliable case.",
                    "label": 0
                },
                {
                    "sent": "So the only difference is this basically outlines the same as before.",
                    "label": 0
                },
                {
                    "sent": "The only difference is the PP metrics updating rules about the P metrics or be modified a little bit.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we will get the mistake bounds for for the improved ellipsoid method as well as Commission here.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I will skip the extension to the multiple label learning because.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's it's straightforward, and now we're going to look at it.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Elation station we do evaluate experiment several datasets, including USPS UCI letter you you see a shuttle this sites and we have two baseline here.",
                    "label": 0
                },
                {
                    "sent": "The one is the algorithm called outline passive aggressive algorithm.",
                    "label": 0
                },
                {
                    "sent": "Another is margin, infuse relaxed algorithm.",
                    "label": 0
                },
                {
                    "sent": "So they are state of our online learning algorithm in terms of performance and we're going to look at linear case basically means for other parameter.",
                    "label": 0
                },
                {
                    "sent": "Here we got going.",
                    "label": 0
                },
                {
                    "sent": "Set it to be a linear one, and we assume the margin gamma is 0.1 for all the baselines.",
                    "label": 0
                },
                {
                    "sent": "The test error will just be the number of mistakes made on the given sequence is divided by the length of the sequence.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here is the result results.",
                    "label": 0
                },
                {
                    "sent": "We can, we can.",
                    "label": 0
                },
                {
                    "sent": "So the first row is the mystery number mistake and the 2nd row is number of the applications need OK so we can find out.",
                    "label": 0
                },
                {
                    "sent": "So the there is 3 method here.",
                    "label": 0
                },
                {
                    "sent": "Pieza passive aggressive and Mira is the other other one.",
                    "label": 0
                },
                {
                    "sent": "Just mention is margin infused relaxed algorithm and there is not one ellipsoid is our algorithm so this is on different data site.",
                    "label": 1
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And this is 1 Apple.",
                    "label": 0
                },
                {
                    "sent": "This is another one is there are three apox entirely by Hawks.",
                    "label": 0
                },
                {
                    "sent": "We mean we somehow permutate the data set randomly and come up with different Apple.",
                    "label": 0
                },
                {
                    "sent": "So from this result you can find out actually the algorithm we proposed is.",
                    "label": 0
                },
                {
                    "sent": "They can parable or even better than the two baselines across data sites.",
                    "label": 0
                },
                {
                    "sent": "And also we find out we need less number of number of iterations to achieve such results.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So as a conclusion, so this work basically is the first attempt to explicitly represent the version space I talk about why we want to explicit represent and why we're interested very space, and how learning can benefit from such explicit representations of very space, and we somehow we represent, you know, we represent the version space available storage, so we can capture our classifiers that is consistent with hindsight.",
                    "label": 0
                },
                {
                    "sent": "And we derive the missing bounds which we have where we have shown that is the same with perceptual up to the constant factor and the shape metrics P allows us to store more information of the training examples and additional controls of the updating process.",
                    "label": 0
                },
                {
                    "sent": "So empirical study shows the ellipsoid method somehow is compatible with the states of ours online learners.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So do you have bounds on the unrelated case?",
                    "label": 0
                },
                {
                    "sent": "Other.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Tool.",
                    "label": 0
                },
                {
                    "sent": "Hence the best offline or something.",
                    "label": 0
                },
                {
                    "sent": "I mean, I have a bound, but what about if you tune those providers, and all of those?",
                    "label": 0
                },
                {
                    "sent": "You're saying which planet are you talking about?",
                    "label": 0
                },
                {
                    "sent": "the B or the sea?",
                    "label": 0
                },
                {
                    "sent": "You can see this is just up to a constant constant factor.",
                    "label": 1
                },
                {
                    "sent": "Sorry yeah.",
                    "label": 0
                },
                {
                    "sent": "How much?",
                    "label": 1
                },
                {
                    "sent": "How much more expensive is the algorithm?",
                    "label": 0
                },
                {
                    "sent": "Actually, it's it's not.",
                    "label": 0
                },
                {
                    "sent": "It's not.",
                    "label": 0
                },
                {
                    "sent": "It's not slow as I as I show, you know empirical study.",
                    "label": 0
                },
                {
                    "sent": "The number of iterations, right?",
                    "label": 0
                },
                {
                    "sent": "You're.",
                    "label": 0
                },
                {
                    "sent": "So we actually the the time for this algorithm is relative.",
                    "label": 0
                },
                {
                    "sent": "So this is this is the number of iterations is algorithm needs compared to perception.",
                    "label": 0
                },
                {
                    "sent": "Oh, it's very fast because you left side by nature is very efficiently updating.",
                    "label": 0
                },
                {
                    "sent": "Remember, I talked in the beginning like it's rule is very simple.",
                    "label": 0
                },
                {
                    "sent": "Yes, there is a step of matrix inverse.",
                    "label": 0
                },
                {
                    "sent": "So as I remember.",
                    "label": 0
                }
            ]
        }
    }
}