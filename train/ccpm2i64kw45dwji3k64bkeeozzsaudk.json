{
    "id": "ccpm2i64kw45dwji3k64bkeeozzsaudk",
    "title": "Continuous-Time Regression Models for Longitudinal Networks",
    "info": {
        "author": [
            "Arthur Asuncion, Center for Machine Learning and Intelligent Systems, University of California, Irvine"
        ],
        "published": "Jan. 25, 2012",
        "recorded": "December 2011",
        "category": [
            "Top->Computer Science->Machine Learning->Regression"
        ]
    },
    "url": "http://videolectures.net/nips2011_asuncion_networks/",
    "segmentation": [
        [
            "So today I'll be talking about how we can model fine grained longitudinal networks using continuous time regression."
        ],
        [
            "Models.",
            "And there are several motivations for why we would like to create continuous time regression models for long little networks.",
            "So consider the type of data that I that you see here on the screen.",
            "Say we have a network where we could observe timestamps on edge events so we could observe both nodes and edges appearing overtime in the network.",
            "One motivation for creating models over these types of networks is that we would like to be able to perform statistical analysis to see how network effects evolve overtime, so this is interesting.",
            "For instance, social scientists who would like to see how effects like reciprocity or transitivity change overtime.",
            "Creating such models is also important from a prediction perspective.",
            "So for instance, we'd like to be able to accurately predict which edge events will occur in the future.",
            "And it's also important to note that while there has been a fair amount of work on coarse grained modeling of longitudinal networks where you take snapshots of the network at discrete time intervals, there's relatively little work on continuous time network modeling, and so that's what we're trying to achieve in this paper, and actually another high level motivation for this work is we want to model the rates of.",
            "Edge formation for each edge and if we have a lot of nodes in the network, we would have a lot of possible edges and modeling.",
            "The all of these rates directly is infeasible, so we'd like to actually learn a parsimonious model for these rates."
        ],
        [
            "So here's an outline for the talk.",
            "1st, I'll discuss this notion of counting processes which we use as the underlying modeling mechanism.",
            "Then we'll look into how we can model the intensity process for edge formation using a few models.",
            "The Cox and alien models.",
            "And finally, we'll discuss inference methods and evaluation result."
        ],
        [
            "So the underlying modeling mechanism that we use is what's known as the counting process, and so we actually borrow this idea from the statistics literature from survival and event history analysis an within the network context.",
            "There are two possible formulations.",
            "There's the egocentric approach where we place a different counting process on each node in the network, and so in the ecocentric approach you can define the counting process.",
            "NIT as the cumulative number of events involving the ith node by time T. There's also the relational approach, where you place a different counting process on each edge in the network, and so in the relational case, the counting process NIJT is the cumulative number of events involving the ijaaf node pair bite time T."
        ],
        [
            "So to make this a little more concrete, let's take a look at a few examples of how this could be applied.",
            "One example for how we could apply the egocentric approach is on citation network data.",
            "So this was actually a case that we looked at back at ICML 2011, and so in this setup we observe new research papers joining the network overtime and at arrival of paper, cites others that are already in the citation network.",
            "So it creates links back to the other papers.",
            "So if the main dynamic development that we want to model is the number of citations received, then we can create define accounting process on each paper or each node an IT as the number of citations to paper.",
            "I at time T. So whenever a new paper comes into the citation network so that we would increment the counting processes of each of the cited papers."
        ],
        [
            "An example where the relational approach may be applied is on social network data, and so this is actually what we focus on in this paper, and one of the datasets that we looked at was the meta filter data set.",
            "An meta filter is a community web log for sharing links and discussing content among users and the pattern of Contacts on this website can be thought of as a dynamically evolving network and for this data we actually modeled.",
            "The links is being non recurrent, which means that once a link happens it stays there for the duration of the network and so we can define a really simple counting process here for each edge the counting process an IGT could either be zero or one.",
            "But this actually could be a generalized to recurrent data as well, such as email data where there can be multiple edge events between two nodes."
        ],
        [
            "So now that we've looked at some examples, let's let's discuss some of the underlying properties of counting processes.",
            "The first is that we combine the individual counting processes to form a multivariate counting process, where we don't need to make any assumptions about independence between elements.",
            "Since each of the individual accounting processes are nondecreasing in time, we could consider this multivariate counting process as a submartingale, which basically means that the expectation of the accounting process is nondecreasing."
        ],
        [
            "And this allows us to use the what's known as the dude Meyer decomposition to decompose the observed counts into two terms, a signal term and a noise term, and so let's focus on the signal term for the moment.",
            "It's an integral from zero to T of this Lambda function, or also known as the intensity function, and so the intensity function Lambda IJ of T can be thought of as the instantaneous rate.",
            "Of an edge event occurring between the IJ pair at time T."
        ],
        [
            "So now this raises a question.",
            "How can we model this intensity function?"
        ],
        [
            "So we look at two ways to model the intensity function.",
            "The first is known as the Cox proportional hazards model, which takes a multiplicative form and the 2nd is this Allen model which takes an additive form.",
            "And so let me describe each of the components of this intensity function.",
            "The first thing to note is.",
            "The intensity function at time T conditions on the entire past history of the network up to time T, so there we see we're conditioning on HT and this function depends on a few terms.",
            "The first is our IGT, which is what's known as an at risk indicator, and so this is a binary indicator that tells us whether or not an edge event between I&J is at risk of occurring at time T. So for instance, if either no die or no J are not in the network yet at time T, by definition this indicator would be 0.",
            "There's also these baseline hazard functions, A0, T for the Cox model and beta 0T for the alien model, and this is basically the the default rate at which events occur when the statistics are zero.",
            "And finally we have this combination between the coefficients that we'd like to estimate the betas and the statistics for the node pair, and there are few differences between the Coxon alien models, the first being that the Cox model has a multiplicative form and the other model has an additive form.",
            "Another difference is that for the alien model, the coefficients that we would like to estimate, the betas are actually time varying, while for the Cox model their time fixed.",
            "But for both models the statistics can be time varying."
        ],
        [
            "So here are some statistics that we considered in the paper.",
            "We looked at things like Indegree, outdegree, reciprocity.",
            "We also looked at triangle based statistics and.",
            "Our regression framework is pretty general in the sense that you could throw in arbitrary statistics.",
            "So for example, in the Citation Network case that we looked at back at I CML, we found that adding topic similarity statistics from latent dishley allocation greatly helped to improve predictive performance."
        ],
        [
            "OK, so now let's discuss."
        ],
        [
            "Inference methods.",
            "To fit the Cox model, we use a partial likelihood approach.",
            "And what we do here is we treat the baseline hazard A0 T as a nuisance parameter, which allows us to just optimize a simplified partial likelihood, which I show on the screen, and so we maximize this using Newton Raphson.",
            "Anne."
        ],
        [
            "The paper we actually discuss various computational tricks for speeding this up.",
            "An one of the tricks is actually speeding up the calculation of the denominator of the partial likelihood Kappa an we can write cap in terms of cap at the previous time point of the previous event plus some Delta, and we can actually calculate the deltas pretty quickly using caching and sparsity tricks."
        ],
        [
            "To fit the alien model, we use an approach similar to least squares and actually we don't do inference directly on the betas, but rather for their time integrals be and.",
            "The reason why we do this is it turns out that estimation is become similar to least squares when we when we estimate B.",
            "And so here the estimator for B is dependent on statistics matrix W. There's also this indicator J that indicates that W has full column rank as well as there's this Delta N, which is a vector denoting the change in account from the previous event to the current event.",
            "And if you look at it pretty closely, it looks like the normal equations in least squares and in the paper we actually discuss how we could.",
            "Use caching and sparsity tricks in this case as well to optimize this calculation and as well as doing a single online pass to learn all of the coefficients."
        ],
        [
            "So now let me just quickly go over our evaluation.",
            "We looked at both simulated and real networks.",
            "The real networks we looked at were Irvine which was an online social network among students at UC Irvine and as well as Metafilter."
        ],
        [
            "On the simulated data, our goal was to see whether we could accurately recover the time varying coefficients in the alien model and hear what we did was.",
            "We had ground truth coefficients an we simulated along digital datasets from it.",
            "So Symone had constant coefficients for reciprocity intransitivity while SIM two had varying coefficients for reciprocity and transitivity.",
            "And then once we had those simulated longitudinal networks, we then.",
            "Learn the time varying coefficients of the alien model an on the plots.",
            "Here I show both the ground truth and as well as the alien estimates, and in both the time varying and time fixed cases.",
            "The alien model can accurately recover the time varying coefficients."
        ],
        [
            "We also learned a Cox and alien models on the Irvine data set.",
            "And so on the.",
            "Right here I showed the in Ferndale and coefficients which we can actually interpret and it suggests that there are two distinct phases in network evolution for this data set, and that's actually consistent with an independent analysis of the data an on prediction experiments.",
            "We we compared the alien Cox models to an adaptive form of logistic regression, and actually I don't think you can see the curve of logistic regression, but it's actually it's below the coxswain alien models.",
            "So here I'm showing the recall as a function of cut point and both the alien and Cox models outperform the baseline of logistic regression for."
        ],
        [
            "Data set we also did a similar set of experiments on the meta filter data and what we found was when we infer the alien coefficient.",
            "So we saw that the network effects were continuously changing overtime.",
            "And another interesting thing is that we saw that the time varying alien model outperforms the Cox model.",
            "And the reason we think this is happening is because the alien model has time varying coefficients, while the Cox model has time fixed coefficients, and so since then the network effects here are changing more overtime, the alien model has more predictive performance in this case."
        ],
        [
            "Or predictive power in this case?",
            "OK, so to summarize, we have developed a continuous time regression model for longitudinal network data using counting processes, and we've shown how we can model the intensity process using two different models that Cox and Alien models, and we've looked at inference methods and evaluation results which suggests that we could interpret how network effects evolve, evolve overtime, and also predict future edge events."
        ],
        [
            "Thank you for your time and here are some references in case you're interested in these types of models.",
            "Thank you.",
            "Thanks for your interesting talk.",
            "I'm also interested in evolutionary networks.",
            "I have two questions regarding a talk.",
            "The first one is how did you do the regression?",
            "Was one step ahead or.",
            "Like how you did the prediction in?",
            "Yeah yeah.",
            "I was just predicting the next next event conditional on everything in the past.",
            "Yeah.",
            "And then the second thing is, do you think it is any possibility?",
            "There is any possibility to use any of the methods from the previous talk from evolutionary algorithms to to incorporate that into your evolving networks?",
            "Yeah, that's an interesting question.",
            "So, well, we haven't looked at that, so we've actually been just looking in the social network context, but it would be interesting actually to apply this to biological data as well, and maybe we could recast some of that work as statistics within our regression.",
            "Framework, so yeah, that would be an interesting direction to pursue.",
            "OK, I also have a question.",
            "Can you handle the recurring events in this framework?",
            "'cause it seems that you made the assumption at the beginning that there's just one event.",
            "Yeah, that's right, yeah.",
            "So there are few things we have to change in order to handle recurrent events.",
            "The first is we have to tailor the network statistics to be specific to the recurrent case.",
            "So in our paper we were tailoring the statistics to be similar to the.",
            "Non recurrent case, but if you have the recurrent case you could look at.",
            "Things like preferential attachment and another statistics that are better suited towards the recurrent case.",
            "You also have to change the at risk indicator so that it stays on indefinitely because now you can have arbitrary events, multiple events occurring between two nodes."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So today I'll be talking about how we can model fine grained longitudinal networks using continuous time regression.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Models.",
                    "label": 0
                },
                {
                    "sent": "And there are several motivations for why we would like to create continuous time regression models for long little networks.",
                    "label": 1
                },
                {
                    "sent": "So consider the type of data that I that you see here on the screen.",
                    "label": 0
                },
                {
                    "sent": "Say we have a network where we could observe timestamps on edge events so we could observe both nodes and edges appearing overtime in the network.",
                    "label": 1
                },
                {
                    "sent": "One motivation for creating models over these types of networks is that we would like to be able to perform statistical analysis to see how network effects evolve overtime, so this is interesting.",
                    "label": 0
                },
                {
                    "sent": "For instance, social scientists who would like to see how effects like reciprocity or transitivity change overtime.",
                    "label": 0
                },
                {
                    "sent": "Creating such models is also important from a prediction perspective.",
                    "label": 0
                },
                {
                    "sent": "So for instance, we'd like to be able to accurately predict which edge events will occur in the future.",
                    "label": 0
                },
                {
                    "sent": "And it's also important to note that while there has been a fair amount of work on coarse grained modeling of longitudinal networks where you take snapshots of the network at discrete time intervals, there's relatively little work on continuous time network modeling, and so that's what we're trying to achieve in this paper, and actually another high level motivation for this work is we want to model the rates of.",
                    "label": 1
                },
                {
                    "sent": "Edge formation for each edge and if we have a lot of nodes in the network, we would have a lot of possible edges and modeling.",
                    "label": 0
                },
                {
                    "sent": "The all of these rates directly is infeasible, so we'd like to actually learn a parsimonious model for these rates.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's an outline for the talk.",
                    "label": 0
                },
                {
                    "sent": "1st, I'll discuss this notion of counting processes which we use as the underlying modeling mechanism.",
                    "label": 0
                },
                {
                    "sent": "Then we'll look into how we can model the intensity process for edge formation using a few models.",
                    "label": 1
                },
                {
                    "sent": "The Cox and alien models.",
                    "label": 0
                },
                {
                    "sent": "And finally, we'll discuss inference methods and evaluation result.",
                    "label": 1
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the underlying modeling mechanism that we use is what's known as the counting process, and so we actually borrow this idea from the statistics literature from survival and event history analysis an within the network context.",
                    "label": 0
                },
                {
                    "sent": "There are two possible formulations.",
                    "label": 0
                },
                {
                    "sent": "There's the egocentric approach where we place a different counting process on each node in the network, and so in the ecocentric approach you can define the counting process.",
                    "label": 0
                },
                {
                    "sent": "NIT as the cumulative number of events involving the ith node by time T. There's also the relational approach, where you place a different counting process on each edge in the network, and so in the relational case, the counting process NIJT is the cumulative number of events involving the ijaaf node pair bite time T.",
                    "label": 1
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to make this a little more concrete, let's take a look at a few examples of how this could be applied.",
                    "label": 0
                },
                {
                    "sent": "One example for how we could apply the egocentric approach is on citation network data.",
                    "label": 0
                },
                {
                    "sent": "So this was actually a case that we looked at back at ICML 2011, and so in this setup we observe new research papers joining the network overtime and at arrival of paper, cites others that are already in the citation network.",
                    "label": 1
                },
                {
                    "sent": "So it creates links back to the other papers.",
                    "label": 0
                },
                {
                    "sent": "So if the main dynamic development that we want to model is the number of citations received, then we can create define accounting process on each paper or each node an IT as the number of citations to paper.",
                    "label": 1
                },
                {
                    "sent": "I at time T. So whenever a new paper comes into the citation network so that we would increment the counting processes of each of the cited papers.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "An example where the relational approach may be applied is on social network data, and so this is actually what we focus on in this paper, and one of the datasets that we looked at was the meta filter data set.",
                    "label": 0
                },
                {
                    "sent": "An meta filter is a community web log for sharing links and discussing content among users and the pattern of Contacts on this website can be thought of as a dynamically evolving network and for this data we actually modeled.",
                    "label": 1
                },
                {
                    "sent": "The links is being non recurrent, which means that once a link happens it stays there for the duration of the network and so we can define a really simple counting process here for each edge the counting process an IGT could either be zero or one.",
                    "label": 0
                },
                {
                    "sent": "But this actually could be a generalized to recurrent data as well, such as email data where there can be multiple edge events between two nodes.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now that we've looked at some examples, let's let's discuss some of the underlying properties of counting processes.",
                    "label": 0
                },
                {
                    "sent": "The first is that we combine the individual counting processes to form a multivariate counting process, where we don't need to make any assumptions about independence between elements.",
                    "label": 1
                },
                {
                    "sent": "Since each of the individual accounting processes are nondecreasing in time, we could consider this multivariate counting process as a submartingale, which basically means that the expectation of the accounting process is nondecreasing.",
                    "label": 1
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And this allows us to use the what's known as the dude Meyer decomposition to decompose the observed counts into two terms, a signal term and a noise term, and so let's focus on the signal term for the moment.",
                    "label": 0
                },
                {
                    "sent": "It's an integral from zero to T of this Lambda function, or also known as the intensity function, and so the intensity function Lambda IJ of T can be thought of as the instantaneous rate.",
                    "label": 0
                },
                {
                    "sent": "Of an edge event occurring between the IJ pair at time T.",
                    "label": 1
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now this raises a question.",
                    "label": 0
                },
                {
                    "sent": "How can we model this intensity function?",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we look at two ways to model the intensity function.",
                    "label": 0
                },
                {
                    "sent": "The first is known as the Cox proportional hazards model, which takes a multiplicative form and the 2nd is this Allen model which takes an additive form.",
                    "label": 0
                },
                {
                    "sent": "And so let me describe each of the components of this intensity function.",
                    "label": 0
                },
                {
                    "sent": "The first thing to note is.",
                    "label": 0
                },
                {
                    "sent": "The intensity function at time T conditions on the entire past history of the network up to time T, so there we see we're conditioning on HT and this function depends on a few terms.",
                    "label": 1
                },
                {
                    "sent": "The first is our IGT, which is what's known as an at risk indicator, and so this is a binary indicator that tells us whether or not an edge event between I&J is at risk of occurring at time T. So for instance, if either no die or no J are not in the network yet at time T, by definition this indicator would be 0.",
                    "label": 0
                },
                {
                    "sent": "There's also these baseline hazard functions, A0, T for the Cox model and beta 0T for the alien model, and this is basically the the default rate at which events occur when the statistics are zero.",
                    "label": 0
                },
                {
                    "sent": "And finally we have this combination between the coefficients that we'd like to estimate the betas and the statistics for the node pair, and there are few differences between the Coxon alien models, the first being that the Cox model has a multiplicative form and the other model has an additive form.",
                    "label": 0
                },
                {
                    "sent": "Another difference is that for the alien model, the coefficients that we would like to estimate, the betas are actually time varying, while for the Cox model their time fixed.",
                    "label": 0
                },
                {
                    "sent": "But for both models the statistics can be time varying.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here are some statistics that we considered in the paper.",
                    "label": 0
                },
                {
                    "sent": "We looked at things like Indegree, outdegree, reciprocity.",
                    "label": 0
                },
                {
                    "sent": "We also looked at triangle based statistics and.",
                    "label": 0
                },
                {
                    "sent": "Our regression framework is pretty general in the sense that you could throw in arbitrary statistics.",
                    "label": 0
                },
                {
                    "sent": "So for example, in the Citation Network case that we looked at back at I CML, we found that adding topic similarity statistics from latent dishley allocation greatly helped to improve predictive performance.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so now let's discuss.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Inference methods.",
                    "label": 0
                },
                {
                    "sent": "To fit the Cox model, we use a partial likelihood approach.",
                    "label": 1
                },
                {
                    "sent": "And what we do here is we treat the baseline hazard A0 T as a nuisance parameter, which allows us to just optimize a simplified partial likelihood, which I show on the screen, and so we maximize this using Newton Raphson.",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The paper we actually discuss various computational tricks for speeding this up.",
                    "label": 0
                },
                {
                    "sent": "An one of the tricks is actually speeding up the calculation of the denominator of the partial likelihood Kappa an we can write cap in terms of cap at the previous time point of the previous event plus some Delta, and we can actually calculate the deltas pretty quickly using caching and sparsity tricks.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To fit the alien model, we use an approach similar to least squares and actually we don't do inference directly on the betas, but rather for their time integrals be and.",
                    "label": 1
                },
                {
                    "sent": "The reason why we do this is it turns out that estimation is become similar to least squares when we when we estimate B.",
                    "label": 0
                },
                {
                    "sent": "And so here the estimator for B is dependent on statistics matrix W. There's also this indicator J that indicates that W has full column rank as well as there's this Delta N, which is a vector denoting the change in account from the previous event to the current event.",
                    "label": 0
                },
                {
                    "sent": "And if you look at it pretty closely, it looks like the normal equations in least squares and in the paper we actually discuss how we could.",
                    "label": 0
                },
                {
                    "sent": "Use caching and sparsity tricks in this case as well to optimize this calculation and as well as doing a single online pass to learn all of the coefficients.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now let me just quickly go over our evaluation.",
                    "label": 0
                },
                {
                    "sent": "We looked at both simulated and real networks.",
                    "label": 0
                },
                {
                    "sent": "The real networks we looked at were Irvine which was an online social network among students at UC Irvine and as well as Metafilter.",
                    "label": 1
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "On the simulated data, our goal was to see whether we could accurately recover the time varying coefficients in the alien model and hear what we did was.",
                    "label": 0
                },
                {
                    "sent": "We had ground truth coefficients an we simulated along digital datasets from it.",
                    "label": 1
                },
                {
                    "sent": "So Symone had constant coefficients for reciprocity intransitivity while SIM two had varying coefficients for reciprocity and transitivity.",
                    "label": 1
                },
                {
                    "sent": "And then once we had those simulated longitudinal networks, we then.",
                    "label": 0
                },
                {
                    "sent": "Learn the time varying coefficients of the alien model an on the plots.",
                    "label": 0
                },
                {
                    "sent": "Here I show both the ground truth and as well as the alien estimates, and in both the time varying and time fixed cases.",
                    "label": 0
                },
                {
                    "sent": "The alien model can accurately recover the time varying coefficients.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We also learned a Cox and alien models on the Irvine data set.",
                    "label": 0
                },
                {
                    "sent": "And so on the.",
                    "label": 0
                },
                {
                    "sent": "Right here I showed the in Ferndale and coefficients which we can actually interpret and it suggests that there are two distinct phases in network evolution for this data set, and that's actually consistent with an independent analysis of the data an on prediction experiments.",
                    "label": 1
                },
                {
                    "sent": "We we compared the alien Cox models to an adaptive form of logistic regression, and actually I don't think you can see the curve of logistic regression, but it's actually it's below the coxswain alien models.",
                    "label": 0
                },
                {
                    "sent": "So here I'm showing the recall as a function of cut point and both the alien and Cox models outperform the baseline of logistic regression for.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Data set we also did a similar set of experiments on the meta filter data and what we found was when we infer the alien coefficient.",
                    "label": 0
                },
                {
                    "sent": "So we saw that the network effects were continuously changing overtime.",
                    "label": 0
                },
                {
                    "sent": "And another interesting thing is that we saw that the time varying alien model outperforms the Cox model.",
                    "label": 1
                },
                {
                    "sent": "And the reason we think this is happening is because the alien model has time varying coefficients, while the Cox model has time fixed coefficients, and so since then the network effects here are changing more overtime, the alien model has more predictive performance in this case.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Or predictive power in this case?",
                    "label": 0
                },
                {
                    "sent": "OK, so to summarize, we have developed a continuous time regression model for longitudinal network data using counting processes, and we've shown how we can model the intensity process using two different models that Cox and Alien models, and we've looked at inference methods and evaluation results which suggests that we could interpret how network effects evolve, evolve overtime, and also predict future edge events.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you for your time and here are some references in case you're interested in these types of models.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Thanks for your interesting talk.",
                    "label": 0
                },
                {
                    "sent": "I'm also interested in evolutionary networks.",
                    "label": 0
                },
                {
                    "sent": "I have two questions regarding a talk.",
                    "label": 0
                },
                {
                    "sent": "The first one is how did you do the regression?",
                    "label": 0
                },
                {
                    "sent": "Was one step ahead or.",
                    "label": 0
                },
                {
                    "sent": "Like how you did the prediction in?",
                    "label": 0
                },
                {
                    "sent": "Yeah yeah.",
                    "label": 0
                },
                {
                    "sent": "I was just predicting the next next event conditional on everything in the past.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "And then the second thing is, do you think it is any possibility?",
                    "label": 0
                },
                {
                    "sent": "There is any possibility to use any of the methods from the previous talk from evolutionary algorithms to to incorporate that into your evolving networks?",
                    "label": 0
                },
                {
                    "sent": "Yeah, that's an interesting question.",
                    "label": 0
                },
                {
                    "sent": "So, well, we haven't looked at that, so we've actually been just looking in the social network context, but it would be interesting actually to apply this to biological data as well, and maybe we could recast some of that work as statistics within our regression.",
                    "label": 0
                },
                {
                    "sent": "Framework, so yeah, that would be an interesting direction to pursue.",
                    "label": 0
                },
                {
                    "sent": "OK, I also have a question.",
                    "label": 0
                },
                {
                    "sent": "Can you handle the recurring events in this framework?",
                    "label": 0
                },
                {
                    "sent": "'cause it seems that you made the assumption at the beginning that there's just one event.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that's right, yeah.",
                    "label": 0
                },
                {
                    "sent": "So there are few things we have to change in order to handle recurrent events.",
                    "label": 0
                },
                {
                    "sent": "The first is we have to tailor the network statistics to be specific to the recurrent case.",
                    "label": 0
                },
                {
                    "sent": "So in our paper we were tailoring the statistics to be similar to the.",
                    "label": 0
                },
                {
                    "sent": "Non recurrent case, but if you have the recurrent case you could look at.",
                    "label": 0
                },
                {
                    "sent": "Things like preferential attachment and another statistics that are better suited towards the recurrent case.",
                    "label": 0
                },
                {
                    "sent": "You also have to change the at risk indicator so that it stays on indefinitely because now you can have arbitrary events, multiple events occurring between two nodes.",
                    "label": 0
                }
            ]
        }
    }
}