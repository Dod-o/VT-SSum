{
    "id": "jxj7qeloycuw3mfs44jyvs3ucrkexjjj",
    "title": "On the Complexity of Bandit and Derivative-Free Stochastic Convex Optimization",
    "info": {
        "author": [
            "Ohad Shamir, Faculty of Mathematics and Computer Science, Weizmann Institute of Science"
        ],
        "published": "Aug. 9, 2013",
        "recorded": "June 2013",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/colt2013_shamir_optimization/",
    "segmentation": [
        [
            "OK, so this."
        ],
        [
            "As of about a very simple and fundamental questions, so we're assuming we have some convex domain in Canadian space and some unknown convex function.",
            "We don't know it.",
            "The only thing we can do is to query various points and get a noisy version of the function value at that point, and our goal using is that using as few queries as possible.",
            "We want to optimize this function.",
            "I notice that we have access just to the function values we don't have.",
            "Access to the gradients or the hessian's and so on, so."
        ],
        [
            "This question was studied in at least two communities.",
            "So in the optimization community it's known as derivative free or zero order stochastic convex optimization, with the motivation being black box situations where we don't have access to the function itself or its gradient.",
            "So you can think of the value being the results have some stochastic simulation, so we only get values and our goal is to minimize the optimization error.",
            "So after T queries return some predictor AW party which is as close as possible to the optimal.",
            "And the online learning community.",
            "This setting was of course studied in the context of bandit stochastic convex optimization to model sequential decision making under uncertainty.",
            "So for instance, the case of multi arm bandits and the goal there is usually to minimize regret.",
            "So we have to.",
            "Produce some point after every round and we want the average value of these points to be close to the optimum.",
            "Notice that by Jensen's inequality getting small regret is only harder than getting small error because if we have small regret we can just run the online learning algorithm, return the average and it would have a similarly small optimization error."
        ],
        [
            "And what we're going to be interested in is what kind of error or regret we can get in terms of two important quantities.",
            "So the number of queries and the dimension of our space.",
            "So if we have a gradient information, then things are very, very clear.",
            "We know that for convex problems you can get a 1 / sqrt T rate before Aaron regret, and it's tight if it's strongly convex.",
            "It's 1 / T. Or maybe with an additional log factor in the case of regret.",
            "But when we move to the."
        ],
        [
            "Yes, a bandit or derivative case.",
            "Things are much less clear, so one setting where things are pretty well understood is in the multi armed bandit setting, which corresponds to a linear function and the domain being simplex where the attainable radius sqrt D / T. But once we move to more general cases, things are much less clear, so even if we still talk about linear functions then the bound starts to depend on the domain in nontrivial ways.",
            "And usually it's either square root of the over 2 square root of these squared.",
            "The case of these squared, it's usually cases where the domain is constructed in a very careful and usually artificial way.",
            "An once we talk about more general functions, nonlinear functions, then things are pretty pretty open.",
            "So basically the state of the art is that we have two algorithmic methods, one of them gives us a pretty good dependence on the dimension.",
            "A quadratic dependence on the dimension, but.",
            "The rate is just one 4th.",
            "An alternative method gives you an optimal square root of T dependence, but a horrible dimension dependent sounds like D to the 34th and this problem has been open for quite a long time.",
            "Even if you go to classical works like can, you didn't nemerofsky they point out how we seem to be able to get either good rates or good dimension dependence but not.",
            "Best of both of them, and the situation is pretty far from clear."
        ],
        [
            "OK, So what we do in our work is to try and study the inherent complexity of nonlinear bandit or derivative free convex optimization, focusing on strongly convex functions, and we have several results, so the 1st result is that for strongly convex and smooth functions, both the error and the regret are of the form of square root of the squared over T and this, so the upper bound was known and we get matching the lower bound.",
            "This also has several implications, so as far as we know, the first tight characterization for a general class without making any special assumptions about the domain.",
            "It shows that, unlike, say, multi armed bandits, the price that you pay for bandit information fact that you get only function values as opposed to gradients is probably quadratic in the dimension, not just a linear, and this new lower bound also immediately gives us new lower bounds for.",
            "More general cases for strongly convex and convex functions."
        ],
        [
            "The 2nd result is that if we look at a natural special case of strongly convex and smooth functions that is quadratic functions, we can actually get 1 / T rates or D ^2 / T rate to be exact, which shows that at least in this setting, it's possible to get fast rate even without any gradient information, which may be a bit surprising when you think about it, because even if we care about the value of a function at some fixed points and we have T. Queries we can't estimate it at the rate better than a 1 / sqrt T. And by the way, Interestingly, there was a paper at NIPS at last Nips, which discuss a similar setting and try to show that you cannot get something better than a 1 / sqrt T, But there is a subtlety in their proof that we're able to circumvent an.",
            "I'll discuss it a bit more later.",
            "The 3rd result.",
            "So the result I talked about talks about the error, but if we talk about regret then even if we discuss quadratic functions, the regret is no better than a square root of this squared over T. So you have this large polynomial gap between what you get in terms of error and what you get in terms of regret."
        ],
        [
            "And just to summarize things in a table, so the blue things are new results, so again, we have this new lower bound implying a quadratic dependence on the dimension.",
            "We can characterize things for strongly convex and smooth functions an in the quadratic case we have this interesting gap between the error in their regret.",
            "Again, things are the upper and lower bounds match."
        ],
        [
            "OK, so getting a bit more into the details, so quadratic functions are of course functions of this form where we assume that we have strong convexity and just for simplicity we're going to scale everything so all the norms are bounded by one and we're going to make the assumption that we are allowed to query in some radius around the optimum and this is a very natural assumption here because we strongly convex functions.",
            "It's pretty rare to have the optimum.",
            "Exactly at the domain boundary, in contrast to the linear case, for instance, where the optimum is always at the domain boundary, and."
        ],
        [
            "With this assumption, we can use a very simple algorithm.",
            "There is not.",
            "It uses a standard technique where we do stochastic gradient descent with a one point gradient estimate.",
            "The only key new idea here is that we allow ourselves to query points relatively far away from our current iterate WT.",
            "So in previous works, when people apply this method, they were forced to query a very close to WT.",
            "Because otherwise you get large biased terms, but then you also have a lot of variance, but with quadratic functions they have this nice structure, which means that even if we query very far away we can get a good gradient estimates without bias because Mcqueary far away the variance is also small and that's how we can get a fast 1 / T rate."
        ],
        [
            "And this is the formal statement, and the reason that we can circumvent the previous lower bound which showed the square root over T an lower bound was that their domain was not fixed but actually depended on T, which meant that you basically had.",
            "You were forced to query very, very close to the to the optimum.",
            "But if you.",
            "Don't insist on a fixed domain, it's a fixed epsilon.",
            "You get 1 / T rate.",
            "OK, so these are this is the."
        ],
        [
            "Are bound, by the way, under certain assumptions, it's also possible to improve the dependence on the dimension.",
            "I'm not going to go into it, so if you assume that you have a strongly convex component that is known, some circularization you can improve things.",
            "But again I'll skip it, yes.",
            "Some sense.",
            "Is lamb depending on.",
            "And no, we assume its parameters.",
            "It's a lower bound on the closing value.",
            "Yes, yes.",
            "Yeah, it's a strong convexity parameter, yeah?"
        ],
        [
            "OK, so moving to the lower bound, so this said so the 1st result is that our upper bound is tight, it's D ^2 / T in the quadratic case.",
            "And notice that this thing holds without making any sort of special domain assumptions.",
            "You can assume the main is the unit ball.",
            "It can even be all of the Canadian space because it's a strongly convex function, that's fine."
        ],
        [
            "The hard part, so I won't go into all the details, but basically the hard part is showing that you indeed get this quadratic dependence on the dimension and the key idea is to construct this example where what the learner is trying to do is sort of reduced to a.",
            "A handling a sum of DNA, separate hypothesis testing problems, one for each.",
            "For each coordinate, so the kind of function is just a quadratic with a linear term, where this E is unknown, an you basically need to be able to guess based on the data in the sign of each of the coordinates of A and because the lower bound depends on the sum of these hypothesis testing problems, that's why you get quadratic dependence again without getting into the formal details."
        ],
        [
            "OK, so that was a for the error, but as I said earlier, if we talked about regret, we can prove a much stronger lower bound of square root of the squared over T and the key idea is actually very simple.",
            "So if you look at the analysis more carefully then you notice that the lower bound actually depends on the norm of the points that you query.",
            "If you query very far away.",
            "So consider the one dimensional.",
            "Inversion so basically need to distinguish whether we handle the red parabola or the blue parabola.",
            "If we query very far away, it's easier to distinguish which of the parabolas we're dealing with just because of the nature of the quadratic function.",
            "So for error we can query everywhere we want, but to get small regret, we cannot query too far away from the optimum, so it's like no win situation here either we query far away and get more information.",
            "But then our regret is bad or we query close to the optimum and are regretted smaller.",
            "But then we get less information.",
            "And either way you can't win and that's why you get back the square root of T dependence."
        ],
        [
            "The last lower bound is for strongly convex and smooth functions, where we show that even if we talk about the error, not about regret, it still no better than square root of the squared over T, so we've seen that with quadratic functions we can get something better.",
            "So the example would have to be a non quadratic function.",
            "And again, the basic idea is quite simple, so we look at a function which has this form.",
            "It may not be immediate, but this is a strongly convex and smooth function, and it has this property that it close to the optimum.",
            "Again, depending on the values of E if we choose.",
            "Then close to the optimum, it behaves like parabola which depends on E. But when you look further away it becomes just W squared.",
            "So you sort of recover the same lower bound that we got for regret because you can try to query a far away.",
            "But this doesn't give you a more information, unlike the case of a quadratic function, so we get the same kind of lower bound as we got.",
            "4A regret in the quadratic case.",
            "OK."
        ],
        [
            "So just to summarize, so we got an exact representation of what you can get in the bandit or derivative case for strongly convex and smooth functions, which also implies a new lower bound for more general settings.",
            "An showing that for these kinds of general functions, a quadratic dependence on the dimension is inevitable.",
            "That is, the price of benefit information.",
            "Here, on the other hand, for quadratic functions you can get fast.",
            "Error rate and you have these interesting gaps between what you can get in terms of communication error and what you can get in terms of regret and maybe the main or open question is trying to understand what is the true rate in the more general cases.",
            "So either strongly convex with possibly nonsmooth problems, or the general convex problems and.",
            "Again we have upper bounds which are really not matching either in terms of the dimension or in terms of the rate.",
            "My conjecture is that the right answer is square root of the squared over T first of all, because that's my lower bound, but also because this seems to be the thing you get if you take the best of both upper bounds that we currently have.",
            "The quadratic depends on the dimension and square root of T dependence.",
            "But we don't know how to get this with any of our existing algorithms, so we need some new algorithm to be able to get that.",
            "So that's it.",
            "Thank you very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so this.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As of about a very simple and fundamental questions, so we're assuming we have some convex domain in Canadian space and some unknown convex function.",
                    "label": 1
                },
                {
                    "sent": "We don't know it.",
                    "label": 0
                },
                {
                    "sent": "The only thing we can do is to query various points and get a noisy version of the function value at that point, and our goal using is that using as few queries as possible.",
                    "label": 1
                },
                {
                    "sent": "We want to optimize this function.",
                    "label": 0
                },
                {
                    "sent": "I notice that we have access just to the function values we don't have.",
                    "label": 0
                },
                {
                    "sent": "Access to the gradients or the hessian's and so on, so.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This question was studied in at least two communities.",
                    "label": 0
                },
                {
                    "sent": "So in the optimization community it's known as derivative free or zero order stochastic convex optimization, with the motivation being black box situations where we don't have access to the function itself or its gradient.",
                    "label": 0
                },
                {
                    "sent": "So you can think of the value being the results have some stochastic simulation, so we only get values and our goal is to minimize the optimization error.",
                    "label": 0
                },
                {
                    "sent": "So after T queries return some predictor AW party which is as close as possible to the optimal.",
                    "label": 0
                },
                {
                    "sent": "And the online learning community.",
                    "label": 1
                },
                {
                    "sent": "This setting was of course studied in the context of bandit stochastic convex optimization to model sequential decision making under uncertainty.",
                    "label": 1
                },
                {
                    "sent": "So for instance, the case of multi arm bandits and the goal there is usually to minimize regret.",
                    "label": 0
                },
                {
                    "sent": "So we have to.",
                    "label": 0
                },
                {
                    "sent": "Produce some point after every round and we want the average value of these points to be close to the optimum.",
                    "label": 0
                },
                {
                    "sent": "Notice that by Jensen's inequality getting small regret is only harder than getting small error because if we have small regret we can just run the online learning algorithm, return the average and it would have a similarly small optimization error.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And what we're going to be interested in is what kind of error or regret we can get in terms of two important quantities.",
                    "label": 1
                },
                {
                    "sent": "So the number of queries and the dimension of our space.",
                    "label": 1
                },
                {
                    "sent": "So if we have a gradient information, then things are very, very clear.",
                    "label": 0
                },
                {
                    "sent": "We know that for convex problems you can get a 1 / sqrt T rate before Aaron regret, and it's tight if it's strongly convex.",
                    "label": 0
                },
                {
                    "sent": "It's 1 / T. Or maybe with an additional log factor in the case of regret.",
                    "label": 0
                },
                {
                    "sent": "But when we move to the.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Yes, a bandit or derivative case.",
                    "label": 0
                },
                {
                    "sent": "Things are much less clear, so one setting where things are pretty well understood is in the multi armed bandit setting, which corresponds to a linear function and the domain being simplex where the attainable radius sqrt D / T. But once we move to more general cases, things are much less clear, so even if we still talk about linear functions then the bound starts to depend on the domain in nontrivial ways.",
                    "label": 0
                },
                {
                    "sent": "And usually it's either square root of the over 2 square root of these squared.",
                    "label": 1
                },
                {
                    "sent": "The case of these squared, it's usually cases where the domain is constructed in a very careful and usually artificial way.",
                    "label": 0
                },
                {
                    "sent": "An once we talk about more general functions, nonlinear functions, then things are pretty pretty open.",
                    "label": 0
                },
                {
                    "sent": "So basically the state of the art is that we have two algorithmic methods, one of them gives us a pretty good dependence on the dimension.",
                    "label": 0
                },
                {
                    "sent": "A quadratic dependence on the dimension, but.",
                    "label": 0
                },
                {
                    "sent": "The rate is just one 4th.",
                    "label": 0
                },
                {
                    "sent": "An alternative method gives you an optimal square root of T dependence, but a horrible dimension dependent sounds like D to the 34th and this problem has been open for quite a long time.",
                    "label": 0
                },
                {
                    "sent": "Even if you go to classical works like can, you didn't nemerofsky they point out how we seem to be able to get either good rates or good dimension dependence but not.",
                    "label": 0
                },
                {
                    "sent": "Best of both of them, and the situation is pretty far from clear.",
                    "label": 1
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, So what we do in our work is to try and study the inherent complexity of nonlinear bandit or derivative free convex optimization, focusing on strongly convex functions, and we have several results, so the 1st result is that for strongly convex and smooth functions, both the error and the regret are of the form of square root of the squared over T and this, so the upper bound was known and we get matching the lower bound.",
                    "label": 1
                },
                {
                    "sent": "This also has several implications, so as far as we know, the first tight characterization for a general class without making any special assumptions about the domain.",
                    "label": 1
                },
                {
                    "sent": "It shows that, unlike, say, multi armed bandits, the price that you pay for bandit information fact that you get only function values as opposed to gradients is probably quadratic in the dimension, not just a linear, and this new lower bound also immediately gives us new lower bounds for.",
                    "label": 0
                },
                {
                    "sent": "More general cases for strongly convex and convex functions.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The 2nd result is that if we look at a natural special case of strongly convex and smooth functions that is quadratic functions, we can actually get 1 / T rates or D ^2 / T rate to be exact, which shows that at least in this setting, it's possible to get fast rate even without any gradient information, which may be a bit surprising when you think about it, because even if we care about the value of a function at some fixed points and we have T. Queries we can't estimate it at the rate better than a 1 / sqrt T. And by the way, Interestingly, there was a paper at NIPS at last Nips, which discuss a similar setting and try to show that you cannot get something better than a 1 / sqrt T, But there is a subtlety in their proof that we're able to circumvent an.",
                    "label": 1
                },
                {
                    "sent": "I'll discuss it a bit more later.",
                    "label": 0
                },
                {
                    "sent": "The 3rd result.",
                    "label": 1
                },
                {
                    "sent": "So the result I talked about talks about the error, but if we talk about regret then even if we discuss quadratic functions, the regret is no better than a square root of this squared over T. So you have this large polynomial gap between what you get in terms of error and what you get in terms of regret.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And just to summarize things in a table, so the blue things are new results, so again, we have this new lower bound implying a quadratic dependence on the dimension.",
                    "label": 0
                },
                {
                    "sent": "We can characterize things for strongly convex and smooth functions an in the quadratic case we have this interesting gap between the error in their regret.",
                    "label": 0
                },
                {
                    "sent": "Again, things are the upper and lower bounds match.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so getting a bit more into the details, so quadratic functions are of course functions of this form where we assume that we have strong convexity and just for simplicity we're going to scale everything so all the norms are bounded by one and we're going to make the assumption that we are allowed to query in some radius around the optimum and this is a very natural assumption here because we strongly convex functions.",
                    "label": 0
                },
                {
                    "sent": "It's pretty rare to have the optimum.",
                    "label": 0
                },
                {
                    "sent": "Exactly at the domain boundary, in contrast to the linear case, for instance, where the optimum is always at the domain boundary, and.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With this assumption, we can use a very simple algorithm.",
                    "label": 0
                },
                {
                    "sent": "There is not.",
                    "label": 0
                },
                {
                    "sent": "It uses a standard technique where we do stochastic gradient descent with a one point gradient estimate.",
                    "label": 0
                },
                {
                    "sent": "The only key new idea here is that we allow ourselves to query points relatively far away from our current iterate WT.",
                    "label": 0
                },
                {
                    "sent": "So in previous works, when people apply this method, they were forced to query a very close to WT.",
                    "label": 0
                },
                {
                    "sent": "Because otherwise you get large biased terms, but then you also have a lot of variance, but with quadratic functions they have this nice structure, which means that even if we query very far away we can get a good gradient estimates without bias because Mcqueary far away the variance is also small and that's how we can get a fast 1 / T rate.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is the formal statement, and the reason that we can circumvent the previous lower bound which showed the square root over T an lower bound was that their domain was not fixed but actually depended on T, which meant that you basically had.",
                    "label": 0
                },
                {
                    "sent": "You were forced to query very, very close to the to the optimum.",
                    "label": 0
                },
                {
                    "sent": "But if you.",
                    "label": 0
                },
                {
                    "sent": "Don't insist on a fixed domain, it's a fixed epsilon.",
                    "label": 0
                },
                {
                    "sent": "You get 1 / T rate.",
                    "label": 0
                },
                {
                    "sent": "OK, so these are this is the.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Are bound, by the way, under certain assumptions, it's also possible to improve the dependence on the dimension.",
                    "label": 0
                },
                {
                    "sent": "I'm not going to go into it, so if you assume that you have a strongly convex component that is known, some circularization you can improve things.",
                    "label": 0
                },
                {
                    "sent": "But again I'll skip it, yes.",
                    "label": 0
                },
                {
                    "sent": "Some sense.",
                    "label": 0
                },
                {
                    "sent": "Is lamb depending on.",
                    "label": 0
                },
                {
                    "sent": "And no, we assume its parameters.",
                    "label": 0
                },
                {
                    "sent": "It's a lower bound on the closing value.",
                    "label": 0
                },
                {
                    "sent": "Yes, yes.",
                    "label": 0
                },
                {
                    "sent": "Yeah, it's a strong convexity parameter, yeah?",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so moving to the lower bound, so this said so the 1st result is that our upper bound is tight, it's D ^2 / T in the quadratic case.",
                    "label": 0
                },
                {
                    "sent": "And notice that this thing holds without making any sort of special domain assumptions.",
                    "label": 0
                },
                {
                    "sent": "You can assume the main is the unit ball.",
                    "label": 0
                },
                {
                    "sent": "It can even be all of the Canadian space because it's a strongly convex function, that's fine.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The hard part, so I won't go into all the details, but basically the hard part is showing that you indeed get this quadratic dependence on the dimension and the key idea is to construct this example where what the learner is trying to do is sort of reduced to a.",
                    "label": 1
                },
                {
                    "sent": "A handling a sum of DNA, separate hypothesis testing problems, one for each.",
                    "label": 1
                },
                {
                    "sent": "For each coordinate, so the kind of function is just a quadratic with a linear term, where this E is unknown, an you basically need to be able to guess based on the data in the sign of each of the coordinates of A and because the lower bound depends on the sum of these hypothesis testing problems, that's why you get quadratic dependence again without getting into the formal details.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so that was a for the error, but as I said earlier, if we talked about regret, we can prove a much stronger lower bound of square root of the squared over T and the key idea is actually very simple.",
                    "label": 0
                },
                {
                    "sent": "So if you look at the analysis more carefully then you notice that the lower bound actually depends on the norm of the points that you query.",
                    "label": 0
                },
                {
                    "sent": "If you query very far away.",
                    "label": 0
                },
                {
                    "sent": "So consider the one dimensional.",
                    "label": 0
                },
                {
                    "sent": "Inversion so basically need to distinguish whether we handle the red parabola or the blue parabola.",
                    "label": 0
                },
                {
                    "sent": "If we query very far away, it's easier to distinguish which of the parabolas we're dealing with just because of the nature of the quadratic function.",
                    "label": 0
                },
                {
                    "sent": "So for error we can query everywhere we want, but to get small regret, we cannot query too far away from the optimum, so it's like no win situation here either we query far away and get more information.",
                    "label": 0
                },
                {
                    "sent": "But then our regret is bad or we query close to the optimum and are regretted smaller.",
                    "label": 0
                },
                {
                    "sent": "But then we get less information.",
                    "label": 0
                },
                {
                    "sent": "And either way you can't win and that's why you get back the square root of T dependence.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The last lower bound is for strongly convex and smooth functions, where we show that even if we talk about the error, not about regret, it still no better than square root of the squared over T, so we've seen that with quadratic functions we can get something better.",
                    "label": 1
                },
                {
                    "sent": "So the example would have to be a non quadratic function.",
                    "label": 0
                },
                {
                    "sent": "And again, the basic idea is quite simple, so we look at a function which has this form.",
                    "label": 0
                },
                {
                    "sent": "It may not be immediate, but this is a strongly convex and smooth function, and it has this property that it close to the optimum.",
                    "label": 0
                },
                {
                    "sent": "Again, depending on the values of E if we choose.",
                    "label": 1
                },
                {
                    "sent": "Then close to the optimum, it behaves like parabola which depends on E. But when you look further away it becomes just W squared.",
                    "label": 0
                },
                {
                    "sent": "So you sort of recover the same lower bound that we got for regret because you can try to query a far away.",
                    "label": 0
                },
                {
                    "sent": "But this doesn't give you a more information, unlike the case of a quadratic function, so we get the same kind of lower bound as we got.",
                    "label": 1
                },
                {
                    "sent": "4A regret in the quadratic case.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So just to summarize, so we got an exact representation of what you can get in the bandit or derivative case for strongly convex and smooth functions, which also implies a new lower bound for more general settings.",
                    "label": 1
                },
                {
                    "sent": "An showing that for these kinds of general functions, a quadratic dependence on the dimension is inevitable.",
                    "label": 1
                },
                {
                    "sent": "That is, the price of benefit information.",
                    "label": 0
                },
                {
                    "sent": "Here, on the other hand, for quadratic functions you can get fast.",
                    "label": 1
                },
                {
                    "sent": "Error rate and you have these interesting gaps between what you can get in terms of communication error and what you can get in terms of regret and maybe the main or open question is trying to understand what is the true rate in the more general cases.",
                    "label": 0
                },
                {
                    "sent": "So either strongly convex with possibly nonsmooth problems, or the general convex problems and.",
                    "label": 0
                },
                {
                    "sent": "Again we have upper bounds which are really not matching either in terms of the dimension or in terms of the rate.",
                    "label": 0
                },
                {
                    "sent": "My conjecture is that the right answer is square root of the squared over T first of all, because that's my lower bound, but also because this seems to be the thing you get if you take the best of both upper bounds that we currently have.",
                    "label": 0
                },
                {
                    "sent": "The quadratic depends on the dimension and square root of T dependence.",
                    "label": 0
                },
                {
                    "sent": "But we don't know how to get this with any of our existing algorithms, so we need some new algorithm to be able to get that.",
                    "label": 0
                },
                {
                    "sent": "So that's it.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                }
            ]
        }
    }
}