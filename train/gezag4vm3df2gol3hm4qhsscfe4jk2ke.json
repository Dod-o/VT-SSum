{
    "id": "gezag4vm3df2gol3hm4qhsscfe4jk2ke",
    "title": "PAC-Bayes Analysis of Classification",
    "info": {
        "author": [
            "John Shawe-Taylor, University College London"
        ],
        "published": "Dec. 14, 2007",
        "recorded": "October 2007",
        "category": [
            "Top->Computer Science->Machine Learning->Bayesian Learning",
            "Top->Computer Science->Machine Learning->Kernel Methods->Support Vector Machines"
        ]
    },
    "url": "http://videolectures.net/aop07_shawe_taylor_pba/",
    "segmentation": [
        [
            "So I'll stop.",
            "So welcome to the final session and thank you for coming.",
            "I realize it's been a long day.",
            "And probably this is not the most you say.",
            "You know the thing that will keep you more awake than the previous talks.",
            "I'm what I'm what I mean by that is this is trying to tell you a little bit about a theoretical basis for analysis of learning, so it's sort of a statistical framework that is used.",
            "And my hope is that I can sort of map out the sort of landscape of of some of the theoretical analysis that have been made both in the Bayesian an the frequentist camps.",
            "So give you an idea of how they relate, how they fit together, and in particular look at this PAC Bayes analysis, which is draws from both schools.",
            "So my hope is that you know through that you'll get an understanding of both approaches, but also how they linked to.",
            "Heather Anne.",
            "You know could potentially see how the ideas might be applied in a different application that would be relevant to something that you're investigating, so that would be my hope.",
            "Very happy to take questions at any point.",
            "Even from shy no no, I mean, and so please do."
        ],
        [
            "Got me an."
        ],
        [
            "So let's say I would.",
            "I hope to give us some general perspectives."
        ],
        [
            "New historical note."
        ],
        [
            "Talk about this core result that I think is a very beautiful theorem proving by Matthias Egan and David McAllister, so I'll give you a little bit of detail.",
            "There may be too much for your liking, but if that's the case you know, just check your email.",
            "Well, that's going on, and then I'll talk about applying it to in a little.",
            "Also, in a little bit of detail about how it's applied to support vector machines."
        ],
        [
            "And then."
        ],
        [
            "How that can motivate?",
            "Actually, this idea of learning the prior, which I think is kind of a nice.",
            "Way of using the theory to motivate some algorithms.",
            "And again, it's not that I think it's a particularly.",
            "Necessarily, you know, big step forward, but it's showing how you can use theoretical ideas in inventing new algorithms, which I think is theory shouldn't be there for its own sake.",
            "It should be there to motivate our understanding of what is important and therefore the design of improved algorithms, hopefully."
        ],
        [
            "So here's the overview of the of the presentation.",
            "So a bit of background and sort of motivation and so on.",
            "Then I'll go into this slightly more detailed look at the PAC Bayes theorem and the proof outline.",
            "Talk about some sort of applications that have been made, not probably a complete list by any any means.",
            "And then I'll delve into the application that I want to focus on, which is 2 linear classifiers.",
            "So getting you know, I I right away, will you know confess that this is not going to be a general pattern analysis?",
            "Theoretical.",
            "Approach at this stage we're focusing in on classification is 1 type of pattern that can be found.",
            "But again many of these things can be generalized quite readily and that may be something you're interested in doing yourselves, so I certainly wouldn't want to imply that the approaches can't be extended into other types of pattern."
        ],
        [
            "It might be of interest.",
            "OK, so first of all, general perspective.",
            "So this is really I'm trying to start from.",
            "You know, somebody who's approaching learning as a.",
            "Something to study to try and improve their understanding of the phenomenon with A view to improving the algorithms as I said so.",
            "Stepping right back, what are we trying to do when we develop a theory?",
            "You know, get a paper accepted incoming conference.",
            "OK, that may be a motivation, but the idea is to try and capture the key elements that enable an understanding and analysis of the phenomenon.",
            "So in a sense, what we're trying to do is to abstract away from the detail of a particular application, just those key elements that are critical for understanding how that application, how successful that application will be.",
            "What are the critical components that we can then.",
            "You know, tune to make the.",
            "The algorithms you know, optimize and so on, so it's really it's a an art of trying to understand and through initiative process.",
            "Draw out those key key L."
        ],
        [
            "In machine learning there are several theories and the two that I'm going to be sort of mentioning today are this Bayesian and so called frequentist.",
            "Now they."
        ],
        [
            "Arise from different assumptions.",
            "And hence different range of applicability and and the range of results that can be obtained.",
            "So you know in a sense one could say the more assumptions you put in, the more you can get out in terms of analysis, but possibly the less applicable.",
            "It is because it's a restricted set of problems that it actually can be applied to accurately."
        ],
        [
            "So, for instance, the Bayesians are able to make the Bayesian approaches able to make more detailed probabilistic predictions from the models that they develop, but they are based on perhaps more.",
            "More assumptions which may or may not be."
        ],
        [
            "Just enough why, whereas the frequentist makes only the independent, identically distributed assumption about the training data.",
            "So very weak assumptions in terms of the analysis, though even those may fail in certain in many cases there may be may be problems with that idea assumption."
        ],
        [
            "So I'm going to talk first about the frequentist approach, just as a introductory sort of few key ideas.",
            "Then I'll talk about the Bayesian and then this idea of where the PAC Bayes comes from.",
            "So.",
            "The frequentist approach.",
            "I would claim is was pioneered in Russia by Vapnik and Sherman and Kiss."
        ],
        [
            "Was introduced into the West by Valeant under the name of probably approximately correct into the machine learning community.",
            "At least the type of result that we."
        ],
        [
            "Has is that statement of the type that with probability at least one minus Delta, where Delta is some small, you know, sort of parameter.",
            "So it might be you know 0.01 or something like that, and this is where the word probably comes from.",
            "So probably any classifier from the hypothesis class which has low training error will have low generalization error.",
            "In other words, provided you.",
            "Get a good fit on the training data.",
            "You will actually perform well on new test data.",
            "In other words, it's approximately correct, so at first sight this appears a little bit of magic because you're only seeing a finite set of data.",
            "How come you're inferring from that finite set something to an infinite set of unseen data items that you don't know about?",
            "So the the reason that that works is because the assumption is made that the training data is drawn according to the same distribution as the testing data.",
            "The new data, so that when you actually see enough testing training data you get.",
            "Enough information from that about the statistics of the underlying distribution in order to make the the assertion that you're going to have low generalization error.",
            "Now the Delta is the sort of confidence."
        ],
        [
            "And that is actually picking up the sort of possibly intuitive floor in that argument, which is well, what if you were just very unlucky with your training data?",
            "You know, somehow you just got a really bad set of training data, because after all, it's a random Lee generated set, and that's really what this Delta handles.",
            "It says that OK there is this small probability that I just may have been very unlucky and got a very unrepresentative sample.",
            "And So what I learned from it was actually useless.",
            "So that's that confidence.",
            "And then the glow generalization is just the fact that.",
            "With a finite sample, you are certainly not going to be able to make predictions about everything because there may be pockets of.",
            "You know data that you simply didn't see, which behave very unusually, so I often give this example of, you know, classifying.",
            "'cause into sports cars or not, sports cars and you know you get a sample of sports cars and you know something.",
            "Sorry, a sample of cars and you see which ones are sports cars and you infer from that you get a good idea.",
            "But of course there are very unusual sports cars, perhaps vintage sports cars that don't fit into that pattern and you may therefore get those wrong.",
            "So this would be the approximate approximately correct part and the Delta part would be if you were just very unlucky and happen to.",
            "Look out onto the street as the cars drove past and it was a sort of vintage car rally and all you saw were vintage sports cars and you didn't get the right data as it were for for the training.",
            "OK, so that's the."
        ],
        [
            "This sort of framework, and it's been applied to support vector machines in within this."
        ],
        [
            "Luckiness framework.",
            "So now a little bit of background to the Bayesian approach.",
            "So it the name derives from Bayes theorem which I recently understood maybe shouldn't have been called base theorem.",
            "I'm not sure about this, but anyway, there's certainly some historical contention about that, but.",
            "The way it works is, you assume a prior distribution over functions, so there's a difference immediately.",
            "Remember, in the frequentist we were assuming a distribution over the inputs.",
            "Generating the data here we're assuming a distribution over functions, or in our case classifiers and then what we do is we have a given a data item now, so one of our training data items we can say based on that item, how likely that a particular classifier might be.",
            "So if that classifier misclassified as that data item, then we downgrade its probability.",
            "You can imagine you know if it's saying it's a positive example and.",
            "We know it's a negative example, then we were not going to trust that classifier so much.",
            "So we down weight it's probabilities.",
            "And we do that for all of the classifiers in the in the class with all of the training data, so we know each classifier that so basically according to the number of mistakes it makes you downgrade its probability according to that that amount.",
            "And then at the end of the day, you you end up with what's called a post."
        ],
        [
            ".",
            "Distribution.",
            "Which is the distribution over the classifiers after you've seen the data?",
            "So it's now peaked around classifiers that typically are giving good performance on the training data and is much lower on classifiers that are doing poorly on the training data.",
            "But it's bias.",
            "Still a little bit by the prior distribution, which was the distribution that we started with, which was the distribution.",
            "A priore that was given by the.",
            "By the Bayesian.",
            "Designer of this system.",
            "OK, so that's that's what you're left with is posterior distribution.",
            "Now, if you're a true Bayesian, you will classify according to the expected classification under that posterior distribution.",
            "So you average over the posterior.",
            "So for that particular test point, you average over the posterior.",
            "The classifications that you get weighted according to that posterior distribution.",
            "So the guys that were good on the training data get more weight and are more likely to.",
            "Give you a classification of this new test point.",
            "OK, Notice again, there's still.",
            "There's absolutely no distribution on the inputs.",
            "The inputs are just there, there.",
            "There, in the training set, and they're just there in the test set."
        ],
        [
            "OK, and one of the very interesting so.",
            "As I said, there's many things you can do with the Bayesian framework because you actually have a probability distribution over the function, so you can use that to estimate things, and one of the things you can estimate is the likelihood of the data under that model.",
            "And this allows you.",
            "It's just integrating essentially over all of the functions with the posterior weight, their probability of generating the training data.",
            "And this is known as the evidence for a model, and it was proposed by David Macay back in about 1992, I think.",
            "So in the case if we look at the we only allow consistent so we give zero probability, two points that are two functions that misclassify any of the training data.",
            "Then this can be seen as the volume.",
            "The prior volume in the prior distribution of what's called version space.",
            "And I'll just.",
            "Later on, I'll give you a.",
            "A picture of that which will perhaps make this a little bit more clear of what's going on here, but essentially you can use this posterior sort of evidence for the model as a way of selecting between different models, and this is used, and it's not always reliable, but it's certainly a quite interesting way of doing model selection.",
            "Sorry.",
            "The model.",
            "The model is that the class of functions with the prior probability over them plus the error.",
            "Probability you have to tell you know, so you have to know how much to down way to function when it misclassified as a point.",
            "So that's your error probability.",
            "Which you could set aside to zero.",
            "You could just give zero wait to anything that misclassified something.",
            "But if you allow it to do a few miss class, you know you can give away to that probability.",
            "So the model is defined by a set of functions of prior distribution over them and this error.",
            "Wait?",
            "OK."
        ],
        [
            "And the Gaussian process is for regression are justified within this model and there the prior is a Gaussian prior in this.",
            "Which is defined by the covariance function, which is what would be called by kernel people, the kernel, and that defines a Gaussian prior over the functions effectively and the.",
            "If you follow through all of the updating of that with a, again, a Gaussian error model which you know the error is here in terms of a real valued error, then you get a posterior and you're able to compute it exactly.",
            "It turns out it's also a Gaussian, and you can estimate error bars and do interesting computations with that model.",
            "OK, so I'm that's my story of Bayesian story in one slide, but I'm quite happy again to take more questions if there are any."
        ],
        [
            "Um?",
            "So here's the picture I mentioned.",
            "So here we imagine that this is the the space of weight vectors.",
            "In some learning system nonlinear, should we say so that this is the?",
            "Locus of points in whitespace for which the output of the.",
            "On the 1st training point is equal to 0, so one side of this, let's say this side of this line.",
            "Corresponds to correct classification of the first data point.",
            "And here's the second data point so that this side of this line corresponds to correct classification of the second training point.",
            "So all weights that are in this region sort of to the left of this line and below this line correctly classify X1 and X2 and Similarly X3.",
            "Anything below this line X4 anything to the right of this line, and So what I've drawn here is the largest circle that can be inscribed into the region, which is correctly classifying.",
            "All of the four training points.",
            "So we could think of the evidence if we were using this noise model, which said zero probability of making an error.",
            "The evidence here would be the integral over this region where all of the the.",
            "Points are correctly classified under the prior distribution, which we might assume is uniform, and so this circle would therefore be the sort of largest inscribed sphere or circle in that correctly classified region, and that could be used as some sort of estimate for the evidence for that particular data.",
            "The best option is not at all, no.",
            "I mean in the Bayesian approach you would do the full integral over the thing if you could, but frequently you can't, so you make an estimate of maybe not necessarily a sphere, but maybe some sort of Gaussian with a spherical covariance matrix you know to fit fit into that region to try and get a lower bound on this volume.",
            "So yeah, I mean as soon as you actually try and roll out the Bayesian technology into an application, it does tend to lead to the need to make approximations.",
            "And of this type.",
            "But but let's say the good news is you get out more informed information about the.",
            "The probabilities involved."
        ],
        [
            "OK, so now I'm going to just try and lead into the PAC Bayes approach.",
            "So this is really the idea came from linking evidence and generalization and this link was suggested actually by David Mackay very early on the idea that the evidence might be an indicator of good generalization.",
            "So remember good generalization doesn't really mean anything to a Bayesian because he doesn't have a probability distribution on the.",
            "On the training point, so it's by definition.",
            "It's a sort of cross.",
            "Cross.",
            "How do you say theory concept to link evidence and generalization?",
            "So generalization is about performance on new data from a Bayesian point of view, you don't have that idea of new data being being generated by a probability distribution, but nonetheless this link was suggested by Mackay and."
        ],
        [
            "Bob Williamson and myself obtained first sort of formal link, where we basically analyzed the generalization of a classifier based on the volume of that inscribed sphere.",
            "And this was sort of surprising result in some respects.",
            "Becausw it didn't depend on the VC dimension of the set of functions.",
            "This was sort of cutting across standard sort of results at the time.",
            "In the.",
            "I mean, it's sort of a luckiness."
        ],
        [
            "Idea, so you actually you know the volume of the sphere can be seen as a sort of indication that you've been lucky and actually you can get a bound that is better than you would if you use the sort of ambient VC dimension which would be the normal approach.",
            "Unfortunately, there is a dependence on the dimensionality of the space, and we'll see that as we move through the later applications to support vector machines that is avoided in the newer newer bounds."
        ],
        [
            "So the user luckiness framework and so it's a data dependent style of frequentist bound and it's similar in spirit to the bounds the way that the SVM generalization is bounded OK.",
            "So you could sort of think of, you know, in the case of SVM's you bound in terms of the margin of the of the classifier.",
            "In this case your bounding in terms of the sort of volume of this.",
            "So it's something like a sort of surrogate margin.",
            "This volume of this sphere."
        ],
        [
            "So then this idea was.",
            "Significantly developed by McAllister and later by Matthias Ciga.",
            "They proved what's become to be known as the PAC Bayes theorem.",
            "The first version was a little bit less tight and clean than the version I'm going to show you, which is really due to Matthias Seeger.",
            "His mode."
        ],
        [
            "Ovation was an application to Gaussian processes so he was really thinking about Gaussian process.",
            "You know the prior of the Gaussian process and the posterior that I described to you earlier and he was trying to use those priors and posteriors to bound the performance."
        ],
        [
            "But I'll sort of talk about you don't need to restrict yourself to those particular choices of prime, posterior, or certainly that posterior.",
            "And indeed when John Langford and I looked at SVM then in that case we used a different posterior to the one used in the Gaussian process analysis of Matthias Seeger.",
            "But basically the same bound can be applied.",
            "And there's an egg."
        ],
        [
            "Alan Tutorial by John Langford that appeared in 2005 on Jim Miller.",
            "It's a general thought of all sorts of bounds, but in there there's a very good summary of the PAC Bayes theorem and its application to support vector."
        ],
        [
            "Jeans.",
            "OK, so now I'm going to sort of start to lead up to.",
            "The.",
            "PAC Bayes analysis theorem.",
            "So what I want to do is start to introduce these sort of framework.",
            "And the notation that I'll be using.",
            "So again, you know, do stop me if it's if things aren't clear please.",
            "So basically we've got a class of classifiers.",
            "It's very much like doing Bayesian analysis.",
            "At first sight.",
            "You have a prior distribution over the functions, so you imagine you've got your functions and somehow you think before you start to look at them that some are more likely to occur in this application than others, and you put down that distribution and that could be given implicitly.",
            "As I said, you know, in the Gaussian process example it's given through this covariance function or kernel.",
            "Can you consider the case of a posterior over these functions which will be data dependent on the data?",
            "So this has to be chosen before you see the data."
        ],
        [
            "This P must be chosen before learning, but the bound will hold for all choices of Q.",
            "So that means that you can choose Q to get the best bound based on your data and essentially choosing Q corresponds to choosing your classifier in some sense, so choosing Q is like choosing the classifier.",
            "But Q doesn't need to be the posterior of the classical Bayesian approach, so the classical Bayesian approaches I mentioned would update the prior based on the.",
            "You know the error probabilities of the training data and down weight, those which made errors on the training data in a sort of using some sort of noise model, and that would be the posterior distribution.",
            "There's no need to do that within this theory.",
            "You can do that if you want.",
            "Q can be any distribution, so it doesn't matter what you do.",
            "The theorem will hold."
        ],
        [
            "So the bound works that, provided you choose your P ahead of time.",
            "Whatever Q you choose, the bound will hold OK, so it's so.",
            "In other words, you can choose Q to optimize the bound at posteriori, which is the nice feature of this.",
            "It's interesting here that it kind of undermines a lot of the debates that's held in the Bayesian Cam, because there's a lot of concern about the meaning of the prior distribution.",
            "So how do you choose a prior distribution?",
            "What does it mean?",
            "And there's a philosophical Bayesians and the.",
            "There's another type and I don't know what they call, but there are two sort of schools of thought about what choosing the prior distribution actually means, because in a sense you know how do you arrive at a prior expectation.",
            "So from a practical point of view, I think we can all imagine how you might do that.",
            "You know the sort of domain that you're looking at.",
            "Maybe you've had some experience of working with that type of data, and maybe you know the kind of kernel or covariance function that you should be using, and that kernel would correspond to essentially choosing P. OK.",
            "But from a philosophical point of view, it's very hard to kind of understand what.",
            "You know what this distribution means, and of course, if you are a Bayesian, the.",
            "The results of your analysis are only correct if that prior distribution is correct.",
            "What does it mean to be correct as a prior decision is it's a very difficult question for a Bayesian to answer, however, that all falls away here because the results are going to be true.",
            "Whatever choice of P you make, just if you make a bad choice, then you get a bad resulting bound, so it's not.",
            "The issue goes away.",
            "I mean it's still there because you need to choose a good P, but it isn't an issue of a philosophical nature, it's just an issue of a quality of your.",
            "Classifier and your analysis so that the status of P is now if you like just given, you know as a sort of mathematical object rather than some."
        ],
        [
            "Necessary philosophical accuracy in embedded in it.",
            "So, so I think I've already kind of hinted and you probably guessed that this is actually a frequentist bound.",
            "I mean, although it's called a PAC Bayes analysis, the Bayes is sort of like the inspiration, but the mechanics are packets of frequentist type bound.",
            "So again, we're going to assume an unknown distribution on the input space.",
            "We're going to assume that our examples are being generated according to that distribution and what we're interested in is.",
            "Bounding how well our classifier will perform on data that is generated according to that same distribution that we haven't seen during training."
        ],
        [
            "So again, we use the distribution to generate the labeled training examples ID.",
            "And."
        ],
        [
            "We also use it as our measure of quality of performance, which is the expected value of the misclassification on and you training point.",
            "So this is the link between training and testing.",
            "Again, the training is generated according to the same distribution as is used to to perform the testing and what we're interested in is founding the value of this expectation or this probability here that the test data is misclassified."
        ],
        [
            "And we have an empirical measure of that, which is the average over the training data for that particular classifier of its number of errors that it makes over the size M of the training set.",
            "So there's a in some sense what we're interested in is connecting these two for a given.",
            "Function class so very classical question."
        ],
        [
            "OK, so.",
            "So the.",
            "Then you take that comes in and this is where sort of we dip our to little bit from a classical.",
            "Analysis of generalization.",
            "So where things start to get interesting is that the bound of the performance is not of a classifier, but of a probabilistic classifier.",
            "So we actually when we take a test point X, we choose a classifier according to our posterior distribution and then return the classification of that classifier on that input.",
            "And that's the that's the thing we're going to bound now that isn't actually what you do in a support vector machine.",
            "For instance, for a support vector machine, you have a particular function.",
            "You don't have a probability distribution over functions that you might use.",
            "You have a particular function that your algorithm has output, so we're going to have to connect this analysis, which is about a probabilistic classification with the analysis with the actual practical application of support vector machines will come back to that.",
            "So don't worry about that at the moment, but this is.",
            "What's being analyzed within the PAC Bayes framework?",
            "Yeah.",
            "Gracie is a country itself of the best.",
            "OK, yeah, I mean, remember the Q has been chosen based on the date the training data.",
            "So the Q will have been.",
            "I mean typically what you might happen.",
            "You know you've got this quite uniform prior P. You see your training data and there's sort of basically a small region of functions that do well on that train.",
            "It might be just one function that does well on that training data and you put your posterior Q with a big strong weight on that that region.",
            "OK, so So what should I mean?",
            "The tradeoff you're trying to make?",
            "I mean, this is a very sort of naive diagram, but if you imagine this is your function class, this is your prior distribution with some sort of very uniform set of things, and now you know there's basically a region here where the functions perform well on the training data, so your posterior becomes sort of.",
            "Very peaked around at that point, and indeed that might be a single function.",
            "And so then what you're interested in is sampling.",
            "According to this posterior distribution and using that to do the actual classification of a test point.",
            "Yeah, yes.",
            "Present from the true vision by averaging around it is different.",
            "Yeah, so if you're unfortunately, that's yeah, that is different.",
            "That's a slight.",
            "Handicap of the analysis here because the Bayesian would average according to that, whereas we're taking an expectation according well.",
            "I mean what it means, we're taking the expected classification rather than the.",
            "It seems that if you repeat because initially many times then aren't, you already have it?",
            "Yeah, if you did it many times, that's true.",
            "That's would be the same then.",
            "Yeah, yeah.",
            "This thing is saying as a generalization error of Asian restaurant or no, not not so.",
            "So I'll mention it.",
            "There's a factor of two that might come in between the two.",
            "I'll mention it, yeah.",
            "Factors of crime, or anything else.",
            "It was that he was notified.",
            "Yeah, in this case, so it may be.",
            "I mean it's very difficult to draw a good diagram, but you know if you didn't see much training data and the posterior, maybe the good.",
            "Maybe it goes down here quite low and the good stuff is here.",
            "So then the posterior and you didn't have that much training data.",
            "So then the posterior might sort of look like that.",
            "You know where.",
            "There's still quite a bit of weight being preserved on these rather useless, but yeah, I mean the bayesians would always argue that the priors not important, really, but.",
            "Problem is that if you're being if you're doing that analysis, it is 'cause it's the only thing you've got in some sense.",
            "Any other questions?",
            "OK good OK so.",
            "Yeah, so there's something else I was going to say this movie.",
            "Yeah, OK so."
        ],
        [
            "So that's the picture to have in mind, so we're interested in these two quantities.",
            "So one is this expectation of the.",
            "The error as we choose C according to this posterior distribution of the true error, and then the expectation of as we choose C according to Q of the empirical error, right?",
            "So it's.",
            "It's sort of if we just look at CD relating CD and see hat of S. It would be just a classical sort of pack type, but the fact that we've introduced these expectations gives it the Bayesian.",
            "Later, because we're talking about a posterior distribution.",
            "OK."
        ],
        [
            "So this is the the point that about the relation to the.",
            "You know expectation, so this would be what you would do if you were doing a posterior distribution.",
            "You would average the classification according to.",
            "The.",
            "According to this C of Q.",
            "And then take the sign of that, as it were, so you would use the sort of average of the posterior distribution of the classic classifiers as your classifier, and that will be the interesting thing you want to to bound.",
            "But in fact you can bound that by twice the the QD thing that I put up on the previous slide.",
            "So although it's not the right thing, it's at most a factor two though, that two is probably quite conservative here.",
            "In general, but maybe in some cases it's not.",
            "OK, so the argument why that is the case?",
            "Any point X mix misclassified by this guy here, there must be at least half of the season probability weight under Q that misclassify.",
            "So our average classification is going to be wrong, about half of the time."
        ],
        [
            "OK, so this is the theorem.",
            "OK, so we've got all the notation down.",
            "This is what it says.",
            "OK, so.",
            "You've got an arbitrary distribution on the inputs.",
            "You got an arbitrary distribution on the functions.",
            "You've gotta confidence Delta, then with probability 1 minus Delta over the sample.",
            "So you specify the conference that is that are drawn according to this distribution, IID.",
            "As we said, all posteriors satisfy the following inequality.",
            "OK, so this is a little hard to read, but basically what what's happening here is there on this side?",
            "We've got the misfit between the empirical and true error of this randomized classifier, so Q hat is the empirical.",
            "This is the true, and by this KL I mean you just treat these as distributions on 0 + 1, where 0 means.",
            "Say correctly classified and plus one means incorrectly classified.",
            "So it's just the.",
            "You know the KL divergent of.",
            "I mean if if P is the error of the true classifying P hat, is the error of the.",
            "Empirical then that KL is actually equal to P hat log P hat over P + 1 -- P hat log 1 -- P hat or 1 -- P. OK.",
            "So, but it's it's a measure of closeness.",
            "So if these two were the same, then this would be 0.",
            "But it's it's more flexible measure of closeness than, say, taking a difference.",
            "The interesting thing about it is that when these two things are close, then there there.",
            "The same amount of KL divergences here corresponds to much less separation between the two, so it's sort of like a flexible measure.",
            "In some sense, it gives you a tighter bound when you're close to 0, which is something you would like, and maybe a looser bound when you're away from zero, which is something you can't avoid, so it's quite a nice sort of measure to have here.",
            "You can get rid of it, but you always end up with something weaker.",
            "So that's that's really just think of it as just a measure of difference between these two, but a slightly more sophisticated one than just taking the difference, OK?",
            "Now on this side you've got a very simple expression which just involves the KL divergent between the two distributions.",
            "So the tradeoff.",
            "That's really if you know if you think of this diagram here what we're trying to do is say OK, I'm going to find.",
            "Here's my prior distribution.",
            "Here's my posterior, I don't.",
            "I want to somehow keep the KL divergent between these two not too big, but but reduce my empirical error by.",
            "By a lot, so we want to sort of move to reduce the empirical error, but in a way that doesn't increase this.",
            "KL divergent too much, so we sort of keep an overlap with the prior distribution, but hopefully get get a low empirical error.",
            "So it's a very intuitive kind of idea that's being described here, I think.",
            "Second time.",
            "US QSQ teach.",
            "Yep, no problem."
        ],
        [
            "So QSQ had S is just the expected.",
            "Error under so Seattle versus just the empirical error of the classifier C right.",
            "And but then Q had a VAS is just the expected value of that error when you draw C According to that posterior distribution.",
            "So you know you draw a C and you see what error it has.",
            "It's just a number.",
            "Yeah, yeah.",
            "No.",
            "And the sorry it is no.",
            "It's a relative relative frequency, right?",
            "See how diverse is the relative error?",
            "And this is just the true error of C. Again expectation when sampled according to this posterior.",
            "So in other words, to choose Q in such a way that this is small, which is what you want to do, you have to put the weight onto onto the functions that typically have small error.",
            "So I'll give an example of, say, a finite class where you put all the weight on a single function.",
            "I mean and it reduces back to a kind of standard.",
            "Result in that case where this is this expectation is just a selection of a single function, so there isn't any randomness at all at that point.",
            "Maybe maybe I'll do that right away, and then I'll come back and say this again.",
            "'cause maybe that's so if we go to this, skip all this.",
            "Um?"
        ],
        [
            "Where is so this is the case of a finite class of functions, so you've got H1 up to HN.",
            "And let's say you put a prior distribution of P1 up to PN, so it's just a finite set of probabilities that sum to one.",
            "Then the posterior.",
            "You can assume now is on a single function, so if you happen to have two functions that correctly classified, you could do is sort of a division on that.",
            "But let's say you just choose a single function and put all your weight on that function.",
            "So then the KL divergent's reduces to just minus log of Pi.",
            "Because the.",
            "You know the Q is essentially one on a single function Pi, so Qi log Pi over Qi or sorry Q / P I is just minus log P because Qi is just one.",
            "And all of the others are zero, so they disappear.",
            "So it's just minus log P. And this is just a very standard result that you can get in the normal pack framework where you have log 1 / P. I essentially a weight on a single function.",
            "OK, so so this unit could think of that as a kind of fullback position, but if we go to the."
        ],
        [
            "The.",
            "Situation here we are allowing this queue to select not just one function but a whole.",
            "You know distribution of functions here, but we're taking the expectation of the empirical errors at that point.",
            "OK. And this is the expectation of the true errors.",
            "So you're going to ask that there was.",
            "The actual theater, yeah?",
            "Spur support."
        ],
        [
            "Of the two.",
            "Fire and service support.",
            "Just to provide one.",
            "Then we kill averages is different in this town?",
            "Is arthritis making memories?",
            "Yeah, if you.",
            "Well, the would be infinite if Q had weight on something that he didn't have, wait on.",
            "It's only in that direction.",
            "That's always the problem, but it's only in that case, so you're not allowed.",
            "Yeah, I mean, you're not allowed if you don't have weight on anything.",
            "I mean if there's some function that you don't have in your prior, then you can't use it absolutely.",
            "Don't wait on just one function to prioritize and same thing, no?",
            "No, no, that example I gave with the finite was.",
            "Surface Pro batteries.",
            "Some way to make it so assume that now I'm not going out with her if I.",
            "Well.",
            "Well, I yeah you could try that, but I think that the yeah.",
            "I mean that's an interesting question.",
            "I think that the bound.",
            "OK, this sort of the mathematicians argument that it's sort of the right bound, you know, kind of.",
            "It makes it makes you know, sort of pops out.",
            "So it sort of feels right, but so that my intuition is that if you try to put something else in, there would just be a weaker found that you derive from a sensually from this one.",
            "But the way you can get round, I mean, if you think of a support vector application with a Gaussian kernel, for instance, you can use a Gaussian distribution which has weight on every function essentially, but very, very small weight.",
            "So then yeah.",
            "Schuylkill that works.",
            "That is gonna be there.",
            "It's going to be very big, but at least not infinite.",
            "Yeah, but yeah.",
            "OK, any other comments?",
            "Not good.",
            "OK so so the intuition just finally once more is to sort of find a posterior which sort of doesn't diverge too much from the prior, but is getting this expected value of the classifier classification low?",
            "That's the aim, and this is the definition of KL divergent, which you probably know, so it's the expectation of a Q.",
            "Notice the first component is the one that gets the expectation.",
            "Of dog."
        ],
        [
            "OK, so now I'm."
        ],
        [
            "Gonna attempt to give you a kind of flavor of the proof, so this is where you know.",
            "Start reading email, not a problem.",
            "And but I mean, I, I, I think it's it's got an intuitive feel to it, which may be of interest so."
        ],
        [
            "I'll give it a try anyway.",
            "So there are three ingredients that you need to prove in order to get this thing to work.",
            "And the first is the following, which is looking at the expectation of.",
            "As you select a function according to the prior of the probability that the new sample gives the same classification error as the previous, as as the probability over a sample that this other sample gives the same classification error, and this is sort of less than or equal to N + 1 over Delta.",
            "So this is kind of a.",
            "One of the ingredients that's needed.",
            "So basically there's going to be a lot of looking at this.",
            "This probability the probability that are under two independent samples.",
            "The two empirical errors are the same, so this is sort of like the double sample trick in some sense.",
            "OK, if you're from."
        ],
        [
            "So with that from so the way this proof works, so this is a proof of this ingredient, or an outline.",
            "Anyway, is you just look at the expectation under the sample drawn according to sample according to D of one over the probability that under a separate sample they get the same error rate.",
            "And you just divide this expectation into the possibilities for error rates that you can have for the first sample.",
            "The sample S. So in other words, there's only M + 1 error rates that you can achieve on M data points 0 up to M, so let's just sum up the probability that we get error rate K and then of course the fact that they're going to be equal is just one over the probability that this is equal to K. Well.",
            "This is pretty obviously equal to N + 1 OK, so I mean this is just the same thing divided by the same thing, so this is clearly N + 1.",
            "Now you take expectations with respect to see.",
            "System, so this is an expectation here with respect to S, But you could take an expectation outside this with respect to C is a constant, so of course we get the same value.",
            "Swap them around and you get this expression here and now you use Markov's inequality, which says that with probability at least one minus Delta this quantity, which is this expectation here is less than or equal to M + 1 over Delta.",
            "OK, so.",
            "So that's basically Marco's.",
            "Inequality's is one of the weaker forms, but it's just bounding the tail ascentia Lee of the distribution, so that's the first ingredient, and really, nothing.",
            "Very magical, but say it relates to this one over the air."
        ],
        [
            "Error rates being the same, so this is perhaps the most.",
            "Important ingredient.",
            "Again, it's quite interesting, I think, but it's gain relating to one over this probability that two samples give the same error rate.",
            "Here we fixed the sample S. Now the way this works is too.",
            "I haven't given a more detailed explanation, but."
        ],
        [
            "Essentially what you do is you just write out this probability.",
            "As you know, some Caples Aventus K probability of being correct essentially.",
            "And you know, make it equal to exactly C hat S primed this probability here, so you actually exactly equal to see how to ask.",
            "And then you sort of make the sum.",
            "You've got a single sort of entry there, but you then make the sum up to that value and it becomes the tail bound on the binomial distribution, and then you use turn offs bound in this scale relative entropy version.",
            "And you basically it's less than or equal to E to the minus M log.",
            "Sorry exponential of M times the KL divergent.",
            "So the log destroys the exponential an, so you've got this EC of Q of this KL divergent of the C hat S and the CD here and then the expectation can be moved through the KL divergent because it's a concave function and so the expectation goes inside and you get the Q hat of S and the QED.",
            "So it's actually a. I think it's the sort of the core of the proof, in a sense, is this one here."
        ],
        [
            "OK, so then these putting it all together, what you do is you create this this artificial distribution PG by essentially waiting the prior distribution with one over this probability of the things being giving the same error rates.",
            "This is just a normalization factor to make sure this is still a distribution.",
            "So the key here is just this quantity here, which is sort of like a reweighting of the prior distribution."
        ],
        [
            "And then you observe that the KL divergences between Q and this PG.",
            "This adapted P is always positive and you can actually unravel this KL divergent.",
            "So you get the KL divergent with respect to P plus these two extra terms which come."
        ],
        [
            "From the this and this."
        ],
        [
            "So this is the first one, and this is the 2nd.",
            "And then finally.",
            "You put it all together so the way you do that is you go back to this.",
            "That one here, I think.",
            "Let me just see."
        ],
        [
            "Sorry yeah that one there, which is which is just this less than or equal to this.",
            "And then you use the."
        ],
        [
            "This expression here because you now know what this is in terms of or it's greater than or equal to less than or equal to this plus this."
        ],
        [
            "Which is this plus this?",
            "And then you the first thing we did was prove this was less than or equal to N + 1 over Delta.",
            "And this holds of course with probability 1 minus Delta, because when we made that substitution, this was only a substitution that's only valid with probability 1 minus Delta over our choice of S. OK, so that's basically it.",
            "I've skipped over details.",
            "You can close the email now."
        ],
        [
            "OK so so but what I wanted to sort of give you there is a flavor of the kind of things that are involved and to really make clear that this is not some hyper mathematics of some complex kind, you know it's something you could follow through the details or be it painfully.",
            "And I mean I say the most painful bit in there if you really wanted to do every bit will be the turn off and that's that's a bit complicated, but.",
            "OK, so now I'm going to talk about applications and this one I've already mentioned.",
            "It's the very sort of simple idea of just having a prior on the functions and you end up with something that's very similar in flavor to the."
        ],
        [
            "Standard bound, the only difference is that there's this extra N + 1 here, which is gives a slight weakening of the bound, but you've got the KL divergent on this side, which is, which is, as I explained, a sort of tighter or a more refined way of comparing 22 error rates here."
        ],
        [
            "OK, so other extensions and applications I'd just like to mention, Matthias Ege has, as I mentioned, right at the beginning.",
            "You know, applied this to bounding the error for Gaussian process classifiers."
        ],
        [
            "Olivier Catone has extended the result to exchangeable distributions and therefore being able to get a pack based version of the Vapnik churning kiss bands and other things as well.",
            "But that is quite interesting because he's sort of I mean, for those sort of familiar with that kind of thing where there's a double sample trick, you get to a sort of what you would normally do is sort of symmetry symmetrization staff, and that's replaced by this sort of PAC Bayes approach, so you end up with something that that is sort of a.",
            "Slightly tighter in the way it deals with the.",
            "With the error rates again."
        ],
        [
            "Germaine and I'll have extended to more general loss functions than just binary.",
            "The loss that I've been considering, so this with the.",
            "Marian Marsh or Anne Francoise Laviolette and another."
        ],
        [
            "Collaborator and David Mcallister's extended the approach to structured output learning, which is a recent kind of development that's been attracting a lot of interest."
        ],
        [
            "OK, but what I want to focus on is this linear classic function.",
            "The application originally due to Langford."
        ],
        [
            "And myself and I want to describe how this application."
        ],
        [
            "Is made and then how we can extend it to learning the prior and."
        ],
        [
            "End up with some results, so this is sort of more like.",
            "These sort of stages are more like sort of.",
            "Detail sort of example to just give you a flavor of what can be achieved.",
            "I mean, one of the things that I think surprising about this theory is the tightness of the bands that you actually get out.",
            "I mean, when I started doing bounds, you know everyone was happy.",
            "If you had a band that would.",
            "You know, be less than one.",
            "Only if you had, you know.",
            "10 million data points and you know that the extreme sort of weakness of the bounds that we were able to prove was was was.",
            "Was accepted as part of life, but here we're actually getting bounds that are non trivial an with with small datasets like these UCI datasets, so it's quite interesting to see what's happening."
        ],
        [
            "OK, So what do we need to apply to roll out the technology?",
            "We need to choose the prior and the posterior distributions and they're both going to be Gaussians with unit variance the prime."
        ],
        [
            "Will be centered at the origin."
        ],
        [
            "And the the posterior will be centered essentially in the direction of the chosen weight vector.",
            "So if you're thinking of a support vector machine, this is the weight vector of the support vector machine, but scaled by a factor mu.",
            "Remember that we can choose any posterior we want, so we can scale to optimize the bound.",
            "We don't have to worry about, you know somehow overfitting if we."
        ],
        [
            "Do that.",
            "So here's the prior.",
            "Centered at the origin."
        ],
        [
            "We find a weight vector by whatever method we might use, so this might be our support vector or some other method, Fisher discriminate or whatever does decide a weight vector.",
            "Going to choose the posterior."
        ],
        [
            "Direction we're going to choose a length in that."
        ],
        [
            "Direction and then the posterior will be again a Gaussian focused at that at that point.",
            "So that's the way that the the."
        ],
        [
            "Prior and posterior look.",
            "So now we plug in to the bound.",
            "These new particular instantiation's.",
            "So here."
        ],
        [
            "Is the.",
            "The true error according to W an mu.",
            "So that's the true performance of the stochastic classifier.",
            "And."
        ],
        [
            "But it's a deterministic classifier that corresponds to doing this thing that I described before, where you take the sign of the expectation, so it's more like the posterior according to the you know the average of the posterior distribution.",
            "But you take that, so it comes as the center of the Gaussian, and it gives the same classification as the half space with more weight.",
            "OK, so this is this is a separate thing, so there's two things going on here.",
            "The second thing I mentioned is related to what I said before.",
            "This is different.",
            "This is saying that we can actually replace this expected classifier by the fixed classifier at the center.",
            "Big cause if you think about the points that are going to correctly classify the points, they're going to be on one side of 1/2 space of a hyperplane.",
            "And this is going to give the same classification as the center of the Gaussian, because the center of the Gaussian is it spherical, will be on the same side of the hyperspace hyperplane as that which has more weight, right?",
            "Because it's vertical, take a hyperplane, the center of the Gaussian is on the side with more weight.",
            "So the center of the Gaussian.",
            "In other words, your support vector machine will give the same classification as this one.",
            "Remember, this isn't the thing we're bounding by the.",
            "PAC bayes"
        ],
        [
            "From but we do know that it's at most twice the bound that we get from the PAC Bayes theorem.",
            "So whenever I put a result of a PAC Bayes bound, you have to really multiply by two to get the bound on a fixed support vector machine.",
            "OK, and that's just that same argument as before that the you know, for any misclassified there must be at least half of the sea according to this Q that.",
            "Under this expectation.",
            "OK.",
            "So I was happy with that."
        ],
        [
            "Yep.",
            "OK, so that's the first component.",
            "The second component is this Q hat of SW mu that's this stochastic error on the training set."
        ],
        [
            "Right, and that can be estimated in the following way.",
            "So it's it's a little bit of a detailed analysis, but not too difficult, but basically it relates to the margin.",
            "This is the normalized margin of the.",
            "Of the example for that particular weight vector, so normalized with respect to so you know effectively normalizing the data point if it's, if it's a Gaussian kernel.",
            "Of course, you don't need to do that.",
            "Normalization is already normalized.",
            "You normalize just so it's just the margin and then in order to compute this stochastic error, you have to do the expectation under the training data of the.",
            "Um?",
            "Cumulative distribution of the Gaussian of this margin error.",
            "So what this says, sorry 1 minus that.",
            "So what?",
            "It's very much a margin based average, but what it's saying is if there's a large margin.",
            "On my example, mu of course is the scaling of my weight vector.",
            "If there's a large margin on my.",
            "My this is positive.",
            "This is going to be very small, so I'm going to make a very small contribution to this error.",
            "If, on the other hand, the margin is small or it's even misclassified, then I'm going to make at least a contribution of 1/2 to this error here.",
            "OK, so that's that's the way that works out."
        ],
        [
            "Um?",
            "So now what is the KL divergent?",
            "So now we have a prior and posterior that are both Gaussian.",
            "So it's a very standard to know the KL divergent between two Gaussian distributions.",
            "In this case, it's particularly easy because they actually have the same covariance structure.",
            "You can compute the general KL divergent between Gaussians with different covariance structures, But this is a very easy case."
        ],
        [
            "And."
        ],
        [
            "The."
        ],
        [
            "Result is simply the.",
            "Square of the distance between the two centers divided by two.",
            "So in our case mu squared over two.",
            "I'm assuming the weight vector was normalized so that the new measures the distance from the origin.",
            "So it's just mu squared over 2.",
            "So clearly you can see immediately how the trade off is happening with Mew Mew here.",
            "As it gets larger, will make this bigger but."
        ],
        [
            "In the previous slide, we saw mu acting to make this smaller because it expands those.",
            "Those margins there and therefore reduces the value of this so."
        ],
        [
            "Going to trade off Point which were allowed to."
        ],
        [
            "Flexibly fix.",
            "So the Delta comes in."
        ],
        [
            "Familiar with that?",
            "That's just the confidence."
        ],
        [
            "So with probability 1 minus Delta over the."
        ],
        [
            "Training data this holds.",
            "OK, so that's I give you some some results for that in a minute, but I just wanted to also immediately introduce a second idea, which is to consider learning the prior.",
            "OK, so."
        ],
        [
            "In our case, the prior was the Gaussian at the origin, but maybe we could do a better prior, because notice that the key thing is the distance between the prime posterior.",
            "If we could somehow.",
            "You know, foreshadow the direction that the weight vector was going to move.",
            "We might get a much tighter bound, and the."
        ],
        [
            "Here is that we could learn the prior using the first, maybe part of the data and then learn the you know actually do the the generalization analysis just with the second part of the data.",
            "So it's not the case that.",
            "I mean this isn't necessarily going to turn into an algorithm, and actually it will later, but at this point it could just be about getting a better bound.",
            "We might still end up with the same support vector machine that we use at the end, but we might just have a tighter bound on its performance.",
            "So the idea is to use part of the data to train.",
            "A sort of sub support vector machine which gives you a prior and then you use your whole support vector machine is your weight vector and now you can test your workout your bound in terms of the difference between the prior."
        ],
        [
            "Posterior.",
            "And so you put that into the bound and you."
        ],
        [
            "Compute the stochastic."
        ],
        [
            "Carajas with remaining data.",
            "So here's the sort of picture again.",
            "So we have some subset R of our data points.",
            "We used to get a prior."
        ],
        [
            "We that is now chosen to have prior distribution which is Gaussian at some distance from the origin in that."
        ],
        [
            "Section we then train the full data and get the posterior W. And then we select the.",
            "Actually this should be a different parameter here, but maybe this is some other scaling factor here and here we have the posterior so."
        ],
        [
            "The idea is that now the distance here is much smaller than it would have been if we had the prior at the origin, so we've gained a lot in that respect.",
            "But of course we've lost a bit because we're now only able to estimate the error here with part of the remaining data.",
            "So this term has been reduced, but the denominator is also been reduced because."
        ],
        [
            "We have a smaller number of training points, so here's how the bound looks in this case.",
            "Again, the."
        ],
        [
            "QD is the trooper."
        ],
        [
            "Formance of the classifier."
        ],
        [
            "This is the expectation with respect to the unused data in the in determining the prior.",
            "So this is an expectation of M -- R, but that is not a big problem.",
            "That's just going to be some subsample.",
            "Maybe a slightly increased variance that."
        ],
        [
            "Might get there.",
            "Here we've got this factor that's potentially giving us a win that the difference distance here is going to be small."
        ],
        [
            "Ola.",
            "That's the distance between the prime posterior."
        ],
        [
            "And but this is where we're going to take a hit, because we're only dividing by the number of points not involved in training the prior.",
            "So notice that this W here the WR is the prior, which is the support vector machine trained on subset of the data.",
            "This is the posterior trained on all of the training data.",
            "There's one other hit we've taken which is here in this J because we essentially it considering different weightings here for the for the priors and each prior has to be treated as a separate application of the theorem.",
            "So the J here correspond to the number of times we chose a different eater.",
            "But that's that's a relatively benign."
        ],
        [
            "Hit."
        ],
        [
            "OK.",
            "So we're going to.",
            "I'll show you in a minute, some comparisons with 10 fold cross Validation PAC, Bayes bound and.",
            "Pack prior PAC Bayes bound when I'm comparing with cross fold validation and meaning to do model selection, so we'll use the bounds to do model selection and compare with the performance and will also see how tight the biomes are."
        ],
        [
            "On UCI data."
        ],
        [
            "Set.",
            "And we can use the.",
            "Bounds or the the?",
            "Cross validation to select both C and Sigma so the Gaussian kernel width, which is Sigma an the C which is the trade off parameter."
        ],
        [
            "OK, so.",
            "In 10 fold cross validation we just select the pair that minimizes the validation."
        ],
        [
            "And in the case of the bounds, we select the pair that minimizes the bound.",
            "So notice that this is a lot less expensive than doing cross validation, so you know we're only having to run the support vector machine once or in this case twice, but on a subset of the data, whereas here you're having to run it 10 times as you go round.",
            "The circuit."
        ],
        [
            "OK, so this is the results that you get of the actual test error and you can see that 10 fold cross validation is outperforming these methods.",
            "But the prior backpack Bayes is doing better than the pack SVM.",
            "And but the differences are not very, very significant.",
            "So where you know?",
            "I mean, when you consider these are significantly lower cost to perform.",
            "I think we could claim that we got a realistic alternative for doing model selection.",
            "Which you know, for having a theoretical bound that that gives you a model selection is quite an, I think, unusual."
        ],
        [
            "And the tightness of the band.",
            "So here's the PAC Bayes bound.",
            "Here's the prior PAC.",
            "Bayes bound, the prior PAC.",
            "Bayes bound is a lot tighter.",
            "And there, you know, really quite reasonable bounds on performance, I mean.",
            "You know they're actually, you know, quite quite small.",
            "Even when I mean when you compare."
        ],
        [
            "To the true error.",
            "So the true error, let's say enring norm is .024."
        ],
        [
            "I.",
            "And here it's .093, so it's maybe a factor of 3 1/2.",
            "You know it's it's not too bad."
        ],
        [
            "Certainly nontrivial, so now I think I've got time to just introduce the two additional ideas that have been developed from this approach, which is OK if you've got a new bound, why don't you try and optimize it so you could this lead to a sort of prior SVM which basically rather than choose W to be the normal SVM on the whole training data, you just train the SVM to optimize this bound relative to the prior.",
            "That you trained on part of that."
        ],
        [
            "Training data.",
            "So the."
        ],
        [
            "The optimization that you get is basically this.",
            "You trying to minimize this difference which correspond to the KL divergent's subject to getting good classification on the remaining data points.",
            "So these N minus are points not involved in the training of this prior distribution."
        ],
        [
            "And this PS VM is only solved with."
        ],
        [
            "Winning points.",
            "I.",
            "And you can translate this into abound, of course, so you can determine the."
        ],
        [
            "Prior with that subset, you solve the P SVM and attain."
        ],
        [
            "W you then get the margins on the M -- R points."
        ],
        [
            "And you do a linear search for the optimal value of mu, plug it in an."
        ],
        [
            "Bound.",
            "So the there's one further extension, so that's that's again taking a finite set of possible choices for the I should have mentioned that."
        ],
        [
            "In this case here WR, you really need to consider rescaling, so you have to consider a finite set of scalings, and you pay a price for that.",
            "So."
        ],
        [
            "So the slide adaptation is to consider the prior distribution, P being elongated in the direction of WR.",
            "So you actually sort of don't pay for using that direction as much."
        ],
        [
            "And that correspond."
        ],
        [
            "And then to using an optimization where you optimize this property, this vector V."
        ],
        [
            "Where your classification is actually being made by V plus some multiple of the prior weight vector, and you can adapt that Eater freely to get the best performance that you like.",
            "So this is now a sort of optimization that ignores essentially the prior direction in costing terms."
        ],
        [
            "And."
        ],
        [
            "You can again."
        ],
        [
            "In use, the PAC Bayes theorem with a novelty that the prior has this elongation in the direction of WR.",
            "So it's a sort of spherical in every other direction.",
            "It's like a rugby ball.",
            "Sorry, should have mentioned we should write.",
            "OK, so it's it has that elongation and if you compute the posterior now between the spherical the posterior spherical at a distance mu but the KL divergent between these two comes out to an expression like this, where this is the perpendicular direction.",
            "So that's just what you would expect if you.",
            "Project the new weight vector into the space perpendicular to the prior but in the direction of the prior.",
            "You have a slightly more complicated expression involving the variance of this rugby ball, and so if you let the variance grow you essentially reduce the cost of this parallel direction at the expense of a slight increase in this log of Tau squared here, but offset by a possible slight reduction here.",
            "So there's actually a very benign cost in.",
            "Making tower reasonably large and effectively, you know, making this this cost of the direction of the prior much much less.",
            "So if we."
        ],
        [
            "We now use that, then model selection again.",
            "It doesn't actually improve the model selection very much.",
            "I mean, in fact, it's slightly worse than the prior SVM in this case.",
            "Sorry, the prior SVM does very well.",
            "Sorry, but the Eater prior doesn't do so well.",
            "The true remember, cross validation was .070.",
            "So this is, you know, virtually indistinguishable from cross validation using this prior SVM.",
            "The Eater prior doesn't do quite so well, but I mean it's it's as good as but the."
        ],
        [
            "Bounds on the error for the Eater prior are very tight and we get even a significant reduction in those bounds, so we.",
            "Well, I'm sort of moving to is a sort of technology that can say look.",
            "I can roll out a reasonably accurate model selection strategy and give you a bound on the performance that is within a factor of about three to four of the true performance, and these are reasonably reliable indicator of the sort of scale of the true performance using these bounds.",
            "Sorry, yeah, Tom.",
            "Yes, that is true.",
            "That is absolutely true, but."
        ],
        [
            "My argument is that it's actually quite a benign parameter in the sense that you know setting it quite large will only pay you.",
            "You only pay a small price here it's log of T style squared, but you're saving yourself a factor of Tau squared in this in this direction.",
            "Yeah.",
            "I don't know how many points you allocated, Royal selection and how many people is there.",
            "Yeah, it's a good question experimentally we've arrived at about 50% is about the right number.",
            "I mean, it's not that again sensitive in the experiments we've done, but it's another parameter that you could chew.",
            "But yeah, you need.",
            "The problem is, the more things you very them.",
            "You can use the bounds, but it's more expensive.",
            "You have to run the algorithms often and you pay a bit of a price in multiple hypothesis testing effectively.",
            "Which situations would you allocate?",
            "No, I say now in our experiments we were finding you know, between 30 and 50%.",
            "Ticking.",
            "It could be based on the band, but the problem with.",
            "Absolutely, you could do that.",
            "The problem with that is that you're paying you having to run the support vector machine lots of times for these different values of R. So you're sort of undermining your argument that the saving is in terms of, you know, and you're losing a bit on the bound as well, because you've got to do an extra cost in here.",
            "OK, so.",
            "Yeah, I think that's that's I think I said everything there any any questions?"
        ],
        [
            "So final concluding remarks, just hopefully I've given you a feeling for their different approaches.",
            "The frequentist and Bayesian.",
            "They're both aiming at sort of analyzing the performance of learning systems and through some crosstalk between them.",
            "This PAC Bayes idea arose, and Interestingly it seems to have look, you know, developed into quite an interesting approach to understand."
        ],
        [
            "Learning systems that somehow combines the intuitions of Bayes with the.",
            "So analysis of pack.",
            "So I've tried to give you a reasonably detailed look inside the ingredients of the theory, hopefully not.",
            "2."
        ],
        [
            "Too boring and I've showed you how to the app."
        ],
        [
            "Patient was VMS works.",
            "I've investigated learning the prior as a sort of again.",
            "I mean that's a detail in a way, but I kind of like it because I think it shows you.",
            "How one can sort of use these theoretical insights to hopefully derive new algorithms?",
            "And maybe you can do something completely different with these theory to motivate different approaches to?"
        ],
        [
            "Ning.",
            "Certainly we seem to get tighter bounds, not always."
        ],
        [
            "Much better.",
            "Model selection, but but somewhat better.",
            "The prior SVM seems to be giving a reasonably reliable, low-cost model selection."
        ],
        [
            "And particularly these ones that directly optimize the newbound seem to give very tight bounds at least and reasonably good model selection as well, so.",
            "Yes.",
            "Which is basically exactly.",
            "I don't think the question of choosing account and we want to allocate some training data to promote a selection of choosing it requires calendar.",
            "So can you say anything about all those?",
            "Hi, I'm sorry.",
            "Well I mean in a way the the model selection there was choosing the Colonel in the sense of choosing the kernel width so.",
            "So only the kernel with yeah, OK, so of course if you're choosing, but it was choosing the kernel with over a finite set of it wasn't choosing the kernel with over, you know as a real value, or choosing a different family of kernels, which is what you're asking, yeah?",
            "Yeah, I mean, I think the you know the key ingredient of what the PAC Bayes approach does is it it gets away from treating things as independent.",
            "It sort of takes into account the dependencies between the classifiers and that's why it does so so well.",
            "I mean even that rugby ball example did better than just taking a finite set of, you know the bound was a lot tighter because it was taking into account the sort of links.",
            "So I think to really get a good roll out to the.",
            "Learning the kernel, you certainly don't want to do model selection in the way that I've done it, which is just pick a finite set you want to somehow get.",
            "The.",
            "Set of functions represented in such a way that you can take into account the.",
            "The correlations between the functions from different kernels, so you know close sigmas should have very similar functions, say in a Gaussian context.",
            "So you don't want to treat those as somehow independent, but how to do that?",
            "I don't think people have made that step.",
            "I think that's a good good research direction now.",
            "Is there?",
            "How other performance?",
            "This model selection approach is affected by different currents.",
            "I mean.",
            "So yeah, you have compared this back based approach for model selection and classical consolidation and But my question is.",
            "The experimental data you show us first, maybe from 2 areas Carol, yes.",
            "That's a good question.",
            "Now we haven't tried that.",
            "I mean, I think this is very preliminary.",
            "Kind of first step, just sort of putting down a marker that it does seem possible, but I think you know these are very much sort of questions that you might say choosing the degree of the polynomial.",
            "Is that what you were thinking?",
            "Yeah, let's say you want to use kernel.",
            "How does this performance Pentecost validation?",
            "So here is not so so much influence.",
            "Baby things are getting better so you just use an average kernel and do you still have good performance?",
            "It would fit to cross validation.",
            "Or yeah that's good question.",
            "I don't know this answer, yeah?",
            "So many students here maybe next year we're gonna have some results.",
            "Then there is only stable and see that the proposed new bonds are better, more targeted than the classical one, but the performers are not not not not that different.",
            "Yeah, I agree.",
            "So this idea?",
            "OK, you can imagine that class 'cause we have compared former good model selection also with not good bands.",
            "Yeah, but I my experience with trying to use sort of the classical bounds for model selection is that they don't work very well.",
            "I mean, I think people have tried that I we certainly tried on one occasion and it doesn't seem to be reliable tool and this is the first time I've sort of seen a theoretical band giving reasonable model selection results.",
            "So I but I agree with you.",
            "I mean, you know you're absolutely right to say, you know, I mean, the hope is the tighter the bound gets, the less room it has to fool you.",
            "In some sense, you know that it can't mislead you by that much, whereas if it's a very weak bound you know might look good on this data set.",
            "But it's actually much worse than on this data set where it looks bad in terms of demand.",
            "So it's it's it's, you know, giving it less room to fool you, but it still can fool you for sure.",
            "You know an you might be lucky and get very good results with some more classical technique.",
            "I agree.",
            "Now thanks.",
            "Well.",
            "Minute conversation could be OK. OK."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I'll stop.",
                    "label": 0
                },
                {
                    "sent": "So welcome to the final session and thank you for coming.",
                    "label": 0
                },
                {
                    "sent": "I realize it's been a long day.",
                    "label": 0
                },
                {
                    "sent": "And probably this is not the most you say.",
                    "label": 0
                },
                {
                    "sent": "You know the thing that will keep you more awake than the previous talks.",
                    "label": 0
                },
                {
                    "sent": "I'm what I'm what I mean by that is this is trying to tell you a little bit about a theoretical basis for analysis of learning, so it's sort of a statistical framework that is used.",
                    "label": 0
                },
                {
                    "sent": "And my hope is that I can sort of map out the sort of landscape of of some of the theoretical analysis that have been made both in the Bayesian an the frequentist camps.",
                    "label": 0
                },
                {
                    "sent": "So give you an idea of how they relate, how they fit together, and in particular look at this PAC Bayes analysis, which is draws from both schools.",
                    "label": 0
                },
                {
                    "sent": "So my hope is that you know through that you'll get an understanding of both approaches, but also how they linked to.",
                    "label": 0
                },
                {
                    "sent": "Heather Anne.",
                    "label": 0
                },
                {
                    "sent": "You know could potentially see how the ideas might be applied in a different application that would be relevant to something that you're investigating, so that would be my hope.",
                    "label": 0
                },
                {
                    "sent": "Very happy to take questions at any point.",
                    "label": 0
                },
                {
                    "sent": "Even from shy no no, I mean, and so please do.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Got me an.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let's say I would.",
                    "label": 0
                },
                {
                    "sent": "I hope to give us some general perspectives.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "New historical note.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Talk about this core result that I think is a very beautiful theorem proving by Matthias Egan and David McAllister, so I'll give you a little bit of detail.",
                    "label": 1
                },
                {
                    "sent": "There may be too much for your liking, but if that's the case you know, just check your email.",
                    "label": 0
                },
                {
                    "sent": "Well, that's going on, and then I'll talk about applying it to in a little.",
                    "label": 0
                },
                {
                    "sent": "Also, in a little bit of detail about how it's applied to support vector machines.",
                    "label": 1
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "How that can motivate?",
                    "label": 0
                },
                {
                    "sent": "Actually, this idea of learning the prior, which I think is kind of a nice.",
                    "label": 1
                },
                {
                    "sent": "Way of using the theory to motivate some algorithms.",
                    "label": 0
                },
                {
                    "sent": "And again, it's not that I think it's a particularly.",
                    "label": 0
                },
                {
                    "sent": "Necessarily, you know, big step forward, but it's showing how you can use theoretical ideas in inventing new algorithms, which I think is theory shouldn't be there for its own sake.",
                    "label": 0
                },
                {
                    "sent": "It should be there to motivate our understanding of what is important and therefore the design of improved algorithms, hopefully.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's the overview of the of the presentation.",
                    "label": 0
                },
                {
                    "sent": "So a bit of background and sort of motivation and so on.",
                    "label": 0
                },
                {
                    "sent": "Then I'll go into this slightly more detailed look at the PAC Bayes theorem and the proof outline.",
                    "label": 0
                },
                {
                    "sent": "Talk about some sort of applications that have been made, not probably a complete list by any any means.",
                    "label": 0
                },
                {
                    "sent": "And then I'll delve into the application that I want to focus on, which is 2 linear classifiers.",
                    "label": 0
                },
                {
                    "sent": "So getting you know, I I right away, will you know confess that this is not going to be a general pattern analysis?",
                    "label": 0
                },
                {
                    "sent": "Theoretical.",
                    "label": 0
                },
                {
                    "sent": "Approach at this stage we're focusing in on classification is 1 type of pattern that can be found.",
                    "label": 0
                },
                {
                    "sent": "But again many of these things can be generalized quite readily and that may be something you're interested in doing yourselves, so I certainly wouldn't want to imply that the approaches can't be extended into other types of pattern.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It might be of interest.",
                    "label": 0
                },
                {
                    "sent": "OK, so first of all, general perspective.",
                    "label": 0
                },
                {
                    "sent": "So this is really I'm trying to start from.",
                    "label": 0
                },
                {
                    "sent": "You know, somebody who's approaching learning as a.",
                    "label": 0
                },
                {
                    "sent": "Something to study to try and improve their understanding of the phenomenon with A view to improving the algorithms as I said so.",
                    "label": 0
                },
                {
                    "sent": "Stepping right back, what are we trying to do when we develop a theory?",
                    "label": 0
                },
                {
                    "sent": "You know, get a paper accepted incoming conference.",
                    "label": 0
                },
                {
                    "sent": "OK, that may be a motivation, but the idea is to try and capture the key elements that enable an understanding and analysis of the phenomenon.",
                    "label": 1
                },
                {
                    "sent": "So in a sense, what we're trying to do is to abstract away from the detail of a particular application, just those key elements that are critical for understanding how that application, how successful that application will be.",
                    "label": 0
                },
                {
                    "sent": "What are the critical components that we can then.",
                    "label": 1
                },
                {
                    "sent": "You know, tune to make the.",
                    "label": 0
                },
                {
                    "sent": "The algorithms you know, optimize and so on, so it's really it's a an art of trying to understand and through initiative process.",
                    "label": 0
                },
                {
                    "sent": "Draw out those key key L.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In machine learning there are several theories and the two that I'm going to be sort of mentioning today are this Bayesian and so called frequentist.",
                    "label": 0
                },
                {
                    "sent": "Now they.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Arise from different assumptions.",
                    "label": 0
                },
                {
                    "sent": "And hence different range of applicability and and the range of results that can be obtained.",
                    "label": 1
                },
                {
                    "sent": "So you know in a sense one could say the more assumptions you put in, the more you can get out in terms of analysis, but possibly the less applicable.",
                    "label": 0
                },
                {
                    "sent": "It is because it's a restricted set of problems that it actually can be applied to accurately.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So, for instance, the Bayesians are able to make the Bayesian approaches able to make more detailed probabilistic predictions from the models that they develop, but they are based on perhaps more.",
                    "label": 0
                },
                {
                    "sent": "More assumptions which may or may not be.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Just enough why, whereas the frequentist makes only the independent, identically distributed assumption about the training data.",
                    "label": 0
                },
                {
                    "sent": "So very weak assumptions in terms of the analysis, though even those may fail in certain in many cases there may be may be problems with that idea assumption.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I'm going to talk first about the frequentist approach, just as a introductory sort of few key ideas.",
                    "label": 0
                },
                {
                    "sent": "Then I'll talk about the Bayesian and then this idea of where the PAC Bayes comes from.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "The frequentist approach.",
                    "label": 0
                },
                {
                    "sent": "I would claim is was pioneered in Russia by Vapnik and Sherman and Kiss.",
                    "label": 1
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Was introduced into the West by Valeant under the name of probably approximately correct into the machine learning community.",
                    "label": 0
                },
                {
                    "sent": "At least the type of result that we.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Has is that statement of the type that with probability at least one minus Delta, where Delta is some small, you know, sort of parameter.",
                    "label": 1
                },
                {
                    "sent": "So it might be you know 0.01 or something like that, and this is where the word probably comes from.",
                    "label": 0
                },
                {
                    "sent": "So probably any classifier from the hypothesis class which has low training error will have low generalization error.",
                    "label": 1
                },
                {
                    "sent": "In other words, provided you.",
                    "label": 0
                },
                {
                    "sent": "Get a good fit on the training data.",
                    "label": 0
                },
                {
                    "sent": "You will actually perform well on new test data.",
                    "label": 0
                },
                {
                    "sent": "In other words, it's approximately correct, so at first sight this appears a little bit of magic because you're only seeing a finite set of data.",
                    "label": 0
                },
                {
                    "sent": "How come you're inferring from that finite set something to an infinite set of unseen data items that you don't know about?",
                    "label": 0
                },
                {
                    "sent": "So the the reason that that works is because the assumption is made that the training data is drawn according to the same distribution as the testing data.",
                    "label": 0
                },
                {
                    "sent": "The new data, so that when you actually see enough testing training data you get.",
                    "label": 0
                },
                {
                    "sent": "Enough information from that about the statistics of the underlying distribution in order to make the the assertion that you're going to have low generalization error.",
                    "label": 0
                },
                {
                    "sent": "Now the Delta is the sort of confidence.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And that is actually picking up the sort of possibly intuitive floor in that argument, which is well, what if you were just very unlucky with your training data?",
                    "label": 0
                },
                {
                    "sent": "You know, somehow you just got a really bad set of training data, because after all, it's a random Lee generated set, and that's really what this Delta handles.",
                    "label": 0
                },
                {
                    "sent": "It says that OK there is this small probability that I just may have been very unlucky and got a very unrepresentative sample.",
                    "label": 0
                },
                {
                    "sent": "And So what I learned from it was actually useless.",
                    "label": 0
                },
                {
                    "sent": "So that's that confidence.",
                    "label": 0
                },
                {
                    "sent": "And then the glow generalization is just the fact that.",
                    "label": 0
                },
                {
                    "sent": "With a finite sample, you are certainly not going to be able to make predictions about everything because there may be pockets of.",
                    "label": 0
                },
                {
                    "sent": "You know data that you simply didn't see, which behave very unusually, so I often give this example of, you know, classifying.",
                    "label": 0
                },
                {
                    "sent": "'cause into sports cars or not, sports cars and you know you get a sample of sports cars and you know something.",
                    "label": 0
                },
                {
                    "sent": "Sorry, a sample of cars and you see which ones are sports cars and you infer from that you get a good idea.",
                    "label": 0
                },
                {
                    "sent": "But of course there are very unusual sports cars, perhaps vintage sports cars that don't fit into that pattern and you may therefore get those wrong.",
                    "label": 0
                },
                {
                    "sent": "So this would be the approximate approximately correct part and the Delta part would be if you were just very unlucky and happen to.",
                    "label": 0
                },
                {
                    "sent": "Look out onto the street as the cars drove past and it was a sort of vintage car rally and all you saw were vintage sports cars and you didn't get the right data as it were for for the training.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's the.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This sort of framework, and it's been applied to support vector machines in within this.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Luckiness framework.",
                    "label": 0
                },
                {
                    "sent": "So now a little bit of background to the Bayesian approach.",
                    "label": 1
                },
                {
                    "sent": "So it the name derives from Bayes theorem which I recently understood maybe shouldn't have been called base theorem.",
                    "label": 1
                },
                {
                    "sent": "I'm not sure about this, but anyway, there's certainly some historical contention about that, but.",
                    "label": 0
                },
                {
                    "sent": "The way it works is, you assume a prior distribution over functions, so there's a difference immediately.",
                    "label": 0
                },
                {
                    "sent": "Remember, in the frequentist we were assuming a distribution over the inputs.",
                    "label": 0
                },
                {
                    "sent": "Generating the data here we're assuming a distribution over functions, or in our case classifiers and then what we do is we have a given a data item now, so one of our training data items we can say based on that item, how likely that a particular classifier might be.",
                    "label": 1
                },
                {
                    "sent": "So if that classifier misclassified as that data item, then we downgrade its probability.",
                    "label": 0
                },
                {
                    "sent": "You can imagine you know if it's saying it's a positive example and.",
                    "label": 0
                },
                {
                    "sent": "We know it's a negative example, then we were not going to trust that classifier so much.",
                    "label": 0
                },
                {
                    "sent": "So we down weight it's probabilities.",
                    "label": 0
                },
                {
                    "sent": "And we do that for all of the classifiers in the in the class with all of the training data, so we know each classifier that so basically according to the number of mistakes it makes you downgrade its probability according to that that amount.",
                    "label": 0
                },
                {
                    "sent": "And then at the end of the day, you you end up with what's called a post.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": ".",
                    "label": 0
                },
                {
                    "sent": "Distribution.",
                    "label": 0
                },
                {
                    "sent": "Which is the distribution over the classifiers after you've seen the data?",
                    "label": 1
                },
                {
                    "sent": "So it's now peaked around classifiers that typically are giving good performance on the training data and is much lower on classifiers that are doing poorly on the training data.",
                    "label": 0
                },
                {
                    "sent": "But it's bias.",
                    "label": 1
                },
                {
                    "sent": "Still a little bit by the prior distribution, which was the distribution that we started with, which was the distribution.",
                    "label": 0
                },
                {
                    "sent": "A priore that was given by the.",
                    "label": 0
                },
                {
                    "sent": "By the Bayesian.",
                    "label": 0
                },
                {
                    "sent": "Designer of this system.",
                    "label": 1
                },
                {
                    "sent": "OK, so that's that's what you're left with is posterior distribution.",
                    "label": 1
                },
                {
                    "sent": "Now, if you're a true Bayesian, you will classify according to the expected classification under that posterior distribution.",
                    "label": 1
                },
                {
                    "sent": "So you average over the posterior.",
                    "label": 0
                },
                {
                    "sent": "So for that particular test point, you average over the posterior.",
                    "label": 0
                },
                {
                    "sent": "The classifications that you get weighted according to that posterior distribution.",
                    "label": 1
                },
                {
                    "sent": "So the guys that were good on the training data get more weight and are more likely to.",
                    "label": 0
                },
                {
                    "sent": "Give you a classification of this new test point.",
                    "label": 0
                },
                {
                    "sent": "OK, Notice again, there's still.",
                    "label": 0
                },
                {
                    "sent": "There's absolutely no distribution on the inputs.",
                    "label": 0
                },
                {
                    "sent": "The inputs are just there, there.",
                    "label": 0
                },
                {
                    "sent": "There, in the training set, and they're just there in the test set.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, and one of the very interesting so.",
                    "label": 1
                },
                {
                    "sent": "As I said, there's many things you can do with the Bayesian framework because you actually have a probability distribution over the function, so you can use that to estimate things, and one of the things you can estimate is the likelihood of the data under that model.",
                    "label": 0
                },
                {
                    "sent": "And this allows you.",
                    "label": 1
                },
                {
                    "sent": "It's just integrating essentially over all of the functions with the posterior weight, their probability of generating the training data.",
                    "label": 0
                },
                {
                    "sent": "And this is known as the evidence for a model, and it was proposed by David Macay back in about 1992, I think.",
                    "label": 1
                },
                {
                    "sent": "So in the case if we look at the we only allow consistent so we give zero probability, two points that are two functions that misclassify any of the training data.",
                    "label": 1
                },
                {
                    "sent": "Then this can be seen as the volume.",
                    "label": 0
                },
                {
                    "sent": "The prior volume in the prior distribution of what's called version space.",
                    "label": 1
                },
                {
                    "sent": "And I'll just.",
                    "label": 0
                },
                {
                    "sent": "Later on, I'll give you a.",
                    "label": 1
                },
                {
                    "sent": "A picture of that which will perhaps make this a little bit more clear of what's going on here, but essentially you can use this posterior sort of evidence for the model as a way of selecting between different models, and this is used, and it's not always reliable, but it's certainly a quite interesting way of doing model selection.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "The model.",
                    "label": 0
                },
                {
                    "sent": "The model is that the class of functions with the prior probability over them plus the error.",
                    "label": 0
                },
                {
                    "sent": "Probability you have to tell you know, so you have to know how much to down way to function when it misclassified as a point.",
                    "label": 0
                },
                {
                    "sent": "So that's your error probability.",
                    "label": 0
                },
                {
                    "sent": "Which you could set aside to zero.",
                    "label": 0
                },
                {
                    "sent": "You could just give zero wait to anything that misclassified something.",
                    "label": 0
                },
                {
                    "sent": "But if you allow it to do a few miss class, you know you can give away to that probability.",
                    "label": 0
                },
                {
                    "sent": "So the model is defined by a set of functions of prior distribution over them and this error.",
                    "label": 0
                },
                {
                    "sent": "Wait?",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the Gaussian process is for regression are justified within this model and there the prior is a Gaussian prior in this.",
                    "label": 1
                },
                {
                    "sent": "Which is defined by the covariance function, which is what would be called by kernel people, the kernel, and that defines a Gaussian prior over the functions effectively and the.",
                    "label": 0
                },
                {
                    "sent": "If you follow through all of the updating of that with a, again, a Gaussian error model which you know the error is here in terms of a real valued error, then you get a posterior and you're able to compute it exactly.",
                    "label": 0
                },
                {
                    "sent": "It turns out it's also a Gaussian, and you can estimate error bars and do interesting computations with that model.",
                    "label": 0
                },
                {
                    "sent": "OK, so I'm that's my story of Bayesian story in one slide, but I'm quite happy again to take more questions if there are any.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So here's the picture I mentioned.",
                    "label": 0
                },
                {
                    "sent": "So here we imagine that this is the the space of weight vectors.",
                    "label": 0
                },
                {
                    "sent": "In some learning system nonlinear, should we say so that this is the?",
                    "label": 0
                },
                {
                    "sent": "Locus of points in whitespace for which the output of the.",
                    "label": 1
                },
                {
                    "sent": "On the 1st training point is equal to 0, so one side of this, let's say this side of this line.",
                    "label": 0
                },
                {
                    "sent": "Corresponds to correct classification of the first data point.",
                    "label": 1
                },
                {
                    "sent": "And here's the second data point so that this side of this line corresponds to correct classification of the second training point.",
                    "label": 1
                },
                {
                    "sent": "So all weights that are in this region sort of to the left of this line and below this line correctly classify X1 and X2 and Similarly X3.",
                    "label": 0
                },
                {
                    "sent": "Anything below this line X4 anything to the right of this line, and So what I've drawn here is the largest circle that can be inscribed into the region, which is correctly classifying.",
                    "label": 1
                },
                {
                    "sent": "All of the four training points.",
                    "label": 1
                },
                {
                    "sent": "So we could think of the evidence if we were using this noise model, which said zero probability of making an error.",
                    "label": 0
                },
                {
                    "sent": "The evidence here would be the integral over this region where all of the the.",
                    "label": 1
                },
                {
                    "sent": "Points are correctly classified under the prior distribution, which we might assume is uniform, and so this circle would therefore be the sort of largest inscribed sphere or circle in that correctly classified region, and that could be used as some sort of estimate for the evidence for that particular data.",
                    "label": 0
                },
                {
                    "sent": "The best option is not at all, no.",
                    "label": 0
                },
                {
                    "sent": "I mean in the Bayesian approach you would do the full integral over the thing if you could, but frequently you can't, so you make an estimate of maybe not necessarily a sphere, but maybe some sort of Gaussian with a spherical covariance matrix you know to fit fit into that region to try and get a lower bound on this volume.",
                    "label": 0
                },
                {
                    "sent": "So yeah, I mean as soon as you actually try and roll out the Bayesian technology into an application, it does tend to lead to the need to make approximations.",
                    "label": 0
                },
                {
                    "sent": "And of this type.",
                    "label": 0
                },
                {
                    "sent": "But but let's say the good news is you get out more informed information about the.",
                    "label": 0
                },
                {
                    "sent": "The probabilities involved.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so now I'm going to just try and lead into the PAC Bayes approach.",
                    "label": 0
                },
                {
                    "sent": "So this is really the idea came from linking evidence and generalization and this link was suggested actually by David Mackay very early on the idea that the evidence might be an indicator of good generalization.",
                    "label": 1
                },
                {
                    "sent": "So remember good generalization doesn't really mean anything to a Bayesian because he doesn't have a probability distribution on the.",
                    "label": 1
                },
                {
                    "sent": "On the training point, so it's by definition.",
                    "label": 0
                },
                {
                    "sent": "It's a sort of cross.",
                    "label": 0
                },
                {
                    "sent": "Cross.",
                    "label": 0
                },
                {
                    "sent": "How do you say theory concept to link evidence and generalization?",
                    "label": 0
                },
                {
                    "sent": "So generalization is about performance on new data from a Bayesian point of view, you don't have that idea of new data being being generated by a probability distribution, but nonetheless this link was suggested by Mackay and.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Bob Williamson and myself obtained first sort of formal link, where we basically analyzed the generalization of a classifier based on the volume of that inscribed sphere.",
                    "label": 1
                },
                {
                    "sent": "And this was sort of surprising result in some respects.",
                    "label": 1
                },
                {
                    "sent": "Becausw it didn't depend on the VC dimension of the set of functions.",
                    "label": 0
                },
                {
                    "sent": "This was sort of cutting across standard sort of results at the time.",
                    "label": 0
                },
                {
                    "sent": "In the.",
                    "label": 0
                },
                {
                    "sent": "I mean, it's sort of a luckiness.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Idea, so you actually you know the volume of the sphere can be seen as a sort of indication that you've been lucky and actually you can get a bound that is better than you would if you use the sort of ambient VC dimension which would be the normal approach.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately, there is a dependence on the dimensionality of the space, and we'll see that as we move through the later applications to support vector machines that is avoided in the newer newer bounds.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the user luckiness framework and so it's a data dependent style of frequentist bound and it's similar in spirit to the bounds the way that the SVM generalization is bounded OK.",
                    "label": 1
                },
                {
                    "sent": "So you could sort of think of, you know, in the case of SVM's you bound in terms of the margin of the of the classifier.",
                    "label": 1
                },
                {
                    "sent": "In this case your bounding in terms of the sort of volume of this.",
                    "label": 1
                },
                {
                    "sent": "So it's something like a sort of surrogate margin.",
                    "label": 0
                },
                {
                    "sent": "This volume of this sphere.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So then this idea was.",
                    "label": 0
                },
                {
                    "sent": "Significantly developed by McAllister and later by Matthias Ciga.",
                    "label": 0
                },
                {
                    "sent": "They proved what's become to be known as the PAC Bayes theorem.",
                    "label": 0
                },
                {
                    "sent": "The first version was a little bit less tight and clean than the version I'm going to show you, which is really due to Matthias Seeger.",
                    "label": 0
                },
                {
                    "sent": "His mode.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Ovation was an application to Gaussian processes so he was really thinking about Gaussian process.",
                    "label": 0
                },
                {
                    "sent": "You know the prior of the Gaussian process and the posterior that I described to you earlier and he was trying to use those priors and posteriors to bound the performance.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But I'll sort of talk about you don't need to restrict yourself to those particular choices of prime, posterior, or certainly that posterior.",
                    "label": 0
                },
                {
                    "sent": "And indeed when John Langford and I looked at SVM then in that case we used a different posterior to the one used in the Gaussian process analysis of Matthias Seeger.",
                    "label": 0
                },
                {
                    "sent": "But basically the same bound can be applied.",
                    "label": 0
                },
                {
                    "sent": "And there's an egg.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Alan Tutorial by John Langford that appeared in 2005 on Jim Miller.",
                    "label": 0
                },
                {
                    "sent": "It's a general thought of all sorts of bounds, but in there there's a very good summary of the PAC Bayes theorem and its application to support vector.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Jeans.",
                    "label": 0
                },
                {
                    "sent": "OK, so now I'm going to sort of start to lead up to.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "PAC Bayes analysis theorem.",
                    "label": 0
                },
                {
                    "sent": "So what I want to do is start to introduce these sort of framework.",
                    "label": 0
                },
                {
                    "sent": "And the notation that I'll be using.",
                    "label": 0
                },
                {
                    "sent": "So again, you know, do stop me if it's if things aren't clear please.",
                    "label": 0
                },
                {
                    "sent": "So basically we've got a class of classifiers.",
                    "label": 1
                },
                {
                    "sent": "It's very much like doing Bayesian analysis.",
                    "label": 0
                },
                {
                    "sent": "At first sight.",
                    "label": 0
                },
                {
                    "sent": "You have a prior distribution over the functions, so you imagine you've got your functions and somehow you think before you start to look at them that some are more likely to occur in this application than others, and you put down that distribution and that could be given implicitly.",
                    "label": 0
                },
                {
                    "sent": "As I said, you know, in the Gaussian process example it's given through this covariance function or kernel.",
                    "label": 0
                },
                {
                    "sent": "Can you consider the case of a posterior over these functions which will be data dependent on the data?",
                    "label": 1
                },
                {
                    "sent": "So this has to be chosen before you see the data.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This P must be chosen before learning, but the bound will hold for all choices of Q.",
                    "label": 1
                },
                {
                    "sent": "So that means that you can choose Q to get the best bound based on your data and essentially choosing Q corresponds to choosing your classifier in some sense, so choosing Q is like choosing the classifier.",
                    "label": 1
                },
                {
                    "sent": "But Q doesn't need to be the posterior of the classical Bayesian approach, so the classical Bayesian approaches I mentioned would update the prior based on the.",
                    "label": 0
                },
                {
                    "sent": "You know the error probabilities of the training data and down weight, those which made errors on the training data in a sort of using some sort of noise model, and that would be the posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "There's no need to do that within this theory.",
                    "label": 0
                },
                {
                    "sent": "You can do that if you want.",
                    "label": 0
                },
                {
                    "sent": "Q can be any distribution, so it doesn't matter what you do.",
                    "label": 0
                },
                {
                    "sent": "The theorem will hold.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the bound works that, provided you choose your P ahead of time.",
                    "label": 1
                },
                {
                    "sent": "Whatever Q you choose, the bound will hold OK, so it's so.",
                    "label": 1
                },
                {
                    "sent": "In other words, you can choose Q to optimize the bound at posteriori, which is the nice feature of this.",
                    "label": 0
                },
                {
                    "sent": "It's interesting here that it kind of undermines a lot of the debates that's held in the Bayesian Cam, because there's a lot of concern about the meaning of the prior distribution.",
                    "label": 0
                },
                {
                    "sent": "So how do you choose a prior distribution?",
                    "label": 1
                },
                {
                    "sent": "What does it mean?",
                    "label": 0
                },
                {
                    "sent": "And there's a philosophical Bayesians and the.",
                    "label": 0
                },
                {
                    "sent": "There's another type and I don't know what they call, but there are two sort of schools of thought about what choosing the prior distribution actually means, because in a sense you know how do you arrive at a prior expectation.",
                    "label": 0
                },
                {
                    "sent": "So from a practical point of view, I think we can all imagine how you might do that.",
                    "label": 0
                },
                {
                    "sent": "You know the sort of domain that you're looking at.",
                    "label": 0
                },
                {
                    "sent": "Maybe you've had some experience of working with that type of data, and maybe you know the kind of kernel or covariance function that you should be using, and that kernel would correspond to essentially choosing P. OK.",
                    "label": 0
                },
                {
                    "sent": "But from a philosophical point of view, it's very hard to kind of understand what.",
                    "label": 0
                },
                {
                    "sent": "You know what this distribution means, and of course, if you are a Bayesian, the.",
                    "label": 0
                },
                {
                    "sent": "The results of your analysis are only correct if that prior distribution is correct.",
                    "label": 0
                },
                {
                    "sent": "What does it mean to be correct as a prior decision is it's a very difficult question for a Bayesian to answer, however, that all falls away here because the results are going to be true.",
                    "label": 0
                },
                {
                    "sent": "Whatever choice of P you make, just if you make a bad choice, then you get a bad resulting bound, so it's not.",
                    "label": 1
                },
                {
                    "sent": "The issue goes away.",
                    "label": 0
                },
                {
                    "sent": "I mean it's still there because you need to choose a good P, but it isn't an issue of a philosophical nature, it's just an issue of a quality of your.",
                    "label": 0
                },
                {
                    "sent": "Classifier and your analysis so that the status of P is now if you like just given, you know as a sort of mathematical object rather than some.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Necessary philosophical accuracy in embedded in it.",
                    "label": 0
                },
                {
                    "sent": "So, so I think I've already kind of hinted and you probably guessed that this is actually a frequentist bound.",
                    "label": 0
                },
                {
                    "sent": "I mean, although it's called a PAC Bayes analysis, the Bayes is sort of like the inspiration, but the mechanics are packets of frequentist type bound.",
                    "label": 0
                },
                {
                    "sent": "So again, we're going to assume an unknown distribution on the input space.",
                    "label": 1
                },
                {
                    "sent": "We're going to assume that our examples are being generated according to that distribution and what we're interested in is.",
                    "label": 0
                },
                {
                    "sent": "Bounding how well our classifier will perform on data that is generated according to that same distribution that we haven't seen during training.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So again, we use the distribution to generate the labeled training examples ID.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We also use it as our measure of quality of performance, which is the expected value of the misclassification on and you training point.",
                    "label": 0
                },
                {
                    "sent": "So this is the link between training and testing.",
                    "label": 0
                },
                {
                    "sent": "Again, the training is generated according to the same distribution as is used to to perform the testing and what we're interested in is founding the value of this expectation or this probability here that the test data is misclassified.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we have an empirical measure of that, which is the average over the training data for that particular classifier of its number of errors that it makes over the size M of the training set.",
                    "label": 0
                },
                {
                    "sent": "So there's a in some sense what we're interested in is connecting these two for a given.",
                    "label": 0
                },
                {
                    "sent": "Function class so very classical question.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "So the.",
                    "label": 0
                },
                {
                    "sent": "Then you take that comes in and this is where sort of we dip our to little bit from a classical.",
                    "label": 0
                },
                {
                    "sent": "Analysis of generalization.",
                    "label": 0
                },
                {
                    "sent": "So where things start to get interesting is that the bound of the performance is not of a classifier, but of a probabilistic classifier.",
                    "label": 1
                },
                {
                    "sent": "So we actually when we take a test point X, we choose a classifier according to our posterior distribution and then return the classification of that classifier on that input.",
                    "label": 1
                },
                {
                    "sent": "And that's the that's the thing we're going to bound now that isn't actually what you do in a support vector machine.",
                    "label": 0
                },
                {
                    "sent": "For instance, for a support vector machine, you have a particular function.",
                    "label": 0
                },
                {
                    "sent": "You don't have a probability distribution over functions that you might use.",
                    "label": 0
                },
                {
                    "sent": "You have a particular function that your algorithm has output, so we're going to have to connect this analysis, which is about a probabilistic classification with the analysis with the actual practical application of support vector machines will come back to that.",
                    "label": 1
                },
                {
                    "sent": "So don't worry about that at the moment, but this is.",
                    "label": 0
                },
                {
                    "sent": "What's being analyzed within the PAC Bayes framework?",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 1
                },
                {
                    "sent": "Gracie is a country itself of the best.",
                    "label": 0
                },
                {
                    "sent": "OK, yeah, I mean, remember the Q has been chosen based on the date the training data.",
                    "label": 0
                },
                {
                    "sent": "So the Q will have been.",
                    "label": 0
                },
                {
                    "sent": "I mean typically what you might happen.",
                    "label": 0
                },
                {
                    "sent": "You know you've got this quite uniform prior P. You see your training data and there's sort of basically a small region of functions that do well on that train.",
                    "label": 0
                },
                {
                    "sent": "It might be just one function that does well on that training data and you put your posterior Q with a big strong weight on that that region.",
                    "label": 0
                },
                {
                    "sent": "OK, so So what should I mean?",
                    "label": 0
                },
                {
                    "sent": "The tradeoff you're trying to make?",
                    "label": 0
                },
                {
                    "sent": "I mean, this is a very sort of naive diagram, but if you imagine this is your function class, this is your prior distribution with some sort of very uniform set of things, and now you know there's basically a region here where the functions perform well on the training data, so your posterior becomes sort of.",
                    "label": 0
                },
                {
                    "sent": "Very peaked around at that point, and indeed that might be a single function.",
                    "label": 0
                },
                {
                    "sent": "And so then what you're interested in is sampling.",
                    "label": 0
                },
                {
                    "sent": "According to this posterior distribution and using that to do the actual classification of a test point.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yes.",
                    "label": 0
                },
                {
                    "sent": "Present from the true vision by averaging around it is different.",
                    "label": 1
                },
                {
                    "sent": "Yeah, so if you're unfortunately, that's yeah, that is different.",
                    "label": 0
                },
                {
                    "sent": "That's a slight.",
                    "label": 0
                },
                {
                    "sent": "Handicap of the analysis here because the Bayesian would average according to that, whereas we're taking an expectation according well.",
                    "label": 0
                },
                {
                    "sent": "I mean what it means, we're taking the expected classification rather than the.",
                    "label": 0
                },
                {
                    "sent": "It seems that if you repeat because initially many times then aren't, you already have it?",
                    "label": 0
                },
                {
                    "sent": "Yeah, if you did it many times, that's true.",
                    "label": 0
                },
                {
                    "sent": "That's would be the same then.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah.",
                    "label": 0
                },
                {
                    "sent": "This thing is saying as a generalization error of Asian restaurant or no, not not so.",
                    "label": 0
                },
                {
                    "sent": "So I'll mention it.",
                    "label": 0
                },
                {
                    "sent": "There's a factor of two that might come in between the two.",
                    "label": 0
                },
                {
                    "sent": "I'll mention it, yeah.",
                    "label": 0
                },
                {
                    "sent": "Factors of crime, or anything else.",
                    "label": 0
                },
                {
                    "sent": "It was that he was notified.",
                    "label": 0
                },
                {
                    "sent": "Yeah, in this case, so it may be.",
                    "label": 0
                },
                {
                    "sent": "I mean it's very difficult to draw a good diagram, but you know if you didn't see much training data and the posterior, maybe the good.",
                    "label": 0
                },
                {
                    "sent": "Maybe it goes down here quite low and the good stuff is here.",
                    "label": 0
                },
                {
                    "sent": "So then the posterior and you didn't have that much training data.",
                    "label": 0
                },
                {
                    "sent": "So then the posterior might sort of look like that.",
                    "label": 0
                },
                {
                    "sent": "You know where.",
                    "label": 0
                },
                {
                    "sent": "There's still quite a bit of weight being preserved on these rather useless, but yeah, I mean the bayesians would always argue that the priors not important, really, but.",
                    "label": 0
                },
                {
                    "sent": "Problem is that if you're being if you're doing that analysis, it is 'cause it's the only thing you've got in some sense.",
                    "label": 0
                },
                {
                    "sent": "Any other questions?",
                    "label": 0
                },
                {
                    "sent": "OK good OK so.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so there's something else I was going to say this movie.",
                    "label": 0
                },
                {
                    "sent": "Yeah, OK so.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that's the picture to have in mind, so we're interested in these two quantities.",
                    "label": 1
                },
                {
                    "sent": "So one is this expectation of the.",
                    "label": 0
                },
                {
                    "sent": "The error as we choose C according to this posterior distribution of the true error, and then the expectation of as we choose C according to Q of the empirical error, right?",
                    "label": 1
                },
                {
                    "sent": "So it's.",
                    "label": 0
                },
                {
                    "sent": "It's sort of if we just look at CD relating CD and see hat of S. It would be just a classical sort of pack type, but the fact that we've introduced these expectations gives it the Bayesian.",
                    "label": 0
                },
                {
                    "sent": "Later, because we're talking about a posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is the the point that about the relation to the.",
                    "label": 0
                },
                {
                    "sent": "You know expectation, so this would be what you would do if you were doing a posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "You would average the classification according to.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "According to this C of Q.",
                    "label": 0
                },
                {
                    "sent": "And then take the sign of that, as it were, so you would use the sort of average of the posterior distribution of the classic classifiers as your classifier, and that will be the interesting thing you want to to bound.",
                    "label": 0
                },
                {
                    "sent": "But in fact you can bound that by twice the the QD thing that I put up on the previous slide.",
                    "label": 0
                },
                {
                    "sent": "So although it's not the right thing, it's at most a factor two though, that two is probably quite conservative here.",
                    "label": 0
                },
                {
                    "sent": "In general, but maybe in some cases it's not.",
                    "label": 0
                },
                {
                    "sent": "OK, so the argument why that is the case?",
                    "label": 0
                },
                {
                    "sent": "Any point X mix misclassified by this guy here, there must be at least half of the season probability weight under Q that misclassify.",
                    "label": 1
                },
                {
                    "sent": "So our average classification is going to be wrong, about half of the time.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so this is the theorem.",
                    "label": 0
                },
                {
                    "sent": "OK, so we've got all the notation down.",
                    "label": 0
                },
                {
                    "sent": "This is what it says.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "You've got an arbitrary distribution on the inputs.",
                    "label": 0
                },
                {
                    "sent": "You got an arbitrary distribution on the functions.",
                    "label": 0
                },
                {
                    "sent": "You've gotta confidence Delta, then with probability 1 minus Delta over the sample.",
                    "label": 0
                },
                {
                    "sent": "So you specify the conference that is that are drawn according to this distribution, IID.",
                    "label": 0
                },
                {
                    "sent": "As we said, all posteriors satisfy the following inequality.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is a little hard to read, but basically what what's happening here is there on this side?",
                    "label": 0
                },
                {
                    "sent": "We've got the misfit between the empirical and true error of this randomized classifier, so Q hat is the empirical.",
                    "label": 0
                },
                {
                    "sent": "This is the true, and by this KL I mean you just treat these as distributions on 0 + 1, where 0 means.",
                    "label": 0
                },
                {
                    "sent": "Say correctly classified and plus one means incorrectly classified.",
                    "label": 0
                },
                {
                    "sent": "So it's just the.",
                    "label": 0
                },
                {
                    "sent": "You know the KL divergent of.",
                    "label": 0
                },
                {
                    "sent": "I mean if if P is the error of the true classifying P hat, is the error of the.",
                    "label": 0
                },
                {
                    "sent": "Empirical then that KL is actually equal to P hat log P hat over P + 1 -- P hat log 1 -- P hat or 1 -- P. OK.",
                    "label": 0
                },
                {
                    "sent": "So, but it's it's a measure of closeness.",
                    "label": 0
                },
                {
                    "sent": "So if these two were the same, then this would be 0.",
                    "label": 0
                },
                {
                    "sent": "But it's it's more flexible measure of closeness than, say, taking a difference.",
                    "label": 0
                },
                {
                    "sent": "The interesting thing about it is that when these two things are close, then there there.",
                    "label": 0
                },
                {
                    "sent": "The same amount of KL divergences here corresponds to much less separation between the two, so it's sort of like a flexible measure.",
                    "label": 0
                },
                {
                    "sent": "In some sense, it gives you a tighter bound when you're close to 0, which is something you would like, and maybe a looser bound when you're away from zero, which is something you can't avoid, so it's quite a nice sort of measure to have here.",
                    "label": 0
                },
                {
                    "sent": "You can get rid of it, but you always end up with something weaker.",
                    "label": 0
                },
                {
                    "sent": "So that's that's really just think of it as just a measure of difference between these two, but a slightly more sophisticated one than just taking the difference, OK?",
                    "label": 0
                },
                {
                    "sent": "Now on this side you've got a very simple expression which just involves the KL divergent between the two distributions.",
                    "label": 0
                },
                {
                    "sent": "So the tradeoff.",
                    "label": 0
                },
                {
                    "sent": "That's really if you know if you think of this diagram here what we're trying to do is say OK, I'm going to find.",
                    "label": 0
                },
                {
                    "sent": "Here's my prior distribution.",
                    "label": 0
                },
                {
                    "sent": "Here's my posterior, I don't.",
                    "label": 0
                },
                {
                    "sent": "I want to somehow keep the KL divergent between these two not too big, but but reduce my empirical error by.",
                    "label": 0
                },
                {
                    "sent": "By a lot, so we want to sort of move to reduce the empirical error, but in a way that doesn't increase this.",
                    "label": 0
                },
                {
                    "sent": "KL divergent too much, so we sort of keep an overlap with the prior distribution, but hopefully get get a low empirical error.",
                    "label": 0
                },
                {
                    "sent": "So it's a very intuitive kind of idea that's being described here, I think.",
                    "label": 0
                },
                {
                    "sent": "Second time.",
                    "label": 0
                },
                {
                    "sent": "US QSQ teach.",
                    "label": 0
                },
                {
                    "sent": "Yep, no problem.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So QSQ had S is just the expected.",
                    "label": 0
                },
                {
                    "sent": "Error under so Seattle versus just the empirical error of the classifier C right.",
                    "label": 0
                },
                {
                    "sent": "And but then Q had a VAS is just the expected value of that error when you draw C According to that posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "So you know you draw a C and you see what error it has.",
                    "label": 0
                },
                {
                    "sent": "It's just a number.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah.",
                    "label": 0
                },
                {
                    "sent": "No.",
                    "label": 0
                },
                {
                    "sent": "And the sorry it is no.",
                    "label": 0
                },
                {
                    "sent": "It's a relative relative frequency, right?",
                    "label": 0
                },
                {
                    "sent": "See how diverse is the relative error?",
                    "label": 0
                },
                {
                    "sent": "And this is just the true error of C. Again expectation when sampled according to this posterior.",
                    "label": 0
                },
                {
                    "sent": "So in other words, to choose Q in such a way that this is small, which is what you want to do, you have to put the weight onto onto the functions that typically have small error.",
                    "label": 0
                },
                {
                    "sent": "So I'll give an example of, say, a finite class where you put all the weight on a single function.",
                    "label": 0
                },
                {
                    "sent": "I mean and it reduces back to a kind of standard.",
                    "label": 0
                },
                {
                    "sent": "Result in that case where this is this expectation is just a selection of a single function, so there isn't any randomness at all at that point.",
                    "label": 0
                },
                {
                    "sent": "Maybe maybe I'll do that right away, and then I'll come back and say this again.",
                    "label": 0
                },
                {
                    "sent": "'cause maybe that's so if we go to this, skip all this.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Where is so this is the case of a finite class of functions, so you've got H1 up to HN.",
                    "label": 1
                },
                {
                    "sent": "And let's say you put a prior distribution of P1 up to PN, so it's just a finite set of probabilities that sum to one.",
                    "label": 0
                },
                {
                    "sent": "Then the posterior.",
                    "label": 0
                },
                {
                    "sent": "You can assume now is on a single function, so if you happen to have two functions that correctly classified, you could do is sort of a division on that.",
                    "label": 0
                },
                {
                    "sent": "But let's say you just choose a single function and put all your weight on that function.",
                    "label": 1
                },
                {
                    "sent": "So then the KL divergent's reduces to just minus log of Pi.",
                    "label": 0
                },
                {
                    "sent": "Because the.",
                    "label": 0
                },
                {
                    "sent": "You know the Q is essentially one on a single function Pi, so Qi log Pi over Qi or sorry Q / P I is just minus log P because Qi is just one.",
                    "label": 0
                },
                {
                    "sent": "And all of the others are zero, so they disappear.",
                    "label": 1
                },
                {
                    "sent": "So it's just minus log P. And this is just a very standard result that you can get in the normal pack framework where you have log 1 / P. I essentially a weight on a single function.",
                    "label": 0
                },
                {
                    "sent": "OK, so so this unit could think of that as a kind of fullback position, but if we go to the.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "Situation here we are allowing this queue to select not just one function but a whole.",
                    "label": 1
                },
                {
                    "sent": "You know distribution of functions here, but we're taking the expectation of the empirical errors at that point.",
                    "label": 0
                },
                {
                    "sent": "OK. And this is the expectation of the true errors.",
                    "label": 1
                },
                {
                    "sent": "So you're going to ask that there was.",
                    "label": 0
                },
                {
                    "sent": "The actual theater, yeah?",
                    "label": 0
                },
                {
                    "sent": "Spur support.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Of the two.",
                    "label": 0
                },
                {
                    "sent": "Fire and service support.",
                    "label": 0
                },
                {
                    "sent": "Just to provide one.",
                    "label": 0
                },
                {
                    "sent": "Then we kill averages is different in this town?",
                    "label": 0
                },
                {
                    "sent": "Is arthritis making memories?",
                    "label": 0
                },
                {
                    "sent": "Yeah, if you.",
                    "label": 0
                },
                {
                    "sent": "Well, the would be infinite if Q had weight on something that he didn't have, wait on.",
                    "label": 0
                },
                {
                    "sent": "It's only in that direction.",
                    "label": 0
                },
                {
                    "sent": "That's always the problem, but it's only in that case, so you're not allowed.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I mean, you're not allowed if you don't have weight on anything.",
                    "label": 0
                },
                {
                    "sent": "I mean if there's some function that you don't have in your prior, then you can't use it absolutely.",
                    "label": 0
                },
                {
                    "sent": "Don't wait on just one function to prioritize and same thing, no?",
                    "label": 0
                },
                {
                    "sent": "No, no, that example I gave with the finite was.",
                    "label": 0
                },
                {
                    "sent": "Surface Pro batteries.",
                    "label": 0
                },
                {
                    "sent": "Some way to make it so assume that now I'm not going out with her if I.",
                    "label": 0
                },
                {
                    "sent": "Well.",
                    "label": 0
                },
                {
                    "sent": "Well, I yeah you could try that, but I think that the yeah.",
                    "label": 0
                },
                {
                    "sent": "I mean that's an interesting question.",
                    "label": 0
                },
                {
                    "sent": "I think that the bound.",
                    "label": 0
                },
                {
                    "sent": "OK, this sort of the mathematicians argument that it's sort of the right bound, you know, kind of.",
                    "label": 1
                },
                {
                    "sent": "It makes it makes you know, sort of pops out.",
                    "label": 0
                },
                {
                    "sent": "So it sort of feels right, but so that my intuition is that if you try to put something else in, there would just be a weaker found that you derive from a sensually from this one.",
                    "label": 0
                },
                {
                    "sent": "But the way you can get round, I mean, if you think of a support vector application with a Gaussian kernel, for instance, you can use a Gaussian distribution which has weight on every function essentially, but very, very small weight.",
                    "label": 0
                },
                {
                    "sent": "So then yeah.",
                    "label": 0
                },
                {
                    "sent": "Schuylkill that works.",
                    "label": 0
                },
                {
                    "sent": "That is gonna be there.",
                    "label": 0
                },
                {
                    "sent": "It's going to be very big, but at least not infinite.",
                    "label": 0
                },
                {
                    "sent": "Yeah, but yeah.",
                    "label": 0
                },
                {
                    "sent": "OK, any other comments?",
                    "label": 0
                },
                {
                    "sent": "Not good.",
                    "label": 1
                },
                {
                    "sent": "OK so so the intuition just finally once more is to sort of find a posterior which sort of doesn't diverge too much from the prior, but is getting this expected value of the classifier classification low?",
                    "label": 0
                },
                {
                    "sent": "That's the aim, and this is the definition of KL divergent, which you probably know, so it's the expectation of a Q.",
                    "label": 0
                },
                {
                    "sent": "Notice the first component is the one that gets the expectation.",
                    "label": 0
                },
                {
                    "sent": "Of dog.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so now I'm.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Gonna attempt to give you a kind of flavor of the proof, so this is where you know.",
                    "label": 0
                },
                {
                    "sent": "Start reading email, not a problem.",
                    "label": 0
                },
                {
                    "sent": "And but I mean, I, I, I think it's it's got an intuitive feel to it, which may be of interest so.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'll give it a try anyway.",
                    "label": 0
                },
                {
                    "sent": "So there are three ingredients that you need to prove in order to get this thing to work.",
                    "label": 0
                },
                {
                    "sent": "And the first is the following, which is looking at the expectation of.",
                    "label": 0
                },
                {
                    "sent": "As you select a function according to the prior of the probability that the new sample gives the same classification error as the previous, as as the probability over a sample that this other sample gives the same classification error, and this is sort of less than or equal to N + 1 over Delta.",
                    "label": 0
                },
                {
                    "sent": "So this is kind of a.",
                    "label": 0
                },
                {
                    "sent": "One of the ingredients that's needed.",
                    "label": 0
                },
                {
                    "sent": "So basically there's going to be a lot of looking at this.",
                    "label": 0
                },
                {
                    "sent": "This probability the probability that are under two independent samples.",
                    "label": 0
                },
                {
                    "sent": "The two empirical errors are the same, so this is sort of like the double sample trick in some sense.",
                    "label": 0
                },
                {
                    "sent": "OK, if you're from.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So with that from so the way this proof works, so this is a proof of this ingredient, or an outline.",
                    "label": 0
                },
                {
                    "sent": "Anyway, is you just look at the expectation under the sample drawn according to sample according to D of one over the probability that under a separate sample they get the same error rate.",
                    "label": 0
                },
                {
                    "sent": "And you just divide this expectation into the possibilities for error rates that you can have for the first sample.",
                    "label": 0
                },
                {
                    "sent": "The sample S. So in other words, there's only M + 1 error rates that you can achieve on M data points 0 up to M, so let's just sum up the probability that we get error rate K and then of course the fact that they're going to be equal is just one over the probability that this is equal to K. Well.",
                    "label": 0
                },
                {
                    "sent": "This is pretty obviously equal to N + 1 OK, so I mean this is just the same thing divided by the same thing, so this is clearly N + 1.",
                    "label": 0
                },
                {
                    "sent": "Now you take expectations with respect to see.",
                    "label": 0
                },
                {
                    "sent": "System, so this is an expectation here with respect to S, But you could take an expectation outside this with respect to C is a constant, so of course we get the same value.",
                    "label": 0
                },
                {
                    "sent": "Swap them around and you get this expression here and now you use Markov's inequality, which says that with probability at least one minus Delta this quantity, which is this expectation here is less than or equal to M + 1 over Delta.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "So that's basically Marco's.",
                    "label": 0
                },
                {
                    "sent": "Inequality's is one of the weaker forms, but it's just bounding the tail ascentia Lee of the distribution, so that's the first ingredient, and really, nothing.",
                    "label": 0
                },
                {
                    "sent": "Very magical, but say it relates to this one over the air.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Error rates being the same, so this is perhaps the most.",
                    "label": 0
                },
                {
                    "sent": "Important ingredient.",
                    "label": 0
                },
                {
                    "sent": "Again, it's quite interesting, I think, but it's gain relating to one over this probability that two samples give the same error rate.",
                    "label": 0
                },
                {
                    "sent": "Here we fixed the sample S. Now the way this works is too.",
                    "label": 0
                },
                {
                    "sent": "I haven't given a more detailed explanation, but.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Essentially what you do is you just write out this probability.",
                    "label": 0
                },
                {
                    "sent": "As you know, some Caples Aventus K probability of being correct essentially.",
                    "label": 0
                },
                {
                    "sent": "And you know, make it equal to exactly C hat S primed this probability here, so you actually exactly equal to see how to ask.",
                    "label": 0
                },
                {
                    "sent": "And then you sort of make the sum.",
                    "label": 0
                },
                {
                    "sent": "You've got a single sort of entry there, but you then make the sum up to that value and it becomes the tail bound on the binomial distribution, and then you use turn offs bound in this scale relative entropy version.",
                    "label": 0
                },
                {
                    "sent": "And you basically it's less than or equal to E to the minus M log.",
                    "label": 0
                },
                {
                    "sent": "Sorry exponential of M times the KL divergent.",
                    "label": 0
                },
                {
                    "sent": "So the log destroys the exponential an, so you've got this EC of Q of this KL divergent of the C hat S and the CD here and then the expectation can be moved through the KL divergent because it's a concave function and so the expectation goes inside and you get the Q hat of S and the QED.",
                    "label": 0
                },
                {
                    "sent": "So it's actually a. I think it's the sort of the core of the proof, in a sense, is this one here.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so then these putting it all together, what you do is you create this this artificial distribution PG by essentially waiting the prior distribution with one over this probability of the things being giving the same error rates.",
                    "label": 0
                },
                {
                    "sent": "This is just a normalization factor to make sure this is still a distribution.",
                    "label": 0
                },
                {
                    "sent": "So the key here is just this quantity here, which is sort of like a reweighting of the prior distribution.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then you observe that the KL divergences between Q and this PG.",
                    "label": 0
                },
                {
                    "sent": "This adapted P is always positive and you can actually unravel this KL divergent.",
                    "label": 0
                },
                {
                    "sent": "So you get the KL divergent with respect to P plus these two extra terms which come.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "From the this and this.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is the first one, and this is the 2nd.",
                    "label": 0
                },
                {
                    "sent": "And then finally.",
                    "label": 0
                },
                {
                    "sent": "You put it all together so the way you do that is you go back to this.",
                    "label": 0
                },
                {
                    "sent": "That one here, I think.",
                    "label": 0
                },
                {
                    "sent": "Let me just see.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sorry yeah that one there, which is which is just this less than or equal to this.",
                    "label": 0
                },
                {
                    "sent": "And then you use the.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This expression here because you now know what this is in terms of or it's greater than or equal to less than or equal to this plus this.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which is this plus this?",
                    "label": 0
                },
                {
                    "sent": "And then you the first thing we did was prove this was less than or equal to N + 1 over Delta.",
                    "label": 0
                },
                {
                    "sent": "And this holds of course with probability 1 minus Delta, because when we made that substitution, this was only a substitution that's only valid with probability 1 minus Delta over our choice of S. OK, so that's basically it.",
                    "label": 0
                },
                {
                    "sent": "I've skipped over details.",
                    "label": 0
                },
                {
                    "sent": "You can close the email now.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK so so but what I wanted to sort of give you there is a flavor of the kind of things that are involved and to really make clear that this is not some hyper mathematics of some complex kind, you know it's something you could follow through the details or be it painfully.",
                    "label": 0
                },
                {
                    "sent": "And I mean I say the most painful bit in there if you really wanted to do every bit will be the turn off and that's that's a bit complicated, but.",
                    "label": 0
                },
                {
                    "sent": "OK, so now I'm going to talk about applications and this one I've already mentioned.",
                    "label": 0
                },
                {
                    "sent": "It's the very sort of simple idea of just having a prior on the functions and you end up with something that's very similar in flavor to the.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Standard bound, the only difference is that there's this extra N + 1 here, which is gives a slight weakening of the bound, but you've got the KL divergent on this side, which is, which is, as I explained, a sort of tighter or a more refined way of comparing 22 error rates here.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so other extensions and applications I'd just like to mention, Matthias Ege has, as I mentioned, right at the beginning.",
                    "label": 0
                },
                {
                    "sent": "You know, applied this to bounding the error for Gaussian process classifiers.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Olivier Catone has extended the result to exchangeable distributions and therefore being able to get a pack based version of the Vapnik churning kiss bands and other things as well.",
                    "label": 1
                },
                {
                    "sent": "But that is quite interesting because he's sort of I mean, for those sort of familiar with that kind of thing where there's a double sample trick, you get to a sort of what you would normally do is sort of symmetry symmetrization staff, and that's replaced by this sort of PAC Bayes approach, so you end up with something that that is sort of a.",
                    "label": 0
                },
                {
                    "sent": "Slightly tighter in the way it deals with the.",
                    "label": 1
                },
                {
                    "sent": "With the error rates again.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Germaine and I'll have extended to more general loss functions than just binary.",
                    "label": 1
                },
                {
                    "sent": "The loss that I've been considering, so this with the.",
                    "label": 0
                },
                {
                    "sent": "Marian Marsh or Anne Francoise Laviolette and another.",
                    "label": 0
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Collaborator and David Mcallister's extended the approach to structured output learning, which is a recent kind of development that's been attracting a lot of interest.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, but what I want to focus on is this linear classic function.",
                    "label": 0
                },
                {
                    "sent": "The application originally due to Langford.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And myself and I want to describe how this application.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is made and then how we can extend it to learning the prior and.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "End up with some results, so this is sort of more like.",
                    "label": 1
                },
                {
                    "sent": "These sort of stages are more like sort of.",
                    "label": 0
                },
                {
                    "sent": "Detail sort of example to just give you a flavor of what can be achieved.",
                    "label": 1
                },
                {
                    "sent": "I mean, one of the things that I think surprising about this theory is the tightness of the bands that you actually get out.",
                    "label": 0
                },
                {
                    "sent": "I mean, when I started doing bounds, you know everyone was happy.",
                    "label": 0
                },
                {
                    "sent": "If you had a band that would.",
                    "label": 0
                },
                {
                    "sent": "You know, be less than one.",
                    "label": 0
                },
                {
                    "sent": "Only if you had, you know.",
                    "label": 0
                },
                {
                    "sent": "10 million data points and you know that the extreme sort of weakness of the bounds that we were able to prove was was was.",
                    "label": 0
                },
                {
                    "sent": "Was accepted as part of life, but here we're actually getting bounds that are non trivial an with with small datasets like these UCI datasets, so it's quite interesting to see what's happening.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, So what do we need to apply to roll out the technology?",
                    "label": 0
                },
                {
                    "sent": "We need to choose the prior and the posterior distributions and they're both going to be Gaussians with unit variance the prime.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Will be centered at the origin.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the the posterior will be centered essentially in the direction of the chosen weight vector.",
                    "label": 1
                },
                {
                    "sent": "So if you're thinking of a support vector machine, this is the weight vector of the support vector machine, but scaled by a factor mu.",
                    "label": 0
                },
                {
                    "sent": "Remember that we can choose any posterior we want, so we can scale to optimize the bound.",
                    "label": 0
                },
                {
                    "sent": "We don't have to worry about, you know somehow overfitting if we.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Do that.",
                    "label": 0
                },
                {
                    "sent": "So here's the prior.",
                    "label": 0
                },
                {
                    "sent": "Centered at the origin.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We find a weight vector by whatever method we might use, so this might be our support vector or some other method, Fisher discriminate or whatever does decide a weight vector.",
                    "label": 0
                },
                {
                    "sent": "Going to choose the posterior.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Direction we're going to choose a length in that.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Direction and then the posterior will be again a Gaussian focused at that at that point.",
                    "label": 0
                },
                {
                    "sent": "So that's the way that the the.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Prior and posterior look.",
                    "label": 0
                },
                {
                    "sent": "So now we plug in to the bound.",
                    "label": 0
                },
                {
                    "sent": "These new particular instantiation's.",
                    "label": 0
                },
                {
                    "sent": "So here.",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Is the.",
                    "label": 0
                },
                {
                    "sent": "The true error according to W an mu.",
                    "label": 0
                },
                {
                    "sent": "So that's the true performance of the stochastic classifier.",
                    "label": 1
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But it's a deterministic classifier that corresponds to doing this thing that I described before, where you take the sign of the expectation, so it's more like the posterior according to the you know the average of the posterior distribution.",
                    "label": 0
                },
                {
                    "sent": "But you take that, so it comes as the center of the Gaussian, and it gives the same classification as the half space with more weight.",
                    "label": 1
                },
                {
                    "sent": "OK, so this is this is a separate thing, so there's two things going on here.",
                    "label": 0
                },
                {
                    "sent": "The second thing I mentioned is related to what I said before.",
                    "label": 0
                },
                {
                    "sent": "This is different.",
                    "label": 0
                },
                {
                    "sent": "This is saying that we can actually replace this expected classifier by the fixed classifier at the center.",
                    "label": 0
                },
                {
                    "sent": "Big cause if you think about the points that are going to correctly classify the points, they're going to be on one side of 1/2 space of a hyperplane.",
                    "label": 0
                },
                {
                    "sent": "And this is going to give the same classification as the center of the Gaussian, because the center of the Gaussian is it spherical, will be on the same side of the hyperspace hyperplane as that which has more weight, right?",
                    "label": 0
                },
                {
                    "sent": "Because it's vertical, take a hyperplane, the center of the Gaussian is on the side with more weight.",
                    "label": 1
                },
                {
                    "sent": "So the center of the Gaussian.",
                    "label": 0
                },
                {
                    "sent": "In other words, your support vector machine will give the same classification as this one.",
                    "label": 0
                },
                {
                    "sent": "Remember, this isn't the thing we're bounding by the.",
                    "label": 0
                },
                {
                    "sent": "PAC bayes",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "From but we do know that it's at most twice the bound that we get from the PAC Bayes theorem.",
                    "label": 0
                },
                {
                    "sent": "So whenever I put a result of a PAC Bayes bound, you have to really multiply by two to get the bound on a fixed support vector machine.",
                    "label": 0
                },
                {
                    "sent": "OK, and that's just that same argument as before that the you know, for any misclassified there must be at least half of the sea according to this Q that.",
                    "label": 1
                },
                {
                    "sent": "Under this expectation.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So I was happy with that.",
                    "label": 0
                }
            ]
        },
        "clip_80": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's the first component.",
                    "label": 0
                },
                {
                    "sent": "The second component is this Q hat of SW mu that's this stochastic error on the training set.",
                    "label": 0
                }
            ]
        },
        "clip_81": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right, and that can be estimated in the following way.",
                    "label": 0
                },
                {
                    "sent": "So it's it's a little bit of a detailed analysis, but not too difficult, but basically it relates to the margin.",
                    "label": 0
                },
                {
                    "sent": "This is the normalized margin of the.",
                    "label": 0
                },
                {
                    "sent": "Of the example for that particular weight vector, so normalized with respect to so you know effectively normalizing the data point if it's, if it's a Gaussian kernel.",
                    "label": 0
                },
                {
                    "sent": "Of course, you don't need to do that.",
                    "label": 0
                },
                {
                    "sent": "Normalization is already normalized.",
                    "label": 0
                },
                {
                    "sent": "You normalize just so it's just the margin and then in order to compute this stochastic error, you have to do the expectation under the training data of the.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Cumulative distribution of the Gaussian of this margin error.",
                    "label": 0
                },
                {
                    "sent": "So what this says, sorry 1 minus that.",
                    "label": 0
                },
                {
                    "sent": "So what?",
                    "label": 0
                },
                {
                    "sent": "It's very much a margin based average, but what it's saying is if there's a large margin.",
                    "label": 0
                },
                {
                    "sent": "On my example, mu of course is the scaling of my weight vector.",
                    "label": 0
                },
                {
                    "sent": "If there's a large margin on my.",
                    "label": 0
                },
                {
                    "sent": "My this is positive.",
                    "label": 0
                },
                {
                    "sent": "This is going to be very small, so I'm going to make a very small contribution to this error.",
                    "label": 0
                },
                {
                    "sent": "If, on the other hand, the margin is small or it's even misclassified, then I'm going to make at least a contribution of 1/2 to this error here.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's that's the way that works out.",
                    "label": 0
                }
            ]
        },
        "clip_82": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So now what is the KL divergent?",
                    "label": 0
                },
                {
                    "sent": "So now we have a prior and posterior that are both Gaussian.",
                    "label": 0
                },
                {
                    "sent": "So it's a very standard to know the KL divergent between two Gaussian distributions.",
                    "label": 0
                },
                {
                    "sent": "In this case, it's particularly easy because they actually have the same covariance structure.",
                    "label": 0
                },
                {
                    "sent": "You can compute the general KL divergent between Gaussians with different covariance structures, But this is a very easy case.",
                    "label": 0
                }
            ]
        },
        "clip_83": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_84": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The.",
                    "label": 0
                }
            ]
        },
        "clip_85": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Result is simply the.",
                    "label": 0
                },
                {
                    "sent": "Square of the distance between the two centers divided by two.",
                    "label": 0
                },
                {
                    "sent": "So in our case mu squared over two.",
                    "label": 0
                },
                {
                    "sent": "I'm assuming the weight vector was normalized so that the new measures the distance from the origin.",
                    "label": 0
                },
                {
                    "sent": "So it's just mu squared over 2.",
                    "label": 0
                },
                {
                    "sent": "So clearly you can see immediately how the trade off is happening with Mew Mew here.",
                    "label": 0
                },
                {
                    "sent": "As it gets larger, will make this bigger but.",
                    "label": 0
                }
            ]
        },
        "clip_86": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the previous slide, we saw mu acting to make this smaller because it expands those.",
                    "label": 0
                },
                {
                    "sent": "Those margins there and therefore reduces the value of this so.",
                    "label": 0
                }
            ]
        },
        "clip_87": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Going to trade off Point which were allowed to.",
                    "label": 0
                }
            ]
        },
        "clip_88": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Flexibly fix.",
                    "label": 0
                },
                {
                    "sent": "So the Delta comes in.",
                    "label": 0
                }
            ]
        },
        "clip_89": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Familiar with that?",
                    "label": 0
                },
                {
                    "sent": "That's just the confidence.",
                    "label": 0
                }
            ]
        },
        "clip_90": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So with probability 1 minus Delta over the.",
                    "label": 0
                }
            ]
        },
        "clip_91": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Training data this holds.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's I give you some some results for that in a minute, but I just wanted to also immediately introduce a second idea, which is to consider learning the prior.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_92": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In our case, the prior was the Gaussian at the origin, but maybe we could do a better prior, because notice that the key thing is the distance between the prime posterior.",
                    "label": 1
                },
                {
                    "sent": "If we could somehow.",
                    "label": 0
                },
                {
                    "sent": "You know, foreshadow the direction that the weight vector was going to move.",
                    "label": 1
                },
                {
                    "sent": "We might get a much tighter bound, and the.",
                    "label": 0
                }
            ]
        },
        "clip_93": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here is that we could learn the prior using the first, maybe part of the data and then learn the you know actually do the the generalization analysis just with the second part of the data.",
                    "label": 1
                },
                {
                    "sent": "So it's not the case that.",
                    "label": 0
                },
                {
                    "sent": "I mean this isn't necessarily going to turn into an algorithm, and actually it will later, but at this point it could just be about getting a better bound.",
                    "label": 0
                },
                {
                    "sent": "We might still end up with the same support vector machine that we use at the end, but we might just have a tighter bound on its performance.",
                    "label": 0
                },
                {
                    "sent": "So the idea is to use part of the data to train.",
                    "label": 1
                },
                {
                    "sent": "A sort of sub support vector machine which gives you a prior and then you use your whole support vector machine is your weight vector and now you can test your workout your bound in terms of the difference between the prior.",
                    "label": 0
                }
            ]
        },
        "clip_94": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Posterior.",
                    "label": 0
                },
                {
                    "sent": "And so you put that into the bound and you.",
                    "label": 0
                }
            ]
        },
        "clip_95": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Compute the stochastic.",
                    "label": 0
                }
            ]
        },
        "clip_96": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Carajas with remaining data.",
                    "label": 0
                },
                {
                    "sent": "So here's the sort of picture again.",
                    "label": 0
                },
                {
                    "sent": "So we have some subset R of our data points.",
                    "label": 0
                },
                {
                    "sent": "We used to get a prior.",
                    "label": 0
                }
            ]
        },
        "clip_97": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We that is now chosen to have prior distribution which is Gaussian at some distance from the origin in that.",
                    "label": 0
                }
            ]
        },
        "clip_98": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Section we then train the full data and get the posterior W. And then we select the.",
                    "label": 0
                },
                {
                    "sent": "Actually this should be a different parameter here, but maybe this is some other scaling factor here and here we have the posterior so.",
                    "label": 0
                }
            ]
        },
        "clip_99": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The idea is that now the distance here is much smaller than it would have been if we had the prior at the origin, so we've gained a lot in that respect.",
                    "label": 0
                },
                {
                    "sent": "But of course we've lost a bit because we're now only able to estimate the error here with part of the remaining data.",
                    "label": 0
                },
                {
                    "sent": "So this term has been reduced, but the denominator is also been reduced because.",
                    "label": 0
                }
            ]
        },
        "clip_100": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We have a smaller number of training points, so here's how the bound looks in this case.",
                    "label": 0
                },
                {
                    "sent": "Again, the.",
                    "label": 0
                }
            ]
        },
        "clip_101": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "QD is the trooper.",
                    "label": 0
                }
            ]
        },
        "clip_102": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Formance of the classifier.",
                    "label": 0
                }
            ]
        },
        "clip_103": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is the expectation with respect to the unused data in the in determining the prior.",
                    "label": 0
                },
                {
                    "sent": "So this is an expectation of M -- R, but that is not a big problem.",
                    "label": 0
                },
                {
                    "sent": "That's just going to be some subsample.",
                    "label": 0
                },
                {
                    "sent": "Maybe a slightly increased variance that.",
                    "label": 0
                }
            ]
        },
        "clip_104": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Might get there.",
                    "label": 0
                },
                {
                    "sent": "Here we've got this factor that's potentially giving us a win that the difference distance here is going to be small.",
                    "label": 0
                }
            ]
        },
        "clip_105": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Ola.",
                    "label": 0
                },
                {
                    "sent": "That's the distance between the prime posterior.",
                    "label": 0
                }
            ]
        },
        "clip_106": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And but this is where we're going to take a hit, because we're only dividing by the number of points not involved in training the prior.",
                    "label": 0
                },
                {
                    "sent": "So notice that this W here the WR is the prior, which is the support vector machine trained on subset of the data.",
                    "label": 0
                },
                {
                    "sent": "This is the posterior trained on all of the training data.",
                    "label": 0
                },
                {
                    "sent": "There's one other hit we've taken which is here in this J because we essentially it considering different weightings here for the for the priors and each prior has to be treated as a separate application of the theorem.",
                    "label": 0
                },
                {
                    "sent": "So the J here correspond to the number of times we chose a different eater.",
                    "label": 0
                },
                {
                    "sent": "But that's that's a relatively benign.",
                    "label": 0
                }
            ]
        },
        "clip_107": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hit.",
                    "label": 0
                }
            ]
        },
        "clip_108": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So we're going to.",
                    "label": 0
                },
                {
                    "sent": "I'll show you in a minute, some comparisons with 10 fold cross Validation PAC, Bayes bound and.",
                    "label": 0
                },
                {
                    "sent": "Pack prior PAC Bayes bound when I'm comparing with cross fold validation and meaning to do model selection, so we'll use the bounds to do model selection and compare with the performance and will also see how tight the biomes are.",
                    "label": 0
                }
            ]
        },
        "clip_109": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On UCI data.",
                    "label": 0
                }
            ]
        },
        "clip_110": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Set.",
                    "label": 0
                },
                {
                    "sent": "And we can use the.",
                    "label": 0
                },
                {
                    "sent": "Bounds or the the?",
                    "label": 0
                },
                {
                    "sent": "Cross validation to select both C and Sigma so the Gaussian kernel width, which is Sigma an the C which is the trade off parameter.",
                    "label": 0
                }
            ]
        },
        "clip_111": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "In 10 fold cross validation we just select the pair that minimizes the validation.",
                    "label": 0
                }
            ]
        },
        "clip_112": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And in the case of the bounds, we select the pair that minimizes the bound.",
                    "label": 1
                },
                {
                    "sent": "So notice that this is a lot less expensive than doing cross validation, so you know we're only having to run the support vector machine once or in this case twice, but on a subset of the data, whereas here you're having to run it 10 times as you go round.",
                    "label": 0
                },
                {
                    "sent": "The circuit.",
                    "label": 0
                }
            ]
        },
        "clip_113": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so this is the results that you get of the actual test error and you can see that 10 fold cross validation is outperforming these methods.",
                    "label": 0
                },
                {
                    "sent": "But the prior backpack Bayes is doing better than the pack SVM.",
                    "label": 0
                },
                {
                    "sent": "And but the differences are not very, very significant.",
                    "label": 0
                },
                {
                    "sent": "So where you know?",
                    "label": 0
                },
                {
                    "sent": "I mean, when you consider these are significantly lower cost to perform.",
                    "label": 0
                },
                {
                    "sent": "I think we could claim that we got a realistic alternative for doing model selection.",
                    "label": 0
                },
                {
                    "sent": "Which you know, for having a theoretical bound that that gives you a model selection is quite an, I think, unusual.",
                    "label": 0
                }
            ]
        },
        "clip_114": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And the tightness of the band.",
                    "label": 1
                },
                {
                    "sent": "So here's the PAC Bayes bound.",
                    "label": 0
                },
                {
                    "sent": "Here's the prior PAC.",
                    "label": 1
                },
                {
                    "sent": "Bayes bound, the prior PAC.",
                    "label": 0
                },
                {
                    "sent": "Bayes bound is a lot tighter.",
                    "label": 0
                },
                {
                    "sent": "And there, you know, really quite reasonable bounds on performance, I mean.",
                    "label": 0
                },
                {
                    "sent": "You know they're actually, you know, quite quite small.",
                    "label": 0
                },
                {
                    "sent": "Even when I mean when you compare.",
                    "label": 0
                }
            ]
        },
        "clip_115": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To the true error.",
                    "label": 0
                },
                {
                    "sent": "So the true error, let's say enring norm is .024.",
                    "label": 0
                }
            ]
        },
        "clip_116": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I.",
                    "label": 0
                },
                {
                    "sent": "And here it's .093, so it's maybe a factor of 3 1/2.",
                    "label": 0
                },
                {
                    "sent": "You know it's it's not too bad.",
                    "label": 0
                }
            ]
        },
        "clip_117": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Certainly nontrivial, so now I think I've got time to just introduce the two additional ideas that have been developed from this approach, which is OK if you've got a new bound, why don't you try and optimize it so you could this lead to a sort of prior SVM which basically rather than choose W to be the normal SVM on the whole training data, you just train the SVM to optimize this bound relative to the prior.",
                    "label": 0
                },
                {
                    "sent": "That you trained on part of that.",
                    "label": 0
                }
            ]
        },
        "clip_118": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Training data.",
                    "label": 0
                },
                {
                    "sent": "So the.",
                    "label": 0
                }
            ]
        },
        "clip_119": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The optimization that you get is basically this.",
                    "label": 0
                },
                {
                    "sent": "You trying to minimize this difference which correspond to the KL divergent's subject to getting good classification on the remaining data points.",
                    "label": 0
                },
                {
                    "sent": "So these N minus are points not involved in the training of this prior distribution.",
                    "label": 0
                }
            ]
        },
        "clip_120": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this PS VM is only solved with.",
                    "label": 0
                }
            ]
        },
        "clip_121": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Winning points.",
                    "label": 0
                },
                {
                    "sent": "I.",
                    "label": 0
                },
                {
                    "sent": "And you can translate this into abound, of course, so you can determine the.",
                    "label": 0
                }
            ]
        },
        "clip_122": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Prior with that subset, you solve the P SVM and attain.",
                    "label": 0
                }
            ]
        },
        "clip_123": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "W you then get the margins on the M -- R points.",
                    "label": 0
                }
            ]
        },
        "clip_124": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And you do a linear search for the optimal value of mu, plug it in an.",
                    "label": 0
                }
            ]
        },
        "clip_125": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Bound.",
                    "label": 0
                },
                {
                    "sent": "So the there's one further extension, so that's that's again taking a finite set of possible choices for the I should have mentioned that.",
                    "label": 0
                }
            ]
        },
        "clip_126": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In this case here WR, you really need to consider rescaling, so you have to consider a finite set of scalings, and you pay a price for that.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_127": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the slide adaptation is to consider the prior distribution, P being elongated in the direction of WR.",
                    "label": 0
                },
                {
                    "sent": "So you actually sort of don't pay for using that direction as much.",
                    "label": 0
                }
            ]
        },
        "clip_128": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And that correspond.",
                    "label": 0
                }
            ]
        },
        "clip_129": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then to using an optimization where you optimize this property, this vector V.",
                    "label": 0
                }
            ]
        },
        "clip_130": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Where your classification is actually being made by V plus some multiple of the prior weight vector, and you can adapt that Eater freely to get the best performance that you like.",
                    "label": 0
                },
                {
                    "sent": "So this is now a sort of optimization that ignores essentially the prior direction in costing terms.",
                    "label": 0
                }
            ]
        },
        "clip_131": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_132": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can again.",
                    "label": 0
                }
            ]
        },
        "clip_133": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In use, the PAC Bayes theorem with a novelty that the prior has this elongation in the direction of WR.",
                    "label": 1
                },
                {
                    "sent": "So it's a sort of spherical in every other direction.",
                    "label": 0
                },
                {
                    "sent": "It's like a rugby ball.",
                    "label": 0
                },
                {
                    "sent": "Sorry, should have mentioned we should write.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's it has that elongation and if you compute the posterior now between the spherical the posterior spherical at a distance mu but the KL divergent between these two comes out to an expression like this, where this is the perpendicular direction.",
                    "label": 0
                },
                {
                    "sent": "So that's just what you would expect if you.",
                    "label": 0
                },
                {
                    "sent": "Project the new weight vector into the space perpendicular to the prior but in the direction of the prior.",
                    "label": 0
                },
                {
                    "sent": "You have a slightly more complicated expression involving the variance of this rugby ball, and so if you let the variance grow you essentially reduce the cost of this parallel direction at the expense of a slight increase in this log of Tau squared here, but offset by a possible slight reduction here.",
                    "label": 0
                },
                {
                    "sent": "So there's actually a very benign cost in.",
                    "label": 0
                },
                {
                    "sent": "Making tower reasonably large and effectively, you know, making this this cost of the direction of the prior much much less.",
                    "label": 0
                },
                {
                    "sent": "So if we.",
                    "label": 0
                }
            ]
        },
        "clip_134": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We now use that, then model selection again.",
                    "label": 0
                },
                {
                    "sent": "It doesn't actually improve the model selection very much.",
                    "label": 0
                },
                {
                    "sent": "I mean, in fact, it's slightly worse than the prior SVM in this case.",
                    "label": 0
                },
                {
                    "sent": "Sorry, the prior SVM does very well.",
                    "label": 0
                },
                {
                    "sent": "Sorry, but the Eater prior doesn't do so well.",
                    "label": 0
                },
                {
                    "sent": "The true remember, cross validation was .070.",
                    "label": 0
                },
                {
                    "sent": "So this is, you know, virtually indistinguishable from cross validation using this prior SVM.",
                    "label": 0
                },
                {
                    "sent": "The Eater prior doesn't do quite so well, but I mean it's it's as good as but the.",
                    "label": 0
                }
            ]
        },
        "clip_135": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Bounds on the error for the Eater prior are very tight and we get even a significant reduction in those bounds, so we.",
                    "label": 0
                },
                {
                    "sent": "Well, I'm sort of moving to is a sort of technology that can say look.",
                    "label": 0
                },
                {
                    "sent": "I can roll out a reasonably accurate model selection strategy and give you a bound on the performance that is within a factor of about three to four of the true performance, and these are reasonably reliable indicator of the sort of scale of the true performance using these bounds.",
                    "label": 0
                },
                {
                    "sent": "Sorry, yeah, Tom.",
                    "label": 0
                },
                {
                    "sent": "Yes, that is true.",
                    "label": 0
                },
                {
                    "sent": "That is absolutely true, but.",
                    "label": 0
                }
            ]
        },
        "clip_136": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "My argument is that it's actually quite a benign parameter in the sense that you know setting it quite large will only pay you.",
                    "label": 0
                },
                {
                    "sent": "You only pay a small price here it's log of T style squared, but you're saving yourself a factor of Tau squared in this in this direction.",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "I don't know how many points you allocated, Royal selection and how many people is there.",
                    "label": 0
                },
                {
                    "sent": "Yeah, it's a good question experimentally we've arrived at about 50% is about the right number.",
                    "label": 0
                },
                {
                    "sent": "I mean, it's not that again sensitive in the experiments we've done, but it's another parameter that you could chew.",
                    "label": 0
                },
                {
                    "sent": "But yeah, you need.",
                    "label": 0
                },
                {
                    "sent": "The problem is, the more things you very them.",
                    "label": 0
                },
                {
                    "sent": "You can use the bounds, but it's more expensive.",
                    "label": 0
                },
                {
                    "sent": "You have to run the algorithms often and you pay a bit of a price in multiple hypothesis testing effectively.",
                    "label": 0
                },
                {
                    "sent": "Which situations would you allocate?",
                    "label": 0
                },
                {
                    "sent": "No, I say now in our experiments we were finding you know, between 30 and 50%.",
                    "label": 0
                },
                {
                    "sent": "Ticking.",
                    "label": 0
                },
                {
                    "sent": "It could be based on the band, but the problem with.",
                    "label": 0
                },
                {
                    "sent": "Absolutely, you could do that.",
                    "label": 0
                },
                {
                    "sent": "The problem with that is that you're paying you having to run the support vector machine lots of times for these different values of R. So you're sort of undermining your argument that the saving is in terms of, you know, and you're losing a bit on the bound as well, because you've got to do an extra cost in here.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I think that's that's I think I said everything there any any questions?",
                    "label": 0
                }
            ]
        },
        "clip_137": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So final concluding remarks, just hopefully I've given you a feeling for their different approaches.",
                    "label": 1
                },
                {
                    "sent": "The frequentist and Bayesian.",
                    "label": 0
                },
                {
                    "sent": "They're both aiming at sort of analyzing the performance of learning systems and through some crosstalk between them.",
                    "label": 1
                },
                {
                    "sent": "This PAC Bayes idea arose, and Interestingly it seems to have look, you know, developed into quite an interesting approach to understand.",
                    "label": 0
                }
            ]
        },
        "clip_138": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Learning systems that somehow combines the intuitions of Bayes with the.",
                    "label": 0
                },
                {
                    "sent": "So analysis of pack.",
                    "label": 0
                },
                {
                    "sent": "So I've tried to give you a reasonably detailed look inside the ingredients of the theory, hopefully not.",
                    "label": 1
                },
                {
                    "sent": "2.",
                    "label": 0
                }
            ]
        },
        "clip_139": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Too boring and I've showed you how to the app.",
                    "label": 0
                }
            ]
        },
        "clip_140": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Patient was VMS works.",
                    "label": 0
                },
                {
                    "sent": "I've investigated learning the prior as a sort of again.",
                    "label": 0
                },
                {
                    "sent": "I mean that's a detail in a way, but I kind of like it because I think it shows you.",
                    "label": 0
                },
                {
                    "sent": "How one can sort of use these theoretical insights to hopefully derive new algorithms?",
                    "label": 0
                },
                {
                    "sent": "And maybe you can do something completely different with these theory to motivate different approaches to?",
                    "label": 0
                }
            ]
        },
        "clip_141": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Ning.",
                    "label": 0
                },
                {
                    "sent": "Certainly we seem to get tighter bounds, not always.",
                    "label": 0
                }
            ]
        },
        "clip_142": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Much better.",
                    "label": 0
                },
                {
                    "sent": "Model selection, but but somewhat better.",
                    "label": 0
                },
                {
                    "sent": "The prior SVM seems to be giving a reasonably reliable, low-cost model selection.",
                    "label": 0
                }
            ]
        },
        "clip_143": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And particularly these ones that directly optimize the newbound seem to give very tight bounds at least and reasonably good model selection as well, so.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Which is basically exactly.",
                    "label": 0
                },
                {
                    "sent": "I don't think the question of choosing account and we want to allocate some training data to promote a selection of choosing it requires calendar.",
                    "label": 0
                },
                {
                    "sent": "So can you say anything about all those?",
                    "label": 0
                },
                {
                    "sent": "Hi, I'm sorry.",
                    "label": 0
                },
                {
                    "sent": "Well I mean in a way the the model selection there was choosing the Colonel in the sense of choosing the kernel width so.",
                    "label": 0
                },
                {
                    "sent": "So only the kernel with yeah, OK, so of course if you're choosing, but it was choosing the kernel with over a finite set of it wasn't choosing the kernel with over, you know as a real value, or choosing a different family of kernels, which is what you're asking, yeah?",
                    "label": 0
                },
                {
                    "sent": "Yeah, I mean, I think the you know the key ingredient of what the PAC Bayes approach does is it it gets away from treating things as independent.",
                    "label": 0
                },
                {
                    "sent": "It sort of takes into account the dependencies between the classifiers and that's why it does so so well.",
                    "label": 0
                },
                {
                    "sent": "I mean even that rugby ball example did better than just taking a finite set of, you know the bound was a lot tighter because it was taking into account the sort of links.",
                    "label": 0
                },
                {
                    "sent": "So I think to really get a good roll out to the.",
                    "label": 0
                },
                {
                    "sent": "Learning the kernel, you certainly don't want to do model selection in the way that I've done it, which is just pick a finite set you want to somehow get.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                },
                {
                    "sent": "Set of functions represented in such a way that you can take into account the.",
                    "label": 0
                },
                {
                    "sent": "The correlations between the functions from different kernels, so you know close sigmas should have very similar functions, say in a Gaussian context.",
                    "label": 0
                },
                {
                    "sent": "So you don't want to treat those as somehow independent, but how to do that?",
                    "label": 0
                },
                {
                    "sent": "I don't think people have made that step.",
                    "label": 0
                },
                {
                    "sent": "I think that's a good good research direction now.",
                    "label": 0
                },
                {
                    "sent": "Is there?",
                    "label": 0
                },
                {
                    "sent": "How other performance?",
                    "label": 0
                },
                {
                    "sent": "This model selection approach is affected by different currents.",
                    "label": 0
                },
                {
                    "sent": "I mean.",
                    "label": 0
                },
                {
                    "sent": "So yeah, you have compared this back based approach for model selection and classical consolidation and But my question is.",
                    "label": 0
                },
                {
                    "sent": "The experimental data you show us first, maybe from 2 areas Carol, yes.",
                    "label": 0
                },
                {
                    "sent": "That's a good question.",
                    "label": 0
                },
                {
                    "sent": "Now we haven't tried that.",
                    "label": 0
                },
                {
                    "sent": "I mean, I think this is very preliminary.",
                    "label": 0
                },
                {
                    "sent": "Kind of first step, just sort of putting down a marker that it does seem possible, but I think you know these are very much sort of questions that you might say choosing the degree of the polynomial.",
                    "label": 0
                },
                {
                    "sent": "Is that what you were thinking?",
                    "label": 0
                },
                {
                    "sent": "Yeah, let's say you want to use kernel.",
                    "label": 0
                },
                {
                    "sent": "How does this performance Pentecost validation?",
                    "label": 0
                },
                {
                    "sent": "So here is not so so much influence.",
                    "label": 0
                },
                {
                    "sent": "Baby things are getting better so you just use an average kernel and do you still have good performance?",
                    "label": 0
                },
                {
                    "sent": "It would fit to cross validation.",
                    "label": 0
                },
                {
                    "sent": "Or yeah that's good question.",
                    "label": 0
                },
                {
                    "sent": "I don't know this answer, yeah?",
                    "label": 0
                },
                {
                    "sent": "So many students here maybe next year we're gonna have some results.",
                    "label": 0
                },
                {
                    "sent": "Then there is only stable and see that the proposed new bonds are better, more targeted than the classical one, but the performers are not not not not that different.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I agree.",
                    "label": 0
                },
                {
                    "sent": "So this idea?",
                    "label": 0
                },
                {
                    "sent": "OK, you can imagine that class 'cause we have compared former good model selection also with not good bands.",
                    "label": 0
                },
                {
                    "sent": "Yeah, but I my experience with trying to use sort of the classical bounds for model selection is that they don't work very well.",
                    "label": 0
                },
                {
                    "sent": "I mean, I think people have tried that I we certainly tried on one occasion and it doesn't seem to be reliable tool and this is the first time I've sort of seen a theoretical band giving reasonable model selection results.",
                    "label": 0
                },
                {
                    "sent": "So I but I agree with you.",
                    "label": 0
                },
                {
                    "sent": "I mean, you know you're absolutely right to say, you know, I mean, the hope is the tighter the bound gets, the less room it has to fool you.",
                    "label": 0
                },
                {
                    "sent": "In some sense, you know that it can't mislead you by that much, whereas if it's a very weak bound you know might look good on this data set.",
                    "label": 0
                },
                {
                    "sent": "But it's actually much worse than on this data set where it looks bad in terms of demand.",
                    "label": 0
                },
                {
                    "sent": "So it's it's it's, you know, giving it less room to fool you, but it still can fool you for sure.",
                    "label": 0
                },
                {
                    "sent": "You know an you might be lucky and get very good results with some more classical technique.",
                    "label": 0
                },
                {
                    "sent": "I agree.",
                    "label": 0
                },
                {
                    "sent": "Now thanks.",
                    "label": 0
                },
                {
                    "sent": "Well.",
                    "label": 0
                },
                {
                    "sent": "Minute conversation could be OK. OK.",
                    "label": 0
                }
            ]
        }
    }
}