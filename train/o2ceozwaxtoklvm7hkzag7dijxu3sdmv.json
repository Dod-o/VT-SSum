{
    "id": "o2ceozwaxtoklvm7hkzag7dijxu3sdmv",
    "title": "Semantic Matching using the UMLS",
    "info": {
        "author": [
            "Jetendr Shamdasani, University of the West of England"
        ],
        "published": "July 28, 2009",
        "recorded": "June 2009",
        "category": [
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/eswc09_shamdasanis_smutu/",
    "segmentation": [
        [
            "And from the University of the West of England, and I'm going to be discussing semantic matching using the UML S."
        ],
        [
            "This is the outline of my talk.",
            "I'm going to explain the medical domain 1st and the problems with it.",
            "After that I'm going to go over a semantic matching and a few definitions.",
            "Then I'm going to discuss the Umm, less BS match algorithm and the modifications that we've done and then some results at the end."
        ],
        [
            "Right in our case, the medical domain actually has a very very specialized terminology.",
            "Heterogeneity occurs everywhere, both determined logical level and a conceptual level.",
            "There are lots of ontologies available today.",
            "These are all in use.",
            "Currently integration is required, obviously for interoperability and data sharing.",
            "Semantic matching allows us to discover more fine grained relationships, but."
        ],
        [
            "And concepts into ontologies.",
            "Now in our case we are not matching ontologies as such.",
            "We are actually matching 2 trees of strings.",
            "We're focused on the anchoring process to a background resource.",
            "We use a background resource to help us define context for the matching process.",
            "Our definition of semantic matching, that is, the discovery of set theoretic relationships between concepts in two or more intelligece.",
            "We don't just look for equivalence, were able to discover subsumption as well.",
            "And also in our case, matching matching does not actually return a similarity measure."
        ],
        [
            "Right our method.",
            "We have extended the original S match algorithm, which was done at the University of Trento.",
            "In the original last match algorithm, used Wordnet as background resource, whereas in our case we needed something that was a bit more domain specific.",
            "So we use the young LS."
        ],
        [
            "A little bit of a story.",
            "In our project we have several different hospitals issue.",
            "These are focus on the same very rare diseases.",
            "Since these diseases are rare, the datasets are very small.",
            "We need to integrate this data and and all these datasets are also described by their own."
        ],
        [
            "Ontology.",
            "OK, now I'm going to go over some examples showing you what semantic matching actually is.",
            "In this case we have two concepts from 2 ontologies, so we have a concept of examination and we have another concept of kidney examination, so they expect."
        ],
        [
            "Result is.",
            "That examination would be a superclass of kidney examination.",
            "We"
        ],
        [
            "Is correct, so the reason for this is the S match algorithm actually gets gets the label of the node and and it uses logical operators to give it context, and so the meaning of the concept kidney examination is kidney intersected with examination, whereas the semantics of the concept examination."
        ],
        [
            "Is just examination and visually you can see that the subset relationship is there."
        ],
        [
            "But these are some examples with some structure, so over here once more we have a concept called examination and we want to match this to midbrain.",
            "The Expo."
        ],
        [
            "Active result is that examination is a superclass of midbrain, so and the reason for this is that midbrain has actually been.",
            "That the concept of midbrain has actually been constrained by its parents the way we do this is that we take an intersection of midbrain brain."
        ],
        [
            "Another topic for examination, hence giving it structure the meaning of the concept midbrain in our case is actually the shaded area in this diagram."
        ],
        [
            "Right, I'm going to talk a little bit about answering her background resource.",
            "As I mentioned previously, as much is very reliant on word net.",
            "We use the well chosen your molester, replace word net.",
            "This is probably due to the fact that there is no medical word net available as of today.",
            "We evaluated different forms of background knowledge and in our case we found the young molested the best fit for our domain.",
            "This is because the human less has a good coverage of medical term and it's broad enough for the matching."
        ],
        [
            "Process.",
            "Right now I'm going to talk about the Umm, less for a bit.",
            "The Molasses Medical Thesaurus, which integrates biomedical knowledge from varying vocabularies, it can be considered to be a methodology of biomedical knowledge.",
            "The 2008 version has a total of 140 source vocabularies in there, with over a million concepts an over and over 7 million number of atoms in it.",
            "So it's absolutely huge."
        ],
        [
            "OK, this is the way that the humanness is organized.",
            "So atoms are taken directly from the source vocabularies themselves, and they are all mapped onto concepts.",
            "There are lexical groupings as well, and there are term groupings too.",
            "But we are in our case, we don't actually need this."
        ],
        [
            "Alright.",
            "So the relationships within the year molester actually represented as a graph between.",
            "There's a graph of concepts, and there's a graph of atoms.",
            "And in the year molest the relationships between concepts broader than narrower than parent, child, and sibling.",
            "Whereas the relationships between atoms in the URL's are taken from the source vocabularies.",
            "For example, part of Oryza."
        ],
        [
            "The we have kept the same four step process as the original Smash algorithm.",
            "So the four steps are string to formula conversion where the label of a node is actually converted to a logical formula.",
            "Context creation and filtering where we where we end up taking the structure into account, defining context and we also filter and drop irrelevant concepts and we also match atomic form atomic formulas using the M LS.",
            "The originally in Word net, the mats in sets.",
            "In our case we match concepts using the Umm as hierarchies and the final step is the reasoning step to actually do semantic match between."
        ],
        [
            "Concepts.",
            "OK, this is the example that I'm going to be going through.",
            "I'll come back to it."
        ],
        [
            "OK, so in the first step now and that's the string to formula conversion.",
            "As I mentioned previously, the purpose of this step is to convert the label of the node into a logical formula using logical connectives.",
            "So individually we take we first organized and we take a single token as an atomic formula with the concepts behind it.",
            "For example, if we create the UML S for the string height, we got the following concept returned.",
            "We get hard malignant neoplasm, Part B, 9 year lesson with heart, heart problem, entire heart.",
            "We currently do not know which is the concept that we want, and we only know this when we actually define concept context in this."
        ],
        [
            "I can start.",
            "So especially previously this works in the label Evernote, so if we take a note labeled heart and kidney diseases, we create the UML S4 heart, which is now an atomic formula after tokenizing of course, and that has five concepts attached, we query kidney and that is 1 concept attached.",
            "We query disease and that in itself and that has five concepts attached from the Yuma less the final formula there with all the logical connectives captures the meaning of the node height and kidney diseases in our."
        ],
        [
            "Case.",
            "Right, we're onto the second step now, which is context creation and filtering.",
            "The purpose of the step is to define the context for a node.",
            "As I mentioned previously.",
            "Using the formulas from the previous step and over all of his parents, this constrains the meaning of the node and the concepts in the URL S are still attached to atomic formula.",
            "We also filter at the structural level as with the original estimate algorithm algorithm."
        ],
        [
            "Any different though.",
            "OK, so in this case the way that we create context, for example, if we look at the node hypertrophic cardiomyopathy, so that was the formula for that node, and then from there it's parent's height and kidney diseases, which was a bit more complicated, and these all actually have the concepts attached ill, and this parent was diseased.",
            "This is the formula that we reason with at the end."
        ],
        [
            "I will get to it.",
            "OK, we also perform filtering of concepts using the M LS within the human S. We have 3 features available is available to us for the.",
            "For the disambiguation, these are the concept relationships at in relationships and the Co occurrence relationships from text.",
            "We use all this information for filtering purposes.",
            "However, we only use one feature for disambiguation at the time I we only use the concept relationships or we only use the Atom relationships, or we only use the Co occurrence relationships?"
        ],
        [
            "Yeah, I went to the third step now, which is atomic formula matching using the M LS.",
            "The purpose of this we use either the concept of the Atom hierarchies in the UM LS to actually match atomic formula to give us the background theory to actually reason with at the end."
        ],
        [
            "OK, for the items are for the rules for the atoms are if a concept from a contains the concept from be it, where ANB are both atomic formulas, then we actually return the equivalence relationship.",
            "If an Atom that belongs to a concept in a is a subclass of a concept of an Atom.",
            "An Atom from a concept and be fit in a single source vocabulary.",
            "Then we then we return a substantial relationship.",
            "If if an Atom from a concept in a is a superclass of anathema concept in a single source library, then we actually return a superclass relationship."
        ],
        [
            "For concepts are rules.",
            "I if a concept from from a can contains a concept from B, then we return in the Caribbean's relationship.",
            "If a concept from A is a subclass of a concept from BI, it is.",
            "It is either an arrow then or a child.",
            "Then we return to subclass relationship.",
            "If a concept from A is a superclass of a concept from BIE it is apparent or it is a broader than then we return a superclass."
        ],
        [
            "Relationship.",
            "OK, now I'm now I'm going to talk about the final info step, which is the reasoning with all the information that we that I presented previously.",
            "So the purpose of this step is to actually reduce the relationship between the two concepts between two ontologies that."
        ],
        [
            "Join a match.",
            "We've kept the same propositional reasoning approach as the original Smash algorithm.",
            "In this case, the axioms are the background theory, which is information from the, UM, LS rallies, the relationship that we're trying to prove, and the context where the node formulas which I showed previously and.",
            "We also end up mapping like the idea like connectives.",
            "I showed you onto the property onto the propositional equivalence.",
            "So in our case assumption is covered is converted.",
            "Implication is the same the other way, and to prove equivalence we approve both subsumption and the superclass relationship as well."
        ],
        [
            "OK, alright so in this case I'm going to go through an example quickly so if we matched the nodes Harden kidney diseases from 3 one and we matched an old myocardial infraction from 3 two.",
            "Which one approval superclass relation?"
        ],
        [
            "Yep.",
            "So the axioms from this matching task.",
            "This is information that we actually discovered from the armilus, so we found that disease was equivalent to disorder.",
            "Heart is equivalent to cardiac, and myocardial infraction was a subclass of disease.",
            "Now now when we reason over this, as you can see, we have the axioms here and we actually have the tree context here as well.",
            "This formula is unsatisfiable using equation using the equation showed you previously previously.",
            "Hence this relationship holds.",
            "So that means that I'm hurting.",
            "Kidney disease is a superclass of myocardial infraction."
        ],
        [
            "Right, I'm going to talk about the implementation for a bit.",
            "This implemented.",
            "We've implemented this completely 100% from scratch.",
            "It was developed within the framework of the Healthy, Healthy Child Project and we are currently preparing the implementation for an open source release."
        ],
        [
            "Right I experimental setup, we match subsets of the FMA, two subsets of to a subset of meshes.",
            "Well, the FMA is is an ontology about anatomy, whereas mesh.",
            "I'm sure there must surely familiar with our trees are rooted at the concept of brain.",
            "In both the ontologies to attract to extract a tree from the FMA, we followed the original part of relationship down to its leaf nodes.",
            "So we started their brain and went all the way down and this has a total of 476 concepts.",
            "The extracted tree from mesh which reversed the tree down to its leaf.",
            "Note this has a total of 181 concepts.",
            "We use the standard metrics position and recall in our work and our gold standard was created with the aid of a domain expert.",
            "It's a very, very small gold standard and we selected 20 random concepts from FMA subset and 40 random concept from Ed subset.",
            "We use the 2008 version of the M, LS and all other experiments."
        ],
        [
            "What?",
            "Right, just to give you an example on the left on the left hand side we have a tree.",
            "We have a screenshot of the tree from the FMA and on the right hand side we have a screenshot of the tree from mesh."
        ],
        [
            "And alright results.",
            "We actually run different versions of algorithm on.",
            "Like for like for the matching process.",
            "For example, we only use the concept hierarchies for the matching with no filtering or we use the Atom hierarchies with concept filtering or cones filtering.",
            "So every permutation we ran them all together.",
            "I will results really went as weren't really what we expected, and the reason for this is because our gold standard is very very small, so this is future work and it's actually on going right now."
        ],
        [
            "OK, alright I'm concluding now.",
            "So we have shown a means of adapting semantic matching to the medical domain using the human less as a background resource.",
            "We have shown how different features of the human less concepts, atoms occurrences can be used for disambiguation.",
            "The filtering we found was actually only useful in cases where two ontologies have a similar set of terms, but their Contacts are highly dissimilar.",
            "OK."
        ],
        [
            "So future work we need to conduct a more thorough, thorough evaluation of our method, and this is very difficult since there actually is not a medical goals and are available today, which actually has semantic matches in there.",
            "We will also submit our results to this years away.",
            "A competition for evaluation in the medical track.",
            "We will also investigate how to adapt different background resources from different domains for the semantic matching process."
        ],
        [
            "OK. Quick.",
            "Questions.",
            "OK so I have person announcement in detail.",
            "Will be OAI 2009 this year.",
            "So that's the first news.",
            "Interesting everyone I hope and the second news interesting more specially you is that there would be an organization of a special benchmark for.",
            "Alignments with ordered relation not only equivalent.",
            "So since your system medical track no, it's not the medical track as far as I know.",
            "OK too bad.",
            "So.",
            "Still no question.",
            "Actually Christian, last year when he showed the results for the anatomy track, he told us that.",
            "Of the systems actually not, there were none of the systems found.",
            "About 25% of the non trivial.",
            "Mappings.",
            "And even the system that used background knowledge, which in this case always was Jorma, less they actually missed quite a bit as well, really, which means that you are Melissa is not complete.",
            "Is that going to be a problem for your real systems?",
            "Well, in our case, I mean, as long as we have some information extracted from the URL S, then we're actually able to do some match in most cases.",
            "So I mean, for example, with the reasoning process for.",
            "If this transitive reasoning, we can pull it off so.",
            "So it is possible as long as we have some information there.",
            "Hello question.",
            "Tier one you use.",
            "I assume you such that 4G yes OK and so you have queries with very very huge background.",
            "If you put all your Mail is there.",
            "Is there some specific problem with that?",
            "It's very, very slow.",
            "It's I mean this whole thing.",
            "I mean to match like this upsets over here, it's over night so that's only like 400 to like 180.",
            "It's it's a very very slow process and that's unlike when we've got a beast of a machine as well.",
            "So.",
            "So everybody is hungry, so we will.",
            "We thank all the presenters for this nice presentation, but the lunch is not open yet."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And from the University of the West of England, and I'm going to be discussing semantic matching using the UML S.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is the outline of my talk.",
                    "label": 0
                },
                {
                    "sent": "I'm going to explain the medical domain 1st and the problems with it.",
                    "label": 1
                },
                {
                    "sent": "After that I'm going to go over a semantic matching and a few definitions.",
                    "label": 0
                },
                {
                    "sent": "Then I'm going to discuss the Umm, less BS match algorithm and the modifications that we've done and then some results at the end.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right in our case, the medical domain actually has a very very specialized terminology.",
                    "label": 0
                },
                {
                    "sent": "Heterogeneity occurs everywhere, both determined logical level and a conceptual level.",
                    "label": 0
                },
                {
                    "sent": "There are lots of ontologies available today.",
                    "label": 0
                },
                {
                    "sent": "These are all in use.",
                    "label": 0
                },
                {
                    "sent": "Currently integration is required, obviously for interoperability and data sharing.",
                    "label": 1
                },
                {
                    "sent": "Semantic matching allows us to discover more fine grained relationships, but.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And concepts into ontologies.",
                    "label": 0
                },
                {
                    "sent": "Now in our case we are not matching ontologies as such.",
                    "label": 0
                },
                {
                    "sent": "We are actually matching 2 trees of strings.",
                    "label": 1
                },
                {
                    "sent": "We're focused on the anchoring process to a background resource.",
                    "label": 1
                },
                {
                    "sent": "We use a background resource to help us define context for the matching process.",
                    "label": 1
                },
                {
                    "sent": "Our definition of semantic matching, that is, the discovery of set theoretic relationships between concepts in two or more intelligece.",
                    "label": 1
                },
                {
                    "sent": "We don't just look for equivalence, were able to discover subsumption as well.",
                    "label": 0
                },
                {
                    "sent": "And also in our case, matching matching does not actually return a similarity measure.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right our method.",
                    "label": 0
                },
                {
                    "sent": "We have extended the original S match algorithm, which was done at the University of Trento.",
                    "label": 1
                },
                {
                    "sent": "In the original last match algorithm, used Wordnet as background resource, whereas in our case we needed something that was a bit more domain specific.",
                    "label": 0
                },
                {
                    "sent": "So we use the young LS.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A little bit of a story.",
                    "label": 0
                },
                {
                    "sent": "In our project we have several different hospitals issue.",
                    "label": 1
                },
                {
                    "sent": "These are focus on the same very rare diseases.",
                    "label": 0
                },
                {
                    "sent": "Since these diseases are rare, the datasets are very small.",
                    "label": 0
                },
                {
                    "sent": "We need to integrate this data and and all these datasets are also described by their own.",
                    "label": 1
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Ontology.",
                    "label": 0
                },
                {
                    "sent": "OK, now I'm going to go over some examples showing you what semantic matching actually is.",
                    "label": 0
                },
                {
                    "sent": "In this case we have two concepts from 2 ontologies, so we have a concept of examination and we have another concept of kidney examination, so they expect.",
                    "label": 1
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Result is.",
                    "label": 0
                },
                {
                    "sent": "That examination would be a superclass of kidney examination.",
                    "label": 1
                },
                {
                    "sent": "We",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is correct, so the reason for this is the S match algorithm actually gets gets the label of the node and and it uses logical operators to give it context, and so the meaning of the concept kidney examination is kidney intersected with examination, whereas the semantics of the concept examination.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is just examination and visually you can see that the subset relationship is there.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But these are some examples with some structure, so over here once more we have a concept called examination and we want to match this to midbrain.",
                    "label": 0
                },
                {
                    "sent": "The Expo.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Active result is that examination is a superclass of midbrain, so and the reason for this is that midbrain has actually been.",
                    "label": 0
                },
                {
                    "sent": "That the concept of midbrain has actually been constrained by its parents the way we do this is that we take an intersection of midbrain brain.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Another topic for examination, hence giving it structure the meaning of the concept midbrain in our case is actually the shaded area in this diagram.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right, I'm going to talk a little bit about answering her background resource.",
                    "label": 0
                },
                {
                    "sent": "As I mentioned previously, as much is very reliant on word net.",
                    "label": 0
                },
                {
                    "sent": "We use the well chosen your molester, replace word net.",
                    "label": 0
                },
                {
                    "sent": "This is probably due to the fact that there is no medical word net available as of today.",
                    "label": 1
                },
                {
                    "sent": "We evaluated different forms of background knowledge and in our case we found the young molested the best fit for our domain.",
                    "label": 1
                },
                {
                    "sent": "This is because the human less has a good coverage of medical term and it's broad enough for the matching.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Process.",
                    "label": 0
                },
                {
                    "sent": "Right now I'm going to talk about the Umm, less for a bit.",
                    "label": 0
                },
                {
                    "sent": "The Molasses Medical Thesaurus, which integrates biomedical knowledge from varying vocabularies, it can be considered to be a methodology of biomedical knowledge.",
                    "label": 1
                },
                {
                    "sent": "The 2008 version has a total of 140 source vocabularies in there, with over a million concepts an over and over 7 million number of atoms in it.",
                    "label": 0
                },
                {
                    "sent": "So it's absolutely huge.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, this is the way that the humanness is organized.",
                    "label": 0
                },
                {
                    "sent": "So atoms are taken directly from the source vocabularies themselves, and they are all mapped onto concepts.",
                    "label": 1
                },
                {
                    "sent": "There are lexical groupings as well, and there are term groupings too.",
                    "label": 0
                },
                {
                    "sent": "But we are in our case, we don't actually need this.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright.",
                    "label": 0
                },
                {
                    "sent": "So the relationships within the year molester actually represented as a graph between.",
                    "label": 1
                },
                {
                    "sent": "There's a graph of concepts, and there's a graph of atoms.",
                    "label": 1
                },
                {
                    "sent": "And in the year molest the relationships between concepts broader than narrower than parent, child, and sibling.",
                    "label": 0
                },
                {
                    "sent": "Whereas the relationships between atoms in the URL's are taken from the source vocabularies.",
                    "label": 1
                },
                {
                    "sent": "For example, part of Oryza.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The we have kept the same four step process as the original Smash algorithm.",
                    "label": 0
                },
                {
                    "sent": "So the four steps are string to formula conversion where the label of a node is actually converted to a logical formula.",
                    "label": 1
                },
                {
                    "sent": "Context creation and filtering where we where we end up taking the structure into account, defining context and we also filter and drop irrelevant concepts and we also match atomic form atomic formulas using the M LS.",
                    "label": 0
                },
                {
                    "sent": "The originally in Word net, the mats in sets.",
                    "label": 0
                },
                {
                    "sent": "In our case we match concepts using the Umm as hierarchies and the final step is the reasoning step to actually do semantic match between.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Concepts.",
                    "label": 0
                },
                {
                    "sent": "OK, this is the example that I'm going to be going through.",
                    "label": 0
                },
                {
                    "sent": "I'll come back to it.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so in the first step now and that's the string to formula conversion.",
                    "label": 1
                },
                {
                    "sent": "As I mentioned previously, the purpose of this step is to convert the label of the node into a logical formula using logical connectives.",
                    "label": 1
                },
                {
                    "sent": "So individually we take we first organized and we take a single token as an atomic formula with the concepts behind it.",
                    "label": 1
                },
                {
                    "sent": "For example, if we create the UML S for the string height, we got the following concept returned.",
                    "label": 0
                },
                {
                    "sent": "We get hard malignant neoplasm, Part B, 9 year lesson with heart, heart problem, entire heart.",
                    "label": 0
                },
                {
                    "sent": "We currently do not know which is the concept that we want, and we only know this when we actually define concept context in this.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I can start.",
                    "label": 0
                },
                {
                    "sent": "So especially previously this works in the label Evernote, so if we take a note labeled heart and kidney diseases, we create the UML S4 heart, which is now an atomic formula after tokenizing of course, and that has five concepts attached, we query kidney and that is 1 concept attached.",
                    "label": 1
                },
                {
                    "sent": "We query disease and that in itself and that has five concepts attached from the Yuma less the final formula there with all the logical connectives captures the meaning of the node height and kidney diseases in our.",
                    "label": 1
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Case.",
                    "label": 0
                },
                {
                    "sent": "Right, we're onto the second step now, which is context creation and filtering.",
                    "label": 0
                },
                {
                    "sent": "The purpose of the step is to define the context for a node.",
                    "label": 1
                },
                {
                    "sent": "As I mentioned previously.",
                    "label": 1
                },
                {
                    "sent": "Using the formulas from the previous step and over all of his parents, this constrains the meaning of the node and the concepts in the URL S are still attached to atomic formula.",
                    "label": 1
                },
                {
                    "sent": "We also filter at the structural level as with the original estimate algorithm algorithm.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Any different though.",
                    "label": 0
                },
                {
                    "sent": "OK, so in this case the way that we create context, for example, if we look at the node hypertrophic cardiomyopathy, so that was the formula for that node, and then from there it's parent's height and kidney diseases, which was a bit more complicated, and these all actually have the concepts attached ill, and this parent was diseased.",
                    "label": 0
                },
                {
                    "sent": "This is the formula that we reason with at the end.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I will get to it.",
                    "label": 0
                },
                {
                    "sent": "OK, we also perform filtering of concepts using the M LS within the human S. We have 3 features available is available to us for the.",
                    "label": 1
                },
                {
                    "sent": "For the disambiguation, these are the concept relationships at in relationships and the Co occurrence relationships from text.",
                    "label": 0
                },
                {
                    "sent": "We use all this information for filtering purposes.",
                    "label": 1
                },
                {
                    "sent": "However, we only use one feature for disambiguation at the time I we only use the concept relationships or we only use the Atom relationships, or we only use the Co occurrence relationships?",
                    "label": 1
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, I went to the third step now, which is atomic formula matching using the M LS.",
                    "label": 0
                },
                {
                    "sent": "The purpose of this we use either the concept of the Atom hierarchies in the UM LS to actually match atomic formula to give us the background theory to actually reason with at the end.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, for the items are for the rules for the atoms are if a concept from a contains the concept from be it, where ANB are both atomic formulas, then we actually return the equivalence relationship.",
                    "label": 0
                },
                {
                    "sent": "If an Atom that belongs to a concept in a is a subclass of a concept of an Atom.",
                    "label": 1
                },
                {
                    "sent": "An Atom from a concept and be fit in a single source vocabulary.",
                    "label": 0
                },
                {
                    "sent": "Then we then we return a substantial relationship.",
                    "label": 0
                },
                {
                    "sent": "If if an Atom from a concept in a is a superclass of anathema concept in a single source library, then we actually return a superclass relationship.",
                    "label": 1
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For concepts are rules.",
                    "label": 0
                },
                {
                    "sent": "I if a concept from from a can contains a concept from B, then we return in the Caribbean's relationship.",
                    "label": 1
                },
                {
                    "sent": "If a concept from A is a subclass of a concept from BI, it is.",
                    "label": 1
                },
                {
                    "sent": "It is either an arrow then or a child.",
                    "label": 0
                },
                {
                    "sent": "Then we return to subclass relationship.",
                    "label": 0
                },
                {
                    "sent": "If a concept from A is a superclass of a concept from BIE it is apparent or it is a broader than then we return a superclass.",
                    "label": 1
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Relationship.",
                    "label": 0
                },
                {
                    "sent": "OK, now I'm now I'm going to talk about the final info step, which is the reasoning with all the information that we that I presented previously.",
                    "label": 0
                },
                {
                    "sent": "So the purpose of this step is to actually reduce the relationship between the two concepts between two ontologies that.",
                    "label": 1
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Join a match.",
                    "label": 0
                },
                {
                    "sent": "We've kept the same propositional reasoning approach as the original Smash algorithm.",
                    "label": 0
                },
                {
                    "sent": "In this case, the axioms are the background theory, which is information from the, UM, LS rallies, the relationship that we're trying to prove, and the context where the node formulas which I showed previously and.",
                    "label": 1
                },
                {
                    "sent": "We also end up mapping like the idea like connectives.",
                    "label": 0
                },
                {
                    "sent": "I showed you onto the property onto the propositional equivalence.",
                    "label": 0
                },
                {
                    "sent": "So in our case assumption is covered is converted.",
                    "label": 1
                },
                {
                    "sent": "Implication is the same the other way, and to prove equivalence we approve both subsumption and the superclass relationship as well.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, alright so in this case I'm going to go through an example quickly so if we matched the nodes Harden kidney diseases from 3 one and we matched an old myocardial infraction from 3 two.",
                    "label": 0
                },
                {
                    "sent": "Which one approval superclass relation?",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yep.",
                    "label": 0
                },
                {
                    "sent": "So the axioms from this matching task.",
                    "label": 0
                },
                {
                    "sent": "This is information that we actually discovered from the armilus, so we found that disease was equivalent to disorder.",
                    "label": 0
                },
                {
                    "sent": "Heart is equivalent to cardiac, and myocardial infraction was a subclass of disease.",
                    "label": 0
                },
                {
                    "sent": "Now now when we reason over this, as you can see, we have the axioms here and we actually have the tree context here as well.",
                    "label": 0
                },
                {
                    "sent": "This formula is unsatisfiable using equation using the equation showed you previously previously.",
                    "label": 0
                },
                {
                    "sent": "Hence this relationship holds.",
                    "label": 0
                },
                {
                    "sent": "So that means that I'm hurting.",
                    "label": 0
                },
                {
                    "sent": "Kidney disease is a superclass of myocardial infraction.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right, I'm going to talk about the implementation for a bit.",
                    "label": 0
                },
                {
                    "sent": "This implemented.",
                    "label": 0
                },
                {
                    "sent": "We've implemented this completely 100% from scratch.",
                    "label": 0
                },
                {
                    "sent": "It was developed within the framework of the Healthy, Healthy Child Project and we are currently preparing the implementation for an open source release.",
                    "label": 1
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Right I experimental setup, we match subsets of the FMA, two subsets of to a subset of meshes.",
                    "label": 1
                },
                {
                    "sent": "Well, the FMA is is an ontology about anatomy, whereas mesh.",
                    "label": 0
                },
                {
                    "sent": "I'm sure there must surely familiar with our trees are rooted at the concept of brain.",
                    "label": 1
                },
                {
                    "sent": "In both the ontologies to attract to extract a tree from the FMA, we followed the original part of relationship down to its leaf nodes.",
                    "label": 1
                },
                {
                    "sent": "So we started their brain and went all the way down and this has a total of 476 concepts.",
                    "label": 1
                },
                {
                    "sent": "The extracted tree from mesh which reversed the tree down to its leaf.",
                    "label": 0
                },
                {
                    "sent": "Note this has a total of 181 concepts.",
                    "label": 1
                },
                {
                    "sent": "We use the standard metrics position and recall in our work and our gold standard was created with the aid of a domain expert.",
                    "label": 0
                },
                {
                    "sent": "It's a very, very small gold standard and we selected 20 random concepts from FMA subset and 40 random concept from Ed subset.",
                    "label": 0
                },
                {
                    "sent": "We use the 2008 version of the M, LS and all other experiments.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What?",
                    "label": 0
                },
                {
                    "sent": "Right, just to give you an example on the left on the left hand side we have a tree.",
                    "label": 0
                },
                {
                    "sent": "We have a screenshot of the tree from the FMA and on the right hand side we have a screenshot of the tree from mesh.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And alright results.",
                    "label": 0
                },
                {
                    "sent": "We actually run different versions of algorithm on.",
                    "label": 1
                },
                {
                    "sent": "Like for like for the matching process.",
                    "label": 1
                },
                {
                    "sent": "For example, we only use the concept hierarchies for the matching with no filtering or we use the Atom hierarchies with concept filtering or cones filtering.",
                    "label": 0
                },
                {
                    "sent": "So every permutation we ran them all together.",
                    "label": 0
                },
                {
                    "sent": "I will results really went as weren't really what we expected, and the reason for this is because our gold standard is very very small, so this is future work and it's actually on going right now.",
                    "label": 1
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, alright I'm concluding now.",
                    "label": 0
                },
                {
                    "sent": "So we have shown a means of adapting semantic matching to the medical domain using the human less as a background resource.",
                    "label": 1
                },
                {
                    "sent": "We have shown how different features of the human less concepts, atoms occurrences can be used for disambiguation.",
                    "label": 0
                },
                {
                    "sent": "The filtering we found was actually only useful in cases where two ontologies have a similar set of terms, but their Contacts are highly dissimilar.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So future work we need to conduct a more thorough, thorough evaluation of our method, and this is very difficult since there actually is not a medical goals and are available today, which actually has semantic matches in there.",
                    "label": 1
                },
                {
                    "sent": "We will also submit our results to this years away.",
                    "label": 1
                },
                {
                    "sent": "A competition for evaluation in the medical track.",
                    "label": 0
                },
                {
                    "sent": "We will also investigate how to adapt different background resources from different domains for the semantic matching process.",
                    "label": 1
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK. Quick.",
                    "label": 0
                },
                {
                    "sent": "Questions.",
                    "label": 0
                },
                {
                    "sent": "OK so I have person announcement in detail.",
                    "label": 0
                },
                {
                    "sent": "Will be OAI 2009 this year.",
                    "label": 0
                },
                {
                    "sent": "So that's the first news.",
                    "label": 0
                },
                {
                    "sent": "Interesting everyone I hope and the second news interesting more specially you is that there would be an organization of a special benchmark for.",
                    "label": 0
                },
                {
                    "sent": "Alignments with ordered relation not only equivalent.",
                    "label": 0
                },
                {
                    "sent": "So since your system medical track no, it's not the medical track as far as I know.",
                    "label": 0
                },
                {
                    "sent": "OK too bad.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Still no question.",
                    "label": 0
                },
                {
                    "sent": "Actually Christian, last year when he showed the results for the anatomy track, he told us that.",
                    "label": 0
                },
                {
                    "sent": "Of the systems actually not, there were none of the systems found.",
                    "label": 0
                },
                {
                    "sent": "About 25% of the non trivial.",
                    "label": 0
                },
                {
                    "sent": "Mappings.",
                    "label": 0
                },
                {
                    "sent": "And even the system that used background knowledge, which in this case always was Jorma, less they actually missed quite a bit as well, really, which means that you are Melissa is not complete.",
                    "label": 0
                },
                {
                    "sent": "Is that going to be a problem for your real systems?",
                    "label": 0
                },
                {
                    "sent": "Well, in our case, I mean, as long as we have some information extracted from the URL S, then we're actually able to do some match in most cases.",
                    "label": 0
                },
                {
                    "sent": "So I mean, for example, with the reasoning process for.",
                    "label": 0
                },
                {
                    "sent": "If this transitive reasoning, we can pull it off so.",
                    "label": 0
                },
                {
                    "sent": "So it is possible as long as we have some information there.",
                    "label": 0
                },
                {
                    "sent": "Hello question.",
                    "label": 0
                },
                {
                    "sent": "Tier one you use.",
                    "label": 0
                },
                {
                    "sent": "I assume you such that 4G yes OK and so you have queries with very very huge background.",
                    "label": 0
                },
                {
                    "sent": "If you put all your Mail is there.",
                    "label": 0
                },
                {
                    "sent": "Is there some specific problem with that?",
                    "label": 0
                },
                {
                    "sent": "It's very, very slow.",
                    "label": 0
                },
                {
                    "sent": "It's I mean this whole thing.",
                    "label": 0
                },
                {
                    "sent": "I mean to match like this upsets over here, it's over night so that's only like 400 to like 180.",
                    "label": 0
                },
                {
                    "sent": "It's it's a very very slow process and that's unlike when we've got a beast of a machine as well.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "So everybody is hungry, so we will.",
                    "label": 0
                },
                {
                    "sent": "We thank all the presenters for this nice presentation, but the lunch is not open yet.",
                    "label": 0
                }
            ]
        }
    }
}