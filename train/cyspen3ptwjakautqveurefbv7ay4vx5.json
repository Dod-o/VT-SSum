{
    "id": "cyspen3ptwjakautqveurefbv7ay4vx5",
    "title": "Beyond stochastic gradient descent for large-scale machine learning",
    "info": {
        "author": [
            "Francis R. Bach, INRIA - SIERRA project-team"
        ],
        "published": "Oct. 29, 2014",
        "recorded": "September 2014",
        "category": [
            "Top->Computer Science->Digital Signal Processing",
            "Top->Computer Science->Machine Learning->Computational Learning Theory",
            "Top->Computer Science->Machine Learning->Deep Learning",
            "Top->Computer Science->Information Theory",
            "Top->Mathematics->Statistics"
        ]
    },
    "url": "http://videolectures.net/sahd2014_bach_stochastic_gradient/",
    "segmentation": [
        [
            "So the net present value, the work of my colleague like Malin from from Telecom in Paris.",
            "So today following.",
            "The theme of the."
        ],
        [
            "Workshop I will talk about the high dimensional inference and we have seen many examples of such problems where we have a lot of observations and my talk will follow the statistics convention and the number of observations, and P is the size of the observations and many setups, and we have seen examples from young and rich as well and also examples before yesterday.",
            "Computer vision, lots of images.",
            "Each image is quite big, so both NPR out bearing fanatics as well but I Zing.",
            "Of course, with a good today, will not to look.",
            "We would not be to look at these large P phenomenon, but mostly large N. OK, so we're going to issue P is small, big, whatever.",
            "But N is going to be a very large and if not potentially infinite or the goal.",
            "Of course faced with such a large amount of data you want to preserve and running time complexity and about global B2B only linear in both P&N.",
            "OK so this is a goal for today.",
            "It's an optimization talk.",
            "We want to optimize.",
            "Optimize fast.",
            "OK, so the key is the key message is that at the end game to go to go back to very simple methods and methods that date from the 50s.",
            "So there's been like improvement since 1951, but the main, the main algorithm has not changed emerged in the world today.",
            "So we see that how you can improve on that algorithm to beat existing stochastic identity set.",
            "OK, so just to set up notations, I'm going to have an observations."
        ],
        [
            "Why?",
            "Why I so XI will be my input.",
            "Think about an image an why I will be the output.",
            "Think about the presence or absence of an object in that image and I'll be introducing the data ID an for simplification and we need to consider that I'm doing linear predictions on those those.",
            "Objects X, but not necessarily know index, but Lena in features of X fear of X and then we will see that few of X is a bidimensional, so I assume this is given if PP features and I'm going to do linear predictions on those features.",
            "I'm going to get her eyes done playing call of his nation.",
            "We are going to minimize data fitting term which is averaged over my training data of a loss.",
            "So L here will be a loss.",
            "You can think of that loss being lonely squares if you prefer, but could be syllogistic, love lossless Carlos and he knows which is smooth.",
            "So in this talk about only consider a smooth losses.",
            "So this excludes the support vector machine and have allowed between my what I want to predict in my prediction.",
            "This is classical, like convex data fitting term.",
            "And then we have some complexity.",
            "Of course, for the lozanne you may add some organizer to avoid overfitting, but in this talk about mostly consider no regularizer.",
            "So there are two quantities of interest when you do a machine learning this.",
            "The first one, it didn't take a risk, which is the one you can access.",
            "OK, you can compute it on your training data, the training cost, but what you really care about is minimizing the expected risk on unseen data, which is the this quantity which I will call the testing cost.",
            "So we have access to this, but we want to minimize that so that two there have been 2 main questions tackled.",
            "Typically the first one is an optimization question given MAG data hardware.",
            "Compute the minimizer of that thing that is pure optimization and the 2nd is given this, like minimizer.",
            "How does it perform on unseen data?",
            "This is model statistical question and the main theme of today's talk is to tackle those two simultaneously.",
            "So in the presence of large amounts of data, you cannot simply like separate.",
            "So these things from optimization you have to consider them together and this is the main theme of our code of so many other work."
        ],
        [
            "So a bit of definitions, so we consider on its news losses.",
            "So essentially for me smoothness means like bonded 2nd order derivative, so alterations have maximum values which are bounded by L. So on the left or smooth function or the writer nonsmooth function.",
            "This is how the trivial.",
            "So in the."
        ],
        [
            "Types of machine learning where our cost functions will be like ideologies of a loss.",
            "So if you assume this is a loss, is the squares for simplicity, then the Haitians are simply the compliance matrix of the empirical governance metrics for data.",
            "So being bonded being a smooth means the loss is smooth, so least squares or logistic an you did our bonding so you see so much of a minor assumption might not compare to the order like type of assumption of the history, which is a strong convexity."
        ],
        [
            "So this talk on SCT, so a simple definition is that all of the eigenvalues of your Haitians are not upper bounded below or bounded by a constant, and I because I constant mu throughout the talk, some, you being zero just means convexity.",
            "But you want me to be strictly positive and this means having curvature in every direction.",
            "So on the left here you have a convex function which is not strongly convex because you have a flat part linear part here, whereas this one is a strongly context.",
            "So whether this mean in the context of machine learn."
        ],
        [
            "Same way we will have that convex that I fit in term.",
            "Again.",
            "If you take these squares for simplification where the history and is a covariance matrix, then you need at Cabela's matrix to be invertible.",
            "OK so if North is smaller than pee, which happens quite often, then this would never happen because the metric is having efficient.",
            "So essentially, whenever you see strong convexity, you should think about either low dimensions or local relations.",
            "Essentially simple problems.",
            "So this is typically not adapted to modern modern modern problems, so these people have realized that."
        ],
        [
            "Most problems are not convex, so by not adding a regularizer to negative 20 context OK, it is true that whatever G is.",
            "If you add like a mule over two times the square and two norm you become neutronic on legs.",
            "So it's fine for optimization, but then you start to solve a new problem, so you add some diaspora problem and whenever you seem you here in machine learning it should be you have N as you see more data, UDC will go to zero and grows.",
            "So you should be very careful when you see Mew Mew is never constant and that talk and we simply don't use any any regularizer."
        ],
        [
            "OK, So what are the classical methods to do optimization?",
            "So it's really like Super basic, so if you take any convex function gradient decent OK, you just let further gradient and here you will see on that simple algorithm the impact of strong connectivity.",
            "So if you are really strongly convex so if you have curved in every direction and in 2D this is like you are really like both shape then Kennedy said we converge very quickly like for bullet converges in one iteration of course, but if you have like a bit less than a bowl baby convert like linearly.",
            "So the global team meaning that the convergence as an exponential exponential rate.",
            "So this is for Stony convex functions, and as soon as we get that functions which are more in condition like something like this, then you can start to make smaller step and then.",
            "But you can show that you converge only at rate one.",
            "Averting so easy problem hard problem.",
            "But the key here and that dissent is adaptive to that complexity.",
            "You don't need to tell the algorithm if you're going to be hard.",
            "Easy, we just run it and it's fully adaptive and does the best that it can, so it's not optimal.",
            "You can improve a bit from University.",
            "Probably the constant, but essentially gradient descent already does most most of the work.",
            "Then you have Newton, OK, but you replaces killer gain or the gradient by the metrics metrics gain."
        ],
        [
            "So it's hard to implement in practice with WPP.",
            "Is logical.",
            "You have to solve it in our system, but then you go from linear convergence to aquatic convergence, not used a lot for large scale inference, but since I'm going to mention it later in the talk, let's go, let's keep it here.",
            "So this is for any any convex function, so that is different in machine learning that we don't optimize any convex function and our problems would be different the 1st.",
            "So first inside by both 2 and Bousquet that first when you optimize an average typically averages will vary with the standard deviation of one over root North.",
            "So if you ask for a procedure which is lower than one over root N, you optimize about the noise, so it's useless to have to add like Optima up to machine precision.",
            "So essentially it is waste food to use new term to arrange like to get the last last digits and surrounding inside very important.",
            "Our cost functions are not anything is another edge of functions so we can take this.",
            "We take advantage of this.",
            "This is the topic of the talk of today on the Testek approximation.",
            "So what these are?"
        ],
        [
            "Graphical proximation will be to minimize the function F OK convex function, but you don't observe F. You only observe like unbiased version of the gradients.",
            "So if you could have the gradient will get decent but you just get a noisy estimated gradient and you never can text.",
            "This will mean F will be could be F will be the tester on OK.",
            "So the key here is that the formulation in stochastic approximation is a direct meaning.",
            "Implicit minimization of the test error.",
            "So all of the bound that people get all the results are not on your training data.",
            "But this is an interesting data, so of course we don't have access to F. You don't have access to a creditor of F, but if you sample single payer observation AYNXN and you could FN the loss for a single observation trivially, you have that the gradient of the expected loss is simply the expectation of a gradient of the loss of a single observation.",
            "OK, this season, that hour of services, like a very simple, so we consider like unbiased gradients by taking the gradient of a single observation.",
            "OK, and this is the web going to use that to classic approximation in this in this work.",
            "So clearly the field of stochastic approximation goes far beyond like convex optimization.",
            "But here in that topic consider or sub case on which we can really say a lot of things."
        ],
        [
            "So what is the key?",
            "The key algorithm in that set up?",
            "This is that problems window, also known as the plastic surgeon decent at every time step you go from one to N by going down this negative gradient of your local function.",
            "Here it depends only on the single observation.",
            "And here I've met a subtle change from going from T as an index to end this on purpose because in stochastic approximation the number of iterations is equal to the number of observations.",
            "So T is equal to N. So we always use N as an indexed set.",
            "You see the data only only once, so it used to calculate on this end and the key improvement which looks like super trivial.",
            "You just replacing the last iterate when you want to predict by the other edge of all iterates.",
            "OK, this is called preocupa raging.",
            "And the key question now is what should be the learning rate sequence?",
            "OK, so for anybody who has tried to implement the President sent, this is a test part.",
            "OK, so essentially you want typically gamma to go down to zero.",
            "So if.",
            "Most most of you will have read or learn that typically the sum of gamma should be diverging and there is some of that square will be converging.",
            "OK, this is what you typically learn in that set up.",
            "This is lack true in very like very condition problem.",
            "OK, so typically the set that's the same size of one of our North which is diverging and the squares converging is not adapted to large scale problem.",
            "OK and people have gone to larger step sizes.",
            "And as it is a topic of before I go on just mentioned the holding time.",
            "OK, by design the running time is linear in North since I see that at points on the early months."
        ],
        [
            "Upside only once, then it already by design it's a single path with data OK, which is often interesting, particularly when you have to compute features on your data.",
            "You compute them once and then you can throw them away.",
            "And finally, it's one line of code.",
            "OK, so clearly it's phone line of code among many, many many other lines of code.",
            "OK, so accesses data is a lot of lines of code with the learning part is really tiny.",
            "OK, and today we need to consider that tiny line which can make a big difference.",
            "As well as many other lines of code.",
            "OK, I don't mean to say one is more important than the other, but I'm focusing more on that on that part."
        ],
        [
            "Go to what is known about the problem so that these are the best possible performance penalties you can achieve.",
            "This is also known to be related to strong convexity, so if your problem as curvature then it's easy.",
            "And if it does, it doesn't have curvature.",
            "It's hard and the best we can do is that over result from Europe scheduled in from the 80s is if you're strongly convex you'll get convergence rate of one of our new.",
            "So this means that the best you make the difference between your your test error.",
            "And the best possibilities there are in your class goes down to zero as one of our immune and this this is achieved by stochastic descent with a certain step size, whereas it would just only convex lens.",
            "Again high dimensions, then the best you can do is one of Ruth and this is achieved by bigger step size, because here we see that there is like a mismatch.",
            "Productivity of plastic surgeon dissent.",
            "Depending on the hardness of the problem, you may need to use different different step sizes.",
            "So in other words, from a more optimization, which will global manasam projects are always true for every end.",
            "But there was another line of work more on this task community and particular word bipolar can reduce key in the 90s, showing that if you have moose, if you add this assumption of smoothness OK which those ones were not, but not adding then you can quickly if Ed is large enough you can you can get it can be hard pressed to air conditioning and for any step sizes which is between between those.",
            "OK, so this is like the most the most important related works and the goal for today is trying to mix everything in a single algorithm.",
            "OK, with going to be adaptive to harness of the problem and even better get rid of these different lengths of new.",
            "OK so you you should think of me as being very small.",
            "OK so if when you goes down to there was one of our one of our things are not good to go.",
            "OK so you have to be careful in about this.",
            "So mu is quite small and the goal will be to get a similar rhythm.",
            "With the confidence which is gonna rain in alterations.",
            "OK, so here you should question.",
            "But there were lower bounds here, which I cannot be.",
            "So what am I going to add to the problem?",
            "I'm going to add smoothness.",
            "OK, so you impose a smooth, you allow smoothness and now you can build those lower bounds.",
            "And this is the main topic.",
            "Of three."
        ],
        [
            "So in fact we're going to see at least squares first.",
            "The simple simple problem.",
            "Firstly square.",
            "So this is a square loss.",
            "Is that context?",
            "SGD is often called at least mean square LMS.",
            "And it is usually studied with like without a Virgin and typically with decreasing step sizes and most often with a invertible covariance matrix.",
            "So what we have done with the aqualine is first to take something which is not new.",
            "OK, we simply took.",
            "Event, but instead of trying to decide between the owner and step size or one of the whole 10 step side, we took a constant step size.",
            "OK, take a constant step size.",
            "We can also give a very valued the constraint the best.",
            "OK, our best constant.",
            "We depend on the edges of your features.",
            "Typically you know the edges of your features, so you this you need to know for logarithm.",
            "Take that step size.",
            "If you assume your noise is bounded, you don't need to know the noise value places for the band.",
            "Only then independently of.",
            "So the hardness of edge even in edge is very, very small eigenvalues.",
            "Then we can show that that very simple algorithm, constant step size averaged SGD gets gets you about like this.",
            "So just to pass this data star is the optimal predictor in your class.",
            "If you if you if your test there are antiparallel minus one or N is the average predictor and this is a random because you assumed your data random.",
            "OK, so we take expectations over the 100 Ness of the data and you can see that it goes down as one of our North with two classical terms, one valence term OKC mask.",
            "We happy over North and one bias term which is right at which you forget initial conditions for the experts in like in minimax theory, in the room, that term seem magically appeared on Earth.",
            "Cannot be improved.",
            "This is a mini Max lower bound for statistiques even if you have no constraints and computation.",
            "Whereas this one that can probably be can probably be improved, but the key here is the absence of you.",
            "There is no you'll get one of our end and without any presence of the of the condition number."
        ],
        [
            "So let's try to see why why it should work, and inside you can get this 1 / N rate you can get with no computation.",
            "OK, so this is a good of this slide is to show that.",
            "You could, if I could have like 7 other end directly, so you see the reaction for least squares.",
            "It's Peter gradient of FN and at all, so basic approximation algorithms you have a Markov chain, so you're iterates from the Markov chain.",
            "OK, this is because you have idea data here, but because our step size is constant, the Markov chain is homogeneous.",
            "OK, so this is not the case when Grandma goes to zero, you don't get the homogeneous Markov chain where here we do.",
            "So if you make exception is going to converge to a stationary distribution.",
            "Which are called by Afghan ah.",
            "So what you usually think of is that your resume you started as you roll your initial point.",
            "You move around and at the end you follow like a special distribution, so you will see late around the point so you never converge.",
            "OK, so this is an algorithm before leveraging that will not convert an OC later around a certain value which we called it a bar of gamma.",
            "The key is that police squares that about gamma is your optimal predictor.",
            "OK, so this is easier to see in one line.",
            "Just computing stations because the identity is a linear function.",
            "Then you'll see late OK like this.",
            "So here what we leveraging do value is simply make sure that proof you go closer and closer to your global optimum and even better in terms of rates of convergence.",
            "Edward Excel ramps here to ensure that the distance between the two will go down as one over with North.",
            "And since we consider like we measure performance in squared distances, it's one of our end.",
            "So in the standard file that we get one of our end.",
            "For that matter, with them like I've already GD with constant step size is almost like image it from from the set up of course what is not."
        ],
        [
            "If y'all is what is here, OK, but is the exact variance term and the federal guidance team does not depend on.",
            "There's not depend on the condition number.",
            "OK, so this is."
        ],
        [
            "Very very big data in 20 dimensions.",
            "OK, there we go, a bit bigger or in the one slide.",
            "OK so this is like just 20 dimensions in all of my plugs.",
            "This is N number of iterations or number observations in a log log scale and distance to optimum in a log scale as well.",
            "In playing this is without damaging.",
            "Anecdote is before bridging, so I've tried several values of the step size are constant step sizes with different values.",
            "Plus like predicting step size.",
            "As you can see, before doing averaging login dot in, you don't converge and UCLA situations.",
            "So this is this is normal or hard.",
            "As soon as you do averaging you start to go down as a line and those sort of that line is your curfew.",
            "Carefully is minus one.",
            "OK, so just an illustration of this.",
            "One of our end step size with a very strong difference between before origin or you don't conversion after urging, but you do converge, whereas if you take the decaying step size of course your interesar before arising or a bit better but.",
            "After averaging, they perform worse than the.",
            "At least at the beginning, as without average.",
            "So this is for Snow Day."
        ],
        [
            "Yeah, for bigger data so of course like standard benchmarks for optimization like being quite small and large N and then typical data from a news from tech data when P is very large you have a lot of lot of features, but many of them are equal to the oh and so here I have two columns so I have two lines.",
            "This is like one that I said that I said I have two columns because typically in most optimization works you have like a hidden factor which is a step size.",
            "So yeah, the step size for the bound and then get the step size for the experiments.",
            "Typically those two are different, so on the left is a step size from the bound.",
            "OK, so the one I propose another value step size.",
            "If you, after all, future actions, which is a standard practice.",
            "So this is just just loads that we're doing here.",
            "You have to try several of them and take the best one at the end.",
            "So here you can see the difference between like one of the red curve.",
            "So between like blue which is constant and green which is decaying.",
            "Then if you use a step size of the bound for the decaying step size, the constant is too small, so at the end it goes very slow for very long OK, whereas if you allowed to for the decaying step size to learn the concerns then you can do quite well at the end.",
            "But it's at the price of adding C being violated, the beginning.",
            "OK, so here you see the log scale.",
            "This means that if you want to achieve like good performance here, you need a taxi so big that you need to start to diverge, which is really not not not good in practice, whereas if you take amerge, slower decay and nudity at all, and whether you take the step size of the band or the best possible step side, we get similar behavior.",
            "So this is really key to be able to give to give step aside, which is Robert a different aspect of the problem and the constant step size.",
            "Either is there such a thing?"
        ],
        [
            "OK, so this works for the squares, but of course people do not only care only about his squares, or do I think maybe it's sufficient for many, many things.",
            "But let's go logistic.",
            "OK, so the same Markov chain setup can be can be used.",
            "We have a Markov chain which is Imagineers, so it does converge also too, especially distribution.",
            "And the way you can verify that the what you can say about that stationary distribution of their own.",
            "But the problem now is that because the credit is not a linear function anymore, you cannot invert brightness spec tations.",
            "So the gradient at your average value is not zero.",
            "OK, so this means that you will get a similar setup that oscillate around value, but that value is away from the true value from the true value.",
            "So if you do an origin, you going to converge quickly too.",
            "Long value.",
            "OK, so the fact that constant step study does not converge.",
            "The event was known before May just in the world set of Markov chains.",
            "It's in pretty sure that you converge quickly to on value.",
            "What you can show that by doing leveraging you get a bit closer to the test are, but you never get to the desktop, so this can be shown in simulations at the same exact simulation that replacing the square."
        ],
        [
            "Logistic loss we had before leveraging this is inducted.",
            "You don't converge exact same plot, but when you do averaging you go quickly to a place and you study.",
            "This study lies.",
            "So you convert those late anymore.",
            "But the whole point which does not work 220 or in here since I've logged plots to medicine Infinity.",
            "So you get this this surprising behavior.",
            "So of course if you take smaller step sizes you saturate at better point.",
            "OK, so this is also known as well that if you take a constant state.",
            "It was a constant, is small enough you don't convertible optimum, but to place which might be good enough.",
            "But the world today would be to replace all of this by a single a single line, Yep.",
            "Back to the last one.",
            "But you know it pulls you in One Direction or the other.",
            "I too miss might not only now there's a Disney now so it can be.",
            "You may have different forms, but asymmetry can be also good thing.",
            "It goes good explanation at the end.",
            "You don't converge to the global optimum if you use a small step size, but these are steps is dialyzed more.",
            "You converge very very close, OK and in fact we can.",
            "In fact we have bounds of bounds on the distance to optimum depending on the step size and.",
            "So the goal will be to restore convergence at the garden, and in fact it's almost like with no.",
            "We know a motivating to do this much time.",
            "About 2 minutes OK."
        ],
        [
            "Swollen so we're going to consider like a let's me just forget that slide and simply."
        ],
        [
            "To distract algorithm, so we're going to do.",
            "We're going to do a little step.",
            "OK, so we know how to minimize cratic functions.",
            "I've just presented it so now, what do we do instead?",
            "Newton step is going to minimize aquatic function, so if you want to do and you don't step on the expected loss.",
            "The Taylor approximation is also is aquatic function, which is also an expectation.",
            "So if you want to do a Taylor Newton step, so minimizing this magic function, you can do it using at least mean squares OK and compute compute gradients of that Taylor expansion and you get like a first order term and 2nd order term.",
            "But the key here is that you have relation to the Asian is PDP OK so you might think there is going to be at least be square but never context where we consider linear predictions.",
            "The Hastiness Hank one.",
            "OK, so you see the second of the loss with respect to the second variable time.",
            "So I think one metrics for that like Hessian matrix vector product can be done of P. So at the end you can do that online.",
            "Newton steps only buy online, you don't step by the same complexity as regular regular organization."
        ],
        [
            "So at the end, forget about this one.",
            "Look at this.",
            "So what is about the rhythm we're going to do back?",
            "Implicitly?",
            "Newton step, but we have to decide what are we doing and what are we going to do.",
            "Need to step around.",
            "OK we need to find another point and the pool we going to use is our current average iterate.",
            "OK, so remember that throughout the algorithm we have the fascinating design, but we have the convergence Florida bar and begin to replace the true gradient here by the 1st order.",
            "Oximeter agent around your current average iterate OK, and this is the same capacity as before, and we are.",
            "We have like a tune down version for we can prove this over an organ about convergence rate without any appearance of you before that one that works very well.",
            "We are still trying to prove the convergence rate, and let's see how it works."
        ],
        [
            "So this was logistically this would be my last slide, so before conclusion.",
            "So this is before local versions and as soon as you start to do this online you can step which has the same capacity as before you restore convergence.",
            "And this is true for smooth data, but it is also true for bigger than that."
        ],
        [
            "Which I will present.",
            "So you conclude."
        ],
        [
            "So we've been able to go beyond like this one of our new barrier by opposing.",
            "The smoothness is very low."
        ],
        [
            "Possible extensions, particular, of course, nonconvex problems, parallelization, non differentiability.",
            "So I don't think hostility at parity is good, but it's possible that talk and also plan out because I think this could be interesting as well.",
            "Thank you for your attention."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the net present value, the work of my colleague like Malin from from Telecom in Paris.",
                    "label": 0
                },
                {
                    "sent": "So today following.",
                    "label": 0
                },
                {
                    "sent": "The theme of the.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Workshop I will talk about the high dimensional inference and we have seen many examples of such problems where we have a lot of observations and my talk will follow the statistics convention and the number of observations, and P is the size of the observations and many setups, and we have seen examples from young and rich as well and also examples before yesterday.",
                    "label": 0
                },
                {
                    "sent": "Computer vision, lots of images.",
                    "label": 0
                },
                {
                    "sent": "Each image is quite big, so both NPR out bearing fanatics as well but I Zing.",
                    "label": 0
                },
                {
                    "sent": "Of course, with a good today, will not to look.",
                    "label": 0
                },
                {
                    "sent": "We would not be to look at these large P phenomenon, but mostly large N. OK, so we're going to issue P is small, big, whatever.",
                    "label": 1
                },
                {
                    "sent": "But N is going to be a very large and if not potentially infinite or the goal.",
                    "label": 0
                },
                {
                    "sent": "Of course faced with such a large amount of data you want to preserve and running time complexity and about global B2B only linear in both P&N.",
                    "label": 0
                },
                {
                    "sent": "OK so this is a goal for today.",
                    "label": 0
                },
                {
                    "sent": "It's an optimization talk.",
                    "label": 0
                },
                {
                    "sent": "We want to optimize.",
                    "label": 0
                },
                {
                    "sent": "Optimize fast.",
                    "label": 0
                },
                {
                    "sent": "OK, so the key is the key message is that at the end game to go to go back to very simple methods and methods that date from the 50s.",
                    "label": 1
                },
                {
                    "sent": "So there's been like improvement since 1951, but the main, the main algorithm has not changed emerged in the world today.",
                    "label": 0
                },
                {
                    "sent": "So we see that how you can improve on that algorithm to beat existing stochastic identity set.",
                    "label": 0
                },
                {
                    "sent": "OK, so just to set up notations, I'm going to have an observations.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Why?",
                    "label": 0
                },
                {
                    "sent": "Why I so XI will be my input.",
                    "label": 0
                },
                {
                    "sent": "Think about an image an why I will be the output.",
                    "label": 0
                },
                {
                    "sent": "Think about the presence or absence of an object in that image and I'll be introducing the data ID an for simplification and we need to consider that I'm doing linear predictions on those those.",
                    "label": 0
                },
                {
                    "sent": "Objects X, but not necessarily know index, but Lena in features of X fear of X and then we will see that few of X is a bidimensional, so I assume this is given if PP features and I'm going to do linear predictions on those features.",
                    "label": 0
                },
                {
                    "sent": "I'm going to get her eyes done playing call of his nation.",
                    "label": 0
                },
                {
                    "sent": "We are going to minimize data fitting term which is averaged over my training data of a loss.",
                    "label": 0
                },
                {
                    "sent": "So L here will be a loss.",
                    "label": 0
                },
                {
                    "sent": "You can think of that loss being lonely squares if you prefer, but could be syllogistic, love lossless Carlos and he knows which is smooth.",
                    "label": 0
                },
                {
                    "sent": "So in this talk about only consider a smooth losses.",
                    "label": 0
                },
                {
                    "sent": "So this excludes the support vector machine and have allowed between my what I want to predict in my prediction.",
                    "label": 0
                },
                {
                    "sent": "This is classical, like convex data fitting term.",
                    "label": 1
                },
                {
                    "sent": "And then we have some complexity.",
                    "label": 0
                },
                {
                    "sent": "Of course, for the lozanne you may add some organizer to avoid overfitting, but in this talk about mostly consider no regularizer.",
                    "label": 1
                },
                {
                    "sent": "So there are two quantities of interest when you do a machine learning this.",
                    "label": 0
                },
                {
                    "sent": "The first one, it didn't take a risk, which is the one you can access.",
                    "label": 1
                },
                {
                    "sent": "OK, you can compute it on your training data, the training cost, but what you really care about is minimizing the expected risk on unseen data, which is the this quantity which I will call the testing cost.",
                    "label": 0
                },
                {
                    "sent": "So we have access to this, but we want to minimize that so that two there have been 2 main questions tackled.",
                    "label": 0
                },
                {
                    "sent": "Typically the first one is an optimization question given MAG data hardware.",
                    "label": 0
                },
                {
                    "sent": "Compute the minimizer of that thing that is pure optimization and the 2nd is given this, like minimizer.",
                    "label": 0
                },
                {
                    "sent": "How does it perform on unseen data?",
                    "label": 0
                },
                {
                    "sent": "This is model statistical question and the main theme of today's talk is to tackle those two simultaneously.",
                    "label": 0
                },
                {
                    "sent": "So in the presence of large amounts of data, you cannot simply like separate.",
                    "label": 0
                },
                {
                    "sent": "So these things from optimization you have to consider them together and this is the main theme of our code of so many other work.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So a bit of definitions, so we consider on its news losses.",
                    "label": 0
                },
                {
                    "sent": "So essentially for me smoothness means like bonded 2nd order derivative, so alterations have maximum values which are bounded by L. So on the left or smooth function or the writer nonsmooth function.",
                    "label": 0
                },
                {
                    "sent": "This is how the trivial.",
                    "label": 0
                },
                {
                    "sent": "So in the.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Types of machine learning where our cost functions will be like ideologies of a loss.",
                    "label": 0
                },
                {
                    "sent": "So if you assume this is a loss, is the squares for simplicity, then the Haitians are simply the compliance matrix of the empirical governance metrics for data.",
                    "label": 0
                },
                {
                    "sent": "So being bonded being a smooth means the loss is smooth, so least squares or logistic an you did our bonding so you see so much of a minor assumption might not compare to the order like type of assumption of the history, which is a strong convexity.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this talk on SCT, so a simple definition is that all of the eigenvalues of your Haitians are not upper bounded below or bounded by a constant, and I because I constant mu throughout the talk, some, you being zero just means convexity.",
                    "label": 0
                },
                {
                    "sent": "But you want me to be strictly positive and this means having curvature in every direction.",
                    "label": 0
                },
                {
                    "sent": "So on the left here you have a convex function which is not strongly convex because you have a flat part linear part here, whereas this one is a strongly context.",
                    "label": 0
                },
                {
                    "sent": "So whether this mean in the context of machine learn.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Same way we will have that convex that I fit in term.",
                    "label": 0
                },
                {
                    "sent": "Again.",
                    "label": 0
                },
                {
                    "sent": "If you take these squares for simplification where the history and is a covariance matrix, then you need at Cabela's matrix to be invertible.",
                    "label": 0
                },
                {
                    "sent": "OK so if North is smaller than pee, which happens quite often, then this would never happen because the metric is having efficient.",
                    "label": 0
                },
                {
                    "sent": "So essentially, whenever you see strong convexity, you should think about either low dimensions or local relations.",
                    "label": 0
                },
                {
                    "sent": "Essentially simple problems.",
                    "label": 0
                },
                {
                    "sent": "So this is typically not adapted to modern modern modern problems, so these people have realized that.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Most problems are not convex, so by not adding a regularizer to negative 20 context OK, it is true that whatever G is.",
                    "label": 0
                },
                {
                    "sent": "If you add like a mule over two times the square and two norm you become neutronic on legs.",
                    "label": 0
                },
                {
                    "sent": "So it's fine for optimization, but then you start to solve a new problem, so you add some diaspora problem and whenever you seem you here in machine learning it should be you have N as you see more data, UDC will go to zero and grows.",
                    "label": 0
                },
                {
                    "sent": "So you should be very careful when you see Mew Mew is never constant and that talk and we simply don't use any any regularizer.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, So what are the classical methods to do optimization?",
                    "label": 0
                },
                {
                    "sent": "So it's really like Super basic, so if you take any convex function gradient decent OK, you just let further gradient and here you will see on that simple algorithm the impact of strong connectivity.",
                    "label": 0
                },
                {
                    "sent": "So if you are really strongly convex so if you have curved in every direction and in 2D this is like you are really like both shape then Kennedy said we converge very quickly like for bullet converges in one iteration of course, but if you have like a bit less than a bowl baby convert like linearly.",
                    "label": 0
                },
                {
                    "sent": "So the global team meaning that the convergence as an exponential exponential rate.",
                    "label": 0
                },
                {
                    "sent": "So this is for Stony convex functions, and as soon as we get that functions which are more in condition like something like this, then you can start to make smaller step and then.",
                    "label": 1
                },
                {
                    "sent": "But you can show that you converge only at rate one.",
                    "label": 0
                },
                {
                    "sent": "Averting so easy problem hard problem.",
                    "label": 0
                },
                {
                    "sent": "But the key here and that dissent is adaptive to that complexity.",
                    "label": 0
                },
                {
                    "sent": "You don't need to tell the algorithm if you're going to be hard.",
                    "label": 0
                },
                {
                    "sent": "Easy, we just run it and it's fully adaptive and does the best that it can, so it's not optimal.",
                    "label": 0
                },
                {
                    "sent": "You can improve a bit from University.",
                    "label": 0
                },
                {
                    "sent": "Probably the constant, but essentially gradient descent already does most most of the work.",
                    "label": 1
                },
                {
                    "sent": "Then you have Newton, OK, but you replaces killer gain or the gradient by the metrics metrics gain.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So it's hard to implement in practice with WPP.",
                    "label": 0
                },
                {
                    "sent": "Is logical.",
                    "label": 0
                },
                {
                    "sent": "You have to solve it in our system, but then you go from linear convergence to aquatic convergence, not used a lot for large scale inference, but since I'm going to mention it later in the talk, let's go, let's keep it here.",
                    "label": 0
                },
                {
                    "sent": "So this is for any any convex function, so that is different in machine learning that we don't optimize any convex function and our problems would be different the 1st.",
                    "label": 1
                },
                {
                    "sent": "So first inside by both 2 and Bousquet that first when you optimize an average typically averages will vary with the standard deviation of one over root North.",
                    "label": 0
                },
                {
                    "sent": "So if you ask for a procedure which is lower than one over root N, you optimize about the noise, so it's useless to have to add like Optima up to machine precision.",
                    "label": 0
                },
                {
                    "sent": "So essentially it is waste food to use new term to arrange like to get the last last digits and surrounding inside very important.",
                    "label": 0
                },
                {
                    "sent": "Our cost functions are not anything is another edge of functions so we can take this.",
                    "label": 1
                },
                {
                    "sent": "We take advantage of this.",
                    "label": 0
                },
                {
                    "sent": "This is the topic of the talk of today on the Testek approximation.",
                    "label": 0
                },
                {
                    "sent": "So what these are?",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Graphical proximation will be to minimize the function F OK convex function, but you don't observe F. You only observe like unbiased version of the gradients.",
                    "label": 1
                },
                {
                    "sent": "So if you could have the gradient will get decent but you just get a noisy estimated gradient and you never can text.",
                    "label": 0
                },
                {
                    "sent": "This will mean F will be could be F will be the tester on OK.",
                    "label": 0
                },
                {
                    "sent": "So the key here is that the formulation in stochastic approximation is a direct meaning.",
                    "label": 0
                },
                {
                    "sent": "Implicit minimization of the test error.",
                    "label": 0
                },
                {
                    "sent": "So all of the bound that people get all the results are not on your training data.",
                    "label": 0
                },
                {
                    "sent": "But this is an interesting data, so of course we don't have access to F. You don't have access to a creditor of F, but if you sample single payer observation AYNXN and you could FN the loss for a single observation trivially, you have that the gradient of the expected loss is simply the expectation of a gradient of the loss of a single observation.",
                    "label": 1
                },
                {
                    "sent": "OK, this season, that hour of services, like a very simple, so we consider like unbiased gradients by taking the gradient of a single observation.",
                    "label": 0
                },
                {
                    "sent": "OK, and this is the web going to use that to classic approximation in this in this work.",
                    "label": 0
                },
                {
                    "sent": "So clearly the field of stochastic approximation goes far beyond like convex optimization.",
                    "label": 1
                },
                {
                    "sent": "But here in that topic consider or sub case on which we can really say a lot of things.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what is the key?",
                    "label": 0
                },
                {
                    "sent": "The key algorithm in that set up?",
                    "label": 1
                },
                {
                    "sent": "This is that problems window, also known as the plastic surgeon decent at every time step you go from one to N by going down this negative gradient of your local function.",
                    "label": 0
                },
                {
                    "sent": "Here it depends only on the single observation.",
                    "label": 0
                },
                {
                    "sent": "And here I've met a subtle change from going from T as an index to end this on purpose because in stochastic approximation the number of iterations is equal to the number of observations.",
                    "label": 0
                },
                {
                    "sent": "So T is equal to N. So we always use N as an indexed set.",
                    "label": 0
                },
                {
                    "sent": "You see the data only only once, so it used to calculate on this end and the key improvement which looks like super trivial.",
                    "label": 0
                },
                {
                    "sent": "You just replacing the last iterate when you want to predict by the other edge of all iterates.",
                    "label": 0
                },
                {
                    "sent": "OK, this is called preocupa raging.",
                    "label": 0
                },
                {
                    "sent": "And the key question now is what should be the learning rate sequence?",
                    "label": 1
                },
                {
                    "sent": "OK, so for anybody who has tried to implement the President sent, this is a test part.",
                    "label": 0
                },
                {
                    "sent": "OK, so essentially you want typically gamma to go down to zero.",
                    "label": 0
                },
                {
                    "sent": "So if.",
                    "label": 0
                },
                {
                    "sent": "Most most of you will have read or learn that typically the sum of gamma should be diverging and there is some of that square will be converging.",
                    "label": 0
                },
                {
                    "sent": "OK, this is what you typically learn in that set up.",
                    "label": 0
                },
                {
                    "sent": "This is lack true in very like very condition problem.",
                    "label": 0
                },
                {
                    "sent": "OK, so typically the set that's the same size of one of our North which is diverging and the squares converging is not adapted to large scale problem.",
                    "label": 0
                },
                {
                    "sent": "OK and people have gone to larger step sizes.",
                    "label": 0
                },
                {
                    "sent": "And as it is a topic of before I go on just mentioned the holding time.",
                    "label": 0
                },
                {
                    "sent": "OK, by design the running time is linear in North since I see that at points on the early months.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Upside only once, then it already by design it's a single path with data OK, which is often interesting, particularly when you have to compute features on your data.",
                    "label": 0
                },
                {
                    "sent": "You compute them once and then you can throw them away.",
                    "label": 0
                },
                {
                    "sent": "And finally, it's one line of code.",
                    "label": 0
                },
                {
                    "sent": "OK, so clearly it's phone line of code among many, many many other lines of code.",
                    "label": 0
                },
                {
                    "sent": "OK, so accesses data is a lot of lines of code with the learning part is really tiny.",
                    "label": 0
                },
                {
                    "sent": "OK, and today we need to consider that tiny line which can make a big difference.",
                    "label": 0
                },
                {
                    "sent": "As well as many other lines of code.",
                    "label": 0
                },
                {
                    "sent": "OK, I don't mean to say one is more important than the other, but I'm focusing more on that on that part.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Go to what is known about the problem so that these are the best possible performance penalties you can achieve.",
                    "label": 0
                },
                {
                    "sent": "This is also known to be related to strong convexity, so if your problem as curvature then it's easy.",
                    "label": 0
                },
                {
                    "sent": "And if it does, it doesn't have curvature.",
                    "label": 0
                },
                {
                    "sent": "It's hard and the best we can do is that over result from Europe scheduled in from the 80s is if you're strongly convex you'll get convergence rate of one of our new.",
                    "label": 1
                },
                {
                    "sent": "So this means that the best you make the difference between your your test error.",
                    "label": 0
                },
                {
                    "sent": "And the best possibilities there are in your class goes down to zero as one of our immune and this this is achieved by stochastic descent with a certain step size, whereas it would just only convex lens.",
                    "label": 0
                },
                {
                    "sent": "Again high dimensions, then the best you can do is one of Ruth and this is achieved by bigger step size, because here we see that there is like a mismatch.",
                    "label": 0
                },
                {
                    "sent": "Productivity of plastic surgeon dissent.",
                    "label": 1
                },
                {
                    "sent": "Depending on the hardness of the problem, you may need to use different different step sizes.",
                    "label": 0
                },
                {
                    "sent": "So in other words, from a more optimization, which will global manasam projects are always true for every end.",
                    "label": 0
                },
                {
                    "sent": "But there was another line of work more on this task community and particular word bipolar can reduce key in the 90s, showing that if you have moose, if you add this assumption of smoothness OK which those ones were not, but not adding then you can quickly if Ed is large enough you can you can get it can be hard pressed to air conditioning and for any step sizes which is between between those.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is like the most the most important related works and the goal for today is trying to mix everything in a single algorithm.",
                    "label": 1
                },
                {
                    "sent": "OK, with going to be adaptive to harness of the problem and even better get rid of these different lengths of new.",
                    "label": 0
                },
                {
                    "sent": "OK so you you should think of me as being very small.",
                    "label": 0
                },
                {
                    "sent": "OK so if when you goes down to there was one of our one of our things are not good to go.",
                    "label": 0
                },
                {
                    "sent": "OK so you have to be careful in about this.",
                    "label": 0
                },
                {
                    "sent": "So mu is quite small and the goal will be to get a similar rhythm.",
                    "label": 0
                },
                {
                    "sent": "With the confidence which is gonna rain in alterations.",
                    "label": 0
                },
                {
                    "sent": "OK, so here you should question.",
                    "label": 0
                },
                {
                    "sent": "But there were lower bounds here, which I cannot be.",
                    "label": 0
                },
                {
                    "sent": "So what am I going to add to the problem?",
                    "label": 0
                },
                {
                    "sent": "I'm going to add smoothness.",
                    "label": 0
                },
                {
                    "sent": "OK, so you impose a smooth, you allow smoothness and now you can build those lower bounds.",
                    "label": 0
                },
                {
                    "sent": "And this is the main topic.",
                    "label": 0
                },
                {
                    "sent": "Of three.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in fact we're going to see at least squares first.",
                    "label": 0
                },
                {
                    "sent": "The simple simple problem.",
                    "label": 0
                },
                {
                    "sent": "Firstly square.",
                    "label": 0
                },
                {
                    "sent": "So this is a square loss.",
                    "label": 0
                },
                {
                    "sent": "Is that context?",
                    "label": 0
                },
                {
                    "sent": "SGD is often called at least mean square LMS.",
                    "label": 0
                },
                {
                    "sent": "And it is usually studied with like without a Virgin and typically with decreasing step sizes and most often with a invertible covariance matrix.",
                    "label": 0
                },
                {
                    "sent": "So what we have done with the aqualine is first to take something which is not new.",
                    "label": 0
                },
                {
                    "sent": "OK, we simply took.",
                    "label": 0
                },
                {
                    "sent": "Event, but instead of trying to decide between the owner and step size or one of the whole 10 step side, we took a constant step size.",
                    "label": 0
                },
                {
                    "sent": "OK, take a constant step size.",
                    "label": 0
                },
                {
                    "sent": "We can also give a very valued the constraint the best.",
                    "label": 0
                },
                {
                    "sent": "OK, our best constant.",
                    "label": 0
                },
                {
                    "sent": "We depend on the edges of your features.",
                    "label": 0
                },
                {
                    "sent": "Typically you know the edges of your features, so you this you need to know for logarithm.",
                    "label": 0
                },
                {
                    "sent": "Take that step size.",
                    "label": 0
                },
                {
                    "sent": "If you assume your noise is bounded, you don't need to know the noise value places for the band.",
                    "label": 0
                },
                {
                    "sent": "Only then independently of.",
                    "label": 0
                },
                {
                    "sent": "So the hardness of edge even in edge is very, very small eigenvalues.",
                    "label": 0
                },
                {
                    "sent": "Then we can show that that very simple algorithm, constant step size averaged SGD gets gets you about like this.",
                    "label": 0
                },
                {
                    "sent": "So just to pass this data star is the optimal predictor in your class.",
                    "label": 0
                },
                {
                    "sent": "If you if you if your test there are antiparallel minus one or N is the average predictor and this is a random because you assumed your data random.",
                    "label": 0
                },
                {
                    "sent": "OK, so we take expectations over the 100 Ness of the data and you can see that it goes down as one of our North with two classical terms, one valence term OKC mask.",
                    "label": 0
                },
                {
                    "sent": "We happy over North and one bias term which is right at which you forget initial conditions for the experts in like in minimax theory, in the room, that term seem magically appeared on Earth.",
                    "label": 0
                },
                {
                    "sent": "Cannot be improved.",
                    "label": 0
                },
                {
                    "sent": "This is a mini Max lower bound for statistiques even if you have no constraints and computation.",
                    "label": 0
                },
                {
                    "sent": "Whereas this one that can probably be can probably be improved, but the key here is the absence of you.",
                    "label": 0
                },
                {
                    "sent": "There is no you'll get one of our end and without any presence of the of the condition number.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's try to see why why it should work, and inside you can get this 1 / N rate you can get with no computation.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is a good of this slide is to show that.",
                    "label": 0
                },
                {
                    "sent": "You could, if I could have like 7 other end directly, so you see the reaction for least squares.",
                    "label": 0
                },
                {
                    "sent": "It's Peter gradient of FN and at all, so basic approximation algorithms you have a Markov chain, so you're iterates from the Markov chain.",
                    "label": 0
                },
                {
                    "sent": "OK, this is because you have idea data here, but because our step size is constant, the Markov chain is homogeneous.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is not the case when Grandma goes to zero, you don't get the homogeneous Markov chain where here we do.",
                    "label": 1
                },
                {
                    "sent": "So if you make exception is going to converge to a stationary distribution.",
                    "label": 1
                },
                {
                    "sent": "Which are called by Afghan ah.",
                    "label": 0
                },
                {
                    "sent": "So what you usually think of is that your resume you started as you roll your initial point.",
                    "label": 0
                },
                {
                    "sent": "You move around and at the end you follow like a special distribution, so you will see late around the point so you never converge.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is an algorithm before leveraging that will not convert an OC later around a certain value which we called it a bar of gamma.",
                    "label": 0
                },
                {
                    "sent": "The key is that police squares that about gamma is your optimal predictor.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is easier to see in one line.",
                    "label": 0
                },
                {
                    "sent": "Just computing stations because the identity is a linear function.",
                    "label": 0
                },
                {
                    "sent": "Then you'll see late OK like this.",
                    "label": 0
                },
                {
                    "sent": "So here what we leveraging do value is simply make sure that proof you go closer and closer to your global optimum and even better in terms of rates of convergence.",
                    "label": 0
                },
                {
                    "sent": "Edward Excel ramps here to ensure that the distance between the two will go down as one over with North.",
                    "label": 0
                },
                {
                    "sent": "And since we consider like we measure performance in squared distances, it's one of our end.",
                    "label": 0
                },
                {
                    "sent": "So in the standard file that we get one of our end.",
                    "label": 0
                },
                {
                    "sent": "For that matter, with them like I've already GD with constant step size is almost like image it from from the set up of course what is not.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If y'all is what is here, OK, but is the exact variance term and the federal guidance team does not depend on.",
                    "label": 0
                },
                {
                    "sent": "There's not depend on the condition number.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Very very big data in 20 dimensions.",
                    "label": 0
                },
                {
                    "sent": "OK, there we go, a bit bigger or in the one slide.",
                    "label": 0
                },
                {
                    "sent": "OK so this is like just 20 dimensions in all of my plugs.",
                    "label": 0
                },
                {
                    "sent": "This is N number of iterations or number observations in a log log scale and distance to optimum in a log scale as well.",
                    "label": 0
                },
                {
                    "sent": "In playing this is without damaging.",
                    "label": 0
                },
                {
                    "sent": "Anecdote is before bridging, so I've tried several values of the step size are constant step sizes with different values.",
                    "label": 0
                },
                {
                    "sent": "Plus like predicting step size.",
                    "label": 0
                },
                {
                    "sent": "As you can see, before doing averaging login dot in, you don't converge and UCLA situations.",
                    "label": 0
                },
                {
                    "sent": "So this is this is normal or hard.",
                    "label": 0
                },
                {
                    "sent": "As soon as you do averaging you start to go down as a line and those sort of that line is your curfew.",
                    "label": 0
                },
                {
                    "sent": "Carefully is minus one.",
                    "label": 0
                },
                {
                    "sent": "OK, so just an illustration of this.",
                    "label": 0
                },
                {
                    "sent": "One of our end step size with a very strong difference between before origin or you don't conversion after urging, but you do converge, whereas if you take the decaying step size of course your interesar before arising or a bit better but.",
                    "label": 0
                },
                {
                    "sent": "After averaging, they perform worse than the.",
                    "label": 0
                },
                {
                    "sent": "At least at the beginning, as without average.",
                    "label": 0
                },
                {
                    "sent": "So this is for Snow Day.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, for bigger data so of course like standard benchmarks for optimization like being quite small and large N and then typical data from a news from tech data when P is very large you have a lot of lot of features, but many of them are equal to the oh and so here I have two columns so I have two lines.",
                    "label": 0
                },
                {
                    "sent": "This is like one that I said that I said I have two columns because typically in most optimization works you have like a hidden factor which is a step size.",
                    "label": 0
                },
                {
                    "sent": "So yeah, the step size for the bound and then get the step size for the experiments.",
                    "label": 0
                },
                {
                    "sent": "Typically those two are different, so on the left is a step size from the bound.",
                    "label": 0
                },
                {
                    "sent": "OK, so the one I propose another value step size.",
                    "label": 0
                },
                {
                    "sent": "If you, after all, future actions, which is a standard practice.",
                    "label": 0
                },
                {
                    "sent": "So this is just just loads that we're doing here.",
                    "label": 0
                },
                {
                    "sent": "You have to try several of them and take the best one at the end.",
                    "label": 0
                },
                {
                    "sent": "So here you can see the difference between like one of the red curve.",
                    "label": 0
                },
                {
                    "sent": "So between like blue which is constant and green which is decaying.",
                    "label": 0
                },
                {
                    "sent": "Then if you use a step size of the bound for the decaying step size, the constant is too small, so at the end it goes very slow for very long OK, whereas if you allowed to for the decaying step size to learn the concerns then you can do quite well at the end.",
                    "label": 0
                },
                {
                    "sent": "But it's at the price of adding C being violated, the beginning.",
                    "label": 0
                },
                {
                    "sent": "OK, so here you see the log scale.",
                    "label": 0
                },
                {
                    "sent": "This means that if you want to achieve like good performance here, you need a taxi so big that you need to start to diverge, which is really not not not good in practice, whereas if you take amerge, slower decay and nudity at all, and whether you take the step size of the band or the best possible step side, we get similar behavior.",
                    "label": 0
                },
                {
                    "sent": "So this is really key to be able to give to give step aside, which is Robert a different aspect of the problem and the constant step size.",
                    "label": 0
                },
                {
                    "sent": "Either is there such a thing?",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so this works for the squares, but of course people do not only care only about his squares, or do I think maybe it's sufficient for many, many things.",
                    "label": 0
                },
                {
                    "sent": "But let's go logistic.",
                    "label": 0
                },
                {
                    "sent": "OK, so the same Markov chain setup can be can be used.",
                    "label": 0
                },
                {
                    "sent": "We have a Markov chain which is Imagineers, so it does converge also too, especially distribution.",
                    "label": 1
                },
                {
                    "sent": "And the way you can verify that the what you can say about that stationary distribution of their own.",
                    "label": 0
                },
                {
                    "sent": "But the problem now is that because the credit is not a linear function anymore, you cannot invert brightness spec tations.",
                    "label": 0
                },
                {
                    "sent": "So the gradient at your average value is not zero.",
                    "label": 0
                },
                {
                    "sent": "OK, so this means that you will get a similar setup that oscillate around value, but that value is away from the true value from the true value.",
                    "label": 0
                },
                {
                    "sent": "So if you do an origin, you going to converge quickly too.",
                    "label": 0
                },
                {
                    "sent": "Long value.",
                    "label": 0
                },
                {
                    "sent": "OK, so the fact that constant step study does not converge.",
                    "label": 0
                },
                {
                    "sent": "The event was known before May just in the world set of Markov chains.",
                    "label": 0
                },
                {
                    "sent": "It's in pretty sure that you converge quickly to on value.",
                    "label": 0
                },
                {
                    "sent": "What you can show that by doing leveraging you get a bit closer to the test are, but you never get to the desktop, so this can be shown in simulations at the same exact simulation that replacing the square.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Logistic loss we had before leveraging this is inducted.",
                    "label": 0
                },
                {
                    "sent": "You don't converge exact same plot, but when you do averaging you go quickly to a place and you study.",
                    "label": 0
                },
                {
                    "sent": "This study lies.",
                    "label": 0
                },
                {
                    "sent": "So you convert those late anymore.",
                    "label": 0
                },
                {
                    "sent": "But the whole point which does not work 220 or in here since I've logged plots to medicine Infinity.",
                    "label": 0
                },
                {
                    "sent": "So you get this this surprising behavior.",
                    "label": 0
                },
                {
                    "sent": "So of course if you take smaller step sizes you saturate at better point.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is also known as well that if you take a constant state.",
                    "label": 0
                },
                {
                    "sent": "It was a constant, is small enough you don't convertible optimum, but to place which might be good enough.",
                    "label": 0
                },
                {
                    "sent": "But the world today would be to replace all of this by a single a single line, Yep.",
                    "label": 0
                },
                {
                    "sent": "Back to the last one.",
                    "label": 0
                },
                {
                    "sent": "But you know it pulls you in One Direction or the other.",
                    "label": 0
                },
                {
                    "sent": "I too miss might not only now there's a Disney now so it can be.",
                    "label": 0
                },
                {
                    "sent": "You may have different forms, but asymmetry can be also good thing.",
                    "label": 0
                },
                {
                    "sent": "It goes good explanation at the end.",
                    "label": 0
                },
                {
                    "sent": "You don't converge to the global optimum if you use a small step size, but these are steps is dialyzed more.",
                    "label": 0
                },
                {
                    "sent": "You converge very very close, OK and in fact we can.",
                    "label": 0
                },
                {
                    "sent": "In fact we have bounds of bounds on the distance to optimum depending on the step size and.",
                    "label": 0
                },
                {
                    "sent": "So the goal will be to restore convergence at the garden, and in fact it's almost like with no.",
                    "label": 0
                },
                {
                    "sent": "We know a motivating to do this much time.",
                    "label": 0
                },
                {
                    "sent": "About 2 minutes OK.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Swollen so we're going to consider like a let's me just forget that slide and simply.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To distract algorithm, so we're going to do.",
                    "label": 0
                },
                {
                    "sent": "We're going to do a little step.",
                    "label": 0
                },
                {
                    "sent": "OK, so we know how to minimize cratic functions.",
                    "label": 0
                },
                {
                    "sent": "I've just presented it so now, what do we do instead?",
                    "label": 0
                },
                {
                    "sent": "Newton step is going to minimize aquatic function, so if you want to do and you don't step on the expected loss.",
                    "label": 0
                },
                {
                    "sent": "The Taylor approximation is also is aquatic function, which is also an expectation.",
                    "label": 0
                },
                {
                    "sent": "So if you want to do a Taylor Newton step, so minimizing this magic function, you can do it using at least mean squares OK and compute compute gradients of that Taylor expansion and you get like a first order term and 2nd order term.",
                    "label": 0
                },
                {
                    "sent": "But the key here is that you have relation to the Asian is PDP OK so you might think there is going to be at least be square but never context where we consider linear predictions.",
                    "label": 0
                },
                {
                    "sent": "The Hastiness Hank one.",
                    "label": 0
                },
                {
                    "sent": "OK, so you see the second of the loss with respect to the second variable time.",
                    "label": 0
                },
                {
                    "sent": "So I think one metrics for that like Hessian matrix vector product can be done of P. So at the end you can do that online.",
                    "label": 0
                },
                {
                    "sent": "Newton steps only buy online, you don't step by the same complexity as regular regular organization.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So at the end, forget about this one.",
                    "label": 0
                },
                {
                    "sent": "Look at this.",
                    "label": 0
                },
                {
                    "sent": "So what is about the rhythm we're going to do back?",
                    "label": 0
                },
                {
                    "sent": "Implicitly?",
                    "label": 0
                },
                {
                    "sent": "Newton step, but we have to decide what are we doing and what are we going to do.",
                    "label": 0
                },
                {
                    "sent": "Need to step around.",
                    "label": 0
                },
                {
                    "sent": "OK we need to find another point and the pool we going to use is our current average iterate.",
                    "label": 0
                },
                {
                    "sent": "OK, so remember that throughout the algorithm we have the fascinating design, but we have the convergence Florida bar and begin to replace the true gradient here by the 1st order.",
                    "label": 0
                },
                {
                    "sent": "Oximeter agent around your current average iterate OK, and this is the same capacity as before, and we are.",
                    "label": 0
                },
                {
                    "sent": "We have like a tune down version for we can prove this over an organ about convergence rate without any appearance of you before that one that works very well.",
                    "label": 0
                },
                {
                    "sent": "We are still trying to prove the convergence rate, and let's see how it works.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this was logistically this would be my last slide, so before conclusion.",
                    "label": 0
                },
                {
                    "sent": "So this is before local versions and as soon as you start to do this online you can step which has the same capacity as before you restore convergence.",
                    "label": 0
                },
                {
                    "sent": "And this is true for smooth data, but it is also true for bigger than that.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which I will present.",
                    "label": 0
                },
                {
                    "sent": "So you conclude.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we've been able to go beyond like this one of our new barrier by opposing.",
                    "label": 0
                },
                {
                    "sent": "The smoothness is very low.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Possible extensions, particular, of course, nonconvex problems, parallelization, non differentiability.",
                    "label": 0
                },
                {
                    "sent": "So I don't think hostility at parity is good, but it's possible that talk and also plan out because I think this could be interesting as well.",
                    "label": 0
                },
                {
                    "sent": "Thank you for your attention.",
                    "label": 0
                }
            ]
        }
    }
}