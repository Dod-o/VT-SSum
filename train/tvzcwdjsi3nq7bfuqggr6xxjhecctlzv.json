{
    "id": "tvzcwdjsi3nq7bfuqggr6xxjhecctlzv",
    "title": "A Dataset for Web-scale Knowledge Base Population",
    "info": {
        "author": [
            "Michael Glass, IBM Research"
        ],
        "published": "July 10, 2018",
        "recorded": "June 2018",
        "category": [
            "Top->Computer Science->Big Data",
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/eswc2018_glass_base_population/",
    "segmentation": [
        [
            "Hi Michael, this is data set we built for knowledge based population both to evaluate methods and for purposes of transfer learning.",
            "We've already found it useful at IBM for a few different research paths.",
            "And we hope it will be more useful generally.",
            "So we release this data set to the Community.",
            "So basically will go through the knowledge based population task, both an overview and a breakdown in terms of its sub tasks such as any detection and linking context set, construction, relation prediction and even reasoning."
        ],
        [
            "Then we'll examine the existing data sets that are available for this kind of benchmarking task and then go through how we constructed this data set, emphasizing its modular architecture.",
            "Finally, we have some statistics of the data set going through its Internet in relation types, as well as some important aspects fact that it's a multi instance and multi label task."
        ],
        [
            "So knowledge based population as I'm sure many of us are aware, we're growing a knowledge graph from text, so we're potentially adding new entities and will certainly adding new relations between entities.",
            "This will output a confidence.",
            "One part of the confidence is of course, because our approaches to CBP are not perfect, so there will be some uncertainty, but even the text itself is not always indicating what exactly is the relation between the two entities, so there's that source of uncertainty as well.",
            "It's contrasted with KBC knowledge base completion, especially in that it's from text and we're getting new entities."
        ],
        [
            "So their motivation here is that we want a data set that number one is open, so we want to be available for any group to benchmark against and have comperable results between different methods.",
            "And it's also important.",
            "It's large, so we want you know.",
            "Certainly enough for us to statistical significance and test.",
            "Which you can achieve with a fairly moderate data set.",
            "But there's also this point of context aggregation, so predicting the relations between two entities based on multiple occurrences of them in text and the larger your corpus is, the more often that's going to happen versus a case where two hundreds are occurring only once together, and you're basically predicting only from that sentence or context.",
            "And we want to be large enough to train deep learning approaches, which are often some of the leading approaches for CBP.",
            "It's also important for this data set to be diverse.",
            "We want many relation types, not just a few relation types dominating, so that if you're good at those then your will show effectiveness on this benchmark.",
            "And it's important that the relations interact.",
            "You could have a diverse set of relations like countries capital.",
            "Movies Producer companies CEO.",
            "But there's there's no connection between these, so there's no impact from reasoning you won't be able to deduce who produced a movie based on what the capital of the country is.",
            "So what we really want some relations where there's some nice interactions, some mutually constraining features from these triples.",
            "And by being large and diverse, it also removes most of the temptation to go for tricks.",
            "It's it would be very tedious over a large and diverse data set to just write rules, so it's really encourages in a general approach.",
            "And not in the paper actually, because we hadn't tested this at the time, but we know that a large and diverse data set is also very effective for transfer learning.",
            "So if you have a different smaller schema, you'll benefit from having a source model trained on a very large data set."
        ],
        [
            "So as we said, we go a component by component of you.",
            "And this is really.",
            "The point is that we want to support.",
            "Benchmarking each of these components.",
            "So just to explain what the components are from text, we use any detection linking to find the mentions of entities that are or should be in the knowledge graph in text.",
            "And then the context that construction gathers up the context where two entities are occurring together, which of course can be multiple contexts.",
            "So it will be a set of sentences, or a set of token windows from those context sets.",
            "We do relation prediction.",
            "We predict what relation or relations is between.",
            "Exists between those two entities.",
            "Then those triples with confidence attitude, the cagey and then reasoning can be applied to adjust the confidence of any triple."
        ],
        [
            "As well as Inferno triples.",
            "We like to divide these into the prerequisite subtasks and then the Cork key tasks.",
            "EDL of course is a task on its own.",
            "Someone's only interested in EDL.",
            "They probably have their own benchmarks.",
            "But there are aspects to EDL that are more particularly CBP, so we still want to support improvements in EDL impacting our CBP benchmark.",
            "This is more important when we come to the discussion of the existing datasets, because many of these existing datasets only support the core CVP subtasks."
        ],
        [
            "So for any deduction linking, I think I already mentioned, but I just like to emphasize that there's a generalization over entities, literals and concepts which we refer to simply as nodes.",
            "So something like the Pub Corp, which is an entity which could be not in the Knowledge Base magazine, which is a concept and even literals like monthly.",
            "Here match to every month.",
            "We generalize these and just refer to them as nodes in the Knowledge Graph."
        ],
        [
            "For context, that construction, we generate things like this.",
            "So for London and the Institute for Jewish Policy Research, the relation between them is just the freebase relation or a free based location contains relation.",
            "This is indicated by some extra text, but mainly through this.",
            "Institute for Jewish Policy Research in London.",
            "It's present in both of these sentences.",
            "You could also have context sets between entities that either aren't related or they don't relate those entities.",
            "This is it's true that Steven Baby was born in Chicago, but neither of these sentence is really suggest that, although perhaps they imply that there is some kind of connection.",
            "Also, context sets need not just be sentences.",
            "Here we have a piece of Medline where the section headers are dosage and administration for phenobarbital sodium.",
            "It's already a pretty good indicator based on phenobarbital has been used in the treatment and prophylaxis of people febrile seizures, but it may be additional evidence that it's in the dosage and administration section rather than, say side effects section."
        ],
        [
            "To drill into a context.",
            "More formally, we have a context here.",
            "Of course, we have the two IDs for the entities or nodes.",
            "More generally that are being related.",
            "We also provide the types from the EDL system as well as their spans in text.",
            "The context and the relations between them.",
            "Important there can be multiple relations between them.",
            "Here the relation or the multiple relations are not that interesting, it's just using the DB pedia relation taxonomy to expand out.",
            "The member relation."
        ],
        [
            "For relation prediction we have a somewhat unusual formulation of this.",
            "It's really focused on probabilistic prediction from textual evidence.",
            "The input is a context set.",
            "As we saw before.",
            "Just a set of sentences, perhaps, and the output is a set of triples with probability.",
            "So critically in test we will of course encounter many cases where the context set for a pair of entities doesn't imply the relation that actually holds between them, so we want to make sure we encounter those cases in training as well.",
            "And I also will encounter cases where the context that only partially justifies.",
            "For example, Samuel Smith went to school in New York.",
            "Well, that does not say that he was born in New York, but it is some evidence for that.",
            "So we want some moderate probability for that."
        ],
        [
            "Reasoning here, we just define it by its input output behavior rather than more restrictive view of reasoning.",
            "We just say that it's any procedure that, given some initial set of triples with confidence, produces a new set with those conferences RE estimated.",
            "Possibly New Triples added again with some confidence.",
            "And this is a.",
            "Important because we need a knowledge level of valuation.",
            "So many benchmarks will attempt something like exhaustive annotation will try to annotate every triple that a corpus justifies.",
            "Based on it having a single justifying sentence, but as soon as you want to evaluate reasoning, this part of CBP, you really need to move to a knowledge level evaluation where you're evaluating, not based on.",
            "What you've been able to annotate in the corpus, but in what is known to be true in some knowledge base?"
        ],
        [
            "For existing KBP benchmarks there are two widely used but rather small systems or benchmarks.",
            "New York Times Freebase which just aligns the text of the New York Times with Freebase.",
            "Has about 150,000 related nodes.",
            "And it's effective for the task of relation prediction.",
            "So it's constructed the data set up to the context sets.",
            "But the.",
            "Any detection linking in context that construction is already done and.",
            "Can be modified to show impact by doing something better there.",
            "Attack CBP is quite small, so not very open.",
            "You can get it by signing an agreement.",
            "But it's not something that you can easily redistribute, although it does support many tasks.",
            "You can show him back through ADL contact set construction in relation prediction, not reasoning because they require a justifying sentence for every triple.",
            "Freebase 15 K 237 is quite large and it's effective for freezing.",
            "This is often used for knowledge based completion benchmarking.",
            "And you can use it for relation prediction as well, but it's processed up to the point of context set construction, and it has a very particular kind of context, so it's just the dependency paths between those two entities.",
            "But if you do want to predict just from the dependency paths, it is effective for that purpose.",
            "Wiki rating and T. Rex are both using Wikipedia.",
            "Wiki reading can be used for all of the tasks and is quite large, although it is only effective for title oriented documents.",
            "These are things like.",
            "Wikipedia documents where the document is all about one entity, the title.",
            "Documents are not that rare, but.",
            "They're not usually the common case.",
            "T. Rex doesn't include any of the negative examples, so doesn't include any of the unrelated entities, so it's really more real."
        ],
        [
            "Mission classification benchmark.",
            "For our data set processing.",
            "Taking the text of common crawl, we extract the text.",
            "And then.",
            "The DB pedia.",
            "We do some cagey selection so where selecting down to a subset of DB pedia.",
            "Then we do it.",
            "We apply our baseline DDL components to find the annotated text.",
            "And then do the context of construction to get context from which we can do relation prediction.",
            "And I'll talk about each of these components in detail.",
            "This is called CKD BP, because it's common crawl."
        ],
        [
            "Wendy Pedia that are being aligned.",
            "So for our text preprocessing common crawl includes more than HTML, so we are just filtering into HTML.",
            "And we're extracting just the main textual content.",
            "So many web pages have this behavior where there's some main piece of text as well as some boilerplate.",
            "And here we have this.",
            "The footer on this NPR news page.",
            "We don't really want that.",
            "So we use a boiler pipe to filter out all of this extra boilerplate.",
            "And we also filtered the desired language, in this case English."
        ],
        [
            "For Keiji selection I already mentioned that we're collapsing the distinction between resources and literals, so we're just collapsing those two nodes.",
            "And we're also taking the 400 most frequent relations.",
            "And we want to filter those down to ones that we're going to really be able to predict from text.",
            "So first of all, there's the there's the issue of node labels that are unlikely to be matched in text.",
            "Like DBO, filename was relating resource to the file name that was used on Wikipedia, DBO.",
            "Description will have as its filler some.",
            "A long block of text that's really unlikely to be in any particular webpage.",
            "Top speed will have some floating point value with the unit again difficult to match exactly.",
            "For similar reasons, we map dates to just the year.",
            "'cause a year is much easier to match in text.",
            "And we eliminate these mediator relations, so something like DBO career station that relates a person to a point in their career, which is a blank node that will then connect to some start and end date as well as their job title.",
            "The result is about 300 relations, not including the Super relations from the relation taxonomy."
        ],
        [
            "We supply a sort of baseline components for the any detection, linking, and context that construction.",
            "For any infection, Lincoln just gazeteer matching string matching of the preferred label or the string representation of the literal.",
            "In case of ambiguities of two things that have the same preferred label, we just take the more popular node, which is we measure by how many triples it participates in.",
            "DB pedia.",
            "And we're ignoring labels that occur in the corpus too frequently.",
            "These are generally things that are very generic.",
            "Sometimes kind of a mistake.",
            "An Adobe PDF where it's given a label that's too general or just a truncated label.",
            "For context construction, windows popular form of context is just the sentence, and we use open NLP force in this detection.",
            "And we're also filtering these by type pair, so we're not.",
            "Constructing all of the.",
            "Every context set for every possible entity pair, only those entity pairs that have types that have been related in our selected knowledge base."
        ],
        [
            "As I said, an important part of this is a modular architecture, so New York Times Freebase provides directly the context sets.",
            "And it's very handy for benchmarking relation prediction directly, but if there's some innovative way of selecting contexts, you can't really use this benchmark.",
            "On the other extreme, is tech PP.",
            "Where you can benchmark many different things, but you have to implement some ADL systems, some context set construction in order to get to the point where you can start working on your relation prediction system.",
            "And as we we take the modular approach, we supply the data set at each phase and the code to produce each phase.",
            "So you can start from EDL, do your own contact set construction and from there to your relation prediction or you can leverage these already provided components and just take the context that's directly.",
            "For relation prediction.",
            "And the dependency between these components is gated by this data format, which is documented in the GitHub page.",
            "So."
        ],
        [
            "CDP data set.",
            "In the Knowledge Graph is DB pedia, the Texas Common Crawl has about 3 million positive examples.",
            "And about 170 million sentences.",
            "And we support all of the tasks that we've identified.",
            "So any of these tasks can show impact on the benchmark.",
            "And this is a graph of the entity."
        ],
        [
            "Types there are present.",
            "I think.",
            "The main takeaway here is that the entity types are going beyond person placing organization.",
            "The conventional types that you can get from an NTR.",
            "We definitely have a lot of agents, so broken down into people and organization and a lot of places and locations.",
            "But there's also other things like creative works such as music and books as well as literals for strings and numbers, and this other section for species, plants, and animals, basically.",
            "For relation types."
        ],
        [
            "It is a considerable diversity, so it's really not dominated by one or two relations.",
            "There's about five relations there.",
            "Well, there's exactly 5 relations in New York Times, Freebase, that make up 83% of the positive examples.",
            "But here we get 47 different relation types before up to 80% of the positives.",
            "And they cover all many different entity types so.",
            "It's like release year.",
            "There are many location type relations.",
            "This Co participates.",
            "Relation is sort of a very general relation for someone involved in the production of something.",
            "As well as others, things like is classified by as kind of a general type.",
            "Relation can be used to connect.",
            "Something to its genre, for instance as well.",
            "Another ASP."
        ],
        [
            "This is that is a multi instance.",
            "So as I mentioned before, one of the advantages of a large data set is that.",
            "You're getting multiple contexts in order to predict the relation between the two nodes.",
            "So this is a graph showing how many shared context two nodes have.",
            "And what the distribution of that is?",
            "Certainly one is still the most common case, but there are many entity pairs that have to for up to 1000 different contexts where these two entities are Co occurring and those that really enables strategies that take advantage of many different contexts to show some impact.",
            "And as I said, there can be multiple really."
        ],
        [
            "Oceans between two nodes.",
            "This is a multi label task through, so it's still the most common cases that there is.",
            "Well, in fact, the most common cases there's no relation between two nodes is overwhelmingly the most common case.",
            "But after that, the most common case is that there's just one relation, but there's there can be up to six on.",
            "This occurs in cases relating to a person and some creative work.",
            "Sometimes somebody can produce direct star right in a film as well as I guess, two others."
        ],
        [
            "So to summarize, the key aspects, as I said, the large scale.",
            "Which is both in the size of the text and the size of the Knowledge Graph enables us to have also a lot of diversity in terms of the entity in relation types.",
            "By making it modular, we can support different subtasks, not just support them and that they can be done, but support them in the sense that they can be done right away.",
            "Relation prediction won't require the implementation of some baseline ADL and CSC of your own devising.",
            "You can just use what's there.",
            "For future work, this is not really future work is now completely work, but it's not.",
            "It's not in GitHub yet, but that's coming almost immediately.",
            "The unary contexts, and in this case we're predicting relations.",
            "From context, contain only a single node.",
            "So for example, you can think of something like has location.",
            "You could predict where something is, what country is something is in is in.",
            "Even if the country doesn't occur next to that thing, just from related things around it.",
            "Or things like record label or computing platform.",
            "You may be able to predict that a software piece of software runs on Linux without ever seeing it in proximity to Linux.",
            "Also important, we want to move beyond this baseline DDL of gazeteer matching.",
            "And we have it on GitHub as well.",
            "So if it's.",
            "Oh, it's not showing.",
            "Well.",
            "Well, you can go to get up and see.",
            "There we go.",
            "This is the data set.",
            "For my documentation that was mentioned.",
            "So.",
            "Thanks, great work.",
            "I have actually a couple of questions.",
            "Can you remind us how did you select those 45 types that are being used for the entities?",
            "Yeah, so that's kind of ad hoc.",
            "We just selected a coarse grained type system.",
            "Based on what are frequent types, so we dropped all of the infrequent types.",
            "And then.",
            "We trimmed it down so that.",
            "Each type was the most specific type for 1000 different entities.",
            "OK, so it's based on your analysis on the entire common crawl.",
            "You have a long tail of entity types being used.",
            "At some point you decided to cut the ones you wouldn't need to actually use for rotating.",
            "Yeah, I mean, it's really a property of DB pedia, that it has a lot of very specific types.",
            "And then we can cut that off to just have general types.",
            "OK, and my second question is now that you have.",
            "So if I understand correctly from the GitHub account you're showing here, anyone can run the scripts to actually rebuild the corpora, downloading the common crawl.",
            "But now, did you already try to use this data sets for training and earn a lick structures and test it on whatever over corporate to see if you get.",
            "I think this is what you submitted to ACL or something like this, right?",
            "Right?",
            "Well we have an ACL paper on the unary relations, but I think you're saying something different.",
            "You're saying run the system over a different corpus.",
            "Not common crawl.",
            "Yeah, now we haven't done that.",
            "We've done.",
            "We've done transfer learning where we do it on a different set of relations, Anna different corpus, using the model initialized from.",
            "CDP, but just applying CCP.",
            "OK, I guess that did happen, but we didn't evaluate it.",
            "OK thanks.",
            "One final question, do you have any?",
            "Idea will be using this resource already.",
            "So far the only people we know you have used it is at IBM, but we've gotten a few people trying to use it.",
            "I don't know if they've.",
            "Actually benchmarked a system where they just downloaded it to look at it.",
            "But definitely if you want to use it and you have any trouble, just feel free to create a GitHub issue or email me.",
            "Definitely interested in getting this out to the broader community."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi Michael, this is data set we built for knowledge based population both to evaluate methods and for purposes of transfer learning.",
                    "label": 0
                },
                {
                    "sent": "We've already found it useful at IBM for a few different research paths.",
                    "label": 0
                },
                {
                    "sent": "And we hope it will be more useful generally.",
                    "label": 0
                },
                {
                    "sent": "So we release this data set to the Community.",
                    "label": 0
                },
                {
                    "sent": "So basically will go through the knowledge based population task, both an overview and a breakdown in terms of its sub tasks such as any detection and linking context set, construction, relation prediction and even reasoning.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then we'll examine the existing data sets that are available for this kind of benchmarking task and then go through how we constructed this data set, emphasizing its modular architecture.",
                    "label": 0
                },
                {
                    "sent": "Finally, we have some statistics of the data set going through its Internet in relation types, as well as some important aspects fact that it's a multi instance and multi label task.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So knowledge based population as I'm sure many of us are aware, we're growing a knowledge graph from text, so we're potentially adding new entities and will certainly adding new relations between entities.",
                    "label": 0
                },
                {
                    "sent": "This will output a confidence.",
                    "label": 0
                },
                {
                    "sent": "One part of the confidence is of course, because our approaches to CBP are not perfect, so there will be some uncertainty, but even the text itself is not always indicating what exactly is the relation between the two entities, so there's that source of uncertainty as well.",
                    "label": 0
                },
                {
                    "sent": "It's contrasted with KBC knowledge base completion, especially in that it's from text and we're getting new entities.",
                    "label": 1
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So their motivation here is that we want a data set that number one is open, so we want to be available for any group to benchmark against and have comperable results between different methods.",
                    "label": 0
                },
                {
                    "sent": "And it's also important.",
                    "label": 0
                },
                {
                    "sent": "It's large, so we want you know.",
                    "label": 0
                },
                {
                    "sent": "Certainly enough for us to statistical significance and test.",
                    "label": 1
                },
                {
                    "sent": "Which you can achieve with a fairly moderate data set.",
                    "label": 0
                },
                {
                    "sent": "But there's also this point of context aggregation, so predicting the relations between two entities based on multiple occurrences of them in text and the larger your corpus is, the more often that's going to happen versus a case where two hundreds are occurring only once together, and you're basically predicting only from that sentence or context.",
                    "label": 0
                },
                {
                    "sent": "And we want to be large enough to train deep learning approaches, which are often some of the leading approaches for CBP.",
                    "label": 1
                },
                {
                    "sent": "It's also important for this data set to be diverse.",
                    "label": 1
                },
                {
                    "sent": "We want many relation types, not just a few relation types dominating, so that if you're good at those then your will show effectiveness on this benchmark.",
                    "label": 0
                },
                {
                    "sent": "And it's important that the relations interact.",
                    "label": 0
                },
                {
                    "sent": "You could have a diverse set of relations like countries capital.",
                    "label": 0
                },
                {
                    "sent": "Movies Producer companies CEO.",
                    "label": 0
                },
                {
                    "sent": "But there's there's no connection between these, so there's no impact from reasoning you won't be able to deduce who produced a movie based on what the capital of the country is.",
                    "label": 0
                },
                {
                    "sent": "So what we really want some relations where there's some nice interactions, some mutually constraining features from these triples.",
                    "label": 0
                },
                {
                    "sent": "And by being large and diverse, it also removes most of the temptation to go for tricks.",
                    "label": 0
                },
                {
                    "sent": "It's it would be very tedious over a large and diverse data set to just write rules, so it's really encourages in a general approach.",
                    "label": 1
                },
                {
                    "sent": "And not in the paper actually, because we hadn't tested this at the time, but we know that a large and diverse data set is also very effective for transfer learning.",
                    "label": 0
                },
                {
                    "sent": "So if you have a different smaller schema, you'll benefit from having a source model trained on a very large data set.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So as we said, we go a component by component of you.",
                    "label": 0
                },
                {
                    "sent": "And this is really.",
                    "label": 0
                },
                {
                    "sent": "The point is that we want to support.",
                    "label": 0
                },
                {
                    "sent": "Benchmarking each of these components.",
                    "label": 0
                },
                {
                    "sent": "So just to explain what the components are from text, we use any detection linking to find the mentions of entities that are or should be in the knowledge graph in text.",
                    "label": 0
                },
                {
                    "sent": "And then the context that construction gathers up the context where two entities are occurring together, which of course can be multiple contexts.",
                    "label": 0
                },
                {
                    "sent": "So it will be a set of sentences, or a set of token windows from those context sets.",
                    "label": 1
                },
                {
                    "sent": "We do relation prediction.",
                    "label": 0
                },
                {
                    "sent": "We predict what relation or relations is between.",
                    "label": 0
                },
                {
                    "sent": "Exists between those two entities.",
                    "label": 0
                },
                {
                    "sent": "Then those triples with confidence attitude, the cagey and then reasoning can be applied to adjust the confidence of any triple.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As well as Inferno triples.",
                    "label": 0
                },
                {
                    "sent": "We like to divide these into the prerequisite subtasks and then the Cork key tasks.",
                    "label": 1
                },
                {
                    "sent": "EDL of course is a task on its own.",
                    "label": 0
                },
                {
                    "sent": "Someone's only interested in EDL.",
                    "label": 0
                },
                {
                    "sent": "They probably have their own benchmarks.",
                    "label": 0
                },
                {
                    "sent": "But there are aspects to EDL that are more particularly CBP, so we still want to support improvements in EDL impacting our CBP benchmark.",
                    "label": 0
                },
                {
                    "sent": "This is more important when we come to the discussion of the existing datasets, because many of these existing datasets only support the core CVP subtasks.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for any deduction linking, I think I already mentioned, but I just like to emphasize that there's a generalization over entities, literals and concepts which we refer to simply as nodes.",
                    "label": 0
                },
                {
                    "sent": "So something like the Pub Corp, which is an entity which could be not in the Knowledge Base magazine, which is a concept and even literals like monthly.",
                    "label": 1
                },
                {
                    "sent": "Here match to every month.",
                    "label": 1
                },
                {
                    "sent": "We generalize these and just refer to them as nodes in the Knowledge Graph.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For context, that construction, we generate things like this.",
                    "label": 0
                },
                {
                    "sent": "So for London and the Institute for Jewish Policy Research, the relation between them is just the freebase relation or a free based location contains relation.",
                    "label": 0
                },
                {
                    "sent": "This is indicated by some extra text, but mainly through this.",
                    "label": 0
                },
                {
                    "sent": "Institute for Jewish Policy Research in London.",
                    "label": 1
                },
                {
                    "sent": "It's present in both of these sentences.",
                    "label": 0
                },
                {
                    "sent": "You could also have context sets between entities that either aren't related or they don't relate those entities.",
                    "label": 0
                },
                {
                    "sent": "This is it's true that Steven Baby was born in Chicago, but neither of these sentence is really suggest that, although perhaps they imply that there is some kind of connection.",
                    "label": 0
                },
                {
                    "sent": "Also, context sets need not just be sentences.",
                    "label": 0
                },
                {
                    "sent": "Here we have a piece of Medline where the section headers are dosage and administration for phenobarbital sodium.",
                    "label": 0
                },
                {
                    "sent": "It's already a pretty good indicator based on phenobarbital has been used in the treatment and prophylaxis of people febrile seizures, but it may be additional evidence that it's in the dosage and administration section rather than, say side effects section.",
                    "label": 1
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To drill into a context.",
                    "label": 0
                },
                {
                    "sent": "More formally, we have a context here.",
                    "label": 0
                },
                {
                    "sent": "Of course, we have the two IDs for the entities or nodes.",
                    "label": 0
                },
                {
                    "sent": "More generally that are being related.",
                    "label": 0
                },
                {
                    "sent": "We also provide the types from the EDL system as well as their spans in text.",
                    "label": 0
                },
                {
                    "sent": "The context and the relations between them.",
                    "label": 0
                },
                {
                    "sent": "Important there can be multiple relations between them.",
                    "label": 0
                },
                {
                    "sent": "Here the relation or the multiple relations are not that interesting, it's just using the DB pedia relation taxonomy to expand out.",
                    "label": 0
                },
                {
                    "sent": "The member relation.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For relation prediction we have a somewhat unusual formulation of this.",
                    "label": 0
                },
                {
                    "sent": "It's really focused on probabilistic prediction from textual evidence.",
                    "label": 1
                },
                {
                    "sent": "The input is a context set.",
                    "label": 1
                },
                {
                    "sent": "As we saw before.",
                    "label": 1
                },
                {
                    "sent": "Just a set of sentences, perhaps, and the output is a set of triples with probability.",
                    "label": 1
                },
                {
                    "sent": "So critically in test we will of course encounter many cases where the context set for a pair of entities doesn't imply the relation that actually holds between them, so we want to make sure we encounter those cases in training as well.",
                    "label": 0
                },
                {
                    "sent": "And I also will encounter cases where the context that only partially justifies.",
                    "label": 0
                },
                {
                    "sent": "For example, Samuel Smith went to school in New York.",
                    "label": 1
                },
                {
                    "sent": "Well, that does not say that he was born in New York, but it is some evidence for that.",
                    "label": 0
                },
                {
                    "sent": "So we want some moderate probability for that.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Reasoning here, we just define it by its input output behavior rather than more restrictive view of reasoning.",
                    "label": 1
                },
                {
                    "sent": "We just say that it's any procedure that, given some initial set of triples with confidence, produces a new set with those conferences RE estimated.",
                    "label": 0
                },
                {
                    "sent": "Possibly New Triples added again with some confidence.",
                    "label": 0
                },
                {
                    "sent": "And this is a.",
                    "label": 0
                },
                {
                    "sent": "Important because we need a knowledge level of valuation.",
                    "label": 0
                },
                {
                    "sent": "So many benchmarks will attempt something like exhaustive annotation will try to annotate every triple that a corpus justifies.",
                    "label": 0
                },
                {
                    "sent": "Based on it having a single justifying sentence, but as soon as you want to evaluate reasoning, this part of CBP, you really need to move to a knowledge level evaluation where you're evaluating, not based on.",
                    "label": 0
                },
                {
                    "sent": "What you've been able to annotate in the corpus, but in what is known to be true in some knowledge base?",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For existing KBP benchmarks there are two widely used but rather small systems or benchmarks.",
                    "label": 1
                },
                {
                    "sent": "New York Times Freebase which just aligns the text of the New York Times with Freebase.",
                    "label": 0
                },
                {
                    "sent": "Has about 150,000 related nodes.",
                    "label": 0
                },
                {
                    "sent": "And it's effective for the task of relation prediction.",
                    "label": 0
                },
                {
                    "sent": "So it's constructed the data set up to the context sets.",
                    "label": 0
                },
                {
                    "sent": "But the.",
                    "label": 0
                },
                {
                    "sent": "Any detection linking in context that construction is already done and.",
                    "label": 0
                },
                {
                    "sent": "Can be modified to show impact by doing something better there.",
                    "label": 0
                },
                {
                    "sent": "Attack CBP is quite small, so not very open.",
                    "label": 0
                },
                {
                    "sent": "You can get it by signing an agreement.",
                    "label": 0
                },
                {
                    "sent": "But it's not something that you can easily redistribute, although it does support many tasks.",
                    "label": 0
                },
                {
                    "sent": "You can show him back through ADL contact set construction in relation prediction, not reasoning because they require a justifying sentence for every triple.",
                    "label": 0
                },
                {
                    "sent": "Freebase 15 K 237 is quite large and it's effective for freezing.",
                    "label": 0
                },
                {
                    "sent": "This is often used for knowledge based completion benchmarking.",
                    "label": 0
                },
                {
                    "sent": "And you can use it for relation prediction as well, but it's processed up to the point of context set construction, and it has a very particular kind of context, so it's just the dependency paths between those two entities.",
                    "label": 0
                },
                {
                    "sent": "But if you do want to predict just from the dependency paths, it is effective for that purpose.",
                    "label": 0
                },
                {
                    "sent": "Wiki rating and T. Rex are both using Wikipedia.",
                    "label": 0
                },
                {
                    "sent": "Wiki reading can be used for all of the tasks and is quite large, although it is only effective for title oriented documents.",
                    "label": 0
                },
                {
                    "sent": "These are things like.",
                    "label": 0
                },
                {
                    "sent": "Wikipedia documents where the document is all about one entity, the title.",
                    "label": 0
                },
                {
                    "sent": "Documents are not that rare, but.",
                    "label": 0
                },
                {
                    "sent": "They're not usually the common case.",
                    "label": 0
                },
                {
                    "sent": "T. Rex doesn't include any of the negative examples, so doesn't include any of the unrelated entities, so it's really more real.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Mission classification benchmark.",
                    "label": 0
                },
                {
                    "sent": "For our data set processing.",
                    "label": 0
                },
                {
                    "sent": "Taking the text of common crawl, we extract the text.",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                },
                {
                    "sent": "The DB pedia.",
                    "label": 0
                },
                {
                    "sent": "We do some cagey selection so where selecting down to a subset of DB pedia.",
                    "label": 0
                },
                {
                    "sent": "Then we do it.",
                    "label": 0
                },
                {
                    "sent": "We apply our baseline DDL components to find the annotated text.",
                    "label": 0
                },
                {
                    "sent": "And then do the context of construction to get context from which we can do relation prediction.",
                    "label": 0
                },
                {
                    "sent": "And I'll talk about each of these components in detail.",
                    "label": 0
                },
                {
                    "sent": "This is called CKD BP, because it's common crawl.",
                    "label": 1
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Wendy Pedia that are being aligned.",
                    "label": 0
                },
                {
                    "sent": "So for our text preprocessing common crawl includes more than HTML, so we are just filtering into HTML.",
                    "label": 0
                },
                {
                    "sent": "And we're extracting just the main textual content.",
                    "label": 1
                },
                {
                    "sent": "So many web pages have this behavior where there's some main piece of text as well as some boilerplate.",
                    "label": 0
                },
                {
                    "sent": "And here we have this.",
                    "label": 0
                },
                {
                    "sent": "The footer on this NPR news page.",
                    "label": 0
                },
                {
                    "sent": "We don't really want that.",
                    "label": 0
                },
                {
                    "sent": "So we use a boiler pipe to filter out all of this extra boilerplate.",
                    "label": 1
                },
                {
                    "sent": "And we also filtered the desired language, in this case English.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For Keiji selection I already mentioned that we're collapsing the distinction between resources and literals, so we're just collapsing those two nodes.",
                    "label": 1
                },
                {
                    "sent": "And we're also taking the 400 most frequent relations.",
                    "label": 1
                },
                {
                    "sent": "And we want to filter those down to ones that we're going to really be able to predict from text.",
                    "label": 0
                },
                {
                    "sent": "So first of all, there's the there's the issue of node labels that are unlikely to be matched in text.",
                    "label": 1
                },
                {
                    "sent": "Like DBO, filename was relating resource to the file name that was used on Wikipedia, DBO.",
                    "label": 0
                },
                {
                    "sent": "Description will have as its filler some.",
                    "label": 1
                },
                {
                    "sent": "A long block of text that's really unlikely to be in any particular webpage.",
                    "label": 0
                },
                {
                    "sent": "Top speed will have some floating point value with the unit again difficult to match exactly.",
                    "label": 0
                },
                {
                    "sent": "For similar reasons, we map dates to just the year.",
                    "label": 0
                },
                {
                    "sent": "'cause a year is much easier to match in text.",
                    "label": 0
                },
                {
                    "sent": "And we eliminate these mediator relations, so something like DBO career station that relates a person to a point in their career, which is a blank node that will then connect to some start and end date as well as their job title.",
                    "label": 0
                },
                {
                    "sent": "The result is about 300 relations, not including the Super relations from the relation taxonomy.",
                    "label": 1
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We supply a sort of baseline components for the any detection, linking, and context that construction.",
                    "label": 0
                },
                {
                    "sent": "For any infection, Lincoln just gazeteer matching string matching of the preferred label or the string representation of the literal.",
                    "label": 0
                },
                {
                    "sent": "In case of ambiguities of two things that have the same preferred label, we just take the more popular node, which is we measure by how many triples it participates in.",
                    "label": 1
                },
                {
                    "sent": "DB pedia.",
                    "label": 1
                },
                {
                    "sent": "And we're ignoring labels that occur in the corpus too frequently.",
                    "label": 1
                },
                {
                    "sent": "These are generally things that are very generic.",
                    "label": 0
                },
                {
                    "sent": "Sometimes kind of a mistake.",
                    "label": 0
                },
                {
                    "sent": "An Adobe PDF where it's given a label that's too general or just a truncated label.",
                    "label": 0
                },
                {
                    "sent": "For context construction, windows popular form of context is just the sentence, and we use open NLP force in this detection.",
                    "label": 0
                },
                {
                    "sent": "And we're also filtering these by type pair, so we're not.",
                    "label": 0
                },
                {
                    "sent": "Constructing all of the.",
                    "label": 0
                },
                {
                    "sent": "Every context set for every possible entity pair, only those entity pairs that have types that have been related in our selected knowledge base.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "As I said, an important part of this is a modular architecture, so New York Times Freebase provides directly the context sets.",
                    "label": 1
                },
                {
                    "sent": "And it's very handy for benchmarking relation prediction directly, but if there's some innovative way of selecting contexts, you can't really use this benchmark.",
                    "label": 0
                },
                {
                    "sent": "On the other extreme, is tech PP.",
                    "label": 0
                },
                {
                    "sent": "Where you can benchmark many different things, but you have to implement some ADL systems, some context set construction in order to get to the point where you can start working on your relation prediction system.",
                    "label": 0
                },
                {
                    "sent": "And as we we take the modular approach, we supply the data set at each phase and the code to produce each phase.",
                    "label": 1
                },
                {
                    "sent": "So you can start from EDL, do your own contact set construction and from there to your relation prediction or you can leverage these already provided components and just take the context that's directly.",
                    "label": 1
                },
                {
                    "sent": "For relation prediction.",
                    "label": 0
                },
                {
                    "sent": "And the dependency between these components is gated by this data format, which is documented in the GitHub page.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "CDP data set.",
                    "label": 0
                },
                {
                    "sent": "In the Knowledge Graph is DB pedia, the Texas Common Crawl has about 3 million positive examples.",
                    "label": 0
                },
                {
                    "sent": "And about 170 million sentences.",
                    "label": 0
                },
                {
                    "sent": "And we support all of the tasks that we've identified.",
                    "label": 0
                },
                {
                    "sent": "So any of these tasks can show impact on the benchmark.",
                    "label": 0
                },
                {
                    "sent": "And this is a graph of the entity.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Types there are present.",
                    "label": 0
                },
                {
                    "sent": "I think.",
                    "label": 0
                },
                {
                    "sent": "The main takeaway here is that the entity types are going beyond person placing organization.",
                    "label": 1
                },
                {
                    "sent": "The conventional types that you can get from an NTR.",
                    "label": 1
                },
                {
                    "sent": "We definitely have a lot of agents, so broken down into people and organization and a lot of places and locations.",
                    "label": 0
                },
                {
                    "sent": "But there's also other things like creative works such as music and books as well as literals for strings and numbers, and this other section for species, plants, and animals, basically.",
                    "label": 0
                },
                {
                    "sent": "For relation types.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It is a considerable diversity, so it's really not dominated by one or two relations.",
                    "label": 0
                },
                {
                    "sent": "There's about five relations there.",
                    "label": 0
                },
                {
                    "sent": "Well, there's exactly 5 relations in New York Times, Freebase, that make up 83% of the positive examples.",
                    "label": 1
                },
                {
                    "sent": "But here we get 47 different relation types before up to 80% of the positives.",
                    "label": 1
                },
                {
                    "sent": "And they cover all many different entity types so.",
                    "label": 0
                },
                {
                    "sent": "It's like release year.",
                    "label": 0
                },
                {
                    "sent": "There are many location type relations.",
                    "label": 0
                },
                {
                    "sent": "This Co participates.",
                    "label": 0
                },
                {
                    "sent": "Relation is sort of a very general relation for someone involved in the production of something.",
                    "label": 0
                },
                {
                    "sent": "As well as others, things like is classified by as kind of a general type.",
                    "label": 0
                },
                {
                    "sent": "Relation can be used to connect.",
                    "label": 0
                },
                {
                    "sent": "Something to its genre, for instance as well.",
                    "label": 0
                },
                {
                    "sent": "Another ASP.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is that is a multi instance.",
                    "label": 0
                },
                {
                    "sent": "So as I mentioned before, one of the advantages of a large data set is that.",
                    "label": 0
                },
                {
                    "sent": "You're getting multiple contexts in order to predict the relation between the two nodes.",
                    "label": 1
                },
                {
                    "sent": "So this is a graph showing how many shared context two nodes have.",
                    "label": 0
                },
                {
                    "sent": "And what the distribution of that is?",
                    "label": 0
                },
                {
                    "sent": "Certainly one is still the most common case, but there are many entity pairs that have to for up to 1000 different contexts where these two entities are Co occurring and those that really enables strategies that take advantage of many different contexts to show some impact.",
                    "label": 0
                },
                {
                    "sent": "And as I said, there can be multiple really.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Oceans between two nodes.",
                    "label": 0
                },
                {
                    "sent": "This is a multi label task through, so it's still the most common cases that there is.",
                    "label": 0
                },
                {
                    "sent": "Well, in fact, the most common cases there's no relation between two nodes is overwhelmingly the most common case.",
                    "label": 1
                },
                {
                    "sent": "But after that, the most common case is that there's just one relation, but there's there can be up to six on.",
                    "label": 0
                },
                {
                    "sent": "This occurs in cases relating to a person and some creative work.",
                    "label": 0
                },
                {
                    "sent": "Sometimes somebody can produce direct star right in a film as well as I guess, two others.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to summarize, the key aspects, as I said, the large scale.",
                    "label": 1
                },
                {
                    "sent": "Which is both in the size of the text and the size of the Knowledge Graph enables us to have also a lot of diversity in terms of the entity in relation types.",
                    "label": 0
                },
                {
                    "sent": "By making it modular, we can support different subtasks, not just support them and that they can be done, but support them in the sense that they can be done right away.",
                    "label": 0
                },
                {
                    "sent": "Relation prediction won't require the implementation of some baseline ADL and CSC of your own devising.",
                    "label": 0
                },
                {
                    "sent": "You can just use what's there.",
                    "label": 0
                },
                {
                    "sent": "For future work, this is not really future work is now completely work, but it's not.",
                    "label": 1
                },
                {
                    "sent": "It's not in GitHub yet, but that's coming almost immediately.",
                    "label": 0
                },
                {
                    "sent": "The unary contexts, and in this case we're predicting relations.",
                    "label": 0
                },
                {
                    "sent": "From context, contain only a single node.",
                    "label": 1
                },
                {
                    "sent": "So for example, you can think of something like has location.",
                    "label": 0
                },
                {
                    "sent": "You could predict where something is, what country is something is in is in.",
                    "label": 0
                },
                {
                    "sent": "Even if the country doesn't occur next to that thing, just from related things around it.",
                    "label": 0
                },
                {
                    "sent": "Or things like record label or computing platform.",
                    "label": 0
                },
                {
                    "sent": "You may be able to predict that a software piece of software runs on Linux without ever seeing it in proximity to Linux.",
                    "label": 0
                },
                {
                    "sent": "Also important, we want to move beyond this baseline DDL of gazeteer matching.",
                    "label": 0
                },
                {
                    "sent": "And we have it on GitHub as well.",
                    "label": 0
                },
                {
                    "sent": "So if it's.",
                    "label": 0
                },
                {
                    "sent": "Oh, it's not showing.",
                    "label": 0
                },
                {
                    "sent": "Well.",
                    "label": 0
                },
                {
                    "sent": "Well, you can go to get up and see.",
                    "label": 0
                },
                {
                    "sent": "There we go.",
                    "label": 0
                },
                {
                    "sent": "This is the data set.",
                    "label": 0
                },
                {
                    "sent": "For my documentation that was mentioned.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Thanks, great work.",
                    "label": 0
                },
                {
                    "sent": "I have actually a couple of questions.",
                    "label": 0
                },
                {
                    "sent": "Can you remind us how did you select those 45 types that are being used for the entities?",
                    "label": 0
                },
                {
                    "sent": "Yeah, so that's kind of ad hoc.",
                    "label": 0
                },
                {
                    "sent": "We just selected a coarse grained type system.",
                    "label": 0
                },
                {
                    "sent": "Based on what are frequent types, so we dropped all of the infrequent types.",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 1
                },
                {
                    "sent": "We trimmed it down so that.",
                    "label": 0
                },
                {
                    "sent": "Each type was the most specific type for 1000 different entities.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's based on your analysis on the entire common crawl.",
                    "label": 0
                },
                {
                    "sent": "You have a long tail of entity types being used.",
                    "label": 0
                },
                {
                    "sent": "At some point you decided to cut the ones you wouldn't need to actually use for rotating.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I mean, it's really a property of DB pedia, that it has a lot of very specific types.",
                    "label": 0
                },
                {
                    "sent": "And then we can cut that off to just have general types.",
                    "label": 0
                },
                {
                    "sent": "OK, and my second question is now that you have.",
                    "label": 0
                },
                {
                    "sent": "So if I understand correctly from the GitHub account you're showing here, anyone can run the scripts to actually rebuild the corpora, downloading the common crawl.",
                    "label": 0
                },
                {
                    "sent": "But now, did you already try to use this data sets for training and earn a lick structures and test it on whatever over corporate to see if you get.",
                    "label": 0
                },
                {
                    "sent": "I think this is what you submitted to ACL or something like this, right?",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "Well we have an ACL paper on the unary relations, but I think you're saying something different.",
                    "label": 0
                },
                {
                    "sent": "You're saying run the system over a different corpus.",
                    "label": 0
                },
                {
                    "sent": "Not common crawl.",
                    "label": 0
                },
                {
                    "sent": "Yeah, now we haven't done that.",
                    "label": 0
                },
                {
                    "sent": "We've done.",
                    "label": 0
                },
                {
                    "sent": "We've done transfer learning where we do it on a different set of relations, Anna different corpus, using the model initialized from.",
                    "label": 0
                },
                {
                    "sent": "CDP, but just applying CCP.",
                    "label": 0
                },
                {
                    "sent": "OK, I guess that did happen, but we didn't evaluate it.",
                    "label": 0
                },
                {
                    "sent": "OK thanks.",
                    "label": 0
                },
                {
                    "sent": "One final question, do you have any?",
                    "label": 0
                },
                {
                    "sent": "Idea will be using this resource already.",
                    "label": 0
                },
                {
                    "sent": "So far the only people we know you have used it is at IBM, but we've gotten a few people trying to use it.",
                    "label": 0
                },
                {
                    "sent": "I don't know if they've.",
                    "label": 0
                },
                {
                    "sent": "Actually benchmarked a system where they just downloaded it to look at it.",
                    "label": 0
                },
                {
                    "sent": "But definitely if you want to use it and you have any trouble, just feel free to create a GitHub issue or email me.",
                    "label": 0
                },
                {
                    "sent": "Definitely interested in getting this out to the broader community.",
                    "label": 0
                }
            ]
        }
    }
}