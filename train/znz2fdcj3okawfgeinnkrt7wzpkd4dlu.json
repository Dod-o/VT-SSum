{
    "id": "znz2fdcj3okawfgeinnkrt7wzpkd4dlu",
    "title": "ICA and ISA Using Schweizer-Wolff Measure of Dependence",
    "info": {
        "author": [
            "Sergey Kirshner, Department of Computing Science, University of Alberta"
        ],
        "published": "Aug. 7, 2008",
        "recorded": "July 2008",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/icml08_kirshner_ica/",
    "segmentation": [
        [
            "OK, so my name is Kirschner.",
            "This is joint work with Buttonbush posters who's sitting right in front of me.",
            "This work was done while both of us for at Alberta Engineering Center for Machine Learning at the University of Alberta, so have a mini Canadian innovation in this in this session.",
            "I'll be talking about and you contrast function for.",
            "I see and I say probably."
        ],
        [
            "So in a standard ICS setting we have a number of sources or random variables.",
            "So we have D of them and the sources have been linearly mixed and in this case we're considering the problem where the mixing matrix is square and it has full rank.",
            "So what's observed is actually another D signals.",
            "But in reality we want to recover the original signals.",
            "Want to recover the original source so we need to find a demixing matrix W which is also going to be full rank."
        ],
        [
            "Now, this particular formulation is a special case of independent subspace analysis, where the sources are actually multidimensional themselves, but the idea is the same.",
            "We want to recover the mixing matrix and one."
        ],
        [
            "Recover the original signals.",
            "Now.",
            "Unfortunately, now say setting sources can only be recovered up to scale and permutation.",
            "And because of this, often the original data is processed to remove the scale from the from the equation.",
            "So the data is called white and so for an illustration, say we have the original data which is generated from uniform distribution of on minus one to one interval.",
            "Then it's been rotated.",
            "Actually it's been mixed using a two by two matrix, but in order to remove the scale from the equation with white and it will make the.",
            "This matrix equal to identity and now the problem becomes just finding a rotation.",
            "So in essence we reduce the number of parameters to be equal to the number of truly free parameters and multidimensional problem where we have the dimensions can be solved by a successive to dimensional rotation.",
            "So called Yom Kapoor given situation so often it's enough to find a contrast which would be able to solve a 2 dimensional."
        ],
        [
            "Problem.",
            "OK so but we need to find an objective function which would tell us where there are signals are independent and there are since I see it has been studied for over 20 years Now, there are many different functions which are available and are based on the quantities which can tell the weather.",
            "The sources are independent so it's coming.",
            "This quantity is mutual information and their methods based on that.",
            "And obviously this list is not exhaustive, I'm just listing most prominent methods she used for this purpose.",
            "There are.",
            "There are methods which use entropy estimation which is identical to mutual information.",
            "If we're looking for rotations.",
            "One can pose the problem in the maximum likelihood framework and solve it in that framework.",
            "There are moment based methods.",
            "There are correlation with massacre, many more methods and there are a lot of methods which fit into multiple categories as well now.",
            "But all of these methods we want to measure independence.",
            "We want to be able to identify when the sources are independent.",
            "Now for I say it some other way around, we actually want to see whether the sources are dependent because we want independence between the groups of sources, but within the groups of random to be dependent.",
            "So in particular we will be focusing on the approach proposed by Cardoza when first we mix the sources using ICA and then we group sources which are most."
        ],
        [
            "Together OK, so what's the contribution of this paper?",
            "The contributions and you contrast?",
            "And it's actually quite simple.",
            "This contrast is based on the distribution of ranks, so inside that multivariate dependence between the sources is captured in the ranks of the data, and by using a measure of dependence on the ranks week and we were able to come up with an accurate contrast for ICA.",
            "So the properties is that it does not require density estimation.",
            "So for example, if we want to test.",
            "Admission information or estimate the entropy.",
            "Often the first step is to estimate the density and then compute this quantity.",
            "But really this is not what we are interested in in this particular method, does not explicitly compute the density and this method is not parametric.",
            "We do not assume any functional form for the distribution of the sources.",
            "Whether not assume any functional form for the distribution of the dependence between the sources under rotations.",
            "Now the advantages turns options for dealing with ranks.",
            "This method is very robust to outliers.",
            "It also performs quite well compared to other state of the art methods in some cases, in synthetic data that performs them, some case performance very similar to them.",
            "And also this contrast can measure not only the independence, but the dependence.",
            "So it can be used for for ISA as well.",
            "And it's quite easy to implement in the implementation is publicly available.",
            "Now one of these advantages since we deal with ranks, it's somewhat slow because we need to actually compute the order of the.",
            "We need to compute their ranks, which means we need to sort the data and it turns out Fournier, Gaussian cases, and in general near Gaussian cases are.",
            "Very difficult to separate for most SMF.",
            "Is it?",
            "In practice it requires more samples.",
            "One of the possibilities that since we only using ranks and we throw away the actual values of the data, we might be throwing away too much information to DIMACS under this particular."
        ],
        [
            "Additions OK, So what I mean by ranks?",
            "So say we have a sample from a 2 dimensional data.",
            "What we do we order the values in each dimension.",
            "And the only information which we keep is in essence the index of each value.",
            "So for example here we had value which was about.",
            "It was the 400 largest and 600 largest.",
            "And that's the only information which would require from it.",
            "So we throw away the various.",
            "But we keep the."
        ],
        [
            "The index in the ordering and what's good about rings is that it's invariant under monotonic informations.",
            "So if we increase both values, the order then doesn't change, and since monitoring transformations are not necessarily linear, we have implied nonlinearity in when we use rankings now.",
            "Also, rankings are not very sensitive to outliers because we change one value and the rest of the various change very little, and that value is also bounded when when it's an outlier it's it cannot go higher."
        ],
        [
            "The total number of points now brings can be viewed as a special case of.",
            "Cumulative density function.",
            "So what we can do if we have a distribution in this case we have a sample from a distribution.",
            "If we know the marginals, we can compute the cumulative density function for each point.",
            "We can we can compute.",
            "It's various of its of its community density function for for all of the colors in it and now instead of having the original data set, we can replace it with a data set of of this CDF values.",
            "So this is actually this new.",
            "Object is actually a probability distribution which is defined."
        ],
        [
            "On the unit hypercube.",
            "And one can view it as a probability distribution over normalized ranks.",
            "So before we had drinks from one to N and now we have it in the region between zero and one and it's continuous, it's not discrete anymore, and so that this distribution.",
            "So we think in terms of CDF.",
            "This Jeff is going to be the total mass contained in the rectangle where the lower left vertex is 00 and the top right vertex is the corresponding sides."
        ],
        [
            "Hepatitis and to start.",
            "This distribution has a meaning has been started in statistics for, well, it's cool, popular, and it's a multivariate distribution which has a special property.",
            "Of.",
            "Its marginals are uniform.",
            "And it turns out, for each distribution, we can compute the corresponding corpora using probability integral transform.",
            "And there is a mapping between the original distribution and the couple distribution problem and there is a mapping between the variables for the copula and original value."
        ],
        [
            "For the distribution.",
            "Now what's actually very useful.",
            "Turns out that if the marginals are continuous.",
            "There is a unique representation of probability distribution in terms of its marginals.",
            "And in terms of its popular.",
            "Now, if the marginals are not continue continuous this this couple is unique only on the range for the marginals.",
            "But what follows from this is that copal is really the Canonical way to look at multivariate dependence, because here in the marginals there is nothing in the marginals.",
            "Concerns with multivariate dependence.",
            "All the multivariate dependences."
        ],
        [
            "Should be in the curriculum so we can look at the the copula when we when we want to study multivariate dependencies, as is the case here.",
            "So for example if I want to look at their anchor relations therein, correlations are contained in a calculus.",
            "So for example experiments row is just a linear correlation of the ranks.",
            "It can be computed using copula if we want to look at mutual information, all we need to do we need to look at the entropy of the popular."
        ],
        [
            "So for our case, that's what we're going to do, but since we concern with independence first will probably need to find the analogue of what it means for variables to be independent in the popular domain.",
            "And it turns out that this analogue is actually quite easy to derive, so just visually we can take a probability distribution, work with the variables are independent and look what the copula would look like, and it looks like it just uniform over the unit hypercube, and that's indeed the case, so that the independence copula, which is the Corporal, issues the product popular or just the product of the corresponding variables.",
            "And the probability distribution that two variables are independent of the corresponding corporate is the independence called."
        ],
        [
            "So now what we can do now, we can define a measure of dependence by looking at how far is the couple for a particular distribution from the independence copula, and what I'm going to be looking at just tell norm between the couple over the distribution and the independent scholar one, and this particular approach has been the this particular norm.",
            "This particular measures penicillin proposed actually quite a few years ago.",
            "So we're looking at is all normal.",
            "The only condition which was said and for our purposes it's not really imperative, is that the ranges between zero and one.",
            "So it's zero if and only if the variables are independent, and that's what we really care for for the ICA.",
            "So for example, we can look at the L1 norm and that's schwizer Wolf Sigma.",
            "That which is going to be used as a contrast and all it is is just L1 norm between the copula and the independence copula.",
            "So 12 is just the constant to make sure that the upper upper ranges is 1.",
            "It's actually a very similar to the experiments rocks.",
            "Instead of having a difference inside the integral between the couple and product popular, we actually have absolute value to make sure that it's zero if and only if the couple is the independence calcula.",
            "Another alternative is to use copper, which is just L Infinity norm or instead of L1 norm and it has a resemblance to the Kolmogorov Smirnov statistic for the univariate distributions.",
            "Now this tells us how to compute the dependence measure for the distributions."
        ],
        [
            "But in this case we have just a point sample, so we need to come up with a way to do it for a point sample, and it turns out there is a.",
            "There is a nice way to represent a couple of samples.",
            "It's called empirical copula.",
            "So what we do is this.",
            "We take the values.",
            "We sold them, but we actually record the values.",
            "And then if we want to find a particular value and this value is going to be related in the grid, it's just the number of.",
            "The total number of points which fall inside the region.",
            "It is the total number of points which are smaller than the.",
            "Sorry, it's the total number of points which are smaller than the than the value in one variable and value in another variable, and it's normalized to make sure that this area so this number of points.",
            "Sorry, this quantity is never greater than one.",
            "So it's in essence a discrete equivalence."
        ],
        [
            "Descript equivalent of popular now turns out that for rank correlations there is an equivalent formulation for the.",
            "For the for the sample version using empirical copula and the same quantity also exists for the schwizer Wolf measure of dependence.",
            "Now what we in essence do we approximate an integral with the sum over equal spaced grid points?",
            "And if we use empirical copula and we look at all of the points, we're going to have an square points where we're going to evaluate the sum now for computational.",
            "For computational sake, we might decrease the number of points where we want to evaluate it.",
            "So instead of having a instead of using all of the endpoints, we may use smaller number of points.",
            "We can be significantly smaller than N. What is the benefit?",
            "The computational cost of estimation of the?",
            "Of Sigma is going to be only B squared rather than."
        ],
        [
            "Unsquared now the algorithm is is very straightforward.",
            "We have a 2 by N matrix.",
            "Of signals so.",
            "So we have two signals and we have an samples and we have a number of angles at which we're going to evaluate possible rotations, and we're looking for rotation matrix.",
            "So for each of the angles.",
            "In this case, these are extra space tangles.",
            "We compute the rotation matrix.",
            "Then we compute the rotated signal.",
            "And then we compute the sample estimate of Schwizer Wolf suggested.",
            "And over do we try to find the angle which minimizes the size of the system?",
            "So this is going to be the value which is closest to the independence.",
            "As an output, we can have the rotation matrix.",
            "We can have the mixed signal.",
            "We can have the estimated dependence measure now.",
            "So what's the complexity of this estimation of the rotation matrix is constant.",
            "Computing rotated signal is just just linear in the number of data points.",
            "Now, in order to compute the Schwizer rule statistic, first need to sort the data in each dimension.",
            "So it's on, log on, and then we need to compute.",
            "We need to compute the estimate, which means we need to validate that N squared point, so that's quite expensive.",
            "So, given that it's inside the loop where we where we loop through the angles, that's quite expensive so that we can speed it up by not evaluating it at all of North squared points.",
            "We can instead sort the data.",
            "Really not not completely sorted, but sorted into into bins, where each bin has the same number of points and each successive beans have various larger than each, each previous being.",
            "So you can think of it as running quicksort, but not today aren't just running.",
            "I think it's called Quickselect algorithm.",
            "We just sorts points into into intervals rather than doing complete sort, and it's actually faster and now instead of computing as we compute the approximation of us which requires.",
            "Which has much lower computational complexity.",
            "So now we can have algorithm which is, which is quite a bit faster and in practice.",
            "This algorithm is not as fast as something like fast ICA or Jade because those algorithms are linear in the number of data points, but it's in practice it was faster for example than radical or then Colonel ICA."
        ],
        [
            "OK, so how do we evaluate?",
            "How well perform?",
            "Well, we can look at how close the matrix that we recover is to the permutation matrix, and one such measure is the is the murderer.",
            "So what we look at is this.",
            "We in a simulated experiments we know what the mixing matrix is, and we have the mixing matrix.",
            "So we can compute the total transformation for the data and we want this this transformation matrix to be as close as possible to permutation matrix.",
            "And it turns out there is a quantity of which.",
            "Which takes a value of 0 if the matrix is a permutation matrix and it grows as the matrix becomes.",
            "Further away from so, for example, for two variables, the value is zero when the rotation has.",
            "The rotation has angle zero and it's it's 11 rotations by 45 degrees."
        ],
        [
            "OK, so we use synthetic data to evaluate their methods, so we used to generate marginal distributions.",
            "Sorry to generate Universite.",
            "Sources we used the set of synthetic marginal distributions from Buck and Jordan paper describing kernel essay.",
            "This particular set of sources have been used in other papers as well, and we tried to see how well we can recover the original signals.",
            "If the distributions were drawn.",
            "If the if the."
        ],
        [
            "Horses were drawn from distributions, so.",
            "This particular plot shows a comparison of our methods weaker to four other state of the art methods.",
            "Radical kernel, safe SNJ, and in most cases our performance is similar to that state of the art auction.",
            "In couple of cases we do a little bit better.",
            "There are a couple of cases where we do quite a bit worse, so there's a.",
            "There's a case here in the case here where the source is the distribution for the sources are quite close to Gaussian.",
            "It appears to be dealers that our method.",
            "Needs more samples to pick up the signals so not shown here.",
            "If if the number of data points increases, our method can also pick up the correct mixing matrix.",
            "Now, if we just randomly select sources.",
            "So if we randomly select distributions for the sources we do.",
            "Almost the same as as."
        ],
        [
            "The other state without math is now where the methods really shines in.",
            "When we have outliers.",
            "It can still outperforms the rest of the matters under these conditions, because this particular measure is just not very."
        ],
        [
            "Now if we go to higher dimension, we actually do quite well in learning the.",
            "The original mixing matrix as the number of outliers grow, we will perform radical is another method which uses ranks in it."
        ],
        [
            "Contrast.",
            "No need to show that we can work not only with synthetic data, but with with image data.",
            "We we did the following experiment we took a couple of images, natural images from the from an image repository and we mix them but actually added some outlier so we wanted to show that we can stay robust and still learn the original images back so.",
            "In the comparison this week outperformed the rest of the methods.",
            "This this particular plot.",
            "This particular slide shows kind of typical performance of swieca, so we recover the original sources.",
            "So basically we can't.",
            "We can recover it only up to innocence assign.",
            "So some of the images look as if their inverted.",
            "This is a typical performance for fast ICA, but actually both kernel is a radical and Jade had.",
            "Had similarly poor performance, so it appears to do better and outliers when we we use some natural value, some some natural signals for the for the sources now."
        ],
        [
            "I mentioned it can be used for for ISA as well, so we have 6 three dimensional sources.",
            "Which were mixed using a team based in Matrix.",
            "So this is just the projection for the four.",
            "For three dimensional sources, under the mixing matrix now.",
            "We process the data using fast I say so as I mentioned under Cardoso's conjecture, we can first process the data using ICA, recovered the independent sources and then group them together using some measure of dependence.",
            "In this case we use fast ICA for computational reasons to group them together and then by applying.",
            "Kaiser Wolf Sigma were able to recover the original signals, so this is the Hinton diagram which shows that we actually recovered."
        ],
        [
            "Signals OK, so what's the contribution?",
            "It's a new contrast which is based on measure of dependence for distributions, but distributions over ranks.",
            "It's primarily.",
            "We see it used when the data has outliers at this very robust to them, but the But the performance is comparable to other state of the art algorithms.",
            "While it's a bit slow, it can handle moderate number of sources, so we run it for datasets which had 10,000 data points and.",
            "When your dimensions and they did it in reasonable time and it can be used to solve, I see now.",
            "Sorry can be used to solve.",
            "I say now we would like to accelerate it to be able to use it for for large datasets, but for example, uh, it can be easily parallelized.",
            "Simply doing a sweep over the angles.",
            "Each evaluation can be done separately and there are other tricks which are in the paper which can accelerate the method we still trying to figure out.",
            "What sources this method will do well and why so we understand why it's robust to outliers, but we would like to study of what kind of distributions it would be most applicable to.",
            "And also this can be viewed as a substitute for mutual information where you don't have to when one doesn't have to evaluate densities.",
            "So would be interesting to see whether we can use this.",
            "Ring based approaches to estimate mission information in the parametric fashion."
        ],
        [
            "Exactly, so that's all.",
            "This offer is available on this website.",
            "Thank you very much."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so my name is Kirschner.",
                    "label": 0
                },
                {
                    "sent": "This is joint work with Buttonbush posters who's sitting right in front of me.",
                    "label": 0
                },
                {
                    "sent": "This work was done while both of us for at Alberta Engineering Center for Machine Learning at the University of Alberta, so have a mini Canadian innovation in this in this session.",
                    "label": 1
                },
                {
                    "sent": "I'll be talking about and you contrast function for.",
                    "label": 0
                },
                {
                    "sent": "I see and I say probably.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in a standard ICS setting we have a number of sources or random variables.",
                    "label": 0
                },
                {
                    "sent": "So we have D of them and the sources have been linearly mixed and in this case we're considering the problem where the mixing matrix is square and it has full rank.",
                    "label": 0
                },
                {
                    "sent": "So what's observed is actually another D signals.",
                    "label": 0
                },
                {
                    "sent": "But in reality we want to recover the original signals.",
                    "label": 0
                },
                {
                    "sent": "Want to recover the original source so we need to find a demixing matrix W which is also going to be full rank.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now, this particular formulation is a special case of independent subspace analysis, where the sources are actually multidimensional themselves, but the idea is the same.",
                    "label": 0
                },
                {
                    "sent": "We want to recover the mixing matrix and one.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Recover the original signals.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately, now say setting sources can only be recovered up to scale and permutation.",
                    "label": 1
                },
                {
                    "sent": "And because of this, often the original data is processed to remove the scale from the from the equation.",
                    "label": 0
                },
                {
                    "sent": "So the data is called white and so for an illustration, say we have the original data which is generated from uniform distribution of on minus one to one interval.",
                    "label": 0
                },
                {
                    "sent": "Then it's been rotated.",
                    "label": 0
                },
                {
                    "sent": "Actually it's been mixed using a two by two matrix, but in order to remove the scale from the equation with white and it will make the.",
                    "label": 0
                },
                {
                    "sent": "This matrix equal to identity and now the problem becomes just finding a rotation.",
                    "label": 0
                },
                {
                    "sent": "So in essence we reduce the number of parameters to be equal to the number of truly free parameters and multidimensional problem where we have the dimensions can be solved by a successive to dimensional rotation.",
                    "label": 0
                },
                {
                    "sent": "So called Yom Kapoor given situation so often it's enough to find a contrast which would be able to solve a 2 dimensional.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Problem.",
                    "label": 0
                },
                {
                    "sent": "OK so but we need to find an objective function which would tell us where there are signals are independent and there are since I see it has been studied for over 20 years Now, there are many different functions which are available and are based on the quantities which can tell the weather.",
                    "label": 0
                },
                {
                    "sent": "The sources are independent so it's coming.",
                    "label": 0
                },
                {
                    "sent": "This quantity is mutual information and their methods based on that.",
                    "label": 0
                },
                {
                    "sent": "And obviously this list is not exhaustive, I'm just listing most prominent methods she used for this purpose.",
                    "label": 0
                },
                {
                    "sent": "There are.",
                    "label": 0
                },
                {
                    "sent": "There are methods which use entropy estimation which is identical to mutual information.",
                    "label": 1
                },
                {
                    "sent": "If we're looking for rotations.",
                    "label": 0
                },
                {
                    "sent": "One can pose the problem in the maximum likelihood framework and solve it in that framework.",
                    "label": 0
                },
                {
                    "sent": "There are moment based methods.",
                    "label": 0
                },
                {
                    "sent": "There are correlation with massacre, many more methods and there are a lot of methods which fit into multiple categories as well now.",
                    "label": 0
                },
                {
                    "sent": "But all of these methods we want to measure independence.",
                    "label": 1
                },
                {
                    "sent": "We want to be able to identify when the sources are independent.",
                    "label": 0
                },
                {
                    "sent": "Now for I say it some other way around, we actually want to see whether the sources are dependent because we want independence between the groups of sources, but within the groups of random to be dependent.",
                    "label": 0
                },
                {
                    "sent": "So in particular we will be focusing on the approach proposed by Cardoza when first we mix the sources using ICA and then we group sources which are most.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Together OK, so what's the contribution of this paper?",
                    "label": 0
                },
                {
                    "sent": "The contributions and you contrast?",
                    "label": 0
                },
                {
                    "sent": "And it's actually quite simple.",
                    "label": 0
                },
                {
                    "sent": "This contrast is based on the distribution of ranks, so inside that multivariate dependence between the sources is captured in the ranks of the data, and by using a measure of dependence on the ranks week and we were able to come up with an accurate contrast for ICA.",
                    "label": 1
                },
                {
                    "sent": "So the properties is that it does not require density estimation.",
                    "label": 0
                },
                {
                    "sent": "So for example, if we want to test.",
                    "label": 0
                },
                {
                    "sent": "Admission information or estimate the entropy.",
                    "label": 0
                },
                {
                    "sent": "Often the first step is to estimate the density and then compute this quantity.",
                    "label": 0
                },
                {
                    "sent": "But really this is not what we are interested in in this particular method, does not explicitly compute the density and this method is not parametric.",
                    "label": 0
                },
                {
                    "sent": "We do not assume any functional form for the distribution of the sources.",
                    "label": 0
                },
                {
                    "sent": "Whether not assume any functional form for the distribution of the dependence between the sources under rotations.",
                    "label": 1
                },
                {
                    "sent": "Now the advantages turns options for dealing with ranks.",
                    "label": 0
                },
                {
                    "sent": "This method is very robust to outliers.",
                    "label": 1
                },
                {
                    "sent": "It also performs quite well compared to other state of the art methods in some cases, in synthetic data that performs them, some case performance very similar to them.",
                    "label": 0
                },
                {
                    "sent": "And also this contrast can measure not only the independence, but the dependence.",
                    "label": 0
                },
                {
                    "sent": "So it can be used for for ISA as well.",
                    "label": 0
                },
                {
                    "sent": "And it's quite easy to implement in the implementation is publicly available.",
                    "label": 1
                },
                {
                    "sent": "Now one of these advantages since we deal with ranks, it's somewhat slow because we need to actually compute the order of the.",
                    "label": 0
                },
                {
                    "sent": "We need to compute their ranks, which means we need to sort the data and it turns out Fournier, Gaussian cases, and in general near Gaussian cases are.",
                    "label": 0
                },
                {
                    "sent": "Very difficult to separate for most SMF.",
                    "label": 0
                },
                {
                    "sent": "Is it?",
                    "label": 0
                },
                {
                    "sent": "In practice it requires more samples.",
                    "label": 0
                },
                {
                    "sent": "One of the possibilities that since we only using ranks and we throw away the actual values of the data, we might be throwing away too much information to DIMACS under this particular.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Additions OK, So what I mean by ranks?",
                    "label": 0
                },
                {
                    "sent": "So say we have a sample from a 2 dimensional data.",
                    "label": 0
                },
                {
                    "sent": "What we do we order the values in each dimension.",
                    "label": 0
                },
                {
                    "sent": "And the only information which we keep is in essence the index of each value.",
                    "label": 0
                },
                {
                    "sent": "So for example here we had value which was about.",
                    "label": 0
                },
                {
                    "sent": "It was the 400 largest and 600 largest.",
                    "label": 0
                },
                {
                    "sent": "And that's the only information which would require from it.",
                    "label": 0
                },
                {
                    "sent": "So we throw away the various.",
                    "label": 0
                },
                {
                    "sent": "But we keep the.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The index in the ordering and what's good about rings is that it's invariant under monotonic informations.",
                    "label": 1
                },
                {
                    "sent": "So if we increase both values, the order then doesn't change, and since monitoring transformations are not necessarily linear, we have implied nonlinearity in when we use rankings now.",
                    "label": 0
                },
                {
                    "sent": "Also, rankings are not very sensitive to outliers because we change one value and the rest of the various change very little, and that value is also bounded when when it's an outlier it's it cannot go higher.",
                    "label": 1
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The total number of points now brings can be viewed as a special case of.",
                    "label": 0
                },
                {
                    "sent": "Cumulative density function.",
                    "label": 0
                },
                {
                    "sent": "So what we can do if we have a distribution in this case we have a sample from a distribution.",
                    "label": 0
                },
                {
                    "sent": "If we know the marginals, we can compute the cumulative density function for each point.",
                    "label": 0
                },
                {
                    "sent": "We can we can compute.",
                    "label": 0
                },
                {
                    "sent": "It's various of its of its community density function for for all of the colors in it and now instead of having the original data set, we can replace it with a data set of of this CDF values.",
                    "label": 0
                },
                {
                    "sent": "So this is actually this new.",
                    "label": 0
                },
                {
                    "sent": "Object is actually a probability distribution which is defined.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "On the unit hypercube.",
                    "label": 0
                },
                {
                    "sent": "And one can view it as a probability distribution over normalized ranks.",
                    "label": 1
                },
                {
                    "sent": "So before we had drinks from one to N and now we have it in the region between zero and one and it's continuous, it's not discrete anymore, and so that this distribution.",
                    "label": 0
                },
                {
                    "sent": "So we think in terms of CDF.",
                    "label": 0
                },
                {
                    "sent": "This Jeff is going to be the total mass contained in the rectangle where the lower left vertex is 00 and the top right vertex is the corresponding sides.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Hepatitis and to start.",
                    "label": 0
                },
                {
                    "sent": "This distribution has a meaning has been started in statistics for, well, it's cool, popular, and it's a multivariate distribution which has a special property.",
                    "label": 1
                },
                {
                    "sent": "Of.",
                    "label": 0
                },
                {
                    "sent": "Its marginals are uniform.",
                    "label": 0
                },
                {
                    "sent": "And it turns out, for each distribution, we can compute the corresponding corpora using probability integral transform.",
                    "label": 0
                },
                {
                    "sent": "And there is a mapping between the original distribution and the couple distribution problem and there is a mapping between the variables for the copula and original value.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For the distribution.",
                    "label": 0
                },
                {
                    "sent": "Now what's actually very useful.",
                    "label": 0
                },
                {
                    "sent": "Turns out that if the marginals are continuous.",
                    "label": 0
                },
                {
                    "sent": "There is a unique representation of probability distribution in terms of its marginals.",
                    "label": 0
                },
                {
                    "sent": "And in terms of its popular.",
                    "label": 0
                },
                {
                    "sent": "Now, if the marginals are not continue continuous this this couple is unique only on the range for the marginals.",
                    "label": 0
                },
                {
                    "sent": "But what follows from this is that copal is really the Canonical way to look at multivariate dependence, because here in the marginals there is nothing in the marginals.",
                    "label": 0
                },
                {
                    "sent": "Concerns with multivariate dependence.",
                    "label": 0
                },
                {
                    "sent": "All the multivariate dependences.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Should be in the curriculum so we can look at the the copula when we when we want to study multivariate dependencies, as is the case here.",
                    "label": 0
                },
                {
                    "sent": "So for example if I want to look at their anchor relations therein, correlations are contained in a calculus.",
                    "label": 0
                },
                {
                    "sent": "So for example experiments row is just a linear correlation of the ranks.",
                    "label": 0
                },
                {
                    "sent": "It can be computed using copula if we want to look at mutual information, all we need to do we need to look at the entropy of the popular.",
                    "label": 1
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for our case, that's what we're going to do, but since we concern with independence first will probably need to find the analogue of what it means for variables to be independent in the popular domain.",
                    "label": 0
                },
                {
                    "sent": "And it turns out that this analogue is actually quite easy to derive, so just visually we can take a probability distribution, work with the variables are independent and look what the copula would look like, and it looks like it just uniform over the unit hypercube, and that's indeed the case, so that the independence copula, which is the Corporal, issues the product popular or just the product of the corresponding variables.",
                    "label": 0
                },
                {
                    "sent": "And the probability distribution that two variables are independent of the corresponding corporate is the independence called.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now what we can do now, we can define a measure of dependence by looking at how far is the couple for a particular distribution from the independence copula, and what I'm going to be looking at just tell norm between the couple over the distribution and the independent scholar one, and this particular approach has been the this particular norm.",
                    "label": 0
                },
                {
                    "sent": "This particular measures penicillin proposed actually quite a few years ago.",
                    "label": 0
                },
                {
                    "sent": "So we're looking at is all normal.",
                    "label": 0
                },
                {
                    "sent": "The only condition which was said and for our purposes it's not really imperative, is that the ranges between zero and one.",
                    "label": 0
                },
                {
                    "sent": "So it's zero if and only if the variables are independent, and that's what we really care for for the ICA.",
                    "label": 1
                },
                {
                    "sent": "So for example, we can look at the L1 norm and that's schwizer Wolf Sigma.",
                    "label": 1
                },
                {
                    "sent": "That which is going to be used as a contrast and all it is is just L1 norm between the copula and the independence copula.",
                    "label": 0
                },
                {
                    "sent": "So 12 is just the constant to make sure that the upper upper ranges is 1.",
                    "label": 0
                },
                {
                    "sent": "It's actually a very similar to the experiments rocks.",
                    "label": 0
                },
                {
                    "sent": "Instead of having a difference inside the integral between the couple and product popular, we actually have absolute value to make sure that it's zero if and only if the couple is the independence calcula.",
                    "label": 0
                },
                {
                    "sent": "Another alternative is to use copper, which is just L Infinity norm or instead of L1 norm and it has a resemblance to the Kolmogorov Smirnov statistic for the univariate distributions.",
                    "label": 0
                },
                {
                    "sent": "Now this tells us how to compute the dependence measure for the distributions.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But in this case we have just a point sample, so we need to come up with a way to do it for a point sample, and it turns out there is a.",
                    "label": 0
                },
                {
                    "sent": "There is a nice way to represent a couple of samples.",
                    "label": 0
                },
                {
                    "sent": "It's called empirical copula.",
                    "label": 0
                },
                {
                    "sent": "So what we do is this.",
                    "label": 0
                },
                {
                    "sent": "We take the values.",
                    "label": 0
                },
                {
                    "sent": "We sold them, but we actually record the values.",
                    "label": 0
                },
                {
                    "sent": "And then if we want to find a particular value and this value is going to be related in the grid, it's just the number of.",
                    "label": 0
                },
                {
                    "sent": "The total number of points which fall inside the region.",
                    "label": 0
                },
                {
                    "sent": "It is the total number of points which are smaller than the.",
                    "label": 0
                },
                {
                    "sent": "Sorry, it's the total number of points which are smaller than the than the value in one variable and value in another variable, and it's normalized to make sure that this area so this number of points.",
                    "label": 0
                },
                {
                    "sent": "Sorry, this quantity is never greater than one.",
                    "label": 0
                },
                {
                    "sent": "So it's in essence a discrete equivalence.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Descript equivalent of popular now turns out that for rank correlations there is an equivalent formulation for the.",
                    "label": 0
                },
                {
                    "sent": "For the for the sample version using empirical copula and the same quantity also exists for the schwizer Wolf measure of dependence.",
                    "label": 1
                },
                {
                    "sent": "Now what we in essence do we approximate an integral with the sum over equal spaced grid points?",
                    "label": 0
                },
                {
                    "sent": "And if we use empirical copula and we look at all of the points, we're going to have an square points where we're going to evaluate the sum now for computational.",
                    "label": 0
                },
                {
                    "sent": "For computational sake, we might decrease the number of points where we want to evaluate it.",
                    "label": 0
                },
                {
                    "sent": "So instead of having a instead of using all of the endpoints, we may use smaller number of points.",
                    "label": 0
                },
                {
                    "sent": "We can be significantly smaller than N. What is the benefit?",
                    "label": 0
                },
                {
                    "sent": "The computational cost of estimation of the?",
                    "label": 0
                },
                {
                    "sent": "Of Sigma is going to be only B squared rather than.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Unsquared now the algorithm is is very straightforward.",
                    "label": 0
                },
                {
                    "sent": "We have a 2 by N matrix.",
                    "label": 1
                },
                {
                    "sent": "Of signals so.",
                    "label": 0
                },
                {
                    "sent": "So we have two signals and we have an samples and we have a number of angles at which we're going to evaluate possible rotations, and we're looking for rotation matrix.",
                    "label": 0
                },
                {
                    "sent": "So for each of the angles.",
                    "label": 0
                },
                {
                    "sent": "In this case, these are extra space tangles.",
                    "label": 1
                },
                {
                    "sent": "We compute the rotation matrix.",
                    "label": 0
                },
                {
                    "sent": "Then we compute the rotated signal.",
                    "label": 1
                },
                {
                    "sent": "And then we compute the sample estimate of Schwizer Wolf suggested.",
                    "label": 1
                },
                {
                    "sent": "And over do we try to find the angle which minimizes the size of the system?",
                    "label": 0
                },
                {
                    "sent": "So this is going to be the value which is closest to the independence.",
                    "label": 1
                },
                {
                    "sent": "As an output, we can have the rotation matrix.",
                    "label": 0
                },
                {
                    "sent": "We can have the mixed signal.",
                    "label": 1
                },
                {
                    "sent": "We can have the estimated dependence measure now.",
                    "label": 0
                },
                {
                    "sent": "So what's the complexity of this estimation of the rotation matrix is constant.",
                    "label": 0
                },
                {
                    "sent": "Computing rotated signal is just just linear in the number of data points.",
                    "label": 0
                },
                {
                    "sent": "Now, in order to compute the Schwizer rule statistic, first need to sort the data in each dimension.",
                    "label": 0
                },
                {
                    "sent": "So it's on, log on, and then we need to compute.",
                    "label": 0
                },
                {
                    "sent": "We need to compute the estimate, which means we need to validate that N squared point, so that's quite expensive.",
                    "label": 0
                },
                {
                    "sent": "So, given that it's inside the loop where we where we loop through the angles, that's quite expensive so that we can speed it up by not evaluating it at all of North squared points.",
                    "label": 0
                },
                {
                    "sent": "We can instead sort the data.",
                    "label": 0
                },
                {
                    "sent": "Really not not completely sorted, but sorted into into bins, where each bin has the same number of points and each successive beans have various larger than each, each previous being.",
                    "label": 0
                },
                {
                    "sent": "So you can think of it as running quicksort, but not today aren't just running.",
                    "label": 0
                },
                {
                    "sent": "I think it's called Quickselect algorithm.",
                    "label": 0
                },
                {
                    "sent": "We just sorts points into into intervals rather than doing complete sort, and it's actually faster and now instead of computing as we compute the approximation of us which requires.",
                    "label": 0
                },
                {
                    "sent": "Which has much lower computational complexity.",
                    "label": 0
                },
                {
                    "sent": "So now we can have algorithm which is, which is quite a bit faster and in practice.",
                    "label": 0
                },
                {
                    "sent": "This algorithm is not as fast as something like fast ICA or Jade because those algorithms are linear in the number of data points, but it's in practice it was faster for example than radical or then Colonel ICA.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so how do we evaluate?",
                    "label": 0
                },
                {
                    "sent": "How well perform?",
                    "label": 0
                },
                {
                    "sent": "Well, we can look at how close the matrix that we recover is to the permutation matrix, and one such measure is the is the murderer.",
                    "label": 1
                },
                {
                    "sent": "So what we look at is this.",
                    "label": 0
                },
                {
                    "sent": "We in a simulated experiments we know what the mixing matrix is, and we have the mixing matrix.",
                    "label": 0
                },
                {
                    "sent": "So we can compute the total transformation for the data and we want this this transformation matrix to be as close as possible to permutation matrix.",
                    "label": 0
                },
                {
                    "sent": "And it turns out there is a quantity of which.",
                    "label": 0
                },
                {
                    "sent": "Which takes a value of 0 if the matrix is a permutation matrix and it grows as the matrix becomes.",
                    "label": 1
                },
                {
                    "sent": "Further away from so, for example, for two variables, the value is zero when the rotation has.",
                    "label": 0
                },
                {
                    "sent": "The rotation has angle zero and it's it's 11 rotations by 45 degrees.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so we use synthetic data to evaluate their methods, so we used to generate marginal distributions.",
                    "label": 0
                },
                {
                    "sent": "Sorry to generate Universite.",
                    "label": 0
                },
                {
                    "sent": "Sources we used the set of synthetic marginal distributions from Buck and Jordan paper describing kernel essay.",
                    "label": 1
                },
                {
                    "sent": "This particular set of sources have been used in other papers as well, and we tried to see how well we can recover the original signals.",
                    "label": 0
                },
                {
                    "sent": "If the distributions were drawn.",
                    "label": 0
                },
                {
                    "sent": "If the if the.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Horses were drawn from distributions, so.",
                    "label": 0
                },
                {
                    "sent": "This particular plot shows a comparison of our methods weaker to four other state of the art methods.",
                    "label": 0
                },
                {
                    "sent": "Radical kernel, safe SNJ, and in most cases our performance is similar to that state of the art auction.",
                    "label": 0
                },
                {
                    "sent": "In couple of cases we do a little bit better.",
                    "label": 0
                },
                {
                    "sent": "There are a couple of cases where we do quite a bit worse, so there's a.",
                    "label": 0
                },
                {
                    "sent": "There's a case here in the case here where the source is the distribution for the sources are quite close to Gaussian.",
                    "label": 0
                },
                {
                    "sent": "It appears to be dealers that our method.",
                    "label": 0
                },
                {
                    "sent": "Needs more samples to pick up the signals so not shown here.",
                    "label": 0
                },
                {
                    "sent": "If if the number of data points increases, our method can also pick up the correct mixing matrix.",
                    "label": 0
                },
                {
                    "sent": "Now, if we just randomly select sources.",
                    "label": 0
                },
                {
                    "sent": "So if we randomly select distributions for the sources we do.",
                    "label": 0
                },
                {
                    "sent": "Almost the same as as.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The other state without math is now where the methods really shines in.",
                    "label": 0
                },
                {
                    "sent": "When we have outliers.",
                    "label": 0
                },
                {
                    "sent": "It can still outperforms the rest of the matters under these conditions, because this particular measure is just not very.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now if we go to higher dimension, we actually do quite well in learning the.",
                    "label": 0
                },
                {
                    "sent": "The original mixing matrix as the number of outliers grow, we will perform radical is another method which uses ranks in it.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Contrast.",
                    "label": 0
                },
                {
                    "sent": "No need to show that we can work not only with synthetic data, but with with image data.",
                    "label": 0
                },
                {
                    "sent": "We we did the following experiment we took a couple of images, natural images from the from an image repository and we mix them but actually added some outlier so we wanted to show that we can stay robust and still learn the original images back so.",
                    "label": 0
                },
                {
                    "sent": "In the comparison this week outperformed the rest of the methods.",
                    "label": 0
                },
                {
                    "sent": "This this particular plot.",
                    "label": 0
                },
                {
                    "sent": "This particular slide shows kind of typical performance of swieca, so we recover the original sources.",
                    "label": 0
                },
                {
                    "sent": "So basically we can't.",
                    "label": 0
                },
                {
                    "sent": "We can recover it only up to innocence assign.",
                    "label": 0
                },
                {
                    "sent": "So some of the images look as if their inverted.",
                    "label": 0
                },
                {
                    "sent": "This is a typical performance for fast ICA, but actually both kernel is a radical and Jade had.",
                    "label": 0
                },
                {
                    "sent": "Had similarly poor performance, so it appears to do better and outliers when we we use some natural value, some some natural signals for the for the sources now.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I mentioned it can be used for for ISA as well, so we have 6 three dimensional sources.",
                    "label": 0
                },
                {
                    "sent": "Which were mixed using a team based in Matrix.",
                    "label": 0
                },
                {
                    "sent": "So this is just the projection for the four.",
                    "label": 0
                },
                {
                    "sent": "For three dimensional sources, under the mixing matrix now.",
                    "label": 0
                },
                {
                    "sent": "We process the data using fast I say so as I mentioned under Cardoso's conjecture, we can first process the data using ICA, recovered the independent sources and then group them together using some measure of dependence.",
                    "label": 0
                },
                {
                    "sent": "In this case we use fast ICA for computational reasons to group them together and then by applying.",
                    "label": 0
                },
                {
                    "sent": "Kaiser Wolf Sigma were able to recover the original signals, so this is the Hinton diagram which shows that we actually recovered.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Signals OK, so what's the contribution?",
                    "label": 0
                },
                {
                    "sent": "It's a new contrast which is based on measure of dependence for distributions, but distributions over ranks.",
                    "label": 1
                },
                {
                    "sent": "It's primarily.",
                    "label": 1
                },
                {
                    "sent": "We see it used when the data has outliers at this very robust to them, but the But the performance is comparable to other state of the art algorithms.",
                    "label": 0
                },
                {
                    "sent": "While it's a bit slow, it can handle moderate number of sources, so we run it for datasets which had 10,000 data points and.",
                    "label": 0
                },
                {
                    "sent": "When your dimensions and they did it in reasonable time and it can be used to solve, I see now.",
                    "label": 1
                },
                {
                    "sent": "Sorry can be used to solve.",
                    "label": 0
                },
                {
                    "sent": "I say now we would like to accelerate it to be able to use it for for large datasets, but for example, uh, it can be easily parallelized.",
                    "label": 0
                },
                {
                    "sent": "Simply doing a sweep over the angles.",
                    "label": 0
                },
                {
                    "sent": "Each evaluation can be done separately and there are other tricks which are in the paper which can accelerate the method we still trying to figure out.",
                    "label": 0
                },
                {
                    "sent": "What sources this method will do well and why so we understand why it's robust to outliers, but we would like to study of what kind of distributions it would be most applicable to.",
                    "label": 0
                },
                {
                    "sent": "And also this can be viewed as a substitute for mutual information where you don't have to when one doesn't have to evaluate densities.",
                    "label": 0
                },
                {
                    "sent": "So would be interesting to see whether we can use this.",
                    "label": 0
                },
                {
                    "sent": "Ring based approaches to estimate mission information in the parametric fashion.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Exactly, so that's all.",
                    "label": 0
                },
                {
                    "sent": "This offer is available on this website.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much.",
                    "label": 0
                }
            ]
        }
    }
}