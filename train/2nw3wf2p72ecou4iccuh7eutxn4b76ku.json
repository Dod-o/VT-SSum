{
    "id": "2nw3wf2p72ecou4iccuh7eutxn4b76ku",
    "title": "Are You for Real? Learning Event Factuality in Croatian Texts",
    "info": {
        "author": [
            "Goran Glava\u0161, University of Zagreb"
        ],
        "published": "Nov. 16, 2012",
        "recorded": "October 2012",
        "category": [
            "Top->Computer Science->Machine Learning->Supervised Learning",
            "Top->Computer Science->Natural Language Processing"
        ]
    },
    "url": "http://videolectures.net/is2012_glavas_event_factuality/",
    "segmentation": [
        [
            "Well hello everybody, now something slightly different from from the work that we've seen before.",
            "Something that is more linguistically motivated for thing.",
            "So I'm going to Lushan.",
            "Here's my coauthor.",
            "Yes, either we are from Zagreb, from Faculty of Electrical Engineering and Computing.",
            "So."
        ],
        [
            "A short introduction.",
            "What events factuality is then we show our simple lexically based model for event functionality.",
            "We showed evaluation results and we conclude."
        ],
        [
            "So what is event factuality?",
            "Well we have real world events occurring all the time and we have them represented in text.",
            "As linguistic events or event mentions.",
            "Is there a cold and sometimes these event mentions do not refer to real world events that actually occur, but they refer to something that didn't occur.",
            "They want to stress that something didn't occur or they want to express some level of uncertainty that the real world events occur an.",
            "As sorean pastels carry cantly defined it in manufacture, allati is the level of information that we can find in text that expresses the factual nature of events.",
            "You aren't factual.",
            "It is usually observed through two notions.",
            "Those are the one of polarity.",
            "Which should not be confused with sentiment polarity, which is which is more oftenly used.",
            "Polarity means is it stressed in the text that the event happened or is it stress that it did not happen and the other aspect is certainty?",
            "What is the level of confidence that is expressed in text about the real world event happening?",
            "So what?"
        ],
        [
            "We want to do is to attack this problem computationally.",
            "And as observed for English, the event factuality in text is the results of an interaction of multiple elements and those elements occur at lexical level at syntactical level and at discourse level.",
            "For example, in one sentence you can have a event mention saying that something might have happened and then later in the in the discourse you can have the same.",
            "The same event mention saying or the car referring event mention say that this didn't happen.",
            "So we need all these levels to confidently assess polarity uncertainty events.",
            "But for for many languages such as creation, which are resource poor, we don't have the adequate tools to attack these elements at syntactical level or discourse level.",
            "So what we wanted to do in this research is to investigate how well can we predict polarity and.",
            "Clark Kent and uncertainty events using only only lexical lexical features.",
            "The idea was let's see how well we can do using only words, just words."
        ],
        [
            "And we deal with two tasks we are aiming to predict polarity whether the event mentioned is positive or negative, or in other words, is it saying that something happened or is it saying that something didn't happen and the other task is to predict certainty in three categories?",
            "Is is it expressed?",
            "The something certainly happened, or is it expressed that something possibly happened?",
            "Or was it probably?",
            "Occurring so those are two classification task and we employ supervised machine learning and particularly SVM with linear kernel because we are reusing lexical lexical features.",
            "That means that the feature space with which we are dealing with is large.",
            "So linear kernel should do."
        ],
        [
            "No, no, it's classification, so no regression.",
            "Do two separate classification task, one for polarity and the other one for certain.",
            "And we have some features that we use for both tasks, which are words Lammas temps of the event anchors.",
            "Maybe I should clarify what an event anchor is.",
            "It is a word that bears the core meaning of the event.",
            "An we used our own morphic morphological execution for the lemmatization, and the simple stemming that removes the surface from the last file.",
            "Also some other features as ending of the event anchor morphosyntactic descriptors of the event anchors.",
            "Basically anything we can get from, like from lexical level, only purely lexical features, and we have bag of words features on the on the left and on the right context of the event anchor, and what.",
            "What we define as a context is is A5 talking window around the world."
        ],
        [
            "We also have some additional features which are event type.",
            "Those are the manually labeled types of events according to the time L standard for event extraction and additional features indicating if event anchor is a verbal or deverbal noun.",
            "If the sentence is interrogative.",
            "Because if the sentence is interrogative, then it is more likely that the events that are stated in that sentence are hypothetical or uncertain.",
            "And also we want to know if if the event is an argument of another event, because in such situations we have also the higher probability that the other event which is an argument is non factual.",
            "I have this example here in creation which means the striker failed to score the goal and scoring scoring is the argument of another event which is failing, so an it is non factual so.",
            "This might be a good indicator of non sexuality.",
            "How many types?",
            "I think 6666 or seven?",
            "Yeah, all currencies reporting intentional action.",
            "More like semantic classes, but on a higher level, not not.",
            "Not tide to a specific predicate or semantic role labeling, not something like that.",
            "Topical, yeah?",
            "Anne."
        ],
        [
            "Then we have additional features just for the polarity task, which are intuitive.",
            "We search for negativity clues in the short short context of the event anchors.",
            "And such words are of course no nothing, never neither, and also all the inflectional forms of verbs not to be.",
            "And not to want in creation and we search for those clues in the in the wider context, which means from the sentence start to demon tanker and in the immediate context also as to separate features.",
            "And we measured the distance between the event anchoring the closest negativity clue because if a negativity clue is right next to the event anchored in it's, there's a higher probability that.",
            "It's a non factual event."
        ],
        [
            "And for the certainty features, we also have a couple of sets of clues.",
            "One set is conditionality clues which include inflectional forms of wood and plus words for if or whether also future tense clues.",
            "Because when something is stated in the future it is practically by default uncertain to some level.",
            "Because it's in the future and we don't know at the point if it's going to for sure that it's going to happen and we also have some possibility clues which including inflectional forms of cankered plus maybe possibly.",
            "Etc.",
            "And we have some separate features for these sets of clues.",
            "And we measure also the distances from closest distances from the event anchor to each of the each of the closed sets."
        ],
        [
            "And about the data set, I should state in advance that it's a quite a small data set and there are some constant questions to that later in the evaluation I will stress.",
            "So we had a set of somewhere around 250 documents altogether that were manually labeled with events and temporal relations for another task for another paper an we use a subset of those documents.",
            "We use the fact that we have events already annotated, so we did additional annotation for clarity and certainty of those events on 90 documents and.",
            "As expected, you could see that the majority of events is labeled as positive and certain, which is to be expected because the documents that we used were newspaper texts and newspaper text mostly report about stuff that has already happened, has happened with certainty.",
            "So, but we still we have some examples of uncertainty or negativity.",
            "Yeah, sure.",
            "Documents yes suites altogether.",
            "4500 events even mentions.",
            "When you have many, yeah, the sentence level yeah like micro level events."
        ],
        [
            "So.",
            "Wait, what?",
            "What we used as a baseline?",
            "We took two baselines for both tasks.",
            "One is a majority class baseline.",
            "Since most of examples in the set are positive.",
            "Uncertain, we said OK, the baseline is, let's say, all all of them are positive or and all of them are certain and the other one is a simple rule based baseline.",
            "We said, let's use the clues that we that we put into features.",
            "Let's use them just as simple rules.",
            "If we have a node in front of event, let's say that's a negative event, and.",
            "We did that for clarity and certainty, and we said if we have any of the negativity close close to the close to the event, we would say it's a negative event.",
            "Or if we have any of the conditionality close close to the event will say it's possible.",
            "If we have any of the future tense clues will say it's probable.",
            "And we perform 1010 fold cross validation and report those results."
        ],
        [
            "So for the for the polarity task.",
            "We should focus on the scores for the negative class because the positive class is the majority, so it's expectedly high.",
            "Its results are expectedly high, but on the negative class we got somewhere around 77%, but I stayed at this.",
            "Results of a supervised model are not statistically significantly.",
            "Higher than the results are always baseline, which means OK, the results are good.",
            "We can with a supervised model.",
            "We can.",
            "We can get reasonable results for predicting negativity, but they are not better than a simple rule based baseline, which means which can mean two things.",
            "Either the problem is as easy as it seems, so it's just counting nodes in front of and tankers or.",
            "In our limited data set, we didn't have many examples that state negativity otherwise than than just simple clues.",
            "And there are such examples in language like the one I mentioned before where the attacker failed to scored a goal, so the scoring didn't happen and we don't have an O in front of it to indicate it, but it's indicated otherwise differently.",
            "If you say rule based rules would be such a rule.",
            "Like I said, it's just one rule well.",
            "Depends on the way you look at it, but basically it's counting clues in front of in front of the enclosed context of the event."
        ],
        [
            "And for certainty results here supervised model significantly outperforms the baseline, which also counts the close of uncertainty in front in front of the main tankers.",
            "But here the results are, let's say, rather low.",
            "An.",
            "We conclude that using only lexical features, we do not get results that could be.",
            "That could be perhaps used in real world applications because performance rates at 40 or 50% is not something you can actually use in the real world application and.",
            "Reasoning about factuality is important because if you have temporal reasoning.",
            "There is a different parting of reasoning.",
            "If you have certain events, and if you don't have certain events.",
            "If you have some uncertainty involved.",
            "And something that indicates that the lexical features in this is not shown because I didn't have space to put precision and recall for each class, but.",
            "Something that indicates that we need additional syntactic or discourse level features is that precision is higher than recall.",
            "It means that if we capture something, we capture it right in most cases, but we don't capture enough of it, so we need additional knowledge to recognize other examples of uncertainty.",
            "And."
        ],
        [
            "We conclude it was a supervised machine learning approach to recognizing that functionality in creation texts.",
            "The research was intended to investigate if lexical features and to what level do they suffice for recognizing.",
            "Non factuality or factuality depends on which way you want to look at it.",
            "And for predicting non polarity the results we got with the surprise model perhaps could be used in applications.",
            "They are at rates close to at close to 80%.",
            "But the problem is that the surprise surprise model performance is close too close to the performance of a simple rule based method which is.",
            "Then not so good.",
            "And for predicting then certainty, we can see that surprise model outperforms.",
            "So it does get some knowledge that you cannot catch with a simple simple rule based method.",
            "But the level of performance is not sufficient to be used for.",
            "For real world applications that we need, need additional syntactical knowledge or semantical knowledge or discourse level knowledge.",
            "And yeah, that's pretty much it."
        ],
        [
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well hello everybody, now something slightly different from from the work that we've seen before.",
                    "label": 0
                },
                {
                    "sent": "Something that is more linguistically motivated for thing.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to Lushan.",
                    "label": 0
                },
                {
                    "sent": "Here's my coauthor.",
                    "label": 0
                },
                {
                    "sent": "Yes, either we are from Zagreb, from Faculty of Electrical Engineering and Computing.",
                    "label": 1
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A short introduction.",
                    "label": 0
                },
                {
                    "sent": "What events factuality is then we show our simple lexically based model for event functionality.",
                    "label": 0
                },
                {
                    "sent": "We showed evaluation results and we conclude.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what is event factuality?",
                    "label": 1
                },
                {
                    "sent": "Well we have real world events occurring all the time and we have them represented in text.",
                    "label": 1
                },
                {
                    "sent": "As linguistic events or event mentions.",
                    "label": 1
                },
                {
                    "sent": "Is there a cold and sometimes these event mentions do not refer to real world events that actually occur, but they refer to something that didn't occur.",
                    "label": 0
                },
                {
                    "sent": "They want to stress that something didn't occur or they want to express some level of uncertainty that the real world events occur an.",
                    "label": 0
                },
                {
                    "sent": "As sorean pastels carry cantly defined it in manufacture, allati is the level of information that we can find in text that expresses the factual nature of events.",
                    "label": 1
                },
                {
                    "sent": "You aren't factual.",
                    "label": 0
                },
                {
                    "sent": "It is usually observed through two notions.",
                    "label": 0
                },
                {
                    "sent": "Those are the one of polarity.",
                    "label": 0
                },
                {
                    "sent": "Which should not be confused with sentiment polarity, which is which is more oftenly used.",
                    "label": 0
                },
                {
                    "sent": "Polarity means is it stressed in the text that the event happened or is it stress that it did not happen and the other aspect is certainty?",
                    "label": 0
                },
                {
                    "sent": "What is the level of confidence that is expressed in text about the real world event happening?",
                    "label": 1
                },
                {
                    "sent": "So what?",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We want to do is to attack this problem computationally.",
                    "label": 0
                },
                {
                    "sent": "And as observed for English, the event factuality in text is the results of an interaction of multiple elements and those elements occur at lexical level at syntactical level and at discourse level.",
                    "label": 1
                },
                {
                    "sent": "For example, in one sentence you can have a event mention saying that something might have happened and then later in the in the discourse you can have the same.",
                    "label": 0
                },
                {
                    "sent": "The same event mention saying or the car referring event mention say that this didn't happen.",
                    "label": 0
                },
                {
                    "sent": "So we need all these levels to confidently assess polarity uncertainty events.",
                    "label": 0
                },
                {
                    "sent": "But for for many languages such as creation, which are resource poor, we don't have the adequate tools to attack these elements at syntactical level or discourse level.",
                    "label": 0
                },
                {
                    "sent": "So what we wanted to do in this research is to investigate how well can we predict polarity and.",
                    "label": 0
                },
                {
                    "sent": "Clark Kent and uncertainty events using only only lexical lexical features.",
                    "label": 0
                },
                {
                    "sent": "The idea was let's see how well we can do using only words, just words.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And we deal with two tasks we are aiming to predict polarity whether the event mentioned is positive or negative, or in other words, is it saying that something happened or is it saying that something didn't happen and the other task is to predict certainty in three categories?",
                    "label": 0
                },
                {
                    "sent": "Is is it expressed?",
                    "label": 0
                },
                {
                    "sent": "The something certainly happened, or is it expressed that something possibly happened?",
                    "label": 0
                },
                {
                    "sent": "Or was it probably?",
                    "label": 0
                },
                {
                    "sent": "Occurring so those are two classification task and we employ supervised machine learning and particularly SVM with linear kernel because we are reusing lexical lexical features.",
                    "label": 1
                },
                {
                    "sent": "That means that the feature space with which we are dealing with is large.",
                    "label": 0
                },
                {
                    "sent": "So linear kernel should do.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "No, no, it's classification, so no regression.",
                    "label": 0
                },
                {
                    "sent": "Do two separate classification task, one for polarity and the other one for certain.",
                    "label": 1
                },
                {
                    "sent": "And we have some features that we use for both tasks, which are words Lammas temps of the event anchors.",
                    "label": 1
                },
                {
                    "sent": "Maybe I should clarify what an event anchor is.",
                    "label": 0
                },
                {
                    "sent": "It is a word that bears the core meaning of the event.",
                    "label": 1
                },
                {
                    "sent": "An we used our own morphic morphological execution for the lemmatization, and the simple stemming that removes the surface from the last file.",
                    "label": 0
                },
                {
                    "sent": "Also some other features as ending of the event anchor morphosyntactic descriptors of the event anchors.",
                    "label": 1
                },
                {
                    "sent": "Basically anything we can get from, like from lexical level, only purely lexical features, and we have bag of words features on the on the left and on the right context of the event anchor, and what.",
                    "label": 1
                },
                {
                    "sent": "What we define as a context is is A5 talking window around the world.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We also have some additional features which are event type.",
                    "label": 1
                },
                {
                    "sent": "Those are the manually labeled types of events according to the time L standard for event extraction and additional features indicating if event anchor is a verbal or deverbal noun.",
                    "label": 1
                },
                {
                    "sent": "If the sentence is interrogative.",
                    "label": 1
                },
                {
                    "sent": "Because if the sentence is interrogative, then it is more likely that the events that are stated in that sentence are hypothetical or uncertain.",
                    "label": 1
                },
                {
                    "sent": "And also we want to know if if the event is an argument of another event, because in such situations we have also the higher probability that the other event which is an argument is non factual.",
                    "label": 1
                },
                {
                    "sent": "I have this example here in creation which means the striker failed to score the goal and scoring scoring is the argument of another event which is failing, so an it is non factual so.",
                    "label": 0
                },
                {
                    "sent": "This might be a good indicator of non sexuality.",
                    "label": 0
                },
                {
                    "sent": "How many types?",
                    "label": 0
                },
                {
                    "sent": "I think 6666 or seven?",
                    "label": 0
                },
                {
                    "sent": "Yeah, all currencies reporting intentional action.",
                    "label": 0
                },
                {
                    "sent": "More like semantic classes, but on a higher level, not not.",
                    "label": 0
                },
                {
                    "sent": "Not tide to a specific predicate or semantic role labeling, not something like that.",
                    "label": 0
                },
                {
                    "sent": "Topical, yeah?",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Then we have additional features just for the polarity task, which are intuitive.",
                    "label": 0
                },
                {
                    "sent": "We search for negativity clues in the short short context of the event anchors.",
                    "label": 1
                },
                {
                    "sent": "And such words are of course no nothing, never neither, and also all the inflectional forms of verbs not to be.",
                    "label": 1
                },
                {
                    "sent": "And not to want in creation and we search for those clues in the in the wider context, which means from the sentence start to demon tanker and in the immediate context also as to separate features.",
                    "label": 0
                },
                {
                    "sent": "And we measured the distance between the event anchoring the closest negativity clue because if a negativity clue is right next to the event anchored in it's, there's a higher probability that.",
                    "label": 1
                },
                {
                    "sent": "It's a non factual event.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And for the certainty features, we also have a couple of sets of clues.",
                    "label": 1
                },
                {
                    "sent": "One set is conditionality clues which include inflectional forms of wood and plus words for if or whether also future tense clues.",
                    "label": 1
                },
                {
                    "sent": "Because when something is stated in the future it is practically by default uncertain to some level.",
                    "label": 1
                },
                {
                    "sent": "Because it's in the future and we don't know at the point if it's going to for sure that it's going to happen and we also have some possibility clues which including inflectional forms of cankered plus maybe possibly.",
                    "label": 0
                },
                {
                    "sent": "Etc.",
                    "label": 1
                },
                {
                    "sent": "And we have some separate features for these sets of clues.",
                    "label": 0
                },
                {
                    "sent": "And we measure also the distances from closest distances from the event anchor to each of the each of the closed sets.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And about the data set, I should state in advance that it's a quite a small data set and there are some constant questions to that later in the evaluation I will stress.",
                    "label": 0
                },
                {
                    "sent": "So we had a set of somewhere around 250 documents altogether that were manually labeled with events and temporal relations for another task for another paper an we use a subset of those documents.",
                    "label": 0
                },
                {
                    "sent": "We use the fact that we have events already annotated, so we did additional annotation for clarity and certainty of those events on 90 documents and.",
                    "label": 1
                },
                {
                    "sent": "As expected, you could see that the majority of events is labeled as positive and certain, which is to be expected because the documents that we used were newspaper texts and newspaper text mostly report about stuff that has already happened, has happened with certainty.",
                    "label": 1
                },
                {
                    "sent": "So, but we still we have some examples of uncertainty or negativity.",
                    "label": 0
                },
                {
                    "sent": "Yeah, sure.",
                    "label": 0
                },
                {
                    "sent": "Documents yes suites altogether.",
                    "label": 0
                },
                {
                    "sent": "4500 events even mentions.",
                    "label": 0
                },
                {
                    "sent": "When you have many, yeah, the sentence level yeah like micro level events.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Wait, what?",
                    "label": 0
                },
                {
                    "sent": "What we used as a baseline?",
                    "label": 0
                },
                {
                    "sent": "We took two baselines for both tasks.",
                    "label": 1
                },
                {
                    "sent": "One is a majority class baseline.",
                    "label": 0
                },
                {
                    "sent": "Since most of examples in the set are positive.",
                    "label": 0
                },
                {
                    "sent": "Uncertain, we said OK, the baseline is, let's say, all all of them are positive or and all of them are certain and the other one is a simple rule based baseline.",
                    "label": 0
                },
                {
                    "sent": "We said, let's use the clues that we that we put into features.",
                    "label": 0
                },
                {
                    "sent": "Let's use them just as simple rules.",
                    "label": 0
                },
                {
                    "sent": "If we have a node in front of event, let's say that's a negative event, and.",
                    "label": 0
                },
                {
                    "sent": "We did that for clarity and certainty, and we said if we have any of the negativity close close to the close to the event, we would say it's a negative event.",
                    "label": 1
                },
                {
                    "sent": "Or if we have any of the conditionality close close to the event will say it's possible.",
                    "label": 1
                },
                {
                    "sent": "If we have any of the future tense clues will say it's probable.",
                    "label": 0
                },
                {
                    "sent": "And we perform 1010 fold cross validation and report those results.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So for the for the polarity task.",
                    "label": 0
                },
                {
                    "sent": "We should focus on the scores for the negative class because the positive class is the majority, so it's expectedly high.",
                    "label": 0
                },
                {
                    "sent": "Its results are expectedly high, but on the negative class we got somewhere around 77%, but I stayed at this.",
                    "label": 0
                },
                {
                    "sent": "Results of a supervised model are not statistically significantly.",
                    "label": 1
                },
                {
                    "sent": "Higher than the results are always baseline, which means OK, the results are good.",
                    "label": 1
                },
                {
                    "sent": "We can with a supervised model.",
                    "label": 0
                },
                {
                    "sent": "We can.",
                    "label": 0
                },
                {
                    "sent": "We can get reasonable results for predicting negativity, but they are not better than a simple rule based baseline, which means which can mean two things.",
                    "label": 0
                },
                {
                    "sent": "Either the problem is as easy as it seems, so it's just counting nodes in front of and tankers or.",
                    "label": 0
                },
                {
                    "sent": "In our limited data set, we didn't have many examples that state negativity otherwise than than just simple clues.",
                    "label": 0
                },
                {
                    "sent": "And there are such examples in language like the one I mentioned before where the attacker failed to scored a goal, so the scoring didn't happen and we don't have an O in front of it to indicate it, but it's indicated otherwise differently.",
                    "label": 1
                },
                {
                    "sent": "If you say rule based rules would be such a rule.",
                    "label": 0
                },
                {
                    "sent": "Like I said, it's just one rule well.",
                    "label": 0
                },
                {
                    "sent": "Depends on the way you look at it, but basically it's counting clues in front of in front of the enclosed context of the event.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And for certainty results here supervised model significantly outperforms the baseline, which also counts the close of uncertainty in front in front of the main tankers.",
                    "label": 1
                },
                {
                    "sent": "But here the results are, let's say, rather low.",
                    "label": 0
                },
                {
                    "sent": "An.",
                    "label": 0
                },
                {
                    "sent": "We conclude that using only lexical features, we do not get results that could be.",
                    "label": 1
                },
                {
                    "sent": "That could be perhaps used in real world applications because performance rates at 40 or 50% is not something you can actually use in the real world application and.",
                    "label": 0
                },
                {
                    "sent": "Reasoning about factuality is important because if you have temporal reasoning.",
                    "label": 0
                },
                {
                    "sent": "There is a different parting of reasoning.",
                    "label": 0
                },
                {
                    "sent": "If you have certain events, and if you don't have certain events.",
                    "label": 0
                },
                {
                    "sent": "If you have some uncertainty involved.",
                    "label": 0
                },
                {
                    "sent": "And something that indicates that the lexical features in this is not shown because I didn't have space to put precision and recall for each class, but.",
                    "label": 0
                },
                {
                    "sent": "Something that indicates that we need additional syntactic or discourse level features is that precision is higher than recall.",
                    "label": 1
                },
                {
                    "sent": "It means that if we capture something, we capture it right in most cases, but we don't capture enough of it, so we need additional knowledge to recognize other examples of uncertainty.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We conclude it was a supervised machine learning approach to recognizing that functionality in creation texts.",
                    "label": 1
                },
                {
                    "sent": "The research was intended to investigate if lexical features and to what level do they suffice for recognizing.",
                    "label": 0
                },
                {
                    "sent": "Non factuality or factuality depends on which way you want to look at it.",
                    "label": 0
                },
                {
                    "sent": "And for predicting non polarity the results we got with the surprise model perhaps could be used in applications.",
                    "label": 0
                },
                {
                    "sent": "They are at rates close to at close to 80%.",
                    "label": 0
                },
                {
                    "sent": "But the problem is that the surprise surprise model performance is close too close to the performance of a simple rule based method which is.",
                    "label": 0
                },
                {
                    "sent": "Then not so good.",
                    "label": 0
                },
                {
                    "sent": "And for predicting then certainty, we can see that surprise model outperforms.",
                    "label": 0
                },
                {
                    "sent": "So it does get some knowledge that you cannot catch with a simple simple rule based method.",
                    "label": 0
                },
                {
                    "sent": "But the level of performance is not sufficient to be used for.",
                    "label": 0
                },
                {
                    "sent": "For real world applications that we need, need additional syntactical knowledge or semantical knowledge or discourse level knowledge.",
                    "label": 0
                },
                {
                    "sent": "And yeah, that's pretty much it.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}