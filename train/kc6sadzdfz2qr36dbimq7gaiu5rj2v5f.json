{
    "id": "kc6sadzdfz2qr36dbimq7gaiu5rj2v5f",
    "title": "Learning with Probabilities",
    "info": {
        "author": [
            "Neil D. Lawrence, Department of Computer Science, University of Sheffield"
        ],
        "published": "Aug. 13, 2010",
        "recorded": "May 2010",
        "category": [
            "Top->Computer Science->Machine Learning->Bayesian Learning",
            "Top->Computer Science->Machine Learning",
            "Top->Computer Science->Machine Learning->Statistical Learning",
            "Top->Computer Science->Machine Learning->Principal Component Analysis"
        ]
    },
    "url": "http://videolectures.net/mlss2010_lawrence_mlfcs2/",
    "segmentation": [
        [
            "So what I want."
        ],
        [
            "Do it.",
            "Start with a bit of a probability review.",
            "I'll try and go through that quickly, but it will hopefully serve to sort of introduce the notation in the way I'm using it, and perhaps point out a couple of things that.",
            "I didn't really think about until after I'd been using probabilities for awhile, even if they are perhaps obvious to other people, then I'll talk about probabilistic modeling for supervised learning.",
            "And I'll end bet on doing some unsupervised learning clustering and dimensionality reduction.",
            "I guess it's an hour and a half and I think you could.",
            "You could do an hour and a half on any one of the things I'll talk about.",
            "So obviously there will be details missing."
        ],
        [
            "OK so last time.",
            "I introduced some different learning scenarios and well, initially I use learning rules to introduce them, and indeed we saw in some of the cocci talks the use of talking about learning rules and heavy and learning and how that can be related to what's going on in the brain.",
            "But I sort of at the end tried to say well what's really going on is there's an error function and we're trying to descend the gradient of that.",
            "Now, Bernards talk.",
            "He mentioned empirical risk minimization, and indeed most of what he was talking about was taking the empirical risk and combining it with a term that was reflecting the complexity of the model being used to try and make an estimate of the true risk or the sort of risk on test data.",
            "That's one way of going, and in that case you're actually assuming that the thing you're minimizing is the actual cost function you're interested in, so.",
            "That's an important difference for this, and people confuse it.",
            "People think that we are interested in loss function.",
            "That is the log likelihood.",
            "That's not really the justification.",
            "In probabilistic approaches, the justification probabilistic approaches is that you're fitting the log likelihood and by fitting the log likelihood you're trying to understand the real probability distribution underlying the data, and in particular the whole idea of what your cost function is a separate issue.",
            "You try and make it a separate issue.",
            "In fact, for a lot of cases you can't make it a separate separate issue.",
            "But basically that's the premise that you're going to make that cost function that is at the core of empirical risk minimization, a separate thing.",
            "So the error function as we see it can be seen as the logarithm of a probability density."
        ],
        [
            "Function, But before we take that perspective, I just want."
        ],
        [
            "Quickly review probability, so I mean, I've go through this slide very quickly because I just want to sort of really use this to introduce Bayes rule.",
            "So you should you should know these different things, the joint probability, the probability of X, which is 1 variable having the value of little X&Y.",
            "Another variable having the value of little wife.",
            "Notice this notation is extremely clumsy, but if any of you have programmed in something like Python, it's a bit like Python where you actually indicate the arguments you passed your function by, what their.",
            "Role is going to be so you can change the ordering of these arguments.",
            "That's important because you do that all the time in probabilities.",
            "Once you drop these axes and wise it doesn't change the value of the probability, so there's sort of different notation to function notation, and it took me a long time before I notice that.",
            "But the reason is because it's more like a Python function than, say, AC function, where the ordering of the.",
            "Arguments is important.",
            "The marginal probability is the probability of X being equal to X, regardless of what.",
            "Why is so?",
            "This is the probability of them both being equal to these things and then the conditional probability is the probability that X is equal to X given that we've observed why it wise."
        ],
        [
            "Those are the three.",
            "Main types probability will be looking at and they can be represented in this way.",
            "If we've got X and it's taking discrete values from one to six and why it is taking discrete values from one to four, and we've got practice example instantiation's of what these values are, so these are sort of events, and we're categorizing this event here as X equaling two and Y equaling 3.",
            "And we can look at the counts in any one of these boxes.",
            "So there's three boxes here.",
            "There's a box for X = 5, A box for y = 4 In a box for S = X = 3, and y = 3."
        ],
        [
            "So the definition of these things is that for the."
        ],
        [
            "Probability we're looking at this box here so the colors mismatch.",
            "Apologies for that."
        ],
        [
            "Dividing it by the total number of crosses and taking the limit as X goes to Infinity, that's actually a frequentist definition of probability.",
            "So that's a very probably the one most people have seen before.",
            "It's an interesting one because, of course S never really does go to Infinity, but it will be happy with that definition.",
            "For the moment, the marginal will be."
        ],
        [
            "So the model for X is this box here."
        ],
        [
            "Really bad I've got the colors matching.",
            "Sorry so the blue box is the limit as we saw all those the ones in that box as X goes to Infinity and the conditional."
        ],
        [
            "We'll be looking at one of these boxes here.",
            "X = X three and y = 4, and then dividing by the way."
        ],
        [
            "On in another box, yeah, so for y = 4, so you divide."
        ],
        [
            "Instead of dividing by all the total, you divide of the ones."
        ],
        [
            "The other given.",
            "So the nice thing about those?"
        ],
        [
            "The little definitions and I think this is something that I first saw when I was asked, and in 1996, and Chris Bishop used this way of introducing probabilities.",
            "It wasn't in his first book, but I think it's in his second actually to do it this way.",
            "I haven't read his second, but I think I saw it in there briefly.",
            "Um?",
            "So it's a nice way of introducing all these different things, because you can introduce the rules of probability from it.",
            "So as I was saying before, we typically we should write out this full definition of the probability right?",
            "We should.",
            "To be clear, we should be saying X is equal into little X&Y is equal to the little wife, but in practice we often use this little shortcut and the implication is somehow there's a missing capital X equals, but that has this effect, so this looks very much like we might write a multivariate function like F of X, Y is equal to X / y, but then of course X of X, YF of X, Y is not equal to F of Y, X.",
            "In probabilities, that is true because of that subtle point, but it caused a big argument once with a postdoc.",
            "So to clarify it.",
            "I think he didn't realize that because he was a mathematician, so he was thinking of that.",
            "He didn't believe in that."
        ],
        [
            "I had to explain it to him.",
            "OK, so all distributions are normalized and that can be easily seen from the definition we've seen before by summing over one of these marginals is just the sum of all the things in that marginal divided by the total, which is equal to 1 and marginalization is a really important property of probabilities because it has effects.",
            "It has effects in maximum likelihood when you when you push up your likelihood in one region because the distribution is normalized, it must be suppressed.",
            "In other regions it goes down elsewhere, so it's like a.",
            "It's like a sort of tent when you.",
            "If you want your probability to go up here, your and its attendant it's peg down, then it will go down somewhere else.",
            "If you lift a poll of 10 other parts of it go down, and so that's a sort of important property.",
            "The tent has a certain fixed volume.",
            "In the probability case, and as you move it up and down, it must go down elsewhere.",
            "That's so that's."
        ],
        [
            "Important.",
            "The marginal probability is just the summing across all the axes.",
            "You should know that that's the sum rule of probability, and this is probably one of the biggest pains we experience.",
            "It looks very innocent, but in practice when we're looking at very large state spaces, doing these sums can be very very hard.",
            "When exploring a large state space.",
            "So this is the one of the hardest things to deal with."
        ],
        [
            "Mobility, so it's the sum rule probability and then the product rule of probability is just relating the joint distribution to the conditional distribution.",
            "So probability of X given Y times probability of Y is equal to the probability of X&Y and that can all be seen just by go."
        ],
        [
            "Through those definitions, now the nice thing.",
            "Is the simple definitions will also lead to something that some people think is controversial and one of the points of introducing in that way is you can see this is completely noncontroversial.",
            "Bayes rule is not controversial, it is true.",
            "If you want to invert a probability, this is the way to do it, so you can equate the joint probabilities.",
            "In this way, probability of X, Y is equal to the probability of Y, Rex and probability.",
            "Why, Rex time is equal to appear like given XCOM appear Vexin.",
            "So we can write this basically and then you just divide that into that side and you get this ability to invert the probability go from this probability Y given X, the probability of X1, and that's important.",
            "Now Basded right about this and they I've tried to read his paper.",
            "The introduction is really clear.",
            "It's written by someone else called Richard Price, and the epilogues really clear and most of what you get from the papers from that and then reading the actual paper is not very clear.",
            "Read Laplace to on his.",
            "I can't remember the name of the actual paper where he effectively doesn't define Bayes rule, but he does a lot more interesting stuff with it and I think as a Brit it pains me to say it.",
            "But Laplace is far more interesting than Bazan, and he there's an enormous amount of work on on using this rule without ever actually explicitly saying what the rule is.",
            "An he post date.",
            "Some postdates basil think which is why people credits and base.",
            "But I think if your friends, you can be mightily proud of Laplace.",
            "Who seems to me it's a little bit depressing if you read the class because I realized that my entire research career was already envisaged by Laplace 200 years ago, and it was only through lack of having a computer that he didn't do the sort of things that we do.",
            "But basically he worked out approximations for doing Bayesian inference.",
            "He worked out, talked about error functions, fitting models to data, astronomical models to data.",
            "And he also was first interested.",
            "The example.",
            "He looks at this is for biased coins.",
            "He was interested in what they called.",
            "I think the French called them English dice so.",
            "I suspect we call them French dice, but whether a coin with biased or not, and analyzing that sort of question using Bayes rule, that's what his pay."
        ],
        [
            "Where is about.",
            "Coming.",
            "Coming controversies coming.",
            "Nothing controversial yet, so one of the things we need to do and I won't show a great deal of this.",
            "Well, I there is some examples of this, but what we want our probability distribution to do is reflect our model of the world.",
            "So we want to represent user probability distribution to represent.",
            "Belief state that is sort of in some ways that's against the frequentist definition that was there before, but it's sort of provable that you can have a consistent calculus of probabilities where this does this.",
            "So if you've got a belief state about what you think the world is like, but then you're interested in some function of what that world is like.",
            "Then you want you want to do is very often is compute expectations of that function.",
            "So expectations I'm using this angle notation that I find very convenient.",
            "Of course, lots of other people use this sort of E notation.",
            "I like the angle notation 'cause you know it's it's compact and you can also drop in the distribution under which are taking the expectation there.",
            "Some people put the conditioning sign and put the expectation there.",
            "So the mean of the distribution is is a very useful expectation, and it's just the expectation of X and the variance is computed from a couple of expectations.",
            "Then that's."
        ],
        [
            "How diffuse the distribution?",
            "So one of the things I'm not going to talk about is probabilistic graphical models, but Sylvia is going to talk about that.",
            "I think tomorrow, so I'm not going to look at these sort of representations of probabilities much anymore.",
            "But one way of representing probabilities is at a table, so you've got some different outcomes.",
            "And then here's the probability of each of these outcomes, and obviously they sum to one.",
            "But I prefer to represent them as functions, although this next example is some."
        ],
        [
            "It definitely can be represented as a table.",
            "It looks very complicated when represented as a function, so binomial distribution is very commonly used distribution and I think I don't know if he invented it, but it's one of Jacob.",
            "Bernoulli's did a lot of work on it, and certainly he described it in a certain way, which is going to be important in our controversy.",
            "That's coming up.",
            "This isn't controversial, but the later it will be, so he said, imagine you've got an urn with some black and red balls.",
            "What's the probability if you take a?",
            "Ball out.",
            "That it's going to be black or red.",
            "And if you put it back in and then take another one out.",
            "What's the probability that it's gonna be black or red?",
            "But if you say red is a success and you keep on and you sum the number of successes as you keep doing this, then the binomial distribution gives you the probability distribution over number of successes, which I've called why it's not a very good notation for successes and S for the number of trials.",
            "So given a number of trials, is the distribution of the number of successes.",
            "I'm just keeping using wires.",
            "It's a main objective data interest and S is the number of trials.",
            "So this is the binomial coefficient.",
            "And then this thing here.",
            "It looks nasty, but these things are these things are just probabilistic switches, so if Y is one or zero one for a success, then what the one does is switches in the pie.",
            "One trial, for example.",
            "So if you have one trial, this term disappears.",
            "It's just one, and that's how I'll mainly use this distribution.",
            "So for one trial you get a \u03c0 to the power of 1 * 1 -- \u03c0 can power of 0, so these powers of something that is either 01.",
            "They acted like a switch or mathematical switch to switch on different parts of the system, and I'll use that later as well.",
            "It's a clearer context, so that's the binomial distribution.",
            "It's just using the probability of success, as in a Red Bull being a success being."
        ],
        [
            "High and then you can look at this density as a discrete density over Y for different values of S and probability of success.",
            "So here's 20 trials and with probability of success being .4, that's very widely used physical distribution."
        ],
        [
            "I wanted to talk about it, particularly because I want you to bear this in mind.",
            "So fundamentally what he's saying is that there are.",
            "The ratio of red to black and red balls is given by \u03c0, so that's a fixed number of things that are in the urn."
        ],
        [
            "OK, so remember that.",
            "So far we've talked about discrete values of X&Y, but for continuous models we use probability density functions.",
            "Now probably didn't see functions are odd beings.",
            "In some sense they are misleading 'cause you can use them almost exactly as user probability distribution, but you can't say it meaningless to say what's the probability of an individual number, yeah?",
            "It's completely meaningless, so.",
            "What is the probability density function encapsulate well?"
        ],
        [
            "Here's an example of one, and it's a Gaussian will go back to its form.",
            "What is actually encapsulate Ng is the ability to ask any question I'm interested in about the variable over which I'm dealing with.",
            "So here if I'm interested in Heights, I can't ask what's the probability that someone is 1.5 meters tall.",
            "The reason I can't ask that is because there's infinite possible Heights on this input so that.",
            "You know this is a zero probability of being 1.5 millimeters tall, exactly because there's infinite different Heights you can be, but what you can ask these questions like what's the probability of being between 1.5 meters and two meters, and the way you ask that question as you integrate between those two values.",
            "This function now because this function is constrained to integrate to one.",
            "Now will always be a probability and any question you can think of which you can be turned into discrete terms can be asked about this function and you can get an answer in discrete probabilities.",
            "The only problem where the only time when this problem arises when you're computing likelihoods, because what what you'll find is if you compute likelihoods of this you can have likelihoods greater than one.",
            "So if you look at the probability of being 1.5 meters tall, you'll see it's two, but that's 'cause it's nonsensical thing, right?",
            "It doesn't exist none of these probabilities are too.",
            "The reason you got two here is because the width here is about .5.",
            "Yeah, so the overall height with distribution is about two.",
            "Yeah, so be aware of that because it's a sanity check for discrete probability distributions that your likelihoods should never be greater than one.",
            "It is not a sanity check for continuous probability distributions that your likelihood should never be greater than one.",
            "It also affects things like there's all sorts of things you can do to re scale, which is sort of meaningless in terms of answering these discrete questions so I can take the logarithm of this input and then the discrete questions I ask, I'll get.",
            "All the same answers out, but the shape and form of this function will be completely different.",
            "So."
        ],
        [
            "I mean, it may be subtle and it's actually you don't have to worry about it most of the time, but sometimes it bites you, so that's a Gaussian density and it has to integrate to one, and it has that sort of form.",
            "So apparently proposed, maybe first by DeMar who was a French eugeno living in London.",
            "It was, I think, mainly developed by Laplace and the great thing.",
            "The first time Laplace uses it, he uses it to approximate Bayesian inference.",
            "He invents independently invents the Gaussian distribution to do the Laplace approximation and perform Bayesian inference.",
            "So I kind of love Laplace for that because I think it's great that I mean no tomorrow also mentioned that unfortunately.",
            "But the second mention of it was was for doing Bayesian inference."
        ],
        [
            "So has this multivariate form as well, which will make a lot of use."
        ],
        [
            "So this is across a single variable which might."
        ],
        [
            "Height and then these are variables here which you need a covariance matrix to describe correlations between these variables and you have a mean and so and so forth, OK?",
            "So this is allows you to sort of describe joint distributions."
        ],
        [
            "Over."
        ],
        [
            "Multiple outputs."
        ],
        [
            "OK, so the other thing I want to mention it was which we're not going to use a lot, but it's there and it's very important in probabilities is sample based approximations.",
            "Very often you can't compute the expectations that you're interested in exactly, but what you can do is you can have samples from the density you're interested in, and then you can have a sample in the law of large numbers that Bernard was mentioning.",
            "You can have a sample based approximation to the expectation you're interested in.",
            "So that used to confuse me a bit, because of course the sample mean is is we always talk about means what we think of is sample means, but in some ways that's just an approximation to the true mean.",
            "But we say both of these things are means.",
            "But what we really mean when we're saying this is the sample mean I I tend to think of that as being the true mean, but anything can be computed in that way.",
            "Of course, when we're looking at data, that's what we effectively have.",
            "We have some unknown distribution, and we have samples from it and that sort of thing Bernard was talking about in terms of law of large numbers and convergence is making these sample based approximation."
        ],
        [
            "You've got samples from some unknown distribution."
        ],
        [
            "OK.",
            "So that's as much as I want to talk about on the review.",
            "A probability, hopefully it wasn't well, hopefully there's something in there, so this is what we should have had before, so last time we talked about error functions and we said OK, this is how we're measuring the quality of our regression and we said we were going to come across some output from some function.",
            "So this is a set of bases that we had before those sort of bumps, and then these waiting of these bumps minus the actual target.",
            "So this was our like Delta Yi Squared and the sum of that for every data point we observe.",
            "So the quadratic error function can be seen as a Gaussian noise model.",
            "So the way that works is imagine this is our data generating process and we often talk about generative models, and this is sort of what we mean that our X is inside this basis function.",
            "This vector of basis functions here and what we're observing is why.",
            "Which is a function of X which is a linear weighted set of basis functions.",
            "Plus now this is the new bit.",
            "This is what we have before epsilon where epsilon is Gaussian noise with standard deviation Sigma.",
            "Now this noise model assumption is sort of critical.",
            "It's something you didn't see in what Bernard was talking about, because when he's generating a loss function, you're not actually considering the noise.",
            "What you're considering is the penalty you will pay for getting things incorrect.",
            "This is nothing to do with the penalty you'll pay for getting things incorrect.",
            "So let's say I'm ordering lumber.",
            "From 'cause I've got supply and demand, so I need to buy in lumber to deliver to my customers.",
            "Now there's two things that can happen, right?",
            "If I don't have the right amount of lumber, I might pay a cost for having the incorrect.",
            "If I run out, I pay a cost on missed sales.",
            "If I've got too much, it rods so there's an amount of money I can say that's my cost, right?",
            "So that's one thing, but another thing is the demand for lumber.",
            "So the cost might be.",
            "I don't know linear in the amount of.",
            "In the incorrectness of my lumber prediction, but the demand for lumber might be coming from a Gaussian distribution, so it might be quadratic.",
            "So these things are these two things are important and different.",
            "In some ways actually, I would say that what the frequentist approach that Bernard was describing is more correct because you're trying to take into account your cost at the time of fitting your model.",
            "In the Bayesian approach, you don't do that, and there's a reason why or in this maximum likelihood approach.",
            "Either you won't do that.",
            "The reason why you don't do that is you know that if your model is correct, you don't need to worry about that, so you can prove that you can say if the thing for the model you've got for the system is correct, you don't have to worry about the cost until later.",
            "So that's a really nice separation.",
            "You can do these two things separately.",
            "You worry about your inference, as I would call it.",
            "Then you worry about your cost.",
            "Of course, in practice that's never really true.",
            "You never know you've got the correct model, so you can't really do that separation.",
            "But the nice thing about the separation is it makes everything simpler.",
            "It makes model construction simpler, so you have to be more intelligent to be a frequentist, I would say.",
            "So I'm a Bayesian because it's mechanical and I don't have to think so hard so I can do more with my limited brainpower.",
            "OK, so.",
            "This is Gaussian noise we're adding on here, but it's a product of the generating system."
        ],
        [
            "Nothing to do with the cost.",
            "So once we've got said that this implies that we can write this down, and this is a sort of way we describe a likelihood in this case, that implies that Y is drawn from a Gaussian."
        ],
        [
            "Distribution with the mean given by that.",
            "And since the noise is 0."
        ],
        [
            "Mean when you add noise to a Gaussian, you're just adding you, effectively making that the mean of the distribution.",
            "You're adding a constant function to a zero mean Gaussian, which just means the mean of the new thing is that yeah, so we can also write that I would write that is, that's you, that this is the sort of a very statistical notation.",
            "This till the thing here means.",
            "Why is sampled from this?",
            "And another way of writing that is that the probability of Y given W and Sigma is this Gaussian distribution, so.",
            "My wife is dependent on these parameters and it's dependent through this Gaussian distribution, so I might interchange between those two styles, but they're basically identical, just the wise miss."
        ],
        [
            "Off there.",
            "Now.",
            "One of the things I think is quite confusing is IID assumptions.",
            "The way I think of IID assumptions.",
            "Which you mentioned all the time is this.",
            "So if the noise is sampled independently for each data point from the same density.",
            "So if this noise that we're seeing this corrupting influence is independent every time we get a data point and it's coming from the same dense to each time, that's what I think of as an IID assumption.",
            "I don't like to think of the model as being an IID assumption, because it would seem weird if they were all my data points were completely independent, then I'm not going to learn anything.",
            "So I think of the noise is being IID.",
            "So if we make this IID assumption that the noise is coming independently each time, then we can write down.",
            "Independence allows us to write the joint distribution over Y is just the product of the marginals, so we can write that down in that form, and that's the standard sort of assumption for a regression problem.",
            "And that means that we have a likelihood of this form, so the likelihood is this joint distribution over these Gaussian things.",
            "Now what we're going."
        ],
        [
            "Do is click through here.",
            "We're going to look at that term and say, OK, there's a term there, but it's not dependent on these parameters that I was."
        ],
        [
            "Sitting before so I'm going to ignore it and I'm just going to say that this is proportional to."
        ],
        [
            "That so that was the constant proportion."
        ],
        [
            "It keeps this curve one, so I'm just going to."
        ],
        [
            "Laugh.",
            "Now I'm gonna look at that Prada."
        ],
        [
            "Often say, well, I can pull that product inside the exponential product of exponentials is the same as the exponential of the sums.",
            "So I'm going to."
        ],
        [
            "That then."
        ],
        [
            "I'm going to look at the."
        ],
        [
            "Potential and say well I can remove that by putting a logarithm on the other side.",
            "So now I've got something of this form."
        ],
        [
            "So by constant proportionality here now becomes an additive constant here.",
            "Now I'm going to look at that term and say, well, OK, up to."
        ],
        [
            "A scalar.",
            "That is equal to the error function I defined before, yeah, so.",
            "Before we were minimizing this error function, but now we can see that that error function is equivalent to a negative log likelihood.",
            "OK, negative, so if I minimize.",
            "Something and then take its negative.",
            "I'm maximizing the negative, so in fact I'm if I minimize the error function.",
            "I'm maximizing the log likelihood and then the important thing about the log is it's a monotonic function.",
            "I never got that powered up, did I?",
            "Well, I won't draw then.",
            "Thing about the log is it's a monotonic function.",
            "So if you've got a monotonic function.",
            "If you maximize something and then you Mac and then you put it through a monotonic function, it doesn't change the ordering of things.",
            "So if I you can think about that in the discrete case.",
            "If I take the logarithm of a discrete set of numbers and then I want to find the function.",
            "Sorry I had something are not explaining that very well.",
            "Because it's a monotonic function, if I maximize log of this, I'm also maximizing that itself so I can take the negative log likelihood.",
            "I can minimize the negative log likelihood, and I'm effective."
        ],
        [
            "Maximizing the likelihood.",
            "So the probabilistic interpretation for the error function is the negative log likelihood and minimizing this error function is equivalent to maximizing the log likelihood.",
            "So maximizing the log likelihood is equivalent to maximizing the likelihood because the log is monotonic, so this is the probabilistic interpretation of the error function.",
            "It's basically the.",
            "Minimizing the error function is equivalent to maximizing likelihood with respect to the parameters, so this is called maximum likelihood.",
            "So everything we saw before can be reinterpreted in that way.",
            "Now there was a question in the break after I spoke last time.",
            "Is it true that every error function can be interpreted as a maximum likelihood and the answer is no, because you can imagine error functions that you can't normalize.",
            "And if you can't see when you take the exponential.",
            "Of the error function, you can't actually normalize the result, and if that's the case you can't think of it as maximum likelihood because you don't have this property of a probability distribution, so normalization is vital for to claim some things in probability distribution."
        ],
        [
            "So, but most things the people that using typically can be treated that way.",
            "I know the example that was given was an example not, but there's most sort of standard things people are using.",
            "Is error functions.",
            "You can interpret as likelihood.",
            "So if the data was really generated according to the model be specified, that likelihood really had Gaussian noise plus that.",
            "Weighted linear summer basis functions.",
            "Then what you can say is that the correct parameters will be converged in the limit as N goes to Infinity.",
            "Personally, this is a you know this consistency proof.",
            "I don't remember the last time someone gave me infinite data, so I'm not sure how much I care about these proofs.",
            "Personally, it's as Bernard was mentioning the rate of convergence.",
            "That's actually quite important, but in some sense I really am interested in very low data areas, so it's true, you know, I think a lot of what say Google are doing with very large datasets is reliant on this.",
            "You know, we've got a limited number of parameters, a lot of data and things work really well in that region, and you can prove that this is the case by using the law of large numbers, ANAN showing.",
            "But what you're doing is is more minimizing what's called a callback.",
            "Leiber divergent between the true distribution in your approximation, and this is like a mainstay of classical statistics, although I mean it's credited to Fisher a lot, I haven't really read the papers, but you know, you can go back to Gauss.",
            "His explanation of least squares.",
            "So what I've described to you in this error function is least squares, and I think if you're talking Gauss is sort of re explanation of what these squares was, 'cause he didn't invent it, then you're going back to something like 1810.",
            "That physicists were doing this, so This is why I keep looking at physicists and thinking over there a little bit ahead of machine learning people they just didn't have the computers, so that was their interpretation.",
            "That was Gauss's interpretation, and he claimed that he found that Planet series or whatever it's called the dwarf planet.",
            "He refound where it was through applying this.",
            "Basically in he found that he made that claim in order to justify he didn't."
        ],
        [
            "At least squares first."
        ],
        [
            "That might be a bit dodgy.",
            "I'm so Germans and French.",
            "Where it was at apparently.",
            "So this is the likelihood for aggression, and the suggestion is to maximize this with respect to W. That's what we've been doing in the last time, and that could be done with the gradient based optimization of the log likelihood.",
            "Now there's an alternative approach, and this is the Bayesian approach, so the alternative approach is not to optimize this W, but to integrate it out.",
            "This is where the controversy starts.",
            "So what we're going to do is effectively consider the expected values of all the likelihoods under a range of potential WS that we believed in.",
            "So when Bernard was talking before about prior knowledge over functions, this is effectively how in this model you're introducing that prior knowledge is saying I'm going to have a distribution for W, so I purposefully write my parameters is conditioning as if they are random variables, and that means that I can think of appeared W and then use the sum rule to integrate it out.",
            "That's what goes on."
        ],
        [
            "In the Bayesian approach.",
            "So we're going to use Bayes rule to implement the Bayesian approach an, but basing is not named after Bayes rule.",
            "This is very common confusion if you don't use Bayes rule to invert probability, you're just wrong.",
            "You're not being frequentist.",
            "Bayesian refers to something different.",
            "What Bayesian refers to."
        ],
        [
            "So is this thing that I'm doing here treating the parameters as a stochastic variable, and that's where the controversy lies, I don't think."
        ],
        [
            "To control the controversial in machine learning, but it was very controversial in early statistics, and I think that's because they needed to have things subjective.",
            "And when you were introducing this prize you were introducing, you need to have things objective and they were introducing subjectivity and there's still a big debate in statistics.",
            "You know the great thing in statistics is, you know, we joke around between Bayesians and Frequentists about.",
            "Weather Bayesians frequentists, right, and make fun of each other a little bit in a friendly way in statistics.",
            "As far as I can tell, the Bayesians don't really talk to the frequentists and they fight amongst each other about who's right, the objective Bayesians or the subjective Bayesians and objective Bayesians believe.",
            "You can come up with prizes that are completely objective and subjective.",
            "Bayesians believe a prior is always a personal thing and you."
        ],
        [
            "You can't have a fully objective one, so I don't even want to start on that debate.",
            "But why is it called Bayesian?",
            "Well, remember that binomial distribution, well, let's look at it for one trial, so Bayes also talked about."
        ],
        [
            "Binomial, but when he talked about the burner meal, he considered like a billiard table and he considered rolling a ball on the billiard table and the ball lands somewhere on the billiard table, potentially uniformly.",
            "Let's assume it's uniformly between these two sides."
        ],
        [
            "Then he threw another ball."
        ],
        [
            "So that's where it lands, and it lands either to the left or the right of this first ball.",
            "So you can do that, then trial multiple times.",
            "You can keep rolling the next ball, the red."
        ],
        [
            "Pull multiple times and so the next time it comes out there.",
            "Yeah, so if you believe this Red Bull also lands uniformly, and that's the assumption he made, then you're basically using for one trial using the Bernoulli distribution for multiple trials.",
            "If it's successful to land on the right, you're using the binomial distribution, but the key component about this and what Fisher hated about."
        ],
        [
            "His paper.",
            "Was the fact that he was treating this parameter as a random variable, so he sampled the parameter by rolling the first ball down.",
            "Now, Can you imagine how your base is writing this stuff?",
            "Thinking, oh, I'll just crawl, but here's a way of creating a binomial.",
            "Probably thought about it for 2 seconds and just wrote this down.",
            "I mean, he didn't really, he died before this was published, so he didn't really believe in one way or the other.",
            "But all the controversy is just based around the fact that in one case you talk about an urn.",
            "With a fixed number of black and Red Bull, so that's a known thing.",
            "That's not a random thing, it's a known thing.",
            "You know there's a fixed number of black and red balls, and here you're generating the parameter for binomial by sampling from uniform.",
            "So that makes the parameter of stochastic variable.",
            "Ann Fisher hated that, and Fisher invented the sort of term we use the term Bayesian as an insult to people they used to call it what they call it.",
            "They call it the inverse probability or something, and he invented the term Bayesian as a way of insulting inverse probabilists.",
            "And now the names start, but it's to do with this.",
            "It's not to do with."
        ],
        [
            "Naive Bayes is a method is not Bayesian.",
            "For example, OK.",
            "So what's going on in this in Bayesian inference?",
            "So there's these different components.",
            "The Bayes rule we had earlier is of this form.",
            "Posterior is equal to likelihood times prior divided by marginal and Josh.",
            "Sort of showed this earlier.",
            "So the prior distribution is representing as a probability distribution.",
            "The belief about these parameter values before we observed the data, right?",
            "So somehow we don't observe where this black ball lands.",
            "Yeah, but we know it's uniformly distributed and that's the prior.",
            "The likelihood gives the relation between the parameters and the data, so it's like turning us what the relationship between what we observed and what we didn't observe is the posterior distribution represents an updated belief of what we think.",
            "Now about the parameter.",
            "Once we've observed the data.",
            "The marginal likelihood is very important because the marginal likelihood it looks just like a normalizer here.",
            "If we, if we're thinking of just what we want to know about the parameters, it is that that that's a start state and that's the end state, and This is why this is really interesting for cognitive science, because you can keep processing this.",
            "You can plug a posterior in the back end here and keep learning more and more in an online way.",
            "It's a really nice way of seeing how your beliefs evolve, but the marginal likelihood is very important because it actually assessed mean.",
            "It's just another likelihood.",
            "In some ways it's a likelihood with some of the parameters integrated out and you can sort of do maximum likelihood with the marginal likelihood, but it's a better thing to do because you've removed a lot of the parameters, so you're less likely to be overfitting the ratios that Josh was talking about.",
            "We can we talk about those as Bayes factors and their ratios of these marginal likelihoods.",
            "It's also sometimes called the evidence, particularly by people from the maximum entropy.",
            "Community, which is an important community in physics the in the days when Bayesian inference was almost completely dead.",
            "In statistics, these physicists were using it and suggesting it.",
            "James, sort of, who I think was in the Manhattan Project, was sort of promoting it across all the period.",
            "It died out in statistics.",
            "So they called it the evidence."
        ],
        [
            "When they talk about it.",
            "OK, so here's a Bayesian example of the sort of thing you might want to do, and I just think it's it's one of the most natural examples, and in fact it is Sebastian Thrun who's taking this sort of approach to robot navigation.",
            "And, you know, written entire books about it, so it's a bit more complicated than I'm talking about here.",
            "But as I understand it, this is state of the art in the way you do robot localization and mapping.",
            "So imagine that you represent a robot state, and let's just assume that it's position on a 1 dimensional line.",
            "Earth X.",
            "The robot makes readings using it sensors, so it could be a multidimensional.",
            "Say it could be its position, velocity, rate of turn.",
            "But for a moment you can just think of its position on one dimensional line and it makes you readings using IT sensors.",
            "It may have a multiple array of sensors.",
            "It may have sonar sensors.",
            "We have laser sensors, it may have all sorts of things, but they're going to be sorted Y.",
            "We can think of that sensor is 1 dimensional.",
            "We will in a moment now.",
            "The idea here is that at anytime we might have an idea that where the robot is.",
            "So we think the robots in this room.",
            "And we have a map of this room.",
            "Given the different locations in this room.",
            "We have a model of what the sensor readings should be, because we know where the walls are and if we've got the direction the robots pointing in X, we know where it's pointing, so we know like if it's got sonar sensor.",
            "You know in the robots here facing this way we know that the sensor will be reading with some accuracy.",
            "The distance of that wall.",
            "Yeah, so it might have some noise associated with it, but basically that's our likelihood.",
            "So we can combine the initial picture of that location with the sensor readings to get an updated of the picture of the location using the Bayes rule to get the posterior.",
            "So this is how it works.",
            "We've got an initial idea of where the robot is.",
            "We make an observation of from our sensors and then we update that."
        ],
        [
            "To where we think the robot is afterwards.",
            "So this is X.",
            "This is our prior belief about where the robot is.",
            "Its at minus 1X."
        ],
        [
            "Now it's important when I draw the likelihood that is normalized along X, right?",
            "This is not normalized index, it's normalized in why?",
            "So this doesn't have to integrate to one.",
            "It actually happens to in this case because of our properties of Gaussian, but in general it doesn't integrate to one, so we can draw both.",
            "These things though is it's a function of X.",
            "It's not a probability distribution with respect to X 'cause it's given X, so that's the likelihood, and the likelihood is sort of saying well.",
            "This is how likely we are to get each reading given our position in X."
        ],
        [
            "To get the posterior, we multiply these things to two things together.",
            "And then."
        ],
        [
            "We re normalize?",
            "So what's going on here is basically.",
            "The prior is saying the.",
            "We think the robots there the data maximum likelihood solution would be there, right?",
            "That's the highest likelihood where the robot is.",
            "OK, but there's uncertainty, so in maximum likelihood you don't reflect that uncertainty.",
            "So in maximum likelihood you just say the robots there, and that's all I know.",
            "In Bayesian approach, you say that's my where I thought it was.",
            "That's where the likelihood said it is.",
            "You see this little bit of mass that's overlapping here."
        ],
        [
            "Product of those renormalized.",
            "Is that so?",
            "My updated belief is well.",
            "It's somewhere quite close to the likelihood.",
            "If I had more accurate sensors, the width of this likelihood is the accuracy of my sensor.",
            "If I if I increase the accuracy of the center and the width goes down, I'll be pulled more towards the maximum likelihood solution.",
            "If I'm more uncertain about where I was initially, I'm pulled more towards the maximum likelihood solution.",
            "If I was more certain where I was initially, I'd be pulled less towards it so that it's really odd situation for Gaussians, because what actually happens and common filters, for example, are based entirely on this, but.",
            "You have a Gaussian prior Gaussian likelihood and your posterior Gaussian.",
            "That's very unusual.",
            "Normally you don't have a prior to likelihood to posterior where everything is the same distribution.",
            "I think Gaussians only example I know of.",
            "Sometimes you get the same class of distributions for your prior and your posterior and those are called conjugate models, and that's a really nice computational trick.",
            "Are major criticism of Bayesian inference is that we don't actually choose these things for what we believe we choose them for tractability.",
            "So we choose these conjugate models, which give us nice tractable qualities, and I think that's about it.",
            "Criticism makes things faster, makes the algorithms faster."
        ],
        [
            "So the Gaussian prior combined with Gaussian likelihood for Gaussian posterior.",
            "But if the likelihood is non gas you want."
        ],
        [
            "Coaches to approximate the posterior with a Gaussian.",
            "So here's a different likelihood.",
            "So you might start out with a prior over whether you think I'm going to say anything intelligent or anything dumb in this talk, and you might be observing if I say something intelligent, that's an observation of one, and if I say something dumb, that's an observation of minus one.",
            "Now how you've got an idea of where I am along this line.",
            "So if I'm up here, I'm intelligent, and if I'm down here, I'm dumb, right?",
            "So if I'm down here, the probability I'll say something dumb is very high in the probability I'm saying something intelligent.",
            "Is 1 minus that if I'm up here, the probability I'm saying something intelligent is high and the probability I'm saying something dumb is low?",
            "Or you could even think of this while there are."
        ],
        [
            "Come on to that example later.",
            "OK, so this is your prior you think I'm.",
            "Reasonably dumb."
        ],
        [
            "And then what happens is I say something intelligent.",
            "So you observe this thing.",
            "This is now the likelihood.",
            "Note it's not normalized in any way or form, it's just a function of effects distribution over something discreet, right?",
            "So it just sums the two are the two different things sum to 1 two different probabilities."
        ],
        [
            "So I say something intelligent and then that's the posterior.",
            "Yeah, so now you've moved a little bit, you think?",
            "Well, you know he's probably in this regime because I know he's only said one intelligent thing and he could have said it by accident so.",
            "I I'm going to assume he's yeah.",
            "I mean it is a little bit more intelligent, but not that much more so.",
            "One trick that I'd like to sort of include here the difficult bit if you do this model is.",
            "Once you've done that.",
            "This is a really simple model, but the Xbox.",
            "Ranking system for quality of players is based entirely on this model and what I'm going to do next."
        ],
        [
            "Which is to replace that non Gaussian nasty thing.",
            "We think of that as a truncated Gaussian.",
            "It's convolution of this squashing function of Gaussian with the Gaussian and the way one can do that is by fitting this Gaussian.",
            "Pink curve that we had before.",
            "Now I. I just think that wasn't a great fit until I saw some of Josh is Gaussian fits to his data yesterday.",
            "Well, I think the film stuff and that's pretty.",
            "That's about the same as the film fit, but it can be a really bad fit, because these Gaussians can be completely truncated, so this can be a bad thing to do.",
            "But the nice thing, once you've done this so this is a trick.",
            "Once you've done this, you can then proceed with another observation so you can.",
            "Then you can then say something dumb, and then you can drop down in your estimate.",
            "One thing to notice is because of the quality of some characteristics of these log likelihoods here.",
            "And in fact, it's the log concavity of the likelihood.",
            "So sorry, this is likely not a log likelihood.",
            "If I took the logarithm, you would see it's concave.",
            "It has a nasty property, I think from a cog science point of view.",
            "I definitely think it's nasty what will happen if this likelihood is log concave and most likely as we use our is every time you make an observation, you become more confident about what you're seeing.",
            "So basically I think that's very counter intuitive.",
            "Or maybe it's it's a.",
            "Maybe it's because I'm learning all these good words I can say maybe it's because of introspection.",
            "I think the way I update my beliefs is I might.",
            "I might start thinking yeah yeah, yeah.",
            "He's not said anything really good yet, so I just keep thinking are not very clever.",
            "Not very clever, but then he said something really clever.",
            "Then I would increase my uncertainty an increase my belief that I thought someone had said that I thought the person was clever, right?",
            "That's what I would do.",
            "I would think.",
            "Oh, I was wrong.",
            "I was wrong to be confident about what that person was doing.",
            "That's not what these models do because the log concavity of the likelihood.",
            "In fact, they decrease their uncertainty in pretty much if you look at it in terms of entropy in pretty much linear type of way.",
            "So even if I said something really dumb and really intelligent, really dumb, really intelligent, really dumb.",
            "You would just become really confident about whether I was intelligent.",
            "You wouldn't be like, oh, I'm completely at a loss and I think that the intuition is that that's what you should be thinking.",
            "I mean, that's how I feel.",
            "I have opinions and I'm very opinionated actually.",
            "But one of the things I like to do is if I see something that's against my opinions, then then I like to try and re evaluate completely my opinions and become very uncertain.",
            "The way these models Bayesian inference will do that, but not with most of the classically constructed models, most of the time it just gets more confident as you see data so that something can be quite variable and the actual property is the log concavity of the likelihood.",
            "If the likelihood is log concave, that's going to happen.",
            "If you've got non log concave likelihoods you can get this nice effect and, for example, robust regression is an example of that.",
            "If in robust regression if you see a data point that's a lot further away from where you expect it to be.",
            "Then you will actually increase your uncertainty about what's going on because the like."
        ],
        [
            "It's used to not log concave.",
            "So then this is final example is because there was an election on last night and this is how left or right wing you are.",
            "So on the left wing you're voting labor.",
            "This is you probably don't know these parties if you're not English in the middle.",
            "This is labeled.",
            "Americans may be surprised to see that the Liberal Party is in the middle in the United Kingdom and most of Europe not way on the left.",
            "But this is the Liberal Party and then."
        ],
        [
            "This is the conservative party.",
            "The observation in this case is you think someone."
        ],
        [
            "Left wing, but then they say they voted Liberal and so you've observed."
        ],
        [
            "This middle thing, so you update your opinion there."
        ],
        [
            "Come all right wing and again that's a non Gaussian likelihood so you can update it with."
        ],
        [
            "Yes.",
            "OK.",
            "So I was vaguely hoping that Bernard was going to mention kernels in his talk, given it had kernel methods in the title.",
            "And he wrote a book on it, but he didn't mention kernel methods, so I'll have to.",
            "I've introduced a little bit on this."
        ],
        [
            "Spectrum kernel method.",
            "So that likelihood we have before from regression what we can do is we can combine it with pride and stay over the parameters and this prize.",
            "Just saying we don't know if a vague sort of the parameters are equally likely to be the same size is a spherical Gaussian prior.",
            "It's the identity matrix on the covariance, an independent and basically some scale of these parameters that will eventually affect the scale of the function.",
            "Now what I'm not going to show you, but you can do this integral and you recover because of these Gaussian Gaussian Gaussian effect.",
            "You recover the marginal likelihood.",
            "Model is Gaussian and you recover in particular that the elements of this new covariance zero mean because your prior over W is 0 mean.",
            "So even though you had a mean here.",
            "This primer is 0 mean and the effect of that is to make the final marginal likelihood zero mean.",
            "Now this was independent and this is independent, but looking here this is not independent.",
            "So basically this is a big covariance matrix that says what the correlation between different observations are, and in fact it depends on the X is.",
            "So the elements of this covariance matrix which is giving you the correlations between your training points are given by this inner product between your basis functions and this is where I hope Bernard.",
            "Had talked about kernel methods because we talked about these basis functions as a fixed set.",
            "If you remember, then I. I was using three for polynomial or the RBF or squared exponential basis.",
            "And then we've also got this term coming from the noise, so it's some sort of term coming from these sum across these basis functions times.",
            "This scale parameter here, which is giving us the overall size of this covariance plus some noise.",
            "Now this is what I would call a Gaussian process, but you."
        ],
        [
            "I also think of this as a kernel, so this is an inner product and if Bernard mentioned in a product in kernels, then we would know that one of the clever tricks you can do is you can replace this inner product with these so called covariance functions or kernels.",
            "Mercer kernels, which allow you to consider infinite basis functions.",
            "Now that's really funky, because instead of having to choose the number of bases which is one question I ask, well how many bases are you going to use?",
            "You just say I'm going to use Infinity of them.",
            "You never have to compute these Infinity basis functions because it's an inner product between two infinite things, and you can prove this relationship.",
            "That's what Mercer's theorem allows you to do.",
            "So this is a way of thinking about it that your current kernel is this sum over infinite basis functions computed at these two different training points.",
            "So it's a covariance over your training data, so the covariance between two different training points is the evaluation of all these infinite basis functions at those two different training points."
        ],
        [
            "The thing about it, I think he's a bit of a mindset change for some machine learning.",
            "People is when we talked and I emphasize before noises, iid noise is iid, yeah.",
            "Hear the noise is IID because there's no cross dependence.",
            "This is the Chronicle Delta that says only be one if I&J are equal otherwise.",
            "So it's just on the diagonal.",
            "The noise is IID, but integrating out these WS makes it very clear that your data is not ideal.",
            "Your data is strongly correlated according to this covariance function, and that's what the covariance function is directly saying.",
            "So when Bernard talked about prior over functions, this is a way of putting a prior over."
        ],
        [
            "It's called the gas."
        ],
        [
            "Process.",
            "So this is what these covariances look like.",
            "Frequently, people call this the Gaussian kernel, which Bayesians don't like because there's no normalizing constant, so they call it the squared exponential kernel, which Bernard told me he didn't like because it's not a squared exponential.",
            "It's a square within an exponential.",
            "I was calling it the RBF kernel for ages, and Tony O'hagan, a statistician, said that was a horrible term.",
            "So I've started calling the exponentiated quadratic kernel function.",
            "But it's a commonly used thing.",
            "It's all using really many kernel methods.",
            "You can use many different ones of these, and one of the things I'm most interested in my research and working at the moment is is covariance functions that come out of mechanistic knowledge about the system.",
            "You know, you can do all sorts of things with this, so this is the vanilla one.",
            "This is the standard one, and it has this form.",
            "If you compute all the elements of it, it's saying that things are very correlated.",
            "If they are close to each other in the input space, and they're not correlated with their distant."
        ],
        [
            "So here's some samples then."
        ],
        [
            "Nice thing is what you can do is you can sample.",
            "You can't sample the infinite function, but what you can do is you can just define that as a covariance of a multivariate Gaussian and then you can sample."
        ],
        [
            "A single sample from that multivariate Gaussian and one of those samples will look like one of these, and these are also.",
            "These are sort of 20 or different samples, which gives you an idea of what you're trying to say about your function and what you're actually saying is it's incredibly smooth, infinitely smooth.",
            "In fact, it's a problem with this covariance function that it's too smooth and you're saying it's sort of stationary goes up and down, and this is an effect of all these basis functions.",
            "Infinite basis functions you put over the real line, all being added together."
        ],
        [
            "Form that result."
        ],
        [
            "So here's some different parameters.",
            "And then here's something called the Ornstein.",
            "German would need to pronounce that correctly.",
            "Ornstein Uhlenbeck process, which is a different covariance where instead of taking it's not an exponentiated quadratic.",
            "It's an exponentiated out absolute and it's important in lots of physical things completely non smooth.",
            "So you might expect something like this to come out."
        ],
        [
            "The Gaussian you might not expect that to come out of a Gaussian that."
        ],
        [
            "Real super smoothness, but these are sort of a.",
            "It's like a stay."
        ],
        [
            "Missionary Brownian motion.",
            "Those paths.",
            "So what you can do is you can take this prior and then you can combine it with data and then you can see the posterior.",
            "What I'm showing you here is before observing these two data points your prior over where this function is illustrated as a zero mean plus the marginal variance is at each point which are just constant for that."
        ],
        [
            "Function if I combine that with the two data points, then what starts to happen is I see the variances collapse near the data."
        ],
        [
            "Point"
        ],
        [
            "As I add data."
        ],
        [
            "Every time I add a data point, they sort of collapse.",
            "I've got these error bars.",
            "I don't know where the functions going between these things.",
            "'cause I've got this length scale and then scale saying you're wiggling, and I can't pin down the wiggles 'cause I haven't seen the data.",
            "So the beauty about the Bayesian approaches you're getting these lovely big error bars.",
            "There's some costs are carrying these things around, and that's why the SVM is sort of algorithmically more efficient than the equivalent Gaussian process classifier, because in the SVM you don't carry these variances around you sort of ignore them effectively, do map solutions, but.",
            "You know they can be really useful.",
            "I worry that if you don't carry them around.",
            "Certainly in some applications you sort of throwing out the baby with the bathwater.",
            "But if you've got very."
        ],
        [
            "Large datasets, then perhaps they don't matter as much 'cause they start to collapse, so I like this, but here this was completely random.",
            "When I first generated this data.",
            "So look, it looks like we're really good."
        ],
        [
            "These error bars are too large, but then look at these next points.",
            "I mean that just was coincidence.",
            "I didn't force that to happen there up here.",
            "Now I am generating this data from the more."
        ],
        [
            "That's why it works so beautifully.",
            "That's why all the error function bars look correct course.",
            "In general, we can't generate the data from the model, and in general even this flexible looking model will be incorrect.",
            "It will be overly smooth floors in the model will come out as we start to observe data that's too close to each other."
        ],
        [
            "If there's a mismatch between the model and the truth.",
            "In the Bernard sort, I think that was being illustrated when he talked about classes of function and the rate of convergence of these empirical risk things.",
            "That's, I think that's equivalent concept that if you have a mismatch between the function you're using in the truth, you won't get a good bound.",
            "So what you can do, people ask me about how you set the length scale on these covariances, where you can maximize the likelihood of this or the negative log likelihood you can minimize.",
            "So here's the log.",
            "Likelihood of this Gaussian process and what it actually has.",
            "So Bernard talked about the empirical risk, which is like a data fit term.",
            "This is like a data fit, and then his capacity control term is like this one.",
            "This is like an entropy.",
            "It's like how many different functions, when he was at saying early.",
            "You can use priors over the functions.",
            "This thing is like counting how many different functions are associated with this prior.",
            "How flexible is this system?",
            "So what you tend to see is I can draw these three different terms, so the sum of the two of them and separately the data fit and the entropy."
        ],
        [
            "I'm in this graph here and as I changed the length scale so this is just the length scale, changing their noise is fixed.",
            "But we could learn that as well as I change the length scale, increasing it, what will."
        ],
        [
            "Happen is the data fit, so the data that is measured by how accurately I'm interpolating the points with the mean.",
            "The data fit term will get worse, but the capacity."
        ],
        [
            "The control will get better."
        ],
        [
            "And the sun."
        ],
        [
            "Who will be the at this point here?",
            "I have a Maxima in the."
        ],
        [
            "Cleared."
        ],
        [
            "So now the data fit is."
        ],
        [
            "Overwhelming the capacity.",
            "So this is the capacity control and then this is the data fit, so the data fits collapsing as where the length scale gets too large and the capacity controls going up.",
            "But the sum of the effect is a maximum in the likelihood.",
            "Now it's not guaranteed to be unique maximum as you start loading this kernel with more parameters, you'll start getting problems, but for a length scale with a reasonable amount of data it is typically going to be."
        ],
        [
            "So we can fit these."
        ],
        [
            "Kernel parameters."
        ],
        [
            "Using this formalism OK."
        ],
        [
            "So I think what I'm going to do is Bernard mentioned it's nice to have a bit of discussion, so I won't go through.",
            "The latent variable, well, is it better I go through latent variables or mix of gas internal?",
            "All that box.",
            "Here we go.",
            "I'll just go through the mix of Gaussians probably and not talk about the latent variables.",
            "So that's a Bayesian.",
            "Well, you can see that as a Bayesian model, although if you don't believe functions of parameters, then this is the problem with this issue about stochastic variables and parameters is controversial.",
            "To make parameters stochastic variables is not controversial.",
            "To use Bayes rule, but is a function of parameter or a stochastic variable.",
            "I don't know if you believe it's a parameter then.",
            "Then this is controversial, but not to me.",
            "If you believe it says casting variable, it's not controversial.",
            "So this is where I have real problems with this worry about, because it sometimes I had a conversation with the frequency statistician once where I explain my model to him and he said no.",
            "That's fine because you've only put prior distributions over things that are stochastic variables.",
            "I said oh, but I also put a parameter over that distribution over that prior distribution over that and he said, Oh no, that's Bayesian.",
            "Then you can't do that.",
            "And I said, oh, but actually, my data is a population of cells.",
            "And each of these parameters could be different in each one of the cells.",
            "Oh, that's OK. Again, you can do that.",
            "So you know it's easier just to just try and forget about it and actually, except in some sense it was an argument that was true for the Edwardian Englishman.",
            "It's not an argument that is true for machine learning or cognitive science, where we're not worried about truth.",
            "Objective truth necessarily worried about doing cool intelligent stuff, then it's a good methodology.",
            "I'm so.",
            "This is mixture Gaussians and it can be done, sort of with Bayes rule.",
            "So.",
            "I'm going to do in society in the way that's not normally written in the textbook, but I think it's the right way because it's the only way you can explicitly see what's going on.",
            "What I'm going to say is that I've got some data that sampled given a component label, but my component label has this nasty form instead of having a component label as a number one to 10 or something like that, I have these component labels would be so S for any data point to identify the components of the data point, I have a 001000, so I think you called this one of encoding.",
            "So there's 123456 possible components, and I'm labeling the component I'm using with.",
            "The one is that coming up, yeah?",
            "I haven't done this in years, cool.",
            "So.",
            "That's my for the ice data point.",
            "That's my assessment of SOS would be a bold S there.",
            "Now the point about using that is I can use this trick I mentioned earlier.",
            "The mathematical switch is like if I constrain S to be of this form, only one one in their vector.",
            "I can basically take a product over this.",
            "The guy here.",
            "So here's a bunch of Gaussians.",
            "Each Gaussian has a different mean and covariance, but only one of these Gaussians actually contributes to the product, because a bunch of them are to the power of 0.",
            "So they just one, and then I switch on only the one.",
            "The case one associated with that.",
            "So basically this is a way of switching between different Gaussians, so the model in a mixture of Gaussians is to have a multinomial prior over this.",
            "Anna multinomial is just the multivariate generation generalization over binomial.",
            "It says for each of these.",
            "For each of these digits here, there's a probability it's on and the probabilities sum to one.",
            "So I have the multinomial for one sample, so it's really not a multinomial, but it's much cleaner to write down, which is sampling my switch.",
            "So I sample my switch from this, and each of these switches has a prior problem."
        ],
        [
            "Redistribution what I can do is I can then write down what the marginal likelihood is.",
            "Now what I want to do here, if I can actually do that some and I can solve that and I can look at the marginal likelihood and I can do gradient descent."
        ],
        [
            "It's on the system to find all the parameters.",
            "Which of these means and covariances of these different Gaussians?",
            "I've switched on, but I'm not going to do that because."
        ],
        [
            "I want to just mention it."
        ],
        [
            "Damn."
        ],
        [
            "So.",
            "EM is an algorithm for fitting models of this type.",
            "It doesn't get you out of intractability.",
            "Your model has to be tractable, and any model you can treat with them.",
            "You can also do gradient descent on.",
            "I think people like EM because it ends up with a bunch of update equations, but it can be horrifically slow, so be careful.",
            "It's not slow in the mixture of Gaussian case, which is where it's probably most widely used so people can get a misleading impression."
        ],
        [
            "Mixture gaussians.",
            "So what you do to drive EM is you first introduce a Phantom distribution, which I'm calling Q of S, which is probability distribution over this.",
            "And then you distribute it over its self."
        ],
        [
            "So it's not affecting anything.",
            "Then you use something called Jensen's."
        ],
        [
            "Equality, which takes this."
        ],
        [
            "Talk here and puts it inside.",
            "So I'm going from that to that and then that makes this a bound.",
            "So Bernard mentioned channels found earlier.",
            "This is a bound drive from a modified form of Jensen's inequality.",
            "So what I now have is a lower bound on my log likelihood."
        ],
        [
            "Now the bound becomes equality.",
            "If I set this distribution to the posterior.",
            "So the reason is because P of Y is equal to the joint over.",
            "This is just like the product rule of probability, but with them bringing that guy down here because that's true, that is just P of Y, then the sum over S is just summing up that it normalizes, so it's just one times P of Y log P of Y.",
            "So basically.",
            "Then there's inequality."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So what I want.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Do it.",
                    "label": 0
                },
                {
                    "sent": "Start with a bit of a probability review.",
                    "label": 1
                },
                {
                    "sent": "I'll try and go through that quickly, but it will hopefully serve to sort of introduce the notation in the way I'm using it, and perhaps point out a couple of things that.",
                    "label": 0
                },
                {
                    "sent": "I didn't really think about until after I'd been using probabilities for awhile, even if they are perhaps obvious to other people, then I'll talk about probabilistic modeling for supervised learning.",
                    "label": 1
                },
                {
                    "sent": "And I'll end bet on doing some unsupervised learning clustering and dimensionality reduction.",
                    "label": 0
                },
                {
                    "sent": "I guess it's an hour and a half and I think you could.",
                    "label": 0
                },
                {
                    "sent": "You could do an hour and a half on any one of the things I'll talk about.",
                    "label": 0
                },
                {
                    "sent": "So obviously there will be details missing.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK so last time.",
                    "label": 0
                },
                {
                    "sent": "I introduced some different learning scenarios and well, initially I use learning rules to introduce them, and indeed we saw in some of the cocci talks the use of talking about learning rules and heavy and learning and how that can be related to what's going on in the brain.",
                    "label": 0
                },
                {
                    "sent": "But I sort of at the end tried to say well what's really going on is there's an error function and we're trying to descend the gradient of that.",
                    "label": 0
                },
                {
                    "sent": "Now, Bernards talk.",
                    "label": 0
                },
                {
                    "sent": "He mentioned empirical risk minimization, and indeed most of what he was talking about was taking the empirical risk and combining it with a term that was reflecting the complexity of the model being used to try and make an estimate of the true risk or the sort of risk on test data.",
                    "label": 0
                },
                {
                    "sent": "That's one way of going, and in that case you're actually assuming that the thing you're minimizing is the actual cost function you're interested in, so.",
                    "label": 0
                },
                {
                    "sent": "That's an important difference for this, and people confuse it.",
                    "label": 0
                },
                {
                    "sent": "People think that we are interested in loss function.",
                    "label": 0
                },
                {
                    "sent": "That is the log likelihood.",
                    "label": 0
                },
                {
                    "sent": "That's not really the justification.",
                    "label": 0
                },
                {
                    "sent": "In probabilistic approaches, the justification probabilistic approaches is that you're fitting the log likelihood and by fitting the log likelihood you're trying to understand the real probability distribution underlying the data, and in particular the whole idea of what your cost function is a separate issue.",
                    "label": 0
                },
                {
                    "sent": "You try and make it a separate issue.",
                    "label": 0
                },
                {
                    "sent": "In fact, for a lot of cases you can't make it a separate separate issue.",
                    "label": 0
                },
                {
                    "sent": "But basically that's the premise that you're going to make that cost function that is at the core of empirical risk minimization, a separate thing.",
                    "label": 0
                },
                {
                    "sent": "So the error function as we see it can be seen as the logarithm of a probability density.",
                    "label": 1
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Function, But before we take that perspective, I just want.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Quickly review probability, so I mean, I've go through this slide very quickly because I just want to sort of really use this to introduce Bayes rule.",
                    "label": 0
                },
                {
                    "sent": "So you should you should know these different things, the joint probability, the probability of X, which is 1 variable having the value of little X&Y.",
                    "label": 0
                },
                {
                    "sent": "Another variable having the value of little wife.",
                    "label": 0
                },
                {
                    "sent": "Notice this notation is extremely clumsy, but if any of you have programmed in something like Python, it's a bit like Python where you actually indicate the arguments you passed your function by, what their.",
                    "label": 0
                },
                {
                    "sent": "Role is going to be so you can change the ordering of these arguments.",
                    "label": 0
                },
                {
                    "sent": "That's important because you do that all the time in probabilities.",
                    "label": 0
                },
                {
                    "sent": "Once you drop these axes and wise it doesn't change the value of the probability, so there's sort of different notation to function notation, and it took me a long time before I notice that.",
                    "label": 0
                },
                {
                    "sent": "But the reason is because it's more like a Python function than, say, AC function, where the ordering of the.",
                    "label": 0
                },
                {
                    "sent": "Arguments is important.",
                    "label": 0
                },
                {
                    "sent": "The marginal probability is the probability of X being equal to X, regardless of what.",
                    "label": 1
                },
                {
                    "sent": "Why is so?",
                    "label": 0
                },
                {
                    "sent": "This is the probability of them both being equal to these things and then the conditional probability is the probability that X is equal to X given that we've observed why it wise.",
                    "label": 1
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Those are the three.",
                    "label": 0
                },
                {
                    "sent": "Main types probability will be looking at and they can be represented in this way.",
                    "label": 0
                },
                {
                    "sent": "If we've got X and it's taking discrete values from one to six and why it is taking discrete values from one to four, and we've got practice example instantiation's of what these values are, so these are sort of events, and we're categorizing this event here as X equaling two and Y equaling 3.",
                    "label": 0
                },
                {
                    "sent": "And we can look at the counts in any one of these boxes.",
                    "label": 0
                },
                {
                    "sent": "So there's three boxes here.",
                    "label": 0
                },
                {
                    "sent": "There's a box for X = 5, A box for y = 4 In a box for S = X = 3, and y = 3.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the definition of these things is that for the.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Probability we're looking at this box here so the colors mismatch.",
                    "label": 0
                },
                {
                    "sent": "Apologies for that.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Dividing it by the total number of crosses and taking the limit as X goes to Infinity, that's actually a frequentist definition of probability.",
                    "label": 1
                },
                {
                    "sent": "So that's a very probably the one most people have seen before.",
                    "label": 0
                },
                {
                    "sent": "It's an interesting one because, of course S never really does go to Infinity, but it will be happy with that definition.",
                    "label": 0
                },
                {
                    "sent": "For the moment, the marginal will be.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the model for X is this box here.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Really bad I've got the colors matching.",
                    "label": 0
                },
                {
                    "sent": "Sorry so the blue box is the limit as we saw all those the ones in that box as X goes to Infinity and the conditional.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We'll be looking at one of these boxes here.",
                    "label": 0
                },
                {
                    "sent": "X = X three and y = 4, and then dividing by the way.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "On in another box, yeah, so for y = 4, so you divide.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Instead of dividing by all the total, you divide of the ones.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The other given.",
                    "label": 0
                },
                {
                    "sent": "So the nice thing about those?",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The little definitions and I think this is something that I first saw when I was asked, and in 1996, and Chris Bishop used this way of introducing probabilities.",
                    "label": 0
                },
                {
                    "sent": "It wasn't in his first book, but I think it's in his second actually to do it this way.",
                    "label": 0
                },
                {
                    "sent": "I haven't read his second, but I think I saw it in there briefly.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So it's a nice way of introducing all these different things, because you can introduce the rules of probability from it.",
                    "label": 0
                },
                {
                    "sent": "So as I was saying before, we typically we should write out this full definition of the probability right?",
                    "label": 0
                },
                {
                    "sent": "We should.",
                    "label": 0
                },
                {
                    "sent": "To be clear, we should be saying X is equal into little X&Y is equal to the little wife, but in practice we often use this little shortcut and the implication is somehow there's a missing capital X equals, but that has this effect, so this looks very much like we might write a multivariate function like F of X, Y is equal to X / y, but then of course X of X, YF of X, Y is not equal to F of Y, X.",
                    "label": 1
                },
                {
                    "sent": "In probabilities, that is true because of that subtle point, but it caused a big argument once with a postdoc.",
                    "label": 0
                },
                {
                    "sent": "So to clarify it.",
                    "label": 0
                },
                {
                    "sent": "I think he didn't realize that because he was a mathematician, so he was thinking of that.",
                    "label": 0
                },
                {
                    "sent": "He didn't believe in that.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I had to explain it to him.",
                    "label": 0
                },
                {
                    "sent": "OK, so all distributions are normalized and that can be easily seen from the definition we've seen before by summing over one of these marginals is just the sum of all the things in that marginal divided by the total, which is equal to 1 and marginalization is a really important property of probabilities because it has effects.",
                    "label": 1
                },
                {
                    "sent": "It has effects in maximum likelihood when you when you push up your likelihood in one region because the distribution is normalized, it must be suppressed.",
                    "label": 0
                },
                {
                    "sent": "In other regions it goes down elsewhere, so it's like a.",
                    "label": 0
                },
                {
                    "sent": "It's like a sort of tent when you.",
                    "label": 0
                },
                {
                    "sent": "If you want your probability to go up here, your and its attendant it's peg down, then it will go down somewhere else.",
                    "label": 0
                },
                {
                    "sent": "If you lift a poll of 10 other parts of it go down, and so that's a sort of important property.",
                    "label": 0
                },
                {
                    "sent": "The tent has a certain fixed volume.",
                    "label": 0
                },
                {
                    "sent": "In the probability case, and as you move it up and down, it must go down elsewhere.",
                    "label": 0
                },
                {
                    "sent": "That's so that's.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Important.",
                    "label": 0
                },
                {
                    "sent": "The marginal probability is just the summing across all the axes.",
                    "label": 1
                },
                {
                    "sent": "You should know that that's the sum rule of probability, and this is probably one of the biggest pains we experience.",
                    "label": 1
                },
                {
                    "sent": "It looks very innocent, but in practice when we're looking at very large state spaces, doing these sums can be very very hard.",
                    "label": 0
                },
                {
                    "sent": "When exploring a large state space.",
                    "label": 0
                },
                {
                    "sent": "So this is the one of the hardest things to deal with.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Mobility, so it's the sum rule probability and then the product rule of probability is just relating the joint distribution to the conditional distribution.",
                    "label": 0
                },
                {
                    "sent": "So probability of X given Y times probability of Y is equal to the probability of X&Y and that can all be seen just by go.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Through those definitions, now the nice thing.",
                    "label": 0
                },
                {
                    "sent": "Is the simple definitions will also lead to something that some people think is controversial and one of the points of introducing in that way is you can see this is completely noncontroversial.",
                    "label": 0
                },
                {
                    "sent": "Bayes rule is not controversial, it is true.",
                    "label": 0
                },
                {
                    "sent": "If you want to invert a probability, this is the way to do it, so you can equate the joint probabilities.",
                    "label": 0
                },
                {
                    "sent": "In this way, probability of X, Y is equal to the probability of Y, Rex and probability.",
                    "label": 0
                },
                {
                    "sent": "Why, Rex time is equal to appear like given XCOM appear Vexin.",
                    "label": 0
                },
                {
                    "sent": "So we can write this basically and then you just divide that into that side and you get this ability to invert the probability go from this probability Y given X, the probability of X1, and that's important.",
                    "label": 0
                },
                {
                    "sent": "Now Basded right about this and they I've tried to read his paper.",
                    "label": 0
                },
                {
                    "sent": "The introduction is really clear.",
                    "label": 0
                },
                {
                    "sent": "It's written by someone else called Richard Price, and the epilogues really clear and most of what you get from the papers from that and then reading the actual paper is not very clear.",
                    "label": 0
                },
                {
                    "sent": "Read Laplace to on his.",
                    "label": 0
                },
                {
                    "sent": "I can't remember the name of the actual paper where he effectively doesn't define Bayes rule, but he does a lot more interesting stuff with it and I think as a Brit it pains me to say it.",
                    "label": 0
                },
                {
                    "sent": "But Laplace is far more interesting than Bazan, and he there's an enormous amount of work on on using this rule without ever actually explicitly saying what the rule is.",
                    "label": 0
                },
                {
                    "sent": "An he post date.",
                    "label": 0
                },
                {
                    "sent": "Some postdates basil think which is why people credits and base.",
                    "label": 0
                },
                {
                    "sent": "But I think if your friends, you can be mightily proud of Laplace.",
                    "label": 0
                },
                {
                    "sent": "Who seems to me it's a little bit depressing if you read the class because I realized that my entire research career was already envisaged by Laplace 200 years ago, and it was only through lack of having a computer that he didn't do the sort of things that we do.",
                    "label": 0
                },
                {
                    "sent": "But basically he worked out approximations for doing Bayesian inference.",
                    "label": 0
                },
                {
                    "sent": "He worked out, talked about error functions, fitting models to data, astronomical models to data.",
                    "label": 0
                },
                {
                    "sent": "And he also was first interested.",
                    "label": 0
                },
                {
                    "sent": "The example.",
                    "label": 0
                },
                {
                    "sent": "He looks at this is for biased coins.",
                    "label": 0
                },
                {
                    "sent": "He was interested in what they called.",
                    "label": 0
                },
                {
                    "sent": "I think the French called them English dice so.",
                    "label": 0
                },
                {
                    "sent": "I suspect we call them French dice, but whether a coin with biased or not, and analyzing that sort of question using Bayes rule, that's what his pay.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Where is about.",
                    "label": 0
                },
                {
                    "sent": "Coming.",
                    "label": 0
                },
                {
                    "sent": "Coming controversies coming.",
                    "label": 0
                },
                {
                    "sent": "Nothing controversial yet, so one of the things we need to do and I won't show a great deal of this.",
                    "label": 0
                },
                {
                    "sent": "Well, I there is some examples of this, but what we want our probability distribution to do is reflect our model of the world.",
                    "label": 0
                },
                {
                    "sent": "So we want to represent user probability distribution to represent.",
                    "label": 0
                },
                {
                    "sent": "Belief state that is sort of in some ways that's against the frequentist definition that was there before, but it's sort of provable that you can have a consistent calculus of probabilities where this does this.",
                    "label": 0
                },
                {
                    "sent": "So if you've got a belief state about what you think the world is like, but then you're interested in some function of what that world is like.",
                    "label": 0
                },
                {
                    "sent": "Then you want you want to do is very often is compute expectations of that function.",
                    "label": 0
                },
                {
                    "sent": "So expectations I'm using this angle notation that I find very convenient.",
                    "label": 0
                },
                {
                    "sent": "Of course, lots of other people use this sort of E notation.",
                    "label": 0
                },
                {
                    "sent": "I like the angle notation 'cause you know it's it's compact and you can also drop in the distribution under which are taking the expectation there.",
                    "label": 0
                },
                {
                    "sent": "Some people put the conditioning sign and put the expectation there.",
                    "label": 0
                },
                {
                    "sent": "So the mean of the distribution is is a very useful expectation, and it's just the expectation of X and the variance is computed from a couple of expectations.",
                    "label": 1
                },
                {
                    "sent": "Then that's.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "How diffuse the distribution?",
                    "label": 0
                },
                {
                    "sent": "So one of the things I'm not going to talk about is probabilistic graphical models, but Sylvia is going to talk about that.",
                    "label": 0
                },
                {
                    "sent": "I think tomorrow, so I'm not going to look at these sort of representations of probabilities much anymore.",
                    "label": 0
                },
                {
                    "sent": "But one way of representing probabilities is at a table, so you've got some different outcomes.",
                    "label": 0
                },
                {
                    "sent": "And then here's the probability of each of these outcomes, and obviously they sum to one.",
                    "label": 0
                },
                {
                    "sent": "But I prefer to represent them as functions, although this next example is some.",
                    "label": 1
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It definitely can be represented as a table.",
                    "label": 0
                },
                {
                    "sent": "It looks very complicated when represented as a function, so binomial distribution is very commonly used distribution and I think I don't know if he invented it, but it's one of Jacob.",
                    "label": 0
                },
                {
                    "sent": "Bernoulli's did a lot of work on it, and certainly he described it in a certain way, which is going to be important in our controversy.",
                    "label": 0
                },
                {
                    "sent": "That's coming up.",
                    "label": 0
                },
                {
                    "sent": "This isn't controversial, but the later it will be, so he said, imagine you've got an urn with some black and red balls.",
                    "label": 1
                },
                {
                    "sent": "What's the probability if you take a?",
                    "label": 0
                },
                {
                    "sent": "Ball out.",
                    "label": 0
                },
                {
                    "sent": "That it's going to be black or red.",
                    "label": 0
                },
                {
                    "sent": "And if you put it back in and then take another one out.",
                    "label": 0
                },
                {
                    "sent": "What's the probability that it's gonna be black or red?",
                    "label": 0
                },
                {
                    "sent": "But if you say red is a success and you keep on and you sum the number of successes as you keep doing this, then the binomial distribution gives you the probability distribution over number of successes, which I've called why it's not a very good notation for successes and S for the number of trials.",
                    "label": 1
                },
                {
                    "sent": "So given a number of trials, is the distribution of the number of successes.",
                    "label": 0
                },
                {
                    "sent": "I'm just keeping using wires.",
                    "label": 0
                },
                {
                    "sent": "It's a main objective data interest and S is the number of trials.",
                    "label": 0
                },
                {
                    "sent": "So this is the binomial coefficient.",
                    "label": 0
                },
                {
                    "sent": "And then this thing here.",
                    "label": 0
                },
                {
                    "sent": "It looks nasty, but these things are these things are just probabilistic switches, so if Y is one or zero one for a success, then what the one does is switches in the pie.",
                    "label": 0
                },
                {
                    "sent": "One trial, for example.",
                    "label": 0
                },
                {
                    "sent": "So if you have one trial, this term disappears.",
                    "label": 0
                },
                {
                    "sent": "It's just one, and that's how I'll mainly use this distribution.",
                    "label": 0
                },
                {
                    "sent": "So for one trial you get a \u03c0 to the power of 1 * 1 -- \u03c0 can power of 0, so these powers of something that is either 01.",
                    "label": 1
                },
                {
                    "sent": "They acted like a switch or mathematical switch to switch on different parts of the system, and I'll use that later as well.",
                    "label": 0
                },
                {
                    "sent": "It's a clearer context, so that's the binomial distribution.",
                    "label": 0
                },
                {
                    "sent": "It's just using the probability of success, as in a Red Bull being a success being.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "High and then you can look at this density as a discrete density over Y for different values of S and probability of success.",
                    "label": 0
                },
                {
                    "sent": "So here's 20 trials and with probability of success being .4, that's very widely used physical distribution.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I wanted to talk about it, particularly because I want you to bear this in mind.",
                    "label": 0
                },
                {
                    "sent": "So fundamentally what he's saying is that there are.",
                    "label": 0
                },
                {
                    "sent": "The ratio of red to black and red balls is given by \u03c0, so that's a fixed number of things that are in the urn.",
                    "label": 1
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so remember that.",
                    "label": 0
                },
                {
                    "sent": "So far we've talked about discrete values of X&Y, but for continuous models we use probability density functions.",
                    "label": 0
                },
                {
                    "sent": "Now probably didn't see functions are odd beings.",
                    "label": 0
                },
                {
                    "sent": "In some sense they are misleading 'cause you can use them almost exactly as user probability distribution, but you can't say it meaningless to say what's the probability of an individual number, yeah?",
                    "label": 0
                },
                {
                    "sent": "It's completely meaningless, so.",
                    "label": 0
                },
                {
                    "sent": "What is the probability density function encapsulate well?",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Here's an example of one, and it's a Gaussian will go back to its form.",
                    "label": 0
                },
                {
                    "sent": "What is actually encapsulate Ng is the ability to ask any question I'm interested in about the variable over which I'm dealing with.",
                    "label": 1
                },
                {
                    "sent": "So here if I'm interested in Heights, I can't ask what's the probability that someone is 1.5 meters tall.",
                    "label": 0
                },
                {
                    "sent": "The reason I can't ask that is because there's infinite possible Heights on this input so that.",
                    "label": 0
                },
                {
                    "sent": "You know this is a zero probability of being 1.5 millimeters tall, exactly because there's infinite different Heights you can be, but what you can ask these questions like what's the probability of being between 1.5 meters and two meters, and the way you ask that question as you integrate between those two values.",
                    "label": 0
                },
                {
                    "sent": "This function now because this function is constrained to integrate to one.",
                    "label": 0
                },
                {
                    "sent": "Now will always be a probability and any question you can think of which you can be turned into discrete terms can be asked about this function and you can get an answer in discrete probabilities.",
                    "label": 0
                },
                {
                    "sent": "The only problem where the only time when this problem arises when you're computing likelihoods, because what what you'll find is if you compute likelihoods of this you can have likelihoods greater than one.",
                    "label": 0
                },
                {
                    "sent": "So if you look at the probability of being 1.5 meters tall, you'll see it's two, but that's 'cause it's nonsensical thing, right?",
                    "label": 0
                },
                {
                    "sent": "It doesn't exist none of these probabilities are too.",
                    "label": 0
                },
                {
                    "sent": "The reason you got two here is because the width here is about .5.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so the overall height with distribution is about two.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so be aware of that because it's a sanity check for discrete probability distributions that your likelihoods should never be greater than one.",
                    "label": 0
                },
                {
                    "sent": "It is not a sanity check for continuous probability distributions that your likelihood should never be greater than one.",
                    "label": 1
                },
                {
                    "sent": "It also affects things like there's all sorts of things you can do to re scale, which is sort of meaningless in terms of answering these discrete questions so I can take the logarithm of this input and then the discrete questions I ask, I'll get.",
                    "label": 0
                },
                {
                    "sent": "All the same answers out, but the shape and form of this function will be completely different.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I mean, it may be subtle and it's actually you don't have to worry about it most of the time, but sometimes it bites you, so that's a Gaussian density and it has to integrate to one, and it has that sort of form.",
                    "label": 0
                },
                {
                    "sent": "So apparently proposed, maybe first by DeMar who was a French eugeno living in London.",
                    "label": 0
                },
                {
                    "sent": "It was, I think, mainly developed by Laplace and the great thing.",
                    "label": 0
                },
                {
                    "sent": "The first time Laplace uses it, he uses it to approximate Bayesian inference.",
                    "label": 0
                },
                {
                    "sent": "He invents independently invents the Gaussian distribution to do the Laplace approximation and perform Bayesian inference.",
                    "label": 0
                },
                {
                    "sent": "So I kind of love Laplace for that because I think it's great that I mean no tomorrow also mentioned that unfortunately.",
                    "label": 0
                },
                {
                    "sent": "But the second mention of it was was for doing Bayesian inference.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So has this multivariate form as well, which will make a lot of use.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is across a single variable which might.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Height and then these are variables here which you need a covariance matrix to describe correlations between these variables and you have a mean and so and so forth, OK?",
                    "label": 0
                },
                {
                    "sent": "So this is allows you to sort of describe joint distributions.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Over.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Multiple outputs.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so the other thing I want to mention it was which we're not going to use a lot, but it's there and it's very important in probabilities is sample based approximations.",
                    "label": 1
                },
                {
                    "sent": "Very often you can't compute the expectations that you're interested in exactly, but what you can do is you can have samples from the density you're interested in, and then you can have a sample in the law of large numbers that Bernard was mentioning.",
                    "label": 0
                },
                {
                    "sent": "You can have a sample based approximation to the expectation you're interested in.",
                    "label": 0
                },
                {
                    "sent": "So that used to confuse me a bit, because of course the sample mean is is we always talk about means what we think of is sample means, but in some ways that's just an approximation to the true mean.",
                    "label": 0
                },
                {
                    "sent": "But we say both of these things are means.",
                    "label": 0
                },
                {
                    "sent": "But what we really mean when we're saying this is the sample mean I I tend to think of that as being the true mean, but anything can be computed in that way.",
                    "label": 0
                },
                {
                    "sent": "Of course, when we're looking at data, that's what we effectively have.",
                    "label": 0
                },
                {
                    "sent": "We have some unknown distribution, and we have samples from it and that sort of thing Bernard was talking about in terms of law of large numbers and convergence is making these sample based approximation.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You've got samples from some unknown distribution.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So that's as much as I want to talk about on the review.",
                    "label": 0
                },
                {
                    "sent": "A probability, hopefully it wasn't well, hopefully there's something in there, so this is what we should have had before, so last time we talked about error functions and we said OK, this is how we're measuring the quality of our regression and we said we were going to come across some output from some function.",
                    "label": 0
                },
                {
                    "sent": "So this is a set of bases that we had before those sort of bumps, and then these waiting of these bumps minus the actual target.",
                    "label": 0
                },
                {
                    "sent": "So this was our like Delta Yi Squared and the sum of that for every data point we observe.",
                    "label": 0
                },
                {
                    "sent": "So the quadratic error function can be seen as a Gaussian noise model.",
                    "label": 0
                },
                {
                    "sent": "So the way that works is imagine this is our data generating process and we often talk about generative models, and this is sort of what we mean that our X is inside this basis function.",
                    "label": 0
                },
                {
                    "sent": "This vector of basis functions here and what we're observing is why.",
                    "label": 0
                },
                {
                    "sent": "Which is a function of X which is a linear weighted set of basis functions.",
                    "label": 0
                },
                {
                    "sent": "Plus now this is the new bit.",
                    "label": 0
                },
                {
                    "sent": "This is what we have before epsilon where epsilon is Gaussian noise with standard deviation Sigma.",
                    "label": 0
                },
                {
                    "sent": "Now this noise model assumption is sort of critical.",
                    "label": 0
                },
                {
                    "sent": "It's something you didn't see in what Bernard was talking about, because when he's generating a loss function, you're not actually considering the noise.",
                    "label": 0
                },
                {
                    "sent": "What you're considering is the penalty you will pay for getting things incorrect.",
                    "label": 0
                },
                {
                    "sent": "This is nothing to do with the penalty you'll pay for getting things incorrect.",
                    "label": 0
                },
                {
                    "sent": "So let's say I'm ordering lumber.",
                    "label": 0
                },
                {
                    "sent": "From 'cause I've got supply and demand, so I need to buy in lumber to deliver to my customers.",
                    "label": 0
                },
                {
                    "sent": "Now there's two things that can happen, right?",
                    "label": 0
                },
                {
                    "sent": "If I don't have the right amount of lumber, I might pay a cost for having the incorrect.",
                    "label": 0
                },
                {
                    "sent": "If I run out, I pay a cost on missed sales.",
                    "label": 0
                },
                {
                    "sent": "If I've got too much, it rods so there's an amount of money I can say that's my cost, right?",
                    "label": 0
                },
                {
                    "sent": "So that's one thing, but another thing is the demand for lumber.",
                    "label": 0
                },
                {
                    "sent": "So the cost might be.",
                    "label": 0
                },
                {
                    "sent": "I don't know linear in the amount of.",
                    "label": 0
                },
                {
                    "sent": "In the incorrectness of my lumber prediction, but the demand for lumber might be coming from a Gaussian distribution, so it might be quadratic.",
                    "label": 0
                },
                {
                    "sent": "So these things are these two things are important and different.",
                    "label": 0
                },
                {
                    "sent": "In some ways actually, I would say that what the frequentist approach that Bernard was describing is more correct because you're trying to take into account your cost at the time of fitting your model.",
                    "label": 0
                },
                {
                    "sent": "In the Bayesian approach, you don't do that, and there's a reason why or in this maximum likelihood approach.",
                    "label": 0
                },
                {
                    "sent": "Either you won't do that.",
                    "label": 0
                },
                {
                    "sent": "The reason why you don't do that is you know that if your model is correct, you don't need to worry about that, so you can prove that you can say if the thing for the model you've got for the system is correct, you don't have to worry about the cost until later.",
                    "label": 0
                },
                {
                    "sent": "So that's a really nice separation.",
                    "label": 0
                },
                {
                    "sent": "You can do these two things separately.",
                    "label": 0
                },
                {
                    "sent": "You worry about your inference, as I would call it.",
                    "label": 0
                },
                {
                    "sent": "Then you worry about your cost.",
                    "label": 0
                },
                {
                    "sent": "Of course, in practice that's never really true.",
                    "label": 0
                },
                {
                    "sent": "You never know you've got the correct model, so you can't really do that separation.",
                    "label": 0
                },
                {
                    "sent": "But the nice thing about the separation is it makes everything simpler.",
                    "label": 0
                },
                {
                    "sent": "It makes model construction simpler, so you have to be more intelligent to be a frequentist, I would say.",
                    "label": 0
                },
                {
                    "sent": "So I'm a Bayesian because it's mechanical and I don't have to think so hard so I can do more with my limited brainpower.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "This is Gaussian noise we're adding on here, but it's a product of the generating system.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Nothing to do with the cost.",
                    "label": 0
                },
                {
                    "sent": "So once we've got said that this implies that we can write this down, and this is a sort of way we describe a likelihood in this case, that implies that Y is drawn from a Gaussian.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Distribution with the mean given by that.",
                    "label": 0
                },
                {
                    "sent": "And since the noise is 0.",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Mean when you add noise to a Gaussian, you're just adding you, effectively making that the mean of the distribution.",
                    "label": 0
                },
                {
                    "sent": "You're adding a constant function to a zero mean Gaussian, which just means the mean of the new thing is that yeah, so we can also write that I would write that is, that's you, that this is the sort of a very statistical notation.",
                    "label": 0
                },
                {
                    "sent": "This till the thing here means.",
                    "label": 0
                },
                {
                    "sent": "Why is sampled from this?",
                    "label": 0
                },
                {
                    "sent": "And another way of writing that is that the probability of Y given W and Sigma is this Gaussian distribution, so.",
                    "label": 0
                },
                {
                    "sent": "My wife is dependent on these parameters and it's dependent through this Gaussian distribution, so I might interchange between those two styles, but they're basically identical, just the wise miss.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Off there.",
                    "label": 0
                },
                {
                    "sent": "Now.",
                    "label": 0
                },
                {
                    "sent": "One of the things I think is quite confusing is IID assumptions.",
                    "label": 0
                },
                {
                    "sent": "The way I think of IID assumptions.",
                    "label": 0
                },
                {
                    "sent": "Which you mentioned all the time is this.",
                    "label": 0
                },
                {
                    "sent": "So if the noise is sampled independently for each data point from the same density.",
                    "label": 0
                },
                {
                    "sent": "So if this noise that we're seeing this corrupting influence is independent every time we get a data point and it's coming from the same dense to each time, that's what I think of as an IID assumption.",
                    "label": 0
                },
                {
                    "sent": "I don't like to think of the model as being an IID assumption, because it would seem weird if they were all my data points were completely independent, then I'm not going to learn anything.",
                    "label": 0
                },
                {
                    "sent": "So I think of the noise is being IID.",
                    "label": 0
                },
                {
                    "sent": "So if we make this IID assumption that the noise is coming independently each time, then we can write down.",
                    "label": 0
                },
                {
                    "sent": "Independence allows us to write the joint distribution over Y is just the product of the marginals, so we can write that down in that form, and that's the standard sort of assumption for a regression problem.",
                    "label": 0
                },
                {
                    "sent": "And that means that we have a likelihood of this form, so the likelihood is this joint distribution over these Gaussian things.",
                    "label": 0
                },
                {
                    "sent": "Now what we're going.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Do is click through here.",
                    "label": 0
                },
                {
                    "sent": "We're going to look at that term and say, OK, there's a term there, but it's not dependent on these parameters that I was.",
                    "label": 0
                }
            ]
        },
        "clip_42": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Sitting before so I'm going to ignore it and I'm just going to say that this is proportional to.",
                    "label": 0
                }
            ]
        },
        "clip_43": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That so that was the constant proportion.",
                    "label": 0
                }
            ]
        },
        "clip_44": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It keeps this curve one, so I'm just going to.",
                    "label": 0
                }
            ]
        },
        "clip_45": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Laugh.",
                    "label": 0
                },
                {
                    "sent": "Now I'm gonna look at that Prada.",
                    "label": 0
                }
            ]
        },
        "clip_46": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Often say, well, I can pull that product inside the exponential product of exponentials is the same as the exponential of the sums.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to.",
                    "label": 0
                }
            ]
        },
        "clip_47": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That then.",
                    "label": 0
                }
            ]
        },
        "clip_48": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm going to look at the.",
                    "label": 0
                }
            ]
        },
        "clip_49": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Potential and say well I can remove that by putting a logarithm on the other side.",
                    "label": 0
                },
                {
                    "sent": "So now I've got something of this form.",
                    "label": 0
                }
            ]
        },
        "clip_50": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So by constant proportionality here now becomes an additive constant here.",
                    "label": 0
                },
                {
                    "sent": "Now I'm going to look at that term and say, well, OK, up to.",
                    "label": 0
                }
            ]
        },
        "clip_51": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "A scalar.",
                    "label": 0
                },
                {
                    "sent": "That is equal to the error function I defined before, yeah, so.",
                    "label": 0
                },
                {
                    "sent": "Before we were minimizing this error function, but now we can see that that error function is equivalent to a negative log likelihood.",
                    "label": 0
                },
                {
                    "sent": "OK, negative, so if I minimize.",
                    "label": 0
                },
                {
                    "sent": "Something and then take its negative.",
                    "label": 0
                },
                {
                    "sent": "I'm maximizing the negative, so in fact I'm if I minimize the error function.",
                    "label": 0
                },
                {
                    "sent": "I'm maximizing the log likelihood and then the important thing about the log is it's a monotonic function.",
                    "label": 1
                },
                {
                    "sent": "I never got that powered up, did I?",
                    "label": 0
                },
                {
                    "sent": "Well, I won't draw then.",
                    "label": 0
                },
                {
                    "sent": "Thing about the log is it's a monotonic function.",
                    "label": 0
                },
                {
                    "sent": "So if you've got a monotonic function.",
                    "label": 0
                },
                {
                    "sent": "If you maximize something and then you Mac and then you put it through a monotonic function, it doesn't change the ordering of things.",
                    "label": 0
                },
                {
                    "sent": "So if I you can think about that in the discrete case.",
                    "label": 0
                },
                {
                    "sent": "If I take the logarithm of a discrete set of numbers and then I want to find the function.",
                    "label": 0
                },
                {
                    "sent": "Sorry I had something are not explaining that very well.",
                    "label": 0
                },
                {
                    "sent": "Because it's a monotonic function, if I maximize log of this, I'm also maximizing that itself so I can take the negative log likelihood.",
                    "label": 0
                },
                {
                    "sent": "I can minimize the negative log likelihood, and I'm effective.",
                    "label": 0
                }
            ]
        },
        "clip_52": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Maximizing the likelihood.",
                    "label": 0
                },
                {
                    "sent": "So the probabilistic interpretation for the error function is the negative log likelihood and minimizing this error function is equivalent to maximizing the log likelihood.",
                    "label": 0
                },
                {
                    "sent": "So maximizing the log likelihood is equivalent to maximizing the likelihood because the log is monotonic, so this is the probabilistic interpretation of the error function.",
                    "label": 1
                },
                {
                    "sent": "It's basically the.",
                    "label": 0
                },
                {
                    "sent": "Minimizing the error function is equivalent to maximizing likelihood with respect to the parameters, so this is called maximum likelihood.",
                    "label": 0
                },
                {
                    "sent": "So everything we saw before can be reinterpreted in that way.",
                    "label": 0
                },
                {
                    "sent": "Now there was a question in the break after I spoke last time.",
                    "label": 0
                },
                {
                    "sent": "Is it true that every error function can be interpreted as a maximum likelihood and the answer is no, because you can imagine error functions that you can't normalize.",
                    "label": 0
                },
                {
                    "sent": "And if you can't see when you take the exponential.",
                    "label": 0
                },
                {
                    "sent": "Of the error function, you can't actually normalize the result, and if that's the case you can't think of it as maximum likelihood because you don't have this property of a probability distribution, so normalization is vital for to claim some things in probability distribution.",
                    "label": 0
                }
            ]
        },
        "clip_53": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So, but most things the people that using typically can be treated that way.",
                    "label": 0
                },
                {
                    "sent": "I know the example that was given was an example not, but there's most sort of standard things people are using.",
                    "label": 0
                },
                {
                    "sent": "Is error functions.",
                    "label": 0
                },
                {
                    "sent": "You can interpret as likelihood.",
                    "label": 0
                },
                {
                    "sent": "So if the data was really generated according to the model be specified, that likelihood really had Gaussian noise plus that.",
                    "label": 0
                },
                {
                    "sent": "Weighted linear summer basis functions.",
                    "label": 0
                },
                {
                    "sent": "Then what you can say is that the correct parameters will be converged in the limit as N goes to Infinity.",
                    "label": 0
                },
                {
                    "sent": "Personally, this is a you know this consistency proof.",
                    "label": 0
                },
                {
                    "sent": "I don't remember the last time someone gave me infinite data, so I'm not sure how much I care about these proofs.",
                    "label": 0
                },
                {
                    "sent": "Personally, it's as Bernard was mentioning the rate of convergence.",
                    "label": 0
                },
                {
                    "sent": "That's actually quite important, but in some sense I really am interested in very low data areas, so it's true, you know, I think a lot of what say Google are doing with very large datasets is reliant on this.",
                    "label": 0
                },
                {
                    "sent": "You know, we've got a limited number of parameters, a lot of data and things work really well in that region, and you can prove that this is the case by using the law of large numbers, ANAN showing.",
                    "label": 0
                },
                {
                    "sent": "But what you're doing is is more minimizing what's called a callback.",
                    "label": 0
                },
                {
                    "sent": "Leiber divergent between the true distribution in your approximation, and this is like a mainstay of classical statistics, although I mean it's credited to Fisher a lot, I haven't really read the papers, but you know, you can go back to Gauss.",
                    "label": 0
                },
                {
                    "sent": "His explanation of least squares.",
                    "label": 0
                },
                {
                    "sent": "So what I've described to you in this error function is least squares, and I think if you're talking Gauss is sort of re explanation of what these squares was, 'cause he didn't invent it, then you're going back to something like 1810.",
                    "label": 0
                },
                {
                    "sent": "That physicists were doing this, so This is why I keep looking at physicists and thinking over there a little bit ahead of machine learning people they just didn't have the computers, so that was their interpretation.",
                    "label": 0
                },
                {
                    "sent": "That was Gauss's interpretation, and he claimed that he found that Planet series or whatever it's called the dwarf planet.",
                    "label": 0
                },
                {
                    "sent": "He refound where it was through applying this.",
                    "label": 0
                },
                {
                    "sent": "Basically in he found that he made that claim in order to justify he didn't.",
                    "label": 0
                }
            ]
        },
        "clip_54": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "At least squares first.",
                    "label": 0
                }
            ]
        },
        "clip_55": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That might be a bit dodgy.",
                    "label": 0
                },
                {
                    "sent": "I'm so Germans and French.",
                    "label": 0
                },
                {
                    "sent": "Where it was at apparently.",
                    "label": 0
                },
                {
                    "sent": "So this is the likelihood for aggression, and the suggestion is to maximize this with respect to W. That's what we've been doing in the last time, and that could be done with the gradient based optimization of the log likelihood.",
                    "label": 0
                },
                {
                    "sent": "Now there's an alternative approach, and this is the Bayesian approach, so the alternative approach is not to optimize this W, but to integrate it out.",
                    "label": 0
                },
                {
                    "sent": "This is where the controversy starts.",
                    "label": 0
                },
                {
                    "sent": "So what we're going to do is effectively consider the expected values of all the likelihoods under a range of potential WS that we believed in.",
                    "label": 0
                },
                {
                    "sent": "So when Bernard was talking before about prior knowledge over functions, this is effectively how in this model you're introducing that prior knowledge is saying I'm going to have a distribution for W, so I purposefully write my parameters is conditioning as if they are random variables, and that means that I can think of appeared W and then use the sum rule to integrate it out.",
                    "label": 0
                },
                {
                    "sent": "That's what goes on.",
                    "label": 0
                }
            ]
        },
        "clip_56": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the Bayesian approach.",
                    "label": 0
                },
                {
                    "sent": "So we're going to use Bayes rule to implement the Bayesian approach an, but basing is not named after Bayes rule.",
                    "label": 0
                },
                {
                    "sent": "This is very common confusion if you don't use Bayes rule to invert probability, you're just wrong.",
                    "label": 0
                },
                {
                    "sent": "You're not being frequentist.",
                    "label": 0
                },
                {
                    "sent": "Bayesian refers to something different.",
                    "label": 0
                },
                {
                    "sent": "What Bayesian refers to.",
                    "label": 0
                }
            ]
        },
        "clip_57": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So is this thing that I'm doing here treating the parameters as a stochastic variable, and that's where the controversy lies, I don't think.",
                    "label": 0
                }
            ]
        },
        "clip_58": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To control the controversial in machine learning, but it was very controversial in early statistics, and I think that's because they needed to have things subjective.",
                    "label": 0
                },
                {
                    "sent": "And when you were introducing this prize you were introducing, you need to have things objective and they were introducing subjectivity and there's still a big debate in statistics.",
                    "label": 0
                },
                {
                    "sent": "You know the great thing in statistics is, you know, we joke around between Bayesians and Frequentists about.",
                    "label": 0
                },
                {
                    "sent": "Weather Bayesians frequentists, right, and make fun of each other a little bit in a friendly way in statistics.",
                    "label": 0
                },
                {
                    "sent": "As far as I can tell, the Bayesians don't really talk to the frequentists and they fight amongst each other about who's right, the objective Bayesians or the subjective Bayesians and objective Bayesians believe.",
                    "label": 0
                },
                {
                    "sent": "You can come up with prizes that are completely objective and subjective.",
                    "label": 0
                },
                {
                    "sent": "Bayesians believe a prior is always a personal thing and you.",
                    "label": 0
                }
            ]
        },
        "clip_59": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You can't have a fully objective one, so I don't even want to start on that debate.",
                    "label": 0
                },
                {
                    "sent": "But why is it called Bayesian?",
                    "label": 0
                },
                {
                    "sent": "Well, remember that binomial distribution, well, let's look at it for one trial, so Bayes also talked about.",
                    "label": 0
                }
            ]
        },
        "clip_60": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Binomial, but when he talked about the burner meal, he considered like a billiard table and he considered rolling a ball on the billiard table and the ball lands somewhere on the billiard table, potentially uniformly.",
                    "label": 0
                },
                {
                    "sent": "Let's assume it's uniformly between these two sides.",
                    "label": 0
                }
            ]
        },
        "clip_61": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Then he threw another ball.",
                    "label": 0
                }
            ]
        },
        "clip_62": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that's where it lands, and it lands either to the left or the right of this first ball.",
                    "label": 1
                },
                {
                    "sent": "So you can do that, then trial multiple times.",
                    "label": 0
                },
                {
                    "sent": "You can keep rolling the next ball, the red.",
                    "label": 0
                }
            ]
        },
        "clip_63": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Pull multiple times and so the next time it comes out there.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so if you believe this Red Bull also lands uniformly, and that's the assumption he made, then you're basically using for one trial using the Bernoulli distribution for multiple trials.",
                    "label": 1
                },
                {
                    "sent": "If it's successful to land on the right, you're using the binomial distribution, but the key component about this and what Fisher hated about.",
                    "label": 1
                }
            ]
        },
        "clip_64": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "His paper.",
                    "label": 0
                },
                {
                    "sent": "Was the fact that he was treating this parameter as a random variable, so he sampled the parameter by rolling the first ball down.",
                    "label": 1
                },
                {
                    "sent": "Now, Can you imagine how your base is writing this stuff?",
                    "label": 0
                },
                {
                    "sent": "Thinking, oh, I'll just crawl, but here's a way of creating a binomial.",
                    "label": 0
                },
                {
                    "sent": "Probably thought about it for 2 seconds and just wrote this down.",
                    "label": 0
                },
                {
                    "sent": "I mean, he didn't really, he died before this was published, so he didn't really believe in one way or the other.",
                    "label": 0
                },
                {
                    "sent": "But all the controversy is just based around the fact that in one case you talk about an urn.",
                    "label": 0
                },
                {
                    "sent": "With a fixed number of black and Red Bull, so that's a known thing.",
                    "label": 0
                },
                {
                    "sent": "That's not a random thing, it's a known thing.",
                    "label": 0
                },
                {
                    "sent": "You know there's a fixed number of black and red balls, and here you're generating the parameter for binomial by sampling from uniform.",
                    "label": 0
                },
                {
                    "sent": "So that makes the parameter of stochastic variable.",
                    "label": 0
                },
                {
                    "sent": "Ann Fisher hated that, and Fisher invented the sort of term we use the term Bayesian as an insult to people they used to call it what they call it.",
                    "label": 1
                },
                {
                    "sent": "They call it the inverse probability or something, and he invented the term Bayesian as a way of insulting inverse probabilists.",
                    "label": 0
                },
                {
                    "sent": "And now the names start, but it's to do with this.",
                    "label": 0
                },
                {
                    "sent": "It's not to do with.",
                    "label": 0
                }
            ]
        },
        "clip_65": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Naive Bayes is a method is not Bayesian.",
                    "label": 0
                },
                {
                    "sent": "For example, OK.",
                    "label": 0
                },
                {
                    "sent": "So what's going on in this in Bayesian inference?",
                    "label": 0
                },
                {
                    "sent": "So there's these different components.",
                    "label": 0
                },
                {
                    "sent": "The Bayes rule we had earlier is of this form.",
                    "label": 0
                },
                {
                    "sent": "Posterior is equal to likelihood times prior divided by marginal and Josh.",
                    "label": 0
                },
                {
                    "sent": "Sort of showed this earlier.",
                    "label": 0
                },
                {
                    "sent": "So the prior distribution is representing as a probability distribution.",
                    "label": 0
                },
                {
                    "sent": "The belief about these parameter values before we observed the data, right?",
                    "label": 0
                },
                {
                    "sent": "So somehow we don't observe where this black ball lands.",
                    "label": 0
                },
                {
                    "sent": "Yeah, but we know it's uniformly distributed and that's the prior.",
                    "label": 0
                },
                {
                    "sent": "The likelihood gives the relation between the parameters and the data, so it's like turning us what the relationship between what we observed and what we didn't observe is the posterior distribution represents an updated belief of what we think.",
                    "label": 0
                },
                {
                    "sent": "Now about the parameter.",
                    "label": 0
                },
                {
                    "sent": "Once we've observed the data.",
                    "label": 0
                },
                {
                    "sent": "The marginal likelihood is very important because the marginal likelihood it looks just like a normalizer here.",
                    "label": 0
                },
                {
                    "sent": "If we, if we're thinking of just what we want to know about the parameters, it is that that that's a start state and that's the end state, and This is why this is really interesting for cognitive science, because you can keep processing this.",
                    "label": 0
                },
                {
                    "sent": "You can plug a posterior in the back end here and keep learning more and more in an online way.",
                    "label": 0
                },
                {
                    "sent": "It's a really nice way of seeing how your beliefs evolve, but the marginal likelihood is very important because it actually assessed mean.",
                    "label": 0
                },
                {
                    "sent": "It's just another likelihood.",
                    "label": 0
                },
                {
                    "sent": "In some ways it's a likelihood with some of the parameters integrated out and you can sort of do maximum likelihood with the marginal likelihood, but it's a better thing to do because you've removed a lot of the parameters, so you're less likely to be overfitting the ratios that Josh was talking about.",
                    "label": 0
                },
                {
                    "sent": "We can we talk about those as Bayes factors and their ratios of these marginal likelihoods.",
                    "label": 0
                },
                {
                    "sent": "It's also sometimes called the evidence, particularly by people from the maximum entropy.",
                    "label": 0
                },
                {
                    "sent": "Community, which is an important community in physics the in the days when Bayesian inference was almost completely dead.",
                    "label": 0
                },
                {
                    "sent": "In statistics, these physicists were using it and suggesting it.",
                    "label": 0
                },
                {
                    "sent": "James, sort of, who I think was in the Manhattan Project, was sort of promoting it across all the period.",
                    "label": 0
                },
                {
                    "sent": "It died out in statistics.",
                    "label": 0
                },
                {
                    "sent": "So they called it the evidence.",
                    "label": 0
                }
            ]
        },
        "clip_66": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "When they talk about it.",
                    "label": 0
                },
                {
                    "sent": "OK, so here's a Bayesian example of the sort of thing you might want to do, and I just think it's it's one of the most natural examples, and in fact it is Sebastian Thrun who's taking this sort of approach to robot navigation.",
                    "label": 0
                },
                {
                    "sent": "And, you know, written entire books about it, so it's a bit more complicated than I'm talking about here.",
                    "label": 0
                },
                {
                    "sent": "But as I understand it, this is state of the art in the way you do robot localization and mapping.",
                    "label": 0
                },
                {
                    "sent": "So imagine that you represent a robot state, and let's just assume that it's position on a 1 dimensional line.",
                    "label": 0
                },
                {
                    "sent": "Earth X.",
                    "label": 0
                },
                {
                    "sent": "The robot makes readings using it sensors, so it could be a multidimensional.",
                    "label": 0
                },
                {
                    "sent": "Say it could be its position, velocity, rate of turn.",
                    "label": 0
                },
                {
                    "sent": "But for a moment you can just think of its position on one dimensional line and it makes you readings using IT sensors.",
                    "label": 0
                },
                {
                    "sent": "It may have a multiple array of sensors.",
                    "label": 0
                },
                {
                    "sent": "It may have sonar sensors.",
                    "label": 0
                },
                {
                    "sent": "We have laser sensors, it may have all sorts of things, but they're going to be sorted Y.",
                    "label": 0
                },
                {
                    "sent": "We can think of that sensor is 1 dimensional.",
                    "label": 0
                },
                {
                    "sent": "We will in a moment now.",
                    "label": 0
                },
                {
                    "sent": "The idea here is that at anytime we might have an idea that where the robot is.",
                    "label": 0
                },
                {
                    "sent": "So we think the robots in this room.",
                    "label": 0
                },
                {
                    "sent": "And we have a map of this room.",
                    "label": 0
                },
                {
                    "sent": "Given the different locations in this room.",
                    "label": 0
                },
                {
                    "sent": "We have a model of what the sensor readings should be, because we know where the walls are and if we've got the direction the robots pointing in X, we know where it's pointing, so we know like if it's got sonar sensor.",
                    "label": 0
                },
                {
                    "sent": "You know in the robots here facing this way we know that the sensor will be reading with some accuracy.",
                    "label": 0
                },
                {
                    "sent": "The distance of that wall.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so it might have some noise associated with it, but basically that's our likelihood.",
                    "label": 0
                },
                {
                    "sent": "So we can combine the initial picture of that location with the sensor readings to get an updated of the picture of the location using the Bayes rule to get the posterior.",
                    "label": 0
                },
                {
                    "sent": "So this is how it works.",
                    "label": 0
                },
                {
                    "sent": "We've got an initial idea of where the robot is.",
                    "label": 0
                },
                {
                    "sent": "We make an observation of from our sensors and then we update that.",
                    "label": 0
                }
            ]
        },
        "clip_67": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To where we think the robot is afterwards.",
                    "label": 0
                },
                {
                    "sent": "So this is X.",
                    "label": 0
                },
                {
                    "sent": "This is our prior belief about where the robot is.",
                    "label": 1
                },
                {
                    "sent": "Its at minus 1X.",
                    "label": 0
                }
            ]
        },
        "clip_68": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now it's important when I draw the likelihood that is normalized along X, right?",
                    "label": 0
                },
                {
                    "sent": "This is not normalized index, it's normalized in why?",
                    "label": 0
                },
                {
                    "sent": "So this doesn't have to integrate to one.",
                    "label": 0
                },
                {
                    "sent": "It actually happens to in this case because of our properties of Gaussian, but in general it doesn't integrate to one, so we can draw both.",
                    "label": 0
                },
                {
                    "sent": "These things though is it's a function of X.",
                    "label": 0
                },
                {
                    "sent": "It's not a probability distribution with respect to X 'cause it's given X, so that's the likelihood, and the likelihood is sort of saying well.",
                    "label": 0
                },
                {
                    "sent": "This is how likely we are to get each reading given our position in X.",
                    "label": 0
                }
            ]
        },
        "clip_69": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To get the posterior, we multiply these things to two things together.",
                    "label": 0
                },
                {
                    "sent": "And then.",
                    "label": 0
                }
            ]
        },
        "clip_70": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We re normalize?",
                    "label": 0
                },
                {
                    "sent": "So what's going on here is basically.",
                    "label": 0
                },
                {
                    "sent": "The prior is saying the.",
                    "label": 0
                },
                {
                    "sent": "We think the robots there the data maximum likelihood solution would be there, right?",
                    "label": 0
                },
                {
                    "sent": "That's the highest likelihood where the robot is.",
                    "label": 0
                },
                {
                    "sent": "OK, but there's uncertainty, so in maximum likelihood you don't reflect that uncertainty.",
                    "label": 0
                },
                {
                    "sent": "So in maximum likelihood you just say the robots there, and that's all I know.",
                    "label": 0
                },
                {
                    "sent": "In Bayesian approach, you say that's my where I thought it was.",
                    "label": 0
                },
                {
                    "sent": "That's where the likelihood said it is.",
                    "label": 0
                },
                {
                    "sent": "You see this little bit of mass that's overlapping here.",
                    "label": 0
                }
            ]
        },
        "clip_71": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Product of those renormalized.",
                    "label": 0
                },
                {
                    "sent": "Is that so?",
                    "label": 0
                },
                {
                    "sent": "My updated belief is well.",
                    "label": 0
                },
                {
                    "sent": "It's somewhere quite close to the likelihood.",
                    "label": 0
                },
                {
                    "sent": "If I had more accurate sensors, the width of this likelihood is the accuracy of my sensor.",
                    "label": 0
                },
                {
                    "sent": "If I if I increase the accuracy of the center and the width goes down, I'll be pulled more towards the maximum likelihood solution.",
                    "label": 0
                },
                {
                    "sent": "If I'm more uncertain about where I was initially, I'm pulled more towards the maximum likelihood solution.",
                    "label": 0
                },
                {
                    "sent": "If I was more certain where I was initially, I'd be pulled less towards it so that it's really odd situation for Gaussians, because what actually happens and common filters, for example, are based entirely on this, but.",
                    "label": 0
                },
                {
                    "sent": "You have a Gaussian prior Gaussian likelihood and your posterior Gaussian.",
                    "label": 1
                },
                {
                    "sent": "That's very unusual.",
                    "label": 0
                },
                {
                    "sent": "Normally you don't have a prior to likelihood to posterior where everything is the same distribution.",
                    "label": 0
                },
                {
                    "sent": "I think Gaussians only example I know of.",
                    "label": 0
                },
                {
                    "sent": "Sometimes you get the same class of distributions for your prior and your posterior and those are called conjugate models, and that's a really nice computational trick.",
                    "label": 0
                },
                {
                    "sent": "Are major criticism of Bayesian inference is that we don't actually choose these things for what we believe we choose them for tractability.",
                    "label": 0
                },
                {
                    "sent": "So we choose these conjugate models, which give us nice tractable qualities, and I think that's about it.",
                    "label": 0
                },
                {
                    "sent": "Criticism makes things faster, makes the algorithms faster.",
                    "label": 0
                }
            ]
        },
        "clip_72": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the Gaussian prior combined with Gaussian likelihood for Gaussian posterior.",
                    "label": 0
                },
                {
                    "sent": "But if the likelihood is non gas you want.",
                    "label": 0
                }
            ]
        },
        "clip_73": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Coaches to approximate the posterior with a Gaussian.",
                    "label": 1
                },
                {
                    "sent": "So here's a different likelihood.",
                    "label": 0
                },
                {
                    "sent": "So you might start out with a prior over whether you think I'm going to say anything intelligent or anything dumb in this talk, and you might be observing if I say something intelligent, that's an observation of one, and if I say something dumb, that's an observation of minus one.",
                    "label": 0
                },
                {
                    "sent": "Now how you've got an idea of where I am along this line.",
                    "label": 0
                },
                {
                    "sent": "So if I'm up here, I'm intelligent, and if I'm down here, I'm dumb, right?",
                    "label": 0
                },
                {
                    "sent": "So if I'm down here, the probability I'll say something dumb is very high in the probability I'm saying something intelligent.",
                    "label": 0
                },
                {
                    "sent": "Is 1 minus that if I'm up here, the probability I'm saying something intelligent is high and the probability I'm saying something dumb is low?",
                    "label": 0
                },
                {
                    "sent": "Or you could even think of this while there are.",
                    "label": 0
                }
            ]
        },
        "clip_74": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Come on to that example later.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is your prior you think I'm.",
                    "label": 0
                },
                {
                    "sent": "Reasonably dumb.",
                    "label": 0
                }
            ]
        },
        "clip_75": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And then what happens is I say something intelligent.",
                    "label": 0
                },
                {
                    "sent": "So you observe this thing.",
                    "label": 0
                },
                {
                    "sent": "This is now the likelihood.",
                    "label": 0
                },
                {
                    "sent": "Note it's not normalized in any way or form, it's just a function of effects distribution over something discreet, right?",
                    "label": 0
                },
                {
                    "sent": "So it just sums the two are the two different things sum to 1 two different probabilities.",
                    "label": 0
                }
            ]
        },
        "clip_76": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I say something intelligent and then that's the posterior.",
                    "label": 0
                },
                {
                    "sent": "Yeah, so now you've moved a little bit, you think?",
                    "label": 0
                },
                {
                    "sent": "Well, you know he's probably in this regime because I know he's only said one intelligent thing and he could have said it by accident so.",
                    "label": 0
                },
                {
                    "sent": "I I'm going to assume he's yeah.",
                    "label": 0
                },
                {
                    "sent": "I mean it is a little bit more intelligent, but not that much more so.",
                    "label": 0
                },
                {
                    "sent": "One trick that I'd like to sort of include here the difficult bit if you do this model is.",
                    "label": 0
                },
                {
                    "sent": "Once you've done that.",
                    "label": 0
                },
                {
                    "sent": "This is a really simple model, but the Xbox.",
                    "label": 0
                },
                {
                    "sent": "Ranking system for quality of players is based entirely on this model and what I'm going to do next.",
                    "label": 0
                }
            ]
        },
        "clip_77": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which is to replace that non Gaussian nasty thing.",
                    "label": 0
                },
                {
                    "sent": "We think of that as a truncated Gaussian.",
                    "label": 0
                },
                {
                    "sent": "It's convolution of this squashing function of Gaussian with the Gaussian and the way one can do that is by fitting this Gaussian.",
                    "label": 0
                },
                {
                    "sent": "Pink curve that we had before.",
                    "label": 0
                },
                {
                    "sent": "Now I. I just think that wasn't a great fit until I saw some of Josh is Gaussian fits to his data yesterday.",
                    "label": 0
                },
                {
                    "sent": "Well, I think the film stuff and that's pretty.",
                    "label": 0
                },
                {
                    "sent": "That's about the same as the film fit, but it can be a really bad fit, because these Gaussians can be completely truncated, so this can be a bad thing to do.",
                    "label": 0
                },
                {
                    "sent": "But the nice thing, once you've done this so this is a trick.",
                    "label": 0
                },
                {
                    "sent": "Once you've done this, you can then proceed with another observation so you can.",
                    "label": 0
                },
                {
                    "sent": "Then you can then say something dumb, and then you can drop down in your estimate.",
                    "label": 0
                },
                {
                    "sent": "One thing to notice is because of the quality of some characteristics of these log likelihoods here.",
                    "label": 0
                },
                {
                    "sent": "And in fact, it's the log concavity of the likelihood.",
                    "label": 0
                },
                {
                    "sent": "So sorry, this is likely not a log likelihood.",
                    "label": 0
                },
                {
                    "sent": "If I took the logarithm, you would see it's concave.",
                    "label": 0
                },
                {
                    "sent": "It has a nasty property, I think from a cog science point of view.",
                    "label": 0
                },
                {
                    "sent": "I definitely think it's nasty what will happen if this likelihood is log concave and most likely as we use our is every time you make an observation, you become more confident about what you're seeing.",
                    "label": 0
                },
                {
                    "sent": "So basically I think that's very counter intuitive.",
                    "label": 0
                },
                {
                    "sent": "Or maybe it's it's a.",
                    "label": 0
                },
                {
                    "sent": "Maybe it's because I'm learning all these good words I can say maybe it's because of introspection.",
                    "label": 0
                },
                {
                    "sent": "I think the way I update my beliefs is I might.",
                    "label": 0
                },
                {
                    "sent": "I might start thinking yeah yeah, yeah.",
                    "label": 0
                },
                {
                    "sent": "He's not said anything really good yet, so I just keep thinking are not very clever.",
                    "label": 0
                },
                {
                    "sent": "Not very clever, but then he said something really clever.",
                    "label": 0
                },
                {
                    "sent": "Then I would increase my uncertainty an increase my belief that I thought someone had said that I thought the person was clever, right?",
                    "label": 0
                },
                {
                    "sent": "That's what I would do.",
                    "label": 0
                },
                {
                    "sent": "I would think.",
                    "label": 0
                },
                {
                    "sent": "Oh, I was wrong.",
                    "label": 0
                },
                {
                    "sent": "I was wrong to be confident about what that person was doing.",
                    "label": 0
                },
                {
                    "sent": "That's not what these models do because the log concavity of the likelihood.",
                    "label": 0
                },
                {
                    "sent": "In fact, they decrease their uncertainty in pretty much if you look at it in terms of entropy in pretty much linear type of way.",
                    "label": 0
                },
                {
                    "sent": "So even if I said something really dumb and really intelligent, really dumb, really intelligent, really dumb.",
                    "label": 0
                },
                {
                    "sent": "You would just become really confident about whether I was intelligent.",
                    "label": 0
                },
                {
                    "sent": "You wouldn't be like, oh, I'm completely at a loss and I think that the intuition is that that's what you should be thinking.",
                    "label": 0
                },
                {
                    "sent": "I mean, that's how I feel.",
                    "label": 0
                },
                {
                    "sent": "I have opinions and I'm very opinionated actually.",
                    "label": 0
                },
                {
                    "sent": "But one of the things I like to do is if I see something that's against my opinions, then then I like to try and re evaluate completely my opinions and become very uncertain.",
                    "label": 0
                },
                {
                    "sent": "The way these models Bayesian inference will do that, but not with most of the classically constructed models, most of the time it just gets more confident as you see data so that something can be quite variable and the actual property is the log concavity of the likelihood.",
                    "label": 0
                },
                {
                    "sent": "If the likelihood is log concave, that's going to happen.",
                    "label": 0
                },
                {
                    "sent": "If you've got non log concave likelihoods you can get this nice effect and, for example, robust regression is an example of that.",
                    "label": 0
                },
                {
                    "sent": "If in robust regression if you see a data point that's a lot further away from where you expect it to be.",
                    "label": 0
                },
                {
                    "sent": "Then you will actually increase your uncertainty about what's going on because the like.",
                    "label": 0
                }
            ]
        },
        "clip_78": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's used to not log concave.",
                    "label": 0
                },
                {
                    "sent": "So then this is final example is because there was an election on last night and this is how left or right wing you are.",
                    "label": 0
                },
                {
                    "sent": "So on the left wing you're voting labor.",
                    "label": 0
                },
                {
                    "sent": "This is you probably don't know these parties if you're not English in the middle.",
                    "label": 0
                },
                {
                    "sent": "This is labeled.",
                    "label": 0
                },
                {
                    "sent": "Americans may be surprised to see that the Liberal Party is in the middle in the United Kingdom and most of Europe not way on the left.",
                    "label": 0
                },
                {
                    "sent": "But this is the Liberal Party and then.",
                    "label": 0
                }
            ]
        },
        "clip_79": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is the conservative party.",
                    "label": 0
                },
                {
                    "sent": "The observation in this case is you think someone.",
                    "label": 0
                }
            ]
        },
        "clip_80": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Left wing, but then they say they voted Liberal and so you've observed.",
                    "label": 0
                }
            ]
        },
        "clip_81": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This middle thing, so you update your opinion there.",
                    "label": 0
                }
            ]
        },
        "clip_82": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Come all right wing and again that's a non Gaussian likelihood so you can update it with.",
                    "label": 0
                }
            ]
        },
        "clip_83": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "So I was vaguely hoping that Bernard was going to mention kernels in his talk, given it had kernel methods in the title.",
                    "label": 0
                },
                {
                    "sent": "And he wrote a book on it, but he didn't mention kernel methods, so I'll have to.",
                    "label": 0
                },
                {
                    "sent": "I've introduced a little bit on this.",
                    "label": 0
                }
            ]
        },
        "clip_84": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Spectrum kernel method.",
                    "label": 0
                },
                {
                    "sent": "So that likelihood we have before from regression what we can do is we can combine it with pride and stay over the parameters and this prize.",
                    "label": 0
                },
                {
                    "sent": "Just saying we don't know if a vague sort of the parameters are equally likely to be the same size is a spherical Gaussian prior.",
                    "label": 0
                },
                {
                    "sent": "It's the identity matrix on the covariance, an independent and basically some scale of these parameters that will eventually affect the scale of the function.",
                    "label": 0
                },
                {
                    "sent": "Now what I'm not going to show you, but you can do this integral and you recover because of these Gaussian Gaussian Gaussian effect.",
                    "label": 0
                },
                {
                    "sent": "You recover the marginal likelihood.",
                    "label": 0
                },
                {
                    "sent": "Model is Gaussian and you recover in particular that the elements of this new covariance zero mean because your prior over W is 0 mean.",
                    "label": 0
                },
                {
                    "sent": "So even though you had a mean here.",
                    "label": 0
                },
                {
                    "sent": "This primer is 0 mean and the effect of that is to make the final marginal likelihood zero mean.",
                    "label": 0
                },
                {
                    "sent": "Now this was independent and this is independent, but looking here this is not independent.",
                    "label": 0
                },
                {
                    "sent": "So basically this is a big covariance matrix that says what the correlation between different observations are, and in fact it depends on the X is.",
                    "label": 0
                },
                {
                    "sent": "So the elements of this covariance matrix which is giving you the correlations between your training points are given by this inner product between your basis functions and this is where I hope Bernard.",
                    "label": 0
                },
                {
                    "sent": "Had talked about kernel methods because we talked about these basis functions as a fixed set.",
                    "label": 0
                },
                {
                    "sent": "If you remember, then I. I was using three for polynomial or the RBF or squared exponential basis.",
                    "label": 0
                },
                {
                    "sent": "And then we've also got this term coming from the noise, so it's some sort of term coming from these sum across these basis functions times.",
                    "label": 0
                },
                {
                    "sent": "This scale parameter here, which is giving us the overall size of this covariance plus some noise.",
                    "label": 0
                },
                {
                    "sent": "Now this is what I would call a Gaussian process, but you.",
                    "label": 0
                }
            ]
        },
        "clip_85": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I also think of this as a kernel, so this is an inner product and if Bernard mentioned in a product in kernels, then we would know that one of the clever tricks you can do is you can replace this inner product with these so called covariance functions or kernels.",
                    "label": 0
                },
                {
                    "sent": "Mercer kernels, which allow you to consider infinite basis functions.",
                    "label": 0
                },
                {
                    "sent": "Now that's really funky, because instead of having to choose the number of bases which is one question I ask, well how many bases are you going to use?",
                    "label": 0
                },
                {
                    "sent": "You just say I'm going to use Infinity of them.",
                    "label": 0
                },
                {
                    "sent": "You never have to compute these Infinity basis functions because it's an inner product between two infinite things, and you can prove this relationship.",
                    "label": 0
                },
                {
                    "sent": "That's what Mercer's theorem allows you to do.",
                    "label": 0
                },
                {
                    "sent": "So this is a way of thinking about it that your current kernel is this sum over infinite basis functions computed at these two different training points.",
                    "label": 0
                },
                {
                    "sent": "So it's a covariance over your training data, so the covariance between two different training points is the evaluation of all these infinite basis functions at those two different training points.",
                    "label": 0
                }
            ]
        },
        "clip_86": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The thing about it, I think he's a bit of a mindset change for some machine learning.",
                    "label": 0
                },
                {
                    "sent": "People is when we talked and I emphasize before noises, iid noise is iid, yeah.",
                    "label": 0
                },
                {
                    "sent": "Hear the noise is IID because there's no cross dependence.",
                    "label": 0
                },
                {
                    "sent": "This is the Chronicle Delta that says only be one if I&J are equal otherwise.",
                    "label": 0
                },
                {
                    "sent": "So it's just on the diagonal.",
                    "label": 0
                },
                {
                    "sent": "The noise is IID, but integrating out these WS makes it very clear that your data is not ideal.",
                    "label": 0
                },
                {
                    "sent": "Your data is strongly correlated according to this covariance function, and that's what the covariance function is directly saying.",
                    "label": 0
                },
                {
                    "sent": "So when Bernard talked about prior over functions, this is a way of putting a prior over.",
                    "label": 0
                }
            ]
        },
        "clip_87": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's called the gas.",
                    "label": 0
                }
            ]
        },
        "clip_88": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Process.",
                    "label": 0
                },
                {
                    "sent": "So this is what these covariances look like.",
                    "label": 0
                },
                {
                    "sent": "Frequently, people call this the Gaussian kernel, which Bayesians don't like because there's no normalizing constant, so they call it the squared exponential kernel, which Bernard told me he didn't like because it's not a squared exponential.",
                    "label": 0
                },
                {
                    "sent": "It's a square within an exponential.",
                    "label": 0
                },
                {
                    "sent": "I was calling it the RBF kernel for ages, and Tony O'hagan, a statistician, said that was a horrible term.",
                    "label": 0
                },
                {
                    "sent": "So I've started calling the exponentiated quadratic kernel function.",
                    "label": 0
                },
                {
                    "sent": "But it's a commonly used thing.",
                    "label": 0
                },
                {
                    "sent": "It's all using really many kernel methods.",
                    "label": 0
                },
                {
                    "sent": "You can use many different ones of these, and one of the things I'm most interested in my research and working at the moment is is covariance functions that come out of mechanistic knowledge about the system.",
                    "label": 0
                },
                {
                    "sent": "You know, you can do all sorts of things with this, so this is the vanilla one.",
                    "label": 0
                },
                {
                    "sent": "This is the standard one, and it has this form.",
                    "label": 0
                },
                {
                    "sent": "If you compute all the elements of it, it's saying that things are very correlated.",
                    "label": 0
                },
                {
                    "sent": "If they are close to each other in the input space, and they're not correlated with their distant.",
                    "label": 0
                }
            ]
        },
        "clip_89": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here's some samples then.",
                    "label": 0
                }
            ]
        },
        "clip_90": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Nice thing is what you can do is you can sample.",
                    "label": 0
                },
                {
                    "sent": "You can't sample the infinite function, but what you can do is you can just define that as a covariance of a multivariate Gaussian and then you can sample.",
                    "label": 0
                }
            ]
        },
        "clip_91": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A single sample from that multivariate Gaussian and one of those samples will look like one of these, and these are also.",
                    "label": 0
                },
                {
                    "sent": "These are sort of 20 or different samples, which gives you an idea of what you're trying to say about your function and what you're actually saying is it's incredibly smooth, infinitely smooth.",
                    "label": 0
                },
                {
                    "sent": "In fact, it's a problem with this covariance function that it's too smooth and you're saying it's sort of stationary goes up and down, and this is an effect of all these basis functions.",
                    "label": 0
                },
                {
                    "sent": "Infinite basis functions you put over the real line, all being added together.",
                    "label": 0
                }
            ]
        },
        "clip_92": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Form that result.",
                    "label": 0
                }
            ]
        },
        "clip_93": {
            "is_summarization_sample": false,
            "summarization_data": []
        },
        "clip_94": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So here's some different parameters.",
                    "label": 0
                },
                {
                    "sent": "And then here's something called the Ornstein.",
                    "label": 0
                },
                {
                    "sent": "German would need to pronounce that correctly.",
                    "label": 0
                },
                {
                    "sent": "Ornstein Uhlenbeck process, which is a different covariance where instead of taking it's not an exponentiated quadratic.",
                    "label": 1
                },
                {
                    "sent": "It's an exponentiated out absolute and it's important in lots of physical things completely non smooth.",
                    "label": 0
                },
                {
                    "sent": "So you might expect something like this to come out.",
                    "label": 0
                }
            ]
        },
        "clip_95": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The Gaussian you might not expect that to come out of a Gaussian that.",
                    "label": 0
                }
            ]
        },
        "clip_96": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Real super smoothness, but these are sort of a.",
                    "label": 0
                },
                {
                    "sent": "It's like a stay.",
                    "label": 0
                }
            ]
        },
        "clip_97": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Missionary Brownian motion.",
                    "label": 0
                },
                {
                    "sent": "Those paths.",
                    "label": 0
                },
                {
                    "sent": "So what you can do is you can take this prior and then you can combine it with data and then you can see the posterior.",
                    "label": 0
                },
                {
                    "sent": "What I'm showing you here is before observing these two data points your prior over where this function is illustrated as a zero mean plus the marginal variance is at each point which are just constant for that.",
                    "label": 0
                }
            ]
        },
        "clip_98": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Function if I combine that with the two data points, then what starts to happen is I see the variances collapse near the data.",
                    "label": 0
                }
            ]
        },
        "clip_99": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Point",
                    "label": 0
                }
            ]
        },
        "clip_100": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "As I add data.",
                    "label": 0
                }
            ]
        },
        "clip_101": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Every time I add a data point, they sort of collapse.",
                    "label": 0
                },
                {
                    "sent": "I've got these error bars.",
                    "label": 0
                },
                {
                    "sent": "I don't know where the functions going between these things.",
                    "label": 0
                },
                {
                    "sent": "'cause I've got this length scale and then scale saying you're wiggling, and I can't pin down the wiggles 'cause I haven't seen the data.",
                    "label": 0
                },
                {
                    "sent": "So the beauty about the Bayesian approaches you're getting these lovely big error bars.",
                    "label": 0
                },
                {
                    "sent": "There's some costs are carrying these things around, and that's why the SVM is sort of algorithmically more efficient than the equivalent Gaussian process classifier, because in the SVM you don't carry these variances around you sort of ignore them effectively, do map solutions, but.",
                    "label": 0
                },
                {
                    "sent": "You know they can be really useful.",
                    "label": 0
                },
                {
                    "sent": "I worry that if you don't carry them around.",
                    "label": 0
                },
                {
                    "sent": "Certainly in some applications you sort of throwing out the baby with the bathwater.",
                    "label": 0
                },
                {
                    "sent": "But if you've got very.",
                    "label": 0
                }
            ]
        },
        "clip_102": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Large datasets, then perhaps they don't matter as much 'cause they start to collapse, so I like this, but here this was completely random.",
                    "label": 0
                },
                {
                    "sent": "When I first generated this data.",
                    "label": 0
                },
                {
                    "sent": "So look, it looks like we're really good.",
                    "label": 0
                }
            ]
        },
        "clip_103": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "These error bars are too large, but then look at these next points.",
                    "label": 0
                },
                {
                    "sent": "I mean that just was coincidence.",
                    "label": 0
                },
                {
                    "sent": "I didn't force that to happen there up here.",
                    "label": 0
                },
                {
                    "sent": "Now I am generating this data from the more.",
                    "label": 0
                }
            ]
        },
        "clip_104": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That's why it works so beautifully.",
                    "label": 0
                },
                {
                    "sent": "That's why all the error function bars look correct course.",
                    "label": 0
                },
                {
                    "sent": "In general, we can't generate the data from the model, and in general even this flexible looking model will be incorrect.",
                    "label": 0
                },
                {
                    "sent": "It will be overly smooth floors in the model will come out as we start to observe data that's too close to each other.",
                    "label": 0
                }
            ]
        },
        "clip_105": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If there's a mismatch between the model and the truth.",
                    "label": 0
                },
                {
                    "sent": "In the Bernard sort, I think that was being illustrated when he talked about classes of function and the rate of convergence of these empirical risk things.",
                    "label": 0
                },
                {
                    "sent": "That's, I think that's equivalent concept that if you have a mismatch between the function you're using in the truth, you won't get a good bound.",
                    "label": 0
                },
                {
                    "sent": "So what you can do, people ask me about how you set the length scale on these covariances, where you can maximize the likelihood of this or the negative log likelihood you can minimize.",
                    "label": 0
                },
                {
                    "sent": "So here's the log.",
                    "label": 0
                },
                {
                    "sent": "Likelihood of this Gaussian process and what it actually has.",
                    "label": 0
                },
                {
                    "sent": "So Bernard talked about the empirical risk, which is like a data fit term.",
                    "label": 0
                },
                {
                    "sent": "This is like a data fit, and then his capacity control term is like this one.",
                    "label": 0
                },
                {
                    "sent": "This is like an entropy.",
                    "label": 0
                },
                {
                    "sent": "It's like how many different functions, when he was at saying early.",
                    "label": 0
                },
                {
                    "sent": "You can use priors over the functions.",
                    "label": 0
                },
                {
                    "sent": "This thing is like counting how many different functions are associated with this prior.",
                    "label": 0
                },
                {
                    "sent": "How flexible is this system?",
                    "label": 0
                },
                {
                    "sent": "So what you tend to see is I can draw these three different terms, so the sum of the two of them and separately the data fit and the entropy.",
                    "label": 0
                }
            ]
        },
        "clip_106": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I'm in this graph here and as I changed the length scale so this is just the length scale, changing their noise is fixed.",
                    "label": 0
                },
                {
                    "sent": "But we could learn that as well as I change the length scale, increasing it, what will.",
                    "label": 0
                }
            ]
        },
        "clip_107": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Happen is the data fit, so the data that is measured by how accurately I'm interpolating the points with the mean.",
                    "label": 0
                },
                {
                    "sent": "The data fit term will get worse, but the capacity.",
                    "label": 0
                }
            ]
        },
        "clip_108": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The control will get better.",
                    "label": 0
                }
            ]
        },
        "clip_109": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the sun.",
                    "label": 0
                }
            ]
        },
        "clip_110": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Who will be the at this point here?",
                    "label": 0
                },
                {
                    "sent": "I have a Maxima in the.",
                    "label": 0
                }
            ]
        },
        "clip_111": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Cleared.",
                    "label": 0
                }
            ]
        },
        "clip_112": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now the data fit is.",
                    "label": 0
                }
            ]
        },
        "clip_113": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Overwhelming the capacity.",
                    "label": 0
                },
                {
                    "sent": "So this is the capacity control and then this is the data fit, so the data fits collapsing as where the length scale gets too large and the capacity controls going up.",
                    "label": 0
                },
                {
                    "sent": "But the sum of the effect is a maximum in the likelihood.",
                    "label": 0
                },
                {
                    "sent": "Now it's not guaranteed to be unique maximum as you start loading this kernel with more parameters, you'll start getting problems, but for a length scale with a reasonable amount of data it is typically going to be.",
                    "label": 0
                }
            ]
        },
        "clip_114": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we can fit these.",
                    "label": 0
                }
            ]
        },
        "clip_115": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Kernel parameters.",
                    "label": 0
                }
            ]
        },
        "clip_116": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Using this formalism OK.",
                    "label": 0
                }
            ]
        },
        "clip_117": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I think what I'm going to do is Bernard mentioned it's nice to have a bit of discussion, so I won't go through.",
                    "label": 0
                },
                {
                    "sent": "The latent variable, well, is it better I go through latent variables or mix of gas internal?",
                    "label": 0
                },
                {
                    "sent": "All that box.",
                    "label": 0
                },
                {
                    "sent": "Here we go.",
                    "label": 0
                },
                {
                    "sent": "I'll just go through the mix of Gaussians probably and not talk about the latent variables.",
                    "label": 0
                },
                {
                    "sent": "So that's a Bayesian.",
                    "label": 0
                },
                {
                    "sent": "Well, you can see that as a Bayesian model, although if you don't believe functions of parameters, then this is the problem with this issue about stochastic variables and parameters is controversial.",
                    "label": 0
                },
                {
                    "sent": "To make parameters stochastic variables is not controversial.",
                    "label": 0
                },
                {
                    "sent": "To use Bayes rule, but is a function of parameter or a stochastic variable.",
                    "label": 0
                },
                {
                    "sent": "I don't know if you believe it's a parameter then.",
                    "label": 0
                },
                {
                    "sent": "Then this is controversial, but not to me.",
                    "label": 0
                },
                {
                    "sent": "If you believe it says casting variable, it's not controversial.",
                    "label": 0
                },
                {
                    "sent": "So this is where I have real problems with this worry about, because it sometimes I had a conversation with the frequency statistician once where I explain my model to him and he said no.",
                    "label": 0
                },
                {
                    "sent": "That's fine because you've only put prior distributions over things that are stochastic variables.",
                    "label": 0
                },
                {
                    "sent": "I said oh, but I also put a parameter over that distribution over that prior distribution over that and he said, Oh no, that's Bayesian.",
                    "label": 0
                },
                {
                    "sent": "Then you can't do that.",
                    "label": 0
                },
                {
                    "sent": "And I said, oh, but actually, my data is a population of cells.",
                    "label": 0
                },
                {
                    "sent": "And each of these parameters could be different in each one of the cells.",
                    "label": 0
                },
                {
                    "sent": "Oh, that's OK. Again, you can do that.",
                    "label": 0
                },
                {
                    "sent": "So you know it's easier just to just try and forget about it and actually, except in some sense it was an argument that was true for the Edwardian Englishman.",
                    "label": 0
                },
                {
                    "sent": "It's not an argument that is true for machine learning or cognitive science, where we're not worried about truth.",
                    "label": 0
                },
                {
                    "sent": "Objective truth necessarily worried about doing cool intelligent stuff, then it's a good methodology.",
                    "label": 0
                },
                {
                    "sent": "I'm so.",
                    "label": 0
                },
                {
                    "sent": "This is mixture Gaussians and it can be done, sort of with Bayes rule.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "I'm going to do in society in the way that's not normally written in the textbook, but I think it's the right way because it's the only way you can explicitly see what's going on.",
                    "label": 0
                },
                {
                    "sent": "What I'm going to say is that I've got some data that sampled given a component label, but my component label has this nasty form instead of having a component label as a number one to 10 or something like that, I have these component labels would be so S for any data point to identify the components of the data point, I have a 001000, so I think you called this one of encoding.",
                    "label": 0
                },
                {
                    "sent": "So there's 123456 possible components, and I'm labeling the component I'm using with.",
                    "label": 0
                },
                {
                    "sent": "The one is that coming up, yeah?",
                    "label": 0
                },
                {
                    "sent": "I haven't done this in years, cool.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "That's my for the ice data point.",
                    "label": 0
                },
                {
                    "sent": "That's my assessment of SOS would be a bold S there.",
                    "label": 0
                },
                {
                    "sent": "Now the point about using that is I can use this trick I mentioned earlier.",
                    "label": 0
                },
                {
                    "sent": "The mathematical switch is like if I constrain S to be of this form, only one one in their vector.",
                    "label": 0
                },
                {
                    "sent": "I can basically take a product over this.",
                    "label": 0
                },
                {
                    "sent": "The guy here.",
                    "label": 0
                },
                {
                    "sent": "So here's a bunch of Gaussians.",
                    "label": 0
                },
                {
                    "sent": "Each Gaussian has a different mean and covariance, but only one of these Gaussians actually contributes to the product, because a bunch of them are to the power of 0.",
                    "label": 0
                },
                {
                    "sent": "So they just one, and then I switch on only the one.",
                    "label": 0
                },
                {
                    "sent": "The case one associated with that.",
                    "label": 0
                },
                {
                    "sent": "So basically this is a way of switching between different Gaussians, so the model in a mixture of Gaussians is to have a multinomial prior over this.",
                    "label": 1
                },
                {
                    "sent": "Anna multinomial is just the multivariate generation generalization over binomial.",
                    "label": 0
                },
                {
                    "sent": "It says for each of these.",
                    "label": 0
                },
                {
                    "sent": "For each of these digits here, there's a probability it's on and the probabilities sum to one.",
                    "label": 0
                },
                {
                    "sent": "So I have the multinomial for one sample, so it's really not a multinomial, but it's much cleaner to write down, which is sampling my switch.",
                    "label": 0
                },
                {
                    "sent": "So I sample my switch from this, and each of these switches has a prior problem.",
                    "label": 0
                }
            ]
        },
        "clip_118": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Redistribution what I can do is I can then write down what the marginal likelihood is.",
                    "label": 0
                },
                {
                    "sent": "Now what I want to do here, if I can actually do that some and I can solve that and I can look at the marginal likelihood and I can do gradient descent.",
                    "label": 0
                }
            ]
        },
        "clip_119": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's on the system to find all the parameters.",
                    "label": 0
                },
                {
                    "sent": "Which of these means and covariances of these different Gaussians?",
                    "label": 0
                },
                {
                    "sent": "I've switched on, but I'm not going to do that because.",
                    "label": 0
                }
            ]
        },
        "clip_120": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I want to just mention it.",
                    "label": 0
                }
            ]
        },
        "clip_121": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Damn.",
                    "label": 0
                }
            ]
        },
        "clip_122": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "EM is an algorithm for fitting models of this type.",
                    "label": 0
                },
                {
                    "sent": "It doesn't get you out of intractability.",
                    "label": 0
                },
                {
                    "sent": "Your model has to be tractable, and any model you can treat with them.",
                    "label": 0
                },
                {
                    "sent": "You can also do gradient descent on.",
                    "label": 0
                },
                {
                    "sent": "I think people like EM because it ends up with a bunch of update equations, but it can be horrifically slow, so be careful.",
                    "label": 0
                },
                {
                    "sent": "It's not slow in the mixture of Gaussian case, which is where it's probably most widely used so people can get a misleading impression.",
                    "label": 0
                }
            ]
        },
        "clip_123": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Mixture gaussians.",
                    "label": 0
                },
                {
                    "sent": "So what you do to drive EM is you first introduce a Phantom distribution, which I'm calling Q of S, which is probability distribution over this.",
                    "label": 0
                },
                {
                    "sent": "And then you distribute it over its self.",
                    "label": 0
                }
            ]
        },
        "clip_124": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So it's not affecting anything.",
                    "label": 0
                },
                {
                    "sent": "Then you use something called Jensen's.",
                    "label": 0
                }
            ]
        },
        "clip_125": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Equality, which takes this.",
                    "label": 0
                }
            ]
        },
        "clip_126": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Talk here and puts it inside.",
                    "label": 0
                },
                {
                    "sent": "So I'm going from that to that and then that makes this a bound.",
                    "label": 0
                },
                {
                    "sent": "So Bernard mentioned channels found earlier.",
                    "label": 0
                },
                {
                    "sent": "This is a bound drive from a modified form of Jensen's inequality.",
                    "label": 1
                },
                {
                    "sent": "So what I now have is a lower bound on my log likelihood.",
                    "label": 0
                }
            ]
        },
        "clip_127": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Now the bound becomes equality.",
                    "label": 1
                },
                {
                    "sent": "If I set this distribution to the posterior.",
                    "label": 0
                },
                {
                    "sent": "So the reason is because P of Y is equal to the joint over.",
                    "label": 0
                },
                {
                    "sent": "This is just like the product rule of probability, but with them bringing that guy down here because that's true, that is just P of Y, then the sum over S is just summing up that it normalizes, so it's just one times P of Y log P of Y.",
                    "label": 0
                },
                {
                    "sent": "So basically.",
                    "label": 0
                },
                {
                    "sent": "Then there's inequality.",
                    "label": 0
                }
            ]
        }
    }
}