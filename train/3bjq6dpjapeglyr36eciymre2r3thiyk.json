{
    "id": "3bjq6dpjapeglyr36eciymre2r3thiyk",
    "title": "On the Complexity of A/B Testing",
    "info": {
        "author": [
            "Emilie Kaufmann, Telecom ParisTech"
        ],
        "published": "July 15, 2014",
        "recorded": "June 2014",
        "category": [
            "Top->Computer Science->Machine Learning->On-line Learning",
            "Top->Computer Science->Machine Learning->Unsupervised Learning",
            "Top->Computer Science->Machine Learning->Supervised Learning",
            "Top->Computer Science->Machine Learning->Statistical Learning",
            "Top->Computer Science->Machine Learning->Computational Learning Theory"
        ]
    },
    "url": "http://videolectures.net/colt2014_kaufmann_testing/",
    "segmentation": [
        [
            "Good afternoon I am Emily and I'm going to present a joint work with the Oregon Guardian or difficulty were also in the audience."
        ],
        [
            "So let me start with a simple practical example, say a company want to decide among two version A&B of its website, which one is better in terms of conversion rates, a conversion in just some target event that occurs.",
            "For example buying a product or subscribing to some email list.",
            "So this problem is called AB testing for obvious rhythm and a simple things to do would be for example, to fix a number, say thousands of test user to show the version A to the first half, version B to the second half to see which version at better conversion and decide this is the best page.",
            "So how could we improve this procedure of?",
            "1st Idea would be to allocate the version to be displayed to test user in a more clever and clever ways and just uniformly at random.",
            "Indeed we are going to consider a sequential adaptive allocation rule.",
            "And those are point is that compared to a fixed number of tests, user would it be possible to reduce the number of user needed by randomly stopping and while maintaining the same guarantee?"
        ],
        [
            "So to summarize, we want to improve performance.",
            "Is this kind of procedures so if the number of users is fixed, we want to reduce the probability of error in the recommendation of the right page.",
            "And if the for a fixed probability of here are we want to need more user to detect the right page and so our tool will be to allow for sequential allocation on a sequential are stopping.",
            "So this leads to this problem being cast in the natural framework."
        ],
        [
            "Best sounding notification in two armed bandits."
        ],
        [
            "So that one bandit models is simply a collection of two probability distribution.",
            "So in the previous example, we could imagine that each of the version was associated to an unknown probability distribution, and what we want is to find the one with highest mean.",
            "So a star is the optimal arm, and to find the optimal arms agents can interact with the bandit model by drawing samples.",
            "So at each time at time T is chosen which you choose which 80 want to draw on, observes a sample from the associated distribution.",
            "So in the previous example, so when the user arrives, we observe whether a conversion occurs on that which is a binary random variables which we get consider many other.",
            "Distributions, so then when the agent has seen enough sample of both arms, he decided to stop and is confident enough to make his recommendation.",
            "So we stop according to his stopper stopping rule unchosen Arm 80.",
            "Which you decide is best.",
            "So of course the recommendation rule is quite trivial.",
            "You just recommend the empirical best arm when you stop, but there is a lot of flexibility in the design of good sampling rule and stopping rule.",
            "And in classical Evie testing, so the first idea I presented the sampling Rule 80 was uniform on over 1 two, and the stopping always fixed in advance to some T. So the question is, we ask, is by relaxing these two assumptions could be a could we have improvement in terms of speed or accuracy?",
            "So to quantify the improvement, let me introduce what?",
            "What other classical measure?"
        ],
        [
            "Performance in this problem.",
            "So in the literature of best arm Identification, 2 settings are mostly considered.",
            "The fixed budget setting on the fixed confidence setting.",
            "In the fixed widget setting, the stopping rule is fixed to some tea and we want to minimize the probability of error at time T, denoted by a pit in you.",
            "On the contrary, in the fixed confidence setting, there is some fixed risk parameter Delta, and we want our strategy to have a probability of error bounded by Delta while using as few sample as possible.",
            "So minimizing these are considered called sample complexities.",
            "We expected number of sample use, so like that this setting seems somehow symmetric, but we're going to show that they are not exactly equivalent.",
            "To give you an insight, we consider the special case of algorithm using uniform sampling.",
            "So in this case we can imagine that the sample of the arms are collected as per sample and then we are only in a testing problem.",
            "So we have to test based on this sample between the hypothesis new and larger than you two and one smaller than in the fixed budget setting.",
            "It is a classical test based on the fixed number T of sample and in the fixed confident setting it is a sequential test.",
            "So we have to stop at somewhere random.",
            "Random tight on outputs are I potencies and from testing theory in a more simple case where we know both distribution, it is no need to classic alien statistic from the theory of sequential testing that being sequential can save samples.",
            "So I refer you to the loop by segment sequential analysis where you will be able to see that for example in the Goshen case for a given probability of error, if you do a stack to classical test you will need full time work sample.",
            "Then there's the expected number needed by a sequential list.",
            "No, it won't be true.",
            "So yeah, my point was it's a reason to investigate the link between the two setting and now it won't be true.",
            "And we know that."
        ],
        [
            "The distribution.",
            "So how in order to compare these two settings we introduced in the paper to dedicated notion of complexity in the fixed budget setting.",
            "What we want is consistent algorithm.",
            "So just the probability of error go to zero on every problem in the fixed confident setting we're looking on Delta pack algorithm on which the probability of error is bounded by Delta and our problems.",
            "And of course this program has been studied a lot in the literature and roughly what has been shown in the fixed budget setting is.",
            "That the probability of error is of this order.",
            "So for good algorithm I mean and the expected somewhere complexity in the fixed confident setting in the ease of that order.",
            "So basically there is something called complexity quantity that appears on some constants and the problem is that in the literature in fact the constant do not exactly match and even sometimes the complexity terms are not exactly the same between upper and lower bounds.",
            "So what we define as complexity?",
            "As these two term Kappa beyond capacity and in order to interpret them, seeing that when you want some a probability of error Delta, you will need a Kappa B log when about Delta as a budget.",
            "In the fixed version setting and you will need an expected number of sample of further kapasi log one over Delta in the fixed confident setting.",
            "So the paper is a dedicated to the computation of these two complexities.",
            "So to compute the complexity we need two things lower bounds on the complexity and upper bounds on the probe."
        ],
        [
            "Is your fear are on sample complexity of algorithms that match this lower bound?"
        ],
        [
            "So we start by.",
            "I start by presenting our lower bounds, so for people who know bandits and we've tried to do a lower 1 proof, a key element is changing of distribution.",
            "On the in you know paper we were able to formulate in a very simple way where that their offer short proof this change of distributions that relate.",
            "In fact the probability of some events in two different bandit models to the number of draw of each arms.",
            "And if you are interested, for example, you can recover with the thriller improves the Lion, Robbins lower buttons or regrets with this with this results."
        ],
        [
            "But what we were able to show in the paper with that is that the the two complexity cappabianca pricey are lower bounded by a informational quantity that in fact could be in general difference.",
            "So the quantity of the left is close to what is called a channel information, so so it is a callback library library divergance of some point in the middle of the tour distribution and on the left it is quite similar, but the two marginal are under this.",
            "So we are going to particularize know these lower bounds and try to find matching algorithm in 2D."
        ],
        [
            "So let me start with a simple case, in which, because the callback labeler divergences symmetric, everything goes well.",
            "This is the Goshen case."
        ],
        [
            "So I'm going to consider Goshen bandit models.",
            "So for two fixed value Sigma one and Sigma two of the variances I I so my my under parameters as a mean of each arms and so serum wanna as a nice form for this distribution involving the inverse square gap between the arm and some quantity depending on the variance?",
            "And it is easy to see that strategy were located the sample proportionally to the standard deviation and not to the variances.",
            "Atanes these are this lower bound, so we have computed the complexity of the fix rejected."
        ],
        [
            "The fix confidence setting will be a bit more complicated relatively to algorithm because we have to be a sequential and in fact.",
            "Alright, do is just to maintain the proportion of draw a firearm wonder roughly constant, so this can be achieved by a district.",
            "So the algorithm depends on this target.",
            "Constanta, Alpha, and then so the stopping rule is to stop when the difference of the empirical mean exceed some confidence too.",
            "And in fact the tuning of the confidence to depend on some exploration rate."
        ],
        [
            "And we show that for a choice of exploration rate, which is out of order, lucky divided by Delta and with the constant Alpha being the ratio of the standard deviation, we were able to prove that the sample complexity of Alpha elimination matches zoo lower bound of theorem one.",
            "So in the fixed confidence setting we also were also able to compute the complexity and it turns out that the two complexity are equal."
        ],
        [
            "Moreover, in the special case in which the variances of both armor are equal to some Sigma, it turns out that a uniform sampling is a is optimal and I just mentioned that in the paper we were able to propose a final tuning of the exploracion rates that leads to a quite good improvement in in practice."
        ],
        [
            "So now let's go back to our initial example with barely feedback from the from the user.",
            "It will be a."
        ],
        [
            "Well complicated, so here is a statement of the theorem in this particular case, so just too easy notation.",
            "We will denote just cases we killed by Clara Divergance, so we recover these two information error quantity, but it can be sure from the boundary case they are not equal, so kasap stars is strictly larger than K. Star is strictly larger than K sub star."
        ],
        [
            "So if we are able to provide matching a problem in one of the two setting, we will be able to show that the setting are different and that's what we do.",
            "So algorithm are a bit more complicated, too fine for Bernoulli distribution.",
            "So we first thought about what can we achieve with just uniform sampling in the memory city.",
            "In fact, using exactly the same tools, we are able to, uh, give a lower bound on the probability of error or the sample complexity of algorithm using uniform sampling.",
            "These lower bounds is in this line also features some informational quantities, and in fact these two quantity are very close.",
            "As well as these two quantities.",
            "So somehow if we manage to find algorithm matching this lower bound are so among algorithm using uniform something that we've been not too far from the complexity in the margin rated.",
            "So for the in the fixed budget setting."
        ],
        [
            "These two are actually equality, so more precisely we are.",
            "We can show that the lower one we gave is matched by the simple algorithm that drove both arms uniformly and recommends empirical best.",
            "This lower bound it is a bit more complicated, so I refer you to the paper, but there exists a strategy not very useful in practice that attains this this bound."
        ],
        [
            "So then we have shown with this last matching upper bound letter, the complexity is exactly equal in the fixed budget.",
            "Setting to this invert channel information.",
            "And in practice, we still recommend to use a unit."
        ],
        [
            "From something in this case.",
            "What about the fixed confidence sitting?",
            "So here I simply write the lower bound I gave you in the previous.",
            "Previous a tabular.",
            "So this information that quantity are a sub star will be refused because the first strategy we could think of was just to do the same as in the Goshen case.",
            "That is to decide to stop depending on the difference in empirical means.",
            "So when the empirical mean exceed some threshold, but it can be proved with the tool of the paper, then then the sample complexity is a depends on the inverse square gap, but is strictly larger than.",
            "Horror or complexity, a term here, so we conjecture that a better stopping stopping rule would be to stop, not according to the difference of the empirical mean, but according to the distance relative to this information error quantity.",
            "So we have some elements to support your claim E in the paper.",
            "So too."
        ],
        [
            "You conclude for binary distribution.",
            "So we were able to compute the complexity of the fixed budget setting to show that the complexity of the fixed confidence setting is strictly larger than this quantity and with the inequality I show, this leads to us the complexity of the fixed confident setting being larger than the complexity of the fixed budget city, which seems a bit surprising from our initial guess that it was better to be sequential.",
            "Remember when the distribution are harder."
        ],
        [
            "And to conclude, for good.",
            "So it turns out that the complete the fixed budget and fixed confident setting are not so equivalent, since we can show the two complexity are our difference.",
            "So we also regarding our initial question to improving AB testing procedure.",
            "We show that in fact in some cases there is not much more to gain by departing from uniform sampling.",
            "And that we should not expect strategy using sequential stopping to lead to a saving in terms of sample.",
            "So this last remark is to be a bitter.",
            "Discussed because.",
            "Indeed, the complexity is a bit higher.",
            "Better for a given probability of error in the fixed budget setting.",
            "You will need to know the complexity to know how to adjust your sample size, whereas the sequential rule we still be allowed to learn the complexity, but not with fewer samples than in the fixed budget.",
            "And just as a teaser, because apparently it's a good thing to do.",
            "You can check archive in a few weeks to know more about M best arm identification.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Good afternoon I am Emily and I'm going to present a joint work with the Oregon Guardian or difficulty were also in the audience.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let me start with a simple practical example, say a company want to decide among two version A&B of its website, which one is better in terms of conversion rates, a conversion in just some target event that occurs.",
                    "label": 0
                },
                {
                    "sent": "For example buying a product or subscribing to some email list.",
                    "label": 0
                },
                {
                    "sent": "So this problem is called AB testing for obvious rhythm and a simple things to do would be for example, to fix a number, say thousands of test user to show the version A to the first half, version B to the second half to see which version at better conversion and decide this is the best page.",
                    "label": 0
                },
                {
                    "sent": "So how could we improve this procedure of?",
                    "label": 0
                },
                {
                    "sent": "1st Idea would be to allocate the version to be displayed to test user in a more clever and clever ways and just uniformly at random.",
                    "label": 0
                },
                {
                    "sent": "Indeed we are going to consider a sequential adaptive allocation rule.",
                    "label": 0
                },
                {
                    "sent": "And those are point is that compared to a fixed number of tests, user would it be possible to reduce the number of user needed by randomly stopping and while maintaining the same guarantee?",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to summarize, we want to improve performance.",
                    "label": 1
                },
                {
                    "sent": "Is this kind of procedures so if the number of users is fixed, we want to reduce the probability of error in the recommendation of the right page.",
                    "label": 1
                },
                {
                    "sent": "And if the for a fixed probability of here are we want to need more user to detect the right page and so our tool will be to allow for sequential allocation on a sequential are stopping.",
                    "label": 0
                },
                {
                    "sent": "So this leads to this problem being cast in the natural framework.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Best sounding notification in two armed bandits.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So that one bandit models is simply a collection of two probability distribution.",
                    "label": 1
                },
                {
                    "sent": "So in the previous example, we could imagine that each of the version was associated to an unknown probability distribution, and what we want is to find the one with highest mean.",
                    "label": 0
                },
                {
                    "sent": "So a star is the optimal arm, and to find the optimal arms agents can interact with the bandit model by drawing samples.",
                    "label": 1
                },
                {
                    "sent": "So at each time at time T is chosen which you choose which 80 want to draw on, observes a sample from the associated distribution.",
                    "label": 1
                },
                {
                    "sent": "So in the previous example, so when the user arrives, we observe whether a conversion occurs on that which is a binary random variables which we get consider many other.",
                    "label": 1
                },
                {
                    "sent": "Distributions, so then when the agent has seen enough sample of both arms, he decided to stop and is confident enough to make his recommendation.",
                    "label": 0
                },
                {
                    "sent": "So we stop according to his stopper stopping rule unchosen Arm 80.",
                    "label": 0
                },
                {
                    "sent": "Which you decide is best.",
                    "label": 1
                },
                {
                    "sent": "So of course the recommendation rule is quite trivial.",
                    "label": 0
                },
                {
                    "sent": "You just recommend the empirical best arm when you stop, but there is a lot of flexibility in the design of good sampling rule and stopping rule.",
                    "label": 0
                },
                {
                    "sent": "And in classical Evie testing, so the first idea I presented the sampling Rule 80 was uniform on over 1 two, and the stopping always fixed in advance to some T. So the question is, we ask, is by relaxing these two assumptions could be a could we have improvement in terms of speed or accuracy?",
                    "label": 1
                },
                {
                    "sent": "So to quantify the improvement, let me introduce what?",
                    "label": 0
                },
                {
                    "sent": "What other classical measure?",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Performance in this problem.",
                    "label": 0
                },
                {
                    "sent": "So in the literature of best arm Identification, 2 settings are mostly considered.",
                    "label": 1
                },
                {
                    "sent": "The fixed budget setting on the fixed confidence setting.",
                    "label": 0
                },
                {
                    "sent": "In the fixed widget setting, the stopping rule is fixed to some tea and we want to minimize the probability of error at time T, denoted by a pit in you.",
                    "label": 0
                },
                {
                    "sent": "On the contrary, in the fixed confidence setting, there is some fixed risk parameter Delta, and we want our strategy to have a probability of error bounded by Delta while using as few sample as possible.",
                    "label": 1
                },
                {
                    "sent": "So minimizing these are considered called sample complexities.",
                    "label": 0
                },
                {
                    "sent": "We expected number of sample use, so like that this setting seems somehow symmetric, but we're going to show that they are not exactly equivalent.",
                    "label": 0
                },
                {
                    "sent": "To give you an insight, we consider the special case of algorithm using uniform sampling.",
                    "label": 1
                },
                {
                    "sent": "So in this case we can imagine that the sample of the arms are collected as per sample and then we are only in a testing problem.",
                    "label": 0
                },
                {
                    "sent": "So we have to test based on this sample between the hypothesis new and larger than you two and one smaller than in the fixed budget setting.",
                    "label": 0
                },
                {
                    "sent": "It is a classical test based on the fixed number T of sample and in the fixed confident setting it is a sequential test.",
                    "label": 1
                },
                {
                    "sent": "So we have to stop at somewhere random.",
                    "label": 0
                },
                {
                    "sent": "Random tight on outputs are I potencies and from testing theory in a more simple case where we know both distribution, it is no need to classic alien statistic from the theory of sequential testing that being sequential can save samples.",
                    "label": 0
                },
                {
                    "sent": "So I refer you to the loop by segment sequential analysis where you will be able to see that for example in the Goshen case for a given probability of error, if you do a stack to classical test you will need full time work sample.",
                    "label": 0
                },
                {
                    "sent": "Then there's the expected number needed by a sequential list.",
                    "label": 0
                },
                {
                    "sent": "No, it won't be true.",
                    "label": 0
                },
                {
                    "sent": "So yeah, my point was it's a reason to investigate the link between the two setting and now it won't be true.",
                    "label": 0
                },
                {
                    "sent": "And we know that.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The distribution.",
                    "label": 0
                },
                {
                    "sent": "So how in order to compare these two settings we introduced in the paper to dedicated notion of complexity in the fixed budget setting.",
                    "label": 0
                },
                {
                    "sent": "What we want is consistent algorithm.",
                    "label": 0
                },
                {
                    "sent": "So just the probability of error go to zero on every problem in the fixed confident setting we're looking on Delta pack algorithm on which the probability of error is bounded by Delta and our problems.",
                    "label": 1
                },
                {
                    "sent": "And of course this program has been studied a lot in the literature and roughly what has been shown in the fixed budget setting is.",
                    "label": 0
                },
                {
                    "sent": "That the probability of error is of this order.",
                    "label": 0
                },
                {
                    "sent": "So for good algorithm I mean and the expected somewhere complexity in the fixed confident setting in the ease of that order.",
                    "label": 0
                },
                {
                    "sent": "So basically there is something called complexity quantity that appears on some constants and the problem is that in the literature in fact the constant do not exactly match and even sometimes the complexity terms are not exactly the same between upper and lower bounds.",
                    "label": 0
                },
                {
                    "sent": "So what we define as complexity?",
                    "label": 0
                },
                {
                    "sent": "As these two term Kappa beyond capacity and in order to interpret them, seeing that when you want some a probability of error Delta, you will need a Kappa B log when about Delta as a budget.",
                    "label": 0
                },
                {
                    "sent": "In the fixed version setting and you will need an expected number of sample of further kapasi log one over Delta in the fixed confident setting.",
                    "label": 1
                },
                {
                    "sent": "So the paper is a dedicated to the computation of these two complexities.",
                    "label": 1
                },
                {
                    "sent": "So to compute the complexity we need two things lower bounds on the complexity and upper bounds on the probe.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is your fear are on sample complexity of algorithms that match this lower bound?",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we start by.",
                    "label": 0
                },
                {
                    "sent": "I start by presenting our lower bounds, so for people who know bandits and we've tried to do a lower 1 proof, a key element is changing of distribution.",
                    "label": 1
                },
                {
                    "sent": "On the in you know paper we were able to formulate in a very simple way where that their offer short proof this change of distributions that relate.",
                    "label": 1
                },
                {
                    "sent": "In fact the probability of some events in two different bandit models to the number of draw of each arms.",
                    "label": 1
                },
                {
                    "sent": "And if you are interested, for example, you can recover with the thriller improves the Lion, Robbins lower buttons or regrets with this with this results.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But what we were able to show in the paper with that is that the the two complexity cappabianca pricey are lower bounded by a informational quantity that in fact could be in general difference.",
                    "label": 0
                },
                {
                    "sent": "So the quantity of the left is close to what is called a channel information, so so it is a callback library library divergance of some point in the middle of the tour distribution and on the left it is quite similar, but the two marginal are under this.",
                    "label": 0
                },
                {
                    "sent": "So we are going to particularize know these lower bounds and try to find matching algorithm in 2D.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So let me start with a simple case, in which, because the callback labeler divergences symmetric, everything goes well.",
                    "label": 0
                },
                {
                    "sent": "This is the Goshen case.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I'm going to consider Goshen bandit models.",
                    "label": 0
                },
                {
                    "sent": "So for two fixed value Sigma one and Sigma two of the variances I I so my my under parameters as a mean of each arms and so serum wanna as a nice form for this distribution involving the inverse square gap between the arm and some quantity depending on the variance?",
                    "label": 0
                },
                {
                    "sent": "And it is easy to see that strategy were located the sample proportionally to the standard deviation and not to the variances.",
                    "label": 0
                },
                {
                    "sent": "Atanes these are this lower bound, so we have computed the complexity of the fix rejected.",
                    "label": 1
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The fix confidence setting will be a bit more complicated relatively to algorithm because we have to be a sequential and in fact.",
                    "label": 0
                },
                {
                    "sent": "Alright, do is just to maintain the proportion of draw a firearm wonder roughly constant, so this can be achieved by a district.",
                    "label": 0
                },
                {
                    "sent": "So the algorithm depends on this target.",
                    "label": 0
                },
                {
                    "sent": "Constanta, Alpha, and then so the stopping rule is to stop when the difference of the empirical mean exceed some confidence too.",
                    "label": 0
                },
                {
                    "sent": "And in fact the tuning of the confidence to depend on some exploration rate.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we show that for a choice of exploration rate, which is out of order, lucky divided by Delta and with the constant Alpha being the ratio of the standard deviation, we were able to prove that the sample complexity of Alpha elimination matches zoo lower bound of theorem one.",
                    "label": 0
                },
                {
                    "sent": "So in the fixed confidence setting we also were also able to compute the complexity and it turns out that the two complexity are equal.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Moreover, in the special case in which the variances of both armor are equal to some Sigma, it turns out that a uniform sampling is a is optimal and I just mentioned that in the paper we were able to propose a final tuning of the exploracion rates that leads to a quite good improvement in in practice.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now let's go back to our initial example with barely feedback from the from the user.",
                    "label": 0
                },
                {
                    "sent": "It will be a.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well complicated, so here is a statement of the theorem in this particular case, so just too easy notation.",
                    "label": 0
                },
                {
                    "sent": "We will denote just cases we killed by Clara Divergance, so we recover these two information error quantity, but it can be sure from the boundary case they are not equal, so kasap stars is strictly larger than K. Star is strictly larger than K sub star.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So if we are able to provide matching a problem in one of the two setting, we will be able to show that the setting are different and that's what we do.",
                    "label": 0
                },
                {
                    "sent": "So algorithm are a bit more complicated, too fine for Bernoulli distribution.",
                    "label": 0
                },
                {
                    "sent": "So we first thought about what can we achieve with just uniform sampling in the memory city.",
                    "label": 1
                },
                {
                    "sent": "In fact, using exactly the same tools, we are able to, uh, give a lower bound on the probability of error or the sample complexity of algorithm using uniform sampling.",
                    "label": 1
                },
                {
                    "sent": "These lower bounds is in this line also features some informational quantities, and in fact these two quantity are very close.",
                    "label": 0
                },
                {
                    "sent": "As well as these two quantities.",
                    "label": 0
                },
                {
                    "sent": "So somehow if we manage to find algorithm matching this lower bound are so among algorithm using uniform something that we've been not too far from the complexity in the margin rated.",
                    "label": 0
                },
                {
                    "sent": "So for the in the fixed budget setting.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "These two are actually equality, so more precisely we are.",
                    "label": 0
                },
                {
                    "sent": "We can show that the lower one we gave is matched by the simple algorithm that drove both arms uniformly and recommends empirical best.",
                    "label": 0
                },
                {
                    "sent": "This lower bound it is a bit more complicated, so I refer you to the paper, but there exists a strategy not very useful in practice that attains this this bound.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So then we have shown with this last matching upper bound letter, the complexity is exactly equal in the fixed budget.",
                    "label": 0
                },
                {
                    "sent": "Setting to this invert channel information.",
                    "label": 0
                },
                {
                    "sent": "And in practice, we still recommend to use a unit.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "From something in this case.",
                    "label": 0
                },
                {
                    "sent": "What about the fixed confidence sitting?",
                    "label": 0
                },
                {
                    "sent": "So here I simply write the lower bound I gave you in the previous.",
                    "label": 0
                },
                {
                    "sent": "Previous a tabular.",
                    "label": 0
                },
                {
                    "sent": "So this information that quantity are a sub star will be refused because the first strategy we could think of was just to do the same as in the Goshen case.",
                    "label": 0
                },
                {
                    "sent": "That is to decide to stop depending on the difference in empirical means.",
                    "label": 1
                },
                {
                    "sent": "So when the empirical mean exceed some threshold, but it can be proved with the tool of the paper, then then the sample complexity is a depends on the inverse square gap, but is strictly larger than.",
                    "label": 0
                },
                {
                    "sent": "Horror or complexity, a term here, so we conjecture that a better stopping stopping rule would be to stop, not according to the difference of the empirical mean, but according to the distance relative to this information error quantity.",
                    "label": 1
                },
                {
                    "sent": "So we have some elements to support your claim E in the paper.",
                    "label": 0
                },
                {
                    "sent": "So too.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You conclude for binary distribution.",
                    "label": 0
                },
                {
                    "sent": "So we were able to compute the complexity of the fixed budget setting to show that the complexity of the fixed confidence setting is strictly larger than this quantity and with the inequality I show, this leads to us the complexity of the fixed confident setting being larger than the complexity of the fixed budget city, which seems a bit surprising from our initial guess that it was better to be sequential.",
                    "label": 1
                },
                {
                    "sent": "Remember when the distribution are harder.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And to conclude, for good.",
                    "label": 0
                },
                {
                    "sent": "So it turns out that the complete the fixed budget and fixed confident setting are not so equivalent, since we can show the two complexity are our difference.",
                    "label": 0
                },
                {
                    "sent": "So we also regarding our initial question to improving AB testing procedure.",
                    "label": 1
                },
                {
                    "sent": "We show that in fact in some cases there is not much more to gain by departing from uniform sampling.",
                    "label": 0
                },
                {
                    "sent": "And that we should not expect strategy using sequential stopping to lead to a saving in terms of sample.",
                    "label": 1
                },
                {
                    "sent": "So this last remark is to be a bitter.",
                    "label": 0
                },
                {
                    "sent": "Discussed because.",
                    "label": 1
                },
                {
                    "sent": "Indeed, the complexity is a bit higher.",
                    "label": 0
                },
                {
                    "sent": "Better for a given probability of error in the fixed budget setting.",
                    "label": 0
                },
                {
                    "sent": "You will need to know the complexity to know how to adjust your sample size, whereas the sequential rule we still be allowed to learn the complexity, but not with fewer samples than in the fixed budget.",
                    "label": 0
                },
                {
                    "sent": "And just as a teaser, because apparently it's a good thing to do.",
                    "label": 0
                },
                {
                    "sent": "You can check archive in a few weeks to know more about M best arm identification.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}