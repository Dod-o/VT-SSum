{
    "id": "ydpqrln3iellghle2rxtuszbavcloy4h",
    "title": "Entity Disambiguation using Relations extracted from Wikipedia",
    "info": {
        "author": [
            "Anja Pilz, Fraunhofer IAIS"
        ],
        "published": "June 7, 2010",
        "recorded": "May 2010",
        "category": [
            "Top->Computer Science->Information Extraction",
            "Top->Computer Science->Web Search",
            "Top->Computer Science->Web Mining",
            "Top->Computer Science->Data Mining"
        ]
    },
    "url": "http://videolectures.net/akbc2010_pilz_edrw/",
    "segmentation": [
        [
            "Hi my name is Anya puts.",
            "I'm grateful to be here.",
            "I'm going to present you some part of my master season Circum PhD.",
            "The users, which is it's my Senate Masters.",
            "He's actually and I'm doing this at farm for Institute of."
        ],
        [
            "For intelligent analysis systems in class, building our scene.",
            "And first of all, I'd like to tell you something about background of my work, which is a new project called Thesis.",
            "I don't know if you anybody knows a few knows about it, but it's a fairly large project and I work on the use case which is contentless and basically our goal is to build a system that is able to perform semantic search on digital libraries and the problem in this case is that these digital libraries libraries contain very different document types.",
            "These are newspaper articles, OCR products but also audio transcripts from news broadcasts.",
            "Basically all in German.",
            "Which is the restriction of my work that is not applied to English but to German.",
            "The goal of this is to, uh, enable people working on archive to search for.",
            "Specific mentions of specific entities in natural language texts.",
            "An first step is then to perform named entity recognition or to detect name phrases mentioning entities or some name in an arbitrary text which is.",
            "Shown.",
            "Above the lower part and then map these mentions to some knowledge base and my case is German National Library which is provide some structure containing dates of birth dates of death.",
            "If already happens and some lists of publications, but the problem is that."
        ],
        [
            "This knowledge base does not contain information that is likely to be found in newspaper articles, so most articles do not mention the publications of an entity or the date of birth of the date of death.",
            "So we take Wikipedia as an intermediate step for entity disambiguation.",
            "Since nobody in Wikipedia have a higher coverage or higher much more content for each entity.",
            "So in my case.",
            "Readesign relation means linking.",
            "We keep texture mentions of name phrases to unique Wikipedia entities.",
            "So for example given we have, we are given three Curie contexts.",
            "I apologize for it being in German, but where's the case?",
            "Um?",
            "And we want to link these this context to some entities in Wikipedia.",
            "So first give me a.",
            "We have some magic Anuar system for German, which is already difficult enough.",
            "We try to select candidates in Wikipedia at the moment is are these include only persons or organizations or locations or entities.",
            "That's where the name matches exactly, but in general it's not difficult to construct a much larger candidate set using Wikipedia.",
            "Direct pages or the simulation pages or something else?",
            "So.",
            "I took in a snapshot of the five mission for machine models that are contained to Wikipedia, the first 2A2 politicians for the same party, and this one is a comedian rather famous Germany but an.",
            "And a handful player.",
            "And the last one is someone we don't know about, which is one of those 3000 entities with the name machine model that is not contained in Wikipedia, but a person.",
            "Nevertheless, right?",
            "So if we want to assign Entity mentions to some.",
            "Entertain Wikipedia, we have to keep in mind that there are 3000 entities not contained, and we do not want to brute force link them to some entity in Wikipedia.",
            "So basically this would be and not politically correct, right?",
            "So doing so, we have to keep in mind that Wikipedia is basically my only knowledge resource that I have and we have to distinguish or I have to do exist English between two or more free and."
        ],
        [
            "It is solely based on a Wikipedia articles.",
            "So let's take a look what we have in German.",
            "This is an article on the comedian Michelle Mueller as you see this.",
            "It seems rather long, but if you compare to the article of Angelina Jolie or he would call or Nicolas Sarkozy OK, something like this, which is who is really a celebrity in some way, you will see that it's rather short, so we have to deal with the great variety and the wealth of detail, but generally we can assume that the most important facts.",
            "We can hope that the most important facts are mentioned in this art in these articles.",
            "So we can assume that a simple cosine similarity measure, which is basically the weighted sum of terms that appear both in the Curie document and the article document, is already sufficient enough to select the most likely entity.",
            "We experimented with this and it's showed rather good results, but, well, I'm not sufficient.",
            "I'm going to tell something more about it later.",
            "Another approach was from 2006 from Bunescu and Pascha.",
            "They build a taxonomie based kernel using Wikipedia as category structure, but well, this works very well for English and very well for many many entities.",
            "But as you see here, we have only four entities and may translate them to you.",
            "It's comedian German man in born in 1958.",
            "So how many entities does this apply, right only?",
            "Descriptive or distinguishing category is occupation with this comedian and then we have a.",
            "A distinctive set only if you add comedian.",
            "So apart from these very small set of categories that can we also be very large set of categories that apply contain categories.",
            "Applying these two entities which is also fairly common in the German version of Wikipedia.",
            "So to smooth these category sets or this category based approach a little bit we used last year topic models instead of categories where we build some probability distribution over like 200 or 300 topics.",
            "It is much smoother than a category based approach, but it does work pretty well, but unfortunately we encountered scaling issues and try to for a different approach.",
            "Which is now."
        ],
        [
            "How the link structure of Wikipedia?",
            "So assuming that each entity can be defined somehow by the entities he or she knows well, then we can also try to model this using Wikipedia as link structure.",
            "A direct approach using relations as mentioned in the relation extraction natural literature is not possible or is not easy for German, since there's no relation extraction module with high accuracy.",
            "So we use links that the links at an article has to other articles as candidates for relations.",
            "We can see that the this handball player has a very different set of relations between the comedian he is related to two claps and the German Handball, Bundesliga and also to his brother who is also in football player.",
            "On the other hand, we have this comedian who is related to the theater.",
            "He appeared and it is hosted spring Marzan Bond which is really nice and you should visit but just checking and to be.",
            "TV show is appears in which is called Switch.",
            "So, assuming that this is a clever approach, we should think about."
        ],
        [
            "How to choose relevant links.",
            "You might know that you might know that."
        ],
        [
            "Each entity is also linked as also links to the date of birth and the year of birth."
        ],
        [
            "Which are not descriptive links.",
            "There are thousands of other entities.",
            "Share these links and we do not want to put too much weight on these.",
            "Instead we want to put more weight or more higher agreement measure to entities that have many common links with the entity of current interests.",
            "Since we can assume that these are topically related and.",
            "Much likelier to be descriptive for the entity, but general attributes such as the city of Roots work that has basically no relation to to machine Miller.",
            "If apart if you, if you would have been the area to major or something like this, then it would be the case, but in this case node.",
            "So."
        ],
        [
            "I used an SVM approach for an eye model.",
            "This is a classification problem and descriptive feature vectors are to be built.",
            "That represent the matching of Ecurie document and the entities article and we first use the binary words link pair, which is basically the correlation between common words as words appearing.",
            "Instances yeah, now if you have one Curie and you have 5 for five to six candidates and one candidate is true.",
            "So your classify each candidate Curie pair as being positive or negative.",
            "Um?",
            "Yeah, and these are bit but well, some of multiplying common words and link pairs and links.",
            "And the first approach is to use this as an A binary representation and the second in a weighted representation which is somehow related."
        ],
        [
            "Through this approach, short here, which puts additional weight to the."
        ],
        [
            "To the likeliness of two articles and this way basically states that two entities to Artix agree if their set of common links is large compared to the set of their overall to the overall size of the set of our trainings.",
            "Novel aspect, some factor, like the Or's number of links in Wikipedia.",
            "So the classification pairwise classification is.",
            "This mention mention of that entity.",
            "So an so I wasn't sure if that 'cause you will comment in the previous slide talking about this.",
            "Weather, which links is going to take into consideration?",
            "Yeah, as features.",
            "Only as features for it would be the same as if I had a selection of categories and I want to put additional way to categories as features.",
            "Um?",
            "So how how much time do I have left?",
            "Well, OK, then let's go choosing experimentation.",
            "Well, OK, I did a 5 fold cross validation on a dissimulated example set for 8155 queries, and these curious was selected by considering names or entities having a very common German surnames, vodka, normal, wet.",
            "Basically the top 7.",
            "And.",
            "We require that these entities have ambiguous name, so this was added basically in and set where each entity has an average or each mention as an average 44 point something candidate."
        ],
        [
            "And hence, the baseline accuracy is 25%.",
            "So to be fair, I compared my approach to the words category based work category pairs from UNESCO.",
            "It's a slightly altered version, but basically the idea is the same and we have to see that the performance where basically in micro it's in my performance as much I have, but we shouldn't be bothered by this.",
            "But both the DDD, the binary word categories work.",
            "Can you repairs and you waited?",
            "Word link pairs perform equally well.",
            "Very well, but with no significant significant difference.",
            "Where is the binary world link pairs.",
            "Not very much.",
            "Um?",
            "Why I'm not so good, right and?",
            "The take home message is set even though these set of categories is much more elaborated and has much more thinking behind it.",
            "We can deduce from a set that it's much more noisy, meaning the set of links an equally relevant, equally distinguished and set of features using some, maybe some more sophisticated wait.",
            "Which brings me to the last slide, which is my eye."
        ],
        [
            "Outlook.",
            "And.",
            "On going from this work here, I well first thing I would like to have is a true relation extraction algorithm performing well for German.",
            "But since I cannot hope to have these.",
            "In the next three years or so.",
            "I have to find some Clarivate or some more sophisticated ways to find to model real relations from links.",
            "So one basic approach would be to use some small topic model which only compute some quick library events between the candidates are between one another and then we would gain a really topically difference.",
            "Yeah, divergance between the two of them.",
            "Additionally, we should take into account that maybe Wikipedia users are somewhat.",
            "Make false and that link detection method methods could be used to find Additionally or more relevant links.",
            "And the long term goal is to combine these things.",
            "These topical information is relational information into one larger model, and this could be compared then in a generative approach.",
            "So this can approach using some kernel methods as I'm craft kernel methods or so.",
            "Well then."
        ],
        [
            "Thank you, anybody questions?",
            "Can you make some comments about the kind of errors that.",
            "When you look at the errors.",
            "The problem is that the errors are.",
            "That mostly the context that I extract from Wikipedia and not very descriptive.",
            "So first of all, to it it would be the nicest thing to have.",
            "Would be a December created, manually annotated sets of documents, but well, not yet.",
            "There is not and.",
            "Mainly those Contacts have received false links that are bad quality, so.",
            "Best quality also includes that it is a synonym.",
            "Miss went many synonyms for words appearing in the article, but not only you can't match time using some simple cosine similarity, but you could match them using word net information or so, or grammar net in my case.",
            "Performance.",
            "It was about a 62% F measure both on micro and macro in that version, but it has a very high variance.",
            "So it truly depends on it works well for some context, and it works very bad for other countries.",
            "Information you consider how it didn't like.",
            "Category.",
            "Where does the problem that you?",
            "Probably won't overcome, since entities with a sparse category information have short articles, have few links are not very representative.",
            "You won't find many examples for them, but.",
            "But maybe they should receive some attention as well.",
            "So."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hi my name is Anya puts.",
                    "label": 0
                },
                {
                    "sent": "I'm grateful to be here.",
                    "label": 0
                },
                {
                    "sent": "I'm going to present you some part of my master season Circum PhD.",
                    "label": 0
                },
                {
                    "sent": "The users, which is it's my Senate Masters.",
                    "label": 0
                },
                {
                    "sent": "He's actually and I'm doing this at farm for Institute of.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For intelligent analysis systems in class, building our scene.",
                    "label": 0
                },
                {
                    "sent": "And first of all, I'd like to tell you something about background of my work, which is a new project called Thesis.",
                    "label": 0
                },
                {
                    "sent": "I don't know if you anybody knows a few knows about it, but it's a fairly large project and I work on the use case which is contentless and basically our goal is to build a system that is able to perform semantic search on digital libraries and the problem in this case is that these digital libraries libraries contain very different document types.",
                    "label": 0
                },
                {
                    "sent": "These are newspaper articles, OCR products but also audio transcripts from news broadcasts.",
                    "label": 1
                },
                {
                    "sent": "Basically all in German.",
                    "label": 0
                },
                {
                    "sent": "Which is the restriction of my work that is not applied to English but to German.",
                    "label": 1
                },
                {
                    "sent": "The goal of this is to, uh, enable people working on archive to search for.",
                    "label": 1
                },
                {
                    "sent": "Specific mentions of specific entities in natural language texts.",
                    "label": 0
                },
                {
                    "sent": "An first step is then to perform named entity recognition or to detect name phrases mentioning entities or some name in an arbitrary text which is.",
                    "label": 0
                },
                {
                    "sent": "Shown.",
                    "label": 0
                },
                {
                    "sent": "Above the lower part and then map these mentions to some knowledge base and my case is German National Library which is provide some structure containing dates of birth dates of death.",
                    "label": 0
                },
                {
                    "sent": "If already happens and some lists of publications, but the problem is that.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This knowledge base does not contain information that is likely to be found in newspaper articles, so most articles do not mention the publications of an entity or the date of birth of the date of death.",
                    "label": 1
                },
                {
                    "sent": "So we take Wikipedia as an intermediate step for entity disambiguation.",
                    "label": 0
                },
                {
                    "sent": "Since nobody in Wikipedia have a higher coverage or higher much more content for each entity.",
                    "label": 0
                },
                {
                    "sent": "So in my case.",
                    "label": 0
                },
                {
                    "sent": "Readesign relation means linking.",
                    "label": 0
                },
                {
                    "sent": "We keep texture mentions of name phrases to unique Wikipedia entities.",
                    "label": 1
                },
                {
                    "sent": "So for example given we have, we are given three Curie contexts.",
                    "label": 0
                },
                {
                    "sent": "I apologize for it being in German, but where's the case?",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "And we want to link these this context to some entities in Wikipedia.",
                    "label": 0
                },
                {
                    "sent": "So first give me a.",
                    "label": 0
                },
                {
                    "sent": "We have some magic Anuar system for German, which is already difficult enough.",
                    "label": 0
                },
                {
                    "sent": "We try to select candidates in Wikipedia at the moment is are these include only persons or organizations or locations or entities.",
                    "label": 0
                },
                {
                    "sent": "That's where the name matches exactly, but in general it's not difficult to construct a much larger candidate set using Wikipedia.",
                    "label": 0
                },
                {
                    "sent": "Direct pages or the simulation pages or something else?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "I took in a snapshot of the five mission for machine models that are contained to Wikipedia, the first 2A2 politicians for the same party, and this one is a comedian rather famous Germany but an.",
                    "label": 0
                },
                {
                    "sent": "And a handful player.",
                    "label": 0
                },
                {
                    "sent": "And the last one is someone we don't know about, which is one of those 3000 entities with the name machine model that is not contained in Wikipedia, but a person.",
                    "label": 0
                },
                {
                    "sent": "Nevertheless, right?",
                    "label": 0
                },
                {
                    "sent": "So if we want to assign Entity mentions to some.",
                    "label": 0
                },
                {
                    "sent": "Entertain Wikipedia, we have to keep in mind that there are 3000 entities not contained, and we do not want to brute force link them to some entity in Wikipedia.",
                    "label": 0
                },
                {
                    "sent": "So basically this would be and not politically correct, right?",
                    "label": 0
                },
                {
                    "sent": "So doing so, we have to keep in mind that Wikipedia is basically my only knowledge resource that I have and we have to distinguish or I have to do exist English between two or more free and.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "It is solely based on a Wikipedia articles.",
                    "label": 1
                },
                {
                    "sent": "So let's take a look what we have in German.",
                    "label": 0
                },
                {
                    "sent": "This is an article on the comedian Michelle Mueller as you see this.",
                    "label": 0
                },
                {
                    "sent": "It seems rather long, but if you compare to the article of Angelina Jolie or he would call or Nicolas Sarkozy OK, something like this, which is who is really a celebrity in some way, you will see that it's rather short, so we have to deal with the great variety and the wealth of detail, but generally we can assume that the most important facts.",
                    "label": 1
                },
                {
                    "sent": "We can hope that the most important facts are mentioned in this art in these articles.",
                    "label": 0
                },
                {
                    "sent": "So we can assume that a simple cosine similarity measure, which is basically the weighted sum of terms that appear both in the Curie document and the article document, is already sufficient enough to select the most likely entity.",
                    "label": 0
                },
                {
                    "sent": "We experimented with this and it's showed rather good results, but, well, I'm not sufficient.",
                    "label": 0
                },
                {
                    "sent": "I'm going to tell something more about it later.",
                    "label": 0
                },
                {
                    "sent": "Another approach was from 2006 from Bunescu and Pascha.",
                    "label": 0
                },
                {
                    "sent": "They build a taxonomie based kernel using Wikipedia as category structure, but well, this works very well for English and very well for many many entities.",
                    "label": 0
                },
                {
                    "sent": "But as you see here, we have only four entities and may translate them to you.",
                    "label": 0
                },
                {
                    "sent": "It's comedian German man in born in 1958.",
                    "label": 0
                },
                {
                    "sent": "So how many entities does this apply, right only?",
                    "label": 0
                },
                {
                    "sent": "Descriptive or distinguishing category is occupation with this comedian and then we have a.",
                    "label": 1
                },
                {
                    "sent": "A distinctive set only if you add comedian.",
                    "label": 0
                },
                {
                    "sent": "So apart from these very small set of categories that can we also be very large set of categories that apply contain categories.",
                    "label": 0
                },
                {
                    "sent": "Applying these two entities which is also fairly common in the German version of Wikipedia.",
                    "label": 0
                },
                {
                    "sent": "So to smooth these category sets or this category based approach a little bit we used last year topic models instead of categories where we build some probability distribution over like 200 or 300 topics.",
                    "label": 0
                },
                {
                    "sent": "It is much smoother than a category based approach, but it does work pretty well, but unfortunately we encountered scaling issues and try to for a different approach.",
                    "label": 0
                },
                {
                    "sent": "Which is now.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "How the link structure of Wikipedia?",
                    "label": 0
                },
                {
                    "sent": "So assuming that each entity can be defined somehow by the entities he or she knows well, then we can also try to model this using Wikipedia as link structure.",
                    "label": 0
                },
                {
                    "sent": "A direct approach using relations as mentioned in the relation extraction natural literature is not possible or is not easy for German, since there's no relation extraction module with high accuracy.",
                    "label": 0
                },
                {
                    "sent": "So we use links that the links at an article has to other articles as candidates for relations.",
                    "label": 1
                },
                {
                    "sent": "We can see that the this handball player has a very different set of relations between the comedian he is related to two claps and the German Handball, Bundesliga and also to his brother who is also in football player.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, we have this comedian who is related to the theater.",
                    "label": 0
                },
                {
                    "sent": "He appeared and it is hosted spring Marzan Bond which is really nice and you should visit but just checking and to be.",
                    "label": 0
                },
                {
                    "sent": "TV show is appears in which is called Switch.",
                    "label": 0
                },
                {
                    "sent": "So, assuming that this is a clever approach, we should think about.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "How to choose relevant links.",
                    "label": 0
                },
                {
                    "sent": "You might know that you might know that.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Each entity is also linked as also links to the date of birth and the year of birth.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which are not descriptive links.",
                    "label": 0
                },
                {
                    "sent": "There are thousands of other entities.",
                    "label": 0
                },
                {
                    "sent": "Share these links and we do not want to put too much weight on these.",
                    "label": 0
                },
                {
                    "sent": "Instead we want to put more weight or more higher agreement measure to entities that have many common links with the entity of current interests.",
                    "label": 0
                },
                {
                    "sent": "Since we can assume that these are topically related and.",
                    "label": 0
                },
                {
                    "sent": "Much likelier to be descriptive for the entity, but general attributes such as the city of Roots work that has basically no relation to to machine Miller.",
                    "label": 0
                },
                {
                    "sent": "If apart if you, if you would have been the area to major or something like this, then it would be the case, but in this case node.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I used an SVM approach for an eye model.",
                    "label": 0
                },
                {
                    "sent": "This is a classification problem and descriptive feature vectors are to be built.",
                    "label": 0
                },
                {
                    "sent": "That represent the matching of Ecurie document and the entities article and we first use the binary words link pair, which is basically the correlation between common words as words appearing.",
                    "label": 0
                },
                {
                    "sent": "Instances yeah, now if you have one Curie and you have 5 for five to six candidates and one candidate is true.",
                    "label": 0
                },
                {
                    "sent": "So your classify each candidate Curie pair as being positive or negative.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Yeah, and these are bit but well, some of multiplying common words and link pairs and links.",
                    "label": 0
                },
                {
                    "sent": "And the first approach is to use this as an A binary representation and the second in a weighted representation which is somehow related.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Through this approach, short here, which puts additional weight to the.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To the likeliness of two articles and this way basically states that two entities to Artix agree if their set of common links is large compared to the set of their overall to the overall size of the set of our trainings.",
                    "label": 0
                },
                {
                    "sent": "Novel aspect, some factor, like the Or's number of links in Wikipedia.",
                    "label": 0
                },
                {
                    "sent": "So the classification pairwise classification is.",
                    "label": 0
                },
                {
                    "sent": "This mention mention of that entity.",
                    "label": 0
                },
                {
                    "sent": "So an so I wasn't sure if that 'cause you will comment in the previous slide talking about this.",
                    "label": 0
                },
                {
                    "sent": "Weather, which links is going to take into consideration?",
                    "label": 0
                },
                {
                    "sent": "Yeah, as features.",
                    "label": 0
                },
                {
                    "sent": "Only as features for it would be the same as if I had a selection of categories and I want to put additional way to categories as features.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So how how much time do I have left?",
                    "label": 0
                },
                {
                    "sent": "Well, OK, then let's go choosing experimentation.",
                    "label": 0
                },
                {
                    "sent": "Well, OK, I did a 5 fold cross validation on a dissimulated example set for 8155 queries, and these curious was selected by considering names or entities having a very common German surnames, vodka, normal, wet.",
                    "label": 0
                },
                {
                    "sent": "Basically the top 7.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "We require that these entities have ambiguous name, so this was added basically in and set where each entity has an average or each mention as an average 44 point something candidate.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And hence, the baseline accuracy is 25%.",
                    "label": 1
                },
                {
                    "sent": "So to be fair, I compared my approach to the words category based work category pairs from UNESCO.",
                    "label": 0
                },
                {
                    "sent": "It's a slightly altered version, but basically the idea is the same and we have to see that the performance where basically in micro it's in my performance as much I have, but we shouldn't be bothered by this.",
                    "label": 1
                },
                {
                    "sent": "But both the DDD, the binary word categories work.",
                    "label": 0
                },
                {
                    "sent": "Can you repairs and you waited?",
                    "label": 0
                },
                {
                    "sent": "Word link pairs perform equally well.",
                    "label": 0
                },
                {
                    "sent": "Very well, but with no significant significant difference.",
                    "label": 1
                },
                {
                    "sent": "Where is the binary world link pairs.",
                    "label": 0
                },
                {
                    "sent": "Not very much.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Why I'm not so good, right and?",
                    "label": 0
                },
                {
                    "sent": "The take home message is set even though these set of categories is much more elaborated and has much more thinking behind it.",
                    "label": 0
                },
                {
                    "sent": "We can deduce from a set that it's much more noisy, meaning the set of links an equally relevant, equally distinguished and set of features using some, maybe some more sophisticated wait.",
                    "label": 1
                },
                {
                    "sent": "Which brings me to the last slide, which is my eye.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Outlook.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                },
                {
                    "sent": "On going from this work here, I well first thing I would like to have is a true relation extraction algorithm performing well for German.",
                    "label": 0
                },
                {
                    "sent": "But since I cannot hope to have these.",
                    "label": 0
                },
                {
                    "sent": "In the next three years or so.",
                    "label": 0
                },
                {
                    "sent": "I have to find some Clarivate or some more sophisticated ways to find to model real relations from links.",
                    "label": 1
                },
                {
                    "sent": "So one basic approach would be to use some small topic model which only compute some quick library events between the candidates are between one another and then we would gain a really topically difference.",
                    "label": 0
                },
                {
                    "sent": "Yeah, divergance between the two of them.",
                    "label": 0
                },
                {
                    "sent": "Additionally, we should take into account that maybe Wikipedia users are somewhat.",
                    "label": 0
                },
                {
                    "sent": "Make false and that link detection method methods could be used to find Additionally or more relevant links.",
                    "label": 1
                },
                {
                    "sent": "And the long term goal is to combine these things.",
                    "label": 0
                },
                {
                    "sent": "These topical information is relational information into one larger model, and this could be compared then in a generative approach.",
                    "label": 0
                },
                {
                    "sent": "So this can approach using some kernel methods as I'm craft kernel methods or so.",
                    "label": 0
                },
                {
                    "sent": "Well then.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you, anybody questions?",
                    "label": 0
                },
                {
                    "sent": "Can you make some comments about the kind of errors that.",
                    "label": 0
                },
                {
                    "sent": "When you look at the errors.",
                    "label": 0
                },
                {
                    "sent": "The problem is that the errors are.",
                    "label": 0
                },
                {
                    "sent": "That mostly the context that I extract from Wikipedia and not very descriptive.",
                    "label": 0
                },
                {
                    "sent": "So first of all, to it it would be the nicest thing to have.",
                    "label": 0
                },
                {
                    "sent": "Would be a December created, manually annotated sets of documents, but well, not yet.",
                    "label": 0
                },
                {
                    "sent": "There is not and.",
                    "label": 0
                },
                {
                    "sent": "Mainly those Contacts have received false links that are bad quality, so.",
                    "label": 0
                },
                {
                    "sent": "Best quality also includes that it is a synonym.",
                    "label": 0
                },
                {
                    "sent": "Miss went many synonyms for words appearing in the article, but not only you can't match time using some simple cosine similarity, but you could match them using word net information or so, or grammar net in my case.",
                    "label": 0
                },
                {
                    "sent": "Performance.",
                    "label": 0
                },
                {
                    "sent": "It was about a 62% F measure both on micro and macro in that version, but it has a very high variance.",
                    "label": 0
                },
                {
                    "sent": "So it truly depends on it works well for some context, and it works very bad for other countries.",
                    "label": 0
                },
                {
                    "sent": "Information you consider how it didn't like.",
                    "label": 0
                },
                {
                    "sent": "Category.",
                    "label": 0
                },
                {
                    "sent": "Where does the problem that you?",
                    "label": 0
                },
                {
                    "sent": "Probably won't overcome, since entities with a sparse category information have short articles, have few links are not very representative.",
                    "label": 0
                },
                {
                    "sent": "You won't find many examples for them, but.",
                    "label": 0
                },
                {
                    "sent": "But maybe they should receive some attention as well.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        }
    }
}