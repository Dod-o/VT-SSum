{
    "id": "g3epiyf3wq3reviq2fu5oyde7hqde5hm",
    "title": "Mining the Web of Linked Data with RapidMiner",
    "info": {
        "author": [
            "Heiko Paulheim, Institut f\u00fcr Informatik, University of Mannheim"
        ],
        "published": "Dec. 19, 2014",
        "recorded": "October 2014",
        "category": [
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/iswc2014_paulheim_rapidminer/",
    "segmentation": [
        [
            "So the first question I would like to check it is why would we want to do that at all?"
        ],
        [
            "So typically we have some information needs and these information needs are complex, so we want to know what factors lead to a high corruption rate in different countries or what.",
            "How can we improve the quality of living in cities or we as researchers wanna now how to publish more scientific articles and so on and so forth.",
            "And speaking to you as linked data people, there is probably no data set against which we can just issue those queries as a sparkle query and get an answer.",
            "So we actually need some more than just the mirror data.",
            "To answer those questions."
        ],
        [
            "So on the one inside, we've got data.",
            "We've got lots of data interesting and cool data, and on the other hand we have some tools that can perform complex analysis on data.",
            "But this extension actually does is it tries to build a bridge between those two worlds, so these large scale datasets with all the interesting data and the complex analysis tools."
        ],
        [
            "Um, so this is what we want to do.",
            "In the end, we probably have some local data at hand, which we want to analyze.",
            "We have some data which is remote like in DB pedia.",
            "And yeah, go and free bays and so on and so forth.",
            "And we want first to perform some linking.",
            "Combine that data may be, cleanse that data, eliminate some noise and errors in that, and then we need to transform and analyze it in the end.",
            "In the end we want to come up with some insight, some decisions in the end.",
            "So this is the pipeline that reminds a lot of buyouts, data mining, power plan.",
            "So this is what we want to achieve in the Ant."
        ],
        [
            "Can we do that with the two called Rapid Miner?",
            "For those of you who don't know, rapidminer, it's an open source platform for data mining.",
            "For predictive analysis.",
            "You can build complex data analysis workflows with it.",
            "I'll show you examples in a minute and you can create those.",
            "Process is just by wiring operators in a user interface, so you don't need to do any programming in that.",
            "There's plenty of operators which load data for you which transform data, which creates predictive models and so on.",
            "And it's actually also two which you can run in a cloud environment if you want to do real large scale analysis.",
            "So rapid miner themselves claimed they have like 200,000 active users.",
            "At the moment.",
            "I haven't checked that number, I just believe them to tell the truth.",
            "They work with many major companies and the interesting thing about rapid miner is that developers can write their own extensions to it, so it's a platform and there is plenty of extensions that do fancy stuff, and one of those is the linked open data extension."
        ],
        [
            "Home.",
            "So what does the extension due to rapid miner adults actually a sudden rapid miner allows you to wire operators?",
            "So we add some more operators to rapidminer, so those operators are capable of accessing local and remote semantic web data, so loading RDF data, showing sparkle queries, loading data from RDF data cubes and stuff like that, we offer operators that allow you to link your local data into data that is in the data cloud, so using services like look up or performing sparkle queries that look for items with certain labels and so on.",
            "On and then, once you've got those links, you can enrich your local data so you have some local data and you can add additional data properties you find somewhere out there in the elody cloud.",
            "You can also automatically follow links between datasets, so once you've got a link to a data set, follow links out there into the cloud to discover new datasets.",
            "We exploit the schema and ontology information we find with those datasets.",
            "Also for performing some operations and performing them better than you could do them with standard operations.",
            "So for example, if you want to.",
            "Reduce the attributes at, which is a typical problem in data mining we have shown in a paper in discovery science this year that exploiting the ontology information you find at the data sources you can get actually better results in attribute subset selection than with standard methods that are not aware of the ontology information.",
            "You can also, if you find data at different sources, you can match them, fuse them together into a unified form.",
            "And one of the crucial thing is rapid miner is a tool for data analysis and data analysts can actually use that tool and use the extension without knowing about sparkle about RDF and your eyes and stuff like that.",
            "We heard that in nitrous keynote this morning that this is one of the main obstacles in promoting link data to people who are not from our community, so you can actually use that tool without knowing anything about linked data, such of course it helps to know, but you can use it without.",
            "Particular knowledge and spark."
        ],
        [
            "We use 11 running example and in the demo yesterday and I will also use it today to to show you what what this extension does.",
            "So this is the question that interests us of course, so which which factors correlate with the increase of published scientific and technical Journal articles?",
            "So we want to increase our publication rates and scientific journals you work for.",
            "I will show you in a second does the following it.",
            "First we've got data about scientific Journal publications and different.",
            "Countries published by the World Bank as an RDF Cube.",
            "So we first import that data and then we link.",
            "Those data, which is not linked by itself to DB Pedia from DB pedia.",
            "We jump to additional datasets and gather all the information about those countries.",
            "We get from there and then we look for interesting findings, so look for are there any significant correlations that help us trying to tell what makes a country increase the amount of scientific publications so let's look what this thing.",
            "Looks like this is rapidminer.",
            "As I said you can wire operators every of these boxes as an operator in rapidminer, and each of those boxes does something so you can load data.",
            "You can compute some aggregations you can perform some selections and so on and so forth.",
            "What I've done here in the 1st place is I've loaded data from the RDF data cube.",
            "I could have done that with the extension itself.",
            "I have cashed it in my local disk to make it a bit faster, So what we have here is we have a list of countries and for each of those countries we have those different.",
            "Numbers of publications which are essentially numbers per year, so we have time series for each of those countries.",
            "In the next step here or where to start to disappear.",
            "OK, so in the next step we compute the average out of those and then what we do is we want to link those data to.",
            "In that case, DB pedia.",
            "So the output of that operator now we have the averages we computed for each country and for each country we know found a link to DB pedia.",
            "So this is our main first entry point into the web of data.",
            "To augment our local data.",
            "And then we have this operator.",
            "Here I should maybe extend that a little bit.",
            "So what that does it sells OK given that entry point at DB pedia.",
            "Please go to.",
            "In that case two hops deep into the link data cloud.",
            "So we follow all the old same as links to other datasets.",
            "And then we tell it what to do with whatever it finds.",
            "And this is what's happening inside first.",
            "OK, please extract me all the data type properties you find and please extract me all the direct types you find and in the end, given that from all the data sources we have discovered two hops deep in the cloud.",
            "Please join them into a unified data set.",
            "The other things happening here is for those types.",
            "We as I sat perform some attribute selection which to use as the hierarchy information we crawled from the datasets an for these data type properties, we perform some matching.",
            "So Paris is a schema matching an instance matching system falling to open data and what is essentially performs is given that we find, for example, a population value in three or four different datasets.",
            "We in the end only want one column which represents the population of those countries.",
            "So this this.",
            "Operator performs a matching and then refused them into one column.",
            "OK, this is what happens here.",
            "If you look at the output of that operator, we see we still have our countries, our numbers and our DB pedia links.",
            "And then we have all those links to other datasets like Euro stat or GEONAMES or YAGO and so on and so forth.",
            "And then you see there is whole bunch of additional information we got for all those data, so so everything you could ever find at any of those datasets is now collected in your data.",
            "And once we got that and we can do what we initially wanted to do, because we can't find out what is the actual correlations here.",
            "So given those average values that we were interested in, we can then find OK. What is the?",
            "What are the interesting correlations here?",
            "So for example, in Northern American states you have a high output of scientific publications, so this is basically what this tool does."
        ],
        [
            "In that case we started from DB pedia.",
            "We collected links from from various datasets and then as I said, we fuse all that data like population numbers from different sources."
        ],
        [
            "So what we found out in that example use cases correlations, for example, there is something called the fragile State index which correlates with the number of population.",
            "So the stability of your political system, the Human Development index.",
            "There is a positive correlation with GDP which is not too surprising.",
            "What is the striking at first glance as these climate indicators so so the more it rains in the country where you live, the higher is the number of scientific publications that are created in that country.",
            "Yeah, lucky you in the UK.",
            "Um, it's you could say, OK, probably people just stay inside if it rains, and then they can write more articles, but it's more likely to be due to unequal distribution of wealth across different climate zones.",
            "You also see your false interpretations.",
            "I put question marks there because all these are just hypothesis which require the verification by a domain expert.",
            "But this is how far the two gets.",
            "It gives you all those interesting correlations and then a domain expert can validate them.",
            "Um?"
        ],
        [
            "Some some more use cases.",
            "We used that for K. One thing is some, there are predictive tasks so so one typical predictive tasks which is very well known.",
            "The machine learning community is this UCI car data set.",
            "You have a set of cars and you are asked to predict the fuel consumption given some attributes about those cars like their weight, their size and so on.",
            "And we have shown that if we link those cars to DB pedia and start from there collecting additional information about the cars we can reduce the prediction error of a standard.",
            "Prediction algorithm by half.",
            "So before adding additional information it is wrong by on average 3 miles per gallon.",
            "Given the additional attributes, we can reduce that error 2 on average 1.6 miles per gallon.",
            "So if you have something where you want to build a predictive model, adding more information without predictive model really helps increasing the precision of that."
        ],
        [
            "Model.",
            "This year was the semantic recommender system challenge.",
            "At ESWC Rep, people were asked given some some book book ratings to predict a ratings for other users and make recommendations for other users.",
            "So in that case we used our extension and we also used another extension.",
            "That case it's a recommender system extension which also exists for rapidminer.",
            "So you can mix operators from different extents to build complex tools and actually we did nothing more than just wiring operators from those two extensions in one process.",
            "And on two out of three tasks, we were actually the best performing systems out of 20 four other systems.",
            "So just by wiring operators in a standard off the shelf toolkit."
        ],
        [
            "And one more use case, we use that forest debugging data.",
            "So I had a paper this year at a workshop at years WC where I looked into links between datasets and I loaded a set of links between datasets in rapid miner and then created features for those links using my operators.",
            "Once you got that you can look for links that are somewhat suspicious, so in that case here these are the major distribution of links, so you have music works linked to songs and albums.",
            "You have music artists linked to artists, and then there is 1 ring which for some reason has gone wrong.",
            "Somebody has linked to music artists in one data set to an album in another data set, and it's actually quite isolated.",
            "So what you can do is you can run outlier detection again.",
            "There is an extension which does that for you.",
            "Load that data set, enhance it with features from the link data cloud and then put it to another operator which rapidminer offers and say please find the suspicious entities and then it can tell you there are some links which are likely to be wrong and actually this is this.",
            "Performs quite well.",
            "It gives you an area under the Roc curve of up to 85%, which for that problem is really not bad."
        ],
        [
            "Alright, in summary, this challenge entry we proposed brings data analysis to the web of data, so it creates that bridge between the two worlds and it can be used by data analysts without that requiring them to learn sparkle.",
            "If you want to use it, you can get it from the rapid miner marketplace.",
            "This is an extension mechanism in rapidminer, so you go into rapidminer.",
            "Search for linked open data extension, then you can install it from within rapid miner and I've checked this morning so far we have more than 5000 installations.",
            "Which disrupted minor marketplace reports and the number is constantly increasing so."
        ],
        [
            "Thank you very much.",
            "I just have a question about the runtime performance of it.",
            "What are you going to cope with when you try to do the sorts of examples that you were telling about us there?",
            "Yeah, it's totally depends on your Internet connection to pounds on the responsiveness of the endpoint.",
            "It also depends on whether the endpoint just blocks you after you issue 10,000 requests.",
            "It depends on the size of the data set, so it's totally different there are.",
            "There are examples which computer.",
            "Count seconds if you're in a fast environment.",
            "That examples to take an hour, but typically for these questions I showed in the beginning, you do not have real time requirements, right?",
            "So you have an information need which you need answered and typically does not depend on one hour more or less, so it's from my perspective it's not that bad.",
            "More about rapidminer than it is about your work, but does that have like a client server architecture or something?",
            "Or are you waiting for all that stuff on your on your laptop?",
            "OK, so you can run on a laptop.",
            "You can also rapid Miner offers cloud services where you can say I have this process.",
            "This process now.",
            "Please run it somewhere on Amazon, in the cloud.",
            "You can also just invoke it from Java and run it on some high performance server whatever so.",
            "Yes."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the first question I would like to check it is why would we want to do that at all?",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So typically we have some information needs and these information needs are complex, so we want to know what factors lead to a high corruption rate in different countries or what.",
                    "label": 1
                },
                {
                    "sent": "How can we improve the quality of living in cities or we as researchers wanna now how to publish more scientific articles and so on and so forth.",
                    "label": 1
                },
                {
                    "sent": "And speaking to you as linked data people, there is probably no data set against which we can just issue those queries as a sparkle query and get an answer.",
                    "label": 0
                },
                {
                    "sent": "So we actually need some more than just the mirror data.",
                    "label": 0
                },
                {
                    "sent": "To answer those questions.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So on the one inside, we've got data.",
                    "label": 0
                },
                {
                    "sent": "We've got lots of data interesting and cool data, and on the other hand we have some tools that can perform complex analysis on data.",
                    "label": 0
                },
                {
                    "sent": "But this extension actually does is it tries to build a bridge between those two worlds, so these large scale datasets with all the interesting data and the complex analysis tools.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Um, so this is what we want to do.",
                    "label": 0
                },
                {
                    "sent": "In the end, we probably have some local data at hand, which we want to analyze.",
                    "label": 1
                },
                {
                    "sent": "We have some data which is remote like in DB pedia.",
                    "label": 0
                },
                {
                    "sent": "And yeah, go and free bays and so on and so forth.",
                    "label": 0
                },
                {
                    "sent": "And we want first to perform some linking.",
                    "label": 0
                },
                {
                    "sent": "Combine that data may be, cleanse that data, eliminate some noise and errors in that, and then we need to transform and analyze it in the end.",
                    "label": 0
                },
                {
                    "sent": "In the end we want to come up with some insight, some decisions in the end.",
                    "label": 0
                },
                {
                    "sent": "So this is the pipeline that reminds a lot of buyouts, data mining, power plan.",
                    "label": 0
                },
                {
                    "sent": "So this is what we want to achieve in the Ant.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Can we do that with the two called Rapid Miner?",
                    "label": 0
                },
                {
                    "sent": "For those of you who don't know, rapidminer, it's an open source platform for data mining.",
                    "label": 1
                },
                {
                    "sent": "For predictive analysis.",
                    "label": 0
                },
                {
                    "sent": "You can build complex data analysis workflows with it.",
                    "label": 0
                },
                {
                    "sent": "I'll show you examples in a minute and you can create those.",
                    "label": 1
                },
                {
                    "sent": "Process is just by wiring operators in a user interface, so you don't need to do any programming in that.",
                    "label": 1
                },
                {
                    "sent": "There's plenty of operators which load data for you which transform data, which creates predictive models and so on.",
                    "label": 1
                },
                {
                    "sent": "And it's actually also two which you can run in a cloud environment if you want to do real large scale analysis.",
                    "label": 0
                },
                {
                    "sent": "So rapid miner themselves claimed they have like 200,000 active users.",
                    "label": 0
                },
                {
                    "sent": "At the moment.",
                    "label": 0
                },
                {
                    "sent": "I haven't checked that number, I just believe them to tell the truth.",
                    "label": 1
                },
                {
                    "sent": "They work with many major companies and the interesting thing about rapid miner is that developers can write their own extensions to it, so it's a platform and there is plenty of extensions that do fancy stuff, and one of those is the linked open data extension.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Home.",
                    "label": 0
                },
                {
                    "sent": "So what does the extension due to rapid miner adults actually a sudden rapid miner allows you to wire operators?",
                    "label": 0
                },
                {
                    "sent": "So we add some more operators to rapidminer, so those operators are capable of accessing local and remote semantic web data, so loading RDF data, showing sparkle queries, loading data from RDF data cubes and stuff like that, we offer operators that allow you to link your local data into data that is in the data cloud, so using services like look up or performing sparkle queries that look for items with certain labels and so on.",
                    "label": 1
                },
                {
                    "sent": "On and then, once you've got those links, you can enrich your local data so you have some local data and you can add additional data properties you find somewhere out there in the elody cloud.",
                    "label": 0
                },
                {
                    "sent": "You can also automatically follow links between datasets, so once you've got a link to a data set, follow links out there into the cloud to discover new datasets.",
                    "label": 0
                },
                {
                    "sent": "We exploit the schema and ontology information we find with those datasets.",
                    "label": 0
                },
                {
                    "sent": "Also for performing some operations and performing them better than you could do them with standard operations.",
                    "label": 0
                },
                {
                    "sent": "So for example, if you want to.",
                    "label": 0
                },
                {
                    "sent": "Reduce the attributes at, which is a typical problem in data mining we have shown in a paper in discovery science this year that exploiting the ontology information you find at the data sources you can get actually better results in attribute subset selection than with standard methods that are not aware of the ontology information.",
                    "label": 0
                },
                {
                    "sent": "You can also, if you find data at different sources, you can match them, fuse them together into a unified form.",
                    "label": 1
                },
                {
                    "sent": "And one of the crucial thing is rapid miner is a tool for data analysis and data analysts can actually use that tool and use the extension without knowing about sparkle about RDF and your eyes and stuff like that.",
                    "label": 0
                },
                {
                    "sent": "We heard that in nitrous keynote this morning that this is one of the main obstacles in promoting link data to people who are not from our community, so you can actually use that tool without knowing anything about linked data, such of course it helps to know, but you can use it without.",
                    "label": 0
                },
                {
                    "sent": "Particular knowledge and spark.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We use 11 running example and in the demo yesterday and I will also use it today to to show you what what this extension does.",
                    "label": 0
                },
                {
                    "sent": "So this is the question that interests us of course, so which which factors correlate with the increase of published scientific and technical Journal articles?",
                    "label": 1
                },
                {
                    "sent": "So we want to increase our publication rates and scientific journals you work for.",
                    "label": 0
                },
                {
                    "sent": "I will show you in a second does the following it.",
                    "label": 0
                },
                {
                    "sent": "First we've got data about scientific Journal publications and different.",
                    "label": 0
                },
                {
                    "sent": "Countries published by the World Bank as an RDF Cube.",
                    "label": 0
                },
                {
                    "sent": "So we first import that data and then we link.",
                    "label": 0
                },
                {
                    "sent": "Those data, which is not linked by itself to DB Pedia from DB pedia.",
                    "label": 0
                },
                {
                    "sent": "We jump to additional datasets and gather all the information about those countries.",
                    "label": 0
                },
                {
                    "sent": "We get from there and then we look for interesting findings, so look for are there any significant correlations that help us trying to tell what makes a country increase the amount of scientific publications so let's look what this thing.",
                    "label": 0
                },
                {
                    "sent": "Looks like this is rapidminer.",
                    "label": 0
                },
                {
                    "sent": "As I said you can wire operators every of these boxes as an operator in rapidminer, and each of those boxes does something so you can load data.",
                    "label": 0
                },
                {
                    "sent": "You can compute some aggregations you can perform some selections and so on and so forth.",
                    "label": 0
                },
                {
                    "sent": "What I've done here in the 1st place is I've loaded data from the RDF data cube.",
                    "label": 0
                },
                {
                    "sent": "I could have done that with the extension itself.",
                    "label": 0
                },
                {
                    "sent": "I have cashed it in my local disk to make it a bit faster, So what we have here is we have a list of countries and for each of those countries we have those different.",
                    "label": 0
                },
                {
                    "sent": "Numbers of publications which are essentially numbers per year, so we have time series for each of those countries.",
                    "label": 0
                },
                {
                    "sent": "In the next step here or where to start to disappear.",
                    "label": 0
                },
                {
                    "sent": "OK, so in the next step we compute the average out of those and then what we do is we want to link those data to.",
                    "label": 0
                },
                {
                    "sent": "In that case, DB pedia.",
                    "label": 0
                },
                {
                    "sent": "So the output of that operator now we have the averages we computed for each country and for each country we know found a link to DB pedia.",
                    "label": 0
                },
                {
                    "sent": "So this is our main first entry point into the web of data.",
                    "label": 0
                },
                {
                    "sent": "To augment our local data.",
                    "label": 0
                },
                {
                    "sent": "And then we have this operator.",
                    "label": 0
                },
                {
                    "sent": "Here I should maybe extend that a little bit.",
                    "label": 0
                },
                {
                    "sent": "So what that does it sells OK given that entry point at DB pedia.",
                    "label": 0
                },
                {
                    "sent": "Please go to.",
                    "label": 0
                },
                {
                    "sent": "In that case two hops deep into the link data cloud.",
                    "label": 0
                },
                {
                    "sent": "So we follow all the old same as links to other datasets.",
                    "label": 0
                },
                {
                    "sent": "And then we tell it what to do with whatever it finds.",
                    "label": 0
                },
                {
                    "sent": "And this is what's happening inside first.",
                    "label": 0
                },
                {
                    "sent": "OK, please extract me all the data type properties you find and please extract me all the direct types you find and in the end, given that from all the data sources we have discovered two hops deep in the cloud.",
                    "label": 0
                },
                {
                    "sent": "Please join them into a unified data set.",
                    "label": 0
                },
                {
                    "sent": "The other things happening here is for those types.",
                    "label": 0
                },
                {
                    "sent": "We as I sat perform some attribute selection which to use as the hierarchy information we crawled from the datasets an for these data type properties, we perform some matching.",
                    "label": 0
                },
                {
                    "sent": "So Paris is a schema matching an instance matching system falling to open data and what is essentially performs is given that we find, for example, a population value in three or four different datasets.",
                    "label": 0
                },
                {
                    "sent": "We in the end only want one column which represents the population of those countries.",
                    "label": 0
                },
                {
                    "sent": "So this this.",
                    "label": 0
                },
                {
                    "sent": "Operator performs a matching and then refused them into one column.",
                    "label": 0
                },
                {
                    "sent": "OK, this is what happens here.",
                    "label": 0
                },
                {
                    "sent": "If you look at the output of that operator, we see we still have our countries, our numbers and our DB pedia links.",
                    "label": 0
                },
                {
                    "sent": "And then we have all those links to other datasets like Euro stat or GEONAMES or YAGO and so on and so forth.",
                    "label": 0
                },
                {
                    "sent": "And then you see there is whole bunch of additional information we got for all those data, so so everything you could ever find at any of those datasets is now collected in your data.",
                    "label": 0
                },
                {
                    "sent": "And once we got that and we can do what we initially wanted to do, because we can't find out what is the actual correlations here.",
                    "label": 0
                },
                {
                    "sent": "So given those average values that we were interested in, we can then find OK. What is the?",
                    "label": 0
                },
                {
                    "sent": "What are the interesting correlations here?",
                    "label": 0
                },
                {
                    "sent": "So for example, in Northern American states you have a high output of scientific publications, so this is basically what this tool does.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In that case we started from DB pedia.",
                    "label": 0
                },
                {
                    "sent": "We collected links from from various datasets and then as I said, we fuse all that data like population numbers from different sources.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what we found out in that example use cases correlations, for example, there is something called the fragile State index which correlates with the number of population.",
                    "label": 1
                },
                {
                    "sent": "So the stability of your political system, the Human Development index.",
                    "label": 0
                },
                {
                    "sent": "There is a positive correlation with GDP which is not too surprising.",
                    "label": 0
                },
                {
                    "sent": "What is the striking at first glance as these climate indicators so so the more it rains in the country where you live, the higher is the number of scientific publications that are created in that country.",
                    "label": 0
                },
                {
                    "sent": "Yeah, lucky you in the UK.",
                    "label": 0
                },
                {
                    "sent": "Um, it's you could say, OK, probably people just stay inside if it rains, and then they can write more articles, but it's more likely to be due to unequal distribution of wealth across different climate zones.",
                    "label": 1
                },
                {
                    "sent": "You also see your false interpretations.",
                    "label": 0
                },
                {
                    "sent": "I put question marks there because all these are just hypothesis which require the verification by a domain expert.",
                    "label": 0
                },
                {
                    "sent": "But this is how far the two gets.",
                    "label": 0
                },
                {
                    "sent": "It gives you all those interesting correlations and then a domain expert can validate them.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Some some more use cases.",
                    "label": 1
                },
                {
                    "sent": "We used that for K. One thing is some, there are predictive tasks so so one typical predictive tasks which is very well known.",
                    "label": 1
                },
                {
                    "sent": "The machine learning community is this UCI car data set.",
                    "label": 0
                },
                {
                    "sent": "You have a set of cars and you are asked to predict the fuel consumption given some attributes about those cars like their weight, their size and so on.",
                    "label": 0
                },
                {
                    "sent": "And we have shown that if we link those cars to DB pedia and start from there collecting additional information about the cars we can reduce the prediction error of a standard.",
                    "label": 1
                },
                {
                    "sent": "Prediction algorithm by half.",
                    "label": 1
                },
                {
                    "sent": "So before adding additional information it is wrong by on average 3 miles per gallon.",
                    "label": 0
                },
                {
                    "sent": "Given the additional attributes, we can reduce that error 2 on average 1.6 miles per gallon.",
                    "label": 0
                },
                {
                    "sent": "So if you have something where you want to build a predictive model, adding more information without predictive model really helps increasing the precision of that.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Model.",
                    "label": 0
                },
                {
                    "sent": "This year was the semantic recommender system challenge.",
                    "label": 0
                },
                {
                    "sent": "At ESWC Rep, people were asked given some some book book ratings to predict a ratings for other users and make recommendations for other users.",
                    "label": 0
                },
                {
                    "sent": "So in that case we used our extension and we also used another extension.",
                    "label": 0
                },
                {
                    "sent": "That case it's a recommender system extension which also exists for rapidminer.",
                    "label": 1
                },
                {
                    "sent": "So you can mix operators from different extents to build complex tools and actually we did nothing more than just wiring operators from those two extensions in one process.",
                    "label": 0
                },
                {
                    "sent": "And on two out of three tasks, we were actually the best performing systems out of 20 four other systems.",
                    "label": 1
                },
                {
                    "sent": "So just by wiring operators in a standard off the shelf toolkit.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And one more use case, we use that forest debugging data.",
                    "label": 0
                },
                {
                    "sent": "So I had a paper this year at a workshop at years WC where I looked into links between datasets and I loaded a set of links between datasets in rapid miner and then created features for those links using my operators.",
                    "label": 0
                },
                {
                    "sent": "Once you got that you can look for links that are somewhat suspicious, so in that case here these are the major distribution of links, so you have music works linked to songs and albums.",
                    "label": 0
                },
                {
                    "sent": "You have music artists linked to artists, and then there is 1 ring which for some reason has gone wrong.",
                    "label": 0
                },
                {
                    "sent": "Somebody has linked to music artists in one data set to an album in another data set, and it's actually quite isolated.",
                    "label": 0
                },
                {
                    "sent": "So what you can do is you can run outlier detection again.",
                    "label": 1
                },
                {
                    "sent": "There is an extension which does that for you.",
                    "label": 0
                },
                {
                    "sent": "Load that data set, enhance it with features from the link data cloud and then put it to another operator which rapidminer offers and say please find the suspicious entities and then it can tell you there are some links which are likely to be wrong and actually this is this.",
                    "label": 0
                },
                {
                    "sent": "Performs quite well.",
                    "label": 1
                },
                {
                    "sent": "It gives you an area under the Roc curve of up to 85%, which for that problem is really not bad.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Alright, in summary, this challenge entry we proposed brings data analysis to the web of data, so it creates that bridge between the two worlds and it can be used by data analysts without that requiring them to learn sparkle.",
                    "label": 1
                },
                {
                    "sent": "If you want to use it, you can get it from the rapid miner marketplace.",
                    "label": 0
                },
                {
                    "sent": "This is an extension mechanism in rapidminer, so you go into rapidminer.",
                    "label": 0
                },
                {
                    "sent": "Search for linked open data extension, then you can install it from within rapid miner and I've checked this morning so far we have more than 5000 installations.",
                    "label": 0
                },
                {
                    "sent": "Which disrupted minor marketplace reports and the number is constantly increasing so.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Thank you very much.",
                    "label": 0
                },
                {
                    "sent": "I just have a question about the runtime performance of it.",
                    "label": 0
                },
                {
                    "sent": "What are you going to cope with when you try to do the sorts of examples that you were telling about us there?",
                    "label": 0
                },
                {
                    "sent": "Yeah, it's totally depends on your Internet connection to pounds on the responsiveness of the endpoint.",
                    "label": 0
                },
                {
                    "sent": "It also depends on whether the endpoint just blocks you after you issue 10,000 requests.",
                    "label": 0
                },
                {
                    "sent": "It depends on the size of the data set, so it's totally different there are.",
                    "label": 0
                },
                {
                    "sent": "There are examples which computer.",
                    "label": 0
                },
                {
                    "sent": "Count seconds if you're in a fast environment.",
                    "label": 0
                },
                {
                    "sent": "That examples to take an hour, but typically for these questions I showed in the beginning, you do not have real time requirements, right?",
                    "label": 0
                },
                {
                    "sent": "So you have an information need which you need answered and typically does not depend on one hour more or less, so it's from my perspective it's not that bad.",
                    "label": 0
                },
                {
                    "sent": "More about rapidminer than it is about your work, but does that have like a client server architecture or something?",
                    "label": 0
                },
                {
                    "sent": "Or are you waiting for all that stuff on your on your laptop?",
                    "label": 0
                },
                {
                    "sent": "OK, so you can run on a laptop.",
                    "label": 0
                },
                {
                    "sent": "You can also rapid Miner offers cloud services where you can say I have this process.",
                    "label": 0
                },
                {
                    "sent": "This process now.",
                    "label": 0
                },
                {
                    "sent": "Please run it somewhere on Amazon, in the cloud.",
                    "label": 0
                },
                {
                    "sent": "You can also just invoke it from Java and run it on some high performance server whatever so.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                }
            ]
        }
    }
}