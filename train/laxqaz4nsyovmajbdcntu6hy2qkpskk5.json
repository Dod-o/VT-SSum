{
    "id": "laxqaz4nsyovmajbdcntu6hy2qkpskk5",
    "title": "HAWK \u2013 Hybrid Question Answering using Linked Data",
    "info": {
        "author": [
            "Ricardo Usbeck, Agile Knowledge Engineering and Semantic Web (AKSW), University of Leipzig"
        ],
        "published": "July 15, 2015",
        "recorded": "June 2015",
        "category": [
            "Top->Computer Science->Big Data",
            "Top->Computer Science->Semantic Web"
        ]
    },
    "url": "http://videolectures.net/eswc2015_usbeck_linked_data/",
    "segmentation": [
        [
            "Welcome everybody to my talk about question answering, in particular about hybrid question answering.",
            "This is joint work.",
            "Together with accident, who's sitting back there and Lawrence Berman and Christina Romer.",
            "Christine almost from the University of Peter Fed.",
            "Axel Lawrence and I are from the University of Leipzig, especially from the CSW group.",
            "So the motivation behind making.",
            "Yet another hybrid question answering system or another question answering system is."
        ],
        [
            "That we can make use of hyper data sources, in particular, the document web has grown for the last 20 years and amounts up to several tons of petabytes of data.",
            "But those petabytes of data, unstructured in nature and hard for machines to read, so it's very hard for question answering systems to extract semantics from those unstructured documents.",
            "On the other hand side, we got the link data web, which is highly structured as semantic annotations, or is full of semantic information and makes it.",
            "Easier for us to answer information needs.",
            "However we have the misalignment mismatch between the linked data web and the document itself.",
            "And so if you consider the example question up there, in which City was the assessment of Martin Luther King born?",
            "You will see that you need information from both websites to find an answer.",
            "So Martin Luther King with many knowledge about him from the DB pedia, meminisse semantic knowledge.",
            "But if we want to find out who the assessment of Martin Luther King is, we have to go to the document Web in particular to the Wikipedia article of James Orlene who assassinated Martin Luther King.",
            "And then go back to Link data Web to link from this person to his birthplace to answer this complex query."
        ],
        [
            "And yesterday night I tried to put this rather complex query to Google and Google will not find any results for you, so at least not entities or your eyes."
        ],
        [
            "So we designed talk.",
            "The first hybrid question answering system that combines fulltext search and link data search.",
            "With each other and results in the list of entity, your eyes in particular.",
            "Please keep in mind we do at that stage only entity search."
        ],
        [
            "And for the rest of the talk, I will go through this eight step pipeline with you.",
            "Why are all running example?"
        ],
        [
            "And the first thing I want to present is how we do tokenization and how we do post tagging, reuse, rather modular pipeline to do that.",
            "And we need tokenization at the first thing because we want to have a generic framework itself that can be applied to multiple languages.",
            "So because not every language has white based organization, we made the module tokenization module and we use a library for more."
        ],
        [
            "Lingual multilingual posting.",
            "So part of speech tagging we need part of speech text in that query or in that question to find out which individuals properties or classes are there in this question and can be linked to a link data resource or the document web."
        ],
        [
            "So after running post taking on our example question, you will see that every token tokenized by whitespace tokenizer ends up with one POS tech.",
            "In particular, we see that Martin Luther King has been tagged as a proper noun, and the word assessment has been taken as a noun.",
            "This will get important later."
        ],
        [
            "So the second step in our pipeline is entity annotation.",
            "So what we do here is we want to find out the parts of the input questions that are that can be mapped to a semantic source, in our case to DB pedia."
        ],
        [
            "An within Hawk we use several entity annotation systems."
        ],
        [
            "With respect to our example query, a good entity annotation system should be capable to find the named entity Martin Luther King Resource from DB Pedia in this question.",
            "So later I will show you how much an entity annotation system can influence the question, answering quality that you get in yet."
        ],
        [
            "The first step basically tells us how it is single tokens that we tokenized and that we posted or annotated.",
            "This entities are linked to each other, so we make a dependency parsing as well."
        ],
        [
            "Tick dependencies positives at him told us.",
            "We do."
        ],
        [
            "You used to clear in the P API to form a dependency argument tree, this is.",
            "A tree that has one root, the roots normally and predicate in a predicate can have one too many arguments there.",
            "So in our case born is the root argument, which has four predicates that are distributed.",
            "This will tell us later how we can link the single semantic units to each other and how this pocket query that we want to generate has to be built up in terms of the basic graph pattern we will use."
        ],
        [
            "So the first step is linguistic pruning.",
            "When we add."
        ],
        [
            "Up with a graph like that, that's very complex to form into his pocket Curry and contains much knowledge but also much knowledge that we cannot use in some way or the other.",
            "So we implemented some Horace."
        ],
        [
            "6 to get rid of.",
            "Tokens that do not carry aunties and any semantic information.",
            "So for example, we discard or determiners or quotation marks or we are which words and so on.",
            "So that we end up with a reduced graph that contains only either way proper nouns or nouns or verbs that can be linked to classes or properties."
        ],
        [
            "But"
        ],
        [
            "If I go back, you see that we only have one note that is semantically linked.",
            "However, making now a fulltext search enter semantic search will not bring any precise results, but rather a big large amount of answers.",
            "So what we?"
        ],
        [
            "Need to do next is to annotate the remaining parts of the question."
        ],
        [
            "With remaining parts in particular in this example I mean city Assassin and Bourne.",
            "So what we did is we used something like a hymns library, so a dictionary based approach to find surface forms for properties and classes, as well as the RDF's label of ontology classes and properties."
        ],
        [
            "If we now execute this module, we will find out that for example, City can stand for the DB Pedia, Ontology class City as well as the property capital.",
            "The same thing holds for born Born will become either birthdate or birthplace.",
            "In finance Parker query.",
            "But what we did module does not find is something from the ontology that Maps to assassin.",
            "It's just that simple that assassin is not modeled in the DBPR ontology.",
            "That's why this gives us a."
        ],
        [
            "Went to full text look up.",
            "We need to do in the document work later.",
            "Keep in mind that assassin would be a hybrid link to the document web."
        ],
        [
            "So and this hyperlink will be created in this pocket generation module."
        ],
        [
            "This module has three smaller stages.",
            "At first you will find or you go through each of these semantic models and bid for each node triple pattern.",
            "That is, you take every annotation from each of the semantic nodes and put in subject, predicate and object position and put the trip to new sparkle query.",
            "So after doing that, you end up with basically the number of annotations, spark queries and do now and forward a cross product between order semantic units so that you could combine every possible combination of a semantic annotation with every other possible annotation.",
            "But still we have a gap here and it is the document web."
        ],
        [
            "What we use is the fuzzy keystore, which allows us to index large amounts of text data and query them via once in his pocket query."
        ],
        [
            "So we do a full text filter for assassin overall entities and their concise bank descriptions made out of full text information."
        ],
        [
            "So now that we got all this pocket queries, Hawk will produce a large, rather large number or large set of spark queries to reduce the number of spark trees we can use our DFS and over our knowledge to rid."
        ],
        [
            "Use the number of sparkers post to the end point.",
            "Film in particular.",
            "We assume the disjointness of classes and discard invalid sparkle queries.",
            "You can imagine that if you combine the info cross product of orders annotations, you end up with spark increases.",
            "Just make no sense and return null sets and before posing them to the end point we can discard them by using the DL learner framework that has been developed.",
            "Their case www.org."
        ],
        [
            "So I'm after doing that.",
            "You see that, for example, capital, the property capital will be removed, since we assume that the first argument of predicate in this dependency tree has to be a type information.",
            "Most often you begin your query by specifying an RDF type.",
            "We do that just by.",
            "Nature.",
            "And what we also delete is the dear DP ontology birthday property.",
            "Why do we do that?",
            "Well, we assume that the projection variable variable that returns the result is an entity and entity, and Uriah birthdate has just as a result, most often literal value.",
            "So we can discard it safely without losing any precision."
        ],
        [
            "And after doing that for those that safe in 1000 Spark pictures, we still end up with 5000 Spark queries and Hawk now has the task to find out which Sparkle query is most matching to the natural language input question."
        ],
        [
            "So we need to rank those set of spark queries for ranking as a first approach to Hyper Question answer, we just use the feature based ranking.",
            "So we calculate 5 simple features on this pocket query.",
            "That is the number of terms, the number of constraints, the number of how many text filters you used and so on."
        ],
        [
            "By doing that, we get a ranked list of sparkle queries and we can now fire once purgatory after the year other until we reach, let's say, a valuable result or something like that."
        ],
        [
            "And what you see here is it's rather simple pipeline that Hawk employees currently, but we wanted to know how good are we.",
            "So we evaluated our approach in three different categories.",
            "The first category is that we wanted to find out how big is the influence of entity annotation system to the question answering system itself.",
            "The second thing is we wanted to find out assuming an optimal ranking, are we able to produce this pocket query?",
            "And the third thing is, given a set of spark queries, how good is our ranking function?"
        ],
        [
            "So we set up a question answering over linked data, four benchmark set, which I'm already used.",
            "So maybe it's going to be used in the first talk as well, and this consists of specially 25 hybrid training queries as well as ten test queries.",
            "But we will only use those 45 queries for the annotation part since we have to discard all non entity queries that demand the aggregation and that human geography types so that we end up with 17 questions that contain only entity knowledge."
        ],
        [
            "So the first step is how good is the entity annotation system?",
            "We compared four different systems, namely, take me folks to Wikipedia Minor.",
            "In spotlight you should know at least one of them.",
            "To see how good do they perform and is also assuming an optimal ranking, what we found out is that Fox performs best and delivers us over those 35 queries and F measure of oh .68, which is quite astonishing.",
            "But what was more interesting is that an optimal handcrafted annotator that is in annotator that we.",
            "Yeah, that we manually implemented that finds always the correct entities, just have an S measure that is lower by 10% sold by OH point 5.",
            "At 8:00 but that means basically, is that this optimal annotator annotates too much entities, and for some questions that's why the hybrid task, you just need some fulltext look up, otherwise you cannot get to the point in the graph, but you will find the correct entities.",
            "And most surprising to us was that the union of all four annotation system resides in low F measure of oh point.",
            "1 This is if you combine all entity annotations from all four systems, you get only information about individuals or on the information about entities, but no information about classes or properties anymore.",
            "And this pocket query containing only of resources but only of in the widgets but not of classes and properties will not find you anything else."
        ],
        [
            "So, knowing that we used folks on our 17 questions and I hope you can read them well.",
            "Otherwise I read them, load out out loud an so we wanted to know how good can we create this pocket queries.",
            "Are we able to create at all this pocket race that can deliver us answers and we see so in two cases, specially the red lines that we are not able to generate this pocket queries yet that is most often due to the structural.",
            "We had the structural dependencies in such sentences.",
            "For example, give me the currencies of all G8 countries is just a whole different dependency argument re.",
            "Then we age query dependency argument trees or the question who composed the music for the film that depend that depicts the early life of Jane Austen just contains an auxiliary sentence in this auxiliary sentence is just way too complicated for hop to answer because the dependency argumenty entry just explodes.",
            "Or the blue queries return recall of 1 but have a low precision.",
            "This is most often do we find all entities, but we find also a lot of noise.",
            "Currently we can get rid of that by using just a better entity annotation system or a better class annotation system.",
            "So our dictionary is not perfect yet.",
            "We're going to evaluate it in a later stage.",
            "And the fourth thing or the third thing I want to point out is that the cream query just returns the precision of 1, but the recall of just 50% ending up in an F measure 4.6 seven for the question of of the people that died of radiation in Los Alamos, whose death was an accident.",
            "Well, there the benchmark is.",
            "Made on DB Pedia 3.9 while we were testing against Peter 2014 and just some information got lost by the benchmark so it's important for the community of question answering also to keep up with the current development and to create its benchmarks.",
            "All other White Rose that you see could be answered completely within F measure of 1.",
            "So out of the 17 queries we are able to answer 89 queries correctly just in a million."
        ],
        [
            "Yeah, I know.",
            "Overall F measure is oh point 70."
        ],
        [
            "The first thing we wanted to know is.",
            "So knowing that entity annotation is important, knowing that we are able to at least get answers with an F measure of oh point 7 two or we are able to generate this pocket queries.",
            "How good is our ranking that means in a production real life environment, how good can we decide which sparkle query is the correct sparker that Maps the natural language input?",
            "And this what we you can see here is on the X axis number of Sparky crates.",
            "You have to look at to get a correct result and what you see is that in a window of the first 10 spark queries out of thousands of spark queries we are able to reach already F measures of OH point 5.",
            "Especially the number of constraints is important, so our tool tends to use more constraints than it should.",
            "Making the precision lower so the number of constraints is a very important feature for ranking, but what happen?"
        ],
        [
            "If we now combine several of those features, you see that within the window of just the first 10 sparkle queries for one natural language question question, we are able to reach F measures at oh point 6 or oh .65.",
            "At least it's better just by combining two of those rather simple feature based things that you can calculate in milliseconds on sparkle query."
        ],
        [
            "Overall, but I wanted to present to you is Hawk another modular question answering system for hybrid questions currently and what you also have seen is that we face several challenges.",
            "For example, the training and benchmark datasets for hybrid queries using the document web and the link data web is rather small.",
            "Even the QLD 5 benchmark set has just 50 questions currently that pertain to hybrid question answer for them or what we're going to do right now is we.",
            "Gonna extend types of answers that Hawks gonna answer or is able to answer so we do also ask queries as well as queries that return non entity types.",
            "The third thing that is important is we need to improve the ranking system.",
            "You cannot currently use machine learning because just 50 examples are not enough to train any valid machine learning algorithm on the ranking system.",
            "So we're looking for intelligent ways to form to let our algorithms rank this public race.",
            "And at last we want to extend the QA ecosystem.",
            "But we want to do is we want to.",
            "Implement more modules for each of the eight stages you have seen, just to make cross product of all those.",
            "Modules to see which modules performs best over which other modules."
        ],
        [
            "So in the end, I want to thank you for listening to me, and if you want to have updates on Hawk or did your learner or any other thing pertaining to HSW Group, please follow us on Twitter and find more information on the project site in the GitHub repository and now I'm happy to get questions from you.",
            "Thank you.",
            "Just have a native questions regarding sort of.",
            "Did you perform a qualitative analysis for the questions that you couldn't really answer?",
            "'cause, for example, coming from the QLD?",
            "He sets an imp articular compare.",
            "We've numerous over systems that Aftac whip khakis, but there are many offers.",
            "Yeah, 'cause he's an so on TBS right?",
            "And sweep, which is really a similar approach.",
            "Then you have OK, interesting.",
            "So the first thing you ask us whether we did a qualitative analysis.",
            "Yeah we did that.",
            "That can also be found in the paper.",
            "It basically found out that several.",
            "Minor mistakes lead to this low F measure, for example, not matching a particular class of property.",
            "So matching the string to or mapping the string from to the ontology files, which is just based on the few examples we got already, because quality is quite slow for.",
            "Again, the hybrid question answering thing.",
            "An I have to say I forgot the second question.",
            "So yeah, no.",
            "It was because of comparing to other systems.",
            "Yeah, yeah, we tried to push just some of the quite for hyper questions to, for example, TSS, INA, and other systems that took part in.",
            "But since everything question from this particular benchmark demands a hybrid.",
            "An answer, so at least every spark redim, ands or higher full text look up into the Wikipedia are tickets.",
            "No system was able to answer any of those questions, it was just no.",
            "Not possible for them to do that because they do not look into the Wikipedia fulltext articles.",
            "Yes, I just want to know why you have chosen to do post tagging with clear NLP rather than use open NLP, did you?",
            "See are any use case or study that shows that?",
            "It is better than the other know.",
            "Basically not.",
            "It was a tool at hand at that time, but as I said, we want to do a or we want to extend the QA ecosystem.",
            "But we're going to launch next month.",
            "Probably is a ontology based description of all the modules so that you can just then go and plug and play other modules for posting for entity annotations on a project we're doing knows already 15 different entity annotation system, so we're eager to see which of those 15 systems performs best over the phone.",
            "We test already.",
            "So we're going to extend it and invite everybody of you to write modules, and then we can maybe show Google how to answer complex queries with semantic web tools and you just cite some of the entity recognition systems that you have used.",
            "Sorry I just.",
            "Yeah, sure, for entity annotation we used in particular the technique system that is made by.",
            "Paulo Ferry now if I'm not wrong, folks that disturbance on ballooning tool accidentally expect developed their Crestview to Wikipedia minor that is known from could certain from 2008 and DBP spotlight.",
            "Of course, I hope everybody will know that.",
            "Thank you.",
            "Did you compare this with Watson?",
            "I think I have to go.",
            "No, I did not.",
            "The reason why is basically Watson is a paid API and we were not able yet to figure out with the team of IBM Watson I research contract so that we can use the API for for more tests, but we are eager to see that.",
            "So if anybody has a IBM Watson account please talk to me.",
            "Yeah we can talk later.",
            "Knowing so, maybe it's more common that I always have it see this because I always always have to deal with this as well.",
            "All this kind of system is also the one I presented this building on a lot of different components, so it would be good too if you're talking about benchmarks also to come up with some kind of whatever subtasks, or at least some kind of components that are standardized to some extent.",
            "Cause it's a lot of work to put something like this together and if you want to compare the whole approach to another approach.",
            "It's really hard to say, OK, yours is better becausw whatever this component and there is better and so it it's getting really, really difficult to compare this stuff.",
            "And I think we need to.",
            "Have some top down approach to think about how to do this.",
            "As a community is also really complex to analyze such a system and say this particular module performs worse or bed and if I changed it exactly and every time you submit a paper you get reviews.",
            "Why didn't you compare to this this and this?",
            "And yeah, I compared it to but I compared to this visit.",
            "This of course could be better or worse and it's always hard to like maneuver around how you say, OK, this is our contribution and.",
            "That's true, So what we're basically, I think all are looking forward is the ecosystem, maybe based on RDF to have different services already in place, so nobody needs to implement any posting anymore or something so that we can just plug and play such a QA system or such a semantic role labeling system and so on.",
            "That's going to.",
            "I'm looking forward to that, just was more about so.",
            "Doesn't follow and perfectly from the sentiment about maybe we can remove the post tracking, but I was thinking in terms of capturing real language questions from a directly from human.",
            "There's been a move towards using speech recognition to try and get samples of natural language queries 'cause we know people aren't very good at formulating well.",
            "We've trained people badly.",
            "Formulating queries for web search engines.",
            "So how sensitive do you have any idea or intuition to how sensitive the system is too?",
            "Noisy input that might come from a speech recognition.",
            "Yes, we do have.",
            "We implement basically currently ADI mode is on the one hand side based on speech recognition, but is not yet finished.",
            "So I do not have any insights yet, but a serious project from the University.",
            "I forgot that some nearest in US have to serious project at the Clarity Labs.",
            "Just check it out.",
            "Amazing speech recognition.",
            "It's open source.",
            "We're going to use that probably, but what we did is we insert manually some typos, but it didn't make it to the evaluation and typos are killer for dead system currently because it does not account for that, but just using simple features like the leucine fuzzy query or something would leverage there then.",
            "Can overcome this problems but I think.",
            "What we are now preparing is systems that can answer complex Cruz, but I've also assume that just maybe next year, maybe the year after first people will then start to use complex queries on Google and so on.",
            "So we do know the basis and then the other guys can do the speech input.",
            "OK, thanks very much.",
            "So let's thank the speaker again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Welcome everybody to my talk about question answering, in particular about hybrid question answering.",
                    "label": 0
                },
                {
                    "sent": "This is joint work.",
                    "label": 0
                },
                {
                    "sent": "Together with accident, who's sitting back there and Lawrence Berman and Christina Romer.",
                    "label": 0
                },
                {
                    "sent": "Christine almost from the University of Peter Fed.",
                    "label": 0
                },
                {
                    "sent": "Axel Lawrence and I are from the University of Leipzig, especially from the CSW group.",
                    "label": 0
                },
                {
                    "sent": "So the motivation behind making.",
                    "label": 0
                },
                {
                    "sent": "Yet another hybrid question answering system or another question answering system is.",
                    "label": 1
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That we can make use of hyper data sources, in particular, the document web has grown for the last 20 years and amounts up to several tons of petabytes of data.",
                    "label": 0
                },
                {
                    "sent": "But those petabytes of data, unstructured in nature and hard for machines to read, so it's very hard for question answering systems to extract semantics from those unstructured documents.",
                    "label": 0
                },
                {
                    "sent": "On the other hand side, we got the link data web, which is highly structured as semantic annotations, or is full of semantic information and makes it.",
                    "label": 0
                },
                {
                    "sent": "Easier for us to answer information needs.",
                    "label": 0
                },
                {
                    "sent": "However we have the misalignment mismatch between the linked data web and the document itself.",
                    "label": 0
                },
                {
                    "sent": "And so if you consider the example question up there, in which City was the assessment of Martin Luther King born?",
                    "label": 1
                },
                {
                    "sent": "You will see that you need information from both websites to find an answer.",
                    "label": 0
                },
                {
                    "sent": "So Martin Luther King with many knowledge about him from the DB pedia, meminisse semantic knowledge.",
                    "label": 0
                },
                {
                    "sent": "But if we want to find out who the assessment of Martin Luther King is, we have to go to the document Web in particular to the Wikipedia article of James Orlene who assassinated Martin Luther King.",
                    "label": 0
                },
                {
                    "sent": "And then go back to Link data Web to link from this person to his birthplace to answer this complex query.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And yesterday night I tried to put this rather complex query to Google and Google will not find any results for you, so at least not entities or your eyes.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we designed talk.",
                    "label": 0
                },
                {
                    "sent": "The first hybrid question answering system that combines fulltext search and link data search.",
                    "label": 1
                },
                {
                    "sent": "With each other and results in the list of entity, your eyes in particular.",
                    "label": 0
                },
                {
                    "sent": "Please keep in mind we do at that stage only entity search.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And for the rest of the talk, I will go through this eight step pipeline with you.",
                    "label": 0
                },
                {
                    "sent": "Why are all running example?",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And the first thing I want to present is how we do tokenization and how we do post tagging, reuse, rather modular pipeline to do that.",
                    "label": 0
                },
                {
                    "sent": "And we need tokenization at the first thing because we want to have a generic framework itself that can be applied to multiple languages.",
                    "label": 0
                },
                {
                    "sent": "So because not every language has white based organization, we made the module tokenization module and we use a library for more.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Lingual multilingual posting.",
                    "label": 0
                },
                {
                    "sent": "So part of speech tagging we need part of speech text in that query or in that question to find out which individuals properties or classes are there in this question and can be linked to a link data resource or the document web.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So after running post taking on our example question, you will see that every token tokenized by whitespace tokenizer ends up with one POS tech.",
                    "label": 0
                },
                {
                    "sent": "In particular, we see that Martin Luther King has been tagged as a proper noun, and the word assessment has been taken as a noun.",
                    "label": 1
                },
                {
                    "sent": "This will get important later.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the second step in our pipeline is entity annotation.",
                    "label": 0
                },
                {
                    "sent": "So what we do here is we want to find out the parts of the input questions that are that can be mapped to a semantic source, in our case to DB pedia.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "An within Hawk we use several entity annotation systems.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With respect to our example query, a good entity annotation system should be capable to find the named entity Martin Luther King Resource from DB Pedia in this question.",
                    "label": 0
                },
                {
                    "sent": "So later I will show you how much an entity annotation system can influence the question, answering quality that you get in yet.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The first step basically tells us how it is single tokens that we tokenized and that we posted or annotated.",
                    "label": 0
                },
                {
                    "sent": "This entities are linked to each other, so we make a dependency parsing as well.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Tick dependencies positives at him told us.",
                    "label": 0
                },
                {
                    "sent": "We do.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You used to clear in the P API to form a dependency argument tree, this is.",
                    "label": 0
                },
                {
                    "sent": "A tree that has one root, the roots normally and predicate in a predicate can have one too many arguments there.",
                    "label": 0
                },
                {
                    "sent": "So in our case born is the root argument, which has four predicates that are distributed.",
                    "label": 0
                },
                {
                    "sent": "This will tell us later how we can link the single semantic units to each other and how this pocket query that we want to generate has to be built up in terms of the basic graph pattern we will use.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the first step is linguistic pruning.",
                    "label": 0
                },
                {
                    "sent": "When we add.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Up with a graph like that, that's very complex to form into his pocket Curry and contains much knowledge but also much knowledge that we cannot use in some way or the other.",
                    "label": 0
                },
                {
                    "sent": "So we implemented some Horace.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "6 to get rid of.",
                    "label": 0
                },
                {
                    "sent": "Tokens that do not carry aunties and any semantic information.",
                    "label": 0
                },
                {
                    "sent": "So for example, we discard or determiners or quotation marks or we are which words and so on.",
                    "label": 0
                },
                {
                    "sent": "So that we end up with a reduced graph that contains only either way proper nouns or nouns or verbs that can be linked to classes or properties.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "But",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If I go back, you see that we only have one note that is semantically linked.",
                    "label": 0
                },
                {
                    "sent": "However, making now a fulltext search enter semantic search will not bring any precise results, but rather a big large amount of answers.",
                    "label": 0
                },
                {
                    "sent": "So what we?",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Need to do next is to annotate the remaining parts of the question.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With remaining parts in particular in this example I mean city Assassin and Bourne.",
                    "label": 0
                },
                {
                    "sent": "So what we did is we used something like a hymns library, so a dictionary based approach to find surface forms for properties and classes, as well as the RDF's label of ontology classes and properties.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If we now execute this module, we will find out that for example, City can stand for the DB Pedia, Ontology class City as well as the property capital.",
                    "label": 0
                },
                {
                    "sent": "The same thing holds for born Born will become either birthdate or birthplace.",
                    "label": 0
                },
                {
                    "sent": "In finance Parker query.",
                    "label": 0
                },
                {
                    "sent": "But what we did module does not find is something from the ontology that Maps to assassin.",
                    "label": 0
                },
                {
                    "sent": "It's just that simple that assassin is not modeled in the DBPR ontology.",
                    "label": 0
                },
                {
                    "sent": "That's why this gives us a.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Went to full text look up.",
                    "label": 0
                },
                {
                    "sent": "We need to do in the document work later.",
                    "label": 0
                },
                {
                    "sent": "Keep in mind that assassin would be a hybrid link to the document web.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So and this hyperlink will be created in this pocket generation module.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This module has three smaller stages.",
                    "label": 0
                },
                {
                    "sent": "At first you will find or you go through each of these semantic models and bid for each node triple pattern.",
                    "label": 0
                },
                {
                    "sent": "That is, you take every annotation from each of the semantic nodes and put in subject, predicate and object position and put the trip to new sparkle query.",
                    "label": 0
                },
                {
                    "sent": "So after doing that, you end up with basically the number of annotations, spark queries and do now and forward a cross product between order semantic units so that you could combine every possible combination of a semantic annotation with every other possible annotation.",
                    "label": 0
                },
                {
                    "sent": "But still we have a gap here and it is the document web.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "What we use is the fuzzy keystore, which allows us to index large amounts of text data and query them via once in his pocket query.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we do a full text filter for assassin overall entities and their concise bank descriptions made out of full text information.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now that we got all this pocket queries, Hawk will produce a large, rather large number or large set of spark queries to reduce the number of spark trees we can use our DFS and over our knowledge to rid.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Use the number of sparkers post to the end point.",
                    "label": 0
                },
                {
                    "sent": "Film in particular.",
                    "label": 0
                },
                {
                    "sent": "We assume the disjointness of classes and discard invalid sparkle queries.",
                    "label": 0
                },
                {
                    "sent": "You can imagine that if you combine the info cross product of orders annotations, you end up with spark increases.",
                    "label": 0
                },
                {
                    "sent": "Just make no sense and return null sets and before posing them to the end point we can discard them by using the DL learner framework that has been developed.",
                    "label": 0
                },
                {
                    "sent": "Their case www.org.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I'm after doing that.",
                    "label": 0
                },
                {
                    "sent": "You see that, for example, capital, the property capital will be removed, since we assume that the first argument of predicate in this dependency tree has to be a type information.",
                    "label": 0
                },
                {
                    "sent": "Most often you begin your query by specifying an RDF type.",
                    "label": 0
                },
                {
                    "sent": "We do that just by.",
                    "label": 0
                },
                {
                    "sent": "Nature.",
                    "label": 0
                },
                {
                    "sent": "And what we also delete is the dear DP ontology birthday property.",
                    "label": 0
                },
                {
                    "sent": "Why do we do that?",
                    "label": 0
                },
                {
                    "sent": "Well, we assume that the projection variable variable that returns the result is an entity and entity, and Uriah birthdate has just as a result, most often literal value.",
                    "label": 0
                },
                {
                    "sent": "So we can discard it safely without losing any precision.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And after doing that for those that safe in 1000 Spark pictures, we still end up with 5000 Spark queries and Hawk now has the task to find out which Sparkle query is most matching to the natural language input question.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we need to rank those set of spark queries for ranking as a first approach to Hyper Question answer, we just use the feature based ranking.",
                    "label": 1
                },
                {
                    "sent": "So we calculate 5 simple features on this pocket query.",
                    "label": 0
                },
                {
                    "sent": "That is the number of terms, the number of constraints, the number of how many text filters you used and so on.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "By doing that, we get a ranked list of sparkle queries and we can now fire once purgatory after the year other until we reach, let's say, a valuable result or something like that.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And what you see here is it's rather simple pipeline that Hawk employees currently, but we wanted to know how good are we.",
                    "label": 0
                },
                {
                    "sent": "So we evaluated our approach in three different categories.",
                    "label": 0
                },
                {
                    "sent": "The first category is that we wanted to find out how big is the influence of entity annotation system to the question answering system itself.",
                    "label": 0
                },
                {
                    "sent": "The second thing is we wanted to find out assuming an optimal ranking, are we able to produce this pocket query?",
                    "label": 0
                },
                {
                    "sent": "And the third thing is, given a set of spark queries, how good is our ranking function?",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we set up a question answering over linked data, four benchmark set, which I'm already used.",
                    "label": 0
                },
                {
                    "sent": "So maybe it's going to be used in the first talk as well, and this consists of specially 25 hybrid training queries as well as ten test queries.",
                    "label": 0
                },
                {
                    "sent": "But we will only use those 45 queries for the annotation part since we have to discard all non entity queries that demand the aggregation and that human geography types so that we end up with 17 questions that contain only entity knowledge.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So the first step is how good is the entity annotation system?",
                    "label": 0
                },
                {
                    "sent": "We compared four different systems, namely, take me folks to Wikipedia Minor.",
                    "label": 0
                },
                {
                    "sent": "In spotlight you should know at least one of them.",
                    "label": 0
                },
                {
                    "sent": "To see how good do they perform and is also assuming an optimal ranking, what we found out is that Fox performs best and delivers us over those 35 queries and F measure of oh .68, which is quite astonishing.",
                    "label": 0
                },
                {
                    "sent": "But what was more interesting is that an optimal handcrafted annotator that is in annotator that we.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that we manually implemented that finds always the correct entities, just have an S measure that is lower by 10% sold by OH point 5.",
                    "label": 0
                },
                {
                    "sent": "At 8:00 but that means basically, is that this optimal annotator annotates too much entities, and for some questions that's why the hybrid task, you just need some fulltext look up, otherwise you cannot get to the point in the graph, but you will find the correct entities.",
                    "label": 0
                },
                {
                    "sent": "And most surprising to us was that the union of all four annotation system resides in low F measure of oh point.",
                    "label": 0
                },
                {
                    "sent": "1 This is if you combine all entity annotations from all four systems, you get only information about individuals or on the information about entities, but no information about classes or properties anymore.",
                    "label": 0
                },
                {
                    "sent": "And this pocket query containing only of resources but only of in the widgets but not of classes and properties will not find you anything else.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So, knowing that we used folks on our 17 questions and I hope you can read them well.",
                    "label": 0
                },
                {
                    "sent": "Otherwise I read them, load out out loud an so we wanted to know how good can we create this pocket queries.",
                    "label": 0
                },
                {
                    "sent": "Are we able to create at all this pocket race that can deliver us answers and we see so in two cases, specially the red lines that we are not able to generate this pocket queries yet that is most often due to the structural.",
                    "label": 0
                },
                {
                    "sent": "We had the structural dependencies in such sentences.",
                    "label": 0
                },
                {
                    "sent": "For example, give me the currencies of all G8 countries is just a whole different dependency argument re.",
                    "label": 0
                },
                {
                    "sent": "Then we age query dependency argument trees or the question who composed the music for the film that depend that depicts the early life of Jane Austen just contains an auxiliary sentence in this auxiliary sentence is just way too complicated for hop to answer because the dependency argumenty entry just explodes.",
                    "label": 0
                },
                {
                    "sent": "Or the blue queries return recall of 1 but have a low precision.",
                    "label": 0
                },
                {
                    "sent": "This is most often do we find all entities, but we find also a lot of noise.",
                    "label": 0
                },
                {
                    "sent": "Currently we can get rid of that by using just a better entity annotation system or a better class annotation system.",
                    "label": 0
                },
                {
                    "sent": "So our dictionary is not perfect yet.",
                    "label": 0
                },
                {
                    "sent": "We're going to evaluate it in a later stage.",
                    "label": 0
                },
                {
                    "sent": "And the fourth thing or the third thing I want to point out is that the cream query just returns the precision of 1, but the recall of just 50% ending up in an F measure 4.6 seven for the question of of the people that died of radiation in Los Alamos, whose death was an accident.",
                    "label": 0
                },
                {
                    "sent": "Well, there the benchmark is.",
                    "label": 0
                },
                {
                    "sent": "Made on DB Pedia 3.9 while we were testing against Peter 2014 and just some information got lost by the benchmark so it's important for the community of question answering also to keep up with the current development and to create its benchmarks.",
                    "label": 0
                },
                {
                    "sent": "All other White Rose that you see could be answered completely within F measure of 1.",
                    "label": 0
                },
                {
                    "sent": "So out of the 17 queries we are able to answer 89 queries correctly just in a million.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yeah, I know.",
                    "label": 0
                },
                {
                    "sent": "Overall F measure is oh point 70.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The first thing we wanted to know is.",
                    "label": 0
                },
                {
                    "sent": "So knowing that entity annotation is important, knowing that we are able to at least get answers with an F measure of oh point 7 two or we are able to generate this pocket queries.",
                    "label": 0
                },
                {
                    "sent": "How good is our ranking that means in a production real life environment, how good can we decide which sparkle query is the correct sparker that Maps the natural language input?",
                    "label": 0
                },
                {
                    "sent": "And this what we you can see here is on the X axis number of Sparky crates.",
                    "label": 0
                },
                {
                    "sent": "You have to look at to get a correct result and what you see is that in a window of the first 10 spark queries out of thousands of spark queries we are able to reach already F measures of OH point 5.",
                    "label": 0
                },
                {
                    "sent": "Especially the number of constraints is important, so our tool tends to use more constraints than it should.",
                    "label": 0
                },
                {
                    "sent": "Making the precision lower so the number of constraints is a very important feature for ranking, but what happen?",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "If we now combine several of those features, you see that within the window of just the first 10 sparkle queries for one natural language question question, we are able to reach F measures at oh point 6 or oh .65.",
                    "label": 0
                },
                {
                    "sent": "At least it's better just by combining two of those rather simple feature based things that you can calculate in milliseconds on sparkle query.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Overall, but I wanted to present to you is Hawk another modular question answering system for hybrid questions currently and what you also have seen is that we face several challenges.",
                    "label": 0
                },
                {
                    "sent": "For example, the training and benchmark datasets for hybrid queries using the document web and the link data web is rather small.",
                    "label": 0
                },
                {
                    "sent": "Even the QLD 5 benchmark set has just 50 questions currently that pertain to hybrid question answer for them or what we're going to do right now is we.",
                    "label": 0
                },
                {
                    "sent": "Gonna extend types of answers that Hawks gonna answer or is able to answer so we do also ask queries as well as queries that return non entity types.",
                    "label": 0
                },
                {
                    "sent": "The third thing that is important is we need to improve the ranking system.",
                    "label": 0
                },
                {
                    "sent": "You cannot currently use machine learning because just 50 examples are not enough to train any valid machine learning algorithm on the ranking system.",
                    "label": 0
                },
                {
                    "sent": "So we're looking for intelligent ways to form to let our algorithms rank this public race.",
                    "label": 0
                },
                {
                    "sent": "And at last we want to extend the QA ecosystem.",
                    "label": 0
                },
                {
                    "sent": "But we want to do is we want to.",
                    "label": 0
                },
                {
                    "sent": "Implement more modules for each of the eight stages you have seen, just to make cross product of all those.",
                    "label": 0
                },
                {
                    "sent": "Modules to see which modules performs best over which other modules.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in the end, I want to thank you for listening to me, and if you want to have updates on Hawk or did your learner or any other thing pertaining to HSW Group, please follow us on Twitter and find more information on the project site in the GitHub repository and now I'm happy to get questions from you.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Just have a native questions regarding sort of.",
                    "label": 0
                },
                {
                    "sent": "Did you perform a qualitative analysis for the questions that you couldn't really answer?",
                    "label": 0
                },
                {
                    "sent": "'cause, for example, coming from the QLD?",
                    "label": 0
                },
                {
                    "sent": "He sets an imp articular compare.",
                    "label": 0
                },
                {
                    "sent": "We've numerous over systems that Aftac whip khakis, but there are many offers.",
                    "label": 0
                },
                {
                    "sent": "Yeah, 'cause he's an so on TBS right?",
                    "label": 0
                },
                {
                    "sent": "And sweep, which is really a similar approach.",
                    "label": 0
                },
                {
                    "sent": "Then you have OK, interesting.",
                    "label": 0
                },
                {
                    "sent": "So the first thing you ask us whether we did a qualitative analysis.",
                    "label": 0
                },
                {
                    "sent": "Yeah we did that.",
                    "label": 0
                },
                {
                    "sent": "That can also be found in the paper.",
                    "label": 0
                },
                {
                    "sent": "It basically found out that several.",
                    "label": 0
                },
                {
                    "sent": "Minor mistakes lead to this low F measure, for example, not matching a particular class of property.",
                    "label": 0
                },
                {
                    "sent": "So matching the string to or mapping the string from to the ontology files, which is just based on the few examples we got already, because quality is quite slow for.",
                    "label": 0
                },
                {
                    "sent": "Again, the hybrid question answering thing.",
                    "label": 1
                },
                {
                    "sent": "An I have to say I forgot the second question.",
                    "label": 0
                },
                {
                    "sent": "So yeah, no.",
                    "label": 0
                },
                {
                    "sent": "It was because of comparing to other systems.",
                    "label": 0
                },
                {
                    "sent": "Yeah, yeah, we tried to push just some of the quite for hyper questions to, for example, TSS, INA, and other systems that took part in.",
                    "label": 0
                },
                {
                    "sent": "But since everything question from this particular benchmark demands a hybrid.",
                    "label": 0
                },
                {
                    "sent": "An answer, so at least every spark redim, ands or higher full text look up into the Wikipedia are tickets.",
                    "label": 0
                },
                {
                    "sent": "No system was able to answer any of those questions, it was just no.",
                    "label": 0
                },
                {
                    "sent": "Not possible for them to do that because they do not look into the Wikipedia fulltext articles.",
                    "label": 0
                },
                {
                    "sent": "Yes, I just want to know why you have chosen to do post tagging with clear NLP rather than use open NLP, did you?",
                    "label": 0
                },
                {
                    "sent": "See are any use case or study that shows that?",
                    "label": 0
                },
                {
                    "sent": "It is better than the other know.",
                    "label": 0
                },
                {
                    "sent": "Basically not.",
                    "label": 1
                },
                {
                    "sent": "It was a tool at hand at that time, but as I said, we want to do a or we want to extend the QA ecosystem.",
                    "label": 0
                },
                {
                    "sent": "But we're going to launch next month.",
                    "label": 0
                },
                {
                    "sent": "Probably is a ontology based description of all the modules so that you can just then go and plug and play other modules for posting for entity annotations on a project we're doing knows already 15 different entity annotation system, so we're eager to see which of those 15 systems performs best over the phone.",
                    "label": 0
                },
                {
                    "sent": "We test already.",
                    "label": 0
                },
                {
                    "sent": "So we're going to extend it and invite everybody of you to write modules, and then we can maybe show Google how to answer complex queries with semantic web tools and you just cite some of the entity recognition systems that you have used.",
                    "label": 0
                },
                {
                    "sent": "Sorry I just.",
                    "label": 0
                },
                {
                    "sent": "Yeah, sure, for entity annotation we used in particular the technique system that is made by.",
                    "label": 0
                },
                {
                    "sent": "Paulo Ferry now if I'm not wrong, folks that disturbance on ballooning tool accidentally expect developed their Crestview to Wikipedia minor that is known from could certain from 2008 and DBP spotlight.",
                    "label": 0
                },
                {
                    "sent": "Of course, I hope everybody will know that.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Did you compare this with Watson?",
                    "label": 0
                },
                {
                    "sent": "I think I have to go.",
                    "label": 0
                },
                {
                    "sent": "No, I did not.",
                    "label": 0
                },
                {
                    "sent": "The reason why is basically Watson is a paid API and we were not able yet to figure out with the team of IBM Watson I research contract so that we can use the API for for more tests, but we are eager to see that.",
                    "label": 0
                },
                {
                    "sent": "So if anybody has a IBM Watson account please talk to me.",
                    "label": 0
                },
                {
                    "sent": "Yeah we can talk later.",
                    "label": 0
                },
                {
                    "sent": "Knowing so, maybe it's more common that I always have it see this because I always always have to deal with this as well.",
                    "label": 0
                },
                {
                    "sent": "All this kind of system is also the one I presented this building on a lot of different components, so it would be good too if you're talking about benchmarks also to come up with some kind of whatever subtasks, or at least some kind of components that are standardized to some extent.",
                    "label": 0
                },
                {
                    "sent": "Cause it's a lot of work to put something like this together and if you want to compare the whole approach to another approach.",
                    "label": 0
                },
                {
                    "sent": "It's really hard to say, OK, yours is better becausw whatever this component and there is better and so it it's getting really, really difficult to compare this stuff.",
                    "label": 0
                },
                {
                    "sent": "And I think we need to.",
                    "label": 0
                },
                {
                    "sent": "Have some top down approach to think about how to do this.",
                    "label": 0
                },
                {
                    "sent": "As a community is also really complex to analyze such a system and say this particular module performs worse or bed and if I changed it exactly and every time you submit a paper you get reviews.",
                    "label": 0
                },
                {
                    "sent": "Why didn't you compare to this this and this?",
                    "label": 0
                },
                {
                    "sent": "And yeah, I compared it to but I compared to this visit.",
                    "label": 0
                },
                {
                    "sent": "This of course could be better or worse and it's always hard to like maneuver around how you say, OK, this is our contribution and.",
                    "label": 0
                },
                {
                    "sent": "That's true, So what we're basically, I think all are looking forward is the ecosystem, maybe based on RDF to have different services already in place, so nobody needs to implement any posting anymore or something so that we can just plug and play such a QA system or such a semantic role labeling system and so on.",
                    "label": 0
                },
                {
                    "sent": "That's going to.",
                    "label": 0
                },
                {
                    "sent": "I'm looking forward to that, just was more about so.",
                    "label": 0
                },
                {
                    "sent": "Doesn't follow and perfectly from the sentiment about maybe we can remove the post tracking, but I was thinking in terms of capturing real language questions from a directly from human.",
                    "label": 0
                },
                {
                    "sent": "There's been a move towards using speech recognition to try and get samples of natural language queries 'cause we know people aren't very good at formulating well.",
                    "label": 0
                },
                {
                    "sent": "We've trained people badly.",
                    "label": 0
                },
                {
                    "sent": "Formulating queries for web search engines.",
                    "label": 0
                },
                {
                    "sent": "So how sensitive do you have any idea or intuition to how sensitive the system is too?",
                    "label": 0
                },
                {
                    "sent": "Noisy input that might come from a speech recognition.",
                    "label": 0
                },
                {
                    "sent": "Yes, we do have.",
                    "label": 0
                },
                {
                    "sent": "We implement basically currently ADI mode is on the one hand side based on speech recognition, but is not yet finished.",
                    "label": 0
                },
                {
                    "sent": "So I do not have any insights yet, but a serious project from the University.",
                    "label": 0
                },
                {
                    "sent": "I forgot that some nearest in US have to serious project at the Clarity Labs.",
                    "label": 0
                },
                {
                    "sent": "Just check it out.",
                    "label": 0
                },
                {
                    "sent": "Amazing speech recognition.",
                    "label": 0
                },
                {
                    "sent": "It's open source.",
                    "label": 0
                },
                {
                    "sent": "We're going to use that probably, but what we did is we insert manually some typos, but it didn't make it to the evaluation and typos are killer for dead system currently because it does not account for that, but just using simple features like the leucine fuzzy query or something would leverage there then.",
                    "label": 0
                },
                {
                    "sent": "Can overcome this problems but I think.",
                    "label": 0
                },
                {
                    "sent": "What we are now preparing is systems that can answer complex Cruz, but I've also assume that just maybe next year, maybe the year after first people will then start to use complex queries on Google and so on.",
                    "label": 0
                },
                {
                    "sent": "So we do know the basis and then the other guys can do the speech input.",
                    "label": 0
                },
                {
                    "sent": "OK, thanks very much.",
                    "label": 0
                },
                {
                    "sent": "So let's thank the speaker again.",
                    "label": 0
                }
            ]
        }
    }
}