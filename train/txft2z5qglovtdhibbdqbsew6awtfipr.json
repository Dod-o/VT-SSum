{
    "id": "txft2z5qglovtdhibbdqbsew6awtfipr",
    "title": "Identifying the Components",
    "info": {
        "author": [
            "Matthijs van Leeuwen, Utrecht University"
        ],
        "published": "Oct. 20, 2009",
        "recorded": "September 2009",
        "category": [
            "Top->Computer Science->Machine Learning"
        ]
    },
    "url": "http://videolectures.net/ecmlpkdd09_van_leeuwen_itc/",
    "segmentation": [
        [
            "The title of this talk is identifying the components.",
            "This is joint work with illustration and she was sitting over there.",
            "My name is indeed the massage flavor.",
            "We're all from the algorithmic data, another group in Utrecht in the Netherlands, so identifying what do we mean by."
        ],
        [
            "What are we talking about?",
            "Anne.",
            "Most data mining algorithms.",
            "That's a certain database input database is drawn from a single data distribution.",
            "However, in practice many or maybe even most or all database are mixtures of samples from different distributions.",
            "And we have seen in.",
            "In history that's model set.",
            "Take this into account are in general spirit superior to mobile stats?",
            "Do not take this into account, so we thought, well, maybe it's a good idea to see if we can find these components that together make up the database and this is the main question that we would like to solve address in this presentation in this talk.",
            "But before we do that, I would like to have a closer look at the problem at hand, so."
        ],
        [
            "For example, if you look at supermarket Basket data, no need to explain that probably to you.",
            "We have baskets, people buy basket with products of different items and if we look at such a database containing supermarket, supermarket, basket data, then we expect to have a mixture of different buying patterns.",
            "So for example, if we look at what people retired people by then, we expect different collections of items to be in there in their baskets then.",
            "Which households with young children by but there might also be overlap, because, well, most people eat bread or pasta or stuff like that so.",
            "This is just one example, of course, I think that's probably the same can be said for PhD students and professors, if only because professors have much more money to spend so.",
            "Our goal is to find these groups of people and not only to find these proofs, but we also want to give insight in their corresponding buying behaviors.",
            "We want to know what is going on in there and also to know well what is the difference between these different groups.",
            "Different components that together make up the database.",
            "So maybe you think now you're wondering, is this not?",
            "Frequent item set mining or clustering or mixture modeling."
        ],
        [
            "No, it's different.",
            "Let me explain.",
            "If we look at frequent itemsets mining is very useful for characterizing data with patterns.",
            "Actually lots of patterns usually, but it cannot help you easily to find groups.",
            "Components that make up a database or the other hand.",
            "Clustering is very good at this.",
            "You can use it to find homogeneous groups, but it does not characterize groups often.",
            "Usually an very often it also requires a distance measure.",
            "While this is not not always easy to specify, especially for transaction data.",
            "Then we have mixture modeling which does characterize an find homogeneous groups, but here we.",
            "Often need to.",
            "Predefined distributions typical types, like a Gaussian or binary distributions, and this strongly limits the type of groups that you can find in their data.",
            "So.",
            "We want to do something different."
        ],
        [
            "What's our plan?",
            "What to do?",
            "Informally, we would like to.",
            "Given a database, we would like to partition this database DB into a set of databases.",
            "Did we want to DBK such that each of these?",
            "Database is different compared to the rest solely behind buying behavior in each of these components is different from the buying behavior in all other components well within search component the data should be homogeneous.",
            "Everything should be very much very well fit together."
        ],
        [
            "A second requirements that we have here is that we would like to avoid any para meters.",
            "We don't want to specify.",
            "How many components are there?",
            "We often don't know.",
            "We want the algorithm to find this out by itself."
        ],
        [
            "So this is very nice, but how do we achieve this?",
            "Our tool, as you may know by now, aren't already spoke about this.",
            "Two days ago we use compression.",
            "If we have a database which is very mixed, it should make sure of different distributions.",
            "Then it's very hard to compress this database.",
            "Add South compression is low.",
            "On the other hand, if there's a lot of structure in a database or server homogeneous then we can very well compress it and then compression is high.",
            "So we use the minimum description length principle.",
            "Which uses lossless compression.",
            "So we compress all data.",
            "We do not throw away anything, an basically the minimum description length principle says that given the data and the set of model set of models, the best model is that model that compresses the data best.",
            "So we're going to look for models that both partition the data while compressing them very well.",
            "The compressor we will use in this talk is called crimp.",
            "Kim, actually from a Dutch four to shrink an using NDL.",
            "It finds small pattern sets that characterize the data very well.",
            "We have introduced this algorithm before an these small pattern sets that compress well are called code tables.",
            "These are our models, so in this talk we will use sets of code tables as our models."
        ],
        [
            "Which you can see in the next slide, which shows our formal problem statement.",
            "That is, we would like to find a partitioning DB, one to DBK of database DB together with a set of associated code tables CTCK such that the total encoded size of each component, each ship database with its own code table is minimized.",
            "So here we should note that because we take the sum of the size of both the code tables in the components encoded with their code tables, we are also taking the size of the models to the code tables into account.",
            "So by minimizing this we're looking for a model that is as simple as possible.",
            "And here it looks as if maybe we should specify a value for K, But this is not true because we can simply try all values of K and then choose that K that minimizes the total increase size.",
            "So with this problem statement.",
            "We seem to solve the problem, but."
        ],
        [
            "Well, there are many possible partitioning of a database and there are also many many possible quote tables.",
            "So we are facing a huge search base here.",
            "So we have to use some heuristics an actually we found two approaches to.",
            "Use for this problem.",
            "One is by looking at the model and going on from there and the other one is to take the data.",
            "The database is.",
            "Start with some random components and then optimize those on the fly.",
            "We will see both of."
        ],
        [
            "These algorithms now and some results.",
            "So the first algorithm, the model different one.",
            "Here we have.",
            "A database which we compress to get a code table.",
            "Now the principle here is that the assumption if our database is a mixture of distributions, then the code table that we induce from this database should also be a mixture of models in this case.",
            "So if we have here a model, a code table.",
            "That is a mixture of quotables.",
            "We should be able to somehow extract all these components from that model, and that's what we do here.",
            "As you may remember, a code table is actually a pattern set, so a couple of 100 patterns associated with coach to compress the database.",
            "So we thought we would like to do here is to find subsets of this original code table on the complete database.",
            "That are specific for distributions we didn't.",
            "That's original database.",
            "We do this by first copying the original code table K times.",
            "So we have K Co tables.",
            "Now we need some way to.",
            "Assign the database all transactions in the original database.",
            "To each of these components, because the components are in this setting specified by the code tables by the models.",
            "Well, as we had if we have K Co tables then we can compress all transactions.",
            "Which were in the database with each of these code tables, and we can simply say a transaction belongs to that model.",
            "That code table that compresses it best.",
            "So again we use compression here to determine what the component should be.",
            "OK, so we now have a way to partitioning.",
            "And the database operational database.",
            "And now the idea is to have iterations.",
            "To remove patterns from a code table.",
            "So in each round each iteration we consider each pattern in each code table for removal.",
            "So we remove it from the code table it is in, and then we.",
            "Compute the new encoded.",
            "Total size and then we do this for all possible removals and then we decide well the pattern that gives the largest gain in compression.",
            "That one is the best one right now.",
            "We remove it.",
            "And then we proceed to the next iteration, so this way.",
            "We allow the Co tables to get rid of some redundant.",
            "Better instead are covered by other code tables, other models and we end up with smaller code tables that are more specialized to specific distributions in the original database."
        ],
        [
            "So that's the algorithm.",
            "Let's have a look at some results of this.",
            "44 databases from the UCI repository.",
            "You can see how many transactions are in each of the databases and also the optimal K that was automatically determined by NDL and you can see that the number of components is actually not that large up to 20 components is still something that can be handled.",
            "By experts can give insight.",
            "The most important, I think is indicated in green, because this is the gain in compression relative to the single component compression.",
            "So this is the different but the percentage in compressing the database as a single component with crimp to the multi component.",
            "Compressor So what you see is for mushroom.",
            "For example we have here 12 mobiles we have 12 code tables to encode the whole database which is partitioned overdose 12 code tables.",
            "But despite this addition of 11 code tables we still in the end gain 25% in total compressed size.",
            "So this clearly indicates that mushroom.",
            "Really contains many.",
            "Actually, 12 in this case distributions.",
            "And then on the right hand side we have some purity values.",
            "The baseline is the percentage of the majority class in the original database, and you obtain values are.",
            "What we the rate of some of the individual component purities and these are not always good, but this is not so strange 'cause a class label doesn't really have to adhere to the distribution in a database.",
            "That program for mushroom.",
            "We can see that the purity is quite good compared to baseline.",
            "So these are all numbers.",
            "Of course, we also want to see some."
        ],
        [
            "Figures from illustrations.",
            "So here's an example for a new with.",
            "K is 2, so actually we started with the code table that you see here on the left column.",
            "Each pattern.",
            "In the code table, is covered by.",
            "Certain code has a certain code attached.",
            "Here you see these codes and the width of these blue boxes represent the lengths of these codes.",
            "So for example here you see quite a long code and this one is very short and a short code means mean.",
            "That's the pattern occurs very often in the database, while a longer code means that it occurs less frequently in a database.",
            "That's how it works.",
            "An then in the middle and on the right you see the two code tables that were extracted from this original code table on the left.",
            "And what we can see here is that it really seems that there actually are multiple components hidden in this original code table.",
            "So our assumption that the code table the model would be a mixture of models seems to be true, because here we have two code tables that are really specialized to subsets of these of this database and well.",
            "It's also good, actually, that we allow patterns to be in multiple components, because the Red Arrows Mark samko table elements that are in both code tables.",
            "So I just meant that seems to work quite well."
        ],
        [
            "But we have a second method which is data driven.",
            "This yes this case.",
            "We start with the database and this.",
            "Methods resembles a bit K means, but then without the need to specify K or a different measure, because we first randomly split the database into K components.",
            "And now the important thing here is that.",
            "The principle this algorithm works on is that if a certain compressor has seen more.",
            "And transactions from a particular distribution, then a second compressor, then this first compressor will compress these transactions better than the other one.",
            "So by randomly splitting the database in 2K components and then compressing each of these components to obtain K code tables, we get compressors that are biased to some specific distributions because, well, it would be.",
            "It's very unlikely that each of these components has.",
            "Except the same amount of distributions, East, same amount of transactions from all these distributions.",
            "So we get these code tables and then again we repartition the database.",
            "So for each partition.",
            "For each transaction, I should say we look.",
            "We compress it with all code tables and then we say, well, we assign it again to the code table that gives it the shortest encoded length, and this way we get new components which we can again compress and this way we thoroughly optimize until.",
            "No more improvements can be made."
        ],
        [
            "Again, some results.",
            "Oh, it's quite similar to the results we obtained with the model driven approach for adults.",
            "We get quite good gaining compression with quite some components.",
            "In this case an for mammals.",
            "This is also geographic data set.",
            "We get quite a large gain in compression if we use.",
            "Six components too.",
            "To compress it."
        ],
        [
            "And this data set is especially nice as we can use it to easily visualize what is going on here.",
            "You may know it or not.",
            "It's a geographic data set which contains data on 121 European memos.",
            "An each transaction represents a GRID location in Europe of about 50 by 50 kilometers, an for each GRID location.",
            "The data only says which animals are present there.",
            "Or not.",
            "And that's all.",
            "That's the algorithm, new when it's made this picture without knowing becausw, the components are made only based on the presence of these mammals.",
            "And if we look at these components then there are really nicely drawn here because.",
            "They are continuous there.",
            "Graphics sound the.",
            "They are one of the North there one in the South, so climate methods, region matters and without knowing anything about location, the algorithm found these components."
        ],
        [
            "So to conclude this talk we showed that compression can be used to identify the components that together make up a database.",
            "Each sample distribution that are going to finds is characterized by a model, a small pattern set that characterizes the data well.",
            "We don't need any prior knowledge.",
            "No distance measure is quiet, and the optimal number of components is determined automatically and we showed two algorithms.",
            "Let's do this one from a mobile perspective, another one from a data perspective, and experiments showed that this works."
        ],
        [
            "So.",
            "Thank you.",
            "1st.",
            "Work relates to Shimada Lee and you think of the components as distributions in the mixture.",
            "Well, yes, I showed on the.",
            "One of the first slides it's related to mixture modeling, but then we don't need to specify any distributions in advance and, well, it works easily for transaction data also fits.",
            "Compare the results empirically.",
            "If you give your data to a mixture modeling tool and then to your tool and we haven't done that yet.",
            "Will start the supermarket if you apply to supermarket.",
            "Actually this there's one data set.",
            "The retail data set that we apply to two, but for this no labels refillable so we could not really inspect what was going on in there.",
            "And then you could have it because the market is they have appeared in market segments.",
            "Yes.",
            "Unfortunately, the providers of the data needed sleep information about.",
            "One of the biggest.",
            "It was actually for testing construction induction algorithms, and it's not the nursery consisted by tables that related attributes but not examples.",
            "So an idea would be to compare the compression the degree of compression of the regional representation with the one with you.",
            "Have you tried it before?",
            "Well, the most important thing here is that compression is only a means to an end, so it's not.",
            "Compression is not the goal here, but it's about well finding these components and characterizing them, and the compression itself is not really what we're interested in.",
            "Yes, I was wondering whether instead of using that partitioning that you have now.",
            "You could also use like a set of overlapping subgroups, visual components.",
            "Sometimes.",
            "People may fit into two components or into 2.",
            "Well, it's of course a nice idea, but the difficult thing here is that makes computation even more difficult.",
            "Now we use compression to assign transactions to, well, the best model.",
            "Actually the best components, but then you would have to say, well, if compression is more or less similar for two code tables, then we can assign it to both more or less something like that, but it makes life more difficult.",
            "So if you think example of items purchased by users, would you say that your method will partition users according to their preferences or partition items according to their categories?",
            "Or none of that.",
            "Well, here we are grouping the transaction.",
            "So then it's about only about the products that you buy an not looking about groups of products.",
            "It's only about groups of people in this case."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The title of this talk is identifying the components.",
                    "label": 1
                },
                {
                    "sent": "This is joint work with illustration and she was sitting over there.",
                    "label": 0
                },
                {
                    "sent": "My name is indeed the massage flavor.",
                    "label": 0
                },
                {
                    "sent": "We're all from the algorithmic data, another group in Utrecht in the Netherlands, so identifying what do we mean by.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What are we talking about?",
                    "label": 0
                },
                {
                    "sent": "Anne.",
                    "label": 0
                },
                {
                    "sent": "Most data mining algorithms.",
                    "label": 0
                },
                {
                    "sent": "That's a certain database input database is drawn from a single data distribution.",
                    "label": 0
                },
                {
                    "sent": "However, in practice many or maybe even most or all database are mixtures of samples from different distributions.",
                    "label": 1
                },
                {
                    "sent": "And we have seen in.",
                    "label": 0
                },
                {
                    "sent": "In history that's model set.",
                    "label": 1
                },
                {
                    "sent": "Take this into account are in general spirit superior to mobile stats?",
                    "label": 0
                },
                {
                    "sent": "Do not take this into account, so we thought, well, maybe it's a good idea to see if we can find these components that together make up the database and this is the main question that we would like to solve address in this presentation in this talk.",
                    "label": 0
                },
                {
                    "sent": "But before we do that, I would like to have a closer look at the problem at hand, so.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "For example, if you look at supermarket Basket data, no need to explain that probably to you.",
                    "label": 0
                },
                {
                    "sent": "We have baskets, people buy basket with products of different items and if we look at such a database containing supermarket, supermarket, basket data, then we expect to have a mixture of different buying patterns.",
                    "label": 1
                },
                {
                    "sent": "So for example, if we look at what people retired people by then, we expect different collections of items to be in there in their baskets then.",
                    "label": 0
                },
                {
                    "sent": "Which households with young children by but there might also be overlap, because, well, most people eat bread or pasta or stuff like that so.",
                    "label": 0
                },
                {
                    "sent": "This is just one example, of course, I think that's probably the same can be said for PhD students and professors, if only because professors have much more money to spend so.",
                    "label": 0
                },
                {
                    "sent": "Our goal is to find these groups of people and not only to find these proofs, but we also want to give insight in their corresponding buying behaviors.",
                    "label": 1
                },
                {
                    "sent": "We want to know what is going on in there and also to know well what is the difference between these different groups.",
                    "label": 0
                },
                {
                    "sent": "Different components that together make up the database.",
                    "label": 0
                },
                {
                    "sent": "So maybe you think now you're wondering, is this not?",
                    "label": 0
                },
                {
                    "sent": "Frequent item set mining or clustering or mixture modeling.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "No, it's different.",
                    "label": 0
                },
                {
                    "sent": "Let me explain.",
                    "label": 0
                },
                {
                    "sent": "If we look at frequent itemsets mining is very useful for characterizing data with patterns.",
                    "label": 1
                },
                {
                    "sent": "Actually lots of patterns usually, but it cannot help you easily to find groups.",
                    "label": 0
                },
                {
                    "sent": "Components that make up a database or the other hand.",
                    "label": 0
                },
                {
                    "sent": "Clustering is very good at this.",
                    "label": 0
                },
                {
                    "sent": "You can use it to find homogeneous groups, but it does not characterize groups often.",
                    "label": 1
                },
                {
                    "sent": "Usually an very often it also requires a distance measure.",
                    "label": 1
                },
                {
                    "sent": "While this is not not always easy to specify, especially for transaction data.",
                    "label": 0
                },
                {
                    "sent": "Then we have mixture modeling which does characterize an find homogeneous groups, but here we.",
                    "label": 0
                },
                {
                    "sent": "Often need to.",
                    "label": 0
                },
                {
                    "sent": "Predefined distributions typical types, like a Gaussian or binary distributions, and this strongly limits the type of groups that you can find in their data.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "We want to do something different.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "What's our plan?",
                    "label": 0
                },
                {
                    "sent": "What to do?",
                    "label": 0
                },
                {
                    "sent": "Informally, we would like to.",
                    "label": 0
                },
                {
                    "sent": "Given a database, we would like to partition this database DB into a set of databases.",
                    "label": 1
                },
                {
                    "sent": "Did we want to DBK such that each of these?",
                    "label": 0
                },
                {
                    "sent": "Database is different compared to the rest solely behind buying behavior in each of these components is different from the buying behavior in all other components well within search component the data should be homogeneous.",
                    "label": 0
                },
                {
                    "sent": "Everything should be very much very well fit together.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A second requirements that we have here is that we would like to avoid any para meters.",
                    "label": 0
                },
                {
                    "sent": "We don't want to specify.",
                    "label": 0
                },
                {
                    "sent": "How many components are there?",
                    "label": 0
                },
                {
                    "sent": "We often don't know.",
                    "label": 0
                },
                {
                    "sent": "We want the algorithm to find this out by itself.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is very nice, but how do we achieve this?",
                    "label": 0
                },
                {
                    "sent": "Our tool, as you may know by now, aren't already spoke about this.",
                    "label": 0
                },
                {
                    "sent": "Two days ago we use compression.",
                    "label": 0
                },
                {
                    "sent": "If we have a database which is very mixed, it should make sure of different distributions.",
                    "label": 0
                },
                {
                    "sent": "Then it's very hard to compress this database.",
                    "label": 0
                },
                {
                    "sent": "Add South compression is low.",
                    "label": 1
                },
                {
                    "sent": "On the other hand, if there's a lot of structure in a database or server homogeneous then we can very well compress it and then compression is high.",
                    "label": 0
                },
                {
                    "sent": "So we use the minimum description length principle.",
                    "label": 1
                },
                {
                    "sent": "Which uses lossless compression.",
                    "label": 0
                },
                {
                    "sent": "So we compress all data.",
                    "label": 0
                },
                {
                    "sent": "We do not throw away anything, an basically the minimum description length principle says that given the data and the set of model set of models, the best model is that model that compresses the data best.",
                    "label": 0
                },
                {
                    "sent": "So we're going to look for models that both partition the data while compressing them very well.",
                    "label": 0
                },
                {
                    "sent": "The compressor we will use in this talk is called crimp.",
                    "label": 0
                },
                {
                    "sent": "Kim, actually from a Dutch four to shrink an using NDL.",
                    "label": 1
                },
                {
                    "sent": "It finds small pattern sets that characterize the data very well.",
                    "label": 0
                },
                {
                    "sent": "We have introduced this algorithm before an these small pattern sets that compress well are called code tables.",
                    "label": 0
                },
                {
                    "sent": "These are our models, so in this talk we will use sets of code tables as our models.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Which you can see in the next slide, which shows our formal problem statement.",
                    "label": 0
                },
                {
                    "sent": "That is, we would like to find a partitioning DB, one to DBK of database DB together with a set of associated code tables CTCK such that the total encoded size of each component, each ship database with its own code table is minimized.",
                    "label": 1
                },
                {
                    "sent": "So here we should note that because we take the sum of the size of both the code tables in the components encoded with their code tables, we are also taking the size of the models to the code tables into account.",
                    "label": 0
                },
                {
                    "sent": "So by minimizing this we're looking for a model that is as simple as possible.",
                    "label": 0
                },
                {
                    "sent": "And here it looks as if maybe we should specify a value for K, But this is not true because we can simply try all values of K and then choose that K that minimizes the total increase size.",
                    "label": 0
                },
                {
                    "sent": "So with this problem statement.",
                    "label": 0
                },
                {
                    "sent": "We seem to solve the problem, but.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well, there are many possible partitioning of a database and there are also many many possible quote tables.",
                    "label": 0
                },
                {
                    "sent": "So we are facing a huge search base here.",
                    "label": 0
                },
                {
                    "sent": "So we have to use some heuristics an actually we found two approaches to.",
                    "label": 0
                },
                {
                    "sent": "Use for this problem.",
                    "label": 0
                },
                {
                    "sent": "One is by looking at the model and going on from there and the other one is to take the data.",
                    "label": 0
                },
                {
                    "sent": "The database is.",
                    "label": 0
                },
                {
                    "sent": "Start with some random components and then optimize those on the fly.",
                    "label": 1
                },
                {
                    "sent": "We will see both of.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "These algorithms now and some results.",
                    "label": 0
                },
                {
                    "sent": "So the first algorithm, the model different one.",
                    "label": 0
                },
                {
                    "sent": "Here we have.",
                    "label": 0
                },
                {
                    "sent": "A database which we compress to get a code table.",
                    "label": 0
                },
                {
                    "sent": "Now the principle here is that the assumption if our database is a mixture of distributions, then the code table that we induce from this database should also be a mixture of models in this case.",
                    "label": 0
                },
                {
                    "sent": "So if we have here a model, a code table.",
                    "label": 0
                },
                {
                    "sent": "That is a mixture of quotables.",
                    "label": 0
                },
                {
                    "sent": "We should be able to somehow extract all these components from that model, and that's what we do here.",
                    "label": 0
                },
                {
                    "sent": "As you may remember, a code table is actually a pattern set, so a couple of 100 patterns associated with coach to compress the database.",
                    "label": 0
                },
                {
                    "sent": "So we thought we would like to do here is to find subsets of this original code table on the complete database.",
                    "label": 0
                },
                {
                    "sent": "That are specific for distributions we didn't.",
                    "label": 0
                },
                {
                    "sent": "That's original database.",
                    "label": 0
                },
                {
                    "sent": "We do this by first copying the original code table K times.",
                    "label": 1
                },
                {
                    "sent": "So we have K Co tables.",
                    "label": 0
                },
                {
                    "sent": "Now we need some way to.",
                    "label": 0
                },
                {
                    "sent": "Assign the database all transactions in the original database.",
                    "label": 0
                },
                {
                    "sent": "To each of these components, because the components are in this setting specified by the code tables by the models.",
                    "label": 0
                },
                {
                    "sent": "Well, as we had if we have K Co tables then we can compress all transactions.",
                    "label": 0
                },
                {
                    "sent": "Which were in the database with each of these code tables, and we can simply say a transaction belongs to that model.",
                    "label": 0
                },
                {
                    "sent": "That code table that compresses it best.",
                    "label": 0
                },
                {
                    "sent": "So again we use compression here to determine what the component should be.",
                    "label": 0
                },
                {
                    "sent": "OK, so we now have a way to partitioning.",
                    "label": 0
                },
                {
                    "sent": "And the database operational database.",
                    "label": 0
                },
                {
                    "sent": "And now the idea is to have iterations.",
                    "label": 0
                },
                {
                    "sent": "To remove patterns from a code table.",
                    "label": 0
                },
                {
                    "sent": "So in each round each iteration we consider each pattern in each code table for removal.",
                    "label": 0
                },
                {
                    "sent": "So we remove it from the code table it is in, and then we.",
                    "label": 0
                },
                {
                    "sent": "Compute the new encoded.",
                    "label": 0
                },
                {
                    "sent": "Total size and then we do this for all possible removals and then we decide well the pattern that gives the largest gain in compression.",
                    "label": 0
                },
                {
                    "sent": "That one is the best one right now.",
                    "label": 0
                },
                {
                    "sent": "We remove it.",
                    "label": 0
                },
                {
                    "sent": "And then we proceed to the next iteration, so this way.",
                    "label": 0
                },
                {
                    "sent": "We allow the Co tables to get rid of some redundant.",
                    "label": 0
                },
                {
                    "sent": "Better instead are covered by other code tables, other models and we end up with smaller code tables that are more specialized to specific distributions in the original database.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So that's the algorithm.",
                    "label": 0
                },
                {
                    "sent": "Let's have a look at some results of this.",
                    "label": 0
                },
                {
                    "sent": "44 databases from the UCI repository.",
                    "label": 0
                },
                {
                    "sent": "You can see how many transactions are in each of the databases and also the optimal K that was automatically determined by NDL and you can see that the number of components is actually not that large up to 20 components is still something that can be handled.",
                    "label": 0
                },
                {
                    "sent": "By experts can give insight.",
                    "label": 0
                },
                {
                    "sent": "The most important, I think is indicated in green, because this is the gain in compression relative to the single component compression.",
                    "label": 0
                },
                {
                    "sent": "So this is the different but the percentage in compressing the database as a single component with crimp to the multi component.",
                    "label": 0
                },
                {
                    "sent": "Compressor So what you see is for mushroom.",
                    "label": 0
                },
                {
                    "sent": "For example we have here 12 mobiles we have 12 code tables to encode the whole database which is partitioned overdose 12 code tables.",
                    "label": 0
                },
                {
                    "sent": "But despite this addition of 11 code tables we still in the end gain 25% in total compressed size.",
                    "label": 0
                },
                {
                    "sent": "So this clearly indicates that mushroom.",
                    "label": 0
                },
                {
                    "sent": "Really contains many.",
                    "label": 0
                },
                {
                    "sent": "Actually, 12 in this case distributions.",
                    "label": 0
                },
                {
                    "sent": "And then on the right hand side we have some purity values.",
                    "label": 0
                },
                {
                    "sent": "The baseline is the percentage of the majority class in the original database, and you obtain values are.",
                    "label": 0
                },
                {
                    "sent": "What we the rate of some of the individual component purities and these are not always good, but this is not so strange 'cause a class label doesn't really have to adhere to the distribution in a database.",
                    "label": 0
                },
                {
                    "sent": "That program for mushroom.",
                    "label": 0
                },
                {
                    "sent": "We can see that the purity is quite good compared to baseline.",
                    "label": 0
                },
                {
                    "sent": "So these are all numbers.",
                    "label": 0
                },
                {
                    "sent": "Of course, we also want to see some.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Figures from illustrations.",
                    "label": 0
                },
                {
                    "sent": "So here's an example for a new with.",
                    "label": 0
                },
                {
                    "sent": "K is 2, so actually we started with the code table that you see here on the left column.",
                    "label": 0
                },
                {
                    "sent": "Each pattern.",
                    "label": 0
                },
                {
                    "sent": "In the code table, is covered by.",
                    "label": 0
                },
                {
                    "sent": "Certain code has a certain code attached.",
                    "label": 0
                },
                {
                    "sent": "Here you see these codes and the width of these blue boxes represent the lengths of these codes.",
                    "label": 0
                },
                {
                    "sent": "So for example here you see quite a long code and this one is very short and a short code means mean.",
                    "label": 0
                },
                {
                    "sent": "That's the pattern occurs very often in the database, while a longer code means that it occurs less frequently in a database.",
                    "label": 0
                },
                {
                    "sent": "That's how it works.",
                    "label": 0
                },
                {
                    "sent": "An then in the middle and on the right you see the two code tables that were extracted from this original code table on the left.",
                    "label": 0
                },
                {
                    "sent": "And what we can see here is that it really seems that there actually are multiple components hidden in this original code table.",
                    "label": 0
                },
                {
                    "sent": "So our assumption that the code table the model would be a mixture of models seems to be true, because here we have two code tables that are really specialized to subsets of these of this database and well.",
                    "label": 0
                },
                {
                    "sent": "It's also good, actually, that we allow patterns to be in multiple components, because the Red Arrows Mark samko table elements that are in both code tables.",
                    "label": 0
                },
                {
                    "sent": "So I just meant that seems to work quite well.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But we have a second method which is data driven.",
                    "label": 0
                },
                {
                    "sent": "This yes this case.",
                    "label": 0
                },
                {
                    "sent": "We start with the database and this.",
                    "label": 0
                },
                {
                    "sent": "Methods resembles a bit K means, but then without the need to specify K or a different measure, because we first randomly split the database into K components.",
                    "label": 0
                },
                {
                    "sent": "And now the important thing here is that.",
                    "label": 0
                },
                {
                    "sent": "The principle this algorithm works on is that if a certain compressor has seen more.",
                    "label": 0
                },
                {
                    "sent": "And transactions from a particular distribution, then a second compressor, then this first compressor will compress these transactions better than the other one.",
                    "label": 0
                },
                {
                    "sent": "So by randomly splitting the database in 2K components and then compressing each of these components to obtain K code tables, we get compressors that are biased to some specific distributions because, well, it would be.",
                    "label": 1
                },
                {
                    "sent": "It's very unlikely that each of these components has.",
                    "label": 0
                },
                {
                    "sent": "Except the same amount of distributions, East, same amount of transactions from all these distributions.",
                    "label": 0
                },
                {
                    "sent": "So we get these code tables and then again we repartition the database.",
                    "label": 0
                },
                {
                    "sent": "So for each partition.",
                    "label": 0
                },
                {
                    "sent": "For each transaction, I should say we look.",
                    "label": 0
                },
                {
                    "sent": "We compress it with all code tables and then we say, well, we assign it again to the code table that gives it the shortest encoded length, and this way we get new components which we can again compress and this way we thoroughly optimize until.",
                    "label": 0
                },
                {
                    "sent": "No more improvements can be made.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Again, some results.",
                    "label": 0
                },
                {
                    "sent": "Oh, it's quite similar to the results we obtained with the model driven approach for adults.",
                    "label": 0
                },
                {
                    "sent": "We get quite good gaining compression with quite some components.",
                    "label": 0
                },
                {
                    "sent": "In this case an for mammals.",
                    "label": 0
                },
                {
                    "sent": "This is also geographic data set.",
                    "label": 0
                },
                {
                    "sent": "We get quite a large gain in compression if we use.",
                    "label": 0
                },
                {
                    "sent": "Six components too.",
                    "label": 0
                },
                {
                    "sent": "To compress it.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this data set is especially nice as we can use it to easily visualize what is going on here.",
                    "label": 0
                },
                {
                    "sent": "You may know it or not.",
                    "label": 0
                },
                {
                    "sent": "It's a geographic data set which contains data on 121 European memos.",
                    "label": 0
                },
                {
                    "sent": "An each transaction represents a GRID location in Europe of about 50 by 50 kilometers, an for each GRID location.",
                    "label": 0
                },
                {
                    "sent": "The data only says which animals are present there.",
                    "label": 0
                },
                {
                    "sent": "Or not.",
                    "label": 0
                },
                {
                    "sent": "And that's all.",
                    "label": 0
                },
                {
                    "sent": "That's the algorithm, new when it's made this picture without knowing becausw, the components are made only based on the presence of these mammals.",
                    "label": 0
                },
                {
                    "sent": "And if we look at these components then there are really nicely drawn here because.",
                    "label": 0
                },
                {
                    "sent": "They are continuous there.",
                    "label": 0
                },
                {
                    "sent": "Graphics sound the.",
                    "label": 0
                },
                {
                    "sent": "They are one of the North there one in the South, so climate methods, region matters and without knowing anything about location, the algorithm found these components.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So to conclude this talk we showed that compression can be used to identify the components that together make up a database.",
                    "label": 0
                },
                {
                    "sent": "Each sample distribution that are going to finds is characterized by a model, a small pattern set that characterizes the data well.",
                    "label": 1
                },
                {
                    "sent": "We don't need any prior knowledge.",
                    "label": 1
                },
                {
                    "sent": "No distance measure is quiet, and the optimal number of components is determined automatically and we showed two algorithms.",
                    "label": 0
                },
                {
                    "sent": "Let's do this one from a mobile perspective, another one from a data perspective, and experiments showed that this works.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "1st.",
                    "label": 0
                },
                {
                    "sent": "Work relates to Shimada Lee and you think of the components as distributions in the mixture.",
                    "label": 0
                },
                {
                    "sent": "Well, yes, I showed on the.",
                    "label": 0
                },
                {
                    "sent": "One of the first slides it's related to mixture modeling, but then we don't need to specify any distributions in advance and, well, it works easily for transaction data also fits.",
                    "label": 0
                },
                {
                    "sent": "Compare the results empirically.",
                    "label": 0
                },
                {
                    "sent": "If you give your data to a mixture modeling tool and then to your tool and we haven't done that yet.",
                    "label": 0
                },
                {
                    "sent": "Will start the supermarket if you apply to supermarket.",
                    "label": 0
                },
                {
                    "sent": "Actually this there's one data set.",
                    "label": 0
                },
                {
                    "sent": "The retail data set that we apply to two, but for this no labels refillable so we could not really inspect what was going on in there.",
                    "label": 0
                },
                {
                    "sent": "And then you could have it because the market is they have appeared in market segments.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately, the providers of the data needed sleep information about.",
                    "label": 0
                },
                {
                    "sent": "One of the biggest.",
                    "label": 0
                },
                {
                    "sent": "It was actually for testing construction induction algorithms, and it's not the nursery consisted by tables that related attributes but not examples.",
                    "label": 0
                },
                {
                    "sent": "So an idea would be to compare the compression the degree of compression of the regional representation with the one with you.",
                    "label": 0
                },
                {
                    "sent": "Have you tried it before?",
                    "label": 0
                },
                {
                    "sent": "Well, the most important thing here is that compression is only a means to an end, so it's not.",
                    "label": 0
                },
                {
                    "sent": "Compression is not the goal here, but it's about well finding these components and characterizing them, and the compression itself is not really what we're interested in.",
                    "label": 0
                },
                {
                    "sent": "Yes, I was wondering whether instead of using that partitioning that you have now.",
                    "label": 0
                },
                {
                    "sent": "You could also use like a set of overlapping subgroups, visual components.",
                    "label": 0
                },
                {
                    "sent": "Sometimes.",
                    "label": 0
                },
                {
                    "sent": "People may fit into two components or into 2.",
                    "label": 0
                },
                {
                    "sent": "Well, it's of course a nice idea, but the difficult thing here is that makes computation even more difficult.",
                    "label": 0
                },
                {
                    "sent": "Now we use compression to assign transactions to, well, the best model.",
                    "label": 0
                },
                {
                    "sent": "Actually the best components, but then you would have to say, well, if compression is more or less similar for two code tables, then we can assign it to both more or less something like that, but it makes life more difficult.",
                    "label": 0
                },
                {
                    "sent": "So if you think example of items purchased by users, would you say that your method will partition users according to their preferences or partition items according to their categories?",
                    "label": 0
                },
                {
                    "sent": "Or none of that.",
                    "label": 0
                },
                {
                    "sent": "Well, here we are grouping the transaction.",
                    "label": 0
                },
                {
                    "sent": "So then it's about only about the products that you buy an not looking about groups of products.",
                    "label": 0
                },
                {
                    "sent": "It's only about groups of people in this case.",
                    "label": 0
                }
            ]
        }
    }
}