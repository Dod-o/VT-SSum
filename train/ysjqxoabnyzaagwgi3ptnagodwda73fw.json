{
    "id": "ysjqxoabnyzaagwgi3ptnagodwda73fw",
    "title": "Dense Active Appearance Models Using a Bounded Diameter Minimum Spanning Tree",
    "info": {
        "author": [
            "Robert Anderson, University of Cambridge"
        ],
        "published": "Oct. 9, 2012",
        "recorded": "September 2012",
        "category": [
            "Top->Computer Science->Computer Vision"
        ]
    },
    "url": "http://videolectures.net/bmvc2012_anderson_spanning_tree/",
    "segmentation": [
        [
            "So just said this is joint work with Bill Stanger, Introverted Pola and is looking at dense actual appearance models.",
            "Select appearance models been around for quite awhile now.",
            "Almost 15 years and then."
        ],
        [
            "A powerful way of modeling objects in images.",
            "To build an experience model, you need a set of training images of whatever you want to model, and you need to label a set of landmarks in these images.",
            "These just landmarks.",
            "You can consistently label in each of the training images.",
            "Given this labeling, you can build a shape model similar to what we saw in this talk, which is a mean shape and a set of shape basis.",
            "And you can also build a texture model, which is just a mean texture and a linear set of text variations.",
            "And when you combine these together you get a nonlinear output in the image space, which means that these models convar model quite complex definitions and appearances friendly small number of parameters.",
            "One thing that's common in."
        ],
        [
            "Appearance models that tend to be quite sparse.",
            "They don't have many points, and this is because you have to hand label every point in every training image, which since starts to take quite a long time and within each triangle in an active appearance, model any defamation.",
            "There's models and find warp, and when you have large triangles, do not having many points.",
            "This affine warp sometimes isn't a good approximation to the definition that's really going on, especially in something like a face where the number definition.",
            "It's not a great model.",
            "What this results in is a blurring of the underlying textures.",
            "As a doubt correctly aligned when you register the training images.",
            "So what then?",
            "Sacraments modesty is trying to reduce this problem by adding many more points to the model.",
            "This makes a triangle lot smaller and then in affine warp is a reasonable approximation for each individual triangle.",
            "And this results in quite a lot sharper.",
            "Model might be easy to see here that the standard model and then the dense model."
        ],
        [
            "Games like sharper.",
            "So where this is useful is if you want to do synthesis using active appearance models and the project that caused us to look at this was building a talking head.",
            "The idea of these is."
        ],
        [
            "You type in some text, any text to tool and then get out a video of a person you've trained the model on saying whatever is not certain.",
            "If this will work, hearing it.",
            "This is a talking head which takes advantage of an active appearance model, since the model allows a face to be described by a few values, we can use sample TTS techniques with almost no modification.",
            "Here the things that you can make your your model the high resolution your output will be and you get nice resolution output without having to blur it.",
            "So This is why we want to use dense actor parents models.",
            "The next question is how do we make them?",
            "Because you can't label thousands of points in each training image and so you need some kind of automatic approach."
        ],
        [
            "So being a little power work on automatic building of active appearance models, that's just the selection and the earlier works by Walker and Baker produce quite sparse models with sort of 10s of points, but some of the more recent work start produce denser ones with hundreds of points in them.",
            "Ideally what we want is to be able to use an arbitrary density of model, so keep on adding points until we don't get anymore advantage for adding them, and that's what we have to do in in this work.",
            "How do we go about building?"
        ],
        [
            "Model length.",
            "First off, we start with a course."
        ],
        [
            "So so say about 30 points in each language which just gives us a good initialization and is sort of a reasonable amount of hand labeling similar to what you do for a normal normal active appearance model.",
            "Given this, we then find joint alignment between all the training images.",
            "So we want to find dense alignment.",
            "So use flow fields to represent walks between images and this gives us a per pixel alignment tool training images.",
            "Given this alignment, we can then iteratively add points to the active appearance model, and since we have an alignment between all the images, if we had a point in one image, will know where to appear in all of the others, and you can go from your initial course model and add as many points as you want.",
            "Slowly densifying the model but then selling it in the areas where the votes of defamation and you have anymore versus.",
            "So the main effort here is in the second stage, and finally the joint alignment between the between all the training images, and that's what I'm going to focus on there."
        ],
        [
            "So if you want to align 2 images in your training set and you want to represent the war between them as a 2D flow field, the obvious thing to do is to run your favorite optical flow algorithm and see what result it gives you whenever we've been doing pairwise alignments in this paper, we've been using a flow method based on that loop.",
            "And yes, we never talk about powers.",
            "Alignment is just running optical flow on a pair of images.",
            "If there's quite a large amount of information between the two images that you want to compare, or if there's occlusions or disc lesions, then optical flow tends to have some errors in these locations, and so if in your training set there are intermediate images you can actually use these to help.",
            "So if you have images in some way for between the two images you're trying to register, instead of calculating one definition for a large large change in appearance, you can calculate several smaller ones where for each of these is not that much defamation.",
            "And so your registration is quite accurate.",
            "And then if using flow fields combining."
        ],
        [
            "Small registrations to get one large one is straightforward.",
            "This is really the idea between graph breach, graph based approaches or manifold approaches for joint image alignment to breakdown large deformations that are hard to calculate directly into many smaller definitions."
        ],
        [
            "So there's been many different types of graph proposed for doing graph based alignment.",
            "K nearest neighbor graph, probably the most popular, but we want to propose here is using a bounded down to minimum spanning tree, which takes advantage of minimum spanning tree and get rid of some of its some of its problems as they will come onto in a minute.",
            "So to set up the problem, we define a graph where."
        ],
        [
            "Each training image is a node in the graph, and each edge in the graph represents a Wolf calculated between those two training images.",
            "If you build a spanning tree on the graph, you can then."
        ],
        [
            "Former joint alignment of the images asked Register 20 image.",
            "Say this center one here.",
            "You simply concatenate flow fields along a path to reach the central image.",
            "Obviously, what spanning tree you choose is going to have a large effect on how good your alignment is, and it's at this point that we want to enforce that we only register between similar images.",
            "To make each pairwise registration as accurate as possible.",
            "Set."
        ],
        [
            "To do this, we introduce a matching score between each image pair in our data set.",
            "This matching scores based on calculating flow between the two images and then walking the images into the same reference frame and comparing the difference.",
            "So if we bought the second image into the first images reference frame, look at the difference and then also do the same going into the second image reference frame, just the cost of symmetrical, which we need since we're building a non directed graph.",
            "If we do this and we wish to minimize the total sum of these pairwise costs in our graph, then it simply becomes a case of finding a minimum spanning tree in the graph.",
            "We assign this pairwise cost to each edge and finding minimum spanning trees are well, well studied problems, you can use whatever algorithm you wish.",
            "So you can do this on a fairly small datasets, it's easy."
        ],
        [
            "See just going on, you have a graph.",
            "Looks like this so quite quite a string of graph and we'd register all of the images to the image at the base of the tree.",
            "This root node here just by concatenating flows along the path in the graph.",
            "So registering this way has a couple of nice properties.",
            "Each of your individual pairwise registrations tends to be very accurate, as you're purposely registering between similar."
        ],
        [
            "Images.",
            "Also, if there are features are only appear in two or three images, these also tend to be well aligned as a place next to each other in the graph where some of the standard approaches such as registering to mean image tend to struggle with this sort of thing, there are some disadvantages to using minimum spanning tree structure that First off it tends to end up with very long paths.",
            "You have to concatenate to each leaf node to get back to the root of the tree and any small errors in your warps will accumulate due to these long paths and will.",
            "Make your registration less accurate.",
            "Also, if there are any errors near the root of the tree, then they have a negative effect on a large number of images.",
            "For example, here if you miss."
        ],
        [
            "Calculate the water here.",
            "Then all of the images further down the tree will have poor registration, so ideally we want to try and reduce, reduce the chance of these errors occurring and this is where the bandit diameter minimum spanning tree comes in.",
            "So the damage of a graph such as this is simply the longest path between any two nodes in the tree.",
            "So if this tree it would be 10, which is the path between.",
            "There along the red path here.",
            "And truth."
        ],
        [
            "And amateurs have very very different properties.",
            "And."
        ],
        [
            "Extreme case where you have a tree of damage, two everything is connected to the same root image and this just is equivalent to registering to one of your training images as you increase."
        ],
        [
            "Diameter up to four.",
            "You start to get clusters of images forming and we got the down to."
        ],
        [
            "We have 410 being the other very spread out tree with long paths coming away from root node.",
            "And finding these trees watching, they have nice properties is the problem of finding abandoned amateur minimum."
        ],
        [
            "Hanging tree.",
            "So bend down to minimum spanning trees are spending treva graph for the minimum sum of edge costs constrained to not exceed a certain damn TD?",
            "The slightly tricky to find than your standard spanning trees.",
            "In fact, for most damages them be hard problem, but it's one that's been studied and there are various heuristics out there.",
            "We use one proposed by Jewel Strum, which tends to give pretty good approximations pretty quickly.",
            "If you're using a banded diameter tree, then you need to decide what damage to use and he have a trade off.",
            "As you decrease the tree diameter, you have shorter paths."
        ],
        [
            "Each of your images to the root image, and this means you don't accumulate so much error by concatenating.",
            "Multiple Wolves have, on the other hand is you decrease the tree.",
            "Dammit, you're forced to register, pulling more and more dissimilar images.",
            "Going to the extreme case of a tree demo of two where you're registering everything to the same image, so you can have some quite tricky pairwise registrations there.",
            "So looking at how how we vary the tree diameter, we used to model compactness here, which is the model compactness of the active appearance model we build after registration.",
            "So here are low score represents a good alignment between the images and these are just two different datasets of different faces and you can see that going from a diameter of two up to diameter of four at least quite a large improvement.",
            "This because you can register between similar images rather than having to register between very different ones.",
            "Beyond this point, though, you don't actually get much improvement by extending the tree, and in fact you start to get a more errors creeping in as you have to concatenate along paths and errors.",
            "In other words, the tree start causing problems.",
            "So in all our experiments we've used trees down to four."
        ],
        [
            "Yes, they treat them for looking it like this.",
            "The nice properties you start to get a.",
            "One root node and then several clusters of similar images appearing around the edge of the tree so it naturally clusters similar images together.",
            "So we have an alignment between.",
            "Your image is defined by graph, like this.",
            "You then have to do something with."
        ],
        [
            "And so the end of this is to densify extra payment models and do so in a useful way.",
            "And the idea of adding the extra points to model is to be able to better model defamation.",
            "So the deformations that we want to model."
        ],
        [
            "Are encoded in the flows with calculated between the training images and what we ideally want is for our after appearance model to be able to describe a flow such as the one on the left.",
            "Unfortunately, if you have a sparse model like that on the right, it can never do this as within each triangle in the mesh, horizontal and vertical displacement can only vary linearly, so bound the best approximation you can get us something like that, which clearly isn't very close.",
            "This why wanted to identify the model in the 1st place so.",
            "So what we aim to do is try to make the image on the right as similar as possible to the image on the left by iteratively adding points to the model, but wish to do this rule training images at once.",
            "So to do this we define."
        ],
        [
            "In a target vector, each pixel which is essentially a concatenation of the flow for each of the training images, and then we want to approximate this as close as we can by flow defined on the model mesh.",
            "So again just stack all of the training images and concatenate the flows as estimated by our bar mesh, and then each iteration we had a point.",
            "To the we had a vertex at the point with the largest error.",
            "So if we do this on the sample data set, we end up with information that runs something like this."
        ],
        [
            "Let's try that again so you can see that we don't end up densifying regions like the background weather isn't any defamation, and most of the points tend to get concentrated around.",
            "We just like the mouth weather, lot of nonrigid deformation going on, and it also starts pick out a border for the face as that moves relative to the background.",
            "We can see the approximation to the flow field we saw before also improves as time goes on.",
            "So it actually ends up quite similar to what we're trying to model, and once all flow fields become similar to what we're trying to model, then there's no need to add any more points we have.",
            "We have a pretty complete model.",
            "Just show the diff."
        ],
        [
            "Between doing this in a simple approach, such as just identifying uniformly sliding, appoint the largest triangle at each iteration.",
            "So yeah, simple densification would add a point in the largest triangle at each iteration and slowly densify that way again, the two different datasets.",
            "Here the circles are using the proposed approach and the cross is just using a simple approach.",
            "You can see the proposed approach.",
            "We don't need to add that many extra points to greatly increase.",
            "Improve the model compactness, whereas if we're just densifying a simple way, then you can get the same model compactness with several times as many points.",
            "It's worth worth actually thinking about where you apply the points.",
            "So just to wrap up with sort of taking messages, I guess that."
        ],
        [
            "Appearance models are good if you want to do high resolution synthesis and yet don't want to have your parents model blurred.",
            "Bandit down to minimum spanning trees.",
            "Hope to tackle some of the problems of using space for joint image alignment.",
            "And when you define an active appearance model, if you want to pay attention to where you're adding the extra points and ensure that they are modeled the observed deformations.",
            "Yes."
        ],
        [
            "Things also have to save.",
            "Does anyone have any questions I said?"
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So just said this is joint work with Bill Stanger, Introverted Pola and is looking at dense actual appearance models.",
                    "label": 0
                },
                {
                    "sent": "Select appearance models been around for quite awhile now.",
                    "label": 1
                },
                {
                    "sent": "Almost 15 years and then.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "A powerful way of modeling objects in images.",
                    "label": 0
                },
                {
                    "sent": "To build an experience model, you need a set of training images of whatever you want to model, and you need to label a set of landmarks in these images.",
                    "label": 0
                },
                {
                    "sent": "These just landmarks.",
                    "label": 0
                },
                {
                    "sent": "You can consistently label in each of the training images.",
                    "label": 0
                },
                {
                    "sent": "Given this labeling, you can build a shape model similar to what we saw in this talk, which is a mean shape and a set of shape basis.",
                    "label": 0
                },
                {
                    "sent": "And you can also build a texture model, which is just a mean texture and a linear set of text variations.",
                    "label": 0
                },
                {
                    "sent": "And when you combine these together you get a nonlinear output in the image space, which means that these models convar model quite complex definitions and appearances friendly small number of parameters.",
                    "label": 0
                },
                {
                    "sent": "One thing that's common in.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Appearance models that tend to be quite sparse.",
                    "label": 0
                },
                {
                    "sent": "They don't have many points, and this is because you have to hand label every point in every training image, which since starts to take quite a long time and within each triangle in an active appearance, model any defamation.",
                    "label": 0
                },
                {
                    "sent": "There's models and find warp, and when you have large triangles, do not having many points.",
                    "label": 0
                },
                {
                    "sent": "This affine warp sometimes isn't a good approximation to the definition that's really going on, especially in something like a face where the number definition.",
                    "label": 0
                },
                {
                    "sent": "It's not a great model.",
                    "label": 0
                },
                {
                    "sent": "What this results in is a blurring of the underlying textures.",
                    "label": 0
                },
                {
                    "sent": "As a doubt correctly aligned when you register the training images.",
                    "label": 0
                },
                {
                    "sent": "So what then?",
                    "label": 0
                },
                {
                    "sent": "Sacraments modesty is trying to reduce this problem by adding many more points to the model.",
                    "label": 0
                },
                {
                    "sent": "This makes a triangle lot smaller and then in affine warp is a reasonable approximation for each individual triangle.",
                    "label": 0
                },
                {
                    "sent": "And this results in quite a lot sharper.",
                    "label": 0
                },
                {
                    "sent": "Model might be easy to see here that the standard model and then the dense model.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Games like sharper.",
                    "label": 0
                },
                {
                    "sent": "So where this is useful is if you want to do synthesis using active appearance models and the project that caused us to look at this was building a talking head.",
                    "label": 0
                },
                {
                    "sent": "The idea of these is.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You type in some text, any text to tool and then get out a video of a person you've trained the model on saying whatever is not certain.",
                    "label": 0
                },
                {
                    "sent": "If this will work, hearing it.",
                    "label": 0
                },
                {
                    "sent": "This is a talking head which takes advantage of an active appearance model, since the model allows a face to be described by a few values, we can use sample TTS techniques with almost no modification.",
                    "label": 1
                },
                {
                    "sent": "Here the things that you can make your your model the high resolution your output will be and you get nice resolution output without having to blur it.",
                    "label": 0
                },
                {
                    "sent": "So This is why we want to use dense actor parents models.",
                    "label": 0
                },
                {
                    "sent": "The next question is how do we make them?",
                    "label": 0
                },
                {
                    "sent": "Because you can't label thousands of points in each training image and so you need some kind of automatic approach.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So being a little power work on automatic building of active appearance models, that's just the selection and the earlier works by Walker and Baker produce quite sparse models with sort of 10s of points, but some of the more recent work start produce denser ones with hundreds of points in them.",
                    "label": 1
                },
                {
                    "sent": "Ideally what we want is to be able to use an arbitrary density of model, so keep on adding points until we don't get anymore advantage for adding them, and that's what we have to do in in this work.",
                    "label": 0
                },
                {
                    "sent": "How do we go about building?",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Model length.",
                    "label": 0
                },
                {
                    "sent": "First off, we start with a course.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So so say about 30 points in each language which just gives us a good initialization and is sort of a reasonable amount of hand labeling similar to what you do for a normal normal active appearance model.",
                    "label": 0
                },
                {
                    "sent": "Given this, we then find joint alignment between all the training images.",
                    "label": 1
                },
                {
                    "sent": "So we want to find dense alignment.",
                    "label": 0
                },
                {
                    "sent": "So use flow fields to represent walks between images and this gives us a per pixel alignment tool training images.",
                    "label": 1
                },
                {
                    "sent": "Given this alignment, we can then iteratively add points to the active appearance model, and since we have an alignment between all the images, if we had a point in one image, will know where to appear in all of the others, and you can go from your initial course model and add as many points as you want.",
                    "label": 1
                },
                {
                    "sent": "Slowly densifying the model but then selling it in the areas where the votes of defamation and you have anymore versus.",
                    "label": 0
                },
                {
                    "sent": "So the main effort here is in the second stage, and finally the joint alignment between the between all the training images, and that's what I'm going to focus on there.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So if you want to align 2 images in your training set and you want to represent the war between them as a 2D flow field, the obvious thing to do is to run your favorite optical flow algorithm and see what result it gives you whenever we've been doing pairwise alignments in this paper, we've been using a flow method based on that loop.",
                    "label": 0
                },
                {
                    "sent": "And yes, we never talk about powers.",
                    "label": 0
                },
                {
                    "sent": "Alignment is just running optical flow on a pair of images.",
                    "label": 0
                },
                {
                    "sent": "If there's quite a large amount of information between the two images that you want to compare, or if there's occlusions or disc lesions, then optical flow tends to have some errors in these locations, and so if in your training set there are intermediate images you can actually use these to help.",
                    "label": 0
                },
                {
                    "sent": "So if you have images in some way for between the two images you're trying to register, instead of calculating one definition for a large large change in appearance, you can calculate several smaller ones where for each of these is not that much defamation.",
                    "label": 0
                },
                {
                    "sent": "And so your registration is quite accurate.",
                    "label": 0
                },
                {
                    "sent": "And then if using flow fields combining.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Small registrations to get one large one is straightforward.",
                    "label": 0
                },
                {
                    "sent": "This is really the idea between graph breach, graph based approaches or manifold approaches for joint image alignment to breakdown large deformations that are hard to calculate directly into many smaller definitions.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So there's been many different types of graph proposed for doing graph based alignment.",
                    "label": 1
                },
                {
                    "sent": "K nearest neighbor graph, probably the most popular, but we want to propose here is using a bounded down to minimum spanning tree, which takes advantage of minimum spanning tree and get rid of some of its some of its problems as they will come onto in a minute.",
                    "label": 1
                },
                {
                    "sent": "So to set up the problem, we define a graph where.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Each training image is a node in the graph, and each edge in the graph represents a Wolf calculated between those two training images.",
                    "label": 0
                },
                {
                    "sent": "If you build a spanning tree on the graph, you can then.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Former joint alignment of the images asked Register 20 image.",
                    "label": 0
                },
                {
                    "sent": "Say this center one here.",
                    "label": 0
                },
                {
                    "sent": "You simply concatenate flow fields along a path to reach the central image.",
                    "label": 0
                },
                {
                    "sent": "Obviously, what spanning tree you choose is going to have a large effect on how good your alignment is, and it's at this point that we want to enforce that we only register between similar images.",
                    "label": 0
                },
                {
                    "sent": "To make each pairwise registration as accurate as possible.",
                    "label": 0
                },
                {
                    "sent": "Set.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "To do this, we introduce a matching score between each image pair in our data set.",
                    "label": 1
                },
                {
                    "sent": "This matching scores based on calculating flow between the two images and then walking the images into the same reference frame and comparing the difference.",
                    "label": 0
                },
                {
                    "sent": "So if we bought the second image into the first images reference frame, look at the difference and then also do the same going into the second image reference frame, just the cost of symmetrical, which we need since we're building a non directed graph.",
                    "label": 0
                },
                {
                    "sent": "If we do this and we wish to minimize the total sum of these pairwise costs in our graph, then it simply becomes a case of finding a minimum spanning tree in the graph.",
                    "label": 1
                },
                {
                    "sent": "We assign this pairwise cost to each edge and finding minimum spanning trees are well, well studied problems, you can use whatever algorithm you wish.",
                    "label": 0
                },
                {
                    "sent": "So you can do this on a fairly small datasets, it's easy.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "See just going on, you have a graph.",
                    "label": 0
                },
                {
                    "sent": "Looks like this so quite quite a string of graph and we'd register all of the images to the image at the base of the tree.",
                    "label": 0
                },
                {
                    "sent": "This root node here just by concatenating flows along the path in the graph.",
                    "label": 0
                },
                {
                    "sent": "So registering this way has a couple of nice properties.",
                    "label": 0
                },
                {
                    "sent": "Each of your individual pairwise registrations tends to be very accurate, as you're purposely registering between similar.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Images.",
                    "label": 0
                },
                {
                    "sent": "Also, if there are features are only appear in two or three images, these also tend to be well aligned as a place next to each other in the graph where some of the standard approaches such as registering to mean image tend to struggle with this sort of thing, there are some disadvantages to using minimum spanning tree structure that First off it tends to end up with very long paths.",
                    "label": 0
                },
                {
                    "sent": "You have to concatenate to each leaf node to get back to the root of the tree and any small errors in your warps will accumulate due to these long paths and will.",
                    "label": 0
                },
                {
                    "sent": "Make your registration less accurate.",
                    "label": 0
                },
                {
                    "sent": "Also, if there are any errors near the root of the tree, then they have a negative effect on a large number of images.",
                    "label": 1
                },
                {
                    "sent": "For example, here if you miss.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Calculate the water here.",
                    "label": 0
                },
                {
                    "sent": "Then all of the images further down the tree will have poor registration, so ideally we want to try and reduce, reduce the chance of these errors occurring and this is where the bandit diameter minimum spanning tree comes in.",
                    "label": 0
                },
                {
                    "sent": "So the damage of a graph such as this is simply the longest path between any two nodes in the tree.",
                    "label": 0
                },
                {
                    "sent": "So if this tree it would be 10, which is the path between.",
                    "label": 0
                },
                {
                    "sent": "There along the red path here.",
                    "label": 0
                },
                {
                    "sent": "And truth.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And amateurs have very very different properties.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Extreme case where you have a tree of damage, two everything is connected to the same root image and this just is equivalent to registering to one of your training images as you increase.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Diameter up to four.",
                    "label": 0
                },
                {
                    "sent": "You start to get clusters of images forming and we got the down to.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We have 410 being the other very spread out tree with long paths coming away from root node.",
                    "label": 0
                },
                {
                    "sent": "And finding these trees watching, they have nice properties is the problem of finding abandoned amateur minimum.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Hanging tree.",
                    "label": 0
                },
                {
                    "sent": "So bend down to minimum spanning trees are spending treva graph for the minimum sum of edge costs constrained to not exceed a certain damn TD?",
                    "label": 1
                },
                {
                    "sent": "The slightly tricky to find than your standard spanning trees.",
                    "label": 0
                },
                {
                    "sent": "In fact, for most damages them be hard problem, but it's one that's been studied and there are various heuristics out there.",
                    "label": 0
                },
                {
                    "sent": "We use one proposed by Jewel Strum, which tends to give pretty good approximations pretty quickly.",
                    "label": 0
                },
                {
                    "sent": "If you're using a banded diameter tree, then you need to decide what damage to use and he have a trade off.",
                    "label": 0
                },
                {
                    "sent": "As you decrease the tree diameter, you have shorter paths.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Each of your images to the root image, and this means you don't accumulate so much error by concatenating.",
                    "label": 1
                },
                {
                    "sent": "Multiple Wolves have, on the other hand is you decrease the tree.",
                    "label": 0
                },
                {
                    "sent": "Dammit, you're forced to register, pulling more and more dissimilar images.",
                    "label": 0
                },
                {
                    "sent": "Going to the extreme case of a tree demo of two where you're registering everything to the same image, so you can have some quite tricky pairwise registrations there.",
                    "label": 0
                },
                {
                    "sent": "So looking at how how we vary the tree diameter, we used to model compactness here, which is the model compactness of the active appearance model we build after registration.",
                    "label": 0
                },
                {
                    "sent": "So here are low score represents a good alignment between the images and these are just two different datasets of different faces and you can see that going from a diameter of two up to diameter of four at least quite a large improvement.",
                    "label": 0
                },
                {
                    "sent": "This because you can register between similar images rather than having to register between very different ones.",
                    "label": 0
                },
                {
                    "sent": "Beyond this point, though, you don't actually get much improvement by extending the tree, and in fact you start to get a more errors creeping in as you have to concatenate along paths and errors.",
                    "label": 0
                },
                {
                    "sent": "In other words, the tree start causing problems.",
                    "label": 0
                },
                {
                    "sent": "So in all our experiments we've used trees down to four.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Yes, they treat them for looking it like this.",
                    "label": 0
                },
                {
                    "sent": "The nice properties you start to get a.",
                    "label": 0
                },
                {
                    "sent": "One root node and then several clusters of similar images appearing around the edge of the tree so it naturally clusters similar images together.",
                    "label": 0
                },
                {
                    "sent": "So we have an alignment between.",
                    "label": 0
                },
                {
                    "sent": "Your image is defined by graph, like this.",
                    "label": 0
                },
                {
                    "sent": "You then have to do something with.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And so the end of this is to densify extra payment models and do so in a useful way.",
                    "label": 0
                },
                {
                    "sent": "And the idea of adding the extra points to model is to be able to better model defamation.",
                    "label": 0
                },
                {
                    "sent": "So the deformations that we want to model.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Are encoded in the flows with calculated between the training images and what we ideally want is for our after appearance model to be able to describe a flow such as the one on the left.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately, if you have a sparse model like that on the right, it can never do this as within each triangle in the mesh, horizontal and vertical displacement can only vary linearly, so bound the best approximation you can get us something like that, which clearly isn't very close.",
                    "label": 0
                },
                {
                    "sent": "This why wanted to identify the model in the 1st place so.",
                    "label": 0
                },
                {
                    "sent": "So what we aim to do is try to make the image on the right as similar as possible to the image on the left by iteratively adding points to the model, but wish to do this rule training images at once.",
                    "label": 0
                },
                {
                    "sent": "So to do this we define.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In a target vector, each pixel which is essentially a concatenation of the flow for each of the training images, and then we want to approximate this as close as we can by flow defined on the model mesh.",
                    "label": 1
                },
                {
                    "sent": "So again just stack all of the training images and concatenate the flows as estimated by our bar mesh, and then each iteration we had a point.",
                    "label": 1
                },
                {
                    "sent": "To the we had a vertex at the point with the largest error.",
                    "label": 0
                },
                {
                    "sent": "So if we do this on the sample data set, we end up with information that runs something like this.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's try that again so you can see that we don't end up densifying regions like the background weather isn't any defamation, and most of the points tend to get concentrated around.",
                    "label": 0
                },
                {
                    "sent": "We just like the mouth weather, lot of nonrigid deformation going on, and it also starts pick out a border for the face as that moves relative to the background.",
                    "label": 0
                },
                {
                    "sent": "We can see the approximation to the flow field we saw before also improves as time goes on.",
                    "label": 0
                },
                {
                    "sent": "So it actually ends up quite similar to what we're trying to model, and once all flow fields become similar to what we're trying to model, then there's no need to add any more points we have.",
                    "label": 0
                },
                {
                    "sent": "We have a pretty complete model.",
                    "label": 0
                },
                {
                    "sent": "Just show the diff.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Between doing this in a simple approach, such as just identifying uniformly sliding, appoint the largest triangle at each iteration.",
                    "label": 1
                },
                {
                    "sent": "So yeah, simple densification would add a point in the largest triangle at each iteration and slowly densify that way again, the two different datasets.",
                    "label": 0
                },
                {
                    "sent": "Here the circles are using the proposed approach and the cross is just using a simple approach.",
                    "label": 1
                },
                {
                    "sent": "You can see the proposed approach.",
                    "label": 0
                },
                {
                    "sent": "We don't need to add that many extra points to greatly increase.",
                    "label": 0
                },
                {
                    "sent": "Improve the model compactness, whereas if we're just densifying a simple way, then you can get the same model compactness with several times as many points.",
                    "label": 0
                },
                {
                    "sent": "It's worth worth actually thinking about where you apply the points.",
                    "label": 0
                },
                {
                    "sent": "So just to wrap up with sort of taking messages, I guess that.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Appearance models are good if you want to do high resolution synthesis and yet don't want to have your parents model blurred.",
                    "label": 0
                },
                {
                    "sent": "Bandit down to minimum spanning trees.",
                    "label": 1
                },
                {
                    "sent": "Hope to tackle some of the problems of using space for joint image alignment.",
                    "label": 1
                },
                {
                    "sent": "And when you define an active appearance model, if you want to pay attention to where you're adding the extra points and ensure that they are modeled the observed deformations.",
                    "label": 0
                },
                {
                    "sent": "Yes.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Things also have to save.",
                    "label": 0
                },
                {
                    "sent": "Does anyone have any questions I said?",
                    "label": 0
                }
            ]
        }
    }
}