{
    "id": "mnjazntgrx5ej6t7sf6orplfpndgooyw",
    "title": "Solving the uncapacitated facility location problem using message passing algorithms",
    "info": {
        "author": [
            "Nevena Lazic, Edward S. Rogers Sr. Department of Electrical and Computer Engineering, University of Toronto"
        ],
        "published": "June 3, 2010",
        "recorded": "May 2010",
        "category": [
            "Top->Computer Science->Machine Learning->Graphical Models"
        ]
    },
    "url": "http://videolectures.net/aistats2010_lazic_stufl/",
    "segmentation": [
        [
            "Hey hi, so the title of my talk is solving the facility location problem using message passing an it's joint work with Brendan Frey and Parm Robbie at the University of Toronto."
        ],
        [
            "So in a facility location problem, you're given a set of facilities and the set of customers, and there's a cost of opening each facility and the cost of connecting each customer to a particular facility.",
            "So the task is to open a subset of the facilities and connect customers to one facility each at minimal total costs."
        ],
        [
            "So this is NP hard problem that arises in several machine learning applications.",
            "For example, in example are based clustering where you're representing each cluster by one of the data points.",
            "So you can think of this as an instance of facility location where the customers and facilities are the same set.",
            "Another example is multiple model selection, where you can think of each model as a facility and data points as customers.",
            "So the facility costs are in this case.",
            "Model complexity, such as the number of parameters.",
            "There are also many practical problems which can be seen as facility location in applications such as wireless sensor networks, computational biology, and computer vision.",
            "So our approach to facility location will be too."
        ],
        [
            "Formulated to find solutions using approximate maximum.",
            "A posterior inference in a graphical model representation.",
            "And to do that we use Max product linear programming, which is one of the recently developed convexified versions of Max product belief propagation.",
            "So one of the properties of MPLP is that once it converges, if it converges to a unique solution, that solution is guaranteed to be optimal, but it does not necessarily have to converge to a unique solution, and you can end up having a set of variables which you don't know how to set.",
            "So this is the case that I will primarily talk about, and I will describe a greedy algorithm that will assign those variables for which you're not certain, which does not always coincide with any of the MPL.",
            "The solutions the final solution will have some optimality guarantees.",
            "In particular, it will be guaranteed to be at most three times worse than the optimal and empirically we observe that we get better solutions that then any unpeeled P solutions in some case.",
            "So here's the graphical."
        ],
        [
            "Follow facility location.",
            "We're using binary variables XIJ to indicate that a customer I is connected to facility J.",
            "We want each customer to because connected to exactly 1 facility.",
            "So for that reason we put these row constraints.",
            "And we also add factors to incorporate connection costs and facility opening costs on the columns.",
            "So this is the overall objective that through minimizing its total sum of the cost subject to this constraint, that each customer is assigned to exactly 1 facility.",
            "OK, so as I mentioned, we."
        ],
        [
            "Zing MP LP and hear some background on MP LP.",
            "So original you're interested in minimizing the sum of all potentials in your graph and MP LP minimizes our weighted sum of those potentials over the weight so it's a linear programming relaxation of the original program problem and these weights are essentially distributions over all possible variable configurations in each potential function.",
            "So for example, here their probability tables over settings of X1 and X2 and X3.",
            "And they are constrained to agree on their overlap variables.",
            "So Muay anubi have to agree on their marginal over the variable that they have in common X, X2.",
            "So a solution of the original Prob."
        ],
        [
            "Simply corresponds to an integral mu, which puts probability one on that configuration of X and probability zero everywhere."
        ],
        [
            "OK, so it turns out that you can write the dual of this linear program as a sum of maximize beliefs, similarly to regular belief propagation, and each belief is a sum of messages.",
            "However, the only difference is that now messages actually correspond to dual variables.",
            "And similarly to standard belief propagation, Anfield proceeds by iteratively updating these messages at convergence, computing beliefs, and assigning variables to the values that maximize their."
        ],
        [
            "Beliefs so as I mentioned at convergence that there can be two different cases, either you can get the unique X which is in that case guaranteed to be optimal, or you can have a set of variables which have an equally for being one and zero.",
            "So even in this case there are some graphs to it in which you can find the optimal solution in polynomial time such as binary pairwise MRF with submodular potentials, but in general it's unknown how to do this for NP hard problems such as facility location.",
            "So I will describe one way of 1 principled way of setting those variables for the facility location problem."
        ],
        [
            "And our approach will be based on the complementary slackness conditions of this LP.",
            "So these are just conditions that always hold for a set of solutions of a linear program that their primal and dual optimal.",
            "It turns out that the integral solution that MP LP constructs by maximizing beliefs always satisfies a special subset of these complementary slackness conditions.",
            "So we will try to greedily find an integral solution.",
            "That satisfies all of the complementary slackness conditions, not necessarily succeeding all the time, because LP relaxation might not be tight.",
            "OK so um."
        ],
        [
            "So I'm not going to write any equations, but I will illustrate what these conditions are using these solutions support graph, so the graph on the left with the green dashed edges just depicts an MP LP.",
            "Fixed points with edges connecting each customer to a facility for which it has positive beliefs.",
            "So for example, at convergence customer one wants to go to either facility one or facility too.",
            "But we don't know how to assign.",
            "And they will just portray integral solutions with this graph with solid black edges.",
            "So the integral, so the complementary cycles conditions for this linear program say that an integral solution satisfying those conditions has to first of all be connected to first of all you have to have."
        ],
        [
            "Each customer connected to a facility using one of these belief edges, so that's one set, and that's the set that MP LP solution satisfies, and the second condition says that if."
        ],
        [
            "We open the facility.",
            "You have to use all of the green edges.",
            "So for example this is.",
            "This is a solution that violates the first condition because there was no edge between between this customer."
        ],
        [
            "And this is a solution that violates the second complementary slackness conditions, because you open that facility, but you didn't use up all of the green links.",
            "So if you can manage to satisfy both of these."
        ],
        [
            "That means that your LP relaxation is tight and that your solution is guaranteed to be optimal because it achieves the lower bound."
        ],
        [
            "So this is an example of a solution that does that."
        ],
        [
            "So as I mentioned, if you do the thing, if you follow the standard belief propagation approach and just assign variables to values that maximize their beliefs, you're always satisfying this first set of complementary slackness conditions.",
            "And you're not really looking at anything else.",
            "And in this case for this problem, it amounts to just picking an edge for each customer.",
            "So if you just do this arbitrarily, you can."
        ],
        [
            "End up with a very bad solution.",
            "For example, this opening all facilities, which is kind of trivial, so our approach."
        ],
        [
            "Will be to always satisfy this second set of complementary slackness conditions which are really related to the higher order potentials on the columns of the graph.",
            "So that means whenever we open the facility, we connect all of the customers to which it has links.",
            "And now we can."
        ],
        [
            "Longer open these but we can open this one and connect all of its customer and we can no longer open this.",
            "So once we can no longer open anymore facilities, we might have to we we might end up with some customers with no green links to any available facility.",
            "So for these customers we actually connect them to any of the facilities that are open and that are the closest.",
            "So now we're violating that first set of complementary slackness conditions, and we're not actually maximizing the beliefs for this set of variables, so this is 1 case in which this is different from the standard.",
            "Belief maximization approach, but we really were just satisfying this second set of conditions as opposed to the first one.",
            "So what can we say about that solution about this?"
        ],
        [
            "So it's location, general complexity results say that first of all, Rob Proximation algorithm is a polynomial time algorithm that guarantees to produce a solution that's at most ro times worse than optimal.",
            "So for facility location in general.",
            "You cannot find a rope approximation algorithm withdrawal less than logarithmic in the number of customers unless P equals NP.",
            "But for metric facility location.",
            "You can find algorithms that constant roll.",
            "And and metric facility locations basically just means that the connection costs satisfied the triangle inequality.",
            "So the sum of the three blue costs."
        ],
        [
            "Is less than or equal to the red cost?",
            "So for this case, we can guarantee that our decoding algorithm will produce solutions at most three times worse than the optimal.",
            "And the proof follows from several things, but some intuition for it is that all of these customers for which to beliefs are not maximized are always 3 links away from an open facility in that original graph with.",
            "With belief links.",
            "So from that in a few other things you can guarantee that your solution is at most three times the optimum.",
            "OK, so it's with."
        ],
        [
            "In 200% of the optimal but we also wanted to get some experimental results to see which one does better and we generated.",
            "We generated some facility location data by ascential uniformly sampling points in the unit square.",
            "An setting connection costs to equity and distance and setting all facility location facility costs to be equal.",
            "So it's an example based clustering problem with metric distances.",
            "So we ran an PLP with beleif decoding and with our greedy algorithm.",
            "And the Barplots showed the error where the error is the percent cost above the LP lower bound.",
            "We don't know what the actual optimum is.",
            "So across several different facility cost settings and choosing several different numbers of points, algorithm always got the lower error than just arbitrary belief decoding."
        ],
        [
            "So just out of curiosity, we compare this to Standard Max product algorithm which corresponds to the affinity propagation algorithm in this case.",
            "And we also use this type of decoding whenever we had died.",
            "Tide beliefs either by always maximizing beliefs or by not always maximizing beliefs, but using this greedy approach.",
            "And for Standard Max product the difference was not that not that big.",
            "In most cases beliefs were uniquely maximized, but in cases when they were not in particularly in this bottom figure, the greedy algorithm also gave us lower error."
        ],
        [
            "And finally we ran some experiments on facility location benchmarks from the Operations Research Library.",
            "And a lot of these were fairly small and were solved to optimality, but I'm showing barplots for the three larger problems which were not solved to optimality, and in this case the decoding doesn't make much difference for standard belief propagation, but it made a big difference.",
            "For MPL, PDR was much higher with just maximize beliefs."
        ],
        [
            "OK, so that concludes my talk, so I described the graphical model for solving facility location problems using MP LP and greedy algorithm for decoding variables.",
            "When the beliefs are tide.",
            "So our approach has some optimality guarantees.",
            "In particular, it's guaranteed to be at most three times the optimal and empirically it gives better solutions than just maximizing beliefs arbitrarily.",
            "So thank you."
        ],
        [
            "So I have a question.",
            "I have a question.",
            "So you do block coding and dissent, right?",
            "Yeah.",
            "Always to the optimal DLP, or can it get stuck in a non optimal point?",
            "I think for this case it could get stuck in a non optimal point.",
            "So for this particular one of an encoding you're not I think guaranteed to find MP is not guaranteed to find the optimum of the LP.",
            "So one interesting thing would be to look at different maybe binary encoding like multi label graph cuts, but I think with this case you can find counterexamples where it doesn't.",
            "Can you say something about rate of convergence?",
            "For MP LP it's very slow.",
            "I had the slide in that, but I took it out.",
            "I think it essentially depends on the number of overlaps.",
            "Sets like the more of those sets you have, the slower the longer MP will take to converge.",
            "So in this case it's much lower than Standard Max product."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Hey hi, so the title of my talk is solving the facility location problem using message passing an it's joint work with Brendan Frey and Parm Robbie at the University of Toronto.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in a facility location problem, you're given a set of facilities and the set of customers, and there's a cost of opening each facility and the cost of connecting each customer to a particular facility.",
                    "label": 0
                },
                {
                    "sent": "So the task is to open a subset of the facilities and connect customers to one facility each at minimal total costs.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So this is NP hard problem that arises in several machine learning applications.",
                    "label": 0
                },
                {
                    "sent": "For example, in example are based clustering where you're representing each cluster by one of the data points.",
                    "label": 0
                },
                {
                    "sent": "So you can think of this as an instance of facility location where the customers and facilities are the same set.",
                    "label": 0
                },
                {
                    "sent": "Another example is multiple model selection, where you can think of each model as a facility and data points as customers.",
                    "label": 0
                },
                {
                    "sent": "So the facility costs are in this case.",
                    "label": 0
                },
                {
                    "sent": "Model complexity, such as the number of parameters.",
                    "label": 0
                },
                {
                    "sent": "There are also many practical problems which can be seen as facility location in applications such as wireless sensor networks, computational biology, and computer vision.",
                    "label": 1
                },
                {
                    "sent": "So our approach to facility location will be too.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Formulated to find solutions using approximate maximum.",
                    "label": 0
                },
                {
                    "sent": "A posterior inference in a graphical model representation.",
                    "label": 1
                },
                {
                    "sent": "And to do that we use Max product linear programming, which is one of the recently developed convexified versions of Max product belief propagation.",
                    "label": 0
                },
                {
                    "sent": "So one of the properties of MPLP is that once it converges, if it converges to a unique solution, that solution is guaranteed to be optimal, but it does not necessarily have to converge to a unique solution, and you can end up having a set of variables which you don't know how to set.",
                    "label": 1
                },
                {
                    "sent": "So this is the case that I will primarily talk about, and I will describe a greedy algorithm that will assign those variables for which you're not certain, which does not always coincide with any of the MPL.",
                    "label": 1
                },
                {
                    "sent": "The solutions the final solution will have some optimality guarantees.",
                    "label": 0
                },
                {
                    "sent": "In particular, it will be guaranteed to be at most three times worse than the optimal and empirically we observe that we get better solutions that then any unpeeled P solutions in some case.",
                    "label": 0
                },
                {
                    "sent": "So here's the graphical.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Follow facility location.",
                    "label": 0
                },
                {
                    "sent": "We're using binary variables XIJ to indicate that a customer I is connected to facility J.",
                    "label": 1
                },
                {
                    "sent": "We want each customer to because connected to exactly 1 facility.",
                    "label": 0
                },
                {
                    "sent": "So for that reason we put these row constraints.",
                    "label": 0
                },
                {
                    "sent": "And we also add factors to incorporate connection costs and facility opening costs on the columns.",
                    "label": 0
                },
                {
                    "sent": "So this is the overall objective that through minimizing its total sum of the cost subject to this constraint, that each customer is assigned to exactly 1 facility.",
                    "label": 0
                },
                {
                    "sent": "OK, so as I mentioned, we.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Zing MP LP and hear some background on MP LP.",
                    "label": 0
                },
                {
                    "sent": "So original you're interested in minimizing the sum of all potentials in your graph and MP LP minimizes our weighted sum of those potentials over the weight so it's a linear programming relaxation of the original program problem and these weights are essentially distributions over all possible variable configurations in each potential function.",
                    "label": 0
                },
                {
                    "sent": "So for example, here their probability tables over settings of X1 and X2 and X3.",
                    "label": 0
                },
                {
                    "sent": "And they are constrained to agree on their overlap variables.",
                    "label": 0
                },
                {
                    "sent": "So Muay anubi have to agree on their marginal over the variable that they have in common X, X2.",
                    "label": 0
                },
                {
                    "sent": "So a solution of the original Prob.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Simply corresponds to an integral mu, which puts probability one on that configuration of X and probability zero everywhere.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so it turns out that you can write the dual of this linear program as a sum of maximize beliefs, similarly to regular belief propagation, and each belief is a sum of messages.",
                    "label": 0
                },
                {
                    "sent": "However, the only difference is that now messages actually correspond to dual variables.",
                    "label": 0
                },
                {
                    "sent": "And similarly to standard belief propagation, Anfield proceeds by iteratively updating these messages at convergence, computing beliefs, and assigning variables to the values that maximize their.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Beliefs so as I mentioned at convergence that there can be two different cases, either you can get the unique X which is in that case guaranteed to be optimal, or you can have a set of variables which have an equally for being one and zero.",
                    "label": 0
                },
                {
                    "sent": "So even in this case there are some graphs to it in which you can find the optimal solution in polynomial time such as binary pairwise MRF with submodular potentials, but in general it's unknown how to do this for NP hard problems such as facility location.",
                    "label": 0
                },
                {
                    "sent": "So I will describe one way of 1 principled way of setting those variables for the facility location problem.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And our approach will be based on the complementary slackness conditions of this LP.",
                    "label": 1
                },
                {
                    "sent": "So these are just conditions that always hold for a set of solutions of a linear program that their primal and dual optimal.",
                    "label": 1
                },
                {
                    "sent": "It turns out that the integral solution that MP LP constructs by maximizing beliefs always satisfies a special subset of these complementary slackness conditions.",
                    "label": 0
                },
                {
                    "sent": "So we will try to greedily find an integral solution.",
                    "label": 0
                },
                {
                    "sent": "That satisfies all of the complementary slackness conditions, not necessarily succeeding all the time, because LP relaxation might not be tight.",
                    "label": 0
                },
                {
                    "sent": "OK so um.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I'm not going to write any equations, but I will illustrate what these conditions are using these solutions support graph, so the graph on the left with the green dashed edges just depicts an MP LP.",
                    "label": 0
                },
                {
                    "sent": "Fixed points with edges connecting each customer to a facility for which it has positive beliefs.",
                    "label": 0
                },
                {
                    "sent": "So for example, at convergence customer one wants to go to either facility one or facility too.",
                    "label": 0
                },
                {
                    "sent": "But we don't know how to assign.",
                    "label": 0
                },
                {
                    "sent": "And they will just portray integral solutions with this graph with solid black edges.",
                    "label": 0
                },
                {
                    "sent": "So the integral, so the complementary cycles conditions for this linear program say that an integral solution satisfying those conditions has to first of all be connected to first of all you have to have.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Each customer connected to a facility using one of these belief edges, so that's one set, and that's the set that MP LP solution satisfies, and the second condition says that if.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We open the facility.",
                    "label": 0
                },
                {
                    "sent": "You have to use all of the green edges.",
                    "label": 0
                },
                {
                    "sent": "So for example this is.",
                    "label": 0
                },
                {
                    "sent": "This is a solution that violates the first condition because there was no edge between between this customer.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And this is a solution that violates the second complementary slackness conditions, because you open that facility, but you didn't use up all of the green links.",
                    "label": 0
                },
                {
                    "sent": "So if you can manage to satisfy both of these.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That means that your LP relaxation is tight and that your solution is guaranteed to be optimal because it achieves the lower bound.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So this is an example of a solution that does that.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So as I mentioned, if you do the thing, if you follow the standard belief propagation approach and just assign variables to values that maximize their beliefs, you're always satisfying this first set of complementary slackness conditions.",
                    "label": 0
                },
                {
                    "sent": "And you're not really looking at anything else.",
                    "label": 0
                },
                {
                    "sent": "And in this case for this problem, it amounts to just picking an edge for each customer.",
                    "label": 1
                },
                {
                    "sent": "So if you just do this arbitrarily, you can.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "End up with a very bad solution.",
                    "label": 0
                },
                {
                    "sent": "For example, this opening all facilities, which is kind of trivial, so our approach.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Will be to always satisfy this second set of complementary slackness conditions which are really related to the higher order potentials on the columns of the graph.",
                    "label": 0
                },
                {
                    "sent": "So that means whenever we open the facility, we connect all of the customers to which it has links.",
                    "label": 0
                },
                {
                    "sent": "And now we can.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Longer open these but we can open this one and connect all of its customer and we can no longer open this.",
                    "label": 0
                },
                {
                    "sent": "So once we can no longer open anymore facilities, we might have to we we might end up with some customers with no green links to any available facility.",
                    "label": 0
                },
                {
                    "sent": "So for these customers we actually connect them to any of the facilities that are open and that are the closest.",
                    "label": 0
                },
                {
                    "sent": "So now we're violating that first set of complementary slackness conditions, and we're not actually maximizing the beliefs for this set of variables, so this is 1 case in which this is different from the standard.",
                    "label": 0
                },
                {
                    "sent": "Belief maximization approach, but we really were just satisfying this second set of conditions as opposed to the first one.",
                    "label": 0
                },
                {
                    "sent": "So what can we say about that solution about this?",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So it's location, general complexity results say that first of all, Rob Proximation algorithm is a polynomial time algorithm that guarantees to produce a solution that's at most ro times worse than optimal.",
                    "label": 0
                },
                {
                    "sent": "So for facility location in general.",
                    "label": 1
                },
                {
                    "sent": "You cannot find a rope approximation algorithm withdrawal less than logarithmic in the number of customers unless P equals NP.",
                    "label": 0
                },
                {
                    "sent": "But for metric facility location.",
                    "label": 1
                },
                {
                    "sent": "You can find algorithms that constant roll.",
                    "label": 0
                },
                {
                    "sent": "And and metric facility locations basically just means that the connection costs satisfied the triangle inequality.",
                    "label": 0
                },
                {
                    "sent": "So the sum of the three blue costs.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is less than or equal to the red cost?",
                    "label": 0
                },
                {
                    "sent": "So for this case, we can guarantee that our decoding algorithm will produce solutions at most three times worse than the optimal.",
                    "label": 0
                },
                {
                    "sent": "And the proof follows from several things, but some intuition for it is that all of these customers for which to beliefs are not maximized are always 3 links away from an open facility in that original graph with.",
                    "label": 0
                },
                {
                    "sent": "With belief links.",
                    "label": 0
                },
                {
                    "sent": "So from that in a few other things you can guarantee that your solution is at most three times the optimum.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's with.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In 200% of the optimal but we also wanted to get some experimental results to see which one does better and we generated.",
                    "label": 0
                },
                {
                    "sent": "We generated some facility location data by ascential uniformly sampling points in the unit square.",
                    "label": 0
                },
                {
                    "sent": "An setting connection costs to equity and distance and setting all facility location facility costs to be equal.",
                    "label": 0
                },
                {
                    "sent": "So it's an example based clustering problem with metric distances.",
                    "label": 0
                },
                {
                    "sent": "So we ran an PLP with beleif decoding and with our greedy algorithm.",
                    "label": 0
                },
                {
                    "sent": "And the Barplots showed the error where the error is the percent cost above the LP lower bound.",
                    "label": 1
                },
                {
                    "sent": "We don't know what the actual optimum is.",
                    "label": 0
                },
                {
                    "sent": "So across several different facility cost settings and choosing several different numbers of points, algorithm always got the lower error than just arbitrary belief decoding.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So just out of curiosity, we compare this to Standard Max product algorithm which corresponds to the affinity propagation algorithm in this case.",
                    "label": 0
                },
                {
                    "sent": "And we also use this type of decoding whenever we had died.",
                    "label": 0
                },
                {
                    "sent": "Tide beliefs either by always maximizing beliefs or by not always maximizing beliefs, but using this greedy approach.",
                    "label": 0
                },
                {
                    "sent": "And for Standard Max product the difference was not that not that big.",
                    "label": 0
                },
                {
                    "sent": "In most cases beliefs were uniquely maximized, but in cases when they were not in particularly in this bottom figure, the greedy algorithm also gave us lower error.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And finally we ran some experiments on facility location benchmarks from the Operations Research Library.",
                    "label": 0
                },
                {
                    "sent": "And a lot of these were fairly small and were solved to optimality, but I'm showing barplots for the three larger problems which were not solved to optimality, and in this case the decoding doesn't make much difference for standard belief propagation, but it made a big difference.",
                    "label": 0
                },
                {
                    "sent": "For MPL, PDR was much higher with just maximize beliefs.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so that concludes my talk, so I described the graphical model for solving facility location problems using MP LP and greedy algorithm for decoding variables.",
                    "label": 1
                },
                {
                    "sent": "When the beliefs are tide.",
                    "label": 0
                },
                {
                    "sent": "So our approach has some optimality guarantees.",
                    "label": 1
                },
                {
                    "sent": "In particular, it's guaranteed to be at most three times the optimal and empirically it gives better solutions than just maximizing beliefs arbitrarily.",
                    "label": 0
                },
                {
                    "sent": "So thank you.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I have a question.",
                    "label": 0
                },
                {
                    "sent": "I have a question.",
                    "label": 0
                },
                {
                    "sent": "So you do block coding and dissent, right?",
                    "label": 0
                },
                {
                    "sent": "Yeah.",
                    "label": 0
                },
                {
                    "sent": "Always to the optimal DLP, or can it get stuck in a non optimal point?",
                    "label": 0
                },
                {
                    "sent": "I think for this case it could get stuck in a non optimal point.",
                    "label": 0
                },
                {
                    "sent": "So for this particular one of an encoding you're not I think guaranteed to find MP is not guaranteed to find the optimum of the LP.",
                    "label": 0
                },
                {
                    "sent": "So one interesting thing would be to look at different maybe binary encoding like multi label graph cuts, but I think with this case you can find counterexamples where it doesn't.",
                    "label": 0
                },
                {
                    "sent": "Can you say something about rate of convergence?",
                    "label": 0
                },
                {
                    "sent": "For MP LP it's very slow.",
                    "label": 0
                },
                {
                    "sent": "I had the slide in that, but I took it out.",
                    "label": 0
                },
                {
                    "sent": "I think it essentially depends on the number of overlaps.",
                    "label": 0
                },
                {
                    "sent": "Sets like the more of those sets you have, the slower the longer MP will take to converge.",
                    "label": 0
                },
                {
                    "sent": "So in this case it's much lower than Standard Max product.",
                    "label": 0
                }
            ]
        }
    }
}