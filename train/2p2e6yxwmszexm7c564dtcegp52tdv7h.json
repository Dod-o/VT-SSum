{
    "id": "2p2e6yxwmszexm7c564dtcegp52tdv7h",
    "title": "Relevant Overlapping Subspace Clusters on Categorical Data",
    "info": {
        "author": [
            "Xiao He, LMU Institut f\u00fcr Informatik, Ludwig-Maximilians Universit\u00e4t"
        ],
        "published": "Oct. 7, 2014",
        "recorded": "August 2014",
        "category": [
            "Top->Computer Science->Data Mining",
            "Top->Computer Science->Knowledge Extraction"
        ]
    },
    "url": "http://videolectures.net/kdd2014_he_categorical_data/",
    "segmentation": [
        [
            "I'm so who are from University of Munich.",
            "This is our joint work with colleagues jinfeng between account.",
            "Sometime I and cooperation partner Doctor Claudia plant from Helmholtz Center, Munich and Technical University of Munich.",
            "The title of our work is relevant overlapping subspace clusters on categorical data."
        ],
        [
            "Let's first have a look at our motivation."
        ],
        [
            "In rare in many real applications, categorical data are collected.",
            "There's a unique challenge for categorical data that the value of average value of an attribute have no order and spacing.",
            "There are many similarity measures for categorical data, but it is very difficult to select a suitable one for specific applique."
        ],
        [
            "Asian.",
            "Most existing category categorical clustering algorithms focus on 4 dimensional cluster but from a medium media dimensionality data.",
            "Sometimes clustering clusters your exist in subspaces but not in a four dimensional space.",
            "Here by the subset of attributes from the subspace is therefore one object can be assigned to multiple clusters.",
            "That means that one object can be can be assigned to a certain subspace in a certain class or and in another cluster in another subspace so traditional."
        ],
        [
            "Subspace clustering follow such ideas to solve the problem.",
            "They first define a subspace cluster with some input para meters like number of points, density, density threshold and some other thresholds to Maryland quality of cluster.",
            "Then they tried enumerate all the possible ones that satisfies the input parameters in a dimensional growth one.",
            "The."
        ],
        [
            "There are some problems of this method because they produce a large number of clusters with high redundancy.",
            "It is very hard for user to interpret the result because there are so many of them and we don't know which one is more important than the others.",
            "Effectively, this strongly rely on the para meters in both effectiveness and efficiency."
        ],
        [
            "So what is redundant overlapping clusters?",
            "Suppose we have sample data here and found cluster C1 with the first 5 objects and 1st four attributes.",
            "If you folder."
        ],
        [
            "Parts A2 and another cluster.",
            "They might be redundant because they share very similar objects and subspaces.",
            "So the question is, how much overlapping we do want to?",
            "Detect overlapping clusters because they may contain some most important information, but harmonic overlapping areas are acceptable."
        ],
        [
            "So in this work.",
            "We're focused on subspace clustering on categorical data, and we're trying to answer such three questions.",
            "The first one, how to evaluate the relevance between overlapping subsets, clusters and 2nd ones?",
            "How to obtain the most informative ones from them, and how to avoid para meters?",
            "We won't do it for automatic."
        ],
        [
            "We found that these three questions."
        ],
        [
            "Can be solved together based on a framework by compression based framework."
        ],
        [
            "So next introduced our optimization goal compression."
        ],
        [
            "The basic idea is to measure the relevance and informativeness of clusters by their contribution to comprise the data object inside clusters should be compact in the corresponding subspaces, and this compactness can be used to effectively effectively encode the data.",
            "The more we can code the data, the more regularity reformed from the data, and the better the clustering model fits to the beta."
        ],
        [
            "So here I gave a simple example to show that how we do compression the data.",
            "Can we compress the data with the clustering?",
            "Suppose we have a data categorical data matrix where each row is object and column attribute.",
            "We want to send it from a sender to receiver.",
            "And we know."
        ],
        [
            "That there might be 3 subclasses here with different colors.",
            "What we do is we we send the cluster separately 1 by 1."
        ],
        [
            "So first we need to describe each cluster of the content inside cluster.",
            "The values in the sub matrixes, and specifically we first calculate the probabilities of each category and then using entropy to approximate the coding cost.",
            "Besides, we need to describe which points belongs to which cluster and which attribute belongs to which cluster.",
            "The cluster assignment cost."
        ],
        [
            "Folder we need to code the cost of non class area to fulfill the lossless compression because this is fair to compare different clustering and then we need to code the probabilities that used to describe the data matrix.",
            "Finally we can code the metrics with the help of clustering."
        ],
        [
            "And here we show example of how we use coding cost to compare different clusterings.",
            "In this case the subsets clustering achieved minimal coding cost and tells us this one the best with our coding cost, but it only tell us which cluster is better but now."
        ],
        [
            "Out how can we achieve them?",
            "So next we propose algorithm to find the best one."
        ],
        [
            "Let's first formalize the problem.",
            "First, we name it minimum coding problem.",
            "The problem is to find the sub matrices.",
            "The set of matrices that allow the highest compression.",
            "There are so many possible sub matrices.",
            "Even more the combination of this sub matrices to form the clusterings.",
            "It's exponential to number of points and dimensionality.",
            "And so even when we have initial set of subspace clusters to find the best one with the most compression ratio, it's an NP hard problem which is equivalent to the weighted subcover problem set covering problem and.",
            "Minimal coding problem is even harder because we don't have initial set.",
            "Thus, we propose an heuristic search of them to look for the."
        ],
        [
            "Local minimum we found that with a large pure substance cluster we can compress the data a lot so that at first we've tried to find the pure subset cluster and then later we for the refund it to allow fault tolerant."
        ],
        [
            "So in our searching phase, where should we search for the initial clusters given a data metrics, we find the lowest attributes with Lloyd."
        ],
        [
            "Entropy, then form the 4th cluster with the most frequent values the similar."
        ],
        [
            "We found the attribute in the rest of attributes with the lowest entropy and form, say two with the first 2 attributes.",
            "Similarly we can form."
        ],
        [
            "Safe."
        ],
        [
            "Array to see M and then from this M clusters we choose the one that achieves minimum coding costs."
        ],
        [
            "Which is in this course in this case."
        ],
        [
            "Ace then we search we split the data space into two new ones and do the searching recursively until including a new cluster would not reduce the class coding cost anymore now, but now we have our initial set of clusters there."
        ],
        [
            "We tried to refine it into fitness first one, combining phase.",
            "We tried some heuristic method like combine them, split them or keep them guided by the coding cost and then we."
        ],
        [
            "Do it in a clustering fashion that we assign objects and attributes to the clusters first.",
            "Fix actually build, set or just the object set and next fixed objects at reformed subspaces.",
            "Do the do it iteratively.",
            "And finally we achieve the local minimum."
        ],
        [
            "The complexity of the algorithm is quadratic.",
            "Two dimensionality in the searching phase and then linear to number of objects and combining phase.",
            "It's quadratic to the number of overlap clusters and the rest of the face.",
            "It's linear to the number of dimensionality and objects.",
            "Next"
        ],
        [
            "I want to use some experiments to show the effectiveness effectiveness of our algorithm low cut."
        ],
        [
            "First, on both synthetic data set in real data sets will generate different synthetic data sets with different character characteristics.",
            "Specifically with first Gen generate the datasets set with subspace clusters as pure cluster, and then we randomly choose 10% of entrance in a cluster, an change their values randomly.",
            "The non error the non class error is also generated randomly."
        ],
        [
            "So we compare our method to three subspace clustering methods.",
            "Sub CAD clicks click and two perimetre fray categorical clustering method, HTC, HTC and three informative items and mining method telling MTV and Hyper Plus.",
            "We compared to Atom send money method because they are related to this.",
            "Atoms that can be regarded and subspace and objects support at and that is the object set from this table we can see that our method outperformed the others in terms of of cluster quality and."
        ],
        [
            "We can also provide very accurate subspace collect and well."
        ],
        [
            "Because our method is based on compression, so we are robust to outliers because clustering outliers will never reduce the coding cost from the finger.",
            "Kathy, with a different amount of outliers to the synthetic datasets and the other methods are degrade their performance in existence of outliers and our method is not affected by by allies anymore."
        ],
        [
            "And we also do some experiments on the real datasets.",
            "Three datasets from machine learning repository UCA and Vote congressional Vote Mushroom and supplies gene sequence data with our achieve good results."
        ],
        [
            "Let's look specify.",
            "Look at the splice junction gene sequence data specs.",
            "Junctions are points on a DNA sequence.",
            "So for sequence there might be some extra part.",
            "An intern part extra part will be used in the future and intra part will be removed.",
            "So in a sequence there might be extra boundary or intra excellent boundary.",
            "So in the boundaries there might be some.",
            "Similar pattern or similar?",
            "Values shown here and our task is to find the extra EI boundaries i.e boundaries.",
            "There are also some sequences neither belong to this call to boundary."
        ],
        [
            "Our algorithm performs very well on this data set and we can find both clusters with IE or EI boundaries.",
            "Besides, we were able to labor.",
            "Other points are objects and outliers, which belongs to neither of this sequence.",
            "This boundaries, and they said that we can find the positions in each sequence that we're boundaries R. Which substances were detected?"
        ],
        [
            "Finally, I want to summary our work."
        ],
        [
            "So our work farmer from from a full contributions here before the first one is data compression as an intuitive notion of similarity, we don't need to choose any similarity measure, and in the future work we want to extend it to the numerical data or makes the data type with both numerical and categorical attributes.",
            "We don't need to specify.",
            "A similarity measure for the for them and compression can solve them intuitively.",
            "Second layer, we can detect the most important, most informative overlapping subsets, clusters and we do not allow any redundancy.",
            "And our algorithm is fully parameter free without any input parameters and we can flexibly handling outliers."
        ],
        [
            "OK, thank you for your attention.",
            "If you have any questions, I'm happy to answer."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm so who are from University of Munich.",
                    "label": 0
                },
                {
                    "sent": "This is our joint work with colleagues jinfeng between account.",
                    "label": 0
                },
                {
                    "sent": "Sometime I and cooperation partner Doctor Claudia plant from Helmholtz Center, Munich and Technical University of Munich.",
                    "label": 0
                },
                {
                    "sent": "The title of our work is relevant overlapping subspace clusters on categorical data.",
                    "label": 1
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Let's first have a look at our motivation.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "In rare in many real applications, categorical data are collected.",
                    "label": 0
                },
                {
                    "sent": "There's a unique challenge for categorical data that the value of average value of an attribute have no order and spacing.",
                    "label": 1
                },
                {
                    "sent": "There are many similarity measures for categorical data, but it is very difficult to select a suitable one for specific applique.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Asian.",
                    "label": 0
                },
                {
                    "sent": "Most existing category categorical clustering algorithms focus on 4 dimensional cluster but from a medium media dimensionality data.",
                    "label": 0
                },
                {
                    "sent": "Sometimes clustering clusters your exist in subspaces but not in a four dimensional space.",
                    "label": 1
                },
                {
                    "sent": "Here by the subset of attributes from the subspace is therefore one object can be assigned to multiple clusters.",
                    "label": 0
                },
                {
                    "sent": "That means that one object can be can be assigned to a certain subspace in a certain class or and in another cluster in another subspace so traditional.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Subspace clustering follow such ideas to solve the problem.",
                    "label": 1
                },
                {
                    "sent": "They first define a subspace cluster with some input para meters like number of points, density, density threshold and some other thresholds to Maryland quality of cluster.",
                    "label": 1
                },
                {
                    "sent": "Then they tried enumerate all the possible ones that satisfies the input parameters in a dimensional growth one.",
                    "label": 0
                },
                {
                    "sent": "The.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "There are some problems of this method because they produce a large number of clusters with high redundancy.",
                    "label": 1
                },
                {
                    "sent": "It is very hard for user to interpret the result because there are so many of them and we don't know which one is more important than the others.",
                    "label": 1
                },
                {
                    "sent": "Effectively, this strongly rely on the para meters in both effectiveness and efficiency.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So what is redundant overlapping clusters?",
                    "label": 1
                },
                {
                    "sent": "Suppose we have sample data here and found cluster C1 with the first 5 objects and 1st four attributes.",
                    "label": 0
                },
                {
                    "sent": "If you folder.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Parts A2 and another cluster.",
                    "label": 0
                },
                {
                    "sent": "They might be redundant because they share very similar objects and subspaces.",
                    "label": 1
                },
                {
                    "sent": "So the question is, how much overlapping we do want to?",
                    "label": 1
                },
                {
                    "sent": "Detect overlapping clusters because they may contain some most important information, but harmonic overlapping areas are acceptable.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in this work.",
                    "label": 0
                },
                {
                    "sent": "We're focused on subspace clustering on categorical data, and we're trying to answer such three questions.",
                    "label": 1
                },
                {
                    "sent": "The first one, how to evaluate the relevance between overlapping subsets, clusters and 2nd ones?",
                    "label": 1
                },
                {
                    "sent": "How to obtain the most informative ones from them, and how to avoid para meters?",
                    "label": 1
                },
                {
                    "sent": "We won't do it for automatic.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We found that these three questions.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Can be solved together based on a framework by compression based framework.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So next introduced our optimization goal compression.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The basic idea is to measure the relevance and informativeness of clusters by their contribution to comprise the data object inside clusters should be compact in the corresponding subspaces, and this compactness can be used to effectively effectively encode the data.",
                    "label": 0
                },
                {
                    "sent": "The more we can code the data, the more regularity reformed from the data, and the better the clustering model fits to the beta.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So here I gave a simple example to show that how we do compression the data.",
                    "label": 0
                },
                {
                    "sent": "Can we compress the data with the clustering?",
                    "label": 0
                },
                {
                    "sent": "Suppose we have a data categorical data matrix where each row is object and column attribute.",
                    "label": 0
                },
                {
                    "sent": "We want to send it from a sender to receiver.",
                    "label": 0
                },
                {
                    "sent": "And we know.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "That there might be 3 subclasses here with different colors.",
                    "label": 0
                },
                {
                    "sent": "What we do is we we send the cluster separately 1 by 1.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So first we need to describe each cluster of the content inside cluster.",
                    "label": 0
                },
                {
                    "sent": "The values in the sub matrixes, and specifically we first calculate the probabilities of each category and then using entropy to approximate the coding cost.",
                    "label": 0
                },
                {
                    "sent": "Besides, we need to describe which points belongs to which cluster and which attribute belongs to which cluster.",
                    "label": 0
                },
                {
                    "sent": "The cluster assignment cost.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Folder we need to code the cost of non class area to fulfill the lossless compression because this is fair to compare different clustering and then we need to code the probabilities that used to describe the data matrix.",
                    "label": 0
                },
                {
                    "sent": "Finally we can code the metrics with the help of clustering.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And here we show example of how we use coding cost to compare different clusterings.",
                    "label": 0
                },
                {
                    "sent": "In this case the subsets clustering achieved minimal coding cost and tells us this one the best with our coding cost, but it only tell us which cluster is better but now.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Out how can we achieve them?",
                    "label": 0
                },
                {
                    "sent": "So next we propose algorithm to find the best one.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let's first formalize the problem.",
                    "label": 0
                },
                {
                    "sent": "First, we name it minimum coding problem.",
                    "label": 1
                },
                {
                    "sent": "The problem is to find the sub matrices.",
                    "label": 0
                },
                {
                    "sent": "The set of matrices that allow the highest compression.",
                    "label": 1
                },
                {
                    "sent": "There are so many possible sub matrices.",
                    "label": 0
                },
                {
                    "sent": "Even more the combination of this sub matrices to form the clusterings.",
                    "label": 0
                },
                {
                    "sent": "It's exponential to number of points and dimensionality.",
                    "label": 0
                },
                {
                    "sent": "And so even when we have initial set of subspace clusters to find the best one with the most compression ratio, it's an NP hard problem which is equivalent to the weighted subcover problem set covering problem and.",
                    "label": 0
                },
                {
                    "sent": "Minimal coding problem is even harder because we don't have initial set.",
                    "label": 0
                },
                {
                    "sent": "Thus, we propose an heuristic search of them to look for the.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Local minimum we found that with a large pure substance cluster we can compress the data a lot so that at first we've tried to find the pure subset cluster and then later we for the refund it to allow fault tolerant.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in our searching phase, where should we search for the initial clusters given a data metrics, we find the lowest attributes with Lloyd.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Entropy, then form the 4th cluster with the most frequent values the similar.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We found the attribute in the rest of attributes with the lowest entropy and form, say two with the first 2 attributes.",
                    "label": 0
                },
                {
                    "sent": "Similarly we can form.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Safe.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Array to see M and then from this M clusters we choose the one that achieves minimum coding costs.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Which is in this course in this case.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Ace then we search we split the data space into two new ones and do the searching recursively until including a new cluster would not reduce the class coding cost anymore now, but now we have our initial set of clusters there.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We tried to refine it into fitness first one, combining phase.",
                    "label": 0
                },
                {
                    "sent": "We tried some heuristic method like combine them, split them or keep them guided by the coding cost and then we.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Do it in a clustering fashion that we assign objects and attributes to the clusters first.",
                    "label": 1
                },
                {
                    "sent": "Fix actually build, set or just the object set and next fixed objects at reformed subspaces.",
                    "label": 0
                },
                {
                    "sent": "Do the do it iteratively.",
                    "label": 0
                },
                {
                    "sent": "And finally we achieve the local minimum.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The complexity of the algorithm is quadratic.",
                    "label": 0
                },
                {
                    "sent": "Two dimensionality in the searching phase and then linear to number of objects and combining phase.",
                    "label": 1
                },
                {
                    "sent": "It's quadratic to the number of overlap clusters and the rest of the face.",
                    "label": 0
                },
                {
                    "sent": "It's linear to the number of dimensionality and objects.",
                    "label": 0
                },
                {
                    "sent": "Next",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I want to use some experiments to show the effectiveness effectiveness of our algorithm low cut.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "First, on both synthetic data set in real data sets will generate different synthetic data sets with different character characteristics.",
                    "label": 0
                },
                {
                    "sent": "Specifically with first Gen generate the datasets set with subspace clusters as pure cluster, and then we randomly choose 10% of entrance in a cluster, an change their values randomly.",
                    "label": 0
                },
                {
                    "sent": "The non error the non class error is also generated randomly.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we compare our method to three subspace clustering methods.",
                    "label": 0
                },
                {
                    "sent": "Sub CAD clicks click and two perimetre fray categorical clustering method, HTC, HTC and three informative items and mining method telling MTV and Hyper Plus.",
                    "label": 0
                },
                {
                    "sent": "We compared to Atom send money method because they are related to this.",
                    "label": 0
                },
                {
                    "sent": "Atoms that can be regarded and subspace and objects support at and that is the object set from this table we can see that our method outperformed the others in terms of of cluster quality and.",
                    "label": 0
                }
            ]
        },
        "clip_34": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We can also provide very accurate subspace collect and well.",
                    "label": 0
                }
            ]
        },
        "clip_35": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Because our method is based on compression, so we are robust to outliers because clustering outliers will never reduce the coding cost from the finger.",
                    "label": 0
                },
                {
                    "sent": "Kathy, with a different amount of outliers to the synthetic datasets and the other methods are degrade their performance in existence of outliers and our method is not affected by by allies anymore.",
                    "label": 0
                }
            ]
        },
        "clip_36": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And we also do some experiments on the real datasets.",
                    "label": 0
                },
                {
                    "sent": "Three datasets from machine learning repository UCA and Vote congressional Vote Mushroom and supplies gene sequence data with our achieve good results.",
                    "label": 0
                }
            ]
        },
        "clip_37": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Let's look specify.",
                    "label": 0
                },
                {
                    "sent": "Look at the splice junction gene sequence data specs.",
                    "label": 0
                },
                {
                    "sent": "Junctions are points on a DNA sequence.",
                    "label": 1
                },
                {
                    "sent": "So for sequence there might be some extra part.",
                    "label": 0
                },
                {
                    "sent": "An intern part extra part will be used in the future and intra part will be removed.",
                    "label": 0
                },
                {
                    "sent": "So in a sequence there might be extra boundary or intra excellent boundary.",
                    "label": 0
                },
                {
                    "sent": "So in the boundaries there might be some.",
                    "label": 0
                },
                {
                    "sent": "Similar pattern or similar?",
                    "label": 0
                },
                {
                    "sent": "Values shown here and our task is to find the extra EI boundaries i.e boundaries.",
                    "label": 0
                },
                {
                    "sent": "There are also some sequences neither belong to this call to boundary.",
                    "label": 0
                }
            ]
        },
        "clip_38": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Our algorithm performs very well on this data set and we can find both clusters with IE or EI boundaries.",
                    "label": 0
                },
                {
                    "sent": "Besides, we were able to labor.",
                    "label": 0
                },
                {
                    "sent": "Other points are objects and outliers, which belongs to neither of this sequence.",
                    "label": 0
                },
                {
                    "sent": "This boundaries, and they said that we can find the positions in each sequence that we're boundaries R. Which substances were detected?",
                    "label": 0
                }
            ]
        },
        "clip_39": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Finally, I want to summary our work.",
                    "label": 0
                }
            ]
        },
        "clip_40": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So our work farmer from from a full contributions here before the first one is data compression as an intuitive notion of similarity, we don't need to choose any similarity measure, and in the future work we want to extend it to the numerical data or makes the data type with both numerical and categorical attributes.",
                    "label": 1
                },
                {
                    "sent": "We don't need to specify.",
                    "label": 0
                },
                {
                    "sent": "A similarity measure for the for them and compression can solve them intuitively.",
                    "label": 0
                },
                {
                    "sent": "Second layer, we can detect the most important, most informative overlapping subsets, clusters and we do not allow any redundancy.",
                    "label": 1
                },
                {
                    "sent": "And our algorithm is fully parameter free without any input parameters and we can flexibly handling outliers.",
                    "label": 0
                }
            ]
        },
        "clip_41": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, thank you for your attention.",
                    "label": 0
                },
                {
                    "sent": "If you have any questions, I'm happy to answer.",
                    "label": 0
                }
            ]
        }
    }
}