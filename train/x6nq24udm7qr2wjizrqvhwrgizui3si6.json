{
    "id": "x6nq24udm7qr2wjizrqvhwrgizui3si6",
    "title": "Parameter Learning Using Approximate MAP Inference",
    "info": {
        "author": [
            "Pawan Kumar Mudigonda, Department of Engineering Science, University of Oxford"
        ],
        "published": "Jan. 19, 2010",
        "recorded": "December 2009",
        "category": [
            "Top->Computer Science->Machine Learning->Linear Models"
        ]
    },
    "url": "http://videolectures.net/nipsworkshops09_kumar_pluamapi/",
    "segmentation": [
        [
            "So I apologize the second time round for the generic title of this talk.",
            "The reason for it is because it's actually two different talks and."
        ],
        [
            "The first one is nonlocal contrastive objectives, and it's worked really done by David and Daphne.",
            "Neither of them could be here, so I'm going to try and explain their work to you as well as."
        ],
        [
            "Like a. OK, so the aim here is to learn log linear models and so to introduce some notation.",
            "There you have some random variables, why you have some observed data X and you are extracting some features out which are represented as F and then you have a waiting for these features.",
            "So you have Peter transpose times F. That gives you a score.",
            "You exponentiated you sort of normalize it and that's your probability."
        ],
        [
            "So now if you given a whole bunch of training data, what you would like to do is is maximize the likelihood of that training data and then get a set of parameters that sort of give you the right answer.",
            "So this week the only problem here of course is that if you were to do maximum likelihood, you end up with this at this really hard to compute expected statistics term, which obviously not."
        ],
        [
            "Handle.",
            "So the way you you solve these problems is two different methods.",
            "Either you sort of approximate your expected statistics or sort of use a completely different objective which is somehow related to what you wanted to do.",
            "So 2 two really well known methods, and the 2nd second paradigm are pseudo likelihood and contrasted divergent."
        ],
        [
            "So I guess you all know what your likelihood is.",
            "It takes the instantiation that's been given to you given to us by the user and looks around it by basically changing one random variable and it compares the correct instantiation to the ones that we have sort of changed.",
            "And of course, you know there are these theorems about in the limit case, when you have infinite amount of data and if you could actually approximate your data distribution with a log linear model, then you can actually get to the optimum, which obviously is not a very practical theorem in any any sense, so, but it works well in practice and lots of people have shown good results for."
        ],
        [
            "Different datasets.",
            "Another thing that you could do is contrastive divergent, so you have your correct instantiation running MCMC chain for certain time, and then you get to a point and then you start comparing where you ended up with the correct instantiation, and this seems to work really well in practices."
        ],
        [
            "Well, so the common theme with both of them is is you take the one the guy that is actually the right solution that you wanted to be at and you pull up its probability.",
            "And obviously that means you'll have to push down the probability of some instantiations around it."
        ],
        [
            "Up OK do the the main problem with both pseudo likelihood and contrasted divergent.",
            "As far as I understand it is that they only look at like a neighbor small neighborhood around around your character instantiation.",
            "So if you had like this really multimodal distribution, then you know sort of pretty much ignoring that part there during your learning, and that might actually end up hurting you when you're testing the with the paramount."
        ],
        [
            "Parameters.",
            "OK, so here's here's our solution to it.",
            "You have sub objectives which look at only certain labelings of your random variables, and you have a whole set of these sub objectives OK.",
            "It's not really important right now what these objectives are and how you get them.",
            "We will get to that when we can come to the experiments, but the basic idea is do sort of maximum likelihood type.",
            "Optimization, but now you actually have this this partition function for a sub objective which is just this small little summation that you can actually do really really fast.",
            "OK, very simple setting of course, but it turns out it's actually."
        ],
        [
            "Quite powerful because if your data distribution was representable by this Theta parameterization, then within a sub objective you guaranteed that you will have a calibrated probability.",
            "So if you so the ratios of the of the data distribution are going to be exactly modelled in your in your learn parameters.",
            "So this is this radio."
        ],
        [
            "Be cool.",
            "Obviously it extends to beyond what I'm just saying here for one, subjective.",
            "If the subject is we're to overlap.",
            "Of course, in this case, for example, like you know, A&B are also calibrated because there's a path that goes from A to B across these different sub objectives."
        ],
        [
            "Compare that with pseudo likelihood you have these instantiations.",
            "You have these sort of star type graphs around it, which is obtained by just changing one random variables, labeling and no real connection between them as such so.",
            "So the results that that that we had in the previous slide are just far better, I suppose than than what we would like to have."
        ],
        [
            "Andy.",
            "OK, of course it did.",
            "Assume that you know you have this data distribution and it's all representable in this theater space.",
            "It's never really going to happen for any real application, but even we sort of observed in our empirical settings that it actually does encourage this calibration of probabilities as as we sort of train our method."
        ],
        [
            "OK, what are the advantages of the method so far?",
            "Well, completely avoided partition function, which is a really good thing.",
            "These sub objectives that I was talking about.",
            "Well, it turns out that you don't have to actually sort of constrain them in any way.",
            "You could use a greedy Hill climb.",
            "Being approximately map imprints really, really bad MCMC to sort of generate these subjectives iteratively.",
            "Keep adding them to your overall function.",
            "An really easily implement.",
            "The ideas are here."
        ],
        [
            "Connections to pseudo likelihood, like we already said, sooner likelihood can actually be thought of as a special case of what we were talking about, contrasted, divergent, and Fortunately it's like slightly different.",
            "'cause it's actually using these expectations from some other type of distribution.",
            "So the results that we are showing for this non local contrastive divergent objectives doesn't actually apply to contrastive divergent, but they're very, very similar labeling."
        ],
        [
            "OK, so how do you actually get to these objectives?",
            "Well, we take inspiration from like the the really cool cutting plane strategies that people have been coming up with.",
            "Safer learning, Max margin or for like adding cycle inequalities for MLP imprints and stuff.",
            "So here we go.",
            "So start off with pseudo likelihood 'cause easy thing to do and then for each of your data points you actually find out say the first best estimate right now or the N best maybe estimates right now.",
            "Try adding a sub objective corresponding to it.",
            "So there are two variants of it.",
            "One is you have your correct instantiation and you have maybe estimate you make one subjective out of this and put it in your set of sub objectives or you have the correct instantiation and all the other in sensations that you got for that particular data point.",
            "You make one big subjects of objective out of it.",
            "Add that in and then sort of run your algorithm.",
            "Now of course you would notice that there is a path in the first variant that kind of goes through like all the all the.",
            "Assignments in the second variant.",
            "So during our experiments will actually just sort of focus on the first one and leave the second variant out as a bit of an open question as to what what more, this would.",
            "This would give us."
        ],
        [
            "OK, so just a very simple illustration here.",
            "Why star is what has been given to me right now.",
            "Why prime is where all the all the mass of my probability is.",
            "I push that down and it's not as if I could get the right solution.",
            "There's another Y double prime that gets that mass and then I push that down and keep doing this until hopefully my correct instantiation's have a higher probability."
        ],
        [
            "Like I said, it's the algorithm by itself is like really inspired from these Max margin bids.",
            "So in Max margin you actually try to minimize some norm of the parameter vector subject to the constraint that the true instantiation's energy minus all other in sensations energy has to be greater than some some loss function.",
            "Otherwise I'll put a penalty on top of that.",
            "And the way you solve this, this problem is once again."
        ],
        [
            "With no constraints whatsoever, and then keep adding the MLP estimate that you found right now to your constraint set and keep doing this in the cutting plane wave until you actually get to the epsilon optimal solution.",
            "Of course very, very similar in flavor, but."
        ],
        [
            "Be the main two advantages of nonlocal contrastive objectives is first, it was really dealing with log linear models, So what you actually are getting out of the system are probabilities and not these Max margin Markov network type things.",
            "Secondly, this is a slightly probably more important difference in Max margin.",
            "You just satisfied so long as energy of the estimate minus energy of any other in sensation is greater than some value.",
            "Whereas here we really really trying to calibrate these probabilities.",
            "So you really want the ratios to be preserved if that is what you can actually do with it, whereas Max margin is just further about getting some some mass onto the under the true.",
            "The to the ground truth there."
        ],
        [
            "OK, so there any questions about the theory bed allowance for them right now.",
            "Otherwise I'll describe some experiments.",
            "So I guess it's not really decomposing the graphical model we're actually decomposing in the labels in the labeling space.",
            "They were, as far as I remember they were actually saying his big graphical model train.",
            "This tiny part of a tiny part of a tiny part of what we're saying is we have all these different labelings whose probabilities we have to compare, divide them up into these tiny subsets so it's a completely different sort of division that we're talking about here.",
            "Consistency in terms of.",
            "Oh yeah, yeah.",
            "So, the likelihood theorems all generalized by by this guy, and that follows from the fact that really pseudo likelihood is a special case here.",
            "No, no it doesn't.",
            "It doesn't matter.",
            "OK, so."
        ],
        [
            "I got these experimental slides last night, so I'll try to describe what's happening here.",
            "I'm not really very clear about the details, but."
        ],
        [
            "Observation person I can guess what's happening here is that you have an image is being divided up into these super pixels which you get from like a standard bottom up segmentation algorithm and it's sort of connected up together.",
            "The neighboring super Pixels are connected together and you have like this big CRF.",
            "You extract regions from features from every one of these super pixels, and then you sort of train your model to actually identify the semantic class given the features."
        ],
        [
            "OK, that part was quite quite clear.",
            "We actually are using about 100 images for training.",
            "Obviously has to be scaled up quite a bit 'cause envision you can't actually expecting learn much from just 100 images.",
            "So the type of experiments and like I said we use this variant one where we have a different subjective every time we generate the new AP estimate for every every training image."
        ],
        [
            "OK, so here are the results you have.",
            "On one axis, the MLP estimation algorithms that we used during during training and other access AP estimates used during testing.",
            "We compare with pseudo likelihood and we compare with this really simple CRF which has no edges in it.",
            "So it's very simple to learn.",
            "So the first thing to observe is I guess that pseudo likelihood Ray isn't doing very great.",
            "Is being beaten by the single tender, so even though the training error really goes down, it turns out doesn't do very well in test line."
        ],
        [
            "Secondly, when we actually have these connections are able to sort of model some sort of context between our super excels, which says, you know, grass and tree sort of tend to appear together in stuff.",
            "It really pushes the accuracy up, so you get like 30% improvement over these Singleton things.",
            "Oh sorry, I should have described that.",
            "So ICM is iterative conditional modes.",
            "The simplest of the algorithms.",
            "MP stands for Max product belief propagation and DD is dual decomposition that solves a linear programming relaxation for inference.",
            "Now you notice that there are stars as far as DD is concerned.",
            "It's because it was run for about 4000 iterations.",
            "It apparently then converge.",
            "It's also possible it has a lot of frustration, so it actually didn't give a good good estimate, which is why the results for DDR.",
            "You're worse than Max product, but I would suspect that that's fixable.",
            "I would expect that to be to be beating Max product.",
            "Soonish."
        ],
        [
            "OK, and finally of course there is this pronounced effect I believe of, you know, use the same algorithm for training that you were doing for testing.",
            "So the diagonals are really sort of starting to dominate, and I think you know lots of people have actually shown similar ish results like the Finley and your claims thing for Max Max margin learning, but these seem to be sort of slightly more pronounced here than in those cases.",
            "I might be mistaken, but I believe these are.",
            "This is a stronger evidence for saying you should be using the same inference an.",
            "Algorithm for learning as well as spore for testing."
        ],
        [
            "OK, just to summarize, his a really flexible framework where you have all these sub objectives.",
            "You take all sets of them and he's tried calibrate probabilities within this subset.",
            "There's some objective so that it's sort of spreads around through the entire set.",
            "I've got it.",
            "There is still sort of a lot of unanswered questions.",
            "So for example, whether the variant two is actually going to give us any gain over or variant one or not and many other things.",
            "So there's a lot of experiments to be done, but preliminary results look rather encouraging, and I think the frameworks actually nice and powerful.",
            "Any questions on the yeah?"
        ],
        [
            "Find Amsterdam.",
            "Generated meetings.",
            "Simple.",
            "And that's what you're thinking.",
            "So basically every sub objective has this really tiny maximum likelihood sort of a score, and then you can actually do gradient descent on each other.",
            "So I think right now there's like they're using LBH is to optimize every subjective.",
            "Right in the winter, things like getting with you just said yes right now, yeah, so.",
            "Sorry.",
            "So contrasted Origins actually does look at neighboring things around the correct instantiation.",
            "This is actually not doing that.",
            "This is looking at the MLP estimate at that point in time given by the parameters.",
            "Yes, and in fact I mean it's possible that these Max margin proofs might be applicable here.",
            "So Max margin says if you were to do this cutting pain thing in polynomial time, you get to the epsilon optimal solution.",
            "So it's possible that that's true here as well, but we don't have any proof yet.",
            "So like I said, the experiments are kind of like, you know, preliminary.",
            "So no, we haven't.",
            "But those are, those are good baselines to test on actually.",
            "So.",
            "Typically don't work for money we have left is able to do that, right?",
            "Right so.",
            "Asian boy, I want to have your family.",
            "OK, that's that's that's a really good question I'm I'm afraid.",
            "Like given that I'm actually not an author on this work, I'm sorry I'll have to defer this to David.",
            "I'll ask him this question and I will definitely come back to you with an answer for that so."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I apologize the second time round for the generic title of this talk.",
                    "label": 0
                },
                {
                    "sent": "The reason for it is because it's actually two different talks and.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The first one is nonlocal contrastive objectives, and it's worked really done by David and Daphne.",
                    "label": 0
                },
                {
                    "sent": "Neither of them could be here, so I'm going to try and explain their work to you as well as.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Like a. OK, so the aim here is to learn log linear models and so to introduce some notation.",
                    "label": 0
                },
                {
                    "sent": "There you have some random variables, why you have some observed data X and you are extracting some features out which are represented as F and then you have a waiting for these features.",
                    "label": 0
                },
                {
                    "sent": "So you have Peter transpose times F. That gives you a score.",
                    "label": 0
                },
                {
                    "sent": "You exponentiated you sort of normalize it and that's your probability.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So now if you given a whole bunch of training data, what you would like to do is is maximize the likelihood of that training data and then get a set of parameters that sort of give you the right answer.",
                    "label": 0
                },
                {
                    "sent": "So this week the only problem here of course is that if you were to do maximum likelihood, you end up with this at this really hard to compute expected statistics term, which obviously not.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Handle.",
                    "label": 0
                },
                {
                    "sent": "So the way you you solve these problems is two different methods.",
                    "label": 0
                },
                {
                    "sent": "Either you sort of approximate your expected statistics or sort of use a completely different objective which is somehow related to what you wanted to do.",
                    "label": 1
                },
                {
                    "sent": "So 2 two really well known methods, and the 2nd second paradigm are pseudo likelihood and contrasted divergent.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So I guess you all know what your likelihood is.",
                    "label": 0
                },
                {
                    "sent": "It takes the instantiation that's been given to you given to us by the user and looks around it by basically changing one random variable and it compares the correct instantiation to the ones that we have sort of changed.",
                    "label": 0
                },
                {
                    "sent": "And of course, you know there are these theorems about in the limit case, when you have infinite amount of data and if you could actually approximate your data distribution with a log linear model, then you can actually get to the optimum, which obviously is not a very practical theorem in any any sense, so, but it works well in practice and lots of people have shown good results for.",
                    "label": 1
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Different datasets.",
                    "label": 0
                },
                {
                    "sent": "Another thing that you could do is contrastive divergent, so you have your correct instantiation running MCMC chain for certain time, and then you get to a point and then you start comparing where you ended up with the correct instantiation, and this seems to work really well in practices.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Well, so the common theme with both of them is is you take the one the guy that is actually the right solution that you wanted to be at and you pull up its probability.",
                    "label": 0
                },
                {
                    "sent": "And obviously that means you'll have to push down the probability of some instantiations around it.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Up OK do the the main problem with both pseudo likelihood and contrasted divergent.",
                    "label": 0
                },
                {
                    "sent": "As far as I understand it is that they only look at like a neighbor small neighborhood around around your character instantiation.",
                    "label": 0
                },
                {
                    "sent": "So if you had like this really multimodal distribution, then you know sort of pretty much ignoring that part there during your learning, and that might actually end up hurting you when you're testing the with the paramount.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Parameters.",
                    "label": 0
                },
                {
                    "sent": "OK, so here's here's our solution to it.",
                    "label": 0
                },
                {
                    "sent": "You have sub objectives which look at only certain labelings of your random variables, and you have a whole set of these sub objectives OK.",
                    "label": 0
                },
                {
                    "sent": "It's not really important right now what these objectives are and how you get them.",
                    "label": 0
                },
                {
                    "sent": "We will get to that when we can come to the experiments, but the basic idea is do sort of maximum likelihood type.",
                    "label": 0
                },
                {
                    "sent": "Optimization, but now you actually have this this partition function for a sub objective which is just this small little summation that you can actually do really really fast.",
                    "label": 0
                },
                {
                    "sent": "OK, very simple setting of course, but it turns out it's actually.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Quite powerful because if your data distribution was representable by this Theta parameterization, then within a sub objective you guaranteed that you will have a calibrated probability.",
                    "label": 0
                },
                {
                    "sent": "So if you so the ratios of the of the data distribution are going to be exactly modelled in your in your learn parameters.",
                    "label": 0
                },
                {
                    "sent": "So this is this radio.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Be cool.",
                    "label": 0
                },
                {
                    "sent": "Obviously it extends to beyond what I'm just saying here for one, subjective.",
                    "label": 0
                },
                {
                    "sent": "If the subject is we're to overlap.",
                    "label": 0
                },
                {
                    "sent": "Of course, in this case, for example, like you know, A&B are also calibrated because there's a path that goes from A to B across these different sub objectives.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Compare that with pseudo likelihood you have these instantiations.",
                    "label": 0
                },
                {
                    "sent": "You have these sort of star type graphs around it, which is obtained by just changing one random variables, labeling and no real connection between them as such so.",
                    "label": 0
                },
                {
                    "sent": "So the results that that that we had in the previous slide are just far better, I suppose than than what we would like to have.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Andy.",
                    "label": 0
                },
                {
                    "sent": "OK, of course it did.",
                    "label": 0
                },
                {
                    "sent": "Assume that you know you have this data distribution and it's all representable in this theater space.",
                    "label": 0
                },
                {
                    "sent": "It's never really going to happen for any real application, but even we sort of observed in our empirical settings that it actually does encourage this calibration of probabilities as as we sort of train our method.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, what are the advantages of the method so far?",
                    "label": 0
                },
                {
                    "sent": "Well, completely avoided partition function, which is a really good thing.",
                    "label": 0
                },
                {
                    "sent": "These sub objectives that I was talking about.",
                    "label": 0
                },
                {
                    "sent": "Well, it turns out that you don't have to actually sort of constrain them in any way.",
                    "label": 0
                },
                {
                    "sent": "You could use a greedy Hill climb.",
                    "label": 0
                },
                {
                    "sent": "Being approximately map imprints really, really bad MCMC to sort of generate these subjectives iteratively.",
                    "label": 0
                },
                {
                    "sent": "Keep adding them to your overall function.",
                    "label": 0
                },
                {
                    "sent": "An really easily implement.",
                    "label": 0
                },
                {
                    "sent": "The ideas are here.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Connections to pseudo likelihood, like we already said, sooner likelihood can actually be thought of as a special case of what we were talking about, contrasted, divergent, and Fortunately it's like slightly different.",
                    "label": 0
                },
                {
                    "sent": "'cause it's actually using these expectations from some other type of distribution.",
                    "label": 0
                },
                {
                    "sent": "So the results that we are showing for this non local contrastive divergent objectives doesn't actually apply to contrastive divergent, but they're very, very similar labeling.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so how do you actually get to these objectives?",
                    "label": 0
                },
                {
                    "sent": "Well, we take inspiration from like the the really cool cutting plane strategies that people have been coming up with.",
                    "label": 0
                },
                {
                    "sent": "Safer learning, Max margin or for like adding cycle inequalities for MLP imprints and stuff.",
                    "label": 0
                },
                {
                    "sent": "So here we go.",
                    "label": 0
                },
                {
                    "sent": "So start off with pseudo likelihood 'cause easy thing to do and then for each of your data points you actually find out say the first best estimate right now or the N best maybe estimates right now.",
                    "label": 0
                },
                {
                    "sent": "Try adding a sub objective corresponding to it.",
                    "label": 0
                },
                {
                    "sent": "So there are two variants of it.",
                    "label": 0
                },
                {
                    "sent": "One is you have your correct instantiation and you have maybe estimate you make one subjective out of this and put it in your set of sub objectives or you have the correct instantiation and all the other in sensations that you got for that particular data point.",
                    "label": 0
                },
                {
                    "sent": "You make one big subjects of objective out of it.",
                    "label": 0
                },
                {
                    "sent": "Add that in and then sort of run your algorithm.",
                    "label": 0
                },
                {
                    "sent": "Now of course you would notice that there is a path in the first variant that kind of goes through like all the all the.",
                    "label": 0
                },
                {
                    "sent": "Assignments in the second variant.",
                    "label": 0
                },
                {
                    "sent": "So during our experiments will actually just sort of focus on the first one and leave the second variant out as a bit of an open question as to what what more, this would.",
                    "label": 0
                },
                {
                    "sent": "This would give us.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so just a very simple illustration here.",
                    "label": 0
                },
                {
                    "sent": "Why star is what has been given to me right now.",
                    "label": 0
                },
                {
                    "sent": "Why prime is where all the all the mass of my probability is.",
                    "label": 0
                },
                {
                    "sent": "I push that down and it's not as if I could get the right solution.",
                    "label": 0
                },
                {
                    "sent": "There's another Y double prime that gets that mass and then I push that down and keep doing this until hopefully my correct instantiation's have a higher probability.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Like I said, it's the algorithm by itself is like really inspired from these Max margin bids.",
                    "label": 0
                },
                {
                    "sent": "So in Max margin you actually try to minimize some norm of the parameter vector subject to the constraint that the true instantiation's energy minus all other in sensations energy has to be greater than some some loss function.",
                    "label": 0
                },
                {
                    "sent": "Otherwise I'll put a penalty on top of that.",
                    "label": 0
                },
                {
                    "sent": "And the way you solve this, this problem is once again.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "With no constraints whatsoever, and then keep adding the MLP estimate that you found right now to your constraint set and keep doing this in the cutting plane wave until you actually get to the epsilon optimal solution.",
                    "label": 0
                },
                {
                    "sent": "Of course very, very similar in flavor, but.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Be the main two advantages of nonlocal contrastive objectives is first, it was really dealing with log linear models, So what you actually are getting out of the system are probabilities and not these Max margin Markov network type things.",
                    "label": 0
                },
                {
                    "sent": "Secondly, this is a slightly probably more important difference in Max margin.",
                    "label": 0
                },
                {
                    "sent": "You just satisfied so long as energy of the estimate minus energy of any other in sensation is greater than some value.",
                    "label": 0
                },
                {
                    "sent": "Whereas here we really really trying to calibrate these probabilities.",
                    "label": 0
                },
                {
                    "sent": "So you really want the ratios to be preserved if that is what you can actually do with it, whereas Max margin is just further about getting some some mass onto the under the true.",
                    "label": 0
                },
                {
                    "sent": "The to the ground truth there.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so there any questions about the theory bed allowance for them right now.",
                    "label": 0
                },
                {
                    "sent": "Otherwise I'll describe some experiments.",
                    "label": 0
                },
                {
                    "sent": "So I guess it's not really decomposing the graphical model we're actually decomposing in the labels in the labeling space.",
                    "label": 0
                },
                {
                    "sent": "They were, as far as I remember they were actually saying his big graphical model train.",
                    "label": 0
                },
                {
                    "sent": "This tiny part of a tiny part of a tiny part of what we're saying is we have all these different labelings whose probabilities we have to compare, divide them up into these tiny subsets so it's a completely different sort of division that we're talking about here.",
                    "label": 0
                },
                {
                    "sent": "Consistency in terms of.",
                    "label": 0
                },
                {
                    "sent": "Oh yeah, yeah.",
                    "label": 0
                },
                {
                    "sent": "So, the likelihood theorems all generalized by by this guy, and that follows from the fact that really pseudo likelihood is a special case here.",
                    "label": 0
                },
                {
                    "sent": "No, no it doesn't.",
                    "label": 0
                },
                {
                    "sent": "It doesn't matter.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "I got these experimental slides last night, so I'll try to describe what's happening here.",
                    "label": 0
                },
                {
                    "sent": "I'm not really very clear about the details, but.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Observation person I can guess what's happening here is that you have an image is being divided up into these super pixels which you get from like a standard bottom up segmentation algorithm and it's sort of connected up together.",
                    "label": 0
                },
                {
                    "sent": "The neighboring super Pixels are connected together and you have like this big CRF.",
                    "label": 0
                },
                {
                    "sent": "You extract regions from features from every one of these super pixels, and then you sort of train your model to actually identify the semantic class given the features.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, that part was quite quite clear.",
                    "label": 0
                },
                {
                    "sent": "We actually are using about 100 images for training.",
                    "label": 0
                },
                {
                    "sent": "Obviously has to be scaled up quite a bit 'cause envision you can't actually expecting learn much from just 100 images.",
                    "label": 0
                },
                {
                    "sent": "So the type of experiments and like I said we use this variant one where we have a different subjective every time we generate the new AP estimate for every every training image.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so here are the results you have.",
                    "label": 0
                },
                {
                    "sent": "On one axis, the MLP estimation algorithms that we used during during training and other access AP estimates used during testing.",
                    "label": 0
                },
                {
                    "sent": "We compare with pseudo likelihood and we compare with this really simple CRF which has no edges in it.",
                    "label": 0
                },
                {
                    "sent": "So it's very simple to learn.",
                    "label": 0
                },
                {
                    "sent": "So the first thing to observe is I guess that pseudo likelihood Ray isn't doing very great.",
                    "label": 0
                },
                {
                    "sent": "Is being beaten by the single tender, so even though the training error really goes down, it turns out doesn't do very well in test line.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Secondly, when we actually have these connections are able to sort of model some sort of context between our super excels, which says, you know, grass and tree sort of tend to appear together in stuff.",
                    "label": 0
                },
                {
                    "sent": "It really pushes the accuracy up, so you get like 30% improvement over these Singleton things.",
                    "label": 0
                },
                {
                    "sent": "Oh sorry, I should have described that.",
                    "label": 0
                },
                {
                    "sent": "So ICM is iterative conditional modes.",
                    "label": 0
                },
                {
                    "sent": "The simplest of the algorithms.",
                    "label": 0
                },
                {
                    "sent": "MP stands for Max product belief propagation and DD is dual decomposition that solves a linear programming relaxation for inference.",
                    "label": 0
                },
                {
                    "sent": "Now you notice that there are stars as far as DD is concerned.",
                    "label": 0
                },
                {
                    "sent": "It's because it was run for about 4000 iterations.",
                    "label": 0
                },
                {
                    "sent": "It apparently then converge.",
                    "label": 0
                },
                {
                    "sent": "It's also possible it has a lot of frustration, so it actually didn't give a good good estimate, which is why the results for DDR.",
                    "label": 0
                },
                {
                    "sent": "You're worse than Max product, but I would suspect that that's fixable.",
                    "label": 0
                },
                {
                    "sent": "I would expect that to be to be beating Max product.",
                    "label": 0
                },
                {
                    "sent": "Soonish.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, and finally of course there is this pronounced effect I believe of, you know, use the same algorithm for training that you were doing for testing.",
                    "label": 0
                },
                {
                    "sent": "So the diagonals are really sort of starting to dominate, and I think you know lots of people have actually shown similar ish results like the Finley and your claims thing for Max Max margin learning, but these seem to be sort of slightly more pronounced here than in those cases.",
                    "label": 0
                },
                {
                    "sent": "I might be mistaken, but I believe these are.",
                    "label": 0
                },
                {
                    "sent": "This is a stronger evidence for saying you should be using the same inference an.",
                    "label": 0
                },
                {
                    "sent": "Algorithm for learning as well as spore for testing.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, just to summarize, his a really flexible framework where you have all these sub objectives.",
                    "label": 0
                },
                {
                    "sent": "You take all sets of them and he's tried calibrate probabilities within this subset.",
                    "label": 0
                },
                {
                    "sent": "There's some objective so that it's sort of spreads around through the entire set.",
                    "label": 0
                },
                {
                    "sent": "I've got it.",
                    "label": 0
                },
                {
                    "sent": "There is still sort of a lot of unanswered questions.",
                    "label": 0
                },
                {
                    "sent": "So for example, whether the variant two is actually going to give us any gain over or variant one or not and many other things.",
                    "label": 0
                },
                {
                    "sent": "So there's a lot of experiments to be done, but preliminary results look rather encouraging, and I think the frameworks actually nice and powerful.",
                    "label": 0
                },
                {
                    "sent": "Any questions on the yeah?",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Find Amsterdam.",
                    "label": 0
                },
                {
                    "sent": "Generated meetings.",
                    "label": 0
                },
                {
                    "sent": "Simple.",
                    "label": 0
                },
                {
                    "sent": "And that's what you're thinking.",
                    "label": 0
                },
                {
                    "sent": "So basically every sub objective has this really tiny maximum likelihood sort of a score, and then you can actually do gradient descent on each other.",
                    "label": 0
                },
                {
                    "sent": "So I think right now there's like they're using LBH is to optimize every subjective.",
                    "label": 0
                },
                {
                    "sent": "Right in the winter, things like getting with you just said yes right now, yeah, so.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "So contrasted Origins actually does look at neighboring things around the correct instantiation.",
                    "label": 0
                },
                {
                    "sent": "This is actually not doing that.",
                    "label": 0
                },
                {
                    "sent": "This is looking at the MLP estimate at that point in time given by the parameters.",
                    "label": 0
                },
                {
                    "sent": "Yes, and in fact I mean it's possible that these Max margin proofs might be applicable here.",
                    "label": 0
                },
                {
                    "sent": "So Max margin says if you were to do this cutting pain thing in polynomial time, you get to the epsilon optimal solution.",
                    "label": 0
                },
                {
                    "sent": "So it's possible that that's true here as well, but we don't have any proof yet.",
                    "label": 0
                },
                {
                    "sent": "So like I said, the experiments are kind of like, you know, preliminary.",
                    "label": 0
                },
                {
                    "sent": "So no, we haven't.",
                    "label": 0
                },
                {
                    "sent": "But those are, those are good baselines to test on actually.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Typically don't work for money we have left is able to do that, right?",
                    "label": 0
                },
                {
                    "sent": "Right so.",
                    "label": 0
                },
                {
                    "sent": "Asian boy, I want to have your family.",
                    "label": 0
                },
                {
                    "sent": "OK, that's that's that's a really good question I'm I'm afraid.",
                    "label": 0
                },
                {
                    "sent": "Like given that I'm actually not an author on this work, I'm sorry I'll have to defer this to David.",
                    "label": 0
                },
                {
                    "sent": "I'll ask him this question and I will definitely come back to you with an answer for that so.",
                    "label": 0
                }
            ]
        }
    }
}