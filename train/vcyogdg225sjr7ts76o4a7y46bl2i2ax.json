{
    "id": "vcyogdg225sjr7ts76o4a7y46bl2i2ax",
    "title": "Game Theory & Clustering",
    "info": {
        "author": [
            "Marcello Pelillo, University Ca' Foscari"
        ],
        "published": "April 1, 2009",
        "recorded": "February 2009",
        "category": [
            "Top->Mathematics->Game Theory",
            "Top->Computer Science->Machine Learning->Clustering"
        ]
    },
    "url": "http://videolectures.net/ssll09_pelillo_gath/",
    "segmentation": [
        [
            "OK, so thanks as the various said today I will be talking about.",
            "Framework we have been developing in my group since 2003 or so.",
            "For a wise data clustering, the nice thing about this approach we actually makes us a lot, I mean quite excited, is that it attaches three different very interesting areas, namely graph theory, optimization theory and game theory.",
            "And actually the talk today will actually attach all these fields.",
            "We start from graph theory and will be just ask a very fundamental and simple question.",
            "What is a cluster?",
            "I mean, we just ask from the very beginning, trying to formalize the very notion of a cluster in a technical way.",
            "And this leads us to a basic fundamental concept in graph theory, which is actually the notion of a click.",
            "Actually, the notion of maximum click, then actually the notion of the click turns out to be the right notion of the cluster for a very simplified version of the clustering problem, where the similarities are assumed to be Boolean mine."
        ],
        [
            "01 So we ask ourselves, how can I generalize the maximum click concept in order to deal with more general similarities between data and this will lead us to the field of optimization.",
            "Actually both combinatorial and continuous optimization, and then in the final step of this store, the final part of this talk I'll be talking about how we can generalize the framework in the most general case where there is no constraints of the.",
            "Only compatibility's on the affinity's and this will lead us to game theory, so it will.",
            "It will be a sort of walk within these three fields."
        ],
        [
            "Actually, the the talk of the lecture will be divided into 3 parts, one hour here each approximately.",
            "In the very first, in the first part I will start with the notion of a click and with the notion of a dominant set, which is our generalization of the notion of a maximal clique, and will.",
            "I will just introduce the basic properties of dominant set and their connections to optimization theory and then I will show how algorithmically we can find dominant sets in arbitrary graphs.",
            "Then in the second part there will talk about several variations on the basic theme.",
            "I will talk about the complexity of finding dominant sets and how we can reduce this complexity because dominant sets I mean they have the problem that they cannot be easily applied to very large datasets and so we will discuss the issue of how we can use dominant set when you have.",
            "High resolution images or video or very large data set.",
            "We talk about how can I get a hierarchical partition of the data and so we talk about several variations of the basic theme of dominant set.",
            "In the third part, finally the third hour I will talk about the transition from optimization theory to game theory.",
            "So in the final part of the talk I will just address the question.",
            "How can we generalize this dominant set framework in such a way that I can deal with arbitrary similarities between data?",
            "I mean for example non symmetric similarities or even negative similarities, which quite often happen in practical applications."
        ],
        [
            "So let's start from the beginning.",
            "First of all, let me briefly.",
            "Define the so called pairwise clustering problem and the outset.",
            "Let me make a distinction between the pairwise clustering problem and the so called central clustering problem.",
            "Actually, there are two variations of the clustering problem.",
            "The first one is called Central, sometimes, or if you like feature based.",
            "And the second one is the one I'm talking about, which is pairwise.",
            "So the difference that the kind of input data that you give to the clustering algorithm.",
            "So if you use this framework this approach, I mean central clustering.",
            "This means that the objects you want to cluster you want to classify without a teacher without a supervisor.",
            "Because we are talking about unsupervised learning represented in terms of vectors in terms of feature vectors.",
            "So the basic assumption here is that each object associated vector of fixed length of.",
            "Real numbers, and this means that each object can be represented as a point in an N dimensional space and then and then we can have.",
            "We can calculate for example the distance Euclidean distance between points and get a sort of similarity in order to see whether two points have to be clustered together or not.",
            "So the the path is that we start from the representation, which is a vectorial one.",
            "Then we end up with the similarity or with the distance.",
            "And then we apply the clustering algorithm.",
            "So in one sense the input to the clustering algorithm is a set of feature vectors.",
            "Well, there are situations though.",
            "Let me just say that one very popular representative for this kind of algorithm is so called K means algorithms, which just actually takes as input a set of vectors, and it tentatively finds K prototypes.",
            "Here's the number of clusters have to be defined before hand.",
            "It finds tentatively K prototypes.",
            "Then it defines a partitions according to a nearest neighbor rule, and then iteratively finds new prototype and so on, so forth until convergence.",
            "OK, so this is one of the classic approach for central clustering.",
            "Now there are applications though were a feature based.",
            "Representation is for the objects we are dealing with is not easy to obtain.",
            "Maybe the classical example is when the objects to be described and to be clustered to be grouped are represented in terms of graphs.",
            "Namely, the objects can be decomposed into parts and parts.",
            "Do not happen without any relation, so there is some relation between the parts and this means that the objects can be described in terms of a graph.",
            "Now once you have a graph representation foreign object, it is very difficult to obtain a Victoria representation, so it's it's quite impossible to start from a graph which is actually a bidimensional structure in relational structure.",
            "And to map this structure into a point in a feature space.",
            "So in this case it is quite difficult to obtain a feature based representation for all the objects.",
            "On the other hand, and this is the good news, there are ways for computing similarities between graphs.",
            "Computing similarities between arbitrary graphs may be difficult problem.",
            "It's NP hard in the general case, but for some instances of graphs, for example trees, the similarities between trees can be computed in polynomial time, so in this case I'm lacking a feature based representation.",
            "I can't use K means, for example or any other central clustering algorithm, but nevertheless I'm able to obtain similarities between the object.",
            "So what I get is a similarity, OK?",
            "Several other situations where actually it is difficult to obtain at pictorial representation, but on the other hand, you may obtain quite easily similarity between the objects you want to cluster.",
            "So pairwise algorithms or the pairwise framework does apply exactly.",
            "In these cases, it's a pairwise clustering algorithm accepts as input a matrix of similarities, it doesn't, it doesn't accept it, it doesn't know anything.",
            "About the way in which we are representing the objects, they maybe they might be graphs or vector or whatever.",
            "It just accepts as input a matrix of similarities and starting from from this similarities it will try to partition the data according to certain coherency criteria.",
            "So in one sense, pairwise clustering is more general than central clustering, because here we need to know something essential about the way in which we are representing the object.",
            "Not only that, we also.",
            "Need that the objects be represented in terms of vectors.",
            "Here we just forget about that.",
            "Any representation is OK, provided that I have a means to compute similarities between object OK.",
            "So in this talk I'll be.",
            "I'll be talking about pairwise clustering problem and so we accept a pairwise clustering algorithm accepts as input a set of N objects and an end times N matrix of pairwise similarities, and the idea of course is to partition the input data the input objects into maximally coherent groups.",
            "So yeah, there's a very simple example we have.",
            "I mean, we can perceptually see that there are four clusters, and so of course we want.",
            "In this case the points.",
            "The objects are represented in terms of points in a plane, and the distance maybe can be Euclidean distance.",
            "And of course we want as the output.",
            "Do we have a laser pointer or something?",
            "Maybe I can.",
            "OK, otherwise it will be OK. And so we have four groups.",
            "But of course this is a very simple case because there are there can be very different situations.",
            "For example, here we have a situation where there are four clusters different in size.",
            "There we have also four clusters, but the difference between the second case in the first one is that the clusters do have very arbitrary shape.",
            "They are not compact clusters, and in the final example we've both.",
            "We have compact clusters.",
            "And we have arbitrary shape.",
            "So the problem is quite challenging.",
            "And actually it's the main problem in unsupervised learning.",
            "Actually unsupervised learning means."
        ],
        [
            "Classroom, so the problems of clustering objects into groups into coherent groups finds application in a number of different domains from image processing and computer vision by informatics information retrieval and so on so forth.",
            "It's a very important problem."
        ],
        [
            "So now we.",
            "We should just start from the from the beginning asking a very simple question.",
            "What is a cluster?",
            "Because this will be the starting point from this from this framework.",
            "Let me also say that.",
            "Many pairwise clustering algorithms existing in the literature start from a different question.",
            "They basically I'm thinking for example of an algorithm which actually we will encounter later which is called, for example normalized, cut and cut.",
            "And there are spectral clustering algorithms also.",
            "Which are quite popular nowadays, so the this kind of algorithms actually start from a different question.",
            "I give you a set of objects.",
            "I give you the similarities between objects and then the question is how can I partition the input data in the best possible way in such a way that the classes are maximally coherent.",
            "So the starting question is not what is a cluster?",
            "And then I define technically what is a cluster and then I go ahead by defining a partition started from the notion of the cluster.",
            "The idea is that how can I partition the data in the best possible way?",
            "So usually what is done is that one defines an objective function among all possible partitions of the input data, and so the idea is just to find the optimal partition according to the to the objective function.",
            "So now we start from a different question, we just try to answer technically in this question.",
            "What is a cluster?",
            "There is no universally accepted definition of the cluster, I mean formally, but at least we can say that.",
            "Everybody will confirm that a cluster, whatever it means, must satisfy these two informal criteria and internal criterion, and then external criterion.",
            "Both are important for defining the notion of a cluster.",
            "The internal criterion says that.",
            "A set of objects is a cluster if all the objects inside the clusters are similar to each other.",
            "OK, well this is not enough for defining the notion of a cluster, because for example if I take let me into this way, if I take.",
            "For example, this cluster here.",
            "Maybe another cluster here?",
            "OK, so if I take a strict subset, proper subset of this class and let's say this one, this is not a cluster technically speaking because it is included in a larger coherent group.",
            "This satisfies the internal criterion though, but it doesn't satisfy the external criterion.",
            "So in order for a + 4 for a set of objects to be defined, the cluster we also have to ask that all objects outside the cluster should be highly the similar to the ones inside.",
            "OK, so this is important.",
            "These two criteria actually will be the the basic starting point from the definition of a dominant set.",
            "So."
        ],
        [
            "Usually when we.",
            "He was plastering problem.",
            "We represent the data, the objects to be clustered in terms of a graph.",
            "Where the vertices of the graph represent the objects to be clustered.",
            "The edges represent similarity relations and the weights on the edge represent the similarity.",
            "The quantitative similarity between the two objects.",
            "So we have a technical speaking, at least in this part of the talk.",
            "We have a non directed weighted graph and we assume that the weights are known negative, so the weights are greater than or equal to zero OK?",
            "A common way to represent.",
            "Directed weighted graph edge.",
            "Weighted graph is by using this pulled weighted adjacency matrix.",
            "This is an M by N matrix where N is the number of vertices in the graph an at the intersection of the row number I in the column.",
            "Rumba Jay.",
            "I just find the similarity between I&J OK. We assume that the main diagonal of this matrix is 0."
        ],
        [
            "OK, so let's start from a very simple, an unrealistic scenario.",
            "Let's try to answer our original question.",
            "What is a cluster when the similarities between the objects are binary?",
            "So in this case we have just that two objects are either similar or dissimilar.",
            "We are not allowing intermediate values of the similarity or similarity.",
            "In other words, the.",
            "The graph is an unweighted graph is an undirected, unweighted graph, and the adjacency matrix is just at 01 metrics.",
            "OK, so let's ask ourselves, what is the sort of structure in this graph that satisfies the two criteria, the internal one and the external one?",
            "The answer is a very classic notion in graph theory, the notion of a maximal clique.",
            "Yesterday we had a talk by Richard Hartley talked about notion of a click from different purposes.",
            "But well, let me just remind what is click, which is a maximal clique.",
            "I give you a graph, for example this one.",
            "OK so it clicks.",
            "See is just a subset of mutually adjacent vertices.",
            "Then we have a notion of a maximal quick.",
            "A maximal clique is a click which is not contained in any larger click.",
            "So for example, this is this one.",
            "Is a click of course, and is also maximal, and this one also is a click and is also maximal, but.",
            "This one is a click but is not maximal because it is contained in a larger click OK. Well, it's not written there.",
            "We have a father notion.",
            "The notion of a maximum click.",
            "To be distinguished from the notion of a maximal click, a maximum click is a click having largest cardinality, so there is no larger click.",
            "So in this case there is only one maximum click and this one.",
            "This is this one is maximal that is not maximum.",
            "Of course.",
            "Any maximum clique is also maximal, but the opposite is not usually true.",
            "For example, in this case we have a maximum clique, which is not maximum.",
            "We also have a notion which we will encounter later on, just called the strictly maximal clique.",
            "Let me just mention that we call it strictly.",
            "Maximum click.",
            "This is a click which is the following property.",
            "OK, if this is a maximal clique.",
            "All the viruses outside it.",
            "Kind of have.",
            "More than two edges.",
            "Incident on those vertices, because if this vertex here, which is outside the click, has three edges, so it's incident to this one.",
            "This will not be a maximally OK.",
            "So what we can say is that if C is a maximal clique.",
            "Then for all J outside C. The the number of edges.",
            "Let's call this way the number of edges between J and an arbitrary I where I is a member of C must be less than or equal, must be less than or equal to the cardinality of, sorry less.",
            "Strictly lessons cutting out it's OK, otherwise it cannot be maximum.",
            "Well, strictly maximal clique as.",
            "This I mean the number of edges started from any outside external verdicts incident to the vertices inside must be strictly less than cardinality of C -- 1.",
            "The reason for having strictly maximal quicks is that maximal cliques, in one sense, are unstable in the sense that if I if I for example take this, click here.",
            "And I drop this verdicts and they add this vertex then this.",
            "Is another maximal quick, so it's unstable quarter then quoted in the sense that I can just take one vertex in the maximum clique, throw it away at the external vertex, and then I get a new maximum click while strictly maximal clique are more stable since no external vertices, so it's an external vertex a sufficient number of edges incident to the internal vertices, so I can just take one of these voters, threw it away, another another one.",
            "OK, so it's in one sense a more stable this is.",
            "A distinction which will be reflected in the structure of local Optima we have.",
            "We have an optimization problem, continuous optimization problem for example.",
            "You might have strict local optimum and local optimum which are not strict and we shall see later on that.",
            "Actually there is a one to one correspondence between the notion of a strictly maximum quick and the notion of a strict maximum.",
            "OK. Now it's clear that when.",
            "We are just have binary similarities.",
            "The notion of a maximum clique is exactly the notion we are looking for.",
            "The notion of the cluster coincide with an open sides with the notion of a maximum click.",
            "It satisfies both the internal and external criteria.",
            "So now the question is, how can we generalize the notion of a maximum Click to edge weighted graphs?",
            "And this is where dominant set coming."
        ],
        [
            "To introduce into the picture.",
            "Yeah, you might have several several maximal cliques, yeah?",
            "OK, so.",
            "Now our objective is to generalize the notion of a maximum clique to edge weighted graphs.",
            "OK, let's wait.",
            "Let's take an edge weighted graph.",
            "Let's take a set of vertices S. And let's take a vertex I belonging to us, so we are in this situation.",
            "We have a set S of vertices and we're vertex I inside.",
            "Probably we have a picture here.",
            "Yeah, OK, now let's start the picture.",
            "OK, so in this set there are other vertices probably.",
            "And so we just sum all the similarities between I an all the vertices inside S and get what we call the average weighted degree of I with respect to S so that some which is the sum over all AJ where J belongs to S is just sort of average similarity average weighted similarity between I and the other objects in C in NS.",
            "Sorry.",
            "Now we derive a notion of a relative similarity between two objects I&J remember that AIJ the elements of the matrix of the similarity matrix.",
            "AIJ represents an absolute similarity between two objects.",
            "OK, now we introduce the notion of a relative similarity.",
            "We are in this situation here.",
            "I don't have a laser pointer.",
            "OK, let's do this way.",
            "We have set S. We have a vertex or we got J and a vertex.",
            "I inside SJ is outside us.",
            "So the number that I write here is the absolute similarity between I&J.",
            "Now introduce 5S.",
            "IJ is just the difference between the absolute similarity between I&J and the average similarity between I and all the objects in S. OK, so this is very simple notion.",
            "I'm just comparing the similarity of I&J with respect to how eyes similar to the other object in J.",
            "Of course this Phi can be negative or positive is positive when the absolute similarity between I&J is greater than the relative similarity itself.",
            "And this negative the other way around.",
            "Now comes the main definition."
        ],
        [
            "Which allows us to.",
            "Define the notion of a dominant set.",
            "It's actually looks quite complicated, but it's quite simple.",
            "It's a recursive definition.",
            "Let's consider a subset of vertices S and let's take a vertex I belonging to S in this example.",
            "OK, so the recursive definition.",
            "This actually allows us to assign to each vertex.",
            "Await OK thanks.",
            "So this allows us to assign to each vertex in S await.",
            "Remember that we have an edge weighted graph, so in this way we are.",
            "We are assigning weights to the vertices, but with respect to S. So we have a set S. We have a vertex I and then if the set S is a Singleton then my definition WSI is 1 by the finish and otherwise if I have more than one object in the in the set.",
            "What I'm doing is just the following and just summing all the relative similarities these files.",
            "Between I and all the remaining objects in S, but this is not just a plain sound, I'm just waiting.",
            "This is a weighted average.",
            "Actually, I'm waiting each of these relative similarities with the weight assigned to J with respect to S -- I.",
            "So here is where the recursive definition comes into the picture.",
            "Where to find this guy here and this guy in their recursive way?",
            "OK, so intuitively what we're doing is just too.",
            "To set to see how similar is I on the average with respect to all other elements in S except I of course.",
            "But we are waiting this sum with the relative weights.",
            "OK, once we have this numbers then we can define the total sum.",
            "We can define the total weight of this of this set by just summing all the contributions here OK?",
            "Now let me give you a very intuitive."
        ],
        [
            "Interpretation of this number here.",
            "It turns out that the sign of WSI.",
            "It's important for defining the notion of a dominant set.",
            "Let's try and see what happens in these two simple cases.",
            "Consider this graph here.",
            "We have these three vertices, 2, three and four.",
            "They are highly similar to each other.",
            "In fact, the similarities is constant is 10.",
            "What happens if I try to add this vertex here to this set to 234?",
            "Well, intuitively, I expect that the overall similarity of this new set consisting of 1234 will decrease because I'm adding something to the set which is less similar with respect to the internal similarity.",
            "OK, so this is reflected by the fact that W one with respect to 1234 is less than 0.",
            "So if I compute this number here and this number is less than zero, what I can conclude this this is the basic intuition is that if I try and AB one to the set then I will decrease the internal similarity of the of the set OK. Let's consider this other example.",
            "Here we have 678.",
            "They are highly similar.",
            "They are similar to each other.",
            "We can say highly, of course, because there is another vertex 5 which is more similar.",
            "But if we just look at 678, they form a coherent group, at least at that scale.",
            "So what happens if I add this vertex here to this set?",
            "I would expect that the overall similarity will increase and this is reflected by the fact that W. 5 So the weight assigned to this guy here with respect to this budget.",
            "Is greater than zero OK?"
        ],
        [
            "Go to sign.",
            "Of this way still tells us in interesting things about what happens when I try and that.",
            "But this is two groups of data, and so this leads us to the main definition of a dominant set.",
            "We are in the symmetric case right now, so we are assuming that the similarity are symmetric and they are no negative.",
            "So we define a subset of vertices at dominant set.",
            "If these two conditions are satisfied, we require that for all internal vertices for all.",
            "I'm in SWSI is greater than zero, which means that this set S is high internal coherence.",
            "But we know that internal damage and it is not the only thing we we need to care about, but we also we also need an external criterion.",
            "So we require that for all I not belonging to S external to us, this number is less than zero, which means that if I try to add I to the set, SI will decrease the internal similarity.",
            "So in one sense, a dominant set is a maximally coherent set of vertices maximally in the sense that as soon as I try to add something else.",
            "The overall similarity will decrease OK.",
            "So this is our basic definition of a dominant set.",
            "Now, now we have formalized the notion of a cluster technically, so from now on our notion of the cluster coincide with the notion of a dominant set.",
            "Here is a numerical example.",
            "Here the set 123 is dominant.",
            "You can see internally it's high, coherently, higher coherency, and then outside the various is outside are less similar to the vertices inside.",
            "No let's, let's start from the beginning.",
            "We started from the case where the metrics of similarities was 01 was binary and now we have introduced the notion in that case.",
            "In the binary case, we saw that the notion of a cluster actually is the notion of a maximal clique.",
            "Now we are in the weighted case and we introduced this notion of a dominant set, and now the natural question is what is the relationship between a maximum clicks and the dominant set?",
            "Or another way around?",
            "If I have an unweighted graph where the edges are weighted either by one or zero, then what is the dominant set?",
            "So the answer is that 401 matrices dominant set will coincide with strictly maximal clique.",
            "OK, actually.",
            "Notice that here we have a strictly maximum clique.",
            "If instead of having less than zero, here we have less than or equal to 0.",
            "So we relax this condition.",
            "Then we would have maximal cliques, but as I said before, maximal cliques are less stable in the sense that I can throw away a vertex and add another one.",
            "I still get another maximum clique while we are interested in stable solutions.",
            "OK, so that's the reason why here we have strictly less than rather than less than or equal to.",
            "The second condition.",
            "This one.",
            "OK, this condition this is.",
            "So this is a technical condition in the sense which mean essentially this.",
            "If I give you a cluster, I expect that every subset of this cluster will be internal coherent.",
            "So in this sense I mean the intuition behind this is just that if I if I get it.",
            "Yeah, if you drop that you won't have again.",
            "You won't have this this one to one correspondence.",
            "You will have a weaker notion which is not in one to one correspondence with the notional mclee.",
            "OK, no."
        ],
        [
            "Now we have defined the notion of a dominant set.",
            "Now let's put ourselves from a computational perspective.",
            "Let's see how can I find a dominant set and then we maybe we can ask how can I partition a set of data into dominant sets?",
            "OK in order to find dominant set.",
            "Actually we could.",
            "For example we could arrive.",
            "I don't know a greedy algorithm.",
            "For example, finding maximum maximum click, not a maximum click in a graph that I can do via straightforward greedy algorithm.",
            "I just think about it.",
            "I just order the vertices in the graph by degree.",
            "It just take the highest degree node and I keep adding vertice.",
            "Is checking that when I add a vertex the click condition is satisfied at the end of this process of this greedy process will end up with the maximal clique, which is not necessarily a maximum one.",
            "Actually finding the maximum clique in graph is an NP hard problem.",
            "It's NP hard even to approximate, so it's a very very difficult problem.",
            "But finding a maximal clique it's a simple problem actually can be found in quadratic time.",
            "So instead of devising greedy like algorithms or you know, standard algorithms for finding a dominant set, we follow quite different route.",
            "Actually we transform the combinatorial problem that purely combinatorial problem of finding a dominant set in the graph into a purely continuous optimization problem.",
            "Once we have done that, we can exploit the full Arsenal of continuous optimization techniques that is available in the optimization literature.",
            "Actually, our problem will be a quadratic optimization problem and there are zillions of algorithms for solving quadratic optimization problem.",
            "Actually we will use a very simple one inspired from evolution.",
            "Again theory.",
            "OK so.",
            "So now we are just seeing how can I transform the know.",
            "How can I characterize the notion of a dominant set in terms of the continuous optimization problem?",
            "So let's take an edge weighted graph G and let's a be the adjacency matrix of this graph.",
            "So let's consider this problem.",
            "The problem of finding the maximum of this quadratic function.",
            "This is written here in matrix form if you like.",
            "I can just write it down in.",
            "The more familiar way so X transpose X.",
            "Is just the sum overall I sum overall JIAJXIXJ.",
            "If you actually, you can also write this in a different way.",
            "You can write it this way.",
            "Well, now we're talking about weighted now, so I will show this different way.",
            "Later on when we go back to the unweighted case.",
            "Yeah, in this case it's a metric.",
            "Yeah it's symmetric and non negative.",
            "Actually with the 0 diagonal.",
            "OK, so consider the problem of finding the maximum of this quadratic polynomial homogeneous polynomial over the standard simplex.",
            "The standard simplex is a very simple geometrical structure.",
            "It's it's the intersection of the plane of equation.",
            "Sum XI equal to 1.",
            "This means the sum of all's I must be equal to 1, so the plane with that equation with a positive author of the space.",
            "So we require that all XI must be greater than or equal to 0.",
            "And actually."
        ],
        [
            "This is an illustration of the standard simplex.",
            "When N is equal to three, just is just a triangle.",
            "And."
        ],
        [
            "So consider this problem.",
            "And let me just point out that.",
            "Other approaches to pairwise clustering, notably one introduced a few years ago by sort.",
            "Karen Boyer and also by Perona and Freeman in ACV ACV, is a European conference on computer vision leads to quite similar but fundamentally different quadratic optimization problem.",
            "The basic idea in this approach, which actually the sort of spectral clustering, is to find the largest eigenvalues and then the corresponding eigenvector of the agency of the adjacency matrix.",
            "Hey in this case.",
            "Finding the largest eigenvalue and the corresponding eigenvector.",
            "Can be found by maximizing X transpose X.",
            "Not on the standard simplex, but on the sphere.",
            "Now The thing is that this problem is computationally much simpler than that problem.",
            "If I have to find the global maximum of this X transpose X over this fear, which leads me to find the maximum eigenvalue.",
            "This can be done in polynomial time in cubic time.",
            "Actually, while finding the maximum even in the 01 case I showed this.",
            "In a few seconds, even if the matrix is 01, finding this maximum is NP complete, even sent, be hard even to approximate because it's related to the maximum clique problem.",
            "OK, so the objective function is exactly the same, but the domain is completely different.",
            "In one case we have to find the maximum over the sphere in case we have to find maximum over the standard simplex."
        ],
        [
            "OK, so now we were able to prove this theorem.",
            "Which actually establishes a one to one correspondence between the.",
            "Local Max strict local maximizer of X transpose X over the simplex.",
            "So the solution of the problem and dominant sets.",
            "OK, so this is the first part of the theorem.",
            "Suppose that you give me a dominant asset and you say that you know that this set S is a dominant set, OK?",
            "So I can construct what is called the weighted characteristic vector of this set.",
            "The weighted characteristic vector is just a vector of N elements and components as many components as there are vertices in the graph.",
            "The Earth component will be 0 if I does not belong to us, will be the ratio between this weight WSI which is positive by definition since S is a dominant set, this is positive and the total weight assigned to us.",
            "So here this is positive.",
            "This is a positive quantity.",
            "Of course, if I sum up all these components in the vector, I end up with a point in the standard simplex.",
            "The some of the components is equal to 1 and all the components are graded.",
            "Are equal to zero OK?",
            "Now, if S is a dominant set this point in the simplex is a strict local maximizer of the function X transpose X, so it's a solution of the optimization problem.",
            "On the other hand.",
            "If you give me a vector X star and you say, well, this is a strict local optimum for your problem, a strict local maximizer of X transpose X over the simplex, then what I can do is there to take the so called support of the vector.",
            "The support of the vector is just a set of indices corresponding to positive components.",
            "It is not a positive component.",
            "The indices corresponding to positive component.",
            "This will correspond to viruses in the graph.",
            "This will be a subset of vertices of the original graph.",
            "Then what I can prove is that S. Sorry Sigma, the support will be a dominant set provided that this condition is satisfied.",
            "This is actually a technical condition which is a generic.",
            "I mean it doesn't happen often in practice because it happens when.",
            "You have a very symmetric CC.",
            "Situation, for example the 01 case.",
            "Then you might have this situation, but in the general case it's very unlikely that it happens.",
            "It has to do with the way in which we can avoid spurious solutions.",
            "I'll be I'll be talking about this in just one minute.",
            "Now the nice thing is that this result is actually a generalization of a well known result in graph theory, which is known as the mosque in Strauss theorem.",
            "Them asking Styles theorem establishes a one to one correspondence between the click number of a graph, namely the cardinality of the largest click and the global optimizer of a quadratic function over the standard simplex.",
            "Let me just write it down just to.",
            "To let you know what is the Mouse King style serum, actually nice thing is that masking and Strauss proved this theorem just in order to provide a different shorter proof to a well known theorem in extremal graph theory, which is known as the two rounds theorem.",
            "the Rams theorem is a very well known theorem which states something about extremal graphs.",
            "So the main objective of muskiness tiles that were pure mathematicians, of course.",
            "But just to provide a different shorter proof, but actually it is very interesting computational implications.",
            "So what masking and Strauss did was the following.",
            "Let's consider an unweighted graph.",
            "OK, so we have a set of vertices and a set of edges and then directed unweighted graph.",
            "8 is the adjacency matrix of the graph is 01 matrix.",
            "Let's consider the problem of maximizing.",
            "X transpose AX over the standard.",
            "Simplest exactly the same problem, but now the difference that a is a binary matrix.",
            "So much skin and Strauss proved that.",
            "There is a one to one correspondence between the clique number of the graph, which is denoted by.",
            "Omega G This is the cardinality of the largest click in the graph.",
            "And the value of the objects of the maximizer of this function.",
            "So if X star is a global optimizer of X, transpose X over the standard simplex then.",
            "The clique number of the graph is just equal to 1 / 1 -- F X transpose and they also show that.",
            "There is actually a one to one correspondence between global maximizers in the form of a characteristic vectors, an maximal cliques.",
            "So any Max, sorry, maximum clicks.",
            "Any maximum clique will induce a global maximizer of the objective function.",
            "Any global optimizer in the form of a characteristic vector will induce a maximally.",
            "Um?",
            "Now what I was saying about Spirit solution is the following.",
            "In the original formulation of masking, Strauss.",
            "There might be spurious solutions, I mean, global optimizers of the objective function which are not in the form of a characteristic vector.",
            "OK, so let's consider this very simple graph.",
            "And we know here there are two maximum clicks.",
            "Is this one?",
            "Not this one.",
            "We can take the standard simplex.",
            "We know from the masking Strauss theorem that.",
            "This point here will be a global optimizer of the objective function and this point here will be a global optimizer of the objective function, but.",
            "The bad news is that if I take all the points on the segment connecting these two points, all these points will be also global optimizer for the objective function.",
            "So there is an Infinity of object of global optimizers.",
            "All these points here will not be in the form of characteristic vector, because of course they belong to the inside of the standard simplex.",
            "So in order to avoid this problem in order to avoid spurious solutions recently, manual bombs are from the University of Vienna.",
            "Just proposed to add a regularization term which is just plus 1 / 2 X transpose X.",
            "This is just the square of the norm of the vector and then he proved the theorem which established the one to one correspondence between local optimizers of the objective function and maximal cliques.",
            "Global optimizers objective function and maximum clicks and show that these are the only global slash local optimizer there.",
            "There is no spurious solution in this.",
            "In this new objective function, so from a computational perspective, if you have to find a maximal clique or a maximum click in the graph, you just maximize this over the standard simplex.",
            "Of course, there is no guarantee that you will find the global optimum, but maybe you will find a good local optimum.",
            "OK."
        ],
        [
            "So.",
            "Now, once we have characterized.",
            "Donegan said"
        ],
        [
            "In terms of solutions of continuous optimization problem, how can we find them?",
            "Well, actually, a straightforward way to do that this is actually quadratic linearly constrained optimization problem.",
            "I can take any textbook from optimization theory, let's say Bloomberg or whatever.",
            "I go to the chapter on nonlinear optimization.",
            "There are plenty of algorithms to do that.",
            "Of course the simplest one would be sort of gradient gradient descent.",
            "I start from the interior of the simplex and I keep following the gradient.",
            "Until I reach the boundary, then I project.",
            "The vector gradient over the over the boundary and I go home this way, but instead of using this kind of algorithms which also requires some tuning regarding the step size, because of course when I take direction of the gradient, I have to say exactly how much I move along that direction and this is a parameter which is not easy to set.",
            "Instead of doing that, we just notice that there is a whole class of parallel dynamical systems.",
            "From evolutionary game theory, which serves very well, our part was actually this class of dynamics is called replicator dynamics, and this are the most are the simplest dynamical systems developed in this branch of game theory, which is called evolutionary game theory.",
            "Let me just give you the basic intuition behind this kind of dynamics.",
            "Actually, evolutionary game theory was introduced in the seven late 70s in the 80s.",
            "Actually by John Minor Smith, who tried to import into biology the the notions and the tools of game theory.",
            "Game theory will talk about game theory in the third part of this stock, game theory was introduced by phenomenon and was developed by John Nash in order to deal with complex situations among rational beings, namely humans.",
            "And there was the notion of rationality, which was fundamental in game theory.",
            "So the trick of John Miner Smith was to apply game theory to the animal behavior to the animal, to the biological context where we typically speaking they don't.",
            "We don't assume that animals are rational in the sense we are, so the trick was to import game theory which was developed for modeling situations among.",
            "Human agents to do biology and to model the evolution of behavior within species.",
            "So we assume a large population of individuals belonging to the same species.",
            "We assume technically that the population is actually an infant population because we want to use relative frequencies, and we want to treat this relative frequencies as probabilities and this individuals will interact.",
            "Probably there is shortage of water or food or whatever, so.",
            "There are usually some conflict between these individuals and this conflict between pairs of individuals is model in terms of the game.",
            "Technically speaking OK.",
            "So.",
            "In this framework, in evolutionary game theory, players do not behave rationally.",
            "Innocence, human do but act instead according to SOA genetically prep program it strategy.",
            "So we assume that each individual will always play that strategy.",
            "For example, if I if I if I meet another guy and then I have a comfort with this guy, I may want to attack.",
            "So I always attack or I just so I just go away.",
            "You know, I have my own strategy.",
            "I can have a double.",
            "It can be an Oak or whatever.",
            "So now the the basic difference between traditional game theory and evolution against theory is that we can measure utility in quantitative way.",
            "Actually, utility is measured in terms of their winning fitness so.",
            "In terms of the reproductive success of that strategy, so how much does how much that strategy pays in that context OK?",
            "So.",
            "Let me just write down the basic intuition behind this replicator dynamics.",
            "Um?",
            "So we assume that we have a finite set of strategies.",
            "Let's say let's call it J.",
            "We have any strategies?",
            "And we have what is called, typically a payoff matrix W. This is a.",
            "And then times N matrix where N is the number of strategies.",
            "WIJ, sorry wha represents the payoff that nice strategist gets when it plays against the J strategist.",
            "OK, in the general case, the payoff matrix doesn't need to be symmetric.",
            "Actually, economist or social scientists use very frequently nonsymmetric matrices, sometimes even negative mattress is.",
            "So in the general case there is no restriction.",
            "On the structure of this matrix.",
            "OK, so.",
            "Let's suppose that we are at time T. Another note by XIT.",
            "The proportion of players in the population which plays strategy I OK, so we have an strategy I can define what is called a state vector vector obtained by just putting together all these.",
            "Of this numbers and of course, this is a vector which belongs to the standard simplex, 'cause this is actually a probability distribution.",
            "OK, so there's some apps around.",
            "There are no known negative.",
            "OK, so.",
            "What happens if I?",
            "Compute WX and I take the I component of this, which we can call lots of pie I.",
            "This is just the sum over all JWIJXJ.",
            "So if XJ is just the probability of picking at chase strategies and WIJ, is the payoff to deny strategist?",
            "Yes, when it meets Ajay strategists then this is just the average pay off that a nice strategist gets.",
            "On the average in this this game OK?",
            "I can also take the average of the average.",
            "I can just average all this pie I can get.",
            "I call it \u03c0, just the sum over all IXI.",
            "Hi I and this is the average fitness over the entire population.",
            "OK, so the basic idea behind the replicator dynamics is that good strategies, which means strategies that are better than the average will spread overtime, while bad strategies, which means bad with respect to the average will get extent.",
            "OK, so actually.",
            "What evolutionary game theory does is to propose dynamical models, which explains the evolution of behavior within a species.",
            "So one possibility could be, for example, to consider a dynamical system like this in continuous time.",
            "So I take the partial derivative of XI with respect to T and I just do the following.",
            "This is exciting and then.",
            "\u03a0 IX minus by X. OK, so now it is clear that if by some I is greater than \u03c0.",
            "Then this would be greater than zero.",
            "This is of course relative probability is greater than zero.",
            "This will be will increase.",
            "This means that overtime the proportion XI will increase.",
            "Yeah, I mean.",
            "Simplex.",
            "Yeah, of course, of course, yeah.",
            "What, of course, the other way around?",
            "If this is less than that.",
            "So in other words, if we divide if we take this.",
            "If we divide by XI, the relative rating of increase is just equal to the difference between the average fitness.",
            "Sorry, the average.",
            "Yeah, the average fitness of strategy at the average fitness over the entire population.",
            "There is also a discrete time version of the Replicator dynamics.",
            "This is the simplest model actually.",
            "The discrete time is the following.",
            "So the proportion of I strategies at time T plus one is equal to XIT.",
            "Divided by \u03c0 at time T. This is actually a normalization factor, so actually.",
            "You can write this down.",
            "This is some overall JXIXJT by JT.",
            "So we are sure that this is a normalization factor in order that we have a dynamics in the simplex.",
            "So again, it is straightforward to see that if this happens.",
            "So if by I is greater than \u03c0, then this will increase.",
            "This will be greater than the previous one, and so on.",
            "So this means that the strategy will spread over the population, otherwise it will.",
            "It will disappear.",
            "OK, so this is exactly what is.",
            "What we have in this transparency here in this slide of these two versions.",
            "The first thing to notice is that in both cases the continuous time dynamics and the discrete time dynamics both leaves the lift.",
            "The simplex invariant.",
            "Technically speaking, this means that any trajectory starting from the interior of the simplex we remain in the simplex for all future time.",
            "OK, this is very simple to check.",
            "Actually here you have just checked it the same for all I of XI T plus one is equal to 1, this is.",
            "Straight forward to check all the components are non negative here.",
            "In order to check this we have to see that the tangent.",
            "Are parallel to the to the to the simplex and this actually happens because if you take the same over over all these guys here, the sum is 0.",
            "This means that this dynamical system will always move within the simplex.",
            "But indeed, the most important fact about Replicator Dynamics is not just."
        ],
        [
            "But it's the so-called fundamental theorem of natural selection.",
            "Elemental team Natural selection, which goes back to every fissure in the 30, actually allows us to say something quite important about replicator dynamics.",
            "When the payoff matrix is symmetric.",
            "So actually, technically speaking, the the theorem states that if the matrix the payoff matrix is symmetric, then the both the continuous time and discrete time dynamics you have a Lyapunov function.",
            "And this level of function is exactly X transpose WX, which is the average fitness over the entire population.",
            "So this means level of function means it will increase overtime.",
            "OK, so anytime technically speaking for the continuous time dynamics, the derivative of the function F of the time is greater than zero is strictly increasing along non constant trajectory for discrete time dynamics the value at each time.",
            "At each step the value of that function will increase.",
            "So actually we have a mean to find local Optima of quadratic function over the standard simplex.",
            "These dynamical systems do work in the simplex at each.",
            "At each step they increase the objective function, so eventually they will end up in a strictly local maximum.",
            "So the idea is to use replicator dynamics for finding the optimization.",
            "The optimisers of the objective function and then dominant sets.",
            "Let me just say one thing.",
            "Notice that in both dynamics, especially the discrete time one, which is the one actually used impr."
        ],
        [
            "Technical applications we don't have any stepsides.",
            "If you use gradient descent, for example for finding the minimum of function, we have to set up the step size.",
            "I mean in theory Gradina send works provided at the step size is close to 0, tends to 0.",
            "OK, so if we have a finite step sides, you're not guaranteed that the function we are optimizing will actually decrease.",
            "Yeah, we don't have any step side, so there is no parameter to set.",
            "There is an implicit stepsize we take every step.",
            "We take a finite step and still we are guaranteed that the function in the next step would be greater than the previous one.",
            "OK."
        ],
        [
            "OK, so we can put everything together now.",
            "Let's start from the beginning.",
            "We want to solve the problem of finding a cluster in a set of data.",
            "So in in a graph where to find the notion of the cluster in terms of a dominant set.",
            "But dominant sets are in one to one correspondence to local optimizers of X transpose X over the simplex.",
            "So I just use replicated dynamics.",
            "I use a the matrix A.",
            "Is the payoff matrix, so by the fundamental theorem of natural selection, the algorithm starting from any point in interior of the simplex.",
            "Eventually will converge to restrict local optimizer.",
            "There is only one case it can happen.",
            "In practice that the algorithm will converge.",
            "To saddle point.",
            "So the point actually is also a stationary point for the dynamics, because the gradient is 0.",
            "But the good news is that stationary points I mean, saddle points, do not have any finite basing attraction around them.",
            "So I can just when this happens I can just perturb the point a little bit and will be with take another route until it converges to a local optimum, OK?",
            "OK, so I think it's time to have a break.",
            "This is a straightforward implementation for the replicator dynamics in Matlab.",
            "It's just three three statements.",
            "3 lines OK, so after the break we will talk about the application of this framework to the image segmentation problem OK?"
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so thanks as the various said today I will be talking about.",
                    "label": 0
                },
                {
                    "sent": "Framework we have been developing in my group since 2003 or so.",
                    "label": 0
                },
                {
                    "sent": "For a wise data clustering, the nice thing about this approach we actually makes us a lot, I mean quite excited, is that it attaches three different very interesting areas, namely graph theory, optimization theory and game theory.",
                    "label": 0
                },
                {
                    "sent": "And actually the talk today will actually attach all these fields.",
                    "label": 0
                },
                {
                    "sent": "We start from graph theory and will be just ask a very fundamental and simple question.",
                    "label": 0
                },
                {
                    "sent": "What is a cluster?",
                    "label": 0
                },
                {
                    "sent": "I mean, we just ask from the very beginning, trying to formalize the very notion of a cluster in a technical way.",
                    "label": 0
                },
                {
                    "sent": "And this leads us to a basic fundamental concept in graph theory, which is actually the notion of a click.",
                    "label": 0
                },
                {
                    "sent": "Actually, the notion of maximum click, then actually the notion of the click turns out to be the right notion of the cluster for a very simplified version of the clustering problem, where the similarities are assumed to be Boolean mine.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "01 So we ask ourselves, how can I generalize the maximum click concept in order to deal with more general similarities between data and this will lead us to the field of optimization.",
                    "label": 0
                },
                {
                    "sent": "Actually both combinatorial and continuous optimization, and then in the final step of this store, the final part of this talk I'll be talking about how we can generalize the framework in the most general case where there is no constraints of the.",
                    "label": 0
                },
                {
                    "sent": "Only compatibility's on the affinity's and this will lead us to game theory, so it will.",
                    "label": 0
                },
                {
                    "sent": "It will be a sort of walk within these three fields.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Actually, the the talk of the lecture will be divided into 3 parts, one hour here each approximately.",
                    "label": 0
                },
                {
                    "sent": "In the very first, in the first part I will start with the notion of a click and with the notion of a dominant set, which is our generalization of the notion of a maximal clique, and will.",
                    "label": 0
                },
                {
                    "sent": "I will just introduce the basic properties of dominant set and their connections to optimization theory and then I will show how algorithmically we can find dominant sets in arbitrary graphs.",
                    "label": 1
                },
                {
                    "sent": "Then in the second part there will talk about several variations on the basic theme.",
                    "label": 0
                },
                {
                    "sent": "I will talk about the complexity of finding dominant sets and how we can reduce this complexity because dominant sets I mean they have the problem that they cannot be easily applied to very large datasets and so we will discuss the issue of how we can use dominant set when you have.",
                    "label": 1
                },
                {
                    "sent": "High resolution images or video or very large data set.",
                    "label": 0
                },
                {
                    "sent": "We talk about how can I get a hierarchical partition of the data and so we talk about several variations of the basic theme of dominant set.",
                    "label": 0
                },
                {
                    "sent": "In the third part, finally the third hour I will talk about the transition from optimization theory to game theory.",
                    "label": 1
                },
                {
                    "sent": "So in the final part of the talk I will just address the question.",
                    "label": 0
                },
                {
                    "sent": "How can we generalize this dominant set framework in such a way that I can deal with arbitrary similarities between data?",
                    "label": 0
                },
                {
                    "sent": "I mean for example non symmetric similarities or even negative similarities, which quite often happen in practical applications.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So let's start from the beginning.",
                    "label": 0
                },
                {
                    "sent": "First of all, let me briefly.",
                    "label": 0
                },
                {
                    "sent": "Define the so called pairwise clustering problem and the outset.",
                    "label": 0
                },
                {
                    "sent": "Let me make a distinction between the pairwise clustering problem and the so called central clustering problem.",
                    "label": 0
                },
                {
                    "sent": "Actually, there are two variations of the clustering problem.",
                    "label": 0
                },
                {
                    "sent": "The first one is called Central, sometimes, or if you like feature based.",
                    "label": 0
                },
                {
                    "sent": "And the second one is the one I'm talking about, which is pairwise.",
                    "label": 0
                },
                {
                    "sent": "So the difference that the kind of input data that you give to the clustering algorithm.",
                    "label": 0
                },
                {
                    "sent": "So if you use this framework this approach, I mean central clustering.",
                    "label": 0
                },
                {
                    "sent": "This means that the objects you want to cluster you want to classify without a teacher without a supervisor.",
                    "label": 0
                },
                {
                    "sent": "Because we are talking about unsupervised learning represented in terms of vectors in terms of feature vectors.",
                    "label": 0
                },
                {
                    "sent": "So the basic assumption here is that each object associated vector of fixed length of.",
                    "label": 0
                },
                {
                    "sent": "Real numbers, and this means that each object can be represented as a point in an N dimensional space and then and then we can have.",
                    "label": 0
                },
                {
                    "sent": "We can calculate for example the distance Euclidean distance between points and get a sort of similarity in order to see whether two points have to be clustered together or not.",
                    "label": 0
                },
                {
                    "sent": "So the the path is that we start from the representation, which is a vectorial one.",
                    "label": 0
                },
                {
                    "sent": "Then we end up with the similarity or with the distance.",
                    "label": 0
                },
                {
                    "sent": "And then we apply the clustering algorithm.",
                    "label": 0
                },
                {
                    "sent": "So in one sense the input to the clustering algorithm is a set of feature vectors.",
                    "label": 0
                },
                {
                    "sent": "Well, there are situations though.",
                    "label": 0
                },
                {
                    "sent": "Let me just say that one very popular representative for this kind of algorithm is so called K means algorithms, which just actually takes as input a set of vectors, and it tentatively finds K prototypes.",
                    "label": 0
                },
                {
                    "sent": "Here's the number of clusters have to be defined before hand.",
                    "label": 0
                },
                {
                    "sent": "It finds tentatively K prototypes.",
                    "label": 0
                },
                {
                    "sent": "Then it defines a partitions according to a nearest neighbor rule, and then iteratively finds new prototype and so on, so forth until convergence.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is one of the classic approach for central clustering.",
                    "label": 0
                },
                {
                    "sent": "Now there are applications though were a feature based.",
                    "label": 0
                },
                {
                    "sent": "Representation is for the objects we are dealing with is not easy to obtain.",
                    "label": 0
                },
                {
                    "sent": "Maybe the classical example is when the objects to be described and to be clustered to be grouped are represented in terms of graphs.",
                    "label": 0
                },
                {
                    "sent": "Namely, the objects can be decomposed into parts and parts.",
                    "label": 0
                },
                {
                    "sent": "Do not happen without any relation, so there is some relation between the parts and this means that the objects can be described in terms of a graph.",
                    "label": 0
                },
                {
                    "sent": "Now once you have a graph representation foreign object, it is very difficult to obtain a Victoria representation, so it's it's quite impossible to start from a graph which is actually a bidimensional structure in relational structure.",
                    "label": 0
                },
                {
                    "sent": "And to map this structure into a point in a feature space.",
                    "label": 0
                },
                {
                    "sent": "So in this case it is quite difficult to obtain a feature based representation for all the objects.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, and this is the good news, there are ways for computing similarities between graphs.",
                    "label": 0
                },
                {
                    "sent": "Computing similarities between arbitrary graphs may be difficult problem.",
                    "label": 0
                },
                {
                    "sent": "It's NP hard in the general case, but for some instances of graphs, for example trees, the similarities between trees can be computed in polynomial time, so in this case I'm lacking a feature based representation.",
                    "label": 0
                },
                {
                    "sent": "I can't use K means, for example or any other central clustering algorithm, but nevertheless I'm able to obtain similarities between the object.",
                    "label": 0
                },
                {
                    "sent": "So what I get is a similarity, OK?",
                    "label": 0
                },
                {
                    "sent": "Several other situations where actually it is difficult to obtain at pictorial representation, but on the other hand, you may obtain quite easily similarity between the objects you want to cluster.",
                    "label": 0
                },
                {
                    "sent": "So pairwise algorithms or the pairwise framework does apply exactly.",
                    "label": 0
                },
                {
                    "sent": "In these cases, it's a pairwise clustering algorithm accepts as input a matrix of similarities, it doesn't, it doesn't accept it, it doesn't know anything.",
                    "label": 0
                },
                {
                    "sent": "About the way in which we are representing the objects, they maybe they might be graphs or vector or whatever.",
                    "label": 0
                },
                {
                    "sent": "It just accepts as input a matrix of similarities and starting from from this similarities it will try to partition the data according to certain coherency criteria.",
                    "label": 0
                },
                {
                    "sent": "So in one sense, pairwise clustering is more general than central clustering, because here we need to know something essential about the way in which we are representing the object.",
                    "label": 0
                },
                {
                    "sent": "Not only that, we also.",
                    "label": 0
                },
                {
                    "sent": "Need that the objects be represented in terms of vectors.",
                    "label": 0
                },
                {
                    "sent": "Here we just forget about that.",
                    "label": 0
                },
                {
                    "sent": "Any representation is OK, provided that I have a means to compute similarities between object OK.",
                    "label": 0
                },
                {
                    "sent": "So in this talk I'll be.",
                    "label": 0
                },
                {
                    "sent": "I'll be talking about pairwise clustering problem and so we accept a pairwise clustering algorithm accepts as input a set of N objects and an end times N matrix of pairwise similarities, and the idea of course is to partition the input data the input objects into maximally coherent groups.",
                    "label": 1
                },
                {
                    "sent": "So yeah, there's a very simple example we have.",
                    "label": 0
                },
                {
                    "sent": "I mean, we can perceptually see that there are four clusters, and so of course we want.",
                    "label": 0
                },
                {
                    "sent": "In this case the points.",
                    "label": 0
                },
                {
                    "sent": "The objects are represented in terms of points in a plane, and the distance maybe can be Euclidean distance.",
                    "label": 0
                },
                {
                    "sent": "And of course we want as the output.",
                    "label": 0
                },
                {
                    "sent": "Do we have a laser pointer or something?",
                    "label": 0
                },
                {
                    "sent": "Maybe I can.",
                    "label": 0
                },
                {
                    "sent": "OK, otherwise it will be OK. And so we have four groups.",
                    "label": 0
                },
                {
                    "sent": "But of course this is a very simple case because there are there can be very different situations.",
                    "label": 0
                },
                {
                    "sent": "For example, here we have a situation where there are four clusters different in size.",
                    "label": 0
                },
                {
                    "sent": "There we have also four clusters, but the difference between the second case in the first one is that the clusters do have very arbitrary shape.",
                    "label": 0
                },
                {
                    "sent": "They are not compact clusters, and in the final example we've both.",
                    "label": 0
                },
                {
                    "sent": "We have compact clusters.",
                    "label": 0
                },
                {
                    "sent": "And we have arbitrary shape.",
                    "label": 0
                },
                {
                    "sent": "So the problem is quite challenging.",
                    "label": 0
                },
                {
                    "sent": "And actually it's the main problem in unsupervised learning.",
                    "label": 0
                },
                {
                    "sent": "Actually unsupervised learning means.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Classroom, so the problems of clustering objects into groups into coherent groups finds application in a number of different domains from image processing and computer vision by informatics information retrieval and so on so forth.",
                    "label": 0
                },
                {
                    "sent": "It's a very important problem.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So now we.",
                    "label": 0
                },
                {
                    "sent": "We should just start from the from the beginning asking a very simple question.",
                    "label": 0
                },
                {
                    "sent": "What is a cluster?",
                    "label": 0
                },
                {
                    "sent": "Because this will be the starting point from this from this framework.",
                    "label": 0
                },
                {
                    "sent": "Let me also say that.",
                    "label": 0
                },
                {
                    "sent": "Many pairwise clustering algorithms existing in the literature start from a different question.",
                    "label": 0
                },
                {
                    "sent": "They basically I'm thinking for example of an algorithm which actually we will encounter later which is called, for example normalized, cut and cut.",
                    "label": 0
                },
                {
                    "sent": "And there are spectral clustering algorithms also.",
                    "label": 0
                },
                {
                    "sent": "Which are quite popular nowadays, so the this kind of algorithms actually start from a different question.",
                    "label": 0
                },
                {
                    "sent": "I give you a set of objects.",
                    "label": 0
                },
                {
                    "sent": "I give you the similarities between objects and then the question is how can I partition the input data in the best possible way in such a way that the classes are maximally coherent.",
                    "label": 0
                },
                {
                    "sent": "So the starting question is not what is a cluster?",
                    "label": 1
                },
                {
                    "sent": "And then I define technically what is a cluster and then I go ahead by defining a partition started from the notion of the cluster.",
                    "label": 0
                },
                {
                    "sent": "The idea is that how can I partition the data in the best possible way?",
                    "label": 0
                },
                {
                    "sent": "So usually what is done is that one defines an objective function among all possible partitions of the input data, and so the idea is just to find the optimal partition according to the to the objective function.",
                    "label": 0
                },
                {
                    "sent": "So now we start from a different question, we just try to answer technically in this question.",
                    "label": 0
                },
                {
                    "sent": "What is a cluster?",
                    "label": 1
                },
                {
                    "sent": "There is no universally accepted definition of the cluster, I mean formally, but at least we can say that.",
                    "label": 1
                },
                {
                    "sent": "Everybody will confirm that a cluster, whatever it means, must satisfy these two informal criteria and internal criterion, and then external criterion.",
                    "label": 0
                },
                {
                    "sent": "Both are important for defining the notion of a cluster.",
                    "label": 0
                },
                {
                    "sent": "The internal criterion says that.",
                    "label": 0
                },
                {
                    "sent": "A set of objects is a cluster if all the objects inside the clusters are similar to each other.",
                    "label": 1
                },
                {
                    "sent": "OK, well this is not enough for defining the notion of a cluster, because for example if I take let me into this way, if I take.",
                    "label": 0
                },
                {
                    "sent": "For example, this cluster here.",
                    "label": 0
                },
                {
                    "sent": "Maybe another cluster here?",
                    "label": 0
                },
                {
                    "sent": "OK, so if I take a strict subset, proper subset of this class and let's say this one, this is not a cluster technically speaking because it is included in a larger coherent group.",
                    "label": 0
                },
                {
                    "sent": "This satisfies the internal criterion though, but it doesn't satisfy the external criterion.",
                    "label": 0
                },
                {
                    "sent": "So in order for a + 4 for a set of objects to be defined, the cluster we also have to ask that all objects outside the cluster should be highly the similar to the ones inside.",
                    "label": 1
                },
                {
                    "sent": "OK, so this is important.",
                    "label": 0
                },
                {
                    "sent": "These two criteria actually will be the the basic starting point from the definition of a dominant set.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Usually when we.",
                    "label": 0
                },
                {
                    "sent": "He was plastering problem.",
                    "label": 0
                },
                {
                    "sent": "We represent the data, the objects to be clustered in terms of a graph.",
                    "label": 1
                },
                {
                    "sent": "Where the vertices of the graph represent the objects to be clustered.",
                    "label": 0
                },
                {
                    "sent": "The edges represent similarity relations and the weights on the edge represent the similarity.",
                    "label": 0
                },
                {
                    "sent": "The quantitative similarity between the two objects.",
                    "label": 0
                },
                {
                    "sent": "So we have a technical speaking, at least in this part of the talk.",
                    "label": 0
                },
                {
                    "sent": "We have a non directed weighted graph and we assume that the weights are known negative, so the weights are greater than or equal to zero OK?",
                    "label": 0
                },
                {
                    "sent": "A common way to represent.",
                    "label": 0
                },
                {
                    "sent": "Directed weighted graph edge.",
                    "label": 0
                },
                {
                    "sent": "Weighted graph is by using this pulled weighted adjacency matrix.",
                    "label": 0
                },
                {
                    "sent": "This is an M by N matrix where N is the number of vertices in the graph an at the intersection of the row number I in the column.",
                    "label": 0
                },
                {
                    "sent": "Rumba Jay.",
                    "label": 0
                },
                {
                    "sent": "I just find the similarity between I&J OK. We assume that the main diagonal of this matrix is 0.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so let's start from a very simple, an unrealistic scenario.",
                    "label": 0
                },
                {
                    "sent": "Let's try to answer our original question.",
                    "label": 0
                },
                {
                    "sent": "What is a cluster when the similarities between the objects are binary?",
                    "label": 0
                },
                {
                    "sent": "So in this case we have just that two objects are either similar or dissimilar.",
                    "label": 0
                },
                {
                    "sent": "We are not allowing intermediate values of the similarity or similarity.",
                    "label": 0
                },
                {
                    "sent": "In other words, the.",
                    "label": 0
                },
                {
                    "sent": "The graph is an unweighted graph is an undirected, unweighted graph, and the adjacency matrix is just at 01 metrics.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's ask ourselves, what is the sort of structure in this graph that satisfies the two criteria, the internal one and the external one?",
                    "label": 0
                },
                {
                    "sent": "The answer is a very classic notion in graph theory, the notion of a maximal clique.",
                    "label": 1
                },
                {
                    "sent": "Yesterday we had a talk by Richard Hartley talked about notion of a click from different purposes.",
                    "label": 0
                },
                {
                    "sent": "But well, let me just remind what is click, which is a maximal clique.",
                    "label": 0
                },
                {
                    "sent": "I give you a graph, for example this one.",
                    "label": 0
                },
                {
                    "sent": "OK so it clicks.",
                    "label": 1
                },
                {
                    "sent": "See is just a subset of mutually adjacent vertices.",
                    "label": 1
                },
                {
                    "sent": "Then we have a notion of a maximal quick.",
                    "label": 0
                },
                {
                    "sent": "A maximal clique is a click which is not contained in any larger click.",
                    "label": 1
                },
                {
                    "sent": "So for example, this is this one.",
                    "label": 0
                },
                {
                    "sent": "Is a click of course, and is also maximal, and this one also is a click and is also maximal, but.",
                    "label": 0
                },
                {
                    "sent": "This one is a click but is not maximal because it is contained in a larger click OK. Well, it's not written there.",
                    "label": 0
                },
                {
                    "sent": "We have a father notion.",
                    "label": 0
                },
                {
                    "sent": "The notion of a maximum click.",
                    "label": 0
                },
                {
                    "sent": "To be distinguished from the notion of a maximal click, a maximum click is a click having largest cardinality, so there is no larger click.",
                    "label": 0
                },
                {
                    "sent": "So in this case there is only one maximum click and this one.",
                    "label": 0
                },
                {
                    "sent": "This is this one is maximal that is not maximum.",
                    "label": 0
                },
                {
                    "sent": "Of course.",
                    "label": 0
                },
                {
                    "sent": "Any maximum clique is also maximal, but the opposite is not usually true.",
                    "label": 0
                },
                {
                    "sent": "For example, in this case we have a maximum clique, which is not maximum.",
                    "label": 0
                },
                {
                    "sent": "We also have a notion which we will encounter later on, just called the strictly maximal clique.",
                    "label": 0
                },
                {
                    "sent": "Let me just mention that we call it strictly.",
                    "label": 1
                },
                {
                    "sent": "Maximum click.",
                    "label": 0
                },
                {
                    "sent": "This is a click which is the following property.",
                    "label": 0
                },
                {
                    "sent": "OK, if this is a maximal clique.",
                    "label": 0
                },
                {
                    "sent": "All the viruses outside it.",
                    "label": 0
                },
                {
                    "sent": "Kind of have.",
                    "label": 0
                },
                {
                    "sent": "More than two edges.",
                    "label": 0
                },
                {
                    "sent": "Incident on those vertices, because if this vertex here, which is outside the click, has three edges, so it's incident to this one.",
                    "label": 0
                },
                {
                    "sent": "This will not be a maximally OK.",
                    "label": 0
                },
                {
                    "sent": "So what we can say is that if C is a maximal clique.",
                    "label": 0
                },
                {
                    "sent": "Then for all J outside C. The the number of edges.",
                    "label": 0
                },
                {
                    "sent": "Let's call this way the number of edges between J and an arbitrary I where I is a member of C must be less than or equal, must be less than or equal to the cardinality of, sorry less.",
                    "label": 0
                },
                {
                    "sent": "Strictly lessons cutting out it's OK, otherwise it cannot be maximum.",
                    "label": 0
                },
                {
                    "sent": "Well, strictly maximal clique as.",
                    "label": 0
                },
                {
                    "sent": "This I mean the number of edges started from any outside external verdicts incident to the vertices inside must be strictly less than cardinality of C -- 1.",
                    "label": 0
                },
                {
                    "sent": "The reason for having strictly maximal quicks is that maximal cliques, in one sense, are unstable in the sense that if I if I for example take this, click here.",
                    "label": 0
                },
                {
                    "sent": "And I drop this verdicts and they add this vertex then this.",
                    "label": 0
                },
                {
                    "sent": "Is another maximal quick, so it's unstable quarter then quoted in the sense that I can just take one vertex in the maximum clique, throw it away at the external vertex, and then I get a new maximum click while strictly maximal clique are more stable since no external vertices, so it's an external vertex a sufficient number of edges incident to the internal vertices, so I can just take one of these voters, threw it away, another another one.",
                    "label": 0
                },
                {
                    "sent": "OK, so it's in one sense a more stable this is.",
                    "label": 0
                },
                {
                    "sent": "A distinction which will be reflected in the structure of local Optima we have.",
                    "label": 0
                },
                {
                    "sent": "We have an optimization problem, continuous optimization problem for example.",
                    "label": 0
                },
                {
                    "sent": "You might have strict local optimum and local optimum which are not strict and we shall see later on that.",
                    "label": 0
                },
                {
                    "sent": "Actually there is a one to one correspondence between the notion of a strictly maximum quick and the notion of a strict maximum.",
                    "label": 0
                },
                {
                    "sent": "OK. Now it's clear that when.",
                    "label": 0
                },
                {
                    "sent": "We are just have binary similarities.",
                    "label": 0
                },
                {
                    "sent": "The notion of a maximum clique is exactly the notion we are looking for.",
                    "label": 1
                },
                {
                    "sent": "The notion of the cluster coincide with an open sides with the notion of a maximum click.",
                    "label": 0
                },
                {
                    "sent": "It satisfies both the internal and external criteria.",
                    "label": 0
                },
                {
                    "sent": "So now the question is, how can we generalize the notion of a maximum Click to edge weighted graphs?",
                    "label": 0
                },
                {
                    "sent": "And this is where dominant set coming.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "To introduce into the picture.",
                    "label": 0
                },
                {
                    "sent": "Yeah, you might have several several maximal cliques, yeah?",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Now our objective is to generalize the notion of a maximum clique to edge weighted graphs.",
                    "label": 0
                },
                {
                    "sent": "OK, let's wait.",
                    "label": 0
                },
                {
                    "sent": "Let's take an edge weighted graph.",
                    "label": 0
                },
                {
                    "sent": "Let's take a set of vertices S. And let's take a vertex I belonging to us, so we are in this situation.",
                    "label": 0
                },
                {
                    "sent": "We have a set S of vertices and we're vertex I inside.",
                    "label": 0
                },
                {
                    "sent": "Probably we have a picture here.",
                    "label": 0
                },
                {
                    "sent": "Yeah, OK, now let's start the picture.",
                    "label": 0
                },
                {
                    "sent": "OK, so in this set there are other vertices probably.",
                    "label": 0
                },
                {
                    "sent": "And so we just sum all the similarities between I an all the vertices inside S and get what we call the average weighted degree of I with respect to S so that some which is the sum over all AJ where J belongs to S is just sort of average similarity average weighted similarity between I and the other objects in C in NS.",
                    "label": 0
                },
                {
                    "sent": "Sorry.",
                    "label": 0
                },
                {
                    "sent": "Now we derive a notion of a relative similarity between two objects I&J remember that AIJ the elements of the matrix of the similarity matrix.",
                    "label": 0
                },
                {
                    "sent": "AIJ represents an absolute similarity between two objects.",
                    "label": 0
                },
                {
                    "sent": "OK, now we introduce the notion of a relative similarity.",
                    "label": 0
                },
                {
                    "sent": "We are in this situation here.",
                    "label": 0
                },
                {
                    "sent": "I don't have a laser pointer.",
                    "label": 0
                },
                {
                    "sent": "OK, let's do this way.",
                    "label": 0
                },
                {
                    "sent": "We have set S. We have a vertex or we got J and a vertex.",
                    "label": 0
                },
                {
                    "sent": "I inside SJ is outside us.",
                    "label": 0
                },
                {
                    "sent": "So the number that I write here is the absolute similarity between I&J.",
                    "label": 0
                },
                {
                    "sent": "Now introduce 5S.",
                    "label": 0
                },
                {
                    "sent": "IJ is just the difference between the absolute similarity between I&J and the average similarity between I and all the objects in S. OK, so this is very simple notion.",
                    "label": 0
                },
                {
                    "sent": "I'm just comparing the similarity of I&J with respect to how eyes similar to the other object in J.",
                    "label": 0
                },
                {
                    "sent": "Of course this Phi can be negative or positive is positive when the absolute similarity between I&J is greater than the relative similarity itself.",
                    "label": 0
                },
                {
                    "sent": "And this negative the other way around.",
                    "label": 0
                },
                {
                    "sent": "Now comes the main definition.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Which allows us to.",
                    "label": 0
                },
                {
                    "sent": "Define the notion of a dominant set.",
                    "label": 0
                },
                {
                    "sent": "It's actually looks quite complicated, but it's quite simple.",
                    "label": 0
                },
                {
                    "sent": "It's a recursive definition.",
                    "label": 0
                },
                {
                    "sent": "Let's consider a subset of vertices S and let's take a vertex I belonging to S in this example.",
                    "label": 0
                },
                {
                    "sent": "OK, so the recursive definition.",
                    "label": 0
                },
                {
                    "sent": "This actually allows us to assign to each vertex.",
                    "label": 0
                },
                {
                    "sent": "Await OK thanks.",
                    "label": 0
                },
                {
                    "sent": "So this allows us to assign to each vertex in S await.",
                    "label": 0
                },
                {
                    "sent": "Remember that we have an edge weighted graph, so in this way we are.",
                    "label": 0
                },
                {
                    "sent": "We are assigning weights to the vertices, but with respect to S. So we have a set S. We have a vertex I and then if the set S is a Singleton then my definition WSI is 1 by the finish and otherwise if I have more than one object in the in the set.",
                    "label": 0
                },
                {
                    "sent": "What I'm doing is just the following and just summing all the relative similarities these files.",
                    "label": 0
                },
                {
                    "sent": "Between I and all the remaining objects in S, but this is not just a plain sound, I'm just waiting.",
                    "label": 0
                },
                {
                    "sent": "This is a weighted average.",
                    "label": 0
                },
                {
                    "sent": "Actually, I'm waiting each of these relative similarities with the weight assigned to J with respect to S -- I.",
                    "label": 1
                },
                {
                    "sent": "So here is where the recursive definition comes into the picture.",
                    "label": 0
                },
                {
                    "sent": "Where to find this guy here and this guy in their recursive way?",
                    "label": 0
                },
                {
                    "sent": "OK, so intuitively what we're doing is just too.",
                    "label": 0
                },
                {
                    "sent": "To set to see how similar is I on the average with respect to all other elements in S except I of course.",
                    "label": 0
                },
                {
                    "sent": "But we are waiting this sum with the relative weights.",
                    "label": 0
                },
                {
                    "sent": "OK, once we have this numbers then we can define the total sum.",
                    "label": 0
                },
                {
                    "sent": "We can define the total weight of this of this set by just summing all the contributions here OK?",
                    "label": 0
                },
                {
                    "sent": "Now let me give you a very intuitive.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Interpretation of this number here.",
                    "label": 0
                },
                {
                    "sent": "It turns out that the sign of WSI.",
                    "label": 0
                },
                {
                    "sent": "It's important for defining the notion of a dominant set.",
                    "label": 0
                },
                {
                    "sent": "Let's try and see what happens in these two simple cases.",
                    "label": 0
                },
                {
                    "sent": "Consider this graph here.",
                    "label": 0
                },
                {
                    "sent": "We have these three vertices, 2, three and four.",
                    "label": 0
                },
                {
                    "sent": "They are highly similar to each other.",
                    "label": 0
                },
                {
                    "sent": "In fact, the similarities is constant is 10.",
                    "label": 0
                },
                {
                    "sent": "What happens if I try to add this vertex here to this set to 234?",
                    "label": 0
                },
                {
                    "sent": "Well, intuitively, I expect that the overall similarity of this new set consisting of 1234 will decrease because I'm adding something to the set which is less similar with respect to the internal similarity.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is reflected by the fact that W one with respect to 1234 is less than 0.",
                    "label": 0
                },
                {
                    "sent": "So if I compute this number here and this number is less than zero, what I can conclude this this is the basic intuition is that if I try and AB one to the set then I will decrease the internal similarity of the of the set OK. Let's consider this other example.",
                    "label": 0
                },
                {
                    "sent": "Here we have 678.",
                    "label": 0
                },
                {
                    "sent": "They are highly similar.",
                    "label": 0
                },
                {
                    "sent": "They are similar to each other.",
                    "label": 0
                },
                {
                    "sent": "We can say highly, of course, because there is another vertex 5 which is more similar.",
                    "label": 0
                },
                {
                    "sent": "But if we just look at 678, they form a coherent group, at least at that scale.",
                    "label": 0
                },
                {
                    "sent": "So what happens if I add this vertex here to this set?",
                    "label": 0
                },
                {
                    "sent": "I would expect that the overall similarity will increase and this is reflected by the fact that W. 5 So the weight assigned to this guy here with respect to this budget.",
                    "label": 0
                },
                {
                    "sent": "Is greater than zero OK?",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Go to sign.",
                    "label": 0
                },
                {
                    "sent": "Of this way still tells us in interesting things about what happens when I try and that.",
                    "label": 0
                },
                {
                    "sent": "But this is two groups of data, and so this leads us to the main definition of a dominant set.",
                    "label": 0
                },
                {
                    "sent": "We are in the symmetric case right now, so we are assuming that the similarity are symmetric and they are no negative.",
                    "label": 0
                },
                {
                    "sent": "So we define a subset of vertices at dominant set.",
                    "label": 0
                },
                {
                    "sent": "If these two conditions are satisfied, we require that for all internal vertices for all.",
                    "label": 0
                },
                {
                    "sent": "I'm in SWSI is greater than zero, which means that this set S is high internal coherence.",
                    "label": 0
                },
                {
                    "sent": "But we know that internal damage and it is not the only thing we we need to care about, but we also we also need an external criterion.",
                    "label": 0
                },
                {
                    "sent": "So we require that for all I not belonging to S external to us, this number is less than zero, which means that if I try to add I to the set, SI will decrease the internal similarity.",
                    "label": 0
                },
                {
                    "sent": "So in one sense, a dominant set is a maximally coherent set of vertices maximally in the sense that as soon as I try to add something else.",
                    "label": 0
                },
                {
                    "sent": "The overall similarity will decrease OK.",
                    "label": 0
                },
                {
                    "sent": "So this is our basic definition of a dominant set.",
                    "label": 0
                },
                {
                    "sent": "Now, now we have formalized the notion of a cluster technically, so from now on our notion of the cluster coincide with the notion of a dominant set.",
                    "label": 0
                },
                {
                    "sent": "Here is a numerical example.",
                    "label": 0
                },
                {
                    "sent": "Here the set 123 is dominant.",
                    "label": 0
                },
                {
                    "sent": "You can see internally it's high, coherently, higher coherency, and then outside the various is outside are less similar to the vertices inside.",
                    "label": 0
                },
                {
                    "sent": "No let's, let's start from the beginning.",
                    "label": 0
                },
                {
                    "sent": "We started from the case where the metrics of similarities was 01 was binary and now we have introduced the notion in that case.",
                    "label": 0
                },
                {
                    "sent": "In the binary case, we saw that the notion of a cluster actually is the notion of a maximal clique.",
                    "label": 0
                },
                {
                    "sent": "Now we are in the weighted case and we introduced this notion of a dominant set, and now the natural question is what is the relationship between a maximum clicks and the dominant set?",
                    "label": 0
                },
                {
                    "sent": "Or another way around?",
                    "label": 0
                },
                {
                    "sent": "If I have an unweighted graph where the edges are weighted either by one or zero, then what is the dominant set?",
                    "label": 0
                },
                {
                    "sent": "So the answer is that 401 matrices dominant set will coincide with strictly maximal clique.",
                    "label": 0
                },
                {
                    "sent": "OK, actually.",
                    "label": 0
                },
                {
                    "sent": "Notice that here we have a strictly maximum clique.",
                    "label": 0
                },
                {
                    "sent": "If instead of having less than zero, here we have less than or equal to 0.",
                    "label": 0
                },
                {
                    "sent": "So we relax this condition.",
                    "label": 0
                },
                {
                    "sent": "Then we would have maximal cliques, but as I said before, maximal cliques are less stable in the sense that I can throw away a vertex and add another one.",
                    "label": 0
                },
                {
                    "sent": "I still get another maximum clique while we are interested in stable solutions.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's the reason why here we have strictly less than rather than less than or equal to.",
                    "label": 0
                },
                {
                    "sent": "The second condition.",
                    "label": 0
                },
                {
                    "sent": "This one.",
                    "label": 0
                },
                {
                    "sent": "OK, this condition this is.",
                    "label": 0
                },
                {
                    "sent": "So this is a technical condition in the sense which mean essentially this.",
                    "label": 0
                },
                {
                    "sent": "If I give you a cluster, I expect that every subset of this cluster will be internal coherent.",
                    "label": 0
                },
                {
                    "sent": "So in this sense I mean the intuition behind this is just that if I if I get it.",
                    "label": 0
                },
                {
                    "sent": "Yeah, if you drop that you won't have again.",
                    "label": 0
                },
                {
                    "sent": "You won't have this this one to one correspondence.",
                    "label": 0
                },
                {
                    "sent": "You will have a weaker notion which is not in one to one correspondence with the notional mclee.",
                    "label": 0
                },
                {
                    "sent": "OK, no.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Now we have defined the notion of a dominant set.",
                    "label": 0
                },
                {
                    "sent": "Now let's put ourselves from a computational perspective.",
                    "label": 0
                },
                {
                    "sent": "Let's see how can I find a dominant set and then we maybe we can ask how can I partition a set of data into dominant sets?",
                    "label": 0
                },
                {
                    "sent": "OK in order to find dominant set.",
                    "label": 0
                },
                {
                    "sent": "Actually we could.",
                    "label": 0
                },
                {
                    "sent": "For example we could arrive.",
                    "label": 0
                },
                {
                    "sent": "I don't know a greedy algorithm.",
                    "label": 0
                },
                {
                    "sent": "For example, finding maximum maximum click, not a maximum click in a graph that I can do via straightforward greedy algorithm.",
                    "label": 0
                },
                {
                    "sent": "I just think about it.",
                    "label": 0
                },
                {
                    "sent": "I just order the vertices in the graph by degree.",
                    "label": 0
                },
                {
                    "sent": "It just take the highest degree node and I keep adding vertice.",
                    "label": 0
                },
                {
                    "sent": "Is checking that when I add a vertex the click condition is satisfied at the end of this process of this greedy process will end up with the maximal clique, which is not necessarily a maximum one.",
                    "label": 0
                },
                {
                    "sent": "Actually finding the maximum clique in graph is an NP hard problem.",
                    "label": 0
                },
                {
                    "sent": "It's NP hard even to approximate, so it's a very very difficult problem.",
                    "label": 0
                },
                {
                    "sent": "But finding a maximal clique it's a simple problem actually can be found in quadratic time.",
                    "label": 0
                },
                {
                    "sent": "So instead of devising greedy like algorithms or you know, standard algorithms for finding a dominant set, we follow quite different route.",
                    "label": 0
                },
                {
                    "sent": "Actually we transform the combinatorial problem that purely combinatorial problem of finding a dominant set in the graph into a purely continuous optimization problem.",
                    "label": 0
                },
                {
                    "sent": "Once we have done that, we can exploit the full Arsenal of continuous optimization techniques that is available in the optimization literature.",
                    "label": 0
                },
                {
                    "sent": "Actually, our problem will be a quadratic optimization problem and there are zillions of algorithms for solving quadratic optimization problem.",
                    "label": 0
                },
                {
                    "sent": "Actually we will use a very simple one inspired from evolution.",
                    "label": 0
                },
                {
                    "sent": "Again theory.",
                    "label": 0
                },
                {
                    "sent": "OK so.",
                    "label": 0
                },
                {
                    "sent": "So now we are just seeing how can I transform the know.",
                    "label": 0
                },
                {
                    "sent": "How can I characterize the notion of a dominant set in terms of the continuous optimization problem?",
                    "label": 0
                },
                {
                    "sent": "So let's take an edge weighted graph G and let's a be the adjacency matrix of this graph.",
                    "label": 0
                },
                {
                    "sent": "So let's consider this problem.",
                    "label": 0
                },
                {
                    "sent": "The problem of finding the maximum of this quadratic function.",
                    "label": 0
                },
                {
                    "sent": "This is written here in matrix form if you like.",
                    "label": 0
                },
                {
                    "sent": "I can just write it down in.",
                    "label": 0
                },
                {
                    "sent": "The more familiar way so X transpose X.",
                    "label": 0
                },
                {
                    "sent": "Is just the sum overall I sum overall JIAJXIXJ.",
                    "label": 0
                },
                {
                    "sent": "If you actually, you can also write this in a different way.",
                    "label": 0
                },
                {
                    "sent": "You can write it this way.",
                    "label": 0
                },
                {
                    "sent": "Well, now we're talking about weighted now, so I will show this different way.",
                    "label": 0
                },
                {
                    "sent": "Later on when we go back to the unweighted case.",
                    "label": 0
                },
                {
                    "sent": "Yeah, in this case it's a metric.",
                    "label": 0
                },
                {
                    "sent": "Yeah it's symmetric and non negative.",
                    "label": 0
                },
                {
                    "sent": "Actually with the 0 diagonal.",
                    "label": 0
                },
                {
                    "sent": "OK, so consider the problem of finding the maximum of this quadratic polynomial homogeneous polynomial over the standard simplex.",
                    "label": 0
                },
                {
                    "sent": "The standard simplex is a very simple geometrical structure.",
                    "label": 0
                },
                {
                    "sent": "It's it's the intersection of the plane of equation.",
                    "label": 0
                },
                {
                    "sent": "Sum XI equal to 1.",
                    "label": 0
                },
                {
                    "sent": "This means the sum of all's I must be equal to 1, so the plane with that equation with a positive author of the space.",
                    "label": 0
                },
                {
                    "sent": "So we require that all XI must be greater than or equal to 0.",
                    "label": 0
                },
                {
                    "sent": "And actually.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "This is an illustration of the standard simplex.",
                    "label": 1
                },
                {
                    "sent": "When N is equal to three, just is just a triangle.",
                    "label": 0
                },
                {
                    "sent": "And.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So consider this problem.",
                    "label": 0
                },
                {
                    "sent": "And let me just point out that.",
                    "label": 0
                },
                {
                    "sent": "Other approaches to pairwise clustering, notably one introduced a few years ago by sort.",
                    "label": 0
                },
                {
                    "sent": "Karen Boyer and also by Perona and Freeman in ACV ACV, is a European conference on computer vision leads to quite similar but fundamentally different quadratic optimization problem.",
                    "label": 0
                },
                {
                    "sent": "The basic idea in this approach, which actually the sort of spectral clustering, is to find the largest eigenvalues and then the corresponding eigenvector of the agency of the adjacency matrix.",
                    "label": 0
                },
                {
                    "sent": "Hey in this case.",
                    "label": 0
                },
                {
                    "sent": "Finding the largest eigenvalue and the corresponding eigenvector.",
                    "label": 0
                },
                {
                    "sent": "Can be found by maximizing X transpose X.",
                    "label": 0
                },
                {
                    "sent": "Not on the standard simplex, but on the sphere.",
                    "label": 0
                },
                {
                    "sent": "Now The thing is that this problem is computationally much simpler than that problem.",
                    "label": 0
                },
                {
                    "sent": "If I have to find the global maximum of this X transpose X over this fear, which leads me to find the maximum eigenvalue.",
                    "label": 0
                },
                {
                    "sent": "This can be done in polynomial time in cubic time.",
                    "label": 0
                },
                {
                    "sent": "Actually, while finding the maximum even in the 01 case I showed this.",
                    "label": 0
                },
                {
                    "sent": "In a few seconds, even if the matrix is 01, finding this maximum is NP complete, even sent, be hard even to approximate because it's related to the maximum clique problem.",
                    "label": 0
                },
                {
                    "sent": "OK, so the objective function is exactly the same, but the domain is completely different.",
                    "label": 0
                },
                {
                    "sent": "In one case we have to find the maximum over the sphere in case we have to find maximum over the standard simplex.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so now we were able to prove this theorem.",
                    "label": 0
                },
                {
                    "sent": "Which actually establishes a one to one correspondence between the.",
                    "label": 0
                },
                {
                    "sent": "Local Max strict local maximizer of X transpose X over the simplex.",
                    "label": 0
                },
                {
                    "sent": "So the solution of the problem and dominant sets.",
                    "label": 1
                },
                {
                    "sent": "OK, so this is the first part of the theorem.",
                    "label": 0
                },
                {
                    "sent": "Suppose that you give me a dominant asset and you say that you know that this set S is a dominant set, OK?",
                    "label": 0
                },
                {
                    "sent": "So I can construct what is called the weighted characteristic vector of this set.",
                    "label": 0
                },
                {
                    "sent": "The weighted characteristic vector is just a vector of N elements and components as many components as there are vertices in the graph.",
                    "label": 0
                },
                {
                    "sent": "The Earth component will be 0 if I does not belong to us, will be the ratio between this weight WSI which is positive by definition since S is a dominant set, this is positive and the total weight assigned to us.",
                    "label": 0
                },
                {
                    "sent": "So here this is positive.",
                    "label": 0
                },
                {
                    "sent": "This is a positive quantity.",
                    "label": 0
                },
                {
                    "sent": "Of course, if I sum up all these components in the vector, I end up with a point in the standard simplex.",
                    "label": 0
                },
                {
                    "sent": "The some of the components is equal to 1 and all the components are graded.",
                    "label": 0
                },
                {
                    "sent": "Are equal to zero OK?",
                    "label": 0
                },
                {
                    "sent": "Now, if S is a dominant set this point in the simplex is a strict local maximizer of the function X transpose X, so it's a solution of the optimization problem.",
                    "label": 0
                },
                {
                    "sent": "On the other hand.",
                    "label": 0
                },
                {
                    "sent": "If you give me a vector X star and you say, well, this is a strict local optimum for your problem, a strict local maximizer of X transpose X over the simplex, then what I can do is there to take the so called support of the vector.",
                    "label": 0
                },
                {
                    "sent": "The support of the vector is just a set of indices corresponding to positive components.",
                    "label": 0
                },
                {
                    "sent": "It is not a positive component.",
                    "label": 0
                },
                {
                    "sent": "The indices corresponding to positive component.",
                    "label": 0
                },
                {
                    "sent": "This will correspond to viruses in the graph.",
                    "label": 0
                },
                {
                    "sent": "This will be a subset of vertices of the original graph.",
                    "label": 0
                },
                {
                    "sent": "Then what I can prove is that S. Sorry Sigma, the support will be a dominant set provided that this condition is satisfied.",
                    "label": 0
                },
                {
                    "sent": "This is actually a technical condition which is a generic.",
                    "label": 0
                },
                {
                    "sent": "I mean it doesn't happen often in practice because it happens when.",
                    "label": 0
                },
                {
                    "sent": "You have a very symmetric CC.",
                    "label": 0
                },
                {
                    "sent": "Situation, for example the 01 case.",
                    "label": 0
                },
                {
                    "sent": "Then you might have this situation, but in the general case it's very unlikely that it happens.",
                    "label": 0
                },
                {
                    "sent": "It has to do with the way in which we can avoid spurious solutions.",
                    "label": 0
                },
                {
                    "sent": "I'll be I'll be talking about this in just one minute.",
                    "label": 0
                },
                {
                    "sent": "Now the nice thing is that this result is actually a generalization of a well known result in graph theory, which is known as the mosque in Strauss theorem.",
                    "label": 1
                },
                {
                    "sent": "Them asking Styles theorem establishes a one to one correspondence between the click number of a graph, namely the cardinality of the largest click and the global optimizer of a quadratic function over the standard simplex.",
                    "label": 0
                },
                {
                    "sent": "Let me just write it down just to.",
                    "label": 0
                },
                {
                    "sent": "To let you know what is the Mouse King style serum, actually nice thing is that masking and Strauss proved this theorem just in order to provide a different shorter proof to a well known theorem in extremal graph theory, which is known as the two rounds theorem.",
                    "label": 0
                },
                {
                    "sent": "the Rams theorem is a very well known theorem which states something about extremal graphs.",
                    "label": 0
                },
                {
                    "sent": "So the main objective of muskiness tiles that were pure mathematicians, of course.",
                    "label": 0
                },
                {
                    "sent": "But just to provide a different shorter proof, but actually it is very interesting computational implications.",
                    "label": 0
                },
                {
                    "sent": "So what masking and Strauss did was the following.",
                    "label": 0
                },
                {
                    "sent": "Let's consider an unweighted graph.",
                    "label": 0
                },
                {
                    "sent": "OK, so we have a set of vertices and a set of edges and then directed unweighted graph.",
                    "label": 0
                },
                {
                    "sent": "8 is the adjacency matrix of the graph is 01 matrix.",
                    "label": 0
                },
                {
                    "sent": "Let's consider the problem of maximizing.",
                    "label": 0
                },
                {
                    "sent": "X transpose AX over the standard.",
                    "label": 0
                },
                {
                    "sent": "Simplest exactly the same problem, but now the difference that a is a binary matrix.",
                    "label": 0
                },
                {
                    "sent": "So much skin and Strauss proved that.",
                    "label": 0
                },
                {
                    "sent": "There is a one to one correspondence between the clique number of the graph, which is denoted by.",
                    "label": 0
                },
                {
                    "sent": "Omega G This is the cardinality of the largest click in the graph.",
                    "label": 0
                },
                {
                    "sent": "And the value of the objects of the maximizer of this function.",
                    "label": 0
                },
                {
                    "sent": "So if X star is a global optimizer of X, transpose X over the standard simplex then.",
                    "label": 0
                },
                {
                    "sent": "The clique number of the graph is just equal to 1 / 1 -- F X transpose and they also show that.",
                    "label": 0
                },
                {
                    "sent": "There is actually a one to one correspondence between global maximizers in the form of a characteristic vectors, an maximal cliques.",
                    "label": 0
                },
                {
                    "sent": "So any Max, sorry, maximum clicks.",
                    "label": 0
                },
                {
                    "sent": "Any maximum clique will induce a global maximizer of the objective function.",
                    "label": 0
                },
                {
                    "sent": "Any global optimizer in the form of a characteristic vector will induce a maximally.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "Now what I was saying about Spirit solution is the following.",
                    "label": 0
                },
                {
                    "sent": "In the original formulation of masking, Strauss.",
                    "label": 0
                },
                {
                    "sent": "There might be spurious solutions, I mean, global optimizers of the objective function which are not in the form of a characteristic vector.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's consider this very simple graph.",
                    "label": 0
                },
                {
                    "sent": "And we know here there are two maximum clicks.",
                    "label": 0
                },
                {
                    "sent": "Is this one?",
                    "label": 0
                },
                {
                    "sent": "Not this one.",
                    "label": 0
                },
                {
                    "sent": "We can take the standard simplex.",
                    "label": 0
                },
                {
                    "sent": "We know from the masking Strauss theorem that.",
                    "label": 0
                },
                {
                    "sent": "This point here will be a global optimizer of the objective function and this point here will be a global optimizer of the objective function, but.",
                    "label": 0
                },
                {
                    "sent": "The bad news is that if I take all the points on the segment connecting these two points, all these points will be also global optimizer for the objective function.",
                    "label": 0
                },
                {
                    "sent": "So there is an Infinity of object of global optimizers.",
                    "label": 0
                },
                {
                    "sent": "All these points here will not be in the form of characteristic vector, because of course they belong to the inside of the standard simplex.",
                    "label": 0
                },
                {
                    "sent": "So in order to avoid this problem in order to avoid spurious solutions recently, manual bombs are from the University of Vienna.",
                    "label": 0
                },
                {
                    "sent": "Just proposed to add a regularization term which is just plus 1 / 2 X transpose X.",
                    "label": 0
                },
                {
                    "sent": "This is just the square of the norm of the vector and then he proved the theorem which established the one to one correspondence between local optimizers of the objective function and maximal cliques.",
                    "label": 0
                },
                {
                    "sent": "Global optimizers objective function and maximum clicks and show that these are the only global slash local optimizer there.",
                    "label": 0
                },
                {
                    "sent": "There is no spurious solution in this.",
                    "label": 0
                },
                {
                    "sent": "In this new objective function, so from a computational perspective, if you have to find a maximal clique or a maximum click in the graph, you just maximize this over the standard simplex.",
                    "label": 0
                },
                {
                    "sent": "Of course, there is no guarantee that you will find the global optimum, but maybe you will find a good local optimum.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Now, once we have characterized.",
                    "label": 0
                },
                {
                    "sent": "Donegan said",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In terms of solutions of continuous optimization problem, how can we find them?",
                    "label": 0
                },
                {
                    "sent": "Well, actually, a straightforward way to do that this is actually quadratic linearly constrained optimization problem.",
                    "label": 0
                },
                {
                    "sent": "I can take any textbook from optimization theory, let's say Bloomberg or whatever.",
                    "label": 0
                },
                {
                    "sent": "I go to the chapter on nonlinear optimization.",
                    "label": 0
                },
                {
                    "sent": "There are plenty of algorithms to do that.",
                    "label": 0
                },
                {
                    "sent": "Of course the simplest one would be sort of gradient gradient descent.",
                    "label": 0
                },
                {
                    "sent": "I start from the interior of the simplex and I keep following the gradient.",
                    "label": 0
                },
                {
                    "sent": "Until I reach the boundary, then I project.",
                    "label": 0
                },
                {
                    "sent": "The vector gradient over the over the boundary and I go home this way, but instead of using this kind of algorithms which also requires some tuning regarding the step size, because of course when I take direction of the gradient, I have to say exactly how much I move along that direction and this is a parameter which is not easy to set.",
                    "label": 0
                },
                {
                    "sent": "Instead of doing that, we just notice that there is a whole class of parallel dynamical systems.",
                    "label": 0
                },
                {
                    "sent": "From evolutionary game theory, which serves very well, our part was actually this class of dynamics is called replicator dynamics, and this are the most are the simplest dynamical systems developed in this branch of game theory, which is called evolutionary game theory.",
                    "label": 0
                },
                {
                    "sent": "Let me just give you the basic intuition behind this kind of dynamics.",
                    "label": 0
                },
                {
                    "sent": "Actually, evolutionary game theory was introduced in the seven late 70s in the 80s.",
                    "label": 0
                },
                {
                    "sent": "Actually by John Minor Smith, who tried to import into biology the the notions and the tools of game theory.",
                    "label": 0
                },
                {
                    "sent": "Game theory will talk about game theory in the third part of this stock, game theory was introduced by phenomenon and was developed by John Nash in order to deal with complex situations among rational beings, namely humans.",
                    "label": 0
                },
                {
                    "sent": "And there was the notion of rationality, which was fundamental in game theory.",
                    "label": 0
                },
                {
                    "sent": "So the trick of John Miner Smith was to apply game theory to the animal behavior to the animal, to the biological context where we typically speaking they don't.",
                    "label": 0
                },
                {
                    "sent": "We don't assume that animals are rational in the sense we are, so the trick was to import game theory which was developed for modeling situations among.",
                    "label": 0
                },
                {
                    "sent": "Human agents to do biology and to model the evolution of behavior within species.",
                    "label": 0
                },
                {
                    "sent": "So we assume a large population of individuals belonging to the same species.",
                    "label": 0
                },
                {
                    "sent": "We assume technically that the population is actually an infant population because we want to use relative frequencies, and we want to treat this relative frequencies as probabilities and this individuals will interact.",
                    "label": 0
                },
                {
                    "sent": "Probably there is shortage of water or food or whatever, so.",
                    "label": 0
                },
                {
                    "sent": "There are usually some conflict between these individuals and this conflict between pairs of individuals is model in terms of the game.",
                    "label": 0
                },
                {
                    "sent": "Technically speaking OK.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "In this framework, in evolutionary game theory, players do not behave rationally.",
                    "label": 0
                },
                {
                    "sent": "Innocence, human do but act instead according to SOA genetically prep program it strategy.",
                    "label": 0
                },
                {
                    "sent": "So we assume that each individual will always play that strategy.",
                    "label": 0
                },
                {
                    "sent": "For example, if I if I if I meet another guy and then I have a comfort with this guy, I may want to attack.",
                    "label": 0
                },
                {
                    "sent": "So I always attack or I just so I just go away.",
                    "label": 0
                },
                {
                    "sent": "You know, I have my own strategy.",
                    "label": 0
                },
                {
                    "sent": "I can have a double.",
                    "label": 0
                },
                {
                    "sent": "It can be an Oak or whatever.",
                    "label": 0
                },
                {
                    "sent": "So now the the basic difference between traditional game theory and evolution against theory is that we can measure utility in quantitative way.",
                    "label": 0
                },
                {
                    "sent": "Actually, utility is measured in terms of their winning fitness so.",
                    "label": 0
                },
                {
                    "sent": "In terms of the reproductive success of that strategy, so how much does how much that strategy pays in that context OK?",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "Let me just write down the basic intuition behind this replicator dynamics.",
                    "label": 0
                },
                {
                    "sent": "Um?",
                    "label": 0
                },
                {
                    "sent": "So we assume that we have a finite set of strategies.",
                    "label": 0
                },
                {
                    "sent": "Let's say let's call it J.",
                    "label": 0
                },
                {
                    "sent": "We have any strategies?",
                    "label": 0
                },
                {
                    "sent": "And we have what is called, typically a payoff matrix W. This is a.",
                    "label": 0
                },
                {
                    "sent": "And then times N matrix where N is the number of strategies.",
                    "label": 0
                },
                {
                    "sent": "WIJ, sorry wha represents the payoff that nice strategist gets when it plays against the J strategist.",
                    "label": 0
                },
                {
                    "sent": "OK, in the general case, the payoff matrix doesn't need to be symmetric.",
                    "label": 0
                },
                {
                    "sent": "Actually, economist or social scientists use very frequently nonsymmetric matrices, sometimes even negative mattress is.",
                    "label": 0
                },
                {
                    "sent": "So in the general case there is no restriction.",
                    "label": 0
                },
                {
                    "sent": "On the structure of this matrix.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "Let's suppose that we are at time T. Another note by XIT.",
                    "label": 0
                },
                {
                    "sent": "The proportion of players in the population which plays strategy I OK, so we have an strategy I can define what is called a state vector vector obtained by just putting together all these.",
                    "label": 0
                },
                {
                    "sent": "Of this numbers and of course, this is a vector which belongs to the standard simplex, 'cause this is actually a probability distribution.",
                    "label": 0
                },
                {
                    "sent": "OK, so there's some apps around.",
                    "label": 0
                },
                {
                    "sent": "There are no known negative.",
                    "label": 0
                },
                {
                    "sent": "OK, so.",
                    "label": 0
                },
                {
                    "sent": "What happens if I?",
                    "label": 0
                },
                {
                    "sent": "Compute WX and I take the I component of this, which we can call lots of pie I.",
                    "label": 0
                },
                {
                    "sent": "This is just the sum over all JWIJXJ.",
                    "label": 0
                },
                {
                    "sent": "So if XJ is just the probability of picking at chase strategies and WIJ, is the payoff to deny strategist?",
                    "label": 0
                },
                {
                    "sent": "Yes, when it meets Ajay strategists then this is just the average pay off that a nice strategist gets.",
                    "label": 0
                },
                {
                    "sent": "On the average in this this game OK?",
                    "label": 0
                },
                {
                    "sent": "I can also take the average of the average.",
                    "label": 0
                },
                {
                    "sent": "I can just average all this pie I can get.",
                    "label": 0
                },
                {
                    "sent": "I call it \u03c0, just the sum over all IXI.",
                    "label": 0
                },
                {
                    "sent": "Hi I and this is the average fitness over the entire population.",
                    "label": 0
                },
                {
                    "sent": "OK, so the basic idea behind the replicator dynamics is that good strategies, which means strategies that are better than the average will spread overtime, while bad strategies, which means bad with respect to the average will get extent.",
                    "label": 0
                },
                {
                    "sent": "OK, so actually.",
                    "label": 0
                },
                {
                    "sent": "What evolutionary game theory does is to propose dynamical models, which explains the evolution of behavior within a species.",
                    "label": 0
                },
                {
                    "sent": "So one possibility could be, for example, to consider a dynamical system like this in continuous time.",
                    "label": 0
                },
                {
                    "sent": "So I take the partial derivative of XI with respect to T and I just do the following.",
                    "label": 0
                },
                {
                    "sent": "This is exciting and then.",
                    "label": 0
                },
                {
                    "sent": "\u03a0 IX minus by X. OK, so now it is clear that if by some I is greater than \u03c0.",
                    "label": 0
                },
                {
                    "sent": "Then this would be greater than zero.",
                    "label": 0
                },
                {
                    "sent": "This is of course relative probability is greater than zero.",
                    "label": 0
                },
                {
                    "sent": "This will be will increase.",
                    "label": 0
                },
                {
                    "sent": "This means that overtime the proportion XI will increase.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I mean.",
                    "label": 0
                },
                {
                    "sent": "Simplex.",
                    "label": 0
                },
                {
                    "sent": "Yeah, of course, of course, yeah.",
                    "label": 0
                },
                {
                    "sent": "What, of course, the other way around?",
                    "label": 0
                },
                {
                    "sent": "If this is less than that.",
                    "label": 0
                },
                {
                    "sent": "So in other words, if we divide if we take this.",
                    "label": 0
                },
                {
                    "sent": "If we divide by XI, the relative rating of increase is just equal to the difference between the average fitness.",
                    "label": 0
                },
                {
                    "sent": "Sorry, the average.",
                    "label": 0
                },
                {
                    "sent": "Yeah, the average fitness of strategy at the average fitness over the entire population.",
                    "label": 0
                },
                {
                    "sent": "There is also a discrete time version of the Replicator dynamics.",
                    "label": 0
                },
                {
                    "sent": "This is the simplest model actually.",
                    "label": 0
                },
                {
                    "sent": "The discrete time is the following.",
                    "label": 0
                },
                {
                    "sent": "So the proportion of I strategies at time T plus one is equal to XIT.",
                    "label": 0
                },
                {
                    "sent": "Divided by \u03c0 at time T. This is actually a normalization factor, so actually.",
                    "label": 0
                },
                {
                    "sent": "You can write this down.",
                    "label": 0
                },
                {
                    "sent": "This is some overall JXIXJT by JT.",
                    "label": 0
                },
                {
                    "sent": "So we are sure that this is a normalization factor in order that we have a dynamics in the simplex.",
                    "label": 0
                },
                {
                    "sent": "So again, it is straightforward to see that if this happens.",
                    "label": 0
                },
                {
                    "sent": "So if by I is greater than \u03c0, then this will increase.",
                    "label": 0
                },
                {
                    "sent": "This will be greater than the previous one, and so on.",
                    "label": 0
                },
                {
                    "sent": "So this means that the strategy will spread over the population, otherwise it will.",
                    "label": 0
                },
                {
                    "sent": "It will disappear.",
                    "label": 0
                },
                {
                    "sent": "OK, so this is exactly what is.",
                    "label": 0
                },
                {
                    "sent": "What we have in this transparency here in this slide of these two versions.",
                    "label": 0
                },
                {
                    "sent": "The first thing to notice is that in both cases the continuous time dynamics and the discrete time dynamics both leaves the lift.",
                    "label": 0
                },
                {
                    "sent": "The simplex invariant.",
                    "label": 0
                },
                {
                    "sent": "Technically speaking, this means that any trajectory starting from the interior of the simplex we remain in the simplex for all future time.",
                    "label": 0
                },
                {
                    "sent": "OK, this is very simple to check.",
                    "label": 0
                },
                {
                    "sent": "Actually here you have just checked it the same for all I of XI T plus one is equal to 1, this is.",
                    "label": 0
                },
                {
                    "sent": "Straight forward to check all the components are non negative here.",
                    "label": 0
                },
                {
                    "sent": "In order to check this we have to see that the tangent.",
                    "label": 0
                },
                {
                    "sent": "Are parallel to the to the to the simplex and this actually happens because if you take the same over over all these guys here, the sum is 0.",
                    "label": 0
                },
                {
                    "sent": "This means that this dynamical system will always move within the simplex.",
                    "label": 0
                },
                {
                    "sent": "But indeed, the most important fact about Replicator Dynamics is not just.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "But it's the so-called fundamental theorem of natural selection.",
                    "label": 1
                },
                {
                    "sent": "Elemental team Natural selection, which goes back to every fissure in the 30, actually allows us to say something quite important about replicator dynamics.",
                    "label": 0
                },
                {
                    "sent": "When the payoff matrix is symmetric.",
                    "label": 0
                },
                {
                    "sent": "So actually, technically speaking, the the theorem states that if the matrix the payoff matrix is symmetric, then the both the continuous time and discrete time dynamics you have a Lyapunov function.",
                    "label": 0
                },
                {
                    "sent": "And this level of function is exactly X transpose WX, which is the average fitness over the entire population.",
                    "label": 0
                },
                {
                    "sent": "So this means level of function means it will increase overtime.",
                    "label": 0
                },
                {
                    "sent": "OK, so anytime technically speaking for the continuous time dynamics, the derivative of the function F of the time is greater than zero is strictly increasing along non constant trajectory for discrete time dynamics the value at each time.",
                    "label": 0
                },
                {
                    "sent": "At each step the value of that function will increase.",
                    "label": 0
                },
                {
                    "sent": "So actually we have a mean to find local Optima of quadratic function over the standard simplex.",
                    "label": 0
                },
                {
                    "sent": "These dynamical systems do work in the simplex at each.",
                    "label": 0
                },
                {
                    "sent": "At each step they increase the objective function, so eventually they will end up in a strictly local maximum.",
                    "label": 0
                },
                {
                    "sent": "So the idea is to use replicator dynamics for finding the optimization.",
                    "label": 0
                },
                {
                    "sent": "The optimisers of the objective function and then dominant sets.",
                    "label": 0
                },
                {
                    "sent": "Let me just say one thing.",
                    "label": 0
                },
                {
                    "sent": "Notice that in both dynamics, especially the discrete time one, which is the one actually used impr.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Technical applications we don't have any stepsides.",
                    "label": 0
                },
                {
                    "sent": "If you use gradient descent, for example for finding the minimum of function, we have to set up the step size.",
                    "label": 0
                },
                {
                    "sent": "I mean in theory Gradina send works provided at the step size is close to 0, tends to 0.",
                    "label": 0
                },
                {
                    "sent": "OK, so if we have a finite step sides, you're not guaranteed that the function we are optimizing will actually decrease.",
                    "label": 0
                },
                {
                    "sent": "Yeah, we don't have any step side, so there is no parameter to set.",
                    "label": 0
                },
                {
                    "sent": "There is an implicit stepsize we take every step.",
                    "label": 0
                },
                {
                    "sent": "We take a finite step and still we are guaranteed that the function in the next step would be greater than the previous one.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so we can put everything together now.",
                    "label": 0
                },
                {
                    "sent": "Let's start from the beginning.",
                    "label": 0
                },
                {
                    "sent": "We want to solve the problem of finding a cluster in a set of data.",
                    "label": 0
                },
                {
                    "sent": "So in in a graph where to find the notion of the cluster in terms of a dominant set.",
                    "label": 0
                },
                {
                    "sent": "But dominant sets are in one to one correspondence to local optimizers of X transpose X over the simplex.",
                    "label": 0
                },
                {
                    "sent": "So I just use replicated dynamics.",
                    "label": 0
                },
                {
                    "sent": "I use a the matrix A.",
                    "label": 0
                },
                {
                    "sent": "Is the payoff matrix, so by the fundamental theorem of natural selection, the algorithm starting from any point in interior of the simplex.",
                    "label": 0
                },
                {
                    "sent": "Eventually will converge to restrict local optimizer.",
                    "label": 0
                },
                {
                    "sent": "There is only one case it can happen.",
                    "label": 0
                },
                {
                    "sent": "In practice that the algorithm will converge.",
                    "label": 0
                },
                {
                    "sent": "To saddle point.",
                    "label": 0
                },
                {
                    "sent": "So the point actually is also a stationary point for the dynamics, because the gradient is 0.",
                    "label": 0
                },
                {
                    "sent": "But the good news is that stationary points I mean, saddle points, do not have any finite basing attraction around them.",
                    "label": 0
                },
                {
                    "sent": "So I can just when this happens I can just perturb the point a little bit and will be with take another route until it converges to a local optimum, OK?",
                    "label": 0
                },
                {
                    "sent": "OK, so I think it's time to have a break.",
                    "label": 0
                },
                {
                    "sent": "This is a straightforward implementation for the replicator dynamics in Matlab.",
                    "label": 0
                },
                {
                    "sent": "It's just three three statements.",
                    "label": 0
                },
                {
                    "sent": "3 lines OK, so after the break we will talk about the application of this framework to the image segmentation problem OK?",
                    "label": 0
                }
            ]
        }
    }
}