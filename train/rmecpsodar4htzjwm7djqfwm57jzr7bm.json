{
    "id": "rmecpsodar4htzjwm7djqfwm57jzr7bm",
    "title": "Evaluation of local spatio-temporal features for action recognition",
    "info": {
        "author": [
            "Alexander Klaser, INRIA Grenoble Rh\u00f4ne-Alpes"
        ],
        "published": "Dec. 1, 2009",
        "recorded": "September 2009",
        "category": [
            "Top->Computer Science->Computer Vision"
        ]
    },
    "url": "http://videolectures.net/bmvc09_klaser_elst/",
    "segmentation": [
        [
            "So hello everybody, how are you?",
            "The last session so.",
            "Hold on so I have the great pressure to have the second last presentation of the BBC conference and the title of our work is a evaluation of local spatial temporal features for action recognition.",
            "This has been a joint work with hanging from the natural Laboratory of pattern recognition in China, from which manipula and even laptop from Indian rent and for me Alexa like Laser encoder, Schmidt from Imran, Grenoble.",
            "So first problem that we addressed here."
        ],
        [
            "Well, local spacetime features or local features in general have been quite become quite popular for action recognition.",
            "So there are several methods.",
            "As for images, there are several methods to detect interesting features and to describe those features, and so far the evaluations that exist to compare these features and descriptors or detectors and descriptors.",
            "They are relatively limited, so there's no exhaustive exhaustive evaluation of all the descriptors or the authors take different datasets that we cannot really compare different works directly or the experimental settings are different."
        ],
        [
            "So the goal of this work is one step.",
            "First step to provide a common evaluation set up with different datasets.",
            "So we chose to use Katie Ages of the UC F Sports data set and the Hollywood Two data set.",
            "So these are datasets with varying difficulty.",
            "We use the same train and test data is very important.",
            "We also use the same classification method to ensure that we have a fair compare fair comparison and then we carry out a systematic study of detector descriptor evaluation and combinations."
        ],
        [
            "Outline of the talk.",
            "First, I will introduce the whole framework that we use for the action recognition, and then I would just browse through the different detectors and descriptors that we used just to give you a hint what these descriptors and detectors are about, and then I will present the experiment experimental results."
        ],
        [
            "The framework.",
            "So."
        ],
        [
            "Detection description just a short overview.",
            "What is the pipeline?",
            "So first given video sequence you want to detect interesting regions or maybe not interesting regions, but regions where you want to compute descriptors, so detecting these regions in the 1st.",
            "At first give you locations and also different scales temporally and spatial scales of interesting regions, patches, spatial, temporal patches that are then described by any kind of descriptor and you will end up with the feature vector presentation of these of these regions.",
            "Taking these feature vectors."
        ],
        [
            "You will apply or reapply in this work a bag of words representation by using gamings for clustering training features together.",
            "Throughout our evaluations K equals to 4000.",
            "And so each sequence is then using this vocabulary.",
            "Each sequence is then transformed into a histogram of occurrence.",
            "Occurrences of for visual words.",
            "And these histograms are then are then classified by nonlinear classifier with chi squared kernel.",
            "So this is the general framework as we chat."
        ],
        [
            "Applied so in other words, before.",
            "So."
        ],
        [
            "First, now the detectors, which detectors do we investigate in this work so we look at the Harris through the detector at the at the cuboid detector, presented by by dollar at the Hessian detector and a dense sampling strategy which hasn't been investigated in detail so far.",
            "So the Harris three detector is a space."
        ],
        [
            "The corner detector detects corner points.",
            "It's an extension of the Harrison 2D detector for images and it's it will detect and a video corner points that will probably change their motion.",
            "This is a spatial temporal corner you can think of it like this.",
            "And we use in our setup we use.",
            "We don't use any explicit scale selection, although that exists.",
            "We just run it on different scales and take points above buffer given threshold.",
            "The keyword detector introduced by dollar."
        ],
        [
            "At all is a spacetime detector based on temporal garbled filters.",
            "Specially, the response function is used.",
            "Users of Goshen and temporally uses the garbled filter in the response functions depicted over there looks something like this, and it's supposed to detect regions that undergo like complex motion and have a distinguishing characteristic spatially.",
            "The Hessian detector, which has been introduced."
        ],
        [
            "STCC balance at all.",
            "It's a spatial temporal extension of the Hessian descriptor for images.",
            "And it's based on the Hessian matrix extension to extend it to videos 23D Hash matrix.",
            "It is computed with an approximation using integral videos.",
            "So it's in computation is feasible.",
            "And it will detect spatial temporal blobs.",
            "It's a bit more difficult to imagine spatial temporal plots, but this is what ideally it is detecting.",
            "Then sampling."
        ],
        [
            "Well, for images, everybody probably knows dense sampling for videos.",
            "Provided you have more dimensions, but first the motivation of dense sampling in image is usually well.",
            "They have been work works that show the dense sampling tends to outperform interest points.",
            "Of course you have a lot more data, so we were interested in how does it perform compared to interest interest point detectors for videos we have XY&T dimensions to sample from regularly and we also have different scale temporal scale spatial scale that you want to decouple.",
            "So we have 5 dimensions to sample from them, so the amount of data is also significantly large.",
            "We use this.",
            "Overlapping descriptors of 50%.",
            "And the minimum size of the descriptive values are different, different different para meters we choose to use 18 * 18 pixel and timeframes as a minimum descriptor size with the scale factor of square root 2.",
            "In the paper, there are more evaluations with the different parameters.",
            "If you're interested in that.",
            "And here here a little."
        ],
        [
            "And of the different detectors you see, the Harris three detector, the cube detector on the right and down the Hessian descriptor just to have visually Samsung impression.",
            "And so this since it's action detection.",
            "So now it's you part, you need to guess what action this is, and you can also guess the movie.",
            "It's not impossible.",
            "So you see interesting to note, the keyword detector has been designed to.",
            "Originally operate on one on one scale and one.",
            "Pick the scale.",
            "So what action is it?",
            "Yeah, very good.",
            "Good detector.",
            "And what video is it?",
            "What movie is it?",
            "Yeah, Forrest Gump.",
            "I think this is sufficient.",
            "So."
        ],
        [
            "So for for the feature detectors Now if we have the interesting points, interest points, spatial temporal points in the videos, and now they're different varying ways to describe them with different descriptors."
        ],
        [
            "We investigate in this work for different descriptors, the harkov descriptor.",
            "Buy locked, if at all.",
            "The keyword descriptor by dollar.",
            "And the hook three descriptor, as well as the extended surf descriptor.",
            "Which I will present a bit into detail now.",
            "The whole cough descriptor."
        ],
        [
            "Has been presented by lot of Adele last year.",
            "It's based on histograms of oriented spatial gradients, spatial gradients, not spatial temporal gradients, hogs and histograms of optical flow offs.",
            "So given downloads, depicted giving, giving a 3D Patch by returned by interest point detector.",
            "This descriptor will divide this Patch into 3D grid for each cell it will compute a Hawk and a half descriptor and these descriptor then concatenated.",
            "Now experiments actually we we also look only at Hawk.",
            "The hog descriptor only at the half descriptor and the combination of the two, which is just a concatenation of history histogram.",
            "Different histogram types.",
            "The Cuba descriptor which has."
        ],
        [
            "Introduced by dollar at all.",
            "Takes a 3D Patch and it describes the three Patch bites.",
            "Gradient, spatial, temporal gradient, pixel values.",
            "All these pixel gradient values are concatenated in one feature vector and its dimensionality is projected down to low dimensional space with PCA and this is the descriptor vector.",
            "The."
        ],
        [
            "3D script has been introduced last year.",
            "So PMDC by class at all.",
            "And it's an extension of the SIFT descriptor popular self descriptor for images.",
            "Extended to videos and it's based on histograms of 3D3DS.",
            "Also spatial temporal gradient orientations and the quantization of 3D gradients is in this case they propose to Orient quantize them using regular polyhedrons as depicted down the nice star like thing in the bottom.",
            "So the faces are the bins.",
            "And Interestingly, this descriptor combines directly in one descriptor, motion and shape information.",
            "And the E surf descriptor presented by Williams."
        ],
        [
            "Last year, the CCD is an extension of the surf descriptor to videos.",
            "And that's before the 3D cuboid is divided into cells and each cell will computer.",
            "Responses of the hard wavelets aligned to the different orientation axis.",
            "And then the descriptor for each cell are called."
        ],
        [
            "Automated and this gives you a final vector.",
            "The results.",
            "So as I said before."
        ],
        [
            "Present results on three datasets KTH dataset, Yousef, Sports data set and the Hollywood 2 datasets and I will treat treat data set by data set.",
            "The KTH data set is probably one of the most known.",
            "Once it has been around for quite a while now, it contains of it contains 10 action classes.",
            "And it has 25 different people performing these actions in different scenarios.",
            "In total there are about 2400 video samples.",
            "And it'll be you sequences and you will see I will have just a demo video of of the data set so you have an impression it has quite homogeneous and static background.",
            "And the current state of the art is about 92%, and the measure is average accuracy over all classes."
        ],
        [
            "Here you see a little sample, so you see the different action classes are depicted in the columns and the different scenarios are in the Rose from bottom to from the top to the bottom.",
            "These first scenarios outdoors.",
            "Then you have second scenarios outdoors with varying scales.",
            "The third scenario is outdoors with different clothes and the last scenario is indoors.",
            "So you can see the homogeneous background and so you get an impression for the depth data set.",
            "The results."
        ],
        [
            "This is a table, so detectors are in the columns and the descriptors are depicted in the rows.",
            "The best 3 results are highlighted with red in red.",
            "You will see that.",
            "To summarize it up, the best results we obtain in our setup for Harris, Philly and half descriptor.",
            "But we also obtain quite fairly good reason Comperable results using the Harris Rudy and the keyboards detector for the Hawk often hog three descriptors.",
            "Note what is interesting to note here is if you look at the dense dense sampling, it does really perform well compared to the best results, and we assume that it's certainly or probably due to the large amount of features that we obtained through the dense sampling on the homogeneous background, which doesn't really give more information but may corrupt the statistics."
        ],
        [
            "The second data set is the USF sports data set, which contains of 10 different sports action classes.",
            "It has altogether 150 video samples and we use also the flipped videos to extend the data set a bit to get more samples.",
            "The evaluation is done by a leap on out cross validation.",
            "And the measure is again a virtual currency of all classes, and the current state of the art is around 70%.",
            "By the authors also presented the data set, but well, this kind of we directly compared to to the results that we get, but it's just to happen to have an idea.",
            "Here are some sample sequences."
        ],
        [
            "Some simple actions.",
            "So again, the action classes are depicted in the columns and you have some different samples.",
            "So we get an impression of the different actions and the difficulty.",
            "Let's put it OK. And the results."
        ],
        [
            "You see that in this case, where you see F. For you CF, we have the best results for using dense sampling for the for the hook through the descriptor, but also gives reasonable results.",
            "As well as hot coffee also gives good results.",
            "And Interestingly, As for the interest point detectors, is the keyword detector in combination with the Hawk 3D descriptor, who gives good results.",
            "And last but not least."
        ],
        [
            "The Hollywood 2 actions data set, which is the most challenging one which has been proposed, released this year.",
            "It contains 12 different action classes.",
            "When all the sequences have been mined from 2 altogether, 69 different Hollywood movies.",
            "It has in total 1700 video samples.",
            "There's a test and training set.",
            "The sample stuff from different movies so there's no overlap.",
            "And it's the measure that has been used as close to the basketball box challenge.",
            "It's mean average position over all classes.",
            "This gives you an impression of the data."
        ],
        [
            "Is it?",
            "So you see, if you look at ansafone, you have a on the very top.",
            "You have the huge variation of different different movie.",
            "Movies.",
            "Different movie styles.",
            "And you may also have for one particular video sequence of 1 sample, you may have different action classes that it belongs to."
        ],
        [
            "The results.",
            "Here in our setup we obtain best results for dense sampling using the horkoff descriptor.",
            "And in general we get good results for the Horcoff descriptor for Hollywood 2 datasets.",
            "The conclusion to wrap it all up."
        ],
        [
            "So we have seen, especially for realistic data settings for realistic videos, video data, we see that then sampling in our setup outperformed the detectors.",
            "This is kind of consistent.",
            "Would have been what has been found also for images.",
            "We also see or we want to would like to point out the importance of realistic media data.",
            "Same as 444 images, so things that we find work on more.",
            "Artificial data cannot really be applied directly to realistic data, so we would like to encourage other people also to check out the Hollywood 2 datasets into to check their algorithms on these datasets.",
            "I think that is really important.",
            "We also see the limitations of the current feature detectors and just a little note then simply works better, but you will also get much more data.",
            "So in our case we have 15 to 20 times more data than for interest point detectors.",
            "As for the detectors globally, we didn't really have the impression that you can point out to ones, particularly detector which works best.",
            "And for the descriptors, the overall ranking is given there, so her cough seems to perform slightly better than all 3D which performed better than a cuboid sandwich performed better than the surf and hog descriptor.",
            "And well, maybe it seems to us.",
            "It seems that it's a good choice to combine them.",
            "Gradients and optical flow into one descriptor's by the results.",
            "This seems to be a good idea.",
            "And just a note.",
            "Of course, this is just the first first step, so there are certainly other open topics that need to be looked more into detail, especially different descriptor parameters for the descriptors we used in the detectors were used in.",
            "Here we use standard settings, so this could be optimized as well as the.",
            "If you look at the dollar descriptor, the keyboard descriptor by dollar, this could be also applied to different different scales, so that would be interesting.",
            "So there a few open things to look at.",
            "But this is the first step and we think it's a good direction to have a global idea of how the different detectors in the script was performed in the same setup.",
            "And that would be all.",
            "Thank you very much for attention."
        ],
        [
            "Make your parents.",
            "Well, in this work we haven't looked at the.",
            "We haven't been combined the different descriptors, but clearly if you want to get the best performance, I think the box challenge shows that this seems to be currently the way to go to combine different detectors descriptors and optimize it on the different action classes.",
            "But this is only possible if you have a reasonably data set.",
            "We can learn these parameters on the training set.",
            "But we haven't looked at it in this work and same applies also to grids.",
            "And this is what we haven't looked at, but this would clearly be be interesting to look at.",
            "Yeah, I think there's probably not one thing that you get one pump of.",
            "Well, I think you need to optimize it on four different for different action classes because each section classes they can vary really much so.",
            "There's nothing general that you can can say that you should read like this.",
            "Otherwise, for focusing the attention, maybe it could be interesting.",
            "Certainly, since human action is closely related to humans, so it probably would also make sense to focus on humans and get more descriptors around the humans.",
            "And we look into this direction, yeah?"
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So hello everybody, how are you?",
                    "label": 0
                },
                {
                    "sent": "The last session so.",
                    "label": 0
                },
                {
                    "sent": "Hold on so I have the great pressure to have the second last presentation of the BBC conference and the title of our work is a evaluation of local spatial temporal features for action recognition.",
                    "label": 1
                },
                {
                    "sent": "This has been a joint work with hanging from the natural Laboratory of pattern recognition in China, from which manipula and even laptop from Indian rent and for me Alexa like Laser encoder, Schmidt from Imran, Grenoble.",
                    "label": 0
                },
                {
                    "sent": "So first problem that we addressed here.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well, local spacetime features or local features in general have been quite become quite popular for action recognition.",
                    "label": 1
                },
                {
                    "sent": "So there are several methods.",
                    "label": 0
                },
                {
                    "sent": "As for images, there are several methods to detect interesting features and to describe those features, and so far the evaluations that exist to compare these features and descriptors or detectors and descriptors.",
                    "label": 0
                },
                {
                    "sent": "They are relatively limited, so there's no exhaustive exhaustive evaluation of all the descriptors or the authors take different datasets that we cannot really compare different works directly or the experimental settings are different.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So the goal of this work is one step.",
                    "label": 1
                },
                {
                    "sent": "First step to provide a common evaluation set up with different datasets.",
                    "label": 0
                },
                {
                    "sent": "So we chose to use Katie Ages of the UC F Sports data set and the Hollywood Two data set.",
                    "label": 1
                },
                {
                    "sent": "So these are datasets with varying difficulty.",
                    "label": 0
                },
                {
                    "sent": "We use the same train and test data is very important.",
                    "label": 0
                },
                {
                    "sent": "We also use the same classification method to ensure that we have a fair compare fair comparison and then we carry out a systematic study of detector descriptor evaluation and combinations.",
                    "label": 1
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Outline of the talk.",
                    "label": 0
                },
                {
                    "sent": "First, I will introduce the whole framework that we use for the action recognition, and then I would just browse through the different detectors and descriptors that we used just to give you a hint what these descriptors and detectors are about, and then I will present the experiment experimental results.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "The framework.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Detection description just a short overview.",
                    "label": 1
                },
                {
                    "sent": "What is the pipeline?",
                    "label": 0
                },
                {
                    "sent": "So first given video sequence you want to detect interesting regions or maybe not interesting regions, but regions where you want to compute descriptors, so detecting these regions in the 1st.",
                    "label": 0
                },
                {
                    "sent": "At first give you locations and also different scales temporally and spatial scales of interesting regions, patches, spatial, temporal patches that are then described by any kind of descriptor and you will end up with the feature vector presentation of these of these regions.",
                    "label": 0
                },
                {
                    "sent": "Taking these feature vectors.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You will apply or reapply in this work a bag of words representation by using gamings for clustering training features together.",
                    "label": 1
                },
                {
                    "sent": "Throughout our evaluations K equals to 4000.",
                    "label": 0
                },
                {
                    "sent": "And so each sequence is then using this vocabulary.",
                    "label": 0
                },
                {
                    "sent": "Each sequence is then transformed into a histogram of occurrence.",
                    "label": 1
                },
                {
                    "sent": "Occurrences of for visual words.",
                    "label": 0
                },
                {
                    "sent": "And these histograms are then are then classified by nonlinear classifier with chi squared kernel.",
                    "label": 0
                },
                {
                    "sent": "So this is the general framework as we chat.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Applied so in other words, before.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "First, now the detectors, which detectors do we investigate in this work so we look at the Harris through the detector at the at the cuboid detector, presented by by dollar at the Hessian detector and a dense sampling strategy which hasn't been investigated in detail so far.",
                    "label": 0
                },
                {
                    "sent": "So the Harris three detector is a space.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The corner detector detects corner points.",
                    "label": 1
                },
                {
                    "sent": "It's an extension of the Harrison 2D detector for images and it's it will detect and a video corner points that will probably change their motion.",
                    "label": 0
                },
                {
                    "sent": "This is a spatial temporal corner you can think of it like this.",
                    "label": 0
                },
                {
                    "sent": "And we use in our setup we use.",
                    "label": 0
                },
                {
                    "sent": "We don't use any explicit scale selection, although that exists.",
                    "label": 1
                },
                {
                    "sent": "We just run it on different scales and take points above buffer given threshold.",
                    "label": 0
                },
                {
                    "sent": "The keyword detector introduced by dollar.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "At all is a spacetime detector based on temporal garbled filters.",
                    "label": 1
                },
                {
                    "sent": "Specially, the response function is used.",
                    "label": 0
                },
                {
                    "sent": "Users of Goshen and temporally uses the garbled filter in the response functions depicted over there looks something like this, and it's supposed to detect regions that undergo like complex motion and have a distinguishing characteristic spatially.",
                    "label": 0
                },
                {
                    "sent": "The Hessian detector, which has been introduced.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "STCC balance at all.",
                    "label": 0
                },
                {
                    "sent": "It's a spatial temporal extension of the Hessian descriptor for images.",
                    "label": 1
                },
                {
                    "sent": "And it's based on the Hessian matrix extension to extend it to videos 23D Hash matrix.",
                    "label": 1
                },
                {
                    "sent": "It is computed with an approximation using integral videos.",
                    "label": 0
                },
                {
                    "sent": "So it's in computation is feasible.",
                    "label": 0
                },
                {
                    "sent": "And it will detect spatial temporal blobs.",
                    "label": 0
                },
                {
                    "sent": "It's a bit more difficult to imagine spatial temporal plots, but this is what ideally it is detecting.",
                    "label": 0
                },
                {
                    "sent": "Then sampling.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Well, for images, everybody probably knows dense sampling for videos.",
                    "label": 1
                },
                {
                    "sent": "Provided you have more dimensions, but first the motivation of dense sampling in image is usually well.",
                    "label": 1
                },
                {
                    "sent": "They have been work works that show the dense sampling tends to outperform interest points.",
                    "label": 0
                },
                {
                    "sent": "Of course you have a lot more data, so we were interested in how does it perform compared to interest interest point detectors for videos we have XY&T dimensions to sample from regularly and we also have different scale temporal scale spatial scale that you want to decouple.",
                    "label": 0
                },
                {
                    "sent": "So we have 5 dimensions to sample from them, so the amount of data is also significantly large.",
                    "label": 0
                },
                {
                    "sent": "We use this.",
                    "label": 0
                },
                {
                    "sent": "Overlapping descriptors of 50%.",
                    "label": 1
                },
                {
                    "sent": "And the minimum size of the descriptive values are different, different different para meters we choose to use 18 * 18 pixel and timeframes as a minimum descriptor size with the scale factor of square root 2.",
                    "label": 0
                },
                {
                    "sent": "In the paper, there are more evaluations with the different parameters.",
                    "label": 0
                },
                {
                    "sent": "If you're interested in that.",
                    "label": 0
                },
                {
                    "sent": "And here here a little.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "And of the different detectors you see, the Harris three detector, the cube detector on the right and down the Hessian descriptor just to have visually Samsung impression.",
                    "label": 0
                },
                {
                    "sent": "And so this since it's action detection.",
                    "label": 0
                },
                {
                    "sent": "So now it's you part, you need to guess what action this is, and you can also guess the movie.",
                    "label": 0
                },
                {
                    "sent": "It's not impossible.",
                    "label": 0
                },
                {
                    "sent": "So you see interesting to note, the keyword detector has been designed to.",
                    "label": 0
                },
                {
                    "sent": "Originally operate on one on one scale and one.",
                    "label": 0
                },
                {
                    "sent": "Pick the scale.",
                    "label": 0
                },
                {
                    "sent": "So what action is it?",
                    "label": 0
                },
                {
                    "sent": "Yeah, very good.",
                    "label": 0
                },
                {
                    "sent": "Good detector.",
                    "label": 0
                },
                {
                    "sent": "And what video is it?",
                    "label": 0
                },
                {
                    "sent": "What movie is it?",
                    "label": 0
                },
                {
                    "sent": "Yeah, Forrest Gump.",
                    "label": 0
                },
                {
                    "sent": "I think this is sufficient.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So for for the feature detectors Now if we have the interesting points, interest points, spatial temporal points in the videos, and now they're different varying ways to describe them with different descriptors.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We investigate in this work for different descriptors, the harkov descriptor.",
                    "label": 0
                },
                {
                    "sent": "Buy locked, if at all.",
                    "label": 0
                },
                {
                    "sent": "The keyword descriptor by dollar.",
                    "label": 0
                },
                {
                    "sent": "And the hook three descriptor, as well as the extended surf descriptor.",
                    "label": 1
                },
                {
                    "sent": "Which I will present a bit into detail now.",
                    "label": 0
                },
                {
                    "sent": "The whole cough descriptor.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Has been presented by lot of Adele last year.",
                    "label": 0
                },
                {
                    "sent": "It's based on histograms of oriented spatial gradients, spatial gradients, not spatial temporal gradients, hogs and histograms of optical flow offs.",
                    "label": 1
                },
                {
                    "sent": "So given downloads, depicted giving, giving a 3D Patch by returned by interest point detector.",
                    "label": 0
                },
                {
                    "sent": "This descriptor will divide this Patch into 3D grid for each cell it will compute a Hawk and a half descriptor and these descriptor then concatenated.",
                    "label": 0
                },
                {
                    "sent": "Now experiments actually we we also look only at Hawk.",
                    "label": 0
                },
                {
                    "sent": "The hog descriptor only at the half descriptor and the combination of the two, which is just a concatenation of history histogram.",
                    "label": 0
                },
                {
                    "sent": "Different histogram types.",
                    "label": 0
                },
                {
                    "sent": "The Cuba descriptor which has.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Introduced by dollar at all.",
                    "label": 0
                },
                {
                    "sent": "Takes a 3D Patch and it describes the three Patch bites.",
                    "label": 1
                },
                {
                    "sent": "Gradient, spatial, temporal gradient, pixel values.",
                    "label": 0
                },
                {
                    "sent": "All these pixel gradient values are concatenated in one feature vector and its dimensionality is projected down to low dimensional space with PCA and this is the descriptor vector.",
                    "label": 1
                },
                {
                    "sent": "The.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "3D script has been introduced last year.",
                    "label": 0
                },
                {
                    "sent": "So PMDC by class at all.",
                    "label": 0
                },
                {
                    "sent": "And it's an extension of the SIFT descriptor popular self descriptor for images.",
                    "label": 1
                },
                {
                    "sent": "Extended to videos and it's based on histograms of 3D3DS.",
                    "label": 1
                },
                {
                    "sent": "Also spatial temporal gradient orientations and the quantization of 3D gradients is in this case they propose to Orient quantize them using regular polyhedrons as depicted down the nice star like thing in the bottom.",
                    "label": 0
                },
                {
                    "sent": "So the faces are the bins.",
                    "label": 0
                },
                {
                    "sent": "And Interestingly, this descriptor combines directly in one descriptor, motion and shape information.",
                    "label": 0
                },
                {
                    "sent": "And the E surf descriptor presented by Williams.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Last year, the CCD is an extension of the surf descriptor to videos.",
                    "label": 1
                },
                {
                    "sent": "And that's before the 3D cuboid is divided into cells and each cell will computer.",
                    "label": 0
                },
                {
                    "sent": "Responses of the hard wavelets aligned to the different orientation axis.",
                    "label": 0
                },
                {
                    "sent": "And then the descriptor for each cell are called.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Automated and this gives you a final vector.",
                    "label": 0
                },
                {
                    "sent": "The results.",
                    "label": 0
                },
                {
                    "sent": "So as I said before.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Present results on three datasets KTH dataset, Yousef, Sports data set and the Hollywood 2 datasets and I will treat treat data set by data set.",
                    "label": 0
                },
                {
                    "sent": "The KTH data set is probably one of the most known.",
                    "label": 0
                },
                {
                    "sent": "Once it has been around for quite a while now, it contains of it contains 10 action classes.",
                    "label": 0
                },
                {
                    "sent": "And it has 25 different people performing these actions in different scenarios.",
                    "label": 0
                },
                {
                    "sent": "In total there are about 2400 video samples.",
                    "label": 1
                },
                {
                    "sent": "And it'll be you sequences and you will see I will have just a demo video of of the data set so you have an impression it has quite homogeneous and static background.",
                    "label": 0
                },
                {
                    "sent": "And the current state of the art is about 92%, and the measure is average accuracy over all classes.",
                    "label": 1
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Here you see a little sample, so you see the different action classes are depicted in the columns and the different scenarios are in the Rose from bottom to from the top to the bottom.",
                    "label": 0
                },
                {
                    "sent": "These first scenarios outdoors.",
                    "label": 0
                },
                {
                    "sent": "Then you have second scenarios outdoors with varying scales.",
                    "label": 0
                },
                {
                    "sent": "The third scenario is outdoors with different clothes and the last scenario is indoors.",
                    "label": 0
                },
                {
                    "sent": "So you can see the homogeneous background and so you get an impression for the depth data set.",
                    "label": 0
                },
                {
                    "sent": "The results.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "This is a table, so detectors are in the columns and the descriptors are depicted in the rows.",
                    "label": 0
                },
                {
                    "sent": "The best 3 results are highlighted with red in red.",
                    "label": 0
                },
                {
                    "sent": "You will see that.",
                    "label": 0
                },
                {
                    "sent": "To summarize it up, the best results we obtain in our setup for Harris, Philly and half descriptor.",
                    "label": 0
                },
                {
                    "sent": "But we also obtain quite fairly good reason Comperable results using the Harris Rudy and the keyboards detector for the Hawk often hog three descriptors.",
                    "label": 0
                },
                {
                    "sent": "Note what is interesting to note here is if you look at the dense dense sampling, it does really perform well compared to the best results, and we assume that it's certainly or probably due to the large amount of features that we obtained through the dense sampling on the homogeneous background, which doesn't really give more information but may corrupt the statistics.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The second data set is the USF sports data set, which contains of 10 different sports action classes.",
                    "label": 1
                },
                {
                    "sent": "It has altogether 150 video samples and we use also the flipped videos to extend the data set a bit to get more samples.",
                    "label": 0
                },
                {
                    "sent": "The evaluation is done by a leap on out cross validation.",
                    "label": 0
                },
                {
                    "sent": "And the measure is again a virtual currency of all classes, and the current state of the art is around 70%.",
                    "label": 0
                },
                {
                    "sent": "By the authors also presented the data set, but well, this kind of we directly compared to to the results that we get, but it's just to happen to have an idea.",
                    "label": 0
                },
                {
                    "sent": "Here are some sample sequences.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Some simple actions.",
                    "label": 0
                },
                {
                    "sent": "So again, the action classes are depicted in the columns and you have some different samples.",
                    "label": 0
                },
                {
                    "sent": "So we get an impression of the different actions and the difficulty.",
                    "label": 0
                },
                {
                    "sent": "Let's put it OK. And the results.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You see that in this case, where you see F. For you CF, we have the best results for using dense sampling for the for the hook through the descriptor, but also gives reasonable results.",
                    "label": 1
                },
                {
                    "sent": "As well as hot coffee also gives good results.",
                    "label": 0
                },
                {
                    "sent": "And Interestingly, As for the interest point detectors, is the keyword detector in combination with the Hawk 3D descriptor, who gives good results.",
                    "label": 0
                },
                {
                    "sent": "And last but not least.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The Hollywood 2 actions data set, which is the most challenging one which has been proposed, released this year.",
                    "label": 0
                },
                {
                    "sent": "It contains 12 different action classes.",
                    "label": 1
                },
                {
                    "sent": "When all the sequences have been mined from 2 altogether, 69 different Hollywood movies.",
                    "label": 1
                },
                {
                    "sent": "It has in total 1700 video samples.",
                    "label": 0
                },
                {
                    "sent": "There's a test and training set.",
                    "label": 0
                },
                {
                    "sent": "The sample stuff from different movies so there's no overlap.",
                    "label": 0
                },
                {
                    "sent": "And it's the measure that has been used as close to the basketball box challenge.",
                    "label": 1
                },
                {
                    "sent": "It's mean average position over all classes.",
                    "label": 0
                },
                {
                    "sent": "This gives you an impression of the data.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Is it?",
                    "label": 0
                },
                {
                    "sent": "So you see, if you look at ansafone, you have a on the very top.",
                    "label": 0
                },
                {
                    "sent": "You have the huge variation of different different movie.",
                    "label": 0
                },
                {
                    "sent": "Movies.",
                    "label": 0
                },
                {
                    "sent": "Different movie styles.",
                    "label": 0
                },
                {
                    "sent": "And you may also have for one particular video sequence of 1 sample, you may have different action classes that it belongs to.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "The results.",
                    "label": 0
                },
                {
                    "sent": "Here in our setup we obtain best results for dense sampling using the horkoff descriptor.",
                    "label": 1
                },
                {
                    "sent": "And in general we get good results for the Horcoff descriptor for Hollywood 2 datasets.",
                    "label": 0
                },
                {
                    "sent": "The conclusion to wrap it all up.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So we have seen, especially for realistic data settings for realistic videos, video data, we see that then sampling in our setup outperformed the detectors.",
                    "label": 0
                },
                {
                    "sent": "This is kind of consistent.",
                    "label": 0
                },
                {
                    "sent": "Would have been what has been found also for images.",
                    "label": 0
                },
                {
                    "sent": "We also see or we want to would like to point out the importance of realistic media data.",
                    "label": 1
                },
                {
                    "sent": "Same as 444 images, so things that we find work on more.",
                    "label": 0
                },
                {
                    "sent": "Artificial data cannot really be applied directly to realistic data, so we would like to encourage other people also to check out the Hollywood 2 datasets into to check their algorithms on these datasets.",
                    "label": 0
                },
                {
                    "sent": "I think that is really important.",
                    "label": 0
                },
                {
                    "sent": "We also see the limitations of the current feature detectors and just a little note then simply works better, but you will also get much more data.",
                    "label": 1
                },
                {
                    "sent": "So in our case we have 15 to 20 times more data than for interest point detectors.",
                    "label": 0
                },
                {
                    "sent": "As for the detectors globally, we didn't really have the impression that you can point out to ones, particularly detector which works best.",
                    "label": 0
                },
                {
                    "sent": "And for the descriptors, the overall ranking is given there, so her cough seems to perform slightly better than all 3D which performed better than a cuboid sandwich performed better than the surf and hog descriptor.",
                    "label": 1
                },
                {
                    "sent": "And well, maybe it seems to us.",
                    "label": 0
                },
                {
                    "sent": "It seems that it's a good choice to combine them.",
                    "label": 0
                },
                {
                    "sent": "Gradients and optical flow into one descriptor's by the results.",
                    "label": 0
                },
                {
                    "sent": "This seems to be a good idea.",
                    "label": 0
                },
                {
                    "sent": "And just a note.",
                    "label": 0
                },
                {
                    "sent": "Of course, this is just the first first step, so there are certainly other open topics that need to be looked more into detail, especially different descriptor parameters for the descriptors we used in the detectors were used in.",
                    "label": 0
                },
                {
                    "sent": "Here we use standard settings, so this could be optimized as well as the.",
                    "label": 0
                },
                {
                    "sent": "If you look at the dollar descriptor, the keyboard descriptor by dollar, this could be also applied to different different scales, so that would be interesting.",
                    "label": 0
                },
                {
                    "sent": "So there a few open things to look at.",
                    "label": 0
                },
                {
                    "sent": "But this is the first step and we think it's a good direction to have a global idea of how the different detectors in the script was performed in the same setup.",
                    "label": 1
                },
                {
                    "sent": "And that would be all.",
                    "label": 0
                },
                {
                    "sent": "Thank you very much for attention.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Make your parents.",
                    "label": 0
                },
                {
                    "sent": "Well, in this work we haven't looked at the.",
                    "label": 0
                },
                {
                    "sent": "We haven't been combined the different descriptors, but clearly if you want to get the best performance, I think the box challenge shows that this seems to be currently the way to go to combine different detectors descriptors and optimize it on the different action classes.",
                    "label": 0
                },
                {
                    "sent": "But this is only possible if you have a reasonably data set.",
                    "label": 1
                },
                {
                    "sent": "We can learn these parameters on the training set.",
                    "label": 0
                },
                {
                    "sent": "But we haven't looked at it in this work and same applies also to grids.",
                    "label": 0
                },
                {
                    "sent": "And this is what we haven't looked at, but this would clearly be be interesting to look at.",
                    "label": 0
                },
                {
                    "sent": "Yeah, I think there's probably not one thing that you get one pump of.",
                    "label": 0
                },
                {
                    "sent": "Well, I think you need to optimize it on four different for different action classes because each section classes they can vary really much so.",
                    "label": 0
                },
                {
                    "sent": "There's nothing general that you can can say that you should read like this.",
                    "label": 0
                },
                {
                    "sent": "Otherwise, for focusing the attention, maybe it could be interesting.",
                    "label": 0
                },
                {
                    "sent": "Certainly, since human action is closely related to humans, so it probably would also make sense to focus on humans and get more descriptors around the humans.",
                    "label": 0
                },
                {
                    "sent": "And we look into this direction, yeah?",
                    "label": 0
                }
            ]
        }
    }
}