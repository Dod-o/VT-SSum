{
    "id": "ak5j6uaa224a65qtjkqcxxst62o6s7gh",
    "title": "Learning structured models for recognizing human actions",
    "info": {
        "author": [
            "Greg Mori, School of Computing Science, Simon Fraser University"
        ],
        "published": "Aug. 24, 2011",
        "recorded": "June 2011",
        "category": [
            "Top->Computer Science->Computer Vision->Motion and Tracking"
        ]
    },
    "url": "http://videolectures.net/gesturerecognition2011_mori_learning/",
    "segmentation": [
        [
            "So I'm going to talk about structure."
        ],
        [
            "It's recognizing human actions, and this is a gesture recognition workshop.",
            "But most of most of my work is on human activity recognition, and in addition to sort of the usual surveillance sort of applications, people use security.",
            "It's also very useful in a lot of more friendly perhaps environments, and one of the projects that we've been working on is on collaborating with some conditions or interest in figuring out why do people fall in nursing homes and the conditions have alot of hypothesis about these.",
            "One is that, for example, people trip on objects that are lying on the floor, and others they might slip over slippery surface.",
            "Otherwise, maybe there's a blood pressure medications that are involved in going from sitting to standing.",
            "In any event, they need data on.",
            "Why do people fall?",
            "Because for each of these false positives are treatments and we do a lot of video surveillance on trying to identify falls and nearfalls so that we can gather data about why are people falling in nursing home.",
            "So most will talk about is a project action recognition."
        ],
        [
            "For the purpose of this workshop, it is about just recognition.",
            "So many algorithms we've developed for recognizing human activities.",
            "We've applied them to settings such as you know, human computer interaction, sort of things.",
            "One does connect, type of interface is trying to figure out gestures.",
            "Another example of this type of."
        ],
        [
            "Application we also use this for human robot interaction, so develop algorithms that can allow user to build up teams of robots by using our methods called face engagement.",
            "So staring at robots to try to get their attention and then making gestures for example with your arm to circle a team of robots and then command them away with adjuster.",
            "So again the similar sort of algorithms we've developed stripped down version that we run in real time on robots to make them do things.",
            "But the main focus my talking."
        ],
        [
            "Going to be about these sort of structured models for activity recognition.",
            "What I mean by that is methods that can capture both the whole sort of salt of what's happening to the person in a large scale representation, as well as some things about the parts.",
            "So things like little part based representations as well, and this talking we talk about representations and learning for these structured models for human."
        ],
        [
            "Actions.",
            "So an example of this for action recognition.",
            "There are a lot of methods that uses called template based methods for representing human actions.",
            "So for example, optical flow based representations or on the other hand versus local part based representations as well.",
            "And one might ask."
        ],
        [
            "So if I want to recognize actions might be nice to build models that combine these two sources of information together, get sort of this sort of whole representation.",
            "Templates of a flow for example, as well as local Patch methods.",
            "And the challenge is how do we build principle models to combine them together so?"
        ],
        [
            "We've done a lot of work on particular type model known in the sort of public market is a hidden conditional random field and I'm going to sort of go through in a little bit of detail, building it up 'cause the work that we're going to talk about today builds on this type of model.",
            "So in these what you have is you have some sort of input image, will call this X something down here, and a class label Y.",
            "This is the actual labels such as persons waving his hand.",
            "He's falling down the nursing home he's running, etc, and will have features that sort of link in between these two together and will have parameters on those and potential function.",
            "They serve your global template model.",
            "Which sorts of global templates go well with which action labels and in addition we like to have some sort of local part features as well, so these can be sort of interest.",
            "Point operators been run on the image and detect little spacetime interest points and describe them with your favorite descriptor, and will do again.",
            "Is have some sort of hidden variables on these saying these are different types of parts and will call those ages, and they'll be some links in between those.",
            "Again, say, how do these parts relate to the different image patches and his usual parameters on top of these as well?",
            "And then we'll have sort of which parts belong together with which action labels.",
            "So if I want to say, for example, this person is waving his hand, I might like parts that are sort of back and forth motion.",
            "Those will say that they are indicative that action class, and so, although this whole big mess together with all these different parameters, other forms, a really big probabilistic model, and this is him get conditional random field model with probability probability distribution over all these hidden parts and action labels.",
            "And just to give some intuition."
        ],
        [
            "Find what these look like and these are some examples on old Weitzman data set.",
            "These are sort of coloring each of those hidden parts by color indicates what type they are, and so as you can see sort of example.",
            "The green is sort of some waving back and forth motion.",
            "The blue ones are sort of hopping up and down parts and here these are sort of these inferred part labels that you have in these models an all the work we've done is on looking at."
        ],
        [
            "Learning criteria for how do you set model parameters?",
            "And there's sort of these two different different approaches that we've explored.",
            "One is a sort of conditional likelihood method where what you do is integrate out all of these hidden part labels H in order to figure out what the cost labels and on the other hand these are these Max margins.",
            "So the latent SVM type of approach for setting parameters, and we've done some work together with young lungs forward student mine on comparing these two different approaches for learning parameters and trying to understand why these Max margin methods tend to be better in."
        ],
        [
            "In the literature and so we have comparative examples on different standard datasets in KTH and Weitzman, and basically what happens is that performance almost always seems better with the Max margin version of these compared to the condition conditional likelihood and Young's intuition about why this is the case.",
            "So in these sort of conditional random field models, probabilistic models.",
            "What you can do is some out over all the latent variables H you form this big sum over all the possible values for these hidden variables and try to make that good for the correct cost label and bad for the.",
            "Incorrect cost label and in the Max margin version.",
            "The latent SVM version of that instead, what you're doing is you're just trying to make 1 setting of H for the correct class label better than one setting of H for the incorrect cost label, and not only is this or better tide to the learning outcome, you want the classification error to be better.",
            "It also seems like a simple learning problem not having to deal with that big sum of variables.",
            "OK, so that's sort of."
        ],
        [
            "In the background, that's the main tool that we're going to be using to do the more intuitive work on doing action recognition.",
            "It's sort of structured latent variable models where one has some output label YA bunch of latent variables, H in between, and we have these Max margin criterion from learning for setting the parameter values, and I'm going to talk about three different examples of using this type of model to do activity recognition.",
            "So the first one is latent pose estimation.",
            "System work with away long young and some."
        ],
        [
            "Simone CPR last year, so the goal here is what we want to do is we want to action recognition from still images.",
            "So even just a single image.",
            "We'd like to figure out what is the person doing here and we think that poses a very important representation of this.",
            "If you were here earlier before the break, they have foresight systems or compositional models and using human pose to try to recognize action.",
            "Also subscribe this view that human pose at its root, if one could accurately localize all of the joints of the person, that problem very very strong Q to figure out what the person is doing.",
            "So we've sort of pose estimation is very, very key part to doing.",
            "Action wreck"
        ],
        [
            "Mission.",
            "There are of course other approaches that have tried to do this before they sort of fall into sort of roughly two categories, where global template based representations.",
            "So just looking at sort of, for example hog of the entire person and try to use that to figure out the actual labels doesn't get much at what the pose of the person is, though on the other hand, there are pieces of work that basically taken an input image or video sequence and then run a pose estimator, for example ramadan's post parser, and then from that try to produce an action label.",
            "So sorry first to pose estimation, then do action recognition.",
            "On the other hand."
        ],
        [
            "We're interested in sort of discriminative methods and we really don't believe all elements of poser equally important when it comes to recognizing actions, so I'm going to little story.",
            "I spent 20 years of my life roughly playing baseball, and it was sort of wasted.",
            "I guess because baseball isn't the most exciting sport, but let me tell this good story so when it comes to playing baseball, one thing that a batter needs to do is in a very, very short amount.",
            "Split second needs to decide whether pitchers throwing a fastball or curveball because pictures showing a fastball he needs to swing straight.",
            "It's a curveball used to plan on that and swing it a slightly different location.",
            "The way in which this distinction is made, one of their key things is to look at the pictures wrist.",
            "If the picture is throwing with a straight risk, that's going to be a fastball.",
            "If you see a thin wrist, a sideways, when it's likely to be a curveball.",
            "So this is very subtle distinction on pose.",
            "It's about is opposed front facing.",
            "Or is it side facing?",
            "Where is the arm?",
            "Where are the legs?",
            "None of this matters when it comes down to this subtle distinction, visit fastball or curveball, make this distinction very, very quickly.",
            "Plan your swing, focus on a discriminative aspect of the pose.",
            "Unfortunately, computer vision algorithms aren't able to sort of distinguishing very, very subtle things.",
            "We talk about golfing and walking, but the idea is sort of similar.",
            "I'm trying to decide between whether this person is golfing or walking rather than looking at the entire pose of the person trying to localize every single bit of him, one can set hone in on the important part of the discriminative bits of the pose.",
            "In particular, for this distinction with matters is the arms.",
            "If you see two arms together like this, or at any point this thing, this is very, very likely to be a golf swing.",
            "It's unlikely to be someone walking.",
            "People tend not to walk with her arms bound together like this.",
            "OK, well, usually I guess right, but what matters is find this discriminative pose rather than focusing on the whole entire thing of your body, right?",
            "So?",
            "What we can do is we can use that formalism that Max margin hidden conditional random field type model."
        ],
        [
            "2.",
            "Embed that intuition into a model to learn.",
            "What are those formative aspects of pose when it comes to pose representation were using what's called oppose.",
            "Let this by bird Evan Malik.",
            "It's sort of a non parametric representation of pose where you discretize sort of stereotypical bits of pose.",
            "So we're using one that sort of an accent specific variant of it by pose that we mean rather than the explicit positions of all these joints.",
            "Mean sort of a bent leg that supposed a bent arm that supposedly two arms that are held together.",
            "That's another type of Poland.",
            "Right, so that's the representation that we use when it comes to impose representation, but you could throw in your favorite one."
        ],
        [
            "You have in mind instead.",
            "So the goal isn't to develop a scoring function similar to that model.",
            "I described a few slides ago where we want to do is taking an input image and have some sort of scoring function as in between it oppose representation and have one that has high scores for the correct cost label and low scores for other ones and wants a model."
        ],
        [
            "Understated that we learn, So what this looks like when we build up another one of these models were again we have input image at the bottom and our cost label the top why?",
            "Which could be why is jogging wise running?",
            "Why is playing golf and in between will have some latent variables in this time no.",
            "L which will be about the pose.",
            "What is opposed to the person right now?",
            "And what we'll be doing is doing this Max margin learning.",
            "Serve Layton SVM style.",
            "What we doing is finding the best possible posed for some particular cost label YO."
        ],
        [
            "For example, if I hypothesize this person is running costly, wise running, let me find a set of pose, let sort of Canonical bits of pose that match well to this this image.",
            "Find me the best such sent and I'm going to be training all these parameters discriminatively, so again will focus in on the bits that matter when it comes to distinguishing between different action categories."
        ],
        [
            "Write the full model.",
            "Of course, links up connects everything up together in the standard sort of way, but inference is still practical.",
            "Tractable for these these MoD."
        ],
        [
            "We've done experiments on a data set of still action images and basically we compare it to to baselines where we just use hog sort of hog and SVM to classify action."
        ],
        [
            "Perhaps more interesting is the visualizations of the latent pose when it comes to recognizing the actions on the top, or examples of successfully classified images.",
            "And we can see these things such as sitting poses, so when it comes to pose estimation, arms are very, very tricky to get right, especially when people tend to hold them against their bodies or wear shirts that have texture on them.",
            "But when it comes to figure out someone sitting, if you see this sort of triangular shaped pattern for the legs, very indicative that the persons sitting down it doesn't matter if the arms right or wrong at that point.",
            "If you could see that type of post for the legs.",
            "That's enough to tell that someone sitting, of course it doesn't always work, poses major is difficult, and if posed, estimated strange things and you'll end up in trouble after all."
        ],
        [
            "OK, so that's a first example of something one can do with these.",
            "These latent variable models for activity recognition.",
            "The next piece of work, and we talk about is jointly recognizing actions and localising them in video sequences, and this is some work by time management of mine that appeared I see in a few months.",
            "So when it comes to recognizing actions in videos, again, there are sort of two approaches is that people tend to follow one of these are statistical approach is characterized by a bag of features.",
            "Approach rotten interest, point operator or videos or densely sample bunch of descriptors and use that to build a histogram representation.",
            "However, this seems like it's sort of very, very lacking.",
            "Obviously doesn't think about the spatial arrangement of the human figure.",
            "Doesn't say about the people that are present in the image.",
            "On the other hand, there are these approaches that try to build so-called figure centric representations.",
            "Ones that say here is a person.",
            "Let's describe something with respect to where the person is.",
            "These are very difficult to do, especially for very interesting actions because they usually require accurate human detection and tracking before they operate and in less people are standing and walking.",
            "It's very difficult to build good pose estimator, so you think about things like people are diving, riding horses, doing gymnastics events.",
            "It's very difficult to have opposed, sorry human detector that will reliably work on those and give you good tracks of the person through the video.",
            "So instead we can do is we can treat that as a latent variable in one of our models.",
            "So what we do is we want to have it.",
            "An input video sequence and we want output both the action label of it as well as a localization of where is that action taking place and the way in which will do.",
            "That is will represent a video sequence rather than just a set of interest points are scattered over the video by those as well as a figure centric representation of those saying.",
            "I think the person is here with these key visual words that are on this person an at a finer level of detail will also say that will have individual cells on the person.",
            "Saying not only is there a bounding box where they're also individual cells within that bounding box that are actually part of the person or not.",
            "And all of these things together are going to be latent variables that we're going to infer at runtime and learn parameters about these as we go.",
            "So just a few details on this model.",
            "Again, it's very similar.",
            "If I drew the graphical picture, look the same as those models I've described before, but this time what we're doing is we're actually having representations that move in time as well, since we have video sequences, so the model consists of a number of terms.",
            "The first one relates individual frames and locations.",
            "These are going to be individual locations, ally of the bounding box of the person in this frame, as well as the zed variables that say which of those cells of that bounding box are active or part of the person who's performing the action.",
            "So they'll be unary terms in the model that are about those as well as a pairwise constraint that basically says from time to time T + 1 the position of that bounding box should change too much.",
            "Just be some consistency and appearance.",
            "Basically a form of tracking constraint that maintains the location of the person overtime.",
            "And finally, we can also concatenate those on with sort of global models that can give things like seeing context by looking at grab bag of words, descriptors for the entire video sequence.",
            "So all of those together can be trained up in one of these models.",
            "If you're familiar with or latency.",
            "Learning it's one of those type of model, except there's a loss function in there that cares about localization as well as action label, correct predictions.",
            "So all of those put in together.",
            "You can learn parameters of this, some example of results on the UC F sports data set, so these are correctly labeled with the correct action labels as well as getting these location as well as red cells highlighted where we think the action is taking place.",
            "So those locations are not given to you at Test time.",
            "Those are in Ferd.",
            "In the methods were localising as well as seeing what the action label is.",
            "So here's some other still frame examples of that as well.",
            "Again, it works reasonably well even when they're sort of cluttered scenes or scenes with multiple people in them.",
            "One can still figure out where the people are and get some notion of which cells of documents are important for recognizing the action.",
            "So one other final thing we talk about is doing some research things with group context.",
            "So looking at activity recognition of an entire scene rather than."
        ],
        [
            "An individual.",
            "So when it comes to doing activity recognition, if I give you individual bounding boxes of people, it might seem like these two people are doing the same action that were standing upright.",
            "But if you reveal the entire context of the scene and see what everybody else around them is doing, you see these people are doing different things.",
            "This person standing in a queue and this person is engaged in a conversation.",
            "So by looking at the entire scene around the person, when you get a better feeling for what's happening this.",
            "Also we were motivated to look at this for the nursing home data set that we're looking at for the nursing home data set.",
            "If somebody falls down in a nursing home, often other people come and rush to help.",
            "And disambiguating what this person is doing is very helpful to look at what the people around them were doing."
        ],
        [
            "So there are two types of context that we try to exploit using this Model 1 is what we call sort of group person interaction, where we say the individual people in a scene are all related by some underlying activity that's occurring in that scene.",
            "For example, everybody here is engaged in talking on another level.",
            "We're also interested in these little person to person interaction, so individual people together people talking each other tend to face each other, so there's this individual to individual interaction that's going on as well, so we can."
        ],
        [
            "Both of these together in one of these these models, where again we have input image and this time instead of these X is being an interest point operators or individual descriptors.",
            "These are personal locations, so we have individual people we've detected as seen.",
            "Each of these people have some underlying action class that he's performing, and they'll be tide together in a global activity class for the entire scene.",
            "So the thing that's slightly different about this from the other models is that the interactions between the individuals are actually going to be something that are latent as well.",
            "So rather than assuming that everybody in the scene is related to everybody else.",
            "For example, if you're in a crowded room and a subset of those people are talking not, it's not necessarily the case at every single person is going to be involved in the interaction together, and not everybody should be linked together in the scene.",
            "So we actually formulated."
        ],
        [
            "Different version of the latent structure model in which we actually have a set of latent connections.",
            "So the connections between the variables age.",
            "In this case the people in the scene.",
            "Those are something that you infer at Test time, so I figure out who should be connected to whom, and this can make you resilient to things like clutter in the form of people who are doing actions unrelated to the underlying activity.",
            "But it's another form of these labels, except we have a straw."
        ],
        [
            "So we've tested this out on a nursing home data set collected from a real nursing home.",
            "With, you know, background clutter challenges from the low resolution of the video and etc an."
        ],
        [
            "You've got quantitative results comparing this to a number of different baselines, so we can just sort of directly apply support vector machines to the individual features.",
            "We can have a number of different possible graph structures in a regular latent SVM type of model, where we connect up people based upon some distance threshold that we have, or we can do approaches that use dynamically inferring the set of connections that should be in front.",
            "So latent connection type of model."
        ],
        [
            "Right, and those those outperform.",
            "So again, some examples of corrective actions.",
            "We say there's a fall.",
            "This is a person is following this person sitting down this person standing out and we can infer an individual actions as well as the underlying activity of."
        ],
        [
            "We'll see."
        ],
        [
            "So in conclusion, I've talked about structured models, models with holes versus parts, and given a few different examples of how we can use this for doing activity recognition so semantically meaningful parts such as latent pose estimation for doing still image action recognition, localising actions in videos, telling which frames are part of an action, which sub regions of those frames are part of them as well as a scene structure model on top of that."
        ],
        [
            "So to conclude, by acknowledging these are the students actually did the work that I talked about, particularly young one was involved in all of this work, and thank you very much.",
            "OK so thanks Greg, any questions?",
            "From the audience.",
            "Right?",
            "The still image action distance from Nazia Kistler so I can give you a pointer to that if you'd like, but it's on her website.",
            "Yeah, that's from a.",
            "It's that it comes from videos, but it's per frame recognition, so that's from U Michigan from choices the author name, Troy and Silvio Separase.",
            "Any other questions?",
            "A question that I had was so the pose in all those still images was analyzed automatically using existing computer vision software.",
            "Yes, and so you found that this analysis was correct for most of them know, or so absolutely not.",
            "So basically where there is doubt that you showed that you manually select cases where the post analysis was correct or is this results on the whole data set.",
            "Basically where you live and die with whatever the post analysis gives you, right?",
            "So just to so these.",
            "His example."
        ],
        [
            "Those were.",
            "So this is the output of the pose estimator in the sense of what you're doing is finding the most likely pose, so the argmax over the over the pose for the cost label the top row or those pose estimations for when we get the class label correct, and the bottom rows for when you get the cost label wrong, right?",
            "So it's not a pose estimator for sacas, it's trained to try to do action classification.",
            "Right there, the learning criterion about action classification, not about pose estimation accuracy, but I would say even if one ran for example, Deva Ramanan pose estimator on images such as this one, the output would be quite strange.",
            "It wouldn't look anything like this are very unusual pose.",
            "OK.",
            "Thanks for your preview.",
            "Fly severe papers seems interesting, so just one question.",
            "So it seemed that when you showed the video, the temporal.",
            "There was not much temporal consistency in your model.",
            "Is it because you don't impose it, or there's some amount of temporal coherence?",
            "But for example, in the persons diving undergoing very drastic changes in appearance, so the terms in the the model involve appearance in appearance, similarity from frame to frame.",
            "So I'm going to say that person is at location Ally in this frame should be at another location next from those appearance of those non box should be similar.",
            "That's a relatively difficult thing to do when the person is diving like this, so it jitters around, but probably because the person is just changing appearance quite drastically.",
            "I mean, the guy who's golfing and standing still, it's much more stable around him.",
            "But yeah, there's a term in the model for that that serve enforces both the spatial position of that bounding box as well as the appearance of it should be similar.",
            "For the fall detection fall recognition reflection you.",
            "Started with person locations as your bottom level representation.",
            "So how did you obtain those right?",
            "So we how detailed where this for that one.",
            "We've done a couple of different datasets for the nursing home data set.",
            "Basically it's background subtraction based.",
            "The camera is such a strange angle that it's hard to build sort of files, installed detectors or hog detectors on there.",
            "They don't work quite so well, so those are noisy and erratic, and I think that's another reason why we think there's some benefit to having these latent variables about who's connected to whom.",
            "If you have a spurious background detection of false positive, one could somewhat ignore those with these latent connections.",
            "Thank you.",
            "And the other question.",
            "OK, so let's thank the speaker once again."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So I'm going to talk about structure.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "It's recognizing human actions, and this is a gesture recognition workshop.",
                    "label": 0
                },
                {
                    "sent": "But most of most of my work is on human activity recognition, and in addition to sort of the usual surveillance sort of applications, people use security.",
                    "label": 0
                },
                {
                    "sent": "It's also very useful in a lot of more friendly perhaps environments, and one of the projects that we've been working on is on collaborating with some conditions or interest in figuring out why do people fall in nursing homes and the conditions have alot of hypothesis about these.",
                    "label": 0
                },
                {
                    "sent": "One is that, for example, people trip on objects that are lying on the floor, and others they might slip over slippery surface.",
                    "label": 0
                },
                {
                    "sent": "Otherwise, maybe there's a blood pressure medications that are involved in going from sitting to standing.",
                    "label": 0
                },
                {
                    "sent": "In any event, they need data on.",
                    "label": 0
                },
                {
                    "sent": "Why do people fall?",
                    "label": 0
                },
                {
                    "sent": "Because for each of these false positives are treatments and we do a lot of video surveillance on trying to identify falls and nearfalls so that we can gather data about why are people falling in nursing home.",
                    "label": 0
                },
                {
                    "sent": "So most will talk about is a project action recognition.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For the purpose of this workshop, it is about just recognition.",
                    "label": 0
                },
                {
                    "sent": "So many algorithms we've developed for recognizing human activities.",
                    "label": 0
                },
                {
                    "sent": "We've applied them to settings such as you know, human computer interaction, sort of things.",
                    "label": 0
                },
                {
                    "sent": "One does connect, type of interface is trying to figure out gestures.",
                    "label": 0
                },
                {
                    "sent": "Another example of this type of.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Application we also use this for human robot interaction, so develop algorithms that can allow user to build up teams of robots by using our methods called face engagement.",
                    "label": 0
                },
                {
                    "sent": "So staring at robots to try to get their attention and then making gestures for example with your arm to circle a team of robots and then command them away with adjuster.",
                    "label": 0
                },
                {
                    "sent": "So again the similar sort of algorithms we've developed stripped down version that we run in real time on robots to make them do things.",
                    "label": 0
                },
                {
                    "sent": "But the main focus my talking.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Going to be about these sort of structured models for activity recognition.",
                    "label": 1
                },
                {
                    "sent": "What I mean by that is methods that can capture both the whole sort of salt of what's happening to the person in a large scale representation, as well as some things about the parts.",
                    "label": 1
                },
                {
                    "sent": "So things like little part based representations as well, and this talking we talk about representations and learning for these structured models for human.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Actions.",
                    "label": 0
                },
                {
                    "sent": "So an example of this for action recognition.",
                    "label": 0
                },
                {
                    "sent": "There are a lot of methods that uses called template based methods for representing human actions.",
                    "label": 0
                },
                {
                    "sent": "So for example, optical flow based representations or on the other hand versus local part based representations as well.",
                    "label": 0
                },
                {
                    "sent": "And one might ask.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So if I want to recognize actions might be nice to build models that combine these two sources of information together, get sort of this sort of whole representation.",
                    "label": 0
                },
                {
                    "sent": "Templates of a flow for example, as well as local Patch methods.",
                    "label": 0
                },
                {
                    "sent": "And the challenge is how do we build principle models to combine them together so?",
                    "label": 1
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We've done a lot of work on particular type model known in the sort of public market is a hidden conditional random field and I'm going to sort of go through in a little bit of detail, building it up 'cause the work that we're going to talk about today builds on this type of model.",
                    "label": 0
                },
                {
                    "sent": "So in these what you have is you have some sort of input image, will call this X something down here, and a class label Y.",
                    "label": 0
                },
                {
                    "sent": "This is the actual labels such as persons waving his hand.",
                    "label": 0
                },
                {
                    "sent": "He's falling down the nursing home he's running, etc, and will have features that sort of link in between these two together and will have parameters on those and potential function.",
                    "label": 0
                },
                {
                    "sent": "They serve your global template model.",
                    "label": 0
                },
                {
                    "sent": "Which sorts of global templates go well with which action labels and in addition we like to have some sort of local part features as well, so these can be sort of interest.",
                    "label": 0
                },
                {
                    "sent": "Point operators been run on the image and detect little spacetime interest points and describe them with your favorite descriptor, and will do again.",
                    "label": 0
                },
                {
                    "sent": "Is have some sort of hidden variables on these saying these are different types of parts and will call those ages, and they'll be some links in between those.",
                    "label": 0
                },
                {
                    "sent": "Again, say, how do these parts relate to the different image patches and his usual parameters on top of these as well?",
                    "label": 0
                },
                {
                    "sent": "And then we'll have sort of which parts belong together with which action labels.",
                    "label": 0
                },
                {
                    "sent": "So if I want to say, for example, this person is waving his hand, I might like parts that are sort of back and forth motion.",
                    "label": 0
                },
                {
                    "sent": "Those will say that they are indicative that action class, and so, although this whole big mess together with all these different parameters, other forms, a really big probabilistic model, and this is him get conditional random field model with probability probability distribution over all these hidden parts and action labels.",
                    "label": 0
                },
                {
                    "sent": "And just to give some intuition.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Find what these look like and these are some examples on old Weitzman data set.",
                    "label": 0
                },
                {
                    "sent": "These are sort of coloring each of those hidden parts by color indicates what type they are, and so as you can see sort of example.",
                    "label": 0
                },
                {
                    "sent": "The green is sort of some waving back and forth motion.",
                    "label": 0
                },
                {
                    "sent": "The blue ones are sort of hopping up and down parts and here these are sort of these inferred part labels that you have in these models an all the work we've done is on looking at.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Learning criteria for how do you set model parameters?",
                    "label": 0
                },
                {
                    "sent": "And there's sort of these two different different approaches that we've explored.",
                    "label": 0
                },
                {
                    "sent": "One is a sort of conditional likelihood method where what you do is integrate out all of these hidden part labels H in order to figure out what the cost labels and on the other hand these are these Max margins.",
                    "label": 1
                },
                {
                    "sent": "So the latent SVM type of approach for setting parameters, and we've done some work together with young lungs forward student mine on comparing these two different approaches for learning parameters and trying to understand why these Max margin methods tend to be better in.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the literature and so we have comparative examples on different standard datasets in KTH and Weitzman, and basically what happens is that performance almost always seems better with the Max margin version of these compared to the condition conditional likelihood and Young's intuition about why this is the case.",
                    "label": 0
                },
                {
                    "sent": "So in these sort of conditional random field models, probabilistic models.",
                    "label": 0
                },
                {
                    "sent": "What you can do is some out over all the latent variables H you form this big sum over all the possible values for these hidden variables and try to make that good for the correct cost label and bad for the.",
                    "label": 0
                },
                {
                    "sent": "Incorrect cost label and in the Max margin version.",
                    "label": 0
                },
                {
                    "sent": "The latent SVM version of that instead, what you're doing is you're just trying to make 1 setting of H for the correct class label better than one setting of H for the incorrect cost label, and not only is this or better tide to the learning outcome, you want the classification error to be better.",
                    "label": 0
                },
                {
                    "sent": "It also seems like a simple learning problem not having to deal with that big sum of variables.",
                    "label": 0
                },
                {
                    "sent": "OK, so that's sort of.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "In the background, that's the main tool that we're going to be using to do the more intuitive work on doing action recognition.",
                    "label": 0
                },
                {
                    "sent": "It's sort of structured latent variable models where one has some output label YA bunch of latent variables, H in between, and we have these Max margin criterion from learning for setting the parameter values, and I'm going to talk about three different examples of using this type of model to do activity recognition.",
                    "label": 0
                },
                {
                    "sent": "So the first one is latent pose estimation.",
                    "label": 0
                },
                {
                    "sent": "System work with away long young and some.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Simone CPR last year, so the goal here is what we want to do is we want to action recognition from still images.",
                    "label": 0
                },
                {
                    "sent": "So even just a single image.",
                    "label": 0
                },
                {
                    "sent": "We'd like to figure out what is the person doing here and we think that poses a very important representation of this.",
                    "label": 0
                },
                {
                    "sent": "If you were here earlier before the break, they have foresight systems or compositional models and using human pose to try to recognize action.",
                    "label": 0
                },
                {
                    "sent": "Also subscribe this view that human pose at its root, if one could accurately localize all of the joints of the person, that problem very very strong Q to figure out what the person is doing.",
                    "label": 0
                },
                {
                    "sent": "So we've sort of pose estimation is very, very key part to doing.",
                    "label": 0
                },
                {
                    "sent": "Action wreck",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Mission.",
                    "label": 0
                },
                {
                    "sent": "There are of course other approaches that have tried to do this before they sort of fall into sort of roughly two categories, where global template based representations.",
                    "label": 0
                },
                {
                    "sent": "So just looking at sort of, for example hog of the entire person and try to use that to figure out the actual labels doesn't get much at what the pose of the person is, though on the other hand, there are pieces of work that basically taken an input image or video sequence and then run a pose estimator, for example ramadan's post parser, and then from that try to produce an action label.",
                    "label": 0
                },
                {
                    "sent": "So sorry first to pose estimation, then do action recognition.",
                    "label": 0
                },
                {
                    "sent": "On the other hand.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "We're interested in sort of discriminative methods and we really don't believe all elements of poser equally important when it comes to recognizing actions, so I'm going to little story.",
                    "label": 1
                },
                {
                    "sent": "I spent 20 years of my life roughly playing baseball, and it was sort of wasted.",
                    "label": 0
                },
                {
                    "sent": "I guess because baseball isn't the most exciting sport, but let me tell this good story so when it comes to playing baseball, one thing that a batter needs to do is in a very, very short amount.",
                    "label": 0
                },
                {
                    "sent": "Split second needs to decide whether pitchers throwing a fastball or curveball because pictures showing a fastball he needs to swing straight.",
                    "label": 0
                },
                {
                    "sent": "It's a curveball used to plan on that and swing it a slightly different location.",
                    "label": 0
                },
                {
                    "sent": "The way in which this distinction is made, one of their key things is to look at the pictures wrist.",
                    "label": 0
                },
                {
                    "sent": "If the picture is throwing with a straight risk, that's going to be a fastball.",
                    "label": 0
                },
                {
                    "sent": "If you see a thin wrist, a sideways, when it's likely to be a curveball.",
                    "label": 0
                },
                {
                    "sent": "So this is very subtle distinction on pose.",
                    "label": 0
                },
                {
                    "sent": "It's about is opposed front facing.",
                    "label": 0
                },
                {
                    "sent": "Or is it side facing?",
                    "label": 0
                },
                {
                    "sent": "Where is the arm?",
                    "label": 0
                },
                {
                    "sent": "Where are the legs?",
                    "label": 0
                },
                {
                    "sent": "None of this matters when it comes down to this subtle distinction, visit fastball or curveball, make this distinction very, very quickly.",
                    "label": 0
                },
                {
                    "sent": "Plan your swing, focus on a discriminative aspect of the pose.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately, computer vision algorithms aren't able to sort of distinguishing very, very subtle things.",
                    "label": 0
                },
                {
                    "sent": "We talk about golfing and walking, but the idea is sort of similar.",
                    "label": 0
                },
                {
                    "sent": "I'm trying to decide between whether this person is golfing or walking rather than looking at the entire pose of the person trying to localize every single bit of him, one can set hone in on the important part of the discriminative bits of the pose.",
                    "label": 0
                },
                {
                    "sent": "In particular, for this distinction with matters is the arms.",
                    "label": 0
                },
                {
                    "sent": "If you see two arms together like this, or at any point this thing, this is very, very likely to be a golf swing.",
                    "label": 0
                },
                {
                    "sent": "It's unlikely to be someone walking.",
                    "label": 0
                },
                {
                    "sent": "People tend not to walk with her arms bound together like this.",
                    "label": 0
                },
                {
                    "sent": "OK, well, usually I guess right, but what matters is find this discriminative pose rather than focusing on the whole entire thing of your body, right?",
                    "label": 0
                },
                {
                    "sent": "So?",
                    "label": 0
                },
                {
                    "sent": "What we can do is we can use that formalism that Max margin hidden conditional random field type model.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "2.",
                    "label": 0
                },
                {
                    "sent": "Embed that intuition into a model to learn.",
                    "label": 0
                },
                {
                    "sent": "What are those formative aspects of pose when it comes to pose representation were using what's called oppose.",
                    "label": 0
                },
                {
                    "sent": "Let this by bird Evan Malik.",
                    "label": 0
                },
                {
                    "sent": "It's sort of a non parametric representation of pose where you discretize sort of stereotypical bits of pose.",
                    "label": 0
                },
                {
                    "sent": "So we're using one that sort of an accent specific variant of it by pose that we mean rather than the explicit positions of all these joints.",
                    "label": 0
                },
                {
                    "sent": "Mean sort of a bent leg that supposed a bent arm that supposedly two arms that are held together.",
                    "label": 0
                },
                {
                    "sent": "That's another type of Poland.",
                    "label": 0
                },
                {
                    "sent": "Right, so that's the representation that we use when it comes to impose representation, but you could throw in your favorite one.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "You have in mind instead.",
                    "label": 0
                },
                {
                    "sent": "So the goal isn't to develop a scoring function similar to that model.",
                    "label": 1
                },
                {
                    "sent": "I described a few slides ago where we want to do is taking an input image and have some sort of scoring function as in between it oppose representation and have one that has high scores for the correct cost label and low scores for other ones and wants a model.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Understated that we learn, So what this looks like when we build up another one of these models were again we have input image at the bottom and our cost label the top why?",
                    "label": 0
                },
                {
                    "sent": "Which could be why is jogging wise running?",
                    "label": 0
                },
                {
                    "sent": "Why is playing golf and in between will have some latent variables in this time no.",
                    "label": 0
                },
                {
                    "sent": "L which will be about the pose.",
                    "label": 0
                },
                {
                    "sent": "What is opposed to the person right now?",
                    "label": 0
                },
                {
                    "sent": "And what we'll be doing is doing this Max margin learning.",
                    "label": 0
                },
                {
                    "sent": "Serve Layton SVM style.",
                    "label": 0
                },
                {
                    "sent": "What we doing is finding the best possible posed for some particular cost label YO.",
                    "label": 0
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "For example, if I hypothesize this person is running costly, wise running, let me find a set of pose, let sort of Canonical bits of pose that match well to this this image.",
                    "label": 0
                },
                {
                    "sent": "Find me the best such sent and I'm going to be training all these parameters discriminatively, so again will focus in on the bits that matter when it comes to distinguishing between different action categories.",
                    "label": 0
                }
            ]
        },
        "clip_19": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Write the full model.",
                    "label": 0
                },
                {
                    "sent": "Of course, links up connects everything up together in the standard sort of way, but inference is still practical.",
                    "label": 0
                },
                {
                    "sent": "Tractable for these these MoD.",
                    "label": 0
                }
            ]
        },
        "clip_20": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We've done experiments on a data set of still action images and basically we compare it to to baselines where we just use hog sort of hog and SVM to classify action.",
                    "label": 0
                }
            ]
        },
        "clip_21": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Perhaps more interesting is the visualizations of the latent pose when it comes to recognizing the actions on the top, or examples of successfully classified images.",
                    "label": 0
                },
                {
                    "sent": "And we can see these things such as sitting poses, so when it comes to pose estimation, arms are very, very tricky to get right, especially when people tend to hold them against their bodies or wear shirts that have texture on them.",
                    "label": 0
                },
                {
                    "sent": "But when it comes to figure out someone sitting, if you see this sort of triangular shaped pattern for the legs, very indicative that the persons sitting down it doesn't matter if the arms right or wrong at that point.",
                    "label": 0
                },
                {
                    "sent": "If you could see that type of post for the legs.",
                    "label": 0
                },
                {
                    "sent": "That's enough to tell that someone sitting, of course it doesn't always work, poses major is difficult, and if posed, estimated strange things and you'll end up in trouble after all.",
                    "label": 0
                }
            ]
        },
        "clip_22": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so that's a first example of something one can do with these.",
                    "label": 0
                },
                {
                    "sent": "These latent variable models for activity recognition.",
                    "label": 0
                },
                {
                    "sent": "The next piece of work, and we talk about is jointly recognizing actions and localising them in video sequences, and this is some work by time management of mine that appeared I see in a few months.",
                    "label": 0
                },
                {
                    "sent": "So when it comes to recognizing actions in videos, again, there are sort of two approaches is that people tend to follow one of these are statistical approach is characterized by a bag of features.",
                    "label": 0
                },
                {
                    "sent": "Approach rotten interest, point operator or videos or densely sample bunch of descriptors and use that to build a histogram representation.",
                    "label": 0
                },
                {
                    "sent": "However, this seems like it's sort of very, very lacking.",
                    "label": 0
                },
                {
                    "sent": "Obviously doesn't think about the spatial arrangement of the human figure.",
                    "label": 0
                },
                {
                    "sent": "Doesn't say about the people that are present in the image.",
                    "label": 0
                },
                {
                    "sent": "On the other hand, there are these approaches that try to build so-called figure centric representations.",
                    "label": 0
                },
                {
                    "sent": "Ones that say here is a person.",
                    "label": 0
                },
                {
                    "sent": "Let's describe something with respect to where the person is.",
                    "label": 0
                },
                {
                    "sent": "These are very difficult to do, especially for very interesting actions because they usually require accurate human detection and tracking before they operate and in less people are standing and walking.",
                    "label": 0
                },
                {
                    "sent": "It's very difficult to build good pose estimator, so you think about things like people are diving, riding horses, doing gymnastics events.",
                    "label": 0
                },
                {
                    "sent": "It's very difficult to have opposed, sorry human detector that will reliably work on those and give you good tracks of the person through the video.",
                    "label": 0
                },
                {
                    "sent": "So instead we can do is we can treat that as a latent variable in one of our models.",
                    "label": 0
                },
                {
                    "sent": "So what we do is we want to have it.",
                    "label": 0
                },
                {
                    "sent": "An input video sequence and we want output both the action label of it as well as a localization of where is that action taking place and the way in which will do.",
                    "label": 0
                },
                {
                    "sent": "That is will represent a video sequence rather than just a set of interest points are scattered over the video by those as well as a figure centric representation of those saying.",
                    "label": 0
                },
                {
                    "sent": "I think the person is here with these key visual words that are on this person an at a finer level of detail will also say that will have individual cells on the person.",
                    "label": 0
                },
                {
                    "sent": "Saying not only is there a bounding box where they're also individual cells within that bounding box that are actually part of the person or not.",
                    "label": 0
                },
                {
                    "sent": "And all of these things together are going to be latent variables that we're going to infer at runtime and learn parameters about these as we go.",
                    "label": 0
                },
                {
                    "sent": "So just a few details on this model.",
                    "label": 0
                },
                {
                    "sent": "Again, it's very similar.",
                    "label": 0
                },
                {
                    "sent": "If I drew the graphical picture, look the same as those models I've described before, but this time what we're doing is we're actually having representations that move in time as well, since we have video sequences, so the model consists of a number of terms.",
                    "label": 0
                },
                {
                    "sent": "The first one relates individual frames and locations.",
                    "label": 0
                },
                {
                    "sent": "These are going to be individual locations, ally of the bounding box of the person in this frame, as well as the zed variables that say which of those cells of that bounding box are active or part of the person who's performing the action.",
                    "label": 0
                },
                {
                    "sent": "So they'll be unary terms in the model that are about those as well as a pairwise constraint that basically says from time to time T + 1 the position of that bounding box should change too much.",
                    "label": 0
                },
                {
                    "sent": "Just be some consistency and appearance.",
                    "label": 0
                },
                {
                    "sent": "Basically a form of tracking constraint that maintains the location of the person overtime.",
                    "label": 0
                },
                {
                    "sent": "And finally, we can also concatenate those on with sort of global models that can give things like seeing context by looking at grab bag of words, descriptors for the entire video sequence.",
                    "label": 0
                },
                {
                    "sent": "So all of those together can be trained up in one of these models.",
                    "label": 0
                },
                {
                    "sent": "If you're familiar with or latency.",
                    "label": 0
                },
                {
                    "sent": "Learning it's one of those type of model, except there's a loss function in there that cares about localization as well as action label, correct predictions.",
                    "label": 0
                },
                {
                    "sent": "So all of those put in together.",
                    "label": 0
                },
                {
                    "sent": "You can learn parameters of this, some example of results on the UC F sports data set, so these are correctly labeled with the correct action labels as well as getting these location as well as red cells highlighted where we think the action is taking place.",
                    "label": 0
                },
                {
                    "sent": "So those locations are not given to you at Test time.",
                    "label": 0
                },
                {
                    "sent": "Those are in Ferd.",
                    "label": 0
                },
                {
                    "sent": "In the methods were localising as well as seeing what the action label is.",
                    "label": 0
                },
                {
                    "sent": "So here's some other still frame examples of that as well.",
                    "label": 0
                },
                {
                    "sent": "Again, it works reasonably well even when they're sort of cluttered scenes or scenes with multiple people in them.",
                    "label": 0
                },
                {
                    "sent": "One can still figure out where the people are and get some notion of which cells of documents are important for recognizing the action.",
                    "label": 0
                },
                {
                    "sent": "So one other final thing we talk about is doing some research things with group context.",
                    "label": 0
                },
                {
                    "sent": "So looking at activity recognition of an entire scene rather than.",
                    "label": 0
                }
            ]
        },
        "clip_23": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "An individual.",
                    "label": 0
                },
                {
                    "sent": "So when it comes to doing activity recognition, if I give you individual bounding boxes of people, it might seem like these two people are doing the same action that were standing upright.",
                    "label": 0
                },
                {
                    "sent": "But if you reveal the entire context of the scene and see what everybody else around them is doing, you see these people are doing different things.",
                    "label": 0
                },
                {
                    "sent": "This person standing in a queue and this person is engaged in a conversation.",
                    "label": 0
                },
                {
                    "sent": "So by looking at the entire scene around the person, when you get a better feeling for what's happening this.",
                    "label": 0
                },
                {
                    "sent": "Also we were motivated to look at this for the nursing home data set that we're looking at for the nursing home data set.",
                    "label": 0
                },
                {
                    "sent": "If somebody falls down in a nursing home, often other people come and rush to help.",
                    "label": 0
                },
                {
                    "sent": "And disambiguating what this person is doing is very helpful to look at what the people around them were doing.",
                    "label": 0
                }
            ]
        },
        "clip_24": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So there are two types of context that we try to exploit using this Model 1 is what we call sort of group person interaction, where we say the individual people in a scene are all related by some underlying activity that's occurring in that scene.",
                    "label": 1
                },
                {
                    "sent": "For example, everybody here is engaged in talking on another level.",
                    "label": 0
                },
                {
                    "sent": "We're also interested in these little person to person interaction, so individual people together people talking each other tend to face each other, so there's this individual to individual interaction that's going on as well, so we can.",
                    "label": 0
                }
            ]
        },
        "clip_25": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Both of these together in one of these these models, where again we have input image and this time instead of these X is being an interest point operators or individual descriptors.",
                    "label": 0
                },
                {
                    "sent": "These are personal locations, so we have individual people we've detected as seen.",
                    "label": 0
                },
                {
                    "sent": "Each of these people have some underlying action class that he's performing, and they'll be tide together in a global activity class for the entire scene.",
                    "label": 0
                },
                {
                    "sent": "So the thing that's slightly different about this from the other models is that the interactions between the individuals are actually going to be something that are latent as well.",
                    "label": 0
                },
                {
                    "sent": "So rather than assuming that everybody in the scene is related to everybody else.",
                    "label": 0
                },
                {
                    "sent": "For example, if you're in a crowded room and a subset of those people are talking not, it's not necessarily the case at every single person is going to be involved in the interaction together, and not everybody should be linked together in the scene.",
                    "label": 0
                },
                {
                    "sent": "So we actually formulated.",
                    "label": 0
                }
            ]
        },
        "clip_26": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Different version of the latent structure model in which we actually have a set of latent connections.",
                    "label": 0
                },
                {
                    "sent": "So the connections between the variables age.",
                    "label": 0
                },
                {
                    "sent": "In this case the people in the scene.",
                    "label": 0
                },
                {
                    "sent": "Those are something that you infer at Test time, so I figure out who should be connected to whom, and this can make you resilient to things like clutter in the form of people who are doing actions unrelated to the underlying activity.",
                    "label": 0
                },
                {
                    "sent": "But it's another form of these labels, except we have a straw.",
                    "label": 0
                }
            ]
        },
        "clip_27": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So we've tested this out on a nursing home data set collected from a real nursing home.",
                    "label": 0
                },
                {
                    "sent": "With, you know, background clutter challenges from the low resolution of the video and etc an.",
                    "label": 0
                }
            ]
        },
        "clip_28": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "You've got quantitative results comparing this to a number of different baselines, so we can just sort of directly apply support vector machines to the individual features.",
                    "label": 0
                },
                {
                    "sent": "We can have a number of different possible graph structures in a regular latent SVM type of model, where we connect up people based upon some distance threshold that we have, or we can do approaches that use dynamically inferring the set of connections that should be in front.",
                    "label": 0
                },
                {
                    "sent": "So latent connection type of model.",
                    "label": 0
                }
            ]
        },
        "clip_29": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Right, and those those outperform.",
                    "label": 0
                },
                {
                    "sent": "So again, some examples of corrective actions.",
                    "label": 0
                },
                {
                    "sent": "We say there's a fall.",
                    "label": 0
                },
                {
                    "sent": "This is a person is following this person sitting down this person standing out and we can infer an individual actions as well as the underlying activity of.",
                    "label": 0
                }
            ]
        },
        "clip_30": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We'll see.",
                    "label": 0
                }
            ]
        },
        "clip_31": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So in conclusion, I've talked about structured models, models with holes versus parts, and given a few different examples of how we can use this for doing activity recognition so semantically meaningful parts such as latent pose estimation for doing still image action recognition, localising actions in videos, telling which frames are part of an action, which sub regions of those frames are part of them as well as a scene structure model on top of that.",
                    "label": 0
                }
            ]
        },
        "clip_32": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So to conclude, by acknowledging these are the students actually did the work that I talked about, particularly young one was involved in all of this work, and thank you very much.",
                    "label": 0
                },
                {
                    "sent": "OK so thanks Greg, any questions?",
                    "label": 0
                },
                {
                    "sent": "From the audience.",
                    "label": 0
                },
                {
                    "sent": "Right?",
                    "label": 0
                },
                {
                    "sent": "The still image action distance from Nazia Kistler so I can give you a pointer to that if you'd like, but it's on her website.",
                    "label": 0
                },
                {
                    "sent": "Yeah, that's from a.",
                    "label": 0
                },
                {
                    "sent": "It's that it comes from videos, but it's per frame recognition, so that's from U Michigan from choices the author name, Troy and Silvio Separase.",
                    "label": 0
                },
                {
                    "sent": "Any other questions?",
                    "label": 0
                },
                {
                    "sent": "A question that I had was so the pose in all those still images was analyzed automatically using existing computer vision software.",
                    "label": 0
                },
                {
                    "sent": "Yes, and so you found that this analysis was correct for most of them know, or so absolutely not.",
                    "label": 0
                },
                {
                    "sent": "So basically where there is doubt that you showed that you manually select cases where the post analysis was correct or is this results on the whole data set.",
                    "label": 0
                },
                {
                    "sent": "Basically where you live and die with whatever the post analysis gives you, right?",
                    "label": 0
                },
                {
                    "sent": "So just to so these.",
                    "label": 0
                },
                {
                    "sent": "His example.",
                    "label": 0
                }
            ]
        },
        "clip_33": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Those were.",
                    "label": 0
                },
                {
                    "sent": "So this is the output of the pose estimator in the sense of what you're doing is finding the most likely pose, so the argmax over the over the pose for the cost label the top row or those pose estimations for when we get the class label correct, and the bottom rows for when you get the cost label wrong, right?",
                    "label": 0
                },
                {
                    "sent": "So it's not a pose estimator for sacas, it's trained to try to do action classification.",
                    "label": 0
                },
                {
                    "sent": "Right there, the learning criterion about action classification, not about pose estimation accuracy, but I would say even if one ran for example, Deva Ramanan pose estimator on images such as this one, the output would be quite strange.",
                    "label": 0
                },
                {
                    "sent": "It wouldn't look anything like this are very unusual pose.",
                    "label": 0
                },
                {
                    "sent": "OK.",
                    "label": 0
                },
                {
                    "sent": "Thanks for your preview.",
                    "label": 0
                },
                {
                    "sent": "Fly severe papers seems interesting, so just one question.",
                    "label": 0
                },
                {
                    "sent": "So it seemed that when you showed the video, the temporal.",
                    "label": 0
                },
                {
                    "sent": "There was not much temporal consistency in your model.",
                    "label": 0
                },
                {
                    "sent": "Is it because you don't impose it, or there's some amount of temporal coherence?",
                    "label": 0
                },
                {
                    "sent": "But for example, in the persons diving undergoing very drastic changes in appearance, so the terms in the the model involve appearance in appearance, similarity from frame to frame.",
                    "label": 0
                },
                {
                    "sent": "So I'm going to say that person is at location Ally in this frame should be at another location next from those appearance of those non box should be similar.",
                    "label": 0
                },
                {
                    "sent": "That's a relatively difficult thing to do when the person is diving like this, so it jitters around, but probably because the person is just changing appearance quite drastically.",
                    "label": 0
                },
                {
                    "sent": "I mean, the guy who's golfing and standing still, it's much more stable around him.",
                    "label": 0
                },
                {
                    "sent": "But yeah, there's a term in the model for that that serve enforces both the spatial position of that bounding box as well as the appearance of it should be similar.",
                    "label": 0
                },
                {
                    "sent": "For the fall detection fall recognition reflection you.",
                    "label": 0
                },
                {
                    "sent": "Started with person locations as your bottom level representation.",
                    "label": 0
                },
                {
                    "sent": "So how did you obtain those right?",
                    "label": 0
                },
                {
                    "sent": "So we how detailed where this for that one.",
                    "label": 0
                },
                {
                    "sent": "We've done a couple of different datasets for the nursing home data set.",
                    "label": 0
                },
                {
                    "sent": "Basically it's background subtraction based.",
                    "label": 0
                },
                {
                    "sent": "The camera is such a strange angle that it's hard to build sort of files, installed detectors or hog detectors on there.",
                    "label": 0
                },
                {
                    "sent": "They don't work quite so well, so those are noisy and erratic, and I think that's another reason why we think there's some benefit to having these latent variables about who's connected to whom.",
                    "label": 0
                },
                {
                    "sent": "If you have a spurious background detection of false positive, one could somewhat ignore those with these latent connections.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "And the other question.",
                    "label": 0
                },
                {
                    "sent": "OK, so let's thank the speaker once again.",
                    "label": 0
                }
            ]
        }
    }
}