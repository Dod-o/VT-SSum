{
    "id": "mmbjjzkzs2ah5u3w6h56vxfaarms5pxo",
    "title": "Dynamics of Conversations",
    "info": {
        "author": [
            "Mary McGlohon, School of Computer Science, Carnegie Mellon University"
        ],
        "published": "Oct. 1, 2010",
        "recorded": "July 2010",
        "category": [
            "Top->Computer Science->Data Mining",
            "Top->Computer Science->Databases"
        ]
    },
    "url": "http://videolectures.net/kdd2010_mcglohon_dc/",
    "segmentation": [
        [
            "Hi, I'm Mary mcglone.",
            "This is work in Columbia.",
            "I'm from Carnegie Mellon.",
            "This is working collaboration with Ravi Kumar and Mohammad Mahdian of Yahoo Research.",
            "And they both send their apologies that they were unable to, unable to make it.",
            "So."
        ],
        [
            "I'm sure I needn't tell anybody in this conference.",
            "Online social networks are becoming a major source of people turned to for information as well as very's very, very interesting resource for us to study.",
            "So our goal in particular is to understand how the dynamics of information disseminate in in into these social networks.",
            "How do?",
            "How do people converse, converse with other people?",
            "And how do they actually obtain the information that they're looking for?",
            "So in particular, we study we study threads that is different.",
            "These different conversations that occur in, say online message boards or Twitter, and we say we we look at what are the properties of these conversations and can we do it?",
            "Can we design A generative models?",
            "Who kind of reproduces properties and help explain what are the what are the exact processes that produce the produce?"
        ],
        [
            "Produce them.",
            "So the way we do this is we analyzed threads in online groups.",
            "We look at Yahoo groups, Usenet, and Twitter.",
            "They're all Yahoo groups in Usenet are essentially online message boards and Twitter is Twitter has it has its own, has its own dynamics, but can basically be thought of as threads in terms of the back and forth conversations that occur.",
            "So the way that we wait, we analyze these as we take each thread.",
            "For instance, you may have like a on the KDD mailing list.",
            "There may be some.",
            "Some conversation about what was the venue for next year.",
            "So somebody may suggest that it have it in Fiji.",
            "Somebody else responds to that and and so that's that's basically one thread.",
            "Is this one conversation subject?",
            "And we can represent this as a sub graft before it where the root of it begins, begins at the top and into other people respond and other people may then respond to those messages.",
            "So these are basically the graphs that were going to be studying in this work as we take each thread and represented as a."
        ],
        [
            "Graph.",
            "So that data that we have come from Yahoo groups where we where they were public groups.",
            "We used moderated groups only to avoid spam and we looked at only groups where a certain number of messages have been posted and this produced 4.9 million messages.",
            "An 1.5 million threads that is 1.5 million of those subgraphs that I just mentioned in the previous slide.",
            "In Usenet we we sent we sampled from 101 hundred groups over over the course of one year and this produced 22,000,000 messages and four million threads.",
            "And Twitter was just used to use the fire hose for one month and had."
        ],
        [
            "And that resulted in 69 million messages and 36 million threads which were extracted by using at replies.",
            "So the first, the first question that we look at is if more reply if if you have a tree like this and more replies are going to occur in the thread, where did they decide to attach?",
            "Do they decide to touch that a root node further down?",
            "And how do they decide?",
            "So we find that the depth of the threads grows sub linearly but super logarithmically in the size of the thread.",
            "So for instance as more nodes are added they don't necessarily attached at the top because that would that would produce.",
            "That would produce lot log rhythmic if you decided to have a complete tree and if it were linear then everybody would be attaching to the bottom.",
            "So it's somewhere in between and we find that there is basically a power law relationship between the size and the average depth of these of these trees.",
            "The second officer."
        ],
        [
            "Has to do with the degree the the degree of nodes within the threads.",
            "So there's a number of responses.",
            "A message gets depends on its depth.",
            "So we find that that yes, it does.",
            "The degrees distribution does change according to the level, so if you took so if the X axis is the degree and the Y axis is the fraction of the fraction of nodes that have that degree, then we find that there are different different distributions depending on how high up in the thread it is.",
            "So roots roots tend to tend to garner more replies as an nodes further."
        ],
        [
            "Content to garner less is which which isn't.",
            "Which isn't that surprising.",
            "The next thing we look at is authorship.",
            "As the threading as a threat increases in size, how many new authors will join?",
            "Do we just do?",
            "Do we just see back and forth between a couple authors in the thread?",
            "Or how quickly do new authors decide to join?",
            "So we find that there is a power love relationship between the size of the thread and the maximum activity from one author and the size of the thread and the number of authors participating.",
            "So by that I mean let.",
            "So that as as as a thread gets bigger there, there will be.",
            "There will be a power law relationship for how much one author will actually interact on that thread that they don't.",
            "They don't simply end up dominating, dominating the entire conversation, and there's also.",
            "There's also power law growth in the site, and the terms of the number of new authors that will actually participate, and these exponents are about .7."
        ],
        [
            "So next we try to try to generate some of these properties and the first thing we thought of just this baseline model was to use a branching process and the way that works is that each node has some K children with some probability distribution P. So we may start with one note at the top and say, well, we're going to decide to have that note.",
            "It has two children.",
            "Next, we may decide that the node the node on the far left will have zero, and the node on the right will have one child, and then we just draw.",
            "Draw this from this power from like a power law distribution to kind of.",
            "To to get the degree distribution that we're looking for.",
            "So this is conceptually simple.",
            "Unfortunately it's not really generative, it won't produce the behave.",
            "The different different behavior by levels.",
            "Every node has the same probability.",
            "And it will also won't have this heavy heavy tail depth distribution that we're looking for, and no and no recency effects either, which is what we often tend to observe.",
            "And in online social networks, is that the most the most recent, the most recent messages tend to have their own have have more more replies as well."
        ],
        [
            "So."
        ],
        [
            "We try to so we try to introduce the this idea of."
        ],
        [
            "Taking into account not only degree but also recency so so we.",
            "In turn, we have the time model and so we say that the thread grows in, grows it in discrete time steps, and each time time tick we may stop the thread.",
            "So for instance, at the top we have this, we have the node at time one, the recent CR is zero and the degree right now at this point is also zero.",
            "So so so another node.",
            "We flip a coin.",
            "That node may decide to attach and it'll attach there, and so that that one's at time two recent C, zero degrees, zero while is the first one is now has recently won.",
            "And so each each time will choose to add it in a different node to two to one of the current nodes based on.",
            "Based on this equation here, the probability of the child is is proportional to a sum of some constant times of degree and and some constant raised to the power of the recency.",
            "And we can fit these.",
            "We can fit fit these parameters using M. So the so the advantages here is that will have both preferential attachment because of the degree and also some recency effects due to due to the fact that we we have some way to test some weight attached to the idea that we were going to try to try to look attached to more recent nodes, which is what tends to happen in the same Twitter.",
            "So notably, using only one of these will lead to either produce bushy or skinny trees, either stars or chain.",
            "So if we had preferential attachment, we would have a lot of a lot of stars, and if we just used recency you would have a lot of."
        ],
        [
            "Chains, but this allows us to produce something in between.",
            "So now are now.",
            "We'd like to do something to try to reproduce the authorship properties, so we so after modeling modeling these threads with the time model, we can assign identity identities to the nodes and we do this using a pulley enlight process.",
            "So at each node we either pick some new author or we pick or pick an author from further up in the chain.",
            "Except except for the parent, because that that would be unrealistic.",
            "Very few people actually respond to their own message.",
            "So the way that would work is for instance we would first assign assign the root node, say the.",
            "Author One which is.",
            "So we represent that is green.",
            "Next week.",
            "OK, next we go down, go down the chain to the to the right.",
            "Then at that time point we choose new author and then then the third, the third node down then that then we.",
            "Then the Poly urn effect becomes.",
            "Then it may either choose a new author or it may choose from further up in the chain.",
            "So in this case it may choose green again.",
            "And so on.",
            "We may choose a new author or that next one could have could have picked the red one as well, or the green.",
            "Or not green and then.",
            "And then on that on the other side, we may choose, we would choose probably a new author from there.",
            "Also, you might note that one drawback of this is that we is that it doesn't.",
            "Is that, for instance, the Red author wouldn't appear on the other branch, and that's so that's something that we're currently working on to try to try to find a way to make make that more realistic, and maybe to maybe use a polar and on different sides of the chain."
        ],
        [
            "So next we did, so we did some simulations and we found that we were able to match pretty closely the size versus depth relationship.",
            "That it would have it would it was.",
            "Super log rhythmic but so."
        ],
        [
            "Growth.",
            "And we were also able to reproduce.",
            "Kind of this by level degree distribution.",
            "Pretty well we that we that is further up in the thread.",
            "They tend to tended to have a.",
            "A longer tail.",
            "And we also reproduced the unique, the unique number of authors power law as well."
        ],
        [
            "So in conclusion, we've examined several several properties of conversations and three large sets of data, and showed that the thread thread, thread structure, and degree of the node are interrelated.",
            "And we also proposed a few models to generate some of these properties.",
            "We took a base, a baseline birth model, and show that some of the properties were unrealistic and then work to improve on it by using a model that used both both recency and preferential attachment.",
            "Any questions?",
            "But the question was whether what sort of differences there were between, say, Twitter data and more.",
            "The message groups Twitter did tend to have more chains because you would just have this to, you know, tend to tend to have more straight straight down the line as opposed to bushier.",
            "Bushier trees because that was a little.",
            "I think, that the recency effects essentially were more.",
            "Not not in this work now, and I can't.",
            "I alright so yeah.",
            "The the question was did we look at any interarrival times but like that is how quickly did people actually respond?",
            "We didn't in this work, but to that tends to have kind of a pretty quick drop off in the you know the path that tends to be a power law that it most of the time you'll get a reply very quickly.",
            "And then after that it drops off.",
            "So the question was whether there is whether we looked at correlations to topic clustering.",
            "So like for instance, what sort do certain topics tend to have certain kinds of threads?",
            "We we didn't.",
            "We didn't look at that yet, but that's that's a good idea.",
            "Thank you."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Hi, I'm Mary mcglone.",
                    "label": 0
                },
                {
                    "sent": "This is work in Columbia.",
                    "label": 0
                },
                {
                    "sent": "I'm from Carnegie Mellon.",
                    "label": 0
                },
                {
                    "sent": "This is working collaboration with Ravi Kumar and Mohammad Mahdian of Yahoo Research.",
                    "label": 1
                },
                {
                    "sent": "And they both send their apologies that they were unable to, unable to make it.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "I'm sure I needn't tell anybody in this conference.",
                    "label": 0
                },
                {
                    "sent": "Online social networks are becoming a major source of people turned to for information as well as very's very, very interesting resource for us to study.",
                    "label": 1
                },
                {
                    "sent": "So our goal in particular is to understand how the dynamics of information disseminate in in into these social networks.",
                    "label": 0
                },
                {
                    "sent": "How do?",
                    "label": 0
                },
                {
                    "sent": "How do people converse, converse with other people?",
                    "label": 0
                },
                {
                    "sent": "And how do they actually obtain the information that they're looking for?",
                    "label": 0
                },
                {
                    "sent": "So in particular, we study we study threads that is different.",
                    "label": 1
                },
                {
                    "sent": "These different conversations that occur in, say online message boards or Twitter, and we say we we look at what are the properties of these conversations and can we do it?",
                    "label": 0
                },
                {
                    "sent": "Can we design A generative models?",
                    "label": 0
                },
                {
                    "sent": "Who kind of reproduces properties and help explain what are the what are the exact processes that produce the produce?",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Produce them.",
                    "label": 0
                },
                {
                    "sent": "So the way we do this is we analyzed threads in online groups.",
                    "label": 0
                },
                {
                    "sent": "We look at Yahoo groups, Usenet, and Twitter.",
                    "label": 1
                },
                {
                    "sent": "They're all Yahoo groups in Usenet are essentially online message boards and Twitter is Twitter has it has its own, has its own dynamics, but can basically be thought of as threads in terms of the back and forth conversations that occur.",
                    "label": 0
                },
                {
                    "sent": "So the way that we wait, we analyze these as we take each thread.",
                    "label": 0
                },
                {
                    "sent": "For instance, you may have like a on the KDD mailing list.",
                    "label": 0
                },
                {
                    "sent": "There may be some.",
                    "label": 0
                },
                {
                    "sent": "Some conversation about what was the venue for next year.",
                    "label": 0
                },
                {
                    "sent": "So somebody may suggest that it have it in Fiji.",
                    "label": 0
                },
                {
                    "sent": "Somebody else responds to that and and so that's that's basically one thread.",
                    "label": 0
                },
                {
                    "sent": "Is this one conversation subject?",
                    "label": 0
                },
                {
                    "sent": "And we can represent this as a sub graft before it where the root of it begins, begins at the top and into other people respond and other people may then respond to those messages.",
                    "label": 0
                },
                {
                    "sent": "So these are basically the graphs that were going to be studying in this work as we take each thread and represented as a.",
                    "label": 0
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Graph.",
                    "label": 0
                },
                {
                    "sent": "So that data that we have come from Yahoo groups where we where they were public groups.",
                    "label": 1
                },
                {
                    "sent": "We used moderated groups only to avoid spam and we looked at only groups where a certain number of messages have been posted and this produced 4.9 million messages.",
                    "label": 0
                },
                {
                    "sent": "An 1.5 million threads that is 1.5 million of those subgraphs that I just mentioned in the previous slide.",
                    "label": 0
                },
                {
                    "sent": "In Usenet we we sent we sampled from 101 hundred groups over over the course of one year and this produced 22,000,000 messages and four million threads.",
                    "label": 0
                },
                {
                    "sent": "And Twitter was just used to use the fire hose for one month and had.",
                    "label": 1
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "And that resulted in 69 million messages and 36 million threads which were extracted by using at replies.",
                    "label": 0
                },
                {
                    "sent": "So the first, the first question that we look at is if more reply if if you have a tree like this and more replies are going to occur in the thread, where did they decide to attach?",
                    "label": 0
                },
                {
                    "sent": "Do they decide to touch that a root node further down?",
                    "label": 0
                },
                {
                    "sent": "And how do they decide?",
                    "label": 0
                },
                {
                    "sent": "So we find that the depth of the threads grows sub linearly but super logarithmically in the size of the thread.",
                    "label": 1
                },
                {
                    "sent": "So for instance as more nodes are added they don't necessarily attached at the top because that would that would produce.",
                    "label": 0
                },
                {
                    "sent": "That would produce lot log rhythmic if you decided to have a complete tree and if it were linear then everybody would be attaching to the bottom.",
                    "label": 0
                },
                {
                    "sent": "So it's somewhere in between and we find that there is basically a power law relationship between the size and the average depth of these of these trees.",
                    "label": 0
                },
                {
                    "sent": "The second officer.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Has to do with the degree the the degree of nodes within the threads.",
                    "label": 1
                },
                {
                    "sent": "So there's a number of responses.",
                    "label": 1
                },
                {
                    "sent": "A message gets depends on its depth.",
                    "label": 1
                },
                {
                    "sent": "So we find that that yes, it does.",
                    "label": 0
                },
                {
                    "sent": "The degrees distribution does change according to the level, so if you took so if the X axis is the degree and the Y axis is the fraction of the fraction of nodes that have that degree, then we find that there are different different distributions depending on how high up in the thread it is.",
                    "label": 0
                },
                {
                    "sent": "So roots roots tend to tend to garner more replies as an nodes further.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Content to garner less is which which isn't.",
                    "label": 0
                },
                {
                    "sent": "Which isn't that surprising.",
                    "label": 0
                },
                {
                    "sent": "The next thing we look at is authorship.",
                    "label": 0
                },
                {
                    "sent": "As the threading as a threat increases in size, how many new authors will join?",
                    "label": 1
                },
                {
                    "sent": "Do we just do?",
                    "label": 0
                },
                {
                    "sent": "Do we just see back and forth between a couple authors in the thread?",
                    "label": 0
                },
                {
                    "sent": "Or how quickly do new authors decide to join?",
                    "label": 0
                },
                {
                    "sent": "So we find that there is a power love relationship between the size of the thread and the maximum activity from one author and the size of the thread and the number of authors participating.",
                    "label": 1
                },
                {
                    "sent": "So by that I mean let.",
                    "label": 0
                },
                {
                    "sent": "So that as as as a thread gets bigger there, there will be.",
                    "label": 0
                },
                {
                    "sent": "There will be a power law relationship for how much one author will actually interact on that thread that they don't.",
                    "label": 0
                },
                {
                    "sent": "They don't simply end up dominating, dominating the entire conversation, and there's also.",
                    "label": 0
                },
                {
                    "sent": "There's also power law growth in the site, and the terms of the number of new authors that will actually participate, and these exponents are about .7.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So next we try to try to generate some of these properties and the first thing we thought of just this baseline model was to use a branching process and the way that works is that each node has some K children with some probability distribution P. So we may start with one note at the top and say, well, we're going to decide to have that note.",
                    "label": 1
                },
                {
                    "sent": "It has two children.",
                    "label": 0
                },
                {
                    "sent": "Next, we may decide that the node the node on the far left will have zero, and the node on the right will have one child, and then we just draw.",
                    "label": 0
                },
                {
                    "sent": "Draw this from this power from like a power law distribution to kind of.",
                    "label": 0
                },
                {
                    "sent": "To to get the degree distribution that we're looking for.",
                    "label": 0
                },
                {
                    "sent": "So this is conceptually simple.",
                    "label": 0
                },
                {
                    "sent": "Unfortunately it's not really generative, it won't produce the behave.",
                    "label": 0
                },
                {
                    "sent": "The different different behavior by levels.",
                    "label": 0
                },
                {
                    "sent": "Every node has the same probability.",
                    "label": 0
                },
                {
                    "sent": "And it will also won't have this heavy heavy tail depth distribution that we're looking for, and no and no recency effects either, which is what we often tend to observe.",
                    "label": 0
                },
                {
                    "sent": "And in online social networks, is that the most the most recent, the most recent messages tend to have their own have have more more replies as well.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "We try to so we try to introduce the this idea of.",
                    "label": 0
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Taking into account not only degree but also recency so so we.",
                    "label": 0
                },
                {
                    "sent": "In turn, we have the time model and so we say that the thread grows in, grows it in discrete time steps, and each time time tick we may stop the thread.",
                    "label": 1
                },
                {
                    "sent": "So for instance, at the top we have this, we have the node at time one, the recent CR is zero and the degree right now at this point is also zero.",
                    "label": 0
                },
                {
                    "sent": "So so so another node.",
                    "label": 0
                },
                {
                    "sent": "We flip a coin.",
                    "label": 0
                },
                {
                    "sent": "That node may decide to attach and it'll attach there, and so that that one's at time two recent C, zero degrees, zero while is the first one is now has recently won.",
                    "label": 0
                },
                {
                    "sent": "And so each each time will choose to add it in a different node to two to one of the current nodes based on.",
                    "label": 0
                },
                {
                    "sent": "Based on this equation here, the probability of the child is is proportional to a sum of some constant times of degree and and some constant raised to the power of the recency.",
                    "label": 0
                },
                {
                    "sent": "And we can fit these.",
                    "label": 0
                },
                {
                    "sent": "We can fit fit these parameters using M. So the so the advantages here is that will have both preferential attachment because of the degree and also some recency effects due to due to the fact that we we have some way to test some weight attached to the idea that we were going to try to try to look attached to more recent nodes, which is what tends to happen in the same Twitter.",
                    "label": 1
                },
                {
                    "sent": "So notably, using only one of these will lead to either produce bushy or skinny trees, either stars or chain.",
                    "label": 0
                },
                {
                    "sent": "So if we had preferential attachment, we would have a lot of a lot of stars, and if we just used recency you would have a lot of.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Chains, but this allows us to produce something in between.",
                    "label": 0
                },
                {
                    "sent": "So now are now.",
                    "label": 0
                },
                {
                    "sent": "We'd like to do something to try to reproduce the authorship properties, so we so after modeling modeling these threads with the time model, we can assign identity identities to the nodes and we do this using a pulley enlight process.",
                    "label": 0
                },
                {
                    "sent": "So at each node we either pick some new author or we pick or pick an author from further up in the chain.",
                    "label": 1
                },
                {
                    "sent": "Except except for the parent, because that that would be unrealistic.",
                    "label": 0
                },
                {
                    "sent": "Very few people actually respond to their own message.",
                    "label": 0
                },
                {
                    "sent": "So the way that would work is for instance we would first assign assign the root node, say the.",
                    "label": 0
                },
                {
                    "sent": "Author One which is.",
                    "label": 0
                },
                {
                    "sent": "So we represent that is green.",
                    "label": 0
                },
                {
                    "sent": "Next week.",
                    "label": 0
                },
                {
                    "sent": "OK, next we go down, go down the chain to the to the right.",
                    "label": 0
                },
                {
                    "sent": "Then at that time point we choose new author and then then the third, the third node down then that then we.",
                    "label": 0
                },
                {
                    "sent": "Then the Poly urn effect becomes.",
                    "label": 0
                },
                {
                    "sent": "Then it may either choose a new author or it may choose from further up in the chain.",
                    "label": 0
                },
                {
                    "sent": "So in this case it may choose green again.",
                    "label": 0
                },
                {
                    "sent": "And so on.",
                    "label": 0
                },
                {
                    "sent": "We may choose a new author or that next one could have could have picked the red one as well, or the green.",
                    "label": 0
                },
                {
                    "sent": "Or not green and then.",
                    "label": 0
                },
                {
                    "sent": "And then on that on the other side, we may choose, we would choose probably a new author from there.",
                    "label": 0
                },
                {
                    "sent": "Also, you might note that one drawback of this is that we is that it doesn't.",
                    "label": 0
                },
                {
                    "sent": "Is that, for instance, the Red author wouldn't appear on the other branch, and that's so that's something that we're currently working on to try to try to find a way to make make that more realistic, and maybe to maybe use a polar and on different sides of the chain.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So next we did, so we did some simulations and we found that we were able to match pretty closely the size versus depth relationship.",
                    "label": 0
                },
                {
                    "sent": "That it would have it would it was.",
                    "label": 0
                },
                {
                    "sent": "Super log rhythmic but so.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Growth.",
                    "label": 0
                },
                {
                    "sent": "And we were also able to reproduce.",
                    "label": 0
                },
                {
                    "sent": "Kind of this by level degree distribution.",
                    "label": 0
                },
                {
                    "sent": "Pretty well we that we that is further up in the thread.",
                    "label": 0
                },
                {
                    "sent": "They tend to tended to have a.",
                    "label": 0
                },
                {
                    "sent": "A longer tail.",
                    "label": 0
                },
                {
                    "sent": "And we also reproduced the unique, the unique number of authors power law as well.",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So in conclusion, we've examined several several properties of conversations and three large sets of data, and showed that the thread thread, thread structure, and degree of the node are interrelated.",
                    "label": 1
                },
                {
                    "sent": "And we also proposed a few models to generate some of these properties.",
                    "label": 0
                },
                {
                    "sent": "We took a base, a baseline birth model, and show that some of the properties were unrealistic and then work to improve on it by using a model that used both both recency and preferential attachment.",
                    "label": 0
                },
                {
                    "sent": "Any questions?",
                    "label": 0
                },
                {
                    "sent": "But the question was whether what sort of differences there were between, say, Twitter data and more.",
                    "label": 0
                },
                {
                    "sent": "The message groups Twitter did tend to have more chains because you would just have this to, you know, tend to tend to have more straight straight down the line as opposed to bushier.",
                    "label": 0
                },
                {
                    "sent": "Bushier trees because that was a little.",
                    "label": 0
                },
                {
                    "sent": "I think, that the recency effects essentially were more.",
                    "label": 0
                },
                {
                    "sent": "Not not in this work now, and I can't.",
                    "label": 0
                },
                {
                    "sent": "I alright so yeah.",
                    "label": 0
                },
                {
                    "sent": "The the question was did we look at any interarrival times but like that is how quickly did people actually respond?",
                    "label": 0
                },
                {
                    "sent": "We didn't in this work, but to that tends to have kind of a pretty quick drop off in the you know the path that tends to be a power law that it most of the time you'll get a reply very quickly.",
                    "label": 0
                },
                {
                    "sent": "And then after that it drops off.",
                    "label": 0
                },
                {
                    "sent": "So the question was whether there is whether we looked at correlations to topic clustering.",
                    "label": 0
                },
                {
                    "sent": "So like for instance, what sort do certain topics tend to have certain kinds of threads?",
                    "label": 0
                },
                {
                    "sent": "We we didn't.",
                    "label": 0
                },
                {
                    "sent": "We didn't look at that yet, but that's that's a good idea.",
                    "label": 0
                },
                {
                    "sent": "Thank you.",
                    "label": 0
                }
            ]
        }
    }
}