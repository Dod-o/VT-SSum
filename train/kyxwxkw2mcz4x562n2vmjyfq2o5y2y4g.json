{
    "id": "kyxwxkw2mcz4x562n2vmjyfq2o5y2y4g",
    "title": "Ancestor Relations in the Presence of Unobserved Variables",
    "info": {
        "author": [
            "Pekka Parviainen, Department of Computer Science, University of Helsinki"
        ],
        "published": "Oct. 3, 2011",
        "recorded": "September 2011",
        "category": [
            "Top->Computer Science->Machine Learning->Bayesian Learning"
        ]
    },
    "url": "http://videolectures.net/ecmlpkdd2011_parviainen_ancestor/",
    "segmentation": [
        [
            "OK, so I'm back up again.",
            "I'm talking about OnStar relations in the presence of observed variables.",
            "This is joint work with Nico."
        ],
        [
            "Vista so first I'm going to give some background information and then tell what honest relations are and why they are interesting.",
            "Then I will explain how understory lessons.",
            "Are learned and then I.",
            "Finish this presentation with some.",
            "Experimental results."
        ],
        [
            "So Bayesian installations are structural features in Bayesian networks, so I'll start.",
            "Bye.",
            "Talking about Bayesian network, so some of you may be familiar with this, because this first pass part is overlapping with yesterday's tutorial.",
            "But OK, so Bayesian networks are representations of joint probability distributions and they consist of two parts.",
            "First structure of a Bayesian network is a directed acyclic graph or deck for short, and it represents the conditional in dependencies between variables.",
            "And then at the second part of the base in network are the local conditional probability distributions, which are specified by some Param."
        ],
        [
            "Interest.",
            "So Bayesian network are attractive models for various reasons.",
            "For example, they are compact, meaning that often one can represent this joint distribution with moderate number of parameters.",
            "They are flexible, you can.",
            "Answer Any probabilistic query using Bayesian networks and then they are interpretable, especially if you.",
            "I've discussed this course or interpretation that arcs.",
            "In that network structure represent direct cause effect pairs, so parent is a.",
            "A course of it child."
        ],
        [
            "So how do we get these Bayesian networks so of course.",
            "We have some we want to model some.",
            "Some phenomenon we could task, for example, expert to construct their network, but that's often not.",
            "Possible, however we might have.",
            "Some observational data.",
            "From those variables, and thus we can construct a best click best fit doc from the observation date.",
            "This task is however challenging.",
            "First of all, the set of conditional independence ease among those variables can often be represented by a number of different attacks.",
            "This decks form a so-called mark of equivalence class.",
            "Then often in practice there are some unobserved variables that affect the ones that we have observed.",
            "And finally, this structure discovery is a difficult problem.",
            "It's NP hard."
        ],
        [
            "So basically there are two approaches in learning structure of Bayesian network.",
            "1st is the constraint based approach is based on testing conditional independence between variables.",
            "And then the second is corpus approach, which is the approach that we take.",
            "It's one assigns each stack score based on how well it fits to the data.",
            "And then one tries to find a deck that maximizes the score.",
            "So this both approaches have some good sites and path sites.",
            "Scorpions approach, for example, enables incorporating prior information.",
            "However, when we compare score based approach to constraint based approach.",
            "In this corpus approach is very hard to handle unobserved variables so often just ignores them assumes that no such thing exists."
        ],
        [
            "Their learning just one best fit dark.",
            "There are some kind of concerns.",
            "There may be several almost equally good decks or equal liquid mark over like classes, and especially if you have lots of nodes, then the best feedback is probably very unlikely.",
            "And therefore.",
            "Wanna kind of instead of learning one doc, one report, some summaries like.",
            "Posterior probabilities of some structural features, for example.",
            "Structure posterior probability of some arc.",
            "So here's the approach is such that we can compute posterior probability for each deck.",
            "And then when we are interested in, for example, in some arc, we some.",
            "Most of the probabilities of all decks that have that particular.",
            "Ark.",
            "And then we get the.",
            "Posterior probability of that arc.",
            "So this approach is called basin averaging, and here we call actually full Bayesian averaging us.",
            "We will later encounter Parcel based in average."
        ],
        [
            "OK, so now we are ready to go to the ancestor relations.",
            "So UN sister relations are one possible structural feature.",
            "That one again learn so.",
            "So basically we have a network and node.",
            "This is a an ancestor of no.",
            "T if there is a directed path from SG.",
            "So this kind of answers to realize is kind of fundamentally different compared to, for example, arcs.",
            "Kind of existence of some Ark is local property.",
            "You just have to check node and one node and see if one of its parents is.",
            "Is the one that you're looking for, but here you have to consider whole.",
            "Holodeck."
        ],
        [
            "So why ancestor relations are are interesting, well, in field.",
            "Or interesting interested in causal relations among the variables when we have, for example, arcs, they describe the.",
            "The direct coastal relationship, however, here.",
            "UN sister relations give also information about.",
            "UN direct indirect.",
            "Causes so the questions that we are trying to answer is, first of all that can we.",
            "Learn ancestor relations, incompetent, efficient manner.",
            "We of course know that we can learn them in some manner because we can.",
            "Always.",
            "Some overall decks there are super exponents in many decks, but that's theory impossible.",
            "Possible.",
            "Then another question is that when we learn answers to realize God, we learn them reliably.",
            "Even if there are some unabsorbed nodes at work.",
            "And then another question is that.",
            "That, are they any good kind of that we know how to.",
            "To learn properties arcs quite efficiently, so does this kind of new approach.",
            "Give anything more."
        ],
        [
            "Learn that.",
            "So first I'm going to explain shortly the outline of the algorithm.",
            "How do we learn that?",
            "No sister relations.",
            "So we take this full Bayesian averaging approach and we have exact algorithm which is based on dynamic."
        ],
        [
            "Programming.",
            "So, so we make a couple of assumptions.",
            "First, is this standard assumption that the likelihood of a deck factorizes?",
            "Two local terms.",
            "Then another assumption that they is not kind of standard.",
            "But this year, for computational convenience, is that the prior for a deck is order modular.",
            "This is in.",
            "Intuitively, this means that the.",
            "Probability of prior probability of a deck is.",
            "Proportional to the number of topological orderings."
        ],
        [
            "So.",
            "But basically what we do.",
            "It is that we compete.",
            "The joint.",
            "So joint probability of transistor lessons in data, using recursing.",
            "So we have this kind of function G. Where which?",
            "It's runs.",
            "Through all nodes, it's capital S and all subsets of S is capital T and this is the contribution of all decks or nodes at South.",
            "That have a direct path from the nodes small S to every.",
            "Node in that capital T and to no other node.",
            "So basically we partition.",
            "The decks on that note said Capital S. Based on.",
            "The witch.",
            "Notes are descendants of our source node SM S."
        ],
        [
            "So then the question is, how do we compute the G function?",
            "We have this kind of nice looking formula, But basically what we just do that we have completed everything.",
            "For smaller sets and.",
            "Then we just.",
            "Just consider all ways to add one more node.",
            "To the network.",
            "And they are this.",
            "Only thing that we need to accomplish this better thing which is basically sum over or possible parents.",
            "It's that we can choose here."
        ],
        [
            "So basically there are two cases.",
            "If we are adding a node.",
            "V to the network.",
            "Then we have to consider 2 cases.",
            "First, here at the left.",
            "The node B is inset capital T, which means that there the we're summing over decks that.",
            "Include a directed path from a small SV so therefore.",
            "We can consider only.",
            "The current sets that contain at least one node.",
            "From that T. Capital T and then Turner case at the right is when the new node V is not in that set capital T. Which means that it is not allowed to have a parent in that capital T. Big cause.",
            "If it had, then there would be a direct path to.",
            "Lee"
        ],
        [
            "That was kind of brief outline of the algorithm.",
            "Here if we ignore the polynomial factors, we get time and space requirement.",
            "Treat the N where N is the number of variables.",
            "So.",
            "When we.",
            "Asked this kind of learned learners, for instance, efficiently.",
            "I guess it depends on the definition of FFCNZ.",
            "The brute force approach would have been super exponential, so this is way better than that, but.",
            "Quite limiting though.",
            "So maximum 20 hours or so."
        ],
        [
            "OK, so then a few words about.",
            "The experimental results.",
            "We did some simulations.",
            "About the power of the learning ancestor relations, here are some Roc curves for learning and sister relations and directed arcs.",
            "With varying.",
            "A number of UN observed variables.",
            "So the power of course goes down when we have more upset variables.",
            "However, even when there are.",
            "For example.",
            "Here we have.",
            "For only four out of 14 nodes from our original network observed, we still have kind of reasonable.",
            "Power."
        ],
        [
            "OK, then another question was that.",
            "What about?",
            "Learning arc, so can we do?",
            "As well.",
            "Learning arcs as well as learning understory isn't directly.",
            "So basically.",
            "Here we have compared first this full Bayesian averaging.",
            "Which basically.",
            "Is that we first compute?",
            "The poster probabilities for ancestor relations and then set a treshold and claim that all understood relations that has posted properly larger than this.",
            "R. Present.",
            "And then this parcel payers in averaging approach is that we learned our probabilities.",
            "Then construct an index based on our probabilities and then.",
            "Then they do studies the relations from the decks.",
            "So basically here are some.",
            "Subset of results.",
            "So basically here are.",
            "Here.",
            "The leftmost and rightmost columns are kind of.",
            "Average number of.",
            "Guess this when the both methods Acree.",
            "So in the middle columns there are times when.",
            "They disagree, so they accurate almost.",
            "Every time, especially with lots of data, and when you analyze.",
            "The cases when.",
            "They disagreed, it turns out the full players in averaging performs only slightly better."
        ],
        [
            "So as a conclusion.",
            "We have shown that.",
            "The ancestor relation is going to be learned in computational fees in manner.",
            "If we have moderate number of nodes.",
            "And they can be learned.",
            "With reasonable power, even in the presence of an observed variables, however, we can do almost equal equity if we use this parcel based in average."
        ],
        [
            "Thank you.",
            "Let's thank the speaker and we have time for a couple of questions perhaps.",
            "OK, then I have a question.",
            "I haven't fully understood how you handle unobserved variables.",
            "It seems to me that.",
            "Since you cannot score mugs, but you're scoring Bayesian networks.",
            "And you have unobservables.",
            "Your method, even with infinite sample size, when you have unobservables, may not give you.",
            "Correct results, yes, so here the.",
            "The kind of reliability aspect was that we have misspecified model, so we assume that.",
            "That we don't have an object variables and then we.",
            "Have actually situation where we actually have an observed variables and then we try to figure out that OK, how well we actually do.",
            "If our assumption.",
            "Isn't in agreement with the reality."
        ]
    ],
    "summarization": {
        "clip_0": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so I'm back up again.",
                    "label": 0
                },
                {
                    "sent": "I'm talking about OnStar relations in the presence of observed variables.",
                    "label": 1
                },
                {
                    "sent": "This is joint work with Nico.",
                    "label": 0
                }
            ]
        },
        "clip_1": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Vista so first I'm going to give some background information and then tell what honest relations are and why they are interesting.",
                    "label": 0
                },
                {
                    "sent": "Then I will explain how understory lessons.",
                    "label": 0
                },
                {
                    "sent": "Are learned and then I.",
                    "label": 0
                },
                {
                    "sent": "Finish this presentation with some.",
                    "label": 0
                },
                {
                    "sent": "Experimental results.",
                    "label": 0
                }
            ]
        },
        "clip_2": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So Bayesian installations are structural features in Bayesian networks, so I'll start.",
                    "label": 0
                },
                {
                    "sent": "Bye.",
                    "label": 0
                },
                {
                    "sent": "Talking about Bayesian network, so some of you may be familiar with this, because this first pass part is overlapping with yesterday's tutorial.",
                    "label": 0
                },
                {
                    "sent": "But OK, so Bayesian networks are representations of joint probability distributions and they consist of two parts.",
                    "label": 1
                },
                {
                    "sent": "First structure of a Bayesian network is a directed acyclic graph or deck for short, and it represents the conditional in dependencies between variables.",
                    "label": 0
                },
                {
                    "sent": "And then at the second part of the base in network are the local conditional probability distributions, which are specified by some Param.",
                    "label": 1
                }
            ]
        },
        "clip_3": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Interest.",
                    "label": 0
                },
                {
                    "sent": "So Bayesian network are attractive models for various reasons.",
                    "label": 0
                },
                {
                    "sent": "For example, they are compact, meaning that often one can represent this joint distribution with moderate number of parameters.",
                    "label": 0
                },
                {
                    "sent": "They are flexible, you can.",
                    "label": 0
                },
                {
                    "sent": "Answer Any probabilistic query using Bayesian networks and then they are interpretable, especially if you.",
                    "label": 1
                },
                {
                    "sent": "I've discussed this course or interpretation that arcs.",
                    "label": 0
                },
                {
                    "sent": "In that network structure represent direct cause effect pairs, so parent is a.",
                    "label": 0
                },
                {
                    "sent": "A course of it child.",
                    "label": 0
                }
            ]
        },
        "clip_4": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So how do we get these Bayesian networks so of course.",
                    "label": 0
                },
                {
                    "sent": "We have some we want to model some.",
                    "label": 0
                },
                {
                    "sent": "Some phenomenon we could task, for example, expert to construct their network, but that's often not.",
                    "label": 0
                },
                {
                    "sent": "Possible, however we might have.",
                    "label": 0
                },
                {
                    "sent": "Some observational data.",
                    "label": 0
                },
                {
                    "sent": "From those variables, and thus we can construct a best click best fit doc from the observation date.",
                    "label": 0
                },
                {
                    "sent": "This task is however challenging.",
                    "label": 0
                },
                {
                    "sent": "First of all, the set of conditional independence ease among those variables can often be represented by a number of different attacks.",
                    "label": 1
                },
                {
                    "sent": "This decks form a so-called mark of equivalence class.",
                    "label": 0
                },
                {
                    "sent": "Then often in practice there are some unobserved variables that affect the ones that we have observed.",
                    "label": 0
                },
                {
                    "sent": "And finally, this structure discovery is a difficult problem.",
                    "label": 0
                },
                {
                    "sent": "It's NP hard.",
                    "label": 0
                }
            ]
        },
        "clip_5": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So basically there are two approaches in learning structure of Bayesian network.",
                    "label": 0
                },
                {
                    "sent": "1st is the constraint based approach is based on testing conditional independence between variables.",
                    "label": 0
                },
                {
                    "sent": "And then the second is corpus approach, which is the approach that we take.",
                    "label": 0
                },
                {
                    "sent": "It's one assigns each stack score based on how well it fits to the data.",
                    "label": 1
                },
                {
                    "sent": "And then one tries to find a deck that maximizes the score.",
                    "label": 0
                },
                {
                    "sent": "So this both approaches have some good sites and path sites.",
                    "label": 1
                },
                {
                    "sent": "Scorpions approach, for example, enables incorporating prior information.",
                    "label": 1
                },
                {
                    "sent": "However, when we compare score based approach to constraint based approach.",
                    "label": 0
                },
                {
                    "sent": "In this corpus approach is very hard to handle unobserved variables so often just ignores them assumes that no such thing exists.",
                    "label": 0
                }
            ]
        },
        "clip_6": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Their learning just one best fit dark.",
                    "label": 0
                },
                {
                    "sent": "There are some kind of concerns.",
                    "label": 0
                },
                {
                    "sent": "There may be several almost equally good decks or equal liquid mark over like classes, and especially if you have lots of nodes, then the best feedback is probably very unlikely.",
                    "label": 1
                },
                {
                    "sent": "And therefore.",
                    "label": 0
                },
                {
                    "sent": "Wanna kind of instead of learning one doc, one report, some summaries like.",
                    "label": 1
                },
                {
                    "sent": "Posterior probabilities of some structural features, for example.",
                    "label": 0
                },
                {
                    "sent": "Structure posterior probability of some arc.",
                    "label": 0
                },
                {
                    "sent": "So here's the approach is such that we can compute posterior probability for each deck.",
                    "label": 1
                },
                {
                    "sent": "And then when we are interested in, for example, in some arc, we some.",
                    "label": 0
                },
                {
                    "sent": "Most of the probabilities of all decks that have that particular.",
                    "label": 1
                },
                {
                    "sent": "Ark.",
                    "label": 0
                },
                {
                    "sent": "And then we get the.",
                    "label": 0
                },
                {
                    "sent": "Posterior probability of that arc.",
                    "label": 0
                },
                {
                    "sent": "So this approach is called basin averaging, and here we call actually full Bayesian averaging us.",
                    "label": 0
                },
                {
                    "sent": "We will later encounter Parcel based in average.",
                    "label": 0
                }
            ]
        },
        "clip_7": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "OK, so now we are ready to go to the ancestor relations.",
                    "label": 0
                },
                {
                    "sent": "So UN sister relations are one possible structural feature.",
                    "label": 0
                },
                {
                    "sent": "That one again learn so.",
                    "label": 0
                },
                {
                    "sent": "So basically we have a network and node.",
                    "label": 0
                },
                {
                    "sent": "This is a an ancestor of no.",
                    "label": 0
                },
                {
                    "sent": "T if there is a directed path from SG.",
                    "label": 1
                },
                {
                    "sent": "So this kind of answers to realize is kind of fundamentally different compared to, for example, arcs.",
                    "label": 0
                },
                {
                    "sent": "Kind of existence of some Ark is local property.",
                    "label": 0
                },
                {
                    "sent": "You just have to check node and one node and see if one of its parents is.",
                    "label": 0
                },
                {
                    "sent": "Is the one that you're looking for, but here you have to consider whole.",
                    "label": 0
                },
                {
                    "sent": "Holodeck.",
                    "label": 0
                }
            ]
        },
        "clip_8": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So why ancestor relations are are interesting, well, in field.",
                    "label": 0
                },
                {
                    "sent": "Or interesting interested in causal relations among the variables when we have, for example, arcs, they describe the.",
                    "label": 0
                },
                {
                    "sent": "The direct coastal relationship, however, here.",
                    "label": 0
                },
                {
                    "sent": "UN sister relations give also information about.",
                    "label": 0
                },
                {
                    "sent": "UN direct indirect.",
                    "label": 0
                },
                {
                    "sent": "Causes so the questions that we are trying to answer is, first of all that can we.",
                    "label": 0
                },
                {
                    "sent": "Learn ancestor relations, incompetent, efficient manner.",
                    "label": 1
                },
                {
                    "sent": "We of course know that we can learn them in some manner because we can.",
                    "label": 0
                },
                {
                    "sent": "Always.",
                    "label": 0
                },
                {
                    "sent": "Some overall decks there are super exponents in many decks, but that's theory impossible.",
                    "label": 0
                },
                {
                    "sent": "Possible.",
                    "label": 0
                },
                {
                    "sent": "Then another question is that when we learn answers to realize God, we learn them reliably.",
                    "label": 0
                },
                {
                    "sent": "Even if there are some unabsorbed nodes at work.",
                    "label": 1
                },
                {
                    "sent": "And then another question is that.",
                    "label": 0
                },
                {
                    "sent": "That, are they any good kind of that we know how to.",
                    "label": 0
                },
                {
                    "sent": "To learn properties arcs quite efficiently, so does this kind of new approach.",
                    "label": 0
                },
                {
                    "sent": "Give anything more.",
                    "label": 0
                }
            ]
        },
        "clip_9": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Learn that.",
                    "label": 0
                },
                {
                    "sent": "So first I'm going to explain shortly the outline of the algorithm.",
                    "label": 0
                },
                {
                    "sent": "How do we learn that?",
                    "label": 0
                },
                {
                    "sent": "No sister relations.",
                    "label": 0
                },
                {
                    "sent": "So we take this full Bayesian averaging approach and we have exact algorithm which is based on dynamic.",
                    "label": 1
                }
            ]
        },
        "clip_10": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "Programming.",
                    "label": 0
                },
                {
                    "sent": "So, so we make a couple of assumptions.",
                    "label": 0
                },
                {
                    "sent": "First, is this standard assumption that the likelihood of a deck factorizes?",
                    "label": 0
                },
                {
                    "sent": "Two local terms.",
                    "label": 0
                },
                {
                    "sent": "Then another assumption that they is not kind of standard.",
                    "label": 0
                },
                {
                    "sent": "But this year, for computational convenience, is that the prior for a deck is order modular.",
                    "label": 0
                },
                {
                    "sent": "This is in.",
                    "label": 0
                },
                {
                    "sent": "Intuitively, this means that the.",
                    "label": 0
                },
                {
                    "sent": "Probability of prior probability of a deck is.",
                    "label": 0
                },
                {
                    "sent": "Proportional to the number of topological orderings.",
                    "label": 0
                }
            ]
        },
        "clip_11": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "But basically what we do.",
                    "label": 0
                },
                {
                    "sent": "It is that we compete.",
                    "label": 0
                },
                {
                    "sent": "The joint.",
                    "label": 0
                },
                {
                    "sent": "So joint probability of transistor lessons in data, using recursing.",
                    "label": 0
                },
                {
                    "sent": "So we have this kind of function G. Where which?",
                    "label": 0
                },
                {
                    "sent": "It's runs.",
                    "label": 0
                },
                {
                    "sent": "Through all nodes, it's capital S and all subsets of S is capital T and this is the contribution of all decks or nodes at South.",
                    "label": 0
                },
                {
                    "sent": "That have a direct path from the nodes small S to every.",
                    "label": 1
                },
                {
                    "sent": "Node in that capital T and to no other node.",
                    "label": 0
                },
                {
                    "sent": "So basically we partition.",
                    "label": 0
                },
                {
                    "sent": "The decks on that note said Capital S. Based on.",
                    "label": 0
                },
                {
                    "sent": "The witch.",
                    "label": 0
                },
                {
                    "sent": "Notes are descendants of our source node SM S.",
                    "label": 0
                }
            ]
        },
        "clip_12": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So then the question is, how do we compute the G function?",
                    "label": 0
                },
                {
                    "sent": "We have this kind of nice looking formula, But basically what we just do that we have completed everything.",
                    "label": 0
                },
                {
                    "sent": "For smaller sets and.",
                    "label": 0
                },
                {
                    "sent": "Then we just.",
                    "label": 0
                },
                {
                    "sent": "Just consider all ways to add one more node.",
                    "label": 0
                },
                {
                    "sent": "To the network.",
                    "label": 0
                },
                {
                    "sent": "And they are this.",
                    "label": 0
                },
                {
                    "sent": "Only thing that we need to accomplish this better thing which is basically sum over or possible parents.",
                    "label": 0
                },
                {
                    "sent": "It's that we can choose here.",
                    "label": 0
                }
            ]
        },
        "clip_13": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "So basically there are two cases.",
                    "label": 0
                },
                {
                    "sent": "If we are adding a node.",
                    "label": 0
                },
                {
                    "sent": "V to the network.",
                    "label": 0
                },
                {
                    "sent": "Then we have to consider 2 cases.",
                    "label": 0
                },
                {
                    "sent": "First, here at the left.",
                    "label": 0
                },
                {
                    "sent": "The node B is inset capital T, which means that there the we're summing over decks that.",
                    "label": 0
                },
                {
                    "sent": "Include a directed path from a small SV so therefore.",
                    "label": 0
                },
                {
                    "sent": "We can consider only.",
                    "label": 0
                },
                {
                    "sent": "The current sets that contain at least one node.",
                    "label": 0
                },
                {
                    "sent": "From that T. Capital T and then Turner case at the right is when the new node V is not in that set capital T. Which means that it is not allowed to have a parent in that capital T. Big cause.",
                    "label": 0
                },
                {
                    "sent": "If it had, then there would be a direct path to.",
                    "label": 0
                },
                {
                    "sent": "Lee",
                    "label": 0
                }
            ]
        },
        "clip_14": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "That was kind of brief outline of the algorithm.",
                    "label": 0
                },
                {
                    "sent": "Here if we ignore the polynomial factors, we get time and space requirement.",
                    "label": 1
                },
                {
                    "sent": "Treat the N where N is the number of variables.",
                    "label": 0
                },
                {
                    "sent": "So.",
                    "label": 0
                },
                {
                    "sent": "When we.",
                    "label": 0
                },
                {
                    "sent": "Asked this kind of learned learners, for instance, efficiently.",
                    "label": 0
                },
                {
                    "sent": "I guess it depends on the definition of FFCNZ.",
                    "label": 0
                },
                {
                    "sent": "The brute force approach would have been super exponential, so this is way better than that, but.",
                    "label": 0
                },
                {
                    "sent": "Quite limiting though.",
                    "label": 0
                },
                {
                    "sent": "So maximum 20 hours or so.",
                    "label": 0
                }
            ]
        },
        "clip_15": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, so then a few words about.",
                    "label": 0
                },
                {
                    "sent": "The experimental results.",
                    "label": 0
                },
                {
                    "sent": "We did some simulations.",
                    "label": 0
                },
                {
                    "sent": "About the power of the learning ancestor relations, here are some Roc curves for learning and sister relations and directed arcs.",
                    "label": 0
                },
                {
                    "sent": "With varying.",
                    "label": 0
                },
                {
                    "sent": "A number of UN observed variables.",
                    "label": 0
                },
                {
                    "sent": "So the power of course goes down when we have more upset variables.",
                    "label": 0
                },
                {
                    "sent": "However, even when there are.",
                    "label": 0
                },
                {
                    "sent": "For example.",
                    "label": 0
                },
                {
                    "sent": "Here we have.",
                    "label": 0
                },
                {
                    "sent": "For only four out of 14 nodes from our original network observed, we still have kind of reasonable.",
                    "label": 0
                },
                {
                    "sent": "Power.",
                    "label": 0
                }
            ]
        },
        "clip_16": {
            "is_summarization_sample": false,
            "summarization_data": [
                {
                    "sent": "OK, then another question was that.",
                    "label": 0
                },
                {
                    "sent": "What about?",
                    "label": 0
                },
                {
                    "sent": "Learning arc, so can we do?",
                    "label": 0
                },
                {
                    "sent": "As well.",
                    "label": 0
                },
                {
                    "sent": "Learning arcs as well as learning understory isn't directly.",
                    "label": 0
                },
                {
                    "sent": "So basically.",
                    "label": 0
                },
                {
                    "sent": "Here we have compared first this full Bayesian averaging.",
                    "label": 0
                },
                {
                    "sent": "Which basically.",
                    "label": 0
                },
                {
                    "sent": "Is that we first compute?",
                    "label": 0
                },
                {
                    "sent": "The poster probabilities for ancestor relations and then set a treshold and claim that all understood relations that has posted properly larger than this.",
                    "label": 0
                },
                {
                    "sent": "R. Present.",
                    "label": 0
                },
                {
                    "sent": "And then this parcel payers in averaging approach is that we learned our probabilities.",
                    "label": 0
                },
                {
                    "sent": "Then construct an index based on our probabilities and then.",
                    "label": 0
                },
                {
                    "sent": "Then they do studies the relations from the decks.",
                    "label": 0
                },
                {
                    "sent": "So basically here are some.",
                    "label": 0
                },
                {
                    "sent": "Subset of results.",
                    "label": 0
                },
                {
                    "sent": "So basically here are.",
                    "label": 0
                },
                {
                    "sent": "Here.",
                    "label": 0
                },
                {
                    "sent": "The leftmost and rightmost columns are kind of.",
                    "label": 0
                },
                {
                    "sent": "Average number of.",
                    "label": 0
                },
                {
                    "sent": "Guess this when the both methods Acree.",
                    "label": 0
                },
                {
                    "sent": "So in the middle columns there are times when.",
                    "label": 0
                },
                {
                    "sent": "They disagree, so they accurate almost.",
                    "label": 0
                },
                {
                    "sent": "Every time, especially with lots of data, and when you analyze.",
                    "label": 0
                },
                {
                    "sent": "The cases when.",
                    "label": 0
                },
                {
                    "sent": "They disagreed, it turns out the full players in averaging performs only slightly better.",
                    "label": 0
                }
            ]
        },
        "clip_17": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "So as a conclusion.",
                    "label": 0
                },
                {
                    "sent": "We have shown that.",
                    "label": 0
                },
                {
                    "sent": "The ancestor relation is going to be learned in computational fees in manner.",
                    "label": 0
                },
                {
                    "sent": "If we have moderate number of nodes.",
                    "label": 1
                },
                {
                    "sent": "And they can be learned.",
                    "label": 0
                },
                {
                    "sent": "With reasonable power, even in the presence of an observed variables, however, we can do almost equal equity if we use this parcel based in average.",
                    "label": 1
                }
            ]
        },
        "clip_18": {
            "is_summarization_sample": true,
            "summarization_data": [
                {
                    "sent": "Thank you.",
                    "label": 0
                },
                {
                    "sent": "Let's thank the speaker and we have time for a couple of questions perhaps.",
                    "label": 0
                },
                {
                    "sent": "OK, then I have a question.",
                    "label": 0
                },
                {
                    "sent": "I haven't fully understood how you handle unobserved variables.",
                    "label": 1
                },
                {
                    "sent": "It seems to me that.",
                    "label": 1
                },
                {
                    "sent": "Since you cannot score mugs, but you're scoring Bayesian networks.",
                    "label": 0
                },
                {
                    "sent": "And you have unobservables.",
                    "label": 0
                },
                {
                    "sent": "Your method, even with infinite sample size, when you have unobservables, may not give you.",
                    "label": 0
                },
                {
                    "sent": "Correct results, yes, so here the.",
                    "label": 0
                },
                {
                    "sent": "The kind of reliability aspect was that we have misspecified model, so we assume that.",
                    "label": 0
                },
                {
                    "sent": "That we don't have an object variables and then we.",
                    "label": 0
                },
                {
                    "sent": "Have actually situation where we actually have an observed variables and then we try to figure out that OK, how well we actually do.",
                    "label": 0
                },
                {
                    "sent": "If our assumption.",
                    "label": 0
                },
                {
                    "sent": "Isn't in agreement with the reality.",
                    "label": 0
                }
            ]
        }
    }
}